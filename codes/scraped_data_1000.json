{"http://act.cs.brown.edu/admission.html": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Get Involved Home Admission Joining ACT Lab Interested Ph.D. students should contact Prof. Ayanian and apply to Brown University Department of Computer Science or School of Engineering. ACT Lab is now at Brown University In January 2022, the ACT Lab moved from the University of Southern California to Brown University. Copyright \u00a9 ACT Lab 2018", "http://act.cs.brown.edu/group.html": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Our Team Home Group Faculty and Graduate Students Prof. Nora Ayanian Director nora_ayanian (at) brown (dot) edu Eric Ewing Ph.D. Student Anoop Kiran Ph.D. Student Lishuo Pan Ph.D. Student Arjun Prakash Ph.D. Student Jingyao Ren Ph.D. Candidate (at USC) Kegan Strawn Ph.D. Student (at USC) M.S. Students Vikraman Sathiyanarayanan Undergraduate Students Laura Lytle Eric Yi Han Chen Andrew Opem Pilar Luiz Natalie Abreu Former Lab Members Elizabeth Boroson, Graduate Research Assistant Connie Zhang, Graduate Research Assistant Baskin \u015eenba\u015flar, Graduate Research Assistant Wolfgang H\u00f6nig, Graduate Research Assistant Alp Cevikel, Master's Student Researcher Trevor Nielsen, Undergraduate Researcher Mark Debord, Master's Student Researcher John Zeiders, Undergraduate Researcher Barbara Boyajian, Undergraduate Researcher Jillian Khoo, Undergraduate Researcher Colin Heath, Undergraduate Researcher Virginia Dudley, Undergraduate Researcher Alex Colello, Undergraduate Researcher Sarthak Arora, Master's Student Researcher Chotiwat Chawannakul, Master's Student Researcher Pavle Medvidovic, Undergraduate Researcher Minzhi Xue, Master's Student Researcher Kim Luong, Undergraduate Researcher Joao Victor Cordeiro Coutinho, Visiting Researcher Nitin Kamra, Graduate Research Assistant Arash Tavakoli, Graduate Research Assistant Lindsay White, Undergraduate Researcher Chirag Sanghvi, Student Worker Abishek Hariharan, Master's Student Researcher U Chun Lao, Master's Student Researcher Kristen Morse, Master's Student Researcher Vishwa Theja, Master's Student Researcher Christina Milanes, Undergraduate Researcher Haig Nalbandian, Undergraduate Researcher Lisa Scaria, Undergraduate Researcher Luis Serv\u00edn, Visiting Researcher Copyright \u00a9 ACT Lab 2018", "http://act.cs.brown.edu/dynamic_allocation.html": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Long-Duration Deployments of Heterogeneous Teams of Robots Home Long-Duration Deployments of Heterogeneous Teams of Robots Description Many tasks require robots to operate in long-duration missions with minimal interruption for recharging or replenishing resources. However, robot power and resources are limited, and without a continuous supply of these resources, robots would have significant downtime for recharging or refreshing other resources, which could be severely disruptive to their mission. In this project, we are developing a theoretical framework to deploy teams of robots (task robots) for exploration and surveillance while taking into account their energy and resource requirements. We envision a distribution center with replenishable resources (batteries, cameras etc.) that receives or predicts requests for fresh resources from deployed robots, and dispatches agile delivery robots (e.g., quadrotors) to deliver them in a timely manner. We will address the scheduling and prediction problem underlying this distribution task and propose solutions which generate near-optimal schedules for resource redistribution with multiple incoming requests from deployed robots. The framework will incorporate priorities on task robots which can be changed over time, and allow a relaxed delivery schedule if there are not enough delivery robots available. Delivery robots can also be dynamically re-routed to make efficient use of time and resources to sustain long-duration missions for robotic teams operating in a given region. Investigators Jingyao Ren Nitin Kamra Ameer Hamza Nora Ayanian Related Publications N. Kamra, T. K. S. Kumar and N. Ayanian . \"Combinatorial Problems in Multirobot Battery Exchange Systems\", in IEEE Trans. Automation Science and Engineering, vol. 15, no. 2, pp. 852-862, April 2018. [ PDF Preprint , DOI , DBLP ] A. Hamza . \"Predicting mission power requirement for mobile robots\" (Master\u2019s Thesis). Viterbi School of Engineering, University of Southern California, 2015. [ Full Thesis ] N. Kamra and N. Ayanian . \u201cA Mixed Integer Programming Model for Timed Deliveries in Multirobot Systems\u201d, in IEEE Conf. on Automation Science and Engineering, Gothenburg, Sweden, August 2015. [ PDF Preprint , BibTeX ] Copyright \u00a9 ACT Lab 2018", "http://act.cs.brown.edu/actbot.html": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT ACTBot Home ACTBot Description Development of a differential-drive robot platform. The platform was successfuly created and is now in the software development and testing phase. We intend to create a public repository and plan on making both the hardware and software design files freely available in the near future. Investigators Luis Serv\u00edn Jacob Swanson Lindsay White Vishwa Theja Arash Tavakoli Nora Ayanian Copyright \u00a9 ACT Lab 2018", "http://act.cs.brown.edu/crazyswarm.html": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Crazyswarm Home Crazyswarm Description The Crazyswarm is a swarm of miniature quadcopters (Crazyflie 2.0) that can fly together in close proximity. Our approach has the goal to make research in multi-robot systems safer, cheaper, and easier to reproduce. The Crazyswarm has the following features (amongst others): Safe operation near humans Small footprint allows to fly many vehicles in small lab spaces Good crash resistance because of low inertia Fully open-source Off-the-shelf hardware The system currently requires a motion capture system (e.g. VICON, OptiTrack, or PhaseSpace). More information, including tutorials on how to setup the Crazyswarm, can be found on its webpage . A video demonstrating the swarms' capabilities is shown below. We used the Crazyswarm to experimentally validate our trajectory planning approach for large quadrotor teams (see related publications below). In the future, we are looking at other applications, including distributed algorithms. Investigators In collaboration with the Robotic Embedded Systems Laboratory (RESL). Wolfgang H\u00f6nig (Summer 2016 - ) James Preiss (RESL) (Summer 2016 - ) Gaurav Sukhatme (RESL) (Summer 2016 - ) Nora Ayanian (Summer 2016 - ) Daniel Lytle (Fall 2016 - ) Trevor Nielsen (Fall 2016 - ) Eric Yi Han Chen (Fall 2016 - ) Alex Colello (Fall 2017 - ) Barbara Boyajian (Fall 2017 - ) Jillian Khoo (Fall 2017 - ) Minzhi Xue (Fall 2015 - Spring 2016) Chotiwat Chawannakul (Summer 2016 - Summer 2017) Related Publications M. Debord , W. H\u00f6nig , and N. Ayanian . \"Trajectory Planning for Heterogeneous Robot Teams\", in Proc. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Madrid, Spain, October 2018. [ PDF Preprint , Video , Blog Post ] M. Debord , W. H\u00f6nig , and N. Ayanian . \"Trajectory Planning for Heterogeneous Robot Teams\", in 2nd International Symposium on Aerial Robotics (ISAR), Philadelphia, USA, June 2018. [ PDF Preprint , Video ] W. H\u00f6nig , J. A. Preiss, T. K. S. Kumar, G. S. Sukhatme, and N. Ayanian . \"Trajectory Planning for Quadrotor Swarms\", in IEEE Transactions on Robotics (T-RO), Special Issue Aerial Swarm Robotics. To Appear. [ PDF Preprint , Video ] J. A. Preiss, W. H\u00f6nig , G. S. Sukhatme, and N. Ayanian . \"Downwash-Aware Trajectory Planning for Large Quadrotor Teams\", in Proc. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Vancouver, BC, Canada, September 2017. [ PDF Preprint , Video ] J. A. Preiss, W. H\u00f6nig , G. S. Sukhatme, and N. Ayanian . \"Downwash-Aware Trajectory Planning for Quadrotor Swarms\", in International Symposium on Aerial Robotics, Philadelphia, PA, USA, June 2017. [ PDF Preprint ] J. A. Preiss, W. H\u00f6nig , G. S. Sukhatme, and N. Ayanian . \"Downwash-Aware Trajectory Planning for Large Quadcopter Teams\", in Southern California Robotics Symposium (SCR), Los Angeles, CA, April 2017. [ PDF Preprint ] J. A. Preiss*, W. H\u00f6nig* , G. S. Sukhatme, and N. Ayanian . \"Crazyswarm: A Large Nano-Quadcopter Swarm\", in Proc. IEEE International Conference on Robotics and Automation, Singapore, 2017. [ PDF Preprint , Video ] J. A. Preiss*, W. H\u00f6nig* , G. S. Sukhatme, and N. Ayanian . \"Crazyswarm: A Large Nano-Quadcopter Swarm (Extended Abstract)\", in Proc. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (Late Breaking), Daejeon, Korea, October 2016. [ PDF Preprint , Video ] Media Coverage USA Today Copyright \u00a9 ACT Lab 2018", "http://act.cs.brown.edu/contact.html": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Contact Home Contact Email Nora Ayanian E : nora_ayanian (at) brown (dot) edu Offices Department of Computer Science 115 Waterman St Providence, Rhode Island 02906 Copyright \u00a9 ACT Lab 2018", "http://act.cs.brown.edu": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Welcome About Us The Automatic Coordination of Teams (ACT) Lab at Brown University. ACT Lab conducts research in the area of coordinated multi-robot systems. The common theme behind our different research threads is that we provide theoretically sound solutions to practically motivated problems. The research of ACT is supported by Office of Naval Research (ONR) , Army Research Laboratory (ARL) , and National Science Foundation (NSF) . Media Follow Us On: Learn More About Brown Robotics: Recent Highlights Our paper \"Inter-Robot Range Measurements in Pose Graph Optimization\" was accepted to IROS 2020. June 2020 Connie Zhang was awarded the NSF Graduate Research Fellowship beginning Fall 2020. April 2020 Eric Ewing was awarded the NSF Graduate Research Fellowship Honorable Mention. April 2020 Our paper \"3-Dimensional Keypoint Repeatability for Heterogeneous Multi-Robot SLAM\" was accepted to ICRA 2019. January 2019 Our paper \"Persistent and Robust Execution of MAPF Schedules in Warehouses\" was accepted to IEEE RA-L 2019. December 2018 Elizabeth Boroson was awarded the NASA Space Technology Research Fellowship beginning Fall 2018. August 2018 Our paper \"Trajectory Planning for Heterogeneous Robot Teams\" was accepted to IROS 2018. June 2018 Our paper \"Conflict-Based Search with Optimal Task Assignment\" was accepted to AAMAS 2018 (joint work with Amazon Robotics). January 2018 Older Highlights... We are seeking multiple Ph.D. students to work on multiple federally funded projects in multi-robot systems. November 2017 Our paper \"Downwash-Aware Trajectory Planning for Large Quadrotor Teams\" was accepted to IROS 2017 June 2017 Our Crazyswarm research is featured at USA Today March 2017 Our paper \"Crazyswarm: A Large Nano-Quadcopter Swarm\" was accepted to IEEE ICRA 2017 January 2017 Our paper \"Seamless Robot Simulation Integration for Education: A Case Study\" has been accepted at the workshop on the Role of Simulation in Robot Programming at SIMPAR 2016. November 2016 Our book chapter \"Flying Multiple UAVs Using ROS\" will appear in the Springer Book on Robot Operating System (ROS) 2017 November 2016 Our Crazyswarm was Accepted to Appear in IEEE IROS 2016 Late Breaking August 2016 Dr. Ayanian Selected by MIT Technology Review as a TR35 Top Innovator August 2016 Two of our submissions were accepted to IROS! July 2016 Our paper \"Multi-Agent Path Finding with Kinematic Contraints\" wins Best Paper in Robotics Track at ICAPS March 2016 Our paper \"Multi-Agent Path Finding with Kinematic Contraints\" was accepted to ICAPS January 2016 ACT Lab featured in the inside cover of the USC Viterbi magazine November 2015 Paper Accepted to Appear in IEEE IROS 2015 July 2015 Dr. Ayanian Honored in Inaugural Mic 50 June 2015 Our Paper is Accepted to Appear in IEEE CASE 2015 May 2015 Dr. Ayanian wins the Hanna Reisler Mentorship Award April 2015 Undergrads in the ACT Lab Receive WiSE Research Awards April 2015 Winning the Best Demo Award in the Annual Research Review March 2015 Copyright \u00a9 ACT Lab 2018 $('.carousel').carousel({ interval: 5000 //changes the speed })", "http://act.cs.brown.edu/human-inspired.html": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Human-Inspired Multirobot Coordination Home Human-Inspired Multirobot Coordination Description Tasks requiring tight coordination between groups of robots are very challenging. Typical approaches use groups with fixed hierarchies or the same simple algorithms on all robots, which may not work for unknown environments and complex problems. However, humans are very good at coordinating and adapting to changes in the environment. A major reason for this is their diversity. In a group, humans take different roles and work together to reach a better solution than they would individually. To understand the behaviors humans use to cooperate, we have developed an online multiplayer game in which a group of players must arrange themselves in a formation using only a limited view of their immediate surroundings, simulating a robot with a lidar sensor. We have observed that humans learn to complete this task efficiently, and take on diverse roles to ensure group success. Every group has some players who take a leading role and direct others into place, some who collaborate by joining groups and forming lines, and some who create anchors for the group to form around. Over several consecutive games, players maintain the same roles, and the group learns to tightly coordinate their actions. We plan to train diverse groups of autonomous agents and robots to use these same behaviors to coordinate on shape formation and other complex tasks. The video below shows a group playing the cooperative game with instructions to form a rectangle. Each participant has only the neighborhood view so can only see the area directly around their position. The players initially form several parts of shapes before finding the rest of the group, and show different roles and communication as they coordinate to form the final rectangle. Investigators Elizabeth Boroson Sarthak Arora John Zeiders Nora Ayanian Funding This project is supported by NSF CAREER IIS-1553726 . Related Publications Refereed Conference Papers and Abstracts E. Boroson , F. Sha, and N. Ayanian . \"Model-Free Policy Gradients for Multi-Agent ShapeFormation (Extended Abstract)\", in Proc. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (Poster), Vancouver, BC, Canada, September 2017. [ PDF Preprint ] A. Tavakoli , H. Nalbandian , and N. Ayanian . \"Crowdsourced Coordination Through Online Games\", in ACM/IEEE Intl Conf. on Human Robot Interaction Late Breaking Reports, 2016. [ PDF Preprint , BibTeX ] Workshop Papers A. Tavakoli and N. Ayanian . \"Multirobot Coordination by Multiplayer Games\", in International Conference on Robotics and Automation (ICRA) Fielded Multi-Robot Systems Operating On Land, Sea, and Air Workshop, 2016. Preprints and Papers Under Review A. Tavakoli , H. Nalbandian , and N. Ayanian . \"Multiplayer Games for Learning Multirobot Coordination Algorithms\". arXiv preprint arXiv:1604.05942. 2016. [ PDF Preprint , arXiv , BibTeX ] Copyright \u00a9 ACT Lab 2018", "http://act.cs.brown.edu/mapfast.html": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Algorithm Selection for Multi-Agent Pathfinding(MAPF) Problems Home Algorithm Selection for Multi-Agent Pathfinding(MAPF) Problems Description Solving the Multi-Agent Path Finding (MAPF) problem optimally is known to be NP-Hard for both make-span and total arrival time minimization. While many algorithms have been developed to solve MAPF problems, there is no dominating optimal MAPF algorithm that works well in all types of problems and no standard guidelines for when to use which algorithm. In this work, we build deep learning network which takes a MAPF problem instance and attempts to select the fastest algorithm to use from a portfolio of algorithms. We improve the performance of our model by including single-agent shortest paths in the instance embedding given to our model and by utilizing supplemental loss functions in addition to a classification loss. We evaluate our model on a large and diverse dataset of MAPF instances, showing that it outperforms all individual algorithms in its portfolio as well as the state-of-the-art optimal MAPF algorithm selector. We also provide an analysis of algorithm behavior in our dataset to gain a deeper understanding of optimal MAPF algorithms' strengths and weaknesses to help other researchers leverage different heuristics in algorithm designs. Investigators Jingyao Ren Eric Ewing Baskin Senbaslar Vikraman Sathiyanarayanan Nora Ayanian Funding This research was supported by NSF awards IIS-1553726, IIS-1724392, IIS-1724399, and CNS-1837779 as well as a gift from Amazon. Related Publications Ren J, Sathiyanarayanan V, Ewing E, Senbaslar B, Ayanian N. \"MAPFAST: A Deep Algorithm Selector for Multi Agent Path Finding using Shortest Path Embeddings\". In Proceedings of the 20th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS-21) 2021 May 3 (pp. 1055-1063). [ PDF ] Ren J, Sathiyanarayanan V, Ewing E, Senbaslar B, Ayanian N. \"Automatic Optimal Multi-Agent Path Finding Algorithm Selector (Student Abstract)\". In Proceedings of the AAAI Conference on Artificial Intelligence 2021 May 18 (Vol. 35, No. 18, pp. 15877-15878). [ PDF ] Copyright \u00a9 ACT Lab 2018", "http://act.cs.brown.edu/mixed-reality.html": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Mixed Reality for Robotics Home Mixed Reality for Robotics Description When robots operate in shared environments with humans, they are expected to behave predictably, operate safely, and complete the task even with the uncertainty inherent with human interaction. Preparing such a system for deployment often requires testing the robots in an environment shared with humans in order to resolve any unanticipated robot behaviors or reactions, which could be potentially dangerous to the human.In the case of a multi-robot system, uncertainty compounds and opportunities for error multiply, increasing the need for exhaustive testing in the shared environment but at the same time increasing the possibility of harm to both the robots and the human. As the number of components of the system (humans, robots, etc.) increases, controlling and debugging the system becomes more difficult. Allowing system components to operate in a combination of physical and virtual environments can provide a safer and simpler way to test these interactions, not only by separating the system components, but also by allowing a gradual transition of the system components into shared physical environments. Such a Mixed Reality platform is a powerful tool for testing that can address these issues and has been used to varying degrees in robotics and other fields. We present Mixed Reality as a tool for multi-robot research and discuss the necessary components for effective use. Furthermore, we present practical applications with different robots (Crazyflie 2 and TurtleBot 2) and simulation platforms (Gazebo, V-REP, and Unity 3D.) Investigators In collaboration with the Mixed Reality Laboratory (MxR). Wolfgang H\u00f6nig Christina Milanes Lisa Scaria Thai Phan (MxR) Mark Bolas (MxR) Nora Ayanian Related Publications Thai Phan, W. H\u00f6nig , and N. Ayanian . \"Mixed Reality Collaboration between Human-Agent Teams (Extended Abstract)\", in Proc. IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR) (Poster), Reutlingen, Germany, March 2018. [ PDF Preprint , Video ] W. H\u00f6nig , C. Milanes , L. Scaria , T. Phan, M. Bolas, and N. Ayanian . \"Mixed Reality for Robotics\", in IEEE/RSJ Intl Conf. on Intelligent Robots and Systems, Hamburg, Germany, September 2015. [ PDF Preprint , Video , Code , BibTeX ] Copyright \u00a9 ACT Lab 2018", "http://act.cs.brown.edu/index.html": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Welcome About Us The Automatic Coordination of Teams (ACT) Lab at Brown University. ACT Lab conducts research in the area of coordinated multi-robot systems. The common theme behind our different research threads is that we provide theoretically sound solutions to practically motivated problems. The research of ACT is supported by Office of Naval Research (ONR) , Army Research Laboratory (ARL) , and National Science Foundation (NSF) . Media Follow Us On: Learn More About Brown Robotics: Recent Highlights Our paper \"Inter-Robot Range Measurements in Pose Graph Optimization\" was accepted to IROS 2020. June 2020 Connie Zhang was awarded the NSF Graduate Research Fellowship beginning Fall 2020. April 2020 Eric Ewing was awarded the NSF Graduate Research Fellowship Honorable Mention. April 2020 Our paper \"3-Dimensional Keypoint Repeatability for Heterogeneous Multi-Robot SLAM\" was accepted to ICRA 2019. January 2019 Our paper \"Persistent and Robust Execution of MAPF Schedules in Warehouses\" was accepted to IEEE RA-L 2019. December 2018 Elizabeth Boroson was awarded the NASA Space Technology Research Fellowship beginning Fall 2018. August 2018 Our paper \"Trajectory Planning for Heterogeneous Robot Teams\" was accepted to IROS 2018. June 2018 Our paper \"Conflict-Based Search with Optimal Task Assignment\" was accepted to AAMAS 2018 (joint work with Amazon Robotics). January 2018 Older Highlights... We are seeking multiple Ph.D. students to work on multiple federally funded projects in multi-robot systems. November 2017 Our paper \"Downwash-Aware Trajectory Planning for Large Quadrotor Teams\" was accepted to IROS 2017 June 2017 Our Crazyswarm research is featured at USA Today March 2017 Our paper \"Crazyswarm: A Large Nano-Quadcopter Swarm\" was accepted to IEEE ICRA 2017 January 2017 Our paper \"Seamless Robot Simulation Integration for Education: A Case Study\" has been accepted at the workshop on the Role of Simulation in Robot Programming at SIMPAR 2016. November 2016 Our book chapter \"Flying Multiple UAVs Using ROS\" will appear in the Springer Book on Robot Operating System (ROS) 2017 November 2016 Our Crazyswarm was Accepted to Appear in IEEE IROS 2016 Late Breaking August 2016 Dr. Ayanian Selected by MIT Technology Review as a TR35 Top Innovator August 2016 Two of our submissions were accepted to IROS! July 2016 Our paper \"Multi-Agent Path Finding with Kinematic Contraints\" wins Best Paper in Robotics Track at ICAPS March 2016 Our paper \"Multi-Agent Path Finding with Kinematic Contraints\" was accepted to ICAPS January 2016 ACT Lab featured in the inside cover of the USC Viterbi magazine November 2015 Paper Accepted to Appear in IEEE IROS 2015 July 2015 Dr. Ayanian Honored in Inaugural Mic 50 June 2015 Our Paper is Accepted to Appear in IEEE CASE 2015 May 2015 Dr. Ayanian wins the Hanna Reisler Mentorship Award April 2015 Undergrads in the ACT Lab Receive WiSE Research Awards April 2015 Winning the Best Demo Award in the Annual Research Review March 2015 Copyright \u00a9 ACT Lab 2018 $('.carousel').carousel({ interval: 5000 //changes the speed })", "http://act.cs.brown.edu/motion-coordination.html": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Motion Coordination for Multi-Robot Systems Home Motion Coordination for Multi-Robot Systems Description Planning is a crucial component in robotic systems. Nevertheless, the state-of-the art algorithms do not perform well in realistic conditions for robot groups. On the one hand, sampling or graph based methods which operate in joint space suffer from the dimensionality explosion. On the other hand, planners which try to avoid that effect make simplifying assumptions, limiting its practical applications. We investigate planning algorithms which work in realistic conditions (that is kinematic constraints and imperfect plan execution) for robot groups. Because there is always the possibility that a single robot fails, such plans need to be either be computable in a very short amount of time or it needs to be possible to update them online. The following video shows an example of a motion planning problem. The robots need to swap sides, but there is only a small corridor available. Nevertheless, we want to find a motion plan for each robot such that the overal swapping time is minimal (or within a specifiable factor away from the optimum). Investigators In collaboration with the Intelligent Decision Making Laboratory (IDM Lab). Wolfgang H\u00f6nig B. \u015eenba\u015flar M. Debord T. K. Satish Kumar Liron Cohen (IDM Lab) Hang Ma (IDM Lab) Hong Xu (IDM Lab) Sven Koenig (IDM Lab) Nora Ayanian Funding This project is supported by NSF IIS-1724392 and NSF CNS-1837779 . Related Publications W. H\u00f6nig , S. Kiesel, A. Tinka, J. W. Durham,, and N. Ayanian . \"Persistent and Robust Execution of MAPF Schedules in Warehouses\", in IEEE Robotics and Automation Letters (RA-L), Accepted, To Appear, 2019. [ PDF Preprint , Video , DOI ] B. \u015eenba\u015flar , W. H\u00f6nig , and N. Ayanian . \"Robust Trajectory Execution for Multi-Robot Teams Using Distributed Real-time Replanning (Extended Abstract)\", in IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (Poster), Madrid, Spain, October 2018. [ PDF Preprint , Video ] B. \u015eenba\u015flar , W. H\u00f6nig , and N. Ayanian . \"Robust Trajectory Execution for Multi-Robot Teams Using Distributed Real-time Replanning\", in Int. Symp. on Distributed Autonomous Robotic Systems (DARS), Boulder, CO, USA, October 2018. [ PDF Preprint , Video ] W. H\u00f6nig , J. A. Preiss, T. K. S. Kumar, G. S. Sukhatme, and N. Ayanian . \"Trajectory Planning for Quadrotor Swarms\", in IEEE Transactions on Robotics (T-RO), Special Issue Aerial Swarm Robotics, vol. 34, no. 4, pp. 856-869, August 2018. [ PDF Preprint , Video , DOI ] M. Debord , W. H\u00f6nig , and N. Ayanian . \"Trajectory Planning for Heterogeneous Robot Teams\", in Proc. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Madrid, Spain, October 2018. [ PDF Preprint , Video , Blog Post ] W. H\u00f6nig , S. Kiesel, A. Tinka, J. W. Durham, and N. Ayanian . \"Conflict-Based Search with Optimal Task Assignment\", In Proc. of the 17th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), Stockholm, Sweden, July 2018. [ PDF Preprint , ACM , DBLP ] J. A. Preiss, W. H\u00f6nig , G. S. Sukhatme, and N. Ayanian . \"Downwash-Aware Trajectory Planning for Large Quadrotor Teams\", in Proc. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Vancouver, BC, Canada, September 2017. [ PDF Preprint , Video , DOI , DBLP ] H. Ma, W. H\u00f6nig , L. Cohen, T. Uras, H. Xu, T. K. S. Kumar, N. Ayanian and S. Koenig. \"Overview: A Hierarchical Framework for Plan Generation and Execution in Multirobot Systems\", in IEEE Intelligent Systems, vol. 32, no. 6, pp. 6-12, November/December 2017. [ PDF Preprint , Video , DOI , DBLP ] W. H\u00f6nig , T. K. S. Kumar, L. Cohen, H. Ma, H. Xu, N. Ayanian , and S. Koenig. \"Summary: Multi-Agent Path Finding with Kinematic Contraints\", in International Joint Conferences on Artificial Intelligence, Melbourne, Australia, August 2017. [ PDF , Video , DBLP ] W. H\u00f6nig , T. K. S. Kumar , H. Ma, S. Koenig, and N. Ayanian \"Formation change for robot groups in occluded environments\", in Proc. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Daejeon, Korea, October 2016. [ PDF Preprint , Video , BibTeX ] H. Ma, S. Koenig, N. Ayanian , L. Cohen, W. H\u00f6nig , T. K. S. Kumar , T. Uras, H. Xu, C. Tovey, and G. Sharon. \"Overview: Generalizations of Multi-Agent Path Finding to Real-World Scenarios\", in IJCAI-16 Workshop on Multi-Agent Path Finding (WOMPF), New York City, NY, July 2016. [ PDF Preprint ] W. H\u00f6nig , T. K. S. Kumar , L. Cohen, H. Ma, S. Koenig, and N. Ayanian . \"Path Planning With Kinematic Constraints For Robot Groups\", in Southern California Robotics Symposium (SCR), San Diego, CA, April 2016. [ PDF Preprint ] W. H\u00f6nig , T. K. S. Kumar , L. Cohen, H. Ma, H. Xu, N. Ayanian , and S. Koenig. \"Multi-Agent Path Finding with Kinematic Contraints\", in International Conference on Automated Planning and Scheduling, London, U.K., June 2016. AWARDED BEST PAPER IN ROBOTICS TRACK. [ PDF Preprint , Video , BibTeX ] Copyright \u00a9 ACT Lab 2018", "http://act.cs.brown.edu/multi-target-tracking.html": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Heterogeneous Multi-Target Tracking Home Heterogeneous Multi-Target Tracking Description Tracking multiple moving targets in a dynamic environment has many applications. For example, it can be used in surveillance, in sports events to keep track on where the players are, or for tracking the position of animals. Furthermore, if cameras are used for tracking, it is beneficial to maximize the visual coverage of the targets. This can be used in post-processing, for example in case of sports events to give detailed feedback about the players, or in case of animals to create 3D-Animations. To achieve both tracking and maximum visual coverage, the robots must collaborate and share sensor information. Moreover, planed paths need to take the limited fields of operation, occlusion, and obstacles into account. A video for the 2D-case is shown below. Assume there are cameras placed on differential drive robots. All robots collaborate to maximize the coverage (marked as green edges) and minimize the surface area which is not visible (red edges). Dynamic path planning is used to find a path to better configuration (blue lines). Investigators Wolfgang H\u00f6nig Nora Ayanian Related Publications W. H\u00f6nig and N. Ayanian . \"Dynamic multi-target coverage with robotic cameras\", in Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., 2016. Accepted, to appear. [ PDF Preprint , Video , BibTeX ] Copyright \u00a9 ACT Lab 2018", "http://act.cs.brown.edu/mrhi.html": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Multi-Robot-Human Interaction Home Multi-Robot-Human Interaction Description Coming soon. Investigators Kegan Strawn Funding Related Publications Workshop Papers K. J. Strawn and N. Ayanian . \"Symmetry Agnostic Learning for Multi-Robot Zero-Shot Coordination\", in AAMAS Workshop on Autonomous and Multi-Robot Systems, May 2022. [ PDF Preprint ] Copyright \u00a9 ACT Lab 2018", "http://act.cs.brown.edu/publications.html": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Publications Home Publications Book Chapters and Journal Publications W. H\u00f6nig , S. Kiesel, A. Tinka, J. W. Durham,, and N. Ayanian . \"Persistent and Robust Execution of MAPF Schedules in Warehouses\", in IEEE Robotics and Automation Letters (RA-L), vol. 4, no. 2, pp. 1125-1131, April 2019. [ PDF Preprint , Video , DOI ] N. Ayanian . \"DART: Diversity-enhanced autonomy in robot teams\", in International Journal of Robotics Research (IJRR), March 2019. [ DOI ] T. Abdelzaher, N. Ayanian , T. Basar, S. Diggavi, J. Diesner, D. Ganesan, R. Govindan, S. Jha, T. Lepoint, B. Marlin, K. Nahrstedt, D. Nicol, R. Rajkumar, S. Russell, S. Seshia, F. Sha, P. Shenoy, M. Srivastava, G. Sukhatme, A. Swami, P. Tabuada, D. Towsley, N. Vaidya and V. Veeravalli. \"Toward an internet of battlefield things: A resilience perspective\", in Computer, vol. 51, no. 11, pp. 24-36, Nov 2018. [ DOI ] W. H\u00f6nig , J. A. Preiss, T. K. S. Kumar, G. S. Sukhatme, and N. Ayanian . \"Trajectory Planning for Quadrotor Swarms\", in IEEE Transactions on Robotics (T-RO), Special Issue Aerial Swarm Robotics, vol. 34, no. 4, pp. 856-869, August 2018. [ PDF Preprint , Video , DOI ] N. Kamra, T. K. S. Kumar and N. Ayanian . \"Combinatorial Problems in Multirobot Battery Exchange Systems\", in IEEE Trans. Automation Science and Engineering, vol. 15, no. 2, pp. 852-862, April 2018. [ PDF Preprint , DOI , DBLP ] H. Ma, W. H\u00f6nig , L. Cohen, T. Uras, H. Xu, T. K. S. Kumar, N. Ayanian and S. Koenig. \"Overview: A Hierarchical Framework for Plan Generation and Execution in Multirobot Systems\", in IEEE Intelligent Systems, vol. 32, no. 6, pp. 6-12, November/December 2017. [ PDF Preprint , Video , DOI , DBLP ] W. H\u00f6nig and N. Ayanian . \"Flying Multiple UAVs Using ROS\", Chapter in Robot Operating System (ROS): The Complete Reference (Volume 2), Springer, 2017. [ PDF Preprint This is a pre-print of a contribution published in \"Robot Operating System (ROS)The Complete Reference (Volume 2)\" (Editor: Koubaa, Anis) published by Springer. The definitive authenticated version is available online via DOI . ] K. Hausman, J. M\u00fcller, A. Hariharan , N. Ayanian and G. Sukhatme. \"Cooperative Control for Target Tracking with Onboard Sensing\", in International Journal of Robotics Research, vol. 34, no. 13, pp. 1660-1677, Nov. 2015. [ PDF Preprint , BibTeX ] Refereed Conference Publications K. Strawn and N. Ayanian . \"Byzantine Fault Tolerant Consensus for Multi-Robot Pickup and Delivery \", in International Symposium on Distributed Autonomous Robotic Systems (DARS), June 2021. [ PDF Preprint ] J. Ren , V. Sathiyanarayanan , E. Ewing , B. \u015eenba\u015flar , and N. Ayanian . \"Automatic Optimal Multi-Agent Path Finding Algorithm Selector (Extended Abstract)\", in AAAI Conference on Artificial Intelligence (AAAI), Accepted, to appear February 2021. [ PDF Preprint ] E.R. Boroson , R. Hewitt, N. Ayanian , and J.-P. de la Croix. \"Inter-Robot Range Measurements in Pose Graph Optimization\", in IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), October 2020. A. Molchanov, T. Chen, W. H\u00f6nig , J.A. Preiss, N. Ayanian , and G.S. Sukhatme. \"Sim- to-(Multi)- Real: Transfer of Low-Level Robust Control Policies to Multiple Quadrotors\", in IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Macau, China, November 2019. E. R. Boroson and N. Ayanian . \"3D Keypoint Repeatability for Heterogeneous Multi-Robot SLAM\", in IEEE International Conference on Robotics and Automation (ICRA), Montr\u00e9al, Canada, May 2019. [ PDF Preprint ] D. Albani* , W. H\u00f6nig* , N. Ayanian , D. Nardi, and V. Trianni. \"Summary: Distributed Task Assignment and Path Planningwith Limited Communication for Robot Teams (Short Paper)\", in International Conference on Autonomous Agents and Multiagent Systems (AAMAS) 2019. [ PDF Preprint ] H. Ma, W. H\u00f6nig , S. Kumar, N. Ayanian , and S. Koenig. \"Lifelong Path Planning with Kinematic Constraints for Multi-Agent Pickup and Delivery\", Proceedings of the AAAI Conference on Artificial Intelligence (AAAI) 2019. [ PDF Preprint , Appendix , Video 1 , Video 2 , Video 3 , Video 4 , Video 5 , Video 6 ] B. \u015eenba\u015flar , W. H\u00f6nig , and N. Ayanian . \"Robust Trajectory Execution for Multi-Robot Teams Using Distributed Real-time Replanning (Extended Abstract)\", in IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (Poster), Madrid, Spain, October 2018. [ PDF Preprint , Video ] B. \u015eenba\u015flar , W. H\u00f6nig , and N. Ayanian . \"Robust Trajectory Execution for Multi-Robot Teams Using Distributed Real-time Replanning\", in Int. Symp. on Distributed Autonomous Robotic Systems (DARS), Boulder, CO, USA, October 2018. [ PDF Preprint , Video , Code ] M. Debord , W. H\u00f6nig , and N. Ayanian . \"Trajectory Planning for Heterogeneous Robot Teams\", in Proc. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Madrid, Spain, October 2018. [ PDF Preprint , Video , Blog Post ] W. H\u00f6nig , S. Kiesel, A. Tinka, J. W. Durham, and N. Ayanian . \"Conflict-Based Search with Optimal Task Assignment\", In Proc. of the 17th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), Stockholm, Sweden, July 2018. [ PDF Preprint , ACM , DBLP ] T. Phan, W. H\u00f6nig , and N. Ayanian . \"Mixed Reality Collaboration between Human-Agent Teams (Extended Abstract)\", in Proc. IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR) (Poster), Reutlingen, Germany, March 2018. [ PDF Preprint , Video , DOI , DBLP ] N. Ayanian . \"DART: Diversity-enhanced autonomy in robot teams\", In International Symposium of Robotics Research (ISRR), Chile, Dec 2017. [ Talk available online , DOI ] J. A. Preiss, W. H\u00f6nig , G. S. Sukhatme, and N. Ayanian . \"Downwash-Aware Trajectory Planning for Large Quadrotor Teams\", in Proc. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Vancouver, BC, Canada, September 2017. [ PDF Preprint , Video , DOI , DBLP ] E. Boroson , F. Sha, and N. Ayanian . \"Model-Free Policy Gradients for Multi-Agent ShapeFormation (Extended Abstract)\", in IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (Poster), Vancouver, BC, Canada, September 2017. [ PDF Preprint ] W. H\u00f6nig , T. K. S. Kumar, L. Cohen, H. Ma, H. Xu, N. Ayanian , and S. Koenig. \"Summary: Multi-Agent Path Finding with Kinematic Contraints\", in International Joint Conferences on Artificial Intelligence, Melbourne, Australia, August 2017. [ PDF , Video , DOI , DBLP ] J. A. Preiss*, W. H\u00f6nig* , G. S. Sukhatme, and N. Ayanian . \"Crazyswarm: A Large Nano-Quadcopter Swarm\", in Proc. IEEE International Conference on Robotics and Automation, Singapore, 2017. [ PDF Preprint , Video ] J. A. Preiss*, W. H\u00f6nig* , G. S. Sukhatme, and N. Ayanian . \"Crazyswarm: A Large Nano-Quadcopter Swarm (Extended Abstract)\", in Proc. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (Late Breaking), Daejeon, Korea, October 2016. [ PDF Preprint , Video ] W. H\u00f6nig and N. Ayanian . \"Dynamic multi-target coverage with robotic cameras\", in Proc. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Daejeon, Korea, October 2016. [ PDF Preprint , Video , BibTeX ] W. H\u00f6nig , T. K. S. Kumar , H. Ma, S. Koenig, and N. Ayanian \"Formation change for robot groups in occluded environments\", in Proc. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Daejeon, Korea, October 2016. [ PDF Preprint , Video , BibTeX ] L. Cohen, T. K. S. Kumar , T. Uras, H. Xu, S. Koenig, and N. Ayanian . \"Improved Bounded-Suboptimal Multi-Agent Path Finding Solvers\", in Proc. International Joint Conference on Artificial Intelligence, New York, NY, July 2016. [ PDF , BibTeX ] W. H\u00f6nig , T. K. S. Kumar , L. Cohen, H. Ma, H. Xu, N. Ayanian , and S. Koenig. \"Multi-Agent Path Finding with Kinematic Contraints\", in International Conference on Automated Planning and Scheduling, London, U.K., June 2016. AWARDED BEST PAPER IN ROBOTICS TRACK. [ PDF Preprint , Video , BibTeX ] T. Cai, D. Zhang, T. K. S. Kumar , S. Koenig, and N. Ayanian . \"Local search on trees and a framework for automated construction using multiple identical robots\", in International Conference on Autonomous Agents and Multiagent Systems, Extended Abstract, Singapore, May 2016. [ PDF Preprint , BibTeX ] A. Tavakoli , H. Nalbandian , and N. Ayanian . \"Crowdsourced Coordination Through Online Games\", in ACM/IEEE Intl Conf. on Human Robot Interaction Late Breaking Reports, 2016. [ PDF Preprint , BibTeX ] W. H\u00f6nig , C. Milanes , L. Scaria , T. Phan, M. Bolas, and N. Ayanian . \"Mixed Reality for Robotics\", in IEEE/RSJ Intl Conf. on Intelligent Robots and Systems, Hamburg, Germany, September 2015. [ PDF Preprint , Video , Code , BibTeX ] S. Wang, B. Krishnamachari, and N. Ayanian . \"The Optimism Principle: A Unified Framework for Optimal Robotic Network Deployment in An Unknown Obstructed Environment\", IEEE/RSJ Intl Conf. on Intelligent Robots and Systems, Hamburg, Germany, September 2015. [ PDF Preprint , BibTeX ] N. Kamra and N. Ayanian . \u201cA Mixed Integer Programming Model for Timed Deliveries in Multirobot Systems\u201d, in IEEE Conf. on Automation Science and Engineering, Gothenburg, Sweden, August 2015. [ PDF Preprint , BibTeX ] S. Garg and N. Ayanian . \"Persistent Monitoring of Stochastic Spatio-temporal Phenomena with a Small Team of Robots\", in Robotics: Science and Systems X, Berkeley, CA, July 2014. [ PDF Preprint , BibTeX ] K. Hausman, J. M\u00fcller, A. Hariharan , N. Ayanian , and G. Sukhatme. \"Cooperative Control for Target Tracking with Onboard Sensing\", in Proceedings of the Int'l Symposium on Experimental Robotics, Morrocco, June 2014. [ PDF Preprint , BibTeX ] Master's Thesis A. Hamza . \"Predicting mission power requirement for mobile robots\" (Master\u2019s Thesis). Viterbi School of Engineering, University of Southern California, 2015. [ Full Thesis ] Workshops and Symposia K. J. Strawn and N. Ayanian . \"Symmetry Agnostic Learning for Multi-Robot Zero-Shot Coordination\", in International Conference on Autonomous Agents and Multiagent Systems (AAMAS), Auckland, New Zealand, May 2022. [ PDF Preprint ] M. Debord , W. H\u00f6nig , and N. Ayanian . \"Trajectory Planning for Heterogeneous Robot Teams\", in 2nd International Symposium on Aerial Robotics (ISAR), Philadelphia, USA, June 2018. [ PDF Preprint , Video ] W. H\u00f6nig . \"Scalable Task and Motion Planning for Multi-Robot Systems in Obstacle-Rich Environments (Doctoral Consortium)\", In Proc. of the 17th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), Stockholm, Sweden, July 2018. [ PDF Preprint , ACM , DBLP ] E. Boroson , F. Sha, and N. Ayanian . \"Model-Free Policy Gradients for Multi-Agent ShapeFormation\", in IEEE International Symposium on Multi-Robot and Multi-Agent Systems (MRS), Los Angeles, CA, December 2017. [ PDF Preprint ] J. A. Preiss, W. H\u00f6nig , G. S. Sukhatme, and N. Ayanian . \"Downwash-Aware Trajectory Planning for Quadrotor Swarms\", in International Symposium on Aerial Robotics, Philadelphia, PA, USA, June 2017. [ PDF Preprint ] J. A. Preiss, W. H\u00f6nig , G. S. Sukhatme, and N. Ayanian . \"Downwash-Aware Trajectory Planning for Large Quadcopter Teams\", in Southern California Robotics Symposium (SCR), Los Angeles, CA, April 2017. [ PDF Preprint ] W. H\u00f6nig , A. Tavakoli , and N. Ayanian . \"Seamless Robot Simulation Integration for Education: A Case Study\", Workshop on the Role of Simulation in Robot Programming at SIMPAR 2016, San Francisco, CA, December 2016. [ PDF Preprint , Code ] H. Ma, S. Koenig, N. Ayanian , L. Cohen, W. H\u00f6nig , T. K. S. Kumar , T. Uras, H. Xu, C. Tovey, and G. Sharon. \"Overview: Generalizations of Multi-Agent Path Finding to Real-World Scenarios\", in IJCAI-16 Workshop on Multi-Agent Path Finding (WOMPF), New York City, NY, July 2016. [ PDF Preprint ] W. H\u00f6nig , T. K. S. Kumar , L. Cohen, H. Ma, S. Koenig, and N. Ayanian . \"Path Planning With Kinematic Constraints For Robot Groups\", in Southern California Robotics Symposium (SCR), San Diego, CA, April 2016. [ PDF Preprint ] Copyright \u00a9 ACT Lab 2018", "http://act.cs.brown.edu/heterogeneous-mapping.html": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Mapping with Heterogeneous Robots Home Mapping with Heterogeneous Robots Description When robots operate in unknown environments like search and rescue or planetary exploration by rovers, it is important for them to build a map that can be used for localization, planning, and identifying science or search targets. Heterogeneous robots with different kinds of sensors are beneficial for exploration because they have different capabilities and may be able to search the area in different ways. However, it is extremely challenging to combine these measurements from different kinds of sensors. This project focuses on combining data from different kinds of sensors to build better maps, and on building maps that can be used by robots with different capabilities. Initially, we have focused on finding ways to represent information which is shared between different kinds of measurements, such as features which appear in point clouds created from different types of sensors, like LIDAR and stereo camera. We plan to do multi-robot SLAM and build maps with these features. We also plan additional work on improving map-building in groups of heterogeneous robots. Investigators Elizabeth Boroson Nora Ayanian Funding Elizabeth Boroson is funded by the NASA Space Technology Research Fellowship . Related Publications E.R. Boroson , R. Hewitt, N. Ayanian , and J.-P. de la Croix. \"Inter-Robot Range Measurements in Pose Graph Optimization\", in IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), October 2020. E.R. Boroson and N. Ayanian . \"3D Keypoint Repeatability for Heterogeneous Multi-Robot SLAM\", in IEEE International Conference on Robotics and Automation (ICRA), Montr\u00e9al, Canada, May 2019. [ PDF Preprint ] Copyright \u00a9 ACT Lab 2018", "http://act.cs.brown.edu/research.html": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Research Projects Home Research Algorithm Selection for Multi-Agent Pathfinding(MAPF) Problems Solving the Multi-Agent Path Finding (MAPF) problem optimally is known to be NP-Hard for both make-span and total arrival time minimization. While many algorithms have been developed to solve MAPF problems, there is no dominating optimal MAPF algorithm that works well in all types of problems and no standard guidelines for when to use which algorithm. In this work, we build deep learning network which takes a MAPF problem instance and attempts to select the fastest algorithm to use from a portfolio of algorithms. View Project Mapping with Heterogeneous Robots This project focuses on combining data from different kinds of sensors to build better maps, and on building maps that can be used by robots with different capabilities. View Project Motion Coordination for Multi-Robot Systems Traditional single-robot algorithms tend to be slow if applied to groups of robots due to the increased dimensionality of the state space. On the other hands, multi-agent solutions from the artificial intelligence community can often not be directly applied to robots because they make invalid, simplifying assumptions. We investigate solutions that bridge the gap between AI and robotics, allowing to plan for large multi-robot systems. View Project Long-Duration Deployments of Heterogeneous Teams We develop both a theoretical framework and empirical models for extended autonomy in multirobot teams. Long-duration deployments require replenished resources, such as batteries and sensors. Our framework deals with both predicting when those resources will be needed, as well as ensuring that they are delivered in a timely manner to reduce robot down-time. View Project Crazyswarm The Crazyswarm is a swarm of miniature quadcopters (Crazyflie 2.0) that can fly together in close proximity. The size of the quadrotors allows safe operations near humans and indoor experiments with many vehicles even in tight lab spaces. The hardware is commercially available and the software (including ROS support) is available as open source. We use and maintain the Crazyswarm for research in multi-robot coordination. View Project Human-Inspired Multirobot Coordination We use a cooperative online multiplayer games to observe the behaviors and algorithms humans use to work together. By applying learning techniques to data from humans, we plan to create an ensemble of diverse controllers for robots that can be used together to complete complex tasks. View Project Multi-Robot-Human Interaction We focus on developing safer and more efficient interaction between multiple robots and humans. We apply reinforcement learning, verification, and human-robot interaction techniques to multiple different interaction scenarios and applications. View Project Mixed Reality for Robotics Mixed Reality can be a valuable tool for research and development in robotics. Specifically, our approach reduces the gap between simulation and implementation, and can eliminate safety concerns with human-robot interaction. View Project Old Projects... Heterogeneous Multi-Target Tracking We investigate algorithms for mobile robotic cameras to maximize the visual coverage of multiple moving targets in dynamic environments including obstacles. This approach has a variety of applications, including for surveillance, sports events, training, and documentation of endangered animals. View Project ACTBot Development of a differential-drive robot platform. View Project \u00ab 1 Copyright \u00a9 ACT Lab 2018", "http://aireu.cs.brown.edu": "Welcome! How to Apply About the Program Faculty Mentors Recent Research Projects Review Criteria Applications for Summer '24 closed on Februrary 2nd. Review of applications is currently ongoing. Welcome! Brown Computer Science is proud to present \"Artificial Intelligence for Computational Creativity,\" an NSF Summer REU Site. This is a 9-week, fully-funded, summer residential program which brings students to the Brown University campus June 3 -- August 2 2024 to conduct original research with computer science faculty and graduate students. Our intellectual focus is creative applications of artificial intelligence: potential research topics include creative generative models (of visual and textual content), detecting \u201cfake\u201d generated content, AI for game playing, user experience design for creative AI systems, and more. Research in this field is poised to revolutionize the means of personal expression for everyone: in writing, photography, design, architecture, and more. Our REU Site is a partnership with The Leadership Alliance , a national consortium of more than 30 PhD-granting and Minority-Serving Institutions (MSIs) dedicated to training students from diverse cultural and academic backgrounds for graduate programs and professional research-based careers. We encourage applications from students from historically-underrepresented groups, which includes (but is not limited to) students that identify as women, underrepresented minority (URM), having a disability, first-generation college, low-income, and/or LGBTQ+. In addition to conducting original research, students at our site will participate in Alliance-led career development activities, professional networking opportunities, and social events. Apply to join us in Providence, Rhode Island this summer! How to Apply To apply for the program, submit an application via NSF ETAP: https://etap.nsf.gov/award/238/opportunity/6337 You will also need to submit an application to The Leadership Alliance's Summer Research Early Identification Program (SR-EIP): https://app.theleadershipalliance.org/ Please submit the same materials (statements, recommendation letters, etc.) to both applications. The application deadline is February 2, 2024 . Admission offers will be sent out on a rolling basis after the application deadline. About the Program Who is eligible to apply: US citizens or permanent residents who are enrolled in a degree program leading to a baccalaureate or associate degree. Students who are transferring from one college or university to another and are enrolled at neither institution during the summer may participate. High school graduates who have been accepted at an undergraduate institution but who have not yet started their undergraduate study are also eligible to participate. Students who have received their bachelor's degrees and are no longer enrolled as undergraduates are generally not eligible to participate. Experience needed: Prospective students should at minimum have completed an introductory computer science course sequence as well as mathematics courses covering calculus, linear algebra, and probability. Additional advanced coursework in areas related to the Site's theme (e.g. computer vision, machine learning) are helpful but not strictly required. Prior research experience is helpful but also not strictly required. Research activities: Participants will be paired with a faculty mentor and a graduate student mentor who will help guide them through a 9-week research project. This includes a weekly study group which walks students through the process of conceiving, developing, and presenting an original research proposal. In addition, the summer begins with crash courses on research methods, artificial intelligence and machine learning principles, and working with modern software tools for AI/ML. Other activities: In addition to their research projects, students will also have the opportunity to participate in Leadership Alliance-sponsored events including faculty and alumni panels on careers in research, graduate student panels on pathways to graduate school, group dinners, and more. We also plan to organize extracurricular social activities in the local area, such as visits to the RISD museum, excursions to Newport and Rhode Island's beaches, and Saturday night visits to Providence's Waterfire celebration. Time commitment: The program runs 9 weeks, from June 3 through August 2, 2024. You can expect to spend ~35 hours a week on your research and an additional ~5 hours a week in other required program activities. Most research and activities will take place between 9-5 Monday - Friday. Optional weekend social activities will also be included. Funding: Participating students will receive a stipend of $6,480 for the summer, in three installments. Students will live in Brown campus housing (with other members of the REU Site cohort) for the duration of the program; housing and travel costs to and from the campus will be covered by the program. Faculty Mentors Students who participate in our Site will be mentored by one or more of the following Brown CS faculty members: Daniel Ritchie Creating, editing, and analyzing 3D structures James Tompkin Creating, editing, and manipulating images and video Nora Ayanian How can we enable almost anyone to use teams of robots? Chen Sun Multimodal machine learning for computer vision to help language understanding, robotics, and social science Srinath Sridhar 3D vision & machine learning for understanding human physical interactions Recent Research Projects Here are just a few examples of research projects recently carried out by our faculty: A data-driven generative model that can synthesize new virtual bedrooms and other types of 3D indoor scenes. Learn more! Reconstructing time-varying 4D objects with unsupervised segmentation. Learn more! A neural network to 'reverse engineer' CAD modeling sequences for 3D shapes. Learn more! A system for creating new 3D floor plans by automatically recombining rooms from existing floor plans. Learn more! A neural network to transmogrify images of animals without altering the image background. Learn more! A neural network to write programs that generate structured 3D shapes, such as chairs. Learn more! High-resolution text-to-shape synthesis without any text labels at training time. Learn more! A neural network to insert images of objects into new environments. Learn more! A neural generative model that can learn to write in your handwriting and represent all kinds of different styles. Learn more! Building high-quality models of objects from only a few images. Learn more! Previous Next Review Criteria When we review applicants to the program, we are looking for the following qualities: Students with strong technical skills, as evidenced by grades in computer science and math courses, prior research projects, or other relevant experience. Students who write thoughtful, compelling statements about why they want to pursue research in creative applications of AI. Students who have limited opportunities to engage in CS research at their own college or university. Students who will contribute to a diverse cohort with a variety of backgrounds, experience levels, and perspectives.", "https://awards.cs.brown.edu/2014/07/22/layla-oespser-wins-ismb-workshop-best-presentation-award/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Layla Oesper Wins ISMB Workshop Best Presentation Award Posted by Jesse Polhemus on July 22, 2014 in Awards Last weekin Boston, Brown University \u2019s Department of Computer Science (BrownCS) and Centerfor Computational Molecular Biology (CCMB) managed to put a capstone ontheir achievement of giving a recordnumber of talks at one of the most prominent conferences in ComputationalBiology . Atthe twenty-second annual International Conference on Intelligent Systems forMolecular Biology (ISMB 2014), PhD candidate Layla Oesper \u2019s talk (\u201c Quantifying TumorHeterogeneity in Whole-Genome and Whole-Exome Sequencing Data\u201d) received theBest Presentation Award, accompanied by a cash prize of $250, for the \u201cHitSeq2014: High-Throughput Sequencing Algorithms and Applications\u201d workshop. Reachedfor comment, Layla says, \u201cI definitely want to acknowledge my co-authors, Gryteand Ben, on the work that was presented at HitSeq.This project is part of a team effort and itwouldn\u2019t have been possible without them.\u201d", "https://awards.cs.brown.edu/2015/10/07/mace-roelke-and-fonseca-win-best-paper-award-sosp-2015/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Mace, Roelke, And Fonseca Win A Best Paper Award At SOSP 2015 Posted by Jesse Polhemus on Oct. 7, 2015 in Awards Brown University Computer Science (Brown CS) PhD Candidate Jonathan Mace , Ryan Roelke '15 (now at Vertica), and Brown CS Assistant Professor Rodrigo Fonseca have just received one of three Best Paper Awards at the 25th Association for Computing Machinery (ACM) Symposium on Operating Systems Principles (SOSP 2015), currently being held in Monterey, California. SOSP is often considered the leading forum for researchers and developers of computer operating systems, and their research compared favorably with more than two dozen entries selected from over 300 global submissions, covering a wide range of theory and practice. Jonathan, Ryan, and Rodrigo\u2019s work (\u201c Pivot Tracing: Dynamic Causal Monitoring for Distributed Systems \u201d) addresses the challenge of monitoring and troubleshooting distributing systems with a monitoring framework that combines techniques from both the dynamic instrumentation and causal tracing literature. Pivot Tracing gives users, at runtime, the ability to define arbitrary metrics at one point of the system, while being able to select, alter, and group by events meaningful at other parts of the system, even when crossing component or machine boundaries. The result is a dynamic and extensible solution that enables cross-tier analysis between inter-operating applications with low execution overhead. \"This is the first framework we are aware of,\u201d Rodrigo says, \u201cthat allows you to ask questions about a system as it runs, while causally combining metrics across its distributed components.\"", "https://awards.cs.brown.edu/2016/05/06/krishna-chaitanya-aluru-wins-ycombinator-fellowship/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Krishna Chaitanya Aluru Wins A Y Combinator Fellowship Posted by Jesse Polhemus on May 6, 2016 in Awards The YC Fellowship, an experiment from Y Combinator in helping create startups, has just put a Brown University student on the path toward using computing to significantly improve lives on a global scale. Krishna Chaitanya Aluru of the Department of Computer Science (Brown CS) and his collaborators Akshat Goenka (Wharton) and Vamsee Chamakura (IIIT) have just been admitted to the program for their \"DocTalk\" project, earning $20,000 and eight weeks of advice from the Y Combinator community to transform their idea into an actual startup. Currently, a single doctor in India serves an astonishing 1,800 patients. DocTalk, which features an app co-developed with Brown University student Justin Brower, will enable doctors to maximize the number of patients they can consult with by solving some of the inefficiencies in the current healthcare ecosystem in India. (Further details will remain proprietary until launch.) \u201cInterviewing with YC was an incredible experience,\" Krishna says. \"We felt so lucky to be able to sit across the table from people who founded and funded insanely successful companies and talk to them about our idea. YC calls you the same day of the interview to let you know whether you got in. We actually decided to watch Zootopia that evening to take our minds off of it. It was barely ten minutes into the movie when we got the phone call from one of the partners saying that we were accepted into the fellowship. Being accepted is the best motivation we could have asked for as we work on DocTalk over the next few months. We\u2019re incredibly grateful and cannot wait to be a part of YC.\u201d For more information, please click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://awards.cs.brown.edu/2015/07/02/four-brown-cs-students-recognized-2015-google-scholars/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Four Brown CS Students Recognized As 2015 Google Scholars Posted by Jesse Polhemus on July 2, 2015 in Awards Four students from Brown University 's Department of Computer Science attended Google's Scholars Retreat in Mountain View, California this past week, where they each accepted highly selective Google scholarships. Together with an incoming student who was also chosen and one who was recognized as a finalist, they received recognition and support toward their education for the 2015-16 academic year as they become part of the next generation of diverse tech leaders. The students were awarded scholarships in several categories, achieving a level of representation that few Brown CS rivals matched: Sharon Lo '16 and Dana\u00eb Metaxa-Kakavouli '15 (incoming Stanford PhD student) won the Google Anita Borg Memorial Scholarship, awarded to 20 women students and leaders in CS Paige Selby M'16 and Eli White '18 won the Google Lime Award, awarded to 12 high-achieving CS students with disabilities Luis Aguirre '19 was one of 20 winners of the Generation Google Scholarship for incoming CS college students from underrepresented backgrounds Ebube Chuba '19 was also recognized as one of ten finalists for the Generation Google Scholarship. During the four-day retreat in Mountain View the scholars attended tech talks, networked with Google employees, participated in developmental activities and sessions, and attended social activities with the other Google scholars. \"I personally would say I left the retreat really appreciative that I get to be part of the Brown community,\" Sharon says. \"During the retreat, we had a talk from a program manager from Google X, one of Google's most innovative teams aimed at creating major 'moonshot' technological advancements and (surprise, but almost no surprise at all!) she was a Brown alum.\"", "https://awards.cs.brown.edu/2015/11/20/alexandra-papoutsaki-and-multiple-brown-cs-collaborators-win-best-paper-award-runner-hcomp-2015/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Multiple Brown CS Collaborators Win Two Best Paper Award Runner Up Honors At HCOMP 2015 Posted by Jesse Polhemus on Nov. 20, 2015 in Awards The Conference on Human Computation and Crowdsourcing (HCOMP), held this year in San Diego, is one of the most prominent conferences on the subject of human cooperation, computation, and crowdsourcing, and Brown University 's Department of Computer Science (Brown CS) made a strong showing this year. Two different groups of students and faculty have been declared Best Paper Award Runner Up at the recent HCOMP 2015: Tropel: Crowdsourcing Detectors with Minimal Training Genevieve Patterson (Brown CS PhD student), Grant Van Horn (California Institute of Technology), Serge Belongie (Cornell University and Cornell Tech), and James Hays (former Brown CS faculty member) received the award for research (\"Tropel: Crowdsourcing Detectors with Minimal Training\") named after the word for \"noisy crowd\" in Spanish. Genevieve would also like to thank Ben Bauer (Brown CS undergraduate student), who contributed software to the project. \"It was a big help and a pleasure to work with him,\" she says. Tropel is a system that enables non-technical users to create arbitrary visual detectors without first annotating a training set. \"Our primary contribution,\" the researchers explain, \" is a crowd active learning pipeline that is seeded with only a single positive example and an unlabeled set of training images. We examine the crowd\u2019s ability to train visual detectors given severely limited training themselves. This paper presents a series of experiments that reveal the relationship between worker training, worker consensus and the average precision of detectors trained by crowd-in-the-loop active learning. In order to verify the efficacy of our system, we train detectors for bird species that work nearly as well as those trained on the exhaustively labeled CUB 200 dataset at significantly lower cost and with little effort from the end user. To further illustrate the usefulness of our pipeline, we demonstrate qualitative results on unlabeled datasets containing fashion images and street- level photographs of Paris.\" Anyone interested in using Tropel should click the link that follows to contact Genevieve . Crowdsourcing from Scratch: A Pragmatic Experiment in Data Collection by Novice Requesters Alexandra Papoutsaki , (Brown CS PhD student), and collaborators Hua Guo (Brown CS PhD student), Danae Metaxa-Kakavouli (Brown CS alum), Connor Gramazio (Brown CS PhD student), Jeff Rasley (Brown CS PhD student), Wenting Xie (Brown University alum), Guan Wang (Brown CS PhD student), and Jeff Huang (Brown CS Assistant Professor) received the award for research (\"Crowdsourcing from Scratch: A Pragmatic Experiment in Data Collection by Novice Requesters\" ) that became something of an Internet sensation, attracting more than 20,000 views in a single week and 100,000 unique visitors to date, including academics, researchers, and potential graduate students. It's the result of a class assignment from the CS2951-L HCI seminar as taught by Jeff in Spring 2014 . All the other authors attended the class as students and were able to see an assignment turn into a peer-reviewed publication. For the undergraduates of the group (Danae and Wenting), it was their first in what will undoubtedly be a long line of publications. To determine how novice requesters design crowdsourcing tasks, the group conducted an experiment with a class of 19 students, each of whom tried their hand at crowdsourcing a real data collection task with a fixed budget and realistic time constraint. Students used Amazon Mechanical Turk to gather information about the academic careers of over 2,000 professors from 50 top Computer Science departments in America. In addition to curating this dataset, they classified the strategies which emerged, discussed design choices students made on task dimensions, and compared these novice strategies to best practices identified in crowdsourcing literature. Their work culminates in a summary of design pitfalls and effective strategies observed to provide guidelines for novice requesters. The data is publicly accessible, and the researchers are still allowing the public to help improve its accuracy at http://jeffhuang.com/computer_science_professors.html . The Human-Computer Interaction (HCI) group will also continue working and expanding both the dataset (including more universities across North America) and the research contributions. You can read more about this project, Drafty, here .", "https://awards.cs.brown.edu/2015/06/02/esha-ghosh-olya-ohrimenko-and-roberto-tamassia-win-acns-2015-best-student-paper-award/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Esha Ghosh, Olya Ohrimenko, And Roberto Tamassia Win The ACNS 2015 Best Student Paper Award Posted by Jesse Polhemus on June 2, 2015 in Awards PhD candidate Esha Ghosh , PhD alumna Olya Ohrimenko, and professor Roberto Tamassia of Brown University \u2019s Computer Science Department have been selected for the Best Student Paper Award at the 13th International Conference on Applied Cryptography and Network Security (ACNS 2015), to be held in New York on June 2-5, 2015. \u201cWith the advent of cloud computing,\u201d Esha explains, \u201ca huge amount of sensitive data gets outsourced. While integrity is essential in accessing outsourced data, privacy is a very important aspect too. Most importantly, since many of the clients accessing this data are small computing devices, efficiency is crucial. There have been attempts to address these issues separately in the past. In this work, we address these issues comprehensively, propose a formal model, and give a very efficient construction for supporting order queries and order statistics on list data.\u201d Their work (\u201cZero-Knowledge Authenticated Order Queries and Order Statistics on a List\u201d), which Esha will present on the afternoon of June 3, shares the honor with one other paper. In addition to the competitive nature of ACNS, which has a historical acceptance rate in the range of 12-23%, the Best Student Paper Award is the only award given by the conference, chosen from all accepted papers with a student among the authors. \u201cI am delighted by the recognition given to our paper,\u201d says Roberto, \u201cwhich is part of an ambitious project aimed at providing an unprecedented level of security and privacy to cloud computing applications.\u201d \u201cThis project began,\u201d says Olya, \u201cwhen Esha and I were sharing an office, and it\u2019s continued across the Atlantic after I moved to Microsoft Research. It\u2019s a great example of both close and remote collaboration.\u201d", "https://awards.cs.brown.edu/2016/05/26/andrew-crotty-wins-google-phd-fellowship/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Andrew Crotty Wins A Google PhD Fellowship Posted by Jesse Polhemus on May 26, 2016 in Awards Andrew Crotty of Brown University 's Department of Computer Science (Brown CS) has just received a Google PhD Fellowship for his research in data management, particularly the design of big data analytics systems. His current work focuses on developing a new high-performance analytics platform, Tupleware , which is geared toward complex computations like machine learning. The fellowship, first launched in 2009, recognizes and supports outstanding graduate students doing exceptional research in computer science and related disciplines. It includes a monetary award and assigns each student a Google Research Mentor to serve as a resource. This year, there were 39 recipients from three different continents: Andrew is one of three winners in the Systems and Networking category, joining colleagues from the University of Cambridge and the University of California, Berkeley. \"This was by far the most accomplished group of students we've seen, and each and every nominee should be proud,\" says Michael Rennaker of Google University Relations. Andrew's research, he explains, is predicated on the fact that data analytics has grown to include increasingly sophisticated techniques, such as machine learning and advanced statistics. \"Frequently,\" he says, \"users express these complex analytics tasks as workflows of user-defined functions (UDFs) that specify each algorithmic step. However, given typical hardware configurations and dataset sizes, the core challenge of complex analytics is no longer sheer data volume but rather the computation itself, and the next generation of analytics frameworks must focus on optimizing for this computation bottleneck. While query compilation has gained widespread popularity as a way to tackle the computation bottleneck for traditional SQL workloads, relatively little work addresses UDF-centric workflows in the domain of complex analytics.\" Crotty's research has primarily focused on the creation of a novel architecture for automatically compiling workflows of UDFs and co-developing several related optimizations that consider properties of the data, UDFs, and hardware together in order to generate different code on a case-by-case basis. These techniques are currently being implemented in Tupleware, a new high-performance distributed analytics system whose benchmarks show performance improvements of up to three orders of magnitude compared to alternative systems. The fellowship is the latest recognition in a busy year for Andrew: he's recently published papers on a variety of topics from compiling UDF-centric workflows to redesigning traditional data management algorithms for high-performance networks to providing interactive analytics through pen and touch. He and other Brown CS colleagues also won a Best Demo Award at VLDB 2015 . \"It's a big honor to be awarded the Google fellowship,\" Andrew says, \"especially this year being included among so many other outstanding recipients. I'm really looking forward to continuing the exciting work we've been doing with Tupleware and exploring applications to new areas, including interactive data analysis and genomics pipelines.\"", "https://awards.cs.brown.edu/2014/09/25/molly-long-and-layla-oesper-win-google-anita-borg-memorial-scholarship/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Molly Long And Layla Oesper Win Google Anita Borg Memorial Scholarship Posted by Jesse Polhemus on Sept. 25, 2014 in Diversity , Awards Brown University\u2019s Molly Long and Layla Oesper have just won the Google Anita Borg Memorial Scholarship for their excellence in computing and technology and their status as activerole models and leaders in the field. It\u2019s accompanied by an award in theexpected amount of $10,000 and an invitation to the Annual Google Scholars\u2019Retreat. Layla and Molly (and fellow Brown University student, Eden Weizman)join multiple previous BrownCS recipients ofthe scholarship, including Tess Avitabile in 2010. \u201cThe more I learn about Anita Borg,\u201d Layla shares, \u201cthe moreI admire her and the work she did to help promote diversity in computing. I thinkthis is the third time I\u2019ve applied for this scholarship, so I\u2019m justabsolutely thrilled to have been chosen as a recipient this year.\u201d A key qualification for the scholarship is leadership in thecommunity and proven experience with inspiring other women to enter the field.Perhaps Molly\u2019s most notable success in this area is the creation of Brown\u2019sfirst annual hackathon, an event in which programmers and others collaboratedover the course of a weekend to create new software. \u201cWorking with Molly was amazing,\u201d comments Mackenzie Clark,a co-founder of the event. \u201cShe is incredibly hard-working, responsible, anddedicated to everything she does. I can\u2019t think of anyone more deserving ofthis award.\u201d A few numbers support these accolades: 35% of hackathon attendeesidentified as female, 75% had never been to a hackathon before, and 100% saidthat they would return next year. Professor Tom Doeppner agrees. \u201cI'm delighted to hear aboutMolly's award,\u201d he says. \u201cShe's been extremely enthusiastic in pretty mucheverything she does, acting as a role model not only for women, but for all CSstudents. She's served as a UTA, she was the co-organizer of Hack@Brown, andnow she's the co-organizer of a CS senior yearbook.\u201d When asked to describe Layla\u2019s achievements, Associate Professor Amy Greenwald mentionsher work on the BrownCS Diversity Committee, her efforts to improve recruitmentof women, and both the design and implementation of key departmental diversityinitiatives. Citing Anita Borg\u2019s ambition of creating male/female parity in thefield by 2020, Amy says, \u201cIf we had 1000 Layla\u2019s all working toward this goalin their spare time \u2013like she does\u2013 I honestly believe we could do it!\u201d Associate Professor BenRaphael is equally enthusiastic: \u201cI\u2019m delighted that Layla's accomplishments are beingrecognized by the Google Anita Borg Memorial Scholarship. Layla is a first-rateresearcher and teacher of computer science and computational biology. Shealso works tirelessly to promote women in computer science, spearheadingdiversity initiatives in the department and in our research group. Theseexemplary qualities would make Anita Borg proud.\u201d Thescholarship will only enhance the already remarkable work of the two women. \u201cThisaward was so competitive and it brings so many opportunities with it,\u201d Mollyconcludes. \u201cI\u2019m ecstatic!\u201d Her efforts and Layla\u2019s will no doubt provideopportunities for an entire generation of colleagues present and future.", "https://awards.cs.brown.edu/2016/08/15/de-stefani-epasto-riondato-and-upfal-win-best-student-paper-award-sigkdd-2016/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) De Stefani, Epasto, Riondato, And Upfal Win A Best Student Paper Award At KDD 2016 Posted by Jesse Polhemus on Aug. 15, 2016 in Awards Professor Eli Upfal of Brown University 's Department of Computer Science (Brown CS) and his research group continue to distinguish themselves in the Big Data research community. Shortly after two of their full papers and one poster paper were accepted at the 22nd ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2016), a prominent Big Data conference, one of the papers has won the conference's Best Student Paper Award for the Research Track. TRIEST: Counting Local and Global Triangles in Fully-dynamic Streams with Fixed Memory Size was a joint publication between Lead Researcher and PhD Candidate Lorenzo De Stefani, former Postdoctoral Research Associate Alessandro Epasto (now at Google), Visiting Assistant Professor of Computer Science Matteo Riondato , and Eli. The paper tackles the problem of triangle counting in large massive graphs. Their work proposes a new algorithm based on adaptive sampling, which provides high quality approximations of the number of triangles in large networks with probabilistic guarantees. Two Sigma Labs, where Matteo works as a research scientist, has also published a news article on TRIEST that's available here . For more information, please click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus . The image above is \u00a9 2016 by the Association for Computing Machinery.", "http://bigai.cs.brown.edu": "Menu Home About Blog People Press Publications Robots Get Started Log In Brown Integrative, General Artificial Intelligence About Learn about bigAI. Blog read about recent work. People Meet the professors and students. Press read about bigai in the press. Publications Robots Meet the robots. Welcome to bigAI @ BrownCS! View our Mission Tweets by BrownBigAI \u00a9 Brown University", "http://bigai.cs.brown.edu/2019/08/28/deepmellow.html": "Menu Home About Blog People Press Publications Robots Get Started Log In DeepMellow - Removing the Need for Target Networks in Deep Q-Learning Seungchan Kim August 12, 2019 In this paper, we proposed an approach to remove the need for a target network from Deep Q-learning. Our DeepMellow algorithm, the combination of Mellowmax operator and DQN, can learn stably without a target network when tuned with specific temperature parameter \u03c9. We proved novel theoretical properties (convexity, monotonic increase, and overestimation bias reduction) of Mellowmax operator, and empirically showed that Mellowmax operator can obviate the need for a target network in multiple domains. To learn more, see the full blog post , or read the IJCAI paper . \u00a9 Brown University", "http://bigai.cs.brown.edu/2019/09/03/hac.html": "Menu Home About Blog People Press Publications Robots Get Started Log In Learning Multi-Level Hierarchies with Hindsight Andrew Levy September 4, 2019 Hierarchical Reinforcement Learning (HRL) has the potential to accelerate learning in sequential decision making tasks like the inverted pendulum domain shown in Figure 1 where the agent needs to learn a sequence of joint torques to balance the pendulum. HRL methods can accelerate learning because they enable agents to break down a task that may require a relatively long sequence of decisions into a set of subtasks that only require short sequences of decisions. HRL methods enable agents to decompose problems into simpler subproblems because HRL approaches train agents to learn multiple levels of policies that each specialize in making decisions at different time scales. Figure 1 shows an example of how hierarchy can shorten the lengths of the sequences of actions that an agent needs to learn. While a non-hierarchical agent (left side of Figure 1) must learn the full sequence of joint torques needed to swing up and balance the pole, a task that is often prohibitively difficult to learn, the 2-level agent (right side of Figure 1) only needs to learn relatively short sequences. The high-level of the agent only needs to learn a sequence of subgoals (purple cubes) to achieve the task goal (yellow cube), and the low-level of the agent only needs to learn the sequences of joint torques to achieve each subgoal. Figure 1: Video compares the actions sequences that need to be learned by a non-hierarchical agent (left) and a 2-level hierarchical agent (right) in order to complete the task. While the non-hierarchical agent needs to learn the full sequence of joint torques that move the agent from its initial state to the goal state (i.e., yellow cube), the 2-level agent only needs to learn relatively short sequences of decisions. The high-level of the agent just needs to learn the short sequence of subgoals (i.e., purple cubes) needed to achieve the goal. The low-level only needs to learn the short sequences of joint torques needed to achieve each subgoal (i.e., purple cube). Yet, in order for hierarchical agents to take advantage of these short decision sequences and realize the potential of faster learning, hierarchical agents need to be able to learn their multiple levels of policies in parallel. That is, at the same time one level in the hierarchy is learning the sequence of subtasks needed to solve a task, the level below should be learning the sequence of shorter time scale actions needed to solve each subtask. The alternative is to learn the hierarchy of policies one level at a time in a bottom-up fashion, but this strategy both may forfeit the sample efficiency gains hierarchy offers and can be difficult to implement. Learning multiple levels of policies in parallel, however, is hard because it is inherently unstable. Changes in a policy at one level of the hierarchy may cause changes in the transition and reward functions at higher levels in the hierarchy, making it difficult to jointly learn multiple levels of policies. In this post, we present a new Hierarchical Reinforcement Learning framework, Hierarchical Actor-Critic (HAC) , that enables hierarchical agents to efficiently learn multiple levels of policies in parallel. The main idea behind HAC is to train each level of the hierarchy independently of the lower levels by training each level as if the lower levels are already optimal. This strategy yields stable transition and reward functions at all levels and thus makes it easier to learn multiple levels of policies simultaneously. The HAC framework is able to simulate optimal lower level policy hierarchies as a result of two components: (i) a particular hierarchical policy architecture and (ii) three types of transitions that take advantage of hindsight. Our empirical results in a variety of discrete and continuous domains show that hierarchical agents trained with HAC can learn tasks significantly faster than both non-hierarchical agents and hierarchical agents trained with another leading HRL approach. Further, to the best of our knowledge, our results include the first 3-level agents trained in tasks with continuous state and action spaces. The remainder of the post is structured as follows. In the first section, we describe in more detail the instability issues that arise when agents try to learn to make decisions at multiple time scales. In the second section, we present our HRL framework and show how it can reduce this instability and thereby help agents to learn multiple levels of policies simultaneously. In the third section, we discuss the experiments we implemented and the results obtained. In final section of the post, we provide some concluding remarks. For a more detailed description of our approach and experiments, please see our ICLR 2019 paper . For open-sourced software to implement our framework, please check out our GitHub repository . In addition, for the video presentation of our experiments, please see the following video . Instability in Hierarchical RL Learning multiple levels of policies simultaneously is problematic due to non-stationary transition and reward functions that naturally emerge. Hierarchical policies almost always use some sort of nested structure. Beginning with the top level, each level will propose a temporally extended action and the level below has a certain number of attempts to try to execute that temporally extended action. Thus, for any temporally extended action from any level above the base level, the next state that action results in and potentially the reward of that action depend on the policies below that level. As a result, when all levels in the hierarchy are learned simultaneously, the transition function and potentially the reward function for any level above the base level may continue to change as long as the policies below that level continue to change. For an example of non-stationary transition functions in hierarchical policies, consider the 2-level toy robot in the video in Figure 2 below. The high-level of this agent attempts to break down the task by setting subgoals for the low-level to achieve. The video shows four different occasions in which the high-level of the agent proposes state B as a subgoal when the agent is currently in state A . Yet due to the nested structure of the 2-level agent, the next state that this high-level action results in after a certain number of attempts (in this case 5) by the low-level will depend on the policy of the low-level. But since the low-level should be improving and likely also exploring over time, the next state that this subgoal action results in will change over time. .tg {border-collapse:collapse;border-spacing:0;}.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}.tg .tg-baqh{text-align:center;vertical-align:top}.tg .tg-amwm{font-weight:bold;text-align:center;vertical-align:top} Iteration State Action Next State 1 A B C 2 A B D 3 A B E 4 A B B Figure 2: Example of non-stationary transition functions that arise when learning hierarchical policies. In this example, when the robot proposes subgoal state B when in state A, the next state that this action results in changes over time as the low-level policy changes. Similarly, non-stationary reward functions can also arise when trying to learning multiple levels of policies simultaneously. Figure 3 shows an example in which a 2-level robot proposes and achieves the same subgoal on two different occasions, but receives transitions with different rewards because the agent follows different paths to the subgoal. .tg {border-collapse:collapse;border-spacing:0;}.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}.tg .tg-baqh{text-align:center;vertical-align:top}.tg .tg-amwm{font-weight:bold;text-align:center;vertical-align:top} Iteration State Action Reward Next State 1 A B -13 B 2 A B -4 B Figure 3: Example of non-stationary reward functions that arise when learning hierarchical policies. In this example, even though in both iterations the agent is able to achieve subgoal B, the low-level takes different paths so the same subgoal action may yield different rewards. In this case, the reward function is assumed to be -1 for any primitive action that does not achieve the goal of task (not shown) and 0 otherwise. Non-stationary transition and reward functions are a significant concern because they make it difficult to learn effective policies. RL algorithms typically estimate the expected long-term value of action a_t in state s_t (i.e., Q_{Target}(s_t, a_t) ) as the sum of the immediate reward r_{t+1} and the discounted value of the current policy \\pi in the succeeding state s_{t+1} (i.e., \\gamma V_{\\pi}(s_{t+1})) ): $$Q_{Target}(s_t, a_t) = r_{t+1} + \\gamma V_{\\pi}(s_{t+1}).$$ If r_{t+1} and s_{t+1} do not have stationary distributions for the same state-action pair, Q-values will not stabilize and it will be difficult to value individual actions, which in turn will make it difficult to learn effective policies. Thus, in order for the hierarchical agent to learn all of its policies in parallel and realize the sample efficiency benefits of HRL, the non-stationary transition and reward functions that occur at all levels above the base level will need to be overcome. Hierarchical Actor-Critic (HAC) The key problem described above is that if all of the levels of the hierarchy are to be trained in parallel, the temporally extended actions from any level cannot be evaluated with respect to the current hierarchy of policies below that level. This lower level hierarchy will continue to change as long as these lower level policies both learn from experience and explore. Changes in lower level policies in turn will cause non-stationary transitions and rewards functions at higher levels that will make it difficult to learn effective policies at those higher levels. The central idea of our approach, Hierarchical Actor-Critic (HAC), is that instead of evaluating the temporally extended actions with respect to the current lower level hierarchy of policies, evaluate the temporally extended actions with respect to where the lower level hierarchy is headed \u2014 an optimal lower level hierarchy. The optimal lower level hierarchy, which consists of optimal versions of all lower level policies, does not change over time. As a result, the distribution of succeeding states and rewards for any temporally extended action will be stable, enabling the hierarchical agent to learn its multiple levels of policies in parallel. Agents that learn with the HAC framework are able to train each non-base level of the hierarchy with respect to optimal versions of lower level policies without actually needing the optimal lower level policy hierarchy as a result of the framework\u2019s two major components: (i) the particular architecture of the hierarchical policy HAC agents learn and (ii) three types of transitions that the agent uses to evaluate actions. Hierarchical Policy Architecture Agents trained with HAC learn hierarchical policies with the following structural properties. Deterministic, Goal-Conditioned Policies HAC agents learn k -level hierarchical policies that consist of k deterministic, goal-conditioned policies. The number of levels, k , is a hyperparameter chosen by the user. Thus, at each level % <![CDATA[i, 0 \\leq i < k %]]> , the agent learns a policy \\pi_i that maps the current state and goal of the level to an action: \\pi_i: \\mathcal{S}_i, \\mathcal{G}_i \\rightarrow \\mathcal{A}_i . The goal will typically be an individual state or a set of states. The space of goals for the highest level of the hierarchy is determined by the user. The goals for all other levels are determined by the actions from the level above. Action Space = State Space for Non-Base Levels HAC agents divide tasks into shorter horizon subtasks using the state space. That is, each policy above the base level attempts to decompose the task of achieving its goal state into a short sequence subgoal states to achieve along the way. Setting the action space of the non-base levels of the hierarchy to be the state space is critical because it makes it simple for the agent to create transitions that simulate an optimal lower level policy hierarchy, which will ultimately help the agent learn multiple levels of policies in parallel. We will explain in more detail why this is the case during our discussion of the three types of transitions HAC agents use to evaluate actions. In addition, the action space for the base level of the hierarchy is the set of primitive actions available to the agent. Nested Policies The hierarchical policies learned by HAC agents are also nested in order to make it easier for higher levels in the hierarchy to learn to act at longer time scales. When a non-base level i outputs a subgoal state, this subgoal is passed down to level i-1 as its next goal. Level i-1 then has at most H attempts to achieve this goal state, in which H is a hyperparameter set by the user. Figure 4 shows the architecture of a 3-level agent trained with HAC. Figure 4: Architecture of a 3-level hierarchical policy using HAC. Each of the three policies is deterministic and goal-conditioned as each policy takes an input the current state and goal state. The top two levels have an action space equal to the state space as these policies will output subgoal states for lower levels to achieve. The bottom level will output primitive actions. Further, each level has H actions to achieve its goal state before another goal is provided. Three Types of Transitions In addition to the structure of the hierarchical policy, HAC agents are able to efficiently learn multiple levels of policies simultaneously as a result of three types of transitions HAC agents use to evaluate actions. We describe each of these transitions next. In order to make these transitions easier to understand, we will make use of the example episode shown in Figure 5 below, in which a 2-level robot is trying to move from its initial state s_0 \u200b to the yellow flag. Figure 5: Example episode of a 2-level agent trying to move from the initial state s_0 to the yellow flag. The pink circles with the label g_i represent the original subgoal state proposed by the high-level of the agent at step i. The gray circles with the label s_{i+1} indicate the state of the agent after H = 5 primitive actions by the low-level policy following the proposal of subgoal g_i. Hindsight Action Transitions In order to efficiently learn multiple policies in parallel, the non-base levels of the hierarchy need transitions that evaluate actions as if the lower level policies are already optimal. This is the purpose of the first set of HAC transitions, which we refer to as hindsight action transitions. Hindsight action transitions are implemented using a simple procedure: replace the proposed action with the action that was actually executed in hindsight. For non-base levels of the agent that propose subgoals, this means that whenever a level proposes some subgoal state but the level below misses that subgoal state and ends in some other state after H attempts, the hindsight action transition will use the state the agent ended in as the original subgoal action. With this change, the action and next state components in the transition will be the same and thus hindsight action transitions can simulate how an optimal lower level policy hierarchy would act. In addition, for the reward component of the transition, the reward will only depend on (i) the state s_{t+1} reached after H attempts and (ii) the goal state g for the level in consideration. The reward will not take into consideration the exact path taken to the state reached after H attempts because the goal is to create transitions that simulate an optimal lower level policy hierarchy and it is not known what path an optimal lower level policy hierarchy would take. The reward will also be sparse and binary to avoid the issues that arise when reward functions are manually engineered. Specifically, the reward for each level, r_{t+1}(s_{t+1},g), will be 0 for any action in which s_{t+1} \\in g and -1 otherwise. Figure 6 shows the hindsight action transitions that would be created for the high-level of the agent in the example episode in Figure 5. Note that had the high-level had access to the optimal version of the low-level policy, the transition would look the same. .tg {border-collapse:collapse;border-spacing:0;} .tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word- break:normal;border-color:black;} .tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border- width:1px;overflow:hidden;word-break:normal;border-color:black;} .tg .tg-baqh{text-align:center;vertical-align:top} .tg .tg-amwm{font-weight:bold;text-align:center;vertical-align:top} Iteration State Action Reward Next State Goal Discount Rate 1 s 0 s 1 -1 s 1 Yellow Flag \u03b3 2 s 1 s 2 -1 s 2 Yellow Flag \u03b3 3 s 2 s 3 -1 s 3 Yellow Flag \u03b3 4 s 3 s 4 -1 s 4 Yellow Flag \u03b3 5 s 4 s 5 -1 s 5 Yellow Flag \u03b3 Figure 6: High-level hindsight action transitions created in the example episode shown in Figure 5. For the low-level of the agent, the hindsight action transitions will be the typical transitions created for flat agents. Hindsight Goal Transitions Although hindsight action transitions help hierarchical agents jointly learn multiple levels of policies by reducing the non-stationary transition and reward function issues, they introduce another problem \u2014 how to learn multiple levels of policies with only sparse reward functions. The HAC framework attempts to overcome this problem by supplementing agents with a second type of transition, which we refer to as hindsight goal transitions . Hindsight goal transitions make it easier to learn multiple level of policies in sparse reward settings by essentially extending the idea of Hindsight Experience Replay (HER) ( Andrychowicz et al., 2017 ) to the hierarchical setting. HER helps agents learn to reach different goal states in sparse reward domains by generalizing from the agent\u2019s experience achieving other goal states. HER is implemented by creating copies of the original [\\textrm{state, action, reward, next state, goal}] transitions and replacing the original goal state with a state that was actually achieved during the episode. The original reward is also replaced with the appropriate reward given the new goal state. Hindsight goal transitions are implemented in the same manner as HER transitions except that in non-base levels of the hierarchy, hindsight goal transitions are made from copies of the hindsight action transitions. Figure 7 lists the hindsight goal transitions created for the high-level after the example episode in Figure 5 assuming the last state that was reached, s_5 , is used as the new goal state. Figure 8 lists the hindsight goal transitions created for the low-level after the 5 attempts to try to achieve the first subgoal assuming the state s_1 is used as the new subgoal. Note that the last transition in these tables now includes the sparse reward of 0 and a discount rate of 0. Each level of the agent can now use this \u201cknowledge\u201d of how to reach these goal states to generalize to other goal states. .tg {border-collapse:collapse;border-spacing:0;} .tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word- break:normal;border-color:black;} .tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border- width:1px;overflow:hidden;word-break:normal;border-color:black;} .tg .tg-baqh{text-align:center;vertical-align:top} .tg .tg-amwm{font-weight:bold;text-align:center;vertical-align:top} Iteration State Action Reward Next State Goal Discount Rate 1 s 0 s 1 -1 s 1 s 5 \u03b3 2 s 1 s 2 -1 s 2 s 5 \u03b3 3 s 2 s 3 -1 s 3 s 5 \u03b3 4 s 3 s 4 -1 s 4 s 5 \u03b3 5 s 4 s 5 0 s 5 s 5 0 Figure 7: High-level hindsight goal transitions created in the example episode shown in Figure 5. .tg {border-collapse:collapse;border-spacing:0;} .tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word- break:normal;border-color:black;} .tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border- width:1px;overflow:hidden;word-break:normal;border-color:black;} .tg .tg-baqh{text-align:center;vertical-align:top} .tg .tg-amwm{font-weight:bold;text-align:center;vertical-align:top} Iteration State Action Reward Next State Goal Discount Rate 1 s 0 Joint Torques -1 1st Tick Mark s 1 \u03b3 2 1st Tick Mark Joint Torques -1 2nd Tick Mark s 1 \u03b3 3 2nd Tick Mark Joint Torques -1 3rd Tick Mark s 1 \u03b3 4 3rd Tick Mark Joint Torques -1 4th Tick Mark s 1 \u03b3 5 4th Tick Mark Joint Torques 0 s 1 s 1 0 Figure 8: Low-level hindsight goal transitions created when the low-level attempted to achieve the first subgoal. Subgoal Testing Transitions Hindsight action and hindsight goal transitions help agents learning multiple levels of policies in parallel using only sparse reward functions, yet a significant problem still remains. These transitions only enable non-base levels to learn Q-values for subgoal states that can actually be achieved within H steps by the level below. They ignore subgoal states that cannot be reached in H actions. Ignoring a region of the subgoal action space is problematic because the critic function may assign relatively high Q-values to these actions, which may then incentivize the level\u2019s policy to output these unrealistic subgoals. For discrete domains, HAC overcomes this issue with pessimistic Q-value initializations. For continuous domains, HAC supplements agents with a third type of transition, which we refer to as subgoal testing transitions . Subgoal testing transitions help agents overcome this issue by penalizing subgoal actions that cannot be achieved with the current lower level policy hierarchy. Subgoal testing transitions are implemented as follows. After a non-base level proposes a subgoal, a certain fraction of the time that level will decide to test whether the policy hierarchy below that level can achieve the proposed subgoal. All lower levels then must greedily follow their policy and not add exploration noise. If the level below is not able to achieve the proposed subgoal in H actions, the level that proposed the subgoal is penalized with a subgoal testing transition that contains some low reward value. In our experiments, we used a reward value of -H for this penalty. As an example of a subgoal testing transition, assume that when the 2-level robot in Figure 5 was in state s_2 , the high-level of the robot decided to test whether the low-level could achieve the proposed subgoal g_2 . The low-level policy then had to follow its policy exactly for H steps. Because the low-level policy failed to achieve g_2 , the high-level would receive the subgoal testing transition below. Note that this transition uses a discount rate of 0 to avoid any non-stationary transition function issues. [\\textrm{state} = s_2, \\textrm{action} = g_2, \\textrm{reward} = -5, \\textrm{next state} = s_3, \\textrm{goal = Yellow Flag}, \\textrm{discount rate} = 0] Subgoal testing transitions thus help agents assign low Q-values to unrealistic subgoals because these subgoal actions will be penalized during subgoal testing. Using these three types of transitions, the policy at each level of the hierarchy can then be trained with an off-policy Reinforcement Learning algorithm (e.g., Deep Deterministic Policy Gradient (DDPG) ( Lillicrap et al., 2015 )). The critic or Q-function at each level i will take the form of a Universal Value Function Approximator ( Schaul et al., 2015 ) that maps states, goals, and actions to the real number space: Q_i: S, G_i, A_i \\rightarrow \\mathbb{R} . The hierarchical architecture and the three types of transitions constitute the bulk of the HAC framework. For the full HAC algorithm, please see our ICLR 2019 paper . For open-sourced software to implement our approach, please see our GitHub repository . Experiments We evaluated our approach on both (i) discrete state and action space and (ii) continuous state and action space environments. The discrete tasks consisted on two grid world tasks: (i) 10x10 grid world and (ii) four rooms. The continuous domains consisted of the following four tasks built in MuJoCo ( Todorov et al., 2012 ): (i) inverted pendulum, (ii) UR5 reacher, (iii) ant reacher, and (iv) ant four rooms. Using these environments, we performed two comparisons. The first comparison we implemented compared agents using 1 (i.e., flat), 2, and 3 levels. The purpose of this comparison was to evaluate our hypothesis that HAC agents with more levels of hierarchy could learn new tasks with better sample efficiency as they can divide tasks into shorter horizon subtasks and solve these simpler subtasks in parallel. In this experiment, the flat agents used Q-Learning + HER in the discrete tasks and DDPG + HER in the continuous domains. Figure 9 below compares the performance of each agent type in all of the tasks listed above. The green, blue, and red lines represent the performance of 1, 2, and 3-level agents, respectively. In all tasks, hierarchical agents significantly outperformed the 1-level agents. Further, in all tasks, the 3-level agents outperformed, often significantly, the 2-level agents. Figure 9: Results of 1 vs. 2 vs. 3-Level Agent Comparison. Below we show two short videos from our ant experiments. For the full video presentation showing all of our experiments, please see our YouTube video . 2-Level Ant Reacher Figure 10: 2-Level HAC agent in the ant reacher task. The task goal is the yellow cube. Subgoal actions from the high-level policy are represented by the purple cubes. Low-level policy outputs joint torques. 3-Level Ant Four Rooms Figure 11: 3-Level HAC agent in the ant four rooms task. The task goal is the yellow cube. Subgoal actions from the high-level and mid-level policies are represented by the green and purple cubes, respectively. Low-level policy outputs joint torques. The second comparison we implemented compared HAC to another leading HRL algorithm, HIRO (HIerarchical Reinforcement learning with Off-policy correction) ( Nachum et al, 2018 ). HIRO, which was developed simultaneously and independently to our approach, trains 2-level agents with a similar architecture to our approach and can also learn off-policy as in our approach. However, HIRO does not use either of our hindsight transitions, and therefore should not be able to learn multiple levels of policies in parallel as efficiently as our approach can. We compared 2-Level HAC with HIRO in the inverted pendulum, UR reacher, and ant reacher tasks. The results are shown in Figure 12 below. The green and blue lines represent the performance of HIRO and 2-Level HAC, respectively. In all tasks, 2-level HAC significantly outperforms HIRO. Figure 12: Comparison of 2-Level HAC vs HIRO in the (left) inverted pendulum, (middle) UR5 reacher, and (right) ant reacher tasks. Conclusion Hierarchy has the potential to accelerate learning but in order to realize this potential, hierarchical agents need to be able to learn their multiple levels of policies in parallel. In this post, we present a new HRL framework that can efficiently learn multiple levels of policies simultaneously. HAC can overcome the instability issues that arise when agents try to learn to make decisions at multiple time scales because the framework primarily trains each level of the hierarchy as if the lower levels are already optimal. Our results in several discrete and continuous domains, which include the first 3-level agents in tasks with continuous state and action spaces, confirm that HAC can significantly improve sample efficiency. Thank you Kate Saenko, George Konidaris, Robert Platt, and Ben Abbatematteo for your helpful feedback on this post. \u00a9 Brown University", "http://bigai.cs.brown.edu/2019/11/04/kinematics.html": "Menu Home About Blog People Press Publications Robots Get Started Log In Learning to Generalize Kinematic Models to Novel Objects Ben Abbatematteo November 4, 2019 Objects with articulated parts are ubiquitous in household tasks. Putting items in a drawer, opening a door, and retrieving a frosty beverage from a refrigerator are just a few examples of the tasks we\u2019d like our domestic robots to be capable of. However, this is a difficult problem for today\u2019s robots: refrigerators, for example, come in different shapes, sizes, and colors, are in different locations, etc, so control policies trained on individual objects do not readily generalize to new instances of the same class. Humans, on the other hand, learn to manipulate household objects with remarkable efficiency. As a child, we learn to interact with our refrigerator, then readily manipulate the refrigerators we encounter in the houses of our friends and relatives. This is because humans recognize the underlying task structure: these objects almost always consist of the same kinds of parts, despite looking a bit different each time. In order for our robots to achieve generalizable manipulation, they require similar priors. This post details our recent work towards this end, training robots to generalize kinematic models to novel objects. After identifying kinematic structures for many examples of an object class, our model learns to predict kinematic model parameters, articulated pose, and object geometry for novel instances of that class, ultimately enabling manipulation from only a handful of observations of a static object. Kinematic Models Kinematic models are commonly used to represent the relative motion of two rigid bodies. In particular, they describe a body\u2019s forward kinematics: the position and orientation of an articulated part as a function of the state of a joint (the angle of a door or the displacement of a drawer, for example). The most common model types are revolute (like a door) or prismatic (like a drawer), but others exist as well (rigid, spherical, screw, etc). These models are parameterized by their position and orientation in space; for example, in the revolute model, the parameters consist of a) the axis about which the door rotates and b) the spatial relationship between the axis and the origin of the door. A kinematic graph represents all of an object\u2019s parts and the kinematic models between them. Nodes in the graph represent the object\u2019s parts, and edges encode model types and model parameters. For example, in Figure 1, the cabinet pictured can be abstracted into three nodes and two edges, with the rotation between the body and the door encoded in the edge between the respective parts. Figure 1: An example object and its corresponding kinematic graph, annotated with the pose of the axis of rotation. To summarize, each node in the graph represents a part, and each edge in the graph consists of: Model type, denoted \\mathcal{M} , between a part and its parent (revolute, prismatic, \u2026) . Kinematic model parameters, \\phi , the axis of rotation/translation and the resting pose of that part. The state (or configuration ) of the joint, denoted q , an angle in revolute models and a displacement in prismatic models. These quantities enable the robot to simulate how the object parts move about each other. If a robot can identify them, it can begin to reason about how to manipulate an object. A large body of literature explores fitting kinematic models to individual objects, requiring part motion generated by either a human demonstrator or by the robot itself. Critically, these approaches fit models to each object from scratch: a demonstration is required for every new object, no matter how similar each is to those experienced previously. This results in a robot which has to deliberately explore every object it encounters, without ever learning the underlying structure in its experiences with those objects. This is insufficient for a robot operating autonomously in a new household environment, where every object it sees will be new. Generalizing to New Objects In contrast, our models are trained to predict kinematic model parameters from observations of static objects, providing the agent with a useful prior over a novel object\u2019s articulation. We choose to categorize objects according to their part connectivity ; once we do so, if our agent can recognize objects, it can identify the kinematic graph structure which represents a novel object. In particular, it will have the same connectivity as all other instances of that class. This enables us to define a template for each object class, then train neural network models which regress from depth images to the parameters of the kinematic model between each pair of parts, as well as the state of each of the object\u2019s joints and a simple parameterization of the object\u2019s geometry. After being trained in simulation, the models are capable of predicting kinematic model parameters for real, novel objects from individual observations. We show that this is sufficient for manipulating new instances of familiar object classes without first seeing a demonstration. Model The task of our neural network models is to predict the parameters of the kinematic model specified by the object\u2019s class, \\phi , the object\u2019s present articulated pose, q_t , and a parameterization of the object\u2019s geometry, \\theta , given the object\u2019s class label, denoted c , and a depth image of the object at time t , x_t . In order to enable the agent to express confidence in its estimates and reason about sequential observations in a principled way, we trained mixture density networks for each object class, which parameterize a mixture of Gaussian distributions over \\phi , q_t , and \\theta . The mixture density networks consist of three neural networks, \\mu , \\sigma , and \\pi , which represent the means, covariances, and weights of the m mixture components, respectively. We trained ResNet backbones jointly with the mixture density networks. The resulting estimate of the joint distribution over model parameters, articulated pose, and object geometry has the following form: $$ p(\\phi, q_t, \\theta \\mid x_t, c) = \\sum_i^m \\pi_i^c(x_t) \\mathcal{N}( \\phi, q_t, \\theta \\mid \\mu_i^c(x_t), \\sigma_i^c(x_t) ).$$ In order to train the models, we require annotated depth images of articulated objects. Given the labels, the models are trained by maximizing the probability of the true labels under the parameterized mixture of gaussians: $$ \\mathcal{L} = - \\mathbb{E}\\left[ \\log{ p(\\phi, q_t, \\theta | x_t, c) } \\right]. $$ Dataset In the absence of an annotated collection of real articulated objects, we procedurally generated objects from geometric primitives, simulated them in Mujoco, rendered synthetic depth images, and recorded ground truth parameters. We did so for six object classes: cabinet, drawer, microwave, toaster oven, two-door cabinet, and refrigerator. Note that we need to classify cabinets into two categories according to the number of articulated parts due to our classification scheme described above. Ongoing work seeks to relax this by learning to identify part connectivity from pointclouds, too. Some samples from the dataset are shown in Figure 2. Figure 2: Sample simulated objects. The models are trained on many examples of a class, then tested on novel instances. Categories from the top: cabinet, drawer, microwave, toaster oven, cabinet2, refrigerator. Manipulating Novel Objects Once our models are trained, they enable a robot to estimate kinematic models for novel objects without first seeing demonstrations of their part mobility.Using an estimated kinematic model, after obtaining a grasp on the object, the agent is able to compute a path of its end-effector through space that sets the object\u2019s degree of freedom to a desired setting while obeying the constraints imposed by the object\u2019s joints. We demonstrated this with two real objects that the robot was not previously trained on: a microwave, and a drawer. Please see the video below for footage of the demonstrations. Conclusion It\u2019s critical that a robot operating autonomously in new environments be capable of interacting with novel articulated objects.Existing approaches demonstrate how an agent might acquire a model of a novel object through exploration, but they fail to provide the agent with a useful prior over how the object might move.As such, the resulting exploration is time consuming and must be repeated from scratch for every object.Our work presented here provides a framework for learning to generalize these models to new objects, ultimately enabling zero-shot manipulation of novel instances of familiar object classes. For more detail, see the paper , the code for the dataset , or the code for the model . \u00a9 Brown University", "http://bigai.cs.brown.edu/2020/05/18/dsc.html": "Menu Home About Blog People Press Publications Robots Get Started Log In Deep Skill Chaining Akhil Bagaria May 18, 2020 html, body { height: 100%;}img.one { height: auto; width: auto;}img.two { height: 33%; width: 33%;} Figure 1: [Top] Combined value function learned by deep skill chaining. [Bottom] Value functions learned by discovered skills. In this U-shaped maze, the goal state is in the top-left and the start state is in the bottom-left While modern RL algorithms have achieved impressive results on hard problems, they have struggled in long-horizon problems with sparse rewards. Hierarchical reinforcement learning is a promising approach to overcome these challenges. While the benefit of using hierarchies has been known for a long time, the question of how useful hierarchies can be discovered autonomously has remained largely unanswered. In this work, we present an algorithm that can construct temporally extended, higher level actions (called skills ) from the set of primitive actions already available to the RL agent. Not only is the ability to break down complex problems into simpler sub-problems a hallmark of intelligence, it is also the missing piece from traditional/flat reinforcement learning techniques. By constructing useful hierarchies, RL agents will be able to combine modular solutions to easy sub-problems to reliably solve hard real-world problems. We propose Deep Skill Chaining as a step towards realizing the goal of autonomous skill discovery in high-dimensional problems with continuous state and action spaces. To learn more, see the full blog post , read the ICLR paper , or check out the code . \u00a9 Brown University", "http://bigai.cs.brown.edu/about.html": "Menu Home About Blog People Press Publications Robots Get Started Log In About The mission of the Brown Integrative, General Artificial Intelligence project is to develop agents with human-level problem-solving ability and communication skills. We believe that these fully integrated, generally intelligent agents should be robots: embodied systems which perceive the world through their sensors, affect the world through their actuators, and interact with humans in complex environments. In order to build these agents, we are drawing on our faculty's expertise in machine learning, artificial intelligence, and natural language processing, and applying cutting-edge ideas to the full AI problem: building machines that learn, reason, and communicate about the natural world. It is our hope that together we can build the world\u2019s first truly generally intelligent robot. Welcome to bigAI @ Brown. Let\u2019s get started! Meet us! \u00a9 Brown University", "http://bigai.cs.brown.edu/blog.html": "Menu Home About Blog People Press Publications Robots Get Started Log In Deep Skill Chaining Akhil Bagaria May 18, 2020 html, body { height: 100%;}img.one { height: auto; width: auto;}img.two { height: 33%; width: 33%;} Figure 1: [Top] Combined value function learned by deep skill chaining. [Bottom] Value functions learned by discovered skills. In this U-shaped maze, the goal state is in the top-left and the start state is in the bottom-left While modern RL algorithms have achieved impressive results on hard problems, they have struggled in long-horizon problems with sparse rewards. Hierarchical reinforcement learning is a promising approach to overcome these challenges. While the benefit of using hierarchies has been known for a long time, the question of how useful hierarchies can be discovered autonomously has remained largely unanswered. In this work, we present an algorithm that can construct temporally extended, higher level actions (called skills ) from the set of primitive actions already available to the RL agent. Not only is the ability to break down complex problems into simpler sub-problems a hallmark of intelligence, it is also the missing piece from traditional/flat reinforcement learning techniques. By constructing useful hierarchies, RL agents will be able to combine modular solutions to easy sub-problems to reliably solve hard real-world problems. We propose Deep Skill Chaining as a step towards realizing the goal of autonomous skill discovery in high-dimensional problems with continuous state and action spaces. To learn more, see the full blog post , read the ICLR paper , or check out the code . Continue reading Learning to Generalize Kinematic Models to Novel Objects Ben Abbatematteo November 4, 2019 Objects with articulated parts are ubiquitous in household tasks. Putting items in a drawer, opening a door, and retrieving a frosty beverage from a refrigerator are just a few examples of the tasks we\u2019d like our domestic robots to be capable of. However, this is a difficult problem for today\u2019s robots: refrigerators, for example, come in different shapes, sizes, and colors, are in different locations, etc, so control policies trained on individual objects do not readily generalize to new instances of the same class. Humans, on the other hand, learn to manipulate household objects with remarkable efficiency. As a child, we learn to interact with our refrigerator, then readily manipulate the refrigerators we encounter in the houses of our friends and relatives. This is because humans recognize the underlying task structure: these objects almost always consist of the same kinds of parts, despite looking a bit different each time. In order for our robots to achieve generalizable manipulation, they require similar priors. This post details our recent work towards this end, training robots to generalize kinematic models to novel objects. After identifying kinematic structures for many examples of an object class, our model learns to predict kinematic model parameters, articulated pose, and object geometry for novel instances of that class, ultimately enabling manipulation from only a handful of observations of a static object. Continue reading Learning Multi-Level Hierarchies with Hindsight Andrew Levy September 4, 2019 Hierarchical Reinforcement Learning (HRL) has the potential to accelerate learning in sequential decision making tasks like the inverted pendulum domain shown in Figure 1 where the agent needs to learn a sequence of joint torques to balance the pendulum. HRL methods can accelerate learning because they enable agents to break down a task that may require a relatively long sequence of decisions into a set of subtasks that only require short sequences of decisions. HRL methods enable agents to decompose problems into simpler subproblems because HRL approaches train agents to learn multiple levels of policies that each specialize in making decisions at different time scales. Figure 1 shows an example of how hierarchy can shorten the lengths of the sequences of actions that an agent needs to learn. While a non-hierarchical agent (left side of Figure 1) must learn the full sequence of joint torques needed to swing up and balance the pole, a task that is often prohibitively difficult to learn, the 2-level agent (right side of Figure 1) only needs to learn relatively short sequences. The high-level of the agent only needs to learn a sequence of subgoals (purple cubes) to achieve the task goal (yellow cube), and the low-level of the agent only needs to learn the sequences of joint torques to achieve each subgoal. Figure 1: Video compares the actions sequences that need to be learned by a non-hierarchical agent (left) and a 2-level hierarchical agent (right) in order to complete the task. While the non-hierarchical agent needs to learn the full sequence of joint torques that move the agent from its initial state to the goal state (i.e., yellow cube), the 2-level agent only needs to learn relatively short sequences of decisions. The high-level of the agent just needs to learn the short sequence of subgoals (i.e., purple cubes) needed to achieve the goal. The low-level only needs to learn the short sequences of joint torques needed to achieve each subgoal (i.e., purple cube). Continue reading DeepMellow - Removing the Need for Target Networks in Deep Q-Learning Seungchan Kim August 12, 2019 In this paper, we proposed an approach to remove the need for a target network from Deep Q-learning. Our DeepMellow algorithm, the combination of Mellowmax operator and DQN, can learn stably without a target network when tuned with specific temperature parameter \u03c9. We proved novel theoretical properties (convexity, monotonic increase, and overestimation bias reduction) of Mellowmax operator, and empirically showed that Mellowmax operator can obviate the need for a target network in multiple domains. To learn more, see the full blog post , or read the IJCAI paper . Continue reading \u00a9 Brown University", "https://awards.cs.brown.edu/2017/05/10/geopipe-co-founded-thomas-dickerson-wins-100k-nyu-entrepreneurs-challenge/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Geopipe, Co-Founded By Thomas Dickerson, Wins $100K At The NYU $300K Entrepreneurs Challenge Posted by Jesse Polhemus on May 10, 2017 Click the links that follow for more Brown CS content about Thomas Dickerson and entrepreneurship . Could anything be more valuable to a young startup than expert-led coaching sessions on how to identify opportunities and design business models, or the chance to pitch ideas to industry leaders? Probably not much, but a check for $100,000 might be a close contender. NYU Stern's W. R. Berkley Innovation Labs $300K Entrepreneurs Challenge, held at New York University's Stern School of Business, offers all those things. Last week, PhD Candidate Thomas Dickerson of Brown University 's Department of Computer Science (Brown CS) returned from the competition with some valuable experience and one of those comically-oversized checks that are almost too big for one person to carry. After months of workshops, coaching sessions, and deliverables, his startup, Geopipe, was selected for its potential for great impact, challenging assumed boundaries, and inspiring a sense of what's possible. It won the top prize of $100,000 in the Challenge's Technology Venture Competition. Co-founded last year with Dr. Christopher Mitchell, a New York University alum, Geopipe builds algorithms to turn 2D and 3D data into highly detailed 3D virtual models. Their system ingests and analyzes data, including satellite photos, maps, laser scans, and much more. It then combines machine learning with a distributed systems approach to rapidly correlate data sources, understand structure, and produce complete 3D models at many different scales. One of Geopipe's strengths is that it offers more semantic modeling than competing solutions with massive amounts of content while coupling models to real-world data without a great deal of manual effort. It puts models in the hands of customers, who can use them in their own software suites with automatic customization options at a consistently high level of visual quality. \"This is an extremely important moment for Geopipe,\" says Thomas, \"and we'll put the money to good use. We have a pretty extensive R&D road-map for the next 12 months, and we're looking to balance pushing that with getting hands-on feedback through pilot programs with customers in the architecture market.\" The image above is \u00a9NYU Photo Bureau: Hollenshead and used with permission. For more information about this story, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "http://bigai.cs.brown.edu/people.html": "Menu Home About Blog People Press Publications Robots Get Started Log In People Professors Several of our faculty members and their students are working together to realize our dream of intelligent robots. Stefanie Tellex Professor Tellex is the director of the Humans To Robots Lab. Learn More George Konidaris Professor Konidaris is the director of the Intelligent Robot Lab. Learn More Michael Littman Professor Littman leads the Reinforcement Learning & Adaptive Behavior group (RLAB), as well as serving as Co-Director of the Humanity Centered Robotics initiative . Learn more Ellie Pavlick Professor Pavlick studies computational models of natural language semantics and pragmatics. She leads the Language Understanding And Representation (LUNAR) Lab. Learn more Eugene Charniak Professor Charniak directs the Brown Laboratory for Linguistic Information Processing (BLLIP). Learn more Students Meet the students! (coming soon) That's all, folks. Meet the robots, check out bigAI in the press, and see our publications. Robots Press Publications \u00a9 Brown University", "http://bigai.cs.brown.edu/pubs.html": "Menu Home About Blog People Press Publications Robots Get Started Log In Publications Please find the publications of each PI on their respective pages below: George Konidaris : http://irl.cs.brown.edu/publications.php Stefanie Tellex : http://h2r.cs.brown.edu/publications/ Michael Littman : https://dblp.uni-trier.de/pers/hd/l/Littman:Michael_L=.html Ellie Pavlick : https://cs.brown.edu/people/epavlick/pubs.html Eugene Charniak : http://cs.brown.edu/people/echarnia/ \u00a9 Brown University", "http://bigai.cs.brown.edu/press.html": "Menu Home About Blog People Press Publications Robots Get Started Log In Press 2019 Brown CS Undergraduate Atsunobu Kotani Teaches Robots Handwriting And Drawing , June 18, 2019 . Retrieved at: http://cs.brown.edu/news/2019/06/18/brown-cs-undergraduate-atsunobu-kotani-teaches-robots-handwriting-and-drawing/ Michael Littman Has Been Named An ACM Fellow , June 17, 2019. Retrieved at: http://cs.brown.edu/news/2019/06/17/michael-littman-has-been-named-acm-fellow/ . See also: https://www.acm.org/media-center/2018/december/fellows-2018 David Abel Wins A Presidential Award For Excellence In Teaching , May 20, 2019. Retrieved at: http://cs.brown.edu/news/2019/05/20/david-abel-wins-presidential-award-excellence-teaching/ George Konidaris Wins An NSF CAREER Award For Autonomous Robotic Learning , April 18, 2019 . Retrieved at: http://cs.brown.edu/news/2019/04/18/george-konidaris-wins-nsf-career-award-autonomous-robotic-learning/ Rhode Island Robot Block Party Returns On April 13 , March 6, 2019. Retrieved at: http://cs.brown.edu/news/2019/03/06/rhode-island-robot-block-party-returns-april-13/ Evan Cater Wins The Randy F. Pausch Computer Science Undergraduate Summer Research Award , February 28, 2019. Retrieved at: http://cs.brown.edu/news/2019/02/28/evan-cater-wins-randy-f-pausch-computer-science-undergraduate-summer-research-award/ Nakul Gopalan, Eric Rosen, Daniel Ullman, And David Whitney Win The Hyundai Visionary Challenge , January 18, 2019. Retrieved at: http://cs.brown.edu/news/2019/01/18/nakul-gopalan-eric-rosen-daniel-ullman-david-whitney-win-hyundai-visionary-challenge/ 2018 Michael Littman Receives Brown's Presidential Faculty Award , October 5, 2018. Retrieved at: http://cs.brown.edu/news/2018/10/05/michael-littman-receives-browns-presidential-faculty-award/ The Serious Security Problem Looming Over Robotics , August 24, 2018. Retrieved at: https://www.wired.com/story/security-robotics/ Undergraduate team helps to develop drone-based intro robotics course , August 17, 2018. Retrieved at: https://news.brown.edu/articles/2018/08/droneutra Tellex's Outreach Inspires A High School Student To Study CS, Then Teach , August 2, 2018. Retrieved at: http://cs.brown.edu/news/2018/08/02/tellexs-outreach-inspires-high-school-student-study-robotics-then-teach/ Hordes of Research Robots Could be Hijacked for Fun and Sabotage , July 24, 2018. Retrieved at: https://www.technologyreview.com/s/611704/hordes-of-research-robots-could-be-hijacked-for-fun-and-sabotage/ Seeing the Mind of a Robot in Augmented Reality , June 4, 2018. Retrieved at: https://www.technologyreview.com/s/611296/seeing-the-mind-of-a-robot-in-augmented-reality/ Meet Realtime Robotics\u2019 CEO Peter Howard and Chief Roboticist George Konidaris , May 22, 2018.Retrieved at: https://medium.com/toyota-ai-ventures/meet-realtime-robotics-ceo-peter-howard-and-chief-roboticist-george-konidaris-a6359ceb117c Stefanie Tellex Wins An Early Career Research Achievement Award , April 19, 2018.Retrieved at: https://cs.brown.edu/news/2018/04/19/stefanie-tellex-wins-early-career-research-achievement-award/ George Konidaris Helps Robots Think And Plan In The Abstract , February 9, 2018.Retrieved at: https://cs.brown.edu/news/2018/02/09/george-konidaris-helps-robots-think-and-plan-abstract/ 2017 David Abel's \"Research Matters\" Talk , December 12, 2017.Retrieved at: https://www.youtube.com/watch?v=rNFP2OC4NYM How I Learned to Stop Worrying and Be Realistic About AI | Michael L. Littman | TEDxProvidence , November 8, 2017.Retrieved at: https://www.youtube.com/watch?v=LFTqdrPXj8A A Cooperative Path to Artificial Intelligence | Michael Littman | TEDxBoston , October 24, 2017.Retrieved at: https://www.youtube.com/watch?v=uMdHGOhSIJY George Konidaris And Stefanie Tellex Earn DARPA Director's Fellowships , October 13, 2017.Retrieved at: https://cs.brown.edu/news/2017/10/13/konidaris-and-tellex-earn-darpa-directors-fellowships/ This Robot Knows When It\u2019s Confused and Asks for Help , April 25, 2017.Retrieved at: https://www.technologyreview.com/s/604031/this-robot-knows-when-its-confused-and-asks-for-help/ Meet Iorek, The Robot That Communicates In A Remarkable Way , March 20, 2017.Retrieved at: https://www.wired.com/2017/03/meet-lorek-robot-communicates-remarkable-way/ Robot Knows The Right Question To Ask When It\u2019s Confused , March 15, 2017.Retrieved at: http://spectrum.ieee.org/automaton/robotics/artificial-intelligence/robot-knows-the-right-question-to-ask-when-its-confused 2016 George Konidaris Wins An AFOSR Young Investigator Research Award , November 17, 2016.Retrieved at: https://cs.brown.edu/news/2016/11/17/george-konidaris-wins-afosr-young-investigator-research-award/ Robots Can Now Teach Each Other New Tricks , October 27, 2016. Retrieved at: https://www.technologyreview.com/s/542821/robots-can-now-teach-each-other-new-tricks/ Robot, Get The Fork Out Of My Sink , October 18, 2016. Retrieved at: https://www.technologyreview.com/s/602626/robot-get-the-fork-out-of-my-sink/?set=602614 Robotic Motion Planning in Real-Time , June 20, 2016.Retrieved at https://pratt.duke.edu/about/news/robotic-motion-planning-real-time \u00a9 Brown University", "http://bigai.cs.brown.edu/robots.html": "Menu Home About Blog People Press Publications Robots Get Started Log In Robots Robots Meet the robots! Miss Tick, the Movo The Movo is our mobile manipulation platform from Kinova Robotics. Miss Tick is quite impressive: she can play the ukulele and knows how to write several alphabets! Winnie, the Baxter Winnie is shy, but she's an expert at pick and place, and has learned to understand natural language task specifications. Iorek, the Baxter Iorek is a proud Baxter, but knows when to ask for help ! Detritus, the KUKA iiwa7 Detritus is learning to manipulate objects. Dorfl, the KUKA iiwa7 Dorfl is learning motor skills with imitation learning. Kuri Our Kuri robots are learning to recognize human activities and answer queries about them. In the meantime, they sing pancake songs, meow with pleasure, and constantly drive into things. \u00a9 Brown University", "http://bigdata.cs.brown.edu": "", "http://bigdata.cs.brown.edu/vctutorial/": "Abstract Slides Instructors Bibliography Acknowledgements Abstract Random sampling is a naturaltechnique to speed up the execution of algorithms on very largedatasets. The results obtained by analyzing only a random sample of thedataset are an approximation of the exact solution. When onlya single value must be computed, the trade-off between the size of thesample and the accuracy of the approximation can be studied throughprobabilistic bounds (e.g., the Chernoff-Hoeffding bounds) for thedeviation of the quantity of interest in the sample from its exactvalue in the dataset. In many classical data mining problems, thenumber of quantities of interest can be extremely large (e.g.,betweenness centrality requires to compute one value for each node in agraph). In these cases, uniform (i.e., simultaneous) bounds to thedeviations of all quantities are needed. Classical techniques likethe Union bound are insufficient because excessively loose due totheir worst-case assumptions that do not hold in many data miningproblems. Rademacher Averages and theVapnik-Chervonenkis dimension have been developed to overcome this issue: they obtain much stricteruniform deviation bounds by taking into account the nature of theproblem and properties of the dataset and of the sampling process. Theyhave been used with success in the analysis of sampling algorithms fordata and graph analysis problems on very large datasets. In this tutorial, we survey the use ofRademacher Averages and VC-dimension for developing sampling-basedalgorithms for graph analysis and pattern mining. We start fromtheir theoretical foundations at the core of machine learning theory , thenshow a generic recipe for formulating data mining problems in a way thatallows using these concepts in the analysis of efficient randomizedalgorithms for those problems. Finally, we show examples of theapplication of this recipe to graph problems (connectivity, shortestpaths, betweenness centrality) and pattern mining . Our goal is to show how these techniques can be avaluable addition to the toolkit of the data mining researcher, and toencourage further research in the area. Slides Slides presented at ECML PKDD (Updated: September 11) Slides presented at KDD (Updated: August 11) Instructors Matteo Riondato is aresearch scientist in the Labs group at TwoSigma . Previously he was a postdoc at Brown University and atStanford University. He received his Ph.D. from Brown in May 2014,where he was advised by Eli Upfal, with a dissertation onsampling-based randomized algorithms for data analytics, which receivedthe Best Student Poster Award at SIAM SDM 2014. He presented a nectartalk about modern sampling algorithms at ECML PKDD 2014. His researchfocuses on exploiting theoretical results for practical algorithms inpattern and graph mining. Eli Upfal is a professor ofcomputer science at Brown University, where he was also the departmentchair from 2002 to 2007. Prior to joining Brown in 1998, he was aresearcher and project manager at the IBM Almaden Research Center inCalifornia, and a professor of Applied Mathematics and Computer Scienceat the Weizmann Institute of Science in Israel. Upfal\u2019s researchfocuses on the design and analysis of algorithms. In particular he isinterested in randomized algorithms, probabilistic analysis ofalgorithms, and computational statistics, with applications rangingfrom combinatorial and stochastic optimization to routing andcommunication networks, computational biology, and computationalfinance. Upfal is a fellow of the IEEE and the ACM. He received the IBMOutstanding Innovation Award, and the IBM Research Division Award. Hiswork at Brown has been funded in part by the National ScienceFoundation (NSF), the Defense Advanced Research Projects Agency(DARPA), the Office of Naval Research (ONR), and the National Instituteof Health (NIH). He is co-author of a popular textbook \u201cProbability andComputing: Randomized Algorithms and Probabilistic Analysis\u201d (with M.Mitzenmacher, Cambridge University Press 2005). Bibliography A BibTeX bibliography of the main publications about VC-dimension and Rademacher averages: vcrade.bib . Acknowledgements This tutorial is part of Project BIGDATA at Brown CS . This work is supported in part by NSF grant IIS-1247581 and NIH grant R01-CA180776. Any opinions, findings, and conclusions orrecommendations expressed in this material are those of the author(s)and do not necessarily reflect the views of the National ScienceFoundation. Website contact: MatteoRiondato ,matteo at cs dot brown dot edu", "http://bllip.cs.brown.edu": "Brown Laboratory for Linguistic Information Processing (BLLIP) BLLIP Home People Publications Resources Photos People Faculty \u00b7 Graduate students \u00b7 Undergraduate Students \u00b7 Alumni Publications 2015 \u00b7 2014 \u00b7 2013 \u00b7 2012 \u00b7 2011 \u00b7 2010 \u00b7 2009 \u00b7 2008 \u00b7 2007 \u00b7 2006 \u00b7 2005 \u00b7 2004 \u00b7 2003 \u00b7 2002 \u00b7 2001 \u00b7 2000 and earlier Resources Software \u00b7 Corpora Departments Computer Science \u00b7 Cognitive & Linguistic Sciences \u00b7 Applied Mathematics Other Pages of Interest BLLIP Listserv Machine Learning Reading Group Pattern Theory Group Assoc. for Computational Linguistics ACL Anthology \u00b7 ACL Wiki elsewhere Computation and Language at arXiv Linguistic Data Consortium Last update: Friday, May 27 2016, 07:56 PM var sc_project=2284705;var sc_invisible=1;var sc_partition=21;var sc_security=\"70f322dc\";", "http://bllip.cs.brown.edu/publications/": "Brown Laboratory for Linguistic Information Processing (BLLIP) BLLIP Home People Publications Resources Photos Lab Publications By Year : 2016 \u00b7 2015 \u00b7 2014 \u00b7 2013 \u00b7 2012 \u00b7 2011 \u00b7 2010 \u00b7 2009 \u00b7 2008 \u00b7 2007 \u00b7 2006 \u00b7 2005 \u00b7 2004 \u00b7 2003 \u00b7 2002 \u00b7 2001 \u00b7 2000 \u00b7 1999 \u00b7 1998 \u00b7 1997 \u00b7 1996 \u00b7 1995 \u00b7 1994 \u00b7 1993 \u00b7 1992 \u00b7 By Author : Eugene Charniak \u00b7 Micha Elsner \u00b7 Heidi Fox \u00b7 Stuart Geman \u00b7 Will Headden \u00b7 Mark Johnson \u00b7 Matt Lease \u00b7 David McClosky \u00b7 Rebecca Mason \u00b7 Ben Swanson \u00b7 Do Kook Choe \u00b7 Chris Tanner \u00b7 2016 2015 Byron C. Wallace, Do Kook Choe, and Eugene Charniak. Sparse, Contextually Informed Models for Irony Detection: Exploiting User Communities, Entities and Sentiment . In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) , pages 1035-1044, Beijing, China, July 2015. Association for Computational Linguistics.[ bib | .pdf ] Do Kook Choe and David McClosky. Parsing Paraphrases with Joint Inference . In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) , pages 1223-1233, Beijing, China, July 2015. Association for Computational Linguistics.[ bib | .pdf ] Do Kook Choe, David McClosky, and Eugene Charniak. Syntactic Parse Fusion . In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing , pages 1360-1366, Lisbon, Portugal, September 2015. Association for Computational Linguistics.[ bib | .pdf ] Chris Tanner and Eugene Charniak. A Hybrid Generative/Discriminative Approach To Citation Prediction . In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies , pages 75-83, Denver, Colorado, May-June 2015. Association for Computational Linguistics.[ bib | .pdf ] 2014 Rebecca Mason and Eugene Charniak. Domain-Specific Image Captioning . In Proceedings of the Eighteenth Conference on Computational Natural Language Learning , pages 11-20, Ann Arbor, Michigan, June 2014. Association for Computational Linguistics.[ bib | .pdf ] Rebecca Mason and Eugene Charniak. Nonparametric Method for Data-driven Image Captioning . In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) , pages 592-598, Baltimore, Maryland, June 2014. Association for Computational Linguistics.[ bib | .pdf ] Byron C. Wallace, Do Kook Choe, Laura Kertz, and Eugene Charniak. Humans Require Context to Infer Ironic Intent (so Computers Probably do, too) . In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) , pages 512-516, Baltimore, Maryland, June 2014. Association for Computational Linguistics.[ bib | .pdf ] Ben Swanson and Eugene Charniak. Data Driven Language Transfer Hypotheses . In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, volume 2: Short Papers , pages 169-173, Gothenburg, Sweden, April 2014. Association for Computational Linguistics.[ bib | .pdf ] 2013 Rebecca Mason. Domain-Independent Captioning of Domain-Specific Images . In Proceedings of the 2013 NAACL HLT Student Research Workshop , pages 69-76, Atlanta, Georgia, June 2013. Association for Computational Linguistics.[ bib | .pdf ] Rebecca Mason and Eugene Charniak. Annotation of Online Shopping Images without Labeled Training Examples . In Proceedings of Workshop on Vision and Language , Atlanta, Georgia, June 2013. Association for Computational Linguistics.[ bib | .pdf ] Do Kook Choe and Eugene Charniak. Naive Bayes Word Sense Induction . In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing , pages 1433-1437, Seattle, Washington, USA, October 2013. Association for Computational Linguistics.[ bib | .pdf ] Ben Swanson and Eugene Charniak. Extracting the Native Language Signal for Second Language Acquisition . In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies , pages 85-94, Atlanta, Georgia, June 2013. Association for Computational Linguistics.[ bib | .pdf ] Ben Swanson, Elif Yamangil, Eugene Charniak, and Stuart Shieber. A Context Free TAG Variant . In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 302-310, Sofia, Bulgaria, August 2013. Association for Computational Linguistics.[ bib | .pdf ] 2012 Rebecca Mason and Eugene Charniak. Apples to Oranges: Evaluating Image Annotations from Natural Language Processing Systems . In NAACL-2012: Main Proceedings , Montreal, Canada, 2012. Association for Computational Linguistics.[ bib | .pdf ] Ben Swanson and Eugene Charniak. Native language detection with tree substitution grammars . In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers - Volume 2 , ACL '12, pages 193-197, Stroudsburg, PA, USA, 2012. Association for Computational Linguistics.[ bib | .pdf ] Ben Swanson and Elif Yamangil. Correction detection and error type selection as an ESL educational aid . In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies , NAACL HLT '12, pages 357-361, Stroudsburg, PA, USA, 2012. Association for Computational Linguistics.[ bib | .pdf ] 2011 Micha Elsner and Eugene Charniak. Disentangling chat with local coherence models . In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1 , HLT '11, pages 1179-1189, Stroudsburg, PA, USA, 2011. Association for Computational Linguistics.[ bib | .pdf ] Micha Elsner and Deepak Santhanam. Learning to fuse disparate sentences . In Proceedings of the Workshop on Monolingual Text-To-Text Generation , MTTG '11, pages 54-63, Stroudsburg, PA, USA, 2011. Association for Computational Linguistics.[ bib | .pdf ] Micha Eisner and Eugene Charniak. Extending the entity grid with entity-specific features . In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2 , HLT '11, pages 125-129, Stroudsburg, PA, USA, 2011. Association for Computational Linguistics.[ bib | .pdf ] Rebecca Mason and Eugene Charniak. Extractive Multi-Document Summaries Should Explicitly Not Contain Document-Specific Content . In Proceedings of the ACL 2011 Workshop on Automatic Summarization for Different Genres, Media, and Languages , Portland, Oregon, 2011. Association for Computational Linguistics.[ bib | .pdf ] Rebecca Mason and Eugene Charniak. BLLIP at TAC 2011: A General Summarization System for a Guided Summarization Task . In Proceedings of TAC 2011 , 2011.[ bib | .pdf ] 2010 Eugene Charniak. Top-down nearly-context-sensitive parsing . In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing , EMNLP '10, pages 674-683, Stroudsburg, PA, USA, 2010. Association for Computational Linguistics.[ bib | .pdf ] Micha Elsner and Eugene Charniak. The Same-head Heuristic for Coreference . In Proceedings of ACL 10 , Uppsala, Sweden, July 2010. Association for Computational Linguistics.[ bib | .pdf ] David McClosky, Eugene Charniak, and Mark Johnson. Automatic domain adaptation for parsing . In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics , HLT '10, pages 28-36, Stroudsburg, PA, USA, 2010. Association for Computational Linguistics.[ bib | .pdf ] 2009 Eugene Charniak and Micha Elsner. EM Works for Pronoun Anaphora Resolution . In Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics (EACL-09) , Athens, Greece, 2009.[ bib | .pdf ] Micha Elsner and Warren Schudy. Bounding and Comparing Methods for Correlation Clustering Beyond ILP . In Proceedings of the NAACL/HLT 2009 Workshop on Integer Linear Programming for Natural Language Processing (ILP-NLP '09) , Boulder, Colorado, June 2009.[ bib | .pdf ] Micha Elsner, Eugene Charniak, and Mark Johnson. Structured Generative Models for Unsupervised Named-Entity Clustering . In Proceedings of NAACL-09: HLT , Boulder, Colorado, June 2009. Association for Computational Linguistics.[ bib | .pdf ] William P. Headden III, Mark Johnson, and David McClosky. Improving Unsupervised Dependency Parsing with Richer Contexts and Smoothing . In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference (to appear) , Boulder, Colorado, May 2009.[ bib ] Matthew Lease. An Improved Markov Random Field Model for Supporting Verbose Queries . In Proceedings of the 32nd Annual ACM SIGIR Conference , 2009. 16% acceptance rate, to appear.[ bib | Abstract ] Matthew Lease, James Allan, and W. Bruce Croft. Regression Rank: Learning to Meet the Opportunity of Descriptive Queries . In Proceedings of the 31st European Conference on Information Retrieval (ECIR) , pages 90-101, 2009. 22% acceptance rate.[ bib | .pdf | Abstract ] 2008 Micha Elsner and Eugene Charniak. You Talking to Me? A Corpus and Algorithm for Conversation Disentanglement . In Proceedings of ACL-08: HLT , pages 834-842, Columbus, Ohio, June 2008. Association for Computational Linguistics.[ bib | .pdf | slides ] Micha Elsner and Eugene Charniak. Coreference-inspired Coherence Modeling . In Proceedings of ACL-08: HLT, Short Papers , pages 41-44, Columbus, Ohio, June 2008. Association for Computational Linguistics.[ bib | .pdf | poster ] William P. Headden III, David McClosky, and Eugene Charniak. Evaluating Unsupervised Part-of-Speech Tagging for Grammar Induction . In Proceedings of the 22nd International Conference on Computational Linguistics (COLING'08) , Manchester, UK, August 2008.[ bib | .pdf | .ps ] Matthew Lease. Incorporating Relevance and Psuedo-relevance Feedback in the Markov Random Field Model: Brown at the TREC'08 Relevance Feedback Track . In Proceedings of the 17th Text Retrieval Conference (TREC'08) , 2008. Best results in track. This paper supersedes an earlier version appearing in conference's Working Notes.[ bib | .pdf | Abstract ] Matthew Lease and Eugene Charniak. A Dirichlet-smoothed Bigram Model for Retrieving Spontaneous Speech . In Advances in Multilingual and Multimodal Information Retrieval: 8th Workshop of the Cross-Language Evaluation Forum, CLEF 2007, Revised Selected Papers , volume 5152 of Lecture Notes in Computer Science . Springer-Verlag, 2008.[ bib | .pdf ] David McClosky and Eugene Charniak. Self-Training for Biomedical Parsing . In Proceedings of ACL-08: HLT, Short Papers , pages 101-104, Columbus, Ohio, June 2008. Association for Computational Linguistics.[ bib | .pdf ] David McClosky, Eugene Charniak, and Mark Johnson. When is Self-training Effective for Parsing? In Proceedings of the 22nd International Conference on Computational Linguistics (COLING'08) , Manchester, UK, August 2008.[ bib | .pdf | .ps ] David McClosky. Modeling Valence Effects in Unsupervised Grammar Induction . Technical Report CS-09-01, Brown University, Providence, RI, USA, 2008.[ bib | tech-report | Abstract ] 2007 Micha Elsner, Joseph Austerweil, and Eugene Charniak. A Unified Local and Global Model for Discourse Coherence . In Proceedings of HLT-NAACL '07 , Rochester, New York, April 2007. Association for Computational Linguistics.[ bib | .pdf | slides ] Micha Elsner and Eugene Charniak. A Generative Discourse-New Model for Text Coherence . Technical Report CS-07-04, Brown University, Providence, RI, USA, 2007.[ bib | .pdf | Abstract ] Jianfeng Gao, Galen Andrew, Mark Johnson, and Kristina Toutanova. A Comparative Study of Parameter Estimation Methods for Statistical Natural Language Processing . In Proceedings of the Association for Computational Linguistics (ACL'07) , 2007.[ bib ] Sharon Goldwater, Thomas L. Griffiths, and Mark Johnson. Distributional Cues to Word Segmentation: Context is Important . In Proceedings of the 31st Boston University Conference on Language Development , 2007.[ bib | .pdf ] Mark Johnson. Why Doesn't EM Find Good HMM POS-Taggers? In Proceedings of Empirical Methods in Natural Language Processing (EMNLP'07) , 2007.[ bib ] Mark Johnson. Transforming Projective Bilexical Dependency Grammars into Efficiently-Parsable CFGs with Unfold-Fold . In Proceedings of the Association for Computational Linguistics (ACL'07) , 2007.[ bib ] Mark Johnson, Thomas L. Griffiths, and Sharon Goldwater. Bayesian inference for PCFGs via Markov chain Monte Carlo . In Proceedings of the North American Conference on Computational Linguistics (NAACL'07) , 2007.[ bib | .pdf ] Mark Johnson, Thomas L. Griffiths, and Sharon Goldwater. Adaptor Grammars: a Framework for Specifying Compositional Nonparametric Bayesian Models . In Advances in Neural Information Processing Systems 19 , 2007.[ bib | .pdf ] Matthew Lease and Eugene Charniak. Brown at CL-SR'07: Retrieving Conversational Speech in English and Czech . In Working Notes of the Cross-Language Evaluation Forum (CLEF): Cross-Language Speech Retrieval (CL-SR) track , 2007. Corrected version.[ bib | .pdf ] Matthew Lease. Natural Language Processing for Information Retrieval: the time is ripe (again) . In Proceedings of the 1st Ph.D. Workshop at the ACM Conference on Information and Knowledge Management (PIKM) , 2007. Best Paper award.[ bib | .pdf | Abstract ] Jenine Turner and Eugene Charniak. Language Modeling for Determiner Selection . In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers , pages 177-180, Rochester, New York, April 2007. Association for Computational Linguistics.[ bib | .pdf ] 2006 Ann Bies, Stephanie Strassel, Haejoong Lee, Kazuaki Maeda, Seth Kulick, Yang Liu, Mary Harper, and Matthew Lease. Linguistic Resources for Speech Parsing . In Fifth International Conference on Language Resources and Evaluation (LREC'06) , Genoa, Italy, 2006.[ bib | .pdf ] Eugene Charniak, Mark Johnson, Micha Elsner, Joseph Austerweil, David Ellis, Isaac Haxton, Catherine Hill, R. Shrivaths, Jeremy Moore, Michael Pozar, and Theresa Vu. Multilevel Coarse-to-Fine PCFG Parsing . In Proceedings of the Human Language Technology Conference of the NAACL (HLT-NAACL'06) , pages 168-175, New York City, USA, June 2006. Association for Computational Linguistics.[ bib | .pdf | slides ] Sharon Goldwater, Tom Griffiths, and Mark Johnson. Interpolating between types and tokens by estimating power-law generators . In Y. Weiss, B. Sch\u00f6lkopf, and J. Platt, editors, Advances in Neural Information Processing Systems 18 , pages 459-466, Cambridge, MA, 2006. MIT Press.[ bib | .pdf ] Sharon Goldwater, Thomas L. Griffiths, and Mark Johnson. Contextual Dependencies in Unsupervised Word Segmentation . In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association or Computational Linguistics (COLING_ACL'06) , pages 673-680, Sydney, Australia, July 2006. Association for Computational Linguistics.[ bib | .pdf ] John Hale, Izhak Shafran, Lisa Yung, Bonnie J. Dorr, Mary Harper, Anna Krasnyanskaya, Matthew Lease, Yang Liu, Brian Roark, Matthew Snover, and Robin Stewart. PCFGs with Syntactic and Prosodic Indicators of Speech Repairs . In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING-ACL'06) , pages 161-168, Sydney, Australia, July 2006. Association for Computational Linguistics.[ bib | .pdf ] William P. Headden III, Eugene Charniak, and Mark Johnson. Learning Phrasal Categories . In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing , pages 301-307, Sydney, Australia, July 2006. Association for Computational Linguistics.[ bib | .pdf ] Matthew Lease, Mark Johnson, and Eugene Charniak. Recognizing disfluencies in conversational speech . IEEE Transactions on Audio, Speech and Language Processing , 14(5):1566-1573, September 2006.[ bib | .pdf | Abstract ] Matthew Lease, Eugene Charniak, Mark Johnson, and David McClosky. A Look At Parsing and Its Applications . In Proceedings of the Twenty-First National Conference on Artificial Intelligence (AAAI-06) , 16-20 July 2006.[ bib | .pdf ] Matthew Lease and Mark Johnson. Early Deletion of Fillers In Processing Conversational Speech . In Proceedings of the Human Language Technology Conference of the NAACL (HLT-NAACL'06), Companion Volume: Short Papers , pages 73-76, New York City, USA, June 2006. Association for Computational Linguistics. Version here corrects Table 2 in published version.[ bib | .pdf ] David McClosky, Eugene Charniak, and Mark Johnson. Reranking and Self-Training for Parser Adaptation . In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (ACL'06) , pages 337-344, Sydney, Australia, July 2006. Association for Computational Linguistics.[ bib | .pdf | .ps ] David McClosky, Eugene Charniak, and Mark Johnson. Effective Self-Training for Parsing . In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference , pages 152-159, New York City, USA, June 2006. Association for Computational Linguistics.[ bib | .pdf | slides | .ps ] B. Roark, Yang Liu, M. Harper, R. Stewart, M. Lease, M. Snover, I. Shafran, B. Dorr, J. Hale, A. Krasnyanskaya, and L. Yung. Reranking for Sentence Boundary Detection in Conversational Speech . In Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP'06) , pages 545-548, May 14-19 2006.[ bib | .pdf | Abstract ] Brian Roark, Mary Harper, Eugene Charniak, Bonnie Dorr, Mark Johnson, Jeremy G. Kahn, Yang Liu, Mari Ostendorf, John Hale, Anna Krasnyanskaya, Matthew Lease, Izhak Shafran, Matthew Snover, Robin Stewart, and Lisa Yung. SParseval: Evaluation Metrics for Parsing Speech . In Fifth International Conference on Language Resources and Evaluation (LREC'06) , Genoa, Italy, 2006.[ bib | .pdf ] 2005 Eugene Charniak and Mark Johnson. Coarse-to-Fine n-Best Parsing and MaxEnt Discriminative Reranking . In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL'05) , pages 173-180, Ann Arbor, Michigan, June 2005. Association for Computational Linguistics.[ bib | .pdf ] Micha Elsner, Mary Swift, James Allen, and Daniel Gildea. Online Statistics for a Unification-Based Dialogue Parser . In Proceedings of the Ninth International Workshop on Parsing Technology (IWPT'05) , pages 198-199, Vancouver, British Columbia, October 2005. Association for Computational Linguistics.[ bib | .pdf | poster ] Heidi Fox. Dependency-Based Statistical Machine Translation . In Proceedings of the ACL Student Research Workshop , pages 91-96, Ann Arbor, Michigan, June 2005. Association for Computational Linguistics.[ bib | .pdf ] Dmitriy Genzel. Inducing a Multilingual Dictionary from a Parallel Multitext in Related Languages . In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing , pages 875-882, Vancouver, British Columbia, Canada, October 2005. Association for Computational Linguistics.[ bib | .pdf ] Sharon Goldwater and David McClosky. Improving Statistical MT through Morphological Analysis . In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing (HLT-EMNLP'05) , pages 676-683, Vancouver, British Columbia, Canada, October 2005. Association for Computational Linguistics.[ bib | .pdf | .ps ] Sharon Goldwater and Mark Johnson. Representational Bias in Unsupervised Learning of Syllable Structure . In Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005) , pages 112-119, Ann Arbor, Michigan, June 2005. Association for Computational Linguistics.[ bib | .pdf ] Jeremy G. Kahn, Matthew Lease, Eugene Charniak, Mark Johnson, and Mari Ostendorf. Effective Use of Prosody in Parsing Conversational Speech . In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing (EMNLP'05) , pages 233-240, Vancouver, British Columbia, Canada, October 2005. Association for Computational Linguistics.[ bib | .pdf ] Matthew Lease. Parsing and Disfluency Modeling . Technical Report CS-05-15, Brown University Department of Computer Science, 2005.[ bib | tech-report ] Matthew Lease, Eugene Charniak, and Mark Johnson. Parsing and its applications for conversational speech . In Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP'05) , volume 5, pages 961-964, March 18 - March 23 2005.[ bib | .pdf | Abstract ] Matthew Lease and Eugene Charniak. Parsing Biomedical Literature . In R. Dale, K.-F. Wong, J. Su, and O. Kwong, editors, Proceedings of the 2nd International Joint Conference on Natural Language Processing (IJCNLP'05) , volume 3651 of Lecture Notes in Computer Science , pages 58 - 69, Jeju Island, Korea, October 11 - October 13 2005. Springer-Verlag.[ bib | .pdf | Abstract ] Heng Lian. Chinese Language Parsing with Maximum-Entropy-Inspired Parser . Master's thesis, Brown University, Providence, RI, 2005.[ bib | .pdf | Abstract ] Jenine Turner and Eugene Charniak. Supervised and Unsupervised Learning for Sentence Compression . In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL'05) , pages 290-297, Ann Arbor, Michigan, June 2005. Association for Computational Linguistics.[ bib | .pdf ] 2004 Massimiliano Ciaramita and Mark Johnson. Multi-component Word Sense Disambiguation . In Rada Mihalcea and Phil Edmonds, editors, Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text , pages 97-100, Barcelona, Spain, July 2004. Association for Computational Linguistics.[ bib | .pdf ] Sharon Goldwater and Mark Johnson. Priors in Bayesian Learning of Phonological Rules . In Proceedings of the Seventh Meeting of the ACL Special Interest Group in Computational Phonology , pages 35-42, Barcelona, Spain, July 2004. Association for Computational Linguistics.[ bib | .pdf ] Michelle Gregory and Yasemin Altun. Using Conditional Random Fields to Predict Pitch Accents in Conversational Speech . In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL'04), Main Volume , pages 677-683, Barcelona, Spain, July 2004.[ bib | .pdf ] Michelle Gregory, Mark Johnson, and Eugene Charniak. Sentence-Internal Prosody Does not Help Parsing the Way Punctuation Does . In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLT-NAACL 2004: Main Proceedings , pages 81-88, Boston, Massachusetts, USA, May 2 - May 7 2004. Association for Computational Linguistics.[ bib | .pdf ] Keith B. Hall and Mark Johnson. Attention Shifting for Parsing Speech . In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL'04), Main Volume , pages 40-46, Barcelona, Spain, July 2004.[ bib | .pdf ] Mark Johnson and Eugene Charniak. A TAG-based noisy-channel model of speech repairs . In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL'04) , pages 33-39, Barcelona, Spain, July 2004.[ bib | .pdf ] Mark Johnson, Eugene Charniak, and Matthew Lease. An Improved Model For Recognizing Disfluencies in Conversational Speech . In Rich Transcription 2004 Fall Workshop (RT-04F) , 2004.[ bib | .pdf ] Ron Kaplan, Stefan Riezler, Tracy H King, John T Maxwell III, Alex Vasserman, and Richard Crouch. Speed and Accuracy in Shallow and Deep Stochastic Parsing . In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLT-NAACL 2004: Main Proceedings , pages 97-104, Boston, Massachusetts, USA, May 2 - May 7 2004. Association for Computational Linguistics.[ bib | .ps | .pdf ] Brian Roark, Murat Saraclar, Michael Collins, and Mark Johnson. Discriminative Language Modeling with Conditional Random Fields and the Perceptron Algorithm. In ACL , pages 47-54, 2004.[ bib ] 2003 Yasemin Altun, Mark Johnson, and Thomas Hofmann. Investigating Loss Functions and Optimization Methods for Discriminative Learning of Label Sequences . In Michael Collins and Mark Steedman, editors, Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing , pages 145-152, 2003.[ bib | .pdf ] Yasemin Altun and Thomas Hofmann. Large Margin Methods for Label Sequence Learning . In Proceedings of the Eighth European Conference on Speech Communication and Technology (EuroSpeech'03) , 2003.[ bib | .pdf | Abstract ] Eugene Charniak, Kevin Knight, and Kenji Yamada. Syntax-based Language Models for Statistical Machine Translation . In Proceedings of the Ninth Machine Translation Summit of the International Association for Machine Translation , New Orleans, Louisiana, September 2003.[ bib | .pdf ] Massimiliano Ciaramita, Thomas Hofmann, and Mark Johnson. Hierarchical Semantic Classification: Word Sense Disambiguation with World Knowledge . In Georg Gottlob and Toby Walsh, editors, IJCAI-03, Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence, Acapulco, Mexico, August 9-15, 2003 , pages 817-822. Morgan Kaufmann, 2003.[ bib | .pdf | .ps ] Massimiliano Ciaramita and Mark Johnson. Supersense Tagging of Unknown Nouns in WordNet . In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing (EMNLP-03) , pages 168-175, 2003.[ bib | .pdf ] Stuart Geman and Mark Johnson. Probability and statistics in computational linguistics, a brief review . Mathematical foundations of speech and language processing , 138:1-26, 2003.[ bib | .pdf ] Dmitriy Genzel and Eugene Charniak. Variation of Entropy and Parse Trees of Sentences as a Function of the Sentence Number . In Michael Collins and Mark Steedman, editors, Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing (EMNLP'03) , pages 65-72, 2003.[ bib | .pdf ] Sharon Goldwater and Mark Johnson. Learning OT Constraint Rankings Using a Maximum Entropy Model . In Proceedings of the Workshop on Variation within Optimality Theory , Stockholm University, 2003.[ bib | .pdf | .ps ] Keith Hall and Mark Johnson. Language modelling using efficient best-first bottom-up parsing . In Automatic Speech Recognition and Understanding Workshop (ASRU) . IEEE ASRU 2003, 2003.[ bib | .pdf ] Thomas Hofmann, Lijuan Cai, and Massimiliano Ciaramita. Learning with taxonomies: Classifying documents and words . In Workshop on Syntax, Semantics and Statistics (NIPS-03). , 2003.[ bib | .pdf ] Mark Johnson. Learning and Parsing Stochastic Unification-Based Grammars . In Bernhard Sch\u00f6lkopf and Manfred K. Warmuth, editors, Computational Learning Theory and Kernel Machines, 16th Annual Conference on Computational Learning Theory and 7th Kernel Workshop, COLT/Kernel 2003, Washington, DC, USA, August 24-27, 2003, Proceedings , volume 2777 of Lecture Notes in Computer Science , pages 671-683. Springer, 2003.[ bib | .pdf ] 2002 Yasemin Altun, Thomas Hofmann, and Mark Johnson. Discriminative Learning for Label Sequences via Boosting . In Proceedings of Neural Information Processing Systems (NIPS02) , 2002.[ bib | .pdf ] Don Blaheta. Handling noisy training and testing data . In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing , Philadelpha, Pennsylvania, July 2002.[ bib | .pdf ] Massimiliano Ciaramita. Boosting automatic lexical acquisition with morphological information . In Unsupervised Lexical Acquisition: Proceedings of the Workshop of the ACL Special Interest Group on the Lexicon (SIGLEX) , pages 17-25, Philadelphia, July 2002. Association for Computational Linguistics.[ bib | .ps | .pdf ] Donald Engel, Eugene Charniak, and Mark Johnson. Parsing and Disfluency Placement . In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP 2002) , pages 49-54, 2002.[ bib | .pdf ] Heidi Fox. Phrasal Cohesion and Statistical Machine Translation . In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP 2002) , pages 304-311, Philadelphia, Pennsylvania, July 2002. Association for Computational Linguistics.[ bib | .pdf ] Stuart Geman and Mark Johnson. Dynamic programming for parsing and estimation of stochastic unification-based grammars . In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics (ACL'02) , pages 279-286, Morristown, NJ, USA, 2002. Association for Computational Linguistics.[ bib | .pdf ] Stuart Geman and Mark Johnson. Probabilistic Grammars and their Applications . In N.J. Smelser and P.B. Baltes, editors, International Encyclopedia of the Social & Behavioral Sciences , pages 12075-12082, Pergamon, Oxford, 2002.[ bib | .pdf ] Dmitriy Genzel and Eugene Charniak. Entropy Rate Constancy in Text . In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL-02) , pages 00-00, 2002.[ bib | .pdf ] Mark Johnson. The DOP Estimation Method is Biased and Inconsistent . Computational Linguistics , 28(1):71-76, 2002.[ bib | .pdf ] Mark Johnson. A Simple Pattern-matching Algorithm for Recovering Empty Nodes and their Antecedents . In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL) , pages 136-143, 2002.[ bib | .pdf | .ps ] Stefan Riezler, Tracy H. King, Ronald M. Kaplan, Richard Crouch, John T. III Maxwell, and Mark Johnson. Parsing the Wall Street Journal using a Lexical-Functional Grammar and Discriminative Estimation Techniques . In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL-02) , pages 271-278, 2002.[ bib | .pdf ] 2001 Yasemin Altun and Mark Johnson. Inducing SFA with Epsilon-Translations Using Minimum Description Length . In Finite State Methods in Natural Language Processing Workshop, ESSLLI 2001 , 2001.[ bib | .pdf ] Don Blaheta and Mark Johnson. Unsupervised learning of multi-word verbs . In Proceedings of the 2001 ACL Workshop on Collocation , 2001.[ bib | .pdf ] Eugene Charniak and Mark Johnson. Edit Detection and Parsing for Transcribed Speech . In Proceedings of the Second Conference of the North American chapter of the Association for Computational Linguistics (NAACL '01) , 2001.[ bib | .pdf ] Eugene Charniak. Immediate-Head Parsing for Language Models . In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics , pages 124-131, 2001.[ bib | .pdf | .ps ] Eugene Charniak. Unsupervised Learning of Name Structure From Coreference Data . In Second Meeting of the North American Chapter of the Association for Computational Linguistics (NACL-01) , 2001.[ bib | .pdf ] Keith Hall. A Statistical Model of Nominal Anaphora . Master's thesis, Brown University, Providence, RI, 2001.[ bib | .pdf ] Mark Johnson. Joint and Conditional Estimation of Tagging and Parsing Models . In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL-01) , 2001.[ bib | .pdf ] Brian Roark. Probabilistic top-down parsing and language modeling . Computational Linguistics , 27(2):249-276, 2001.[ bib | .pdf ] 2000 Don Blaheta and Eugene Charniak. Assigning function tags to parsed text . In Proceedings of the First Conference of the North American chapter of the Association for Computational Linguistics (NAACL '00) , pages 234-240, 2000.[ bib | .pdf ] Eugene Charniak. Parsing to Meaning, Statistically. In Canadian Conference on AI , page 442, 2000.[ bib | .pdf ] Eugene Charniak. A maximum-entropy-inspired parser . In Proceedings of the first conference on North American chapter of the Association for Computational Linguistics , pages 132-139, San Francisco, CA, USA, 2000. Morgan Kaufmann Publishers Inc.[ bib | .pdf | tech-report ] Eugene Charniak, Yasemin Altun, Rodrigo de Salvo Braz, Benjamin Garrett, Margaret Kosmala, Tomer Moscovich, Lixin Pang, Changbee Pyo, Ye Sun, Wei Wy, Z. Yang, S. Zeller, and L. Zorn. Reading Comprehension Programs in a Statistical-Language-Processing Class . In In ANLP/NAACL Workshop on Reading Comprehension Tests as Evaluation for Computer-Based Language Understanding Systems (ANLP/NAACL-00) , 2000.[ bib | .pdf ] Massimiliano Ciaramita and Mark Johnson. Explaining away ambiguity: Learning verb selectional preference with Bayesian networks . In Proceedings of the 18th International Conference on Computational Linguistics , 2000.[ bib | .pdf ] Keith Hall and Thomas Hofmann. Learning Curved Multinomial Subfamilies for Natural Language Processing and Information Retrieval . In Pat Langley, editor, Proceedings of the Seventeenth International Conference on Machine Learning (ICML 2000), Stanford University, Stanford, CA, USA, June 29 - July 2, 2000 , pages 351-358. Morgan Kaufmann, 2000.[ bib | .pdf ] Mark Johnson and Brian Roark. Compact non-left-recursive grammars using the selective left-corner transform and factoring . In Proceedings of the 18th conference on Computational linguistics (COLING '00) , pages 355-361, 2000.[ bib | .pdf ] Mark Johnson and Stefan Riezler. Exploiting auxiliary distributions in stochastic unification-based grammars . In 1st Meeting of the North American Chapter of the Association for Computational Linguistics (NACL-00) , pages 154-161, 2000.[ bib | .pdf ] Scott Miller, Heidi Fox, Lance Ramshaw, and Ralph Weischedel. A novel use of statistical parsing to extract information from text . In Proceedings of the first conference on North American chapter of the Association for Computational Linguistics (NAACL'00) , pages 226-233, San Francisco, CA, USA, 2000. Morgan Kaufmann Publishers Inc.[ bib | .pdf ] Stefan Riezler, Detlef Prescher, Jonas Kuhn, and Mark Johnson. Lexicalized Stochastic Modeling of Constraint-Based Grammars using Log-Linear Measures and EM Training . In In Proceedings of 38th Annual Meeting of the Association for Compuational Linguistics (ACL-00) , 2000.[ bib | .pdf ] Brian Roark and Eugene Charniak. Measuring efficiency in high-accuracy, broad-coverage statistical parsing . In Proceedings of the COLING'00 Workshop on Efficiency in Large-scale Parsing Systems , pages 29-36, 2000.[ bib | .pdf ] 1999 Matthew Berland and Eugene Charniak. Finding parts in very large corpora . In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL '99) , pages 57-64, 1999.[ bib | .pdf | tech-report ] Don Blaheta and Eugene Charniak. Automatic compensation for parser figure-of-merit flaws . In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics (ACL'99) , pages 513-518, Morristown, NJ, 1999. Association for Computational Linguistics.[ bib | .pdf ] Sharon A. Caraballo and Eugene Charniak. Determining the Specificity of Nouns from Text . In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-99) , 1999.[ bib | .ps ] Mark Johnson. Type-driven semantic interpretation and Feature dependencies in R-LFG . Semantics and Syntax in Lexical Functional Grammar , pages 359-388, 1999.[ bib | .pdf ] Mark Johnson. A Resource Sensitive Interpretation of Lexical Functional Grammar . Journal of Logic, Language and Information , 8(1):45-81, 1999.[ bib | .pdf | .ps ] Mark Johnson, Stuart Geman, Stephen Canon, Zhiyi Chi, and Stefan Riezler. Estimators for Stochastic Unification-Based Grammars . In 37th Annual Meeting of the Association for Computational Linguistics (ACL-99) , pages 535-541, 1999.[ bib | .pdf ] Brian Roark and Mark Johnson. Efficient probabilistic top-down and left-corner parsing . In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics (ACL '99) , pages 421-428, 1999.[ bib | .pdf ] 1998 Sharon Caraballo and Eugene Charniak. New Figures of Merit for Best-First Probabalistic Chart Parsing . Computational Linguistics , 24(2):275-298, 1998.[ bib | .pdf ] Eugene Charniak, Sharon Goldwater, and Mark Johnson. Edge-Based Best-First Chart Parsing . In Sixth Workshop on Very Large Corpora , pages 127-133, 1998.[ bib | .pdf ] Zhiyi Chi and Stuart Geman. Estimation of probabilistic context-free grammars . Computational Linguistics , 24(2):299-305, 1998.[ bib | .pdf ] Niyu Ge, John Hale, and Eugene Charniak. A statistical approach to anaphora resolution . In Proceedings of the Sixth Workshop on Very Large Corpora , Orlando, Florida, 1998. Harcourt Brace.[ bib | .pdf | Abstract ] John Hale and Eugene Charniak. Getting Useful Gender Statistics from English Text . Technical Report CS-98-06, Brown University, Providence, RI, 1998.[ bib | .ps.Z | .html | Abstract ] Mark Johnson. Proof Nets and the Complexity of Processing Center Embedded Constructions . Journal of Logic, Language and Information , 7(4):433-447, 1998.[ bib | .pdf ] Mark Johnson. The Effect of Alternative Tree Representations on Tree Bank Grammars . In David M. W. Powers, editor, Proceedings of the Joint Conference on New Methods in Language Processing and Computational Natural Language Learning: (NeMLaP3/CoNLL98) , pages 39-48, Somerset, New Jersey, 1998. Association for Computational Linguistics.[ bib | .pdf ] Mark Johnson. PCFG Models of Linguistic Tree Representations . Computational Linguistics , 24(4):613-632, 1998.[ bib | .pdf | .ps.gz ] Mark Johnson. Finite-state Approximation of Constraint-based Grammars using Left-corner Grammar Transforms . In COLING-ACL , pages 619-623, 1998.[ bib | .pdf | .ps ] 1997 Eugene Charniak. Statistical Techniques for Natural Language Parsing . AI Magazine , 18(4):33-44, 1997.[ bib | .pdf | .ps ] Eugene Charniak. Statistical Parsing with a Context-Free Grammar and Word Statistics . In Proceedings of AAAI , pages 598-603, 1997.[ bib | .pdf | tech-report | .ps | Abstract ] Mark Johnson. Features as resources in R-LFG . In Proceedings of the 1997 LFG Conference , 1997.[ bib | .ps ] 1996 Sharon Caraballo and Eugene Charniak. Figures of Merit for Best-First Probabilistic Parsing . In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP'96) , pages 127-132, 1996.[ bib | tech-report | .pdf | Abstract ] Eugene Charniak. Tree-bank Grammars . In Proceedings of the Eleventh National Conference on Artificial Intelligence (AAAI-96) , 1996.[ bib | tech-report | Abstract ] Eugene Charniak, Glenn Carroll, John Adcock, Anthony R. Cassandra, Yoshihiko Gotoh, Jeremy Katz, Michael L. Littman, and John McCann. Taggers for Parsers . Artificial Intelligence , 85(1-2):45-57, 1996.[ bib | tech-report | .ps | Abstract ] Eugene Charniak. Expected-Frequency Interpolation . Technical Report CS-96-37, Brown University, Providence, RI, 1996.[ bib | .html | Abstract ] Mark Johnson. Resource-sensitivity in Lexical-Functional Grammar . Proceedings of the 1996 Roma Workshop , 1996.[ bib ] 1995 Sam Bayer and Mark Johnson. Features and Agreement . In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics (ACL-95) , pages 70-76, 1995.[ bib | .pdf | Abstract ] Eugene Charniak. Parsing with context-free grammars and word statistics . Technical Report CS-95-28, Brown University, Providence, RI, 1995.[ bib | .ps.Z | Abstract ] Murat Ersan and Eugene Charniak. A statistical syntactic disambiguation program and what it learns . In Stefan Wermter, Ellen Riloff, and Gabriele Scheler, editors, Symbolic, Connectionist, and Statistical Approaches to Learning for Natural Language Processing , 1995.[ bib | tech-report ] Mark Johnson. Memorization in Top-Down Parsing . Computational Linguistics , 21(3):405-415, 1995.[ bib | .pdf ] Mark Johnson and Sam Bayer. Features and Agreement in Lambek Categorial Grammar . In Proceedings of the 1995 ESSLLI Formal Grammar Workshop , pages 123-137, 1995.[ bib | .ps.Z ] Mark Johnson and Jochen Dorre. Memoization of coroutined constraints . In Proceedings of the 33rd annual meeting on Association for Computational Linguistics , pages 100-107, Morristown, NJ, USA, 1995. Association for Computational Linguistics.[ bib | .pdf ] 1994 Glenn Carroll and Eugene Charniak. Combining Grammars For Improved Learning . Technical Report CS-94-08, Department of Computer Science, Brown University, February 1994.[ bib | .pdf | .ps | .html | Abstract ] Eugene Charniak, Glenn Carroll, John Adcock, Antony Cassandra, Yoshihiko Gotoh, Jeremy Katz, Michael Littman, and John McCann. Expected-Frequency Interpolation . Technical Report CS-94-06, Brown University, Providence, RI, 1994.[ bib | .ps.Z ] Eugene Charniak and Glenn Carroll. Context-Sensitive Statistics for Improved Grammatical Language Models . Technical Report CS-94-07, Brown University, Providence, RI, 1994.[ bib | .ps.Z | .html | Abstract ] Mark Johnson. Computing with Features as Formulae . Computational Linguistics , 20(1):1-25, 1994.[ bib | .pdf ] 1993 Eugene Charniak, Curtis Hendrickson, Neil Jacobson, and Mike Perkowitz. Equations for Part-of-Speech Tagging . In National Conference on Artificial Intelligence , pages 784-789, 1993.[ bib | .ps | Abstract ] Eugene Charniak. Statistical Language Learning . The MIT Press, Cambridge, Massachusetts, 1993.[ bib | http ] 1992 Glenn Carroll and Eugene Charniak. Two Experiments on Learning Probabilistic Dependency Grammars from Corpora . Technical Report CS-92-16, Brown University, Providence, RI, USA, 1992.[ bib | .pdf | Abstract ] Last update: Friday, May 27 2016, 04:27 PM var sc_project=2284705;var sc_invisible=1;var sc_partition=21;var sc_security=\"70f322dc\";", "https://awards.cs.brown.edu/2016/12/12/foreign-policy-magazine-names-tellex-and-oberlin-2016-global-thinkers/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Foreign Policy Magazine Names Tellex And Oberlin 2016 Global Thinkers Posted by Jesse Polhemus on Dec. 12, 2016 \"When we consider as we do each year the work of the world's leading thinkers,\" writes David Rothkopf, CEO and Editor of the FP Group, which publishes Foreign Policy Magazine, \"we find that the vast majority of them \u2014in science, technology, business, culture and government\u2014 are actually moving us forward and helping to solve the problems of the past. That's encouraging...and that's what we are acknowledging with this issue.\u201d This year, Foreign Policy included Assistant Professor Stefanie Tellex and PhD candidate John Oberlin of Brown University' s Department of Computer Science (Brown CS) in their 2016 list of Leading Global Thinkers, placing them in the Innovators category. Their work in robotic grasping, human-robot collaboration, and robot-to-robot learning puts them among a small group of only 100 peers, whose accomplishments range from founding a political party in Hong Kong to fighting the Zika virus to exposing lead levels in the tap water of Flint, Michigan. You can read John and Stefanie's profile here and the full article here . For more information, please click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "http://mlrg.cs.brown.edu/": "Machine Learning Reading Group @ BrownU Related Groups AI at Brown Pattern Theory Lunch Courses 2016 CS 2420: Probabilistic Graphical Models 2015 CS 1420: Machine learning ENGN 2520: Machine learning 2014 ENGN 2912P: Topics in Optimization CS 2420: Probabilistic Graphical Models 2013 CS 1420: Introduction to machine learning CS 2950P: Graphical Models CS 2951H: Big Data 2012 CS 2950P: Bayesian Nonparametrics 2006 CS 1955: Intro ML Archives 2016 Spring 2015 Fall Spring 2014 Fall Spring 2013 Fall Spring 2012 Fall Summer Spring 2011 Fall Summer Spring Announcement The MLRG is no longer actively maintained, if you are interested in leading the group, please contact Brown CS for authorization. About We meet weekly to discuss active projects and recent papers. Participants hail from many disciplines, including applied math, neuroscience, computer science, and cognitive science. Please join us! MLRG announcements happen on theML-READING-GROUP list. Click here to subscribe . TheMLRG leader this semester (Fall 2016) is Zhile Ren . Contact: ren(AT)cs.brown.edu Schedule During fall 2016, we'll meet at CIT Library on Mondays 4-5pm . The CIT library is a meeting room/grad lounge at the fourth floor of the building. Schedule Date Topic 9/19 Organizational Meeting 9/26 Practice Talk : DK's Thesis Proposal 10/3 No meeting 10/10 No meeting (Columbus Day) 10/17 Ren : Research update on segmentation/stereo/flow 10/24 Gabe : Introduction to Bayesian Optimization. (link) 10/31 Canceled. 11/7 Leah : Stochastic Variational Inference. (link) 11/14 No meeting (CVPR Deadline) 11/21 No meeting : New England Vision Workshop (link) 11/28 Ren : Practice talk of IVC seminar? See last spring's schedule here .", "https://awards.cs.brown.edu/2019/03/12/alum-adventures-brown-cs-alums-david-simons-daniel-wilk-and-michael-natkin-have-won-academy-award-work-adobe-after-effects/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Alum Adventures: Brown CS Alums David Simons, Daniel Wilk, And Michael Natkin Have Won An Academy Award For Work On Adobe After Effects Posted by Rujul Singh on March 12, 2019 in Awards Click the links that follow for more news items about awards won by Brown CS alums. In the days since we went to press with the story below, Brown CS alums Dave Simons \u201990 and Daniel Wilk \u201992 have won yet another award for their work on Adobe Character Animator. The National Academy of Television Arts and Sciences has recognized the tool as a Pioneering System for Live Performance-Based Animation Using Facial Recognition. Developed by Dave\u2019s team, Character Animator allows artists to animate characters in real time via live tracking and has changed the landscape of character animation. \u201cWe are honored to work on software that allows artists to tell their stories in new ways,\u201d says Dave when asked about his motivations for the project. The tool was used for the first-ever live episode of The Simpsons, live cartoon interviews on The Late Show with Stephen Colbert, and the quick-turnaround production of Our Cartoon President, and will undoubtedly continue to make waves in the animation industry. \u201cWe knew the odds were against us,\u201d laughs Brown CS alum Dave Simons \u201990, \u201cbut the idealism of four recent college graduates trumped the 90% failure rate we were warned about.\u201d Nearly 30 years later, it seems this idealism may not have been misplaced, as Dave, along with fellow Brown CS alums Daniel Wilk \u201992 and Michael Natkin \u201989, have just won an Academy Award in scientific and technical achievement for their work on Adobe After Effects. Awarded to those who provide extraordinary contributions to the science of filmmaking and a proven record of contributing significant value to the process of making motion pictures, the honor truly recognized the critical role that After Effects has come to play in the motion graphics industry. What motivated Dave to begin his work on this pioneering project? Well, it all started in the graphics group of Brown CS Professor Andy van Dam many years ago, at a time when undergraduate contributions to research were far less common. (Michael also mentioned both Andy and his group in his acceptance speech, thanking van Dam for \"giving me a chance\" and a first introduction to graphics.) \u201cWhen I first began my work in this field, all the tools were command-line tools,\u201d explains Dave, \u201cand I actually did my senior thesis on distribution ray-tracing.\u201d Friendships at Brown naturally led to the birth of The Company of Science & Art, otherwise known as CoSA for short. Founded by Dave and three other Brown graduates in June of 1990 \u2013Greg Deocampo \u201988, David Foster (DaveF) \u201990, and David Herbstman (DaveH) \u201990\u2013 the company planned to become the next world-class content provider for the new electronic age. \u201cAfter searching all around Providence, DaveF found a great place near downtown,\u201d he remembers. \u201cDaveH negotiated the rent down to $1000 a month, and we were in business.\u201d With such lofty expectations, it was no surprise that the fledgling company inevitably faced a myriad of setbacks in its early years. The original plan was to have artists and programmers working side by side to produce multimedia content, and CD-ROM production was the first task. Named Connections: The CoSA Journal, this first hypermedia publication was designed to show off the new medium, but garnered little interest. This was followed by PACo (PICS Animation Compiler), which allowed platform-independent low-bandwidth streaming animation playback with synched sound. What initially seemed like a promising idea, however, quickly changed as Apple announced QuickTime a mere few months later. Running low on funds, the team knew that they needed to come up with something fast. And it was from this that Egg (the first codename for After Effects) was born. This is where Dave\u2019s graphics-group training would really start to pay off. With Egg development in full swing, it was at this point that Dan Wilk \u201992 joined the team, helping to write effect plug-ins. The first press demos of the brand-new software were held in a private suite at MacWorld Boston. After receiving positive reviews from the public, the team quickly realized that the project needed a real name \u2013 After Effects. \u201cShowing After Effects 1.0 to the public for the first time was an exhilarating experience,\u201d remembers Dave, \u201cWe had a tiny booth and people were packed ten-deep at times trying to get a glimpse.\u201d The software exploded in popularity, and CoSA was bought out a mere six months later by Aldus Corporation, followed by another merger of Aldus into Adobe Systems a year later. This set into motion the chain of events that led to After Effects becoming the dominant motion graphics and visual effects application used in the post-production process of film and television production. \u201cIt\u2019s easily the most common tool now to do motion graphics in the film industry,\u201d explains Dave, \u201cand it really lets you create anything you want in this field.\u201d Brown CS has certainly left its mark on the industry, as over 15 Brown graduates worked at CoSA or were involved in the After Effects project. Used for most of the iconic Pixar movies\u2019 opening and closing credits, After Effects has quickly become an indispensable tool in the artist\u2019s toolkit. With such an accomplished career, what does Dave believe prepared him best from his years at Brown? Well, it may very well have been his experiences TAing a myriad of classes in Brown CS. \u201cI was a head TA for Andy van Dam in CS 11 and CS 192,\u201d he remembers, \u201cand Andy\u2019s high bar and criticalness made me learn a lot.\u201d Dave has certainly come a long way from the old, refurbished apartment in which the project first began, and his work has undoubtedly made it possible for countless artists to enable their dreams. For more information on the history of CoSA and the team\u2019s Academy Award acceptance speeches, see the following link . For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse Polhemus .", "https://awards.cs.brown.edu/2020/02/17/michael-littman-has-been-named-aaas-leshner-fellow/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Michael Littman Has Been Named An AAAS Leshner Fellow Posted by Rujul Singh on Feb. 17, 2020 in Awards Click the links that follow for more news items about Michael Littman and other recent accomplishments by Brown CS faculty Brown CS Professor Michael Littman has just been named a Leshner Fellow focusing on Artificial Intelligence by the American Association for the Advancement of Science. Each year, the AAAS selects leaders from disciplines at the forefront of important science-society issues, recognizing them for their contributions and commitment to public engagement in the field. Fellows are provided with the opportunity to convene for a week of intensive public-engagement and science-communication collaboration with the rest of the cohort, with the goal of increasing public engagement and enacting institutional change during the fellowship year. \u201cI am most interested in helping people whose lives are being impacted by computing technology,\u201d Michael explains, \u201cto understand how that technology works and how we can best enhance its ability to empower us while minimizing its risks.\u201d As a founding member of \u201cAI Hub\u201d (an organization with the goal of providing free, high-quality information about AI to the public), and co-host of the monthly podcast \u201c Computing Up \u201d, Michael continues to be a pioneer in sharing the wonders of AI and computing with the public. For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse Polhemus .", "https://awards.cs.brown.edu/2019/05/20/david-abel-wins-presidential-award-excellence-teaching/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) David Abel Wins A Presidential Award For Excellence In Teaching Posted by Rujul Singh on May 20, 2019 in Awards Click the links that follow for more news items about David Abel , other winners of the Presidential Award , and other awards won by our students. PhD candidate David Abel of Brown CS , who just recently proposed his thesis and expects to graduate with a PhD in Computer Science and a Master\u2019s in Philosophy next spring, has been recognized for an accomplishment beyond his achievements in research. Chosen out of hundreds of graduate students with teaching appointments, Dave was one of only four to win the Presidential Award for Excellence in Teaching. The award, given annually at the University Awards ceremony, recognizes outstanding pedagogical achievement. Its criteria span from teaching that influences and inspires students to learn to development of curriculum and resources that promote student learning. Dave began his teaching journey in 2014 as a TA for Stefanie Tellex, teaching CS 1410 (an undergraduate Artificial Intelligence class). After being nominated as a \u201cgreat TA\u201d by the students in the class, he became a TA for CS 8 (A First Byte of Computer Science), an introductory computer science class for non-majors taught by Professor Michael Littman with enrollment of 109 students. During his semester of teaching the course, Dave was consistently praised by his students, with many citing his \u201cenergy, availability, and thoughtfulness\u201d as being key to fostering an environment for intellectual curiosity. Dave was instrumental in implementing an optional python unit in the class that gave students the opportunity to learn a language used widely in industry. As a testament to his teaching abilities, a full 98.5% of respondents rated the class as effective or very effective when Michael took a sabbatical and Dave ran the class on his own. Not limited to the classroom, Dave has been involved in a variety of activities that may very well have had an even greater impact on the Brown community. Along with fellow CS PhD students Nediyana Daskalova and Amariah Becker, Dave has been heavily involved in designing and running peer mentorship program in the department. His initiative pairs up post-candidacy PhD students with first year PhD students, ensuring that new students have proper guidance regarding finding research, working with their advisor, and establishing work-life balance. Keeping with the spirit of mentorship, Dave has been a primary research advisor for several Brown undergraduates as well. Over the past few years, he has co-authored 11 papers with many undergraduate students, guiding them through the research process. Dave has clearly shown himself to be a remarkable teacher, both in and outside the classroom. As he finishes up his graduate studies, it's evident that his work has made a personal impact on the many dozens of students with whom he has worked. For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse Polhemus.", "https://blog.cs.brown.edu/2013/07/26/moocs-overview/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) MOOCs: An Overview Posted by Rosemary Simpson on July 26, 2013 MOOCs (Massive Open OnlineCourse) are interactive online courses that typically are free and open toanyone with an Internet connection. Likeearlier free online course offerings, e.g., MIT's OCW (Open CourseWare)initiative, they provide resources such as videos, recommended readings, and problemsets. They differ from these earlieronline courses in two major ways: the courses are designed for online useinstead of being copies of on-site existing courses, and they are structuredaround interactive social networks, called user forums. Currently there are three major MOOCvendors: Coursera (www.coursera.org), edX (www.edx.org), and Udacity(www.udacity.com). While the format forthe three is similar, Udacity differs from Coursera and edX in that it does nothave a calendar-based schedule; students may start a course at any time. The figure below fromStanford (http://www.stanforddaily.com/2013/02/05/a-look-at-online-education-coursera-edx-and-udacity/online-education-page-1/) summarizes keycomponents: history, number of universities, number of courses, number ofstudents, and whether they are for-profit or non-profit.", "https://awards.cs.brown.edu/2019/05/09/evgenios-kornaropoulos-wins-joukowsky-family-foundation-outstanding-dissertation-award/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Evgenios Kornaropoulos Wins The Joukowsky Family Foundation Outstanding Dissertation Award Posted by Jesse Polhemus on May 9, 2019 in Awards Click the link that follows for more news about other Brown CS winners of the Joukowsky Family Foundation Outstanding Dissertation Award and other recent accomplishments by our students . Every year, Brown University 's Graduate School recognizes four students who are receiving doctoral degrees for superior achievements in research: one each in the humanities, life sciences, physical sciences, and social sciences. This year, one of the recipients of the Joukowsky Family Foundation Outstanding Dissertation Award is Evgenios Kornaropoulos of Brown CS , who successfully defended his thesis two weeks ago. He is the Department of Computer Science's second winner of this prestigious award, following Stefan Roth . The award and an honorarium will be given out at the Graduate School Commencement ceremony on Sunday, May 26. \"As the volume and complexity of generated data grow,\" Evgenios explains, \"users would like to maintain the ability to issue expressive queries on their data without sacrificing privacy. Encrypted databases are one of the most promising approaches towards this direction. However, this efficiency comes with the price of leaking information about the plaintext data. In my thesis, we use an algorithmic approach to develop rigorous attacks on encrypted databases and secure protocols.\" Specifically, Evgenios's work addresses the limitation of standard leakage profiles in encrypted databases under widely-used expressive queries such as range queries and k-nearest neighbor queries. \"In the works published from my thesis,\" he says, \"we show that even though we have cryptographic proofs that guarantee that the interaction between a client and a server leaks nothing more than a well-defined piece of information, we are still discovering what an adversary can infer from the leaked information. Using a plethora of algorithmic tools from areas such as computational geometry, statistics, learning theory, probabilistic analysis, and optimization, we devise new attacks that recover the plaintext values of encrypted databases under minimal assumptions about the query and the data distribution. Hopefully, our findings will pave the way towards new efficient cryptographic designs that defend against our attacks.\" When asked about the experience of doing a PhD at Brown CS, Evgenios says, \"I am thrilled to call Prof. Roberto Tamassia my academic father. His experience, rigor, and patience helped me sharpen my technical skills as well as my research taste. I also feel very fortunate to interact frequently with our professors that lead by example such as Prof. Vasileios Kemerlis and the rest of our Security Group . Finally, a big part of my thesis came out of my interaction with my academic sibling Prof. Charalampos Papamanthou from University of Maryland who is doing outstanding research and always sets the bar high. It is an honor to receive this prestigious award from our Graduate School and I am thankful for our professors and staff for making my graduate studies such a rewarding experience!\" A full list of winners is available here . The image above is \u00a9 2019 by Kirtley Righi and used with permission. For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Brown CS PhD Candidate Ji Won Chung Implements A Sleep Regularity Index In A Popular Sleep Tracker Posted by Robayet Hossain on March 7, 2024 Ji Won Chung , a third-year PhD student advised by Jeff Huang , Brown CS faculty member and researcher in human-computer interaction, has been collaborating with the developers of Sleep as Android, a popular sleep tracking app that supports vibration on alarms, anti-snoring measures, and lucid dreaming cues. Ji Won\u2019s research focused on writing code to implement a scientifically-evaluated sleep regularity index (SRI), which is now being incorporated into the app itself, and is expected to impact the sleep patterns of millions of people worldwide. read more \u00bb The Telepresence Of Furniture In Extended Reality Posted by Jesse Polhemus on March 4, 2024 in Socially Responsible Computing In the current issue of ACM Interactions Magazine , Assistant Professor of Practice Ian Gonsher presents a collection of prototypes developed at the intersection of robotics, ubiquitous computing, mixed reality, and furniture design. These design research projects also call attention to inequalities between local and remote telepresence users, and offer viable alternatives away from the dominant paradigm of personal devices towards the development of extended reality infrastructure as a public good. read more \u00bb The Computer History Museum\u2019s 40th Anniversary Celebration Of The Macintosh Includes A Shoutout To Brown CS Posted by Jesse Polhemus on Feb. 27, 2024 On January 24 of 2024, I attended the Computer History Museum (CHM)\u2019s huge celebration in Silicon Valley for the 40th anniversary of the launch of the Apple Macintosh, where Brown CS got a shout-out during the two-hour program. Why would that be? I thought it would be interesting to those who weren\u2019t around to learn about how universities \u2013 Brown in particular \u2013 were instrumental to the success of the computer that many now take for granted. read more \u00bb Brown CS UTAs Start The Semester With A Dodgeball Tournament Posted by Jesse Polhemus on Feb. 2, 2024 read more \u00bb The Brown Daily Herald Meets CSCI 0150's New AI-Powered Chatbot Teaching Assistant Posted by Jesse Polhemus on Feb. 1, 2024 read more \u00bb John Hughes Ranks In The Top 0.21% Of Stack Exchange\u2019s Math Users Posted by Robayet Hossain on Jan. 29, 2024 in Awards Stack Exchange is a network of question-and-answer websites on subjects in diverse fields, with each site covering a specific topic where users\u2019 questions and answers are input into an online reputation award process. Stack Exchange website areas include knitting, electronics, and especially programming, and users are able to upvote questions and answers that feel relevant and right for them. Brown CS faculty member John Hughes was recently ranked in the top 0.21% of Stack Exchange users in the Mathematics stack exchange for his reputation in answering questions posted online. read more \u00bb Research Associate Tom Sgouros And Brown CS Students Use Sound And AI To Make NASA Imagery Accessible Posted by Jesse Polhemus on Dec. 18, 2023 in Diversity , Socially Responsible Computing \"Pivoting is a lot of what I do,\" Brown CS Research Associate Tom Sgouros says of a current project. It began in a familiar research area, virtual reality, and evolved in two different directions, resulting in work that offered unexpected depths along the route to an important and often neglected goal: aiding the visually impaired. read more \u00bb Diverse Career Paths: Jonah Kagan Discusses Meaningful Impact Through CS Posted by Robayet Hossain on Dec. 3, 2023 in Socially Responsible Computing , Diversity A member of the Brown CS class of 2013, Jonah Kagan is a software engineer at VotingWorks , a small nonprofit organization dedicated to building reliable, open-source election technology like voting machines, ballot scanners, and election-auditing software. When asked about the skills he uses for his career, Kagan explained that the knowledge learned in his very first computer science class, CSCI 0190 Accelerated Introduction to Computer Science , has helped him in his day-to-day life. read more \u00bb The New York Times Recommends Rhode Island In The Fall Posted by Jesse Polhemus on Oct. 19, 2023 A recent New York Times describes Rhode Island's East Bay as a beautiful, bountiful autumn destination. \"Just 30 minutes from Providence,\" writes Christine Chitnis, \"over an hour from Boston and four hours from New York City, the Easty Bay towns of Warren, Bristol, Tiverton and Little Compton offer an idyllic fall weekend getaway.\" read more \u00bb Alum Adventures: Atty Eleti Talks About Learning By Building At OpenAI Posted by Robayet Hossain on Sept. 28, 2023 in Socially Responsible Computing , Diversity A member of the Brown CS class of 2017, Atty Eleti spent his time at Brown University organizing various hackathons for Hack@Brown , in the Undergraduate Teaching Assistant (UTA) mentorship program for computer science courses discussing topics such as distributed systems and discrete mathematics, and in the International Mentoring Program helping international students become acclimatized to the university\u2019s community. Atty also augmented his CS degree with Brown\u2019s curriculum and took graphic design courses at the Rhode Island School of Design (RISD). read more \u00bb Page 1 of 45 next \u00bb", "https://awards.cs.brown.edu/2021/05/26/eli-upfal-and-collaborators-receive-acms-paris-kanellakis-theory-and-practice-award/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Eli Upfal And Collaborators Receive ACM's Paris Kanellakis Theory And Practice Award Posted by Jesse Polhemus on May 26, 2021 in Awards Click the links that follow for more news about Eli Upfal and other recent accomplishments by our faculty . This week, Professor Eli Upfal of Brown CS and his collaborators received one of theoretical computer science's highest honors, an award that also pays tribute to Eli's predecessor at Brown University . Together with Yossi Azar (Tel Aviv University), Andrei Broder (Google Research), Anna Karlin (University of Washington), and Michael Mitzenmacher (Harvard University), Upfal has won the Association for Computing Machinery (ACM) Paris Kanellakis Theory and Practice Award for the discovery and analysis of balanced allocations, known as the power of two choices, and their extensive applications to practice. The ACM is the world's largest educational and scientific computing society, and Eli is the first Brown CS recipient of this accolade, which is given annually to recognize specific theoretical accomplishments that have had a significant and demonstrable effect on the practice of computing. It's accompanied by a prize of $10,000. In a 1994 paper , Eli and his colleagues introduced the balanced allocations framework, also known as the power of two choices paradigm, a theoretical work that has had widespread practical impact. It can be explained as follows: when n balls are thrown into n bins chosen uniformly at random, it's known with high probability that the maximum load on any bin is bounded by (lg n/lg lg n) (1+o(1)). The researchers proved that adding a little bit of choice makes a big difference. When throwing each ball, instead of choosing one bin at random, the thrower should choose two bins at random, then place the ball in the bin with the lesser load. This minor change brings an exponential improvement: now, with high probability, the maximal load in any bin is bounded by (lg lg n/lg 2)+O(1). In the same work, they show that if each ball has d choices, the maximum load drops with high probability to (ln ln n/ ln d)+O(1). Since bins and balls are the basic model for analyzing data structures such as hashing or processes like load balancing of jobs in servers, it's not surprising that the power of two choices, which requires only a local decision rather than global coordination, has led to a wide range of practical applications. Just a few examples include Google's web index, Akamai\u2019s overlay routing network, and highly reliable distributed data storage systems used by Microsoft and Dropbox, all based on variants of the power of two choices paradigm. \"The Balanced Allocations paper and the follow-up work on the power of two choices,\" the ACM writes, \"are elegant theoretical results, and their content had, and will surely continue to have, a demonstrable effect on the practice of computing.\" Paris Kanellakis was a distinguished computer scientist who was an esteemed and beloved member of the Brown CS community. His research area was theoretical computer science, with emphasis on the principles of database systems, logic in computer science, the principles of distributed computing, and combinatorial optimization. \"Winning this award is special for me,\" says Eli. \"I've always been proud to be Paris's successor at Brown, and being recognized as someone who has had a similar impact on computing practice is really an honor. Bringing an award named for Paris Kanellakis back to Brown feels like closing a circle.\" The full ACM press release is available here . For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://awards.cs.brown.edu/2020/04/13/nishanth-kumar-has-been-named-2020-barry-m-goldwater-scholar/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Nishanth Kumar Has Been Named A 2020 Barry M. Goldwater Scholar Posted by Rujul Singh on April 13, 2020 Click the links that follow for more news about Nishanth Kumar and other recent accomplishments by Brown CS students and researchers . Brown University undergraduate Nishanth Kumar, a Computer Engineering concentrator and Brown CS researcher, has recently received the Barry Goldwater Scholarship for his research into Learning from Demonstration (LfD). The scholarship was established by Congress in 1986 to identify and support the next generation of research leaders, and is widely regarded as one of the most prestigious undergraduate scholarships in the natural sciences, mathematics, and engineering in America. Nishanth joins fellow Brown students Adam Tropper (Physics and Astronomy concentrator) and Lucas Sanchez (Chemistry concentrator) this year as a scholarship recipient. Nishanth\u2019s research focuses on teaching robots to learn real-world skills directly from observing demonstrations. \u201cLfD allows non-expert operators to program skills simply by demonstrating them many times,\u201d he explains, \u201cand these learned skills are more general: they are able to handle slight variations of a task, such as if an object to be placed is slightly misplaced.\u201d The issue with current LfD techniques, however, is that they train skills that are unable to target specific goals from many possible choices (i.e. targeting a specific button within a grid) without copious amounts of training data. \u201cTo combat this issue, I helped propose a method that learns skills that are parameterized by a goal parameter,\u201d Nishanth says, \u201csuch that altering this parameter correctly alters the skill. In the button pressing scenario, instead of training a new skill for each button, we train one general skill that adapts itself depending on where the button is.\u201d Looking forward, Nishanth is ready to continue solving some of the most practical problems in Artificial Intelligence: \u201cAfter winning the scholarship, I\u2019ve felt a deep responsibility and motivation to continue my research into AI and robotics. I believe the advent of intelligent, collaborative robots can massively change the world for the better and I hope to play some part in making this dream a reality.\u201d For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse Polhemus.", "https://blog.cs.brown.edu/2013/07/29/experiences-line-course-offering/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Experiences from an Online Course Offering Posted by Shriram Krishnamurthi on July 29, 2013 In Fall2012, I offered my course CSCI 1730. This is a junior-, senior-, andbeginning-graduate-level course in programming languages (not in how toprogram, but rather in linguistic mechanisms). Together with my PhD student(and graduate TA) Joe Politz, I decided to offer it on-line in addition toin-class. My primarygoal was to understand this new teaching medium. As someone who runs veryinteractive classes and teaches solely by writing on a board, I had long beenconvinced that my teaching methods would simply never work with a remoteaudience. Having maintained this position for many years, I felt it importantto experiment and learn how to adapt: everyone of a certain age (or pop culturesensibility) recognizes the phrase, \u201cvideo killed the radio star.\u201d I did not do it for the reasons that thefounders of Coursera have proclaimed: that they had almost no studentengagement in their classes, they were tired of telling the same old jokes, andso on. One might conclude from their narrative that teaching and learning atStanford must be a terrible experience; though a more charitable (and much morelikely) reading is that they are exaggerating for corporate effect. Hype andexaggeration apart, I do believe higher education is at a potentially criticaljuncture. Against this backdrop, Brown is engaging in a large planning effort, investingsignificant energy and resources on campus space. We are fortunate to be havingthis discussion after the MOOC (Massive Open On-Line Course, the idea ofteaching courses through electronic media to large numbers of students\u2014aspersonified by courses on Coursera, Udacity, EdX, and other organizations)phenomenon has begun; it would be unfortunate if it did not significantlyaffect these conversations, especially due to the impact on the classroom(which I think is likely to be enormous). THE ONLINE COURSE, AND BROWN'S VALUE ADDITION It was always clear that we could not offer exactly the samecourse as we gave Brown students. One of the important parts of my course is aset of open-ended written assignments. I consider these extremely important inmeasuring student understanding of the material, but we almost certainly lackedthe resources to grade them for the on-line students. Nor were we willing, asmany MOOCs are, to \u201cgrade\u201d using simple computer-driven textual analysis; wewanted to read the responses in depth. Thus the courses differed, and we wereable to point to tangible differences\u2014beyond the evident intangibles\u2014betweenthe Brown and on-line offerings. CERTIFICATION LEVELS Because we were not offering Brown\u2019s course in full, we werefree to customize our course to different on-line clientele. Instead of grades(which would suggest having done the equivalent of the Brown course), we publicizedthree different \u201ccertification levels\u201d: Lite :Completing a sufficient number of daily quizzes (but no more) Mezzanine :Beyond Lite, completing the minor project that occupies the first month Ninja : BeyondMezzanine, completing the major project that occupies the remaining two months When we noticed that many of our initial sign-ups wereprofessional programmers, we added a fourth: Sprint : Theminor project, and quizzes during its duration The Sprint option enabled people to engage intensively forone month, and then disengage fully from the course and return to theirprofessional and other lives. The completion numbers indicate that this was a wiseaddition. BY THE NUMBERS We hadabout 1650+ signups initially. In keeping with all other MOOCs, attendancedropped off rapidly (especially after we made the opening assignment especiallyhard). Our completion ratio was about what one might expect for an upper-leveltechnical course: 80 students finished, distributed as follows: Lite : 23 Sprint : 23 Mezzanine : 32 Ninja : 2 The distribution of sign-ups looked like a heat-map ofcomputer science: large clusters in the US Northeast, the Pacific Northwest,and Northern and Southern California; a strong showing in the London area; andan especially strong cluster in India\u2019s technology hub (and my hometown),Bangalore (now known as Bengalooru). We were surprised by the relative lack ofsignups from China, Japan, and Korea, but attributed this to our publicitymethods and to potential language difficulties. The distribution of finishers was not at all the same. Wehad one each from Argentina, Australia, Tanzania (a Dutchman who has livedthere for a long time doing missionary work with his doctor wife), Thailand,China, Finland, Belarus, Hungary, Romania, Belgium, Spain, and Portugal. OnlyRussia, Germany, Canada, Japan, and India, other than the US, provided multiplefinishers; the Indians were distributed around the country, in no way matchingthe distribution of signups. The American finishers also did not correspond tothe signup distribution, with a very strong showing from the Midwest andNortheast, nobody from the US Pacific Northwest, and one each from Northern andSouthern California. In general, therefore, tech hubs seem to offer masses ofenthusiasts whose initial interest does not translate into completion. (To ourdelight, though, we had at least one person on each settled continent!) I also analyzed the finishers by self-described occupation.\u201cIT\u201d means anyone in the computing industry; \u201cstudent\u201d could mean anywhere fromhigh-school upwards, though I don\u2019t believe any of the high-schoolers whoenrolled got very far. Note that some people did not provide this information. Lite : IT: 6;students: 8; mathematician: 1 Sprint : IT:13; students (graduate-level): 2; finance: 1 Mezzanine : IT:14; students: 3; research scientist: 1; stay-at-home dad: 1; associateprofessor: 1 Ninja : IT: 2 IN TERMS OF PRIOR EDUCATIONAL EXPERIENCE: High school Bachelor's degree Post-bachelor degree Lite 4 5 3 Sprint 9 8 Mezzanine 8 9 7 Ninja 2 The ageswere distributed as follows; though we had several in the 13-18 age range signup, none of them survived the course: 19-25 26-34 35-50 Over 50 Lite 5 3 3 1 Sprint 3 8 5 1 Mezzanine 5 12 7 Ninja 1 1 Atsign-up, we also asked people what their likelihood was of finishing each ofthe certification levels. Suffice it to say these expectations greatly outstrippedreality (not least because roughly 1500 participants failed to complete anylevel). THE BOTTOM LINE I expectedmy in-class experience would remain largely unchanged, while I would learn mostfrom the on-line component. The exact reverse was true. The on-line componentwent along mostly predictable lines, with few surprises. In contrast, theprovision of videos had a dramatic and (in my mind) undesirable effect on thein-class experience: of sixty students, only about twenty attended class regularly. Many studentsattributed their lack of attendance to the \u201cearly\u201d hour of the class: 10am onMWF. As a card-carrying computer scientist, I\u2019m guilty of having had similarviews as an undergraduate. However, the same course has been offered at 10amfor years, and attendance was always close to perfect, and this year\u2019s classdidn\u2019t seem especially different in constitution. In short, there is the potential that the provision of videos will havea significant impact on class attendance, even in relatively interactive,discussion-oriented classes. PUBLICITY We madeour decision during the summer preceding the course, well before Brown\u2019sCoursera announcement. We therefore had to do all publicity ourselves. We madeannouncements on some mailing lists, and on our own social media pages. We didnot employ any other means of advertisement, such as purchasing Google ads. Itwas never our goal to bulk up with large numbers of students (we were franklysurprised when signups first crossed 100!), so other means of advertising madeno sense. FORMAT I normally put all my course material on-line, without anyfirewall (like the abominable Blackboard and its siblings). What changed isthat we created mechanisms for grading on-line student work (more on thislater), and also published videos of all the classes. Rather than createoff-line video snippets (as used in flipped classrooms), we simply recordedclass and published it in full. Some on-line students reported that theyenjoyed the sense this gave of actually being in the class. To avoid visibility problems, I changed from writing on theboard to writing on a tablet computer projected on a screen: nearly the samewriting experience for me, but with perfect visibility on video. (Indeed, thetablet offered some advantages a whiteboard does not, such as the ability tomove a block of text from one location to another.) To protect the privacy ofstudents, we recorded from the back of the room so their faces were not seen. After every class, we converted the videos and publishedthem on YouTube. On-line student discussion took place on Piazza, where Brownstudents were welcome (but most did not actively participate, at least not byname). PLATFORMS Instead ofsticking with one packaged platform, we used a variety of on-line media: GooglePlus, Google Documents, Google Groups, Batchgeo (to make maps), Dropbox (toshare videos), Piazza (for discussion), JotForm (for uploading solutions),Brown Computer Science facilities, and software we wrote. We chose to do thisso we could better understand from scratch what tools such an effort needs, andnot be hemmed in by one platform. Because I had a staff of world-class problemsolvers, I was confident we could fight our way out of any tight corners, andthis approach indeed worked well. STUDY GROUPS We felt itwas important to help people form local study groups, and many students wereinterested in this, too. Lacking a platform to do this for us, we created anopen Google Map that any participant could edit, so they could drop pins indicatingwhere they were and find one another. This worked well enough, and severalstudy groups sprang up around the world. ONLINE STUDENT BEHAVIOR Theon-line students generally behaved in exemplary fashion. Once we had weeded outthe \u201ctourists\u201d (my term for those who were never going to be serious studentsin the class), the remainder were often genuinely grateful for the classexperience, and were far less demanding than I expected. Indeed, I think theywere undemanding to the point of hurting their educational experience. I was especiallyafraid of being pestered with email messages of the \u201ci dont know how to installur software\u201d variety. These never materialized. The few people who contacted usby email had good reasons and kept it brief and on point. We would actuallyhave enjoyed more interaction with some of the on-line students. Thebeginning of the semester was problematic on Piazza. Because there was nothingmuch to do, the on-line students turned it into yet another Web discussion site(perhaps to shake out their anxieties), holding forth vapidly on the coursetopic and much else. I believe this turned off many Brown students, in responseto which we created a Brown-only announcement mailing list. Perhaps if we hadperformed better crowd control initially, Piazza would have remained the singleforum everyone used. Iencountered only one moment of angst: when a male on-line student made aninappropriate remark responding to a female on-line student. I caught thiswithin an hour of its appearance (during which time it had received fewer thantwenty views), deleted it immediately, and posted a chastising comment on thediscussion site. Happily, the female student stayed with the course until thevery end, and remained a strong contributor. Therewas just one sense in which on-line students were very demanding: in digitalformats. We initially expected we would simply upload our videos to YouTube.But some students complained they couldn\u2019t easily access YouTube, or wanted thevideo for off-line viewing (e.g., while commuting to and from work), so we hadto make a direct link also accessible. Some wanted low-resolution versions ofthe video due to weak Internet access. Some wanted access to the digitalversion of what I wrote on the \u201cboard\u201d. Some even wanted only audio access to thelectures. Keeping all these different needs satisfied was a significant andconstant burden. Surveys suggested each of these formats was useful to justenough students to be worth continuing to provide, and once we had begun tooffer one we couldn\u2019t take it away. Thetiming of our home works had an interesting and unintended consequence. BecauseI was redesigning the course from scratch, many of the projects were brand newand needed debugging. We put out assignments on Fridays. Most of the on-linestudents, being working professionals, did them immediately, and helped us findand fix most of the problems. Thus, by the time most Brown students got to theassignments, they encountered much better versions of them. STAFFING I did not have any additional resources to teach the on-lineoffering. My regular course staff consisted of my grad TA and six undergradTAs. I informed the undergrad TAs that, because this was a project being run bymy grad TA and me, they were under no obligation to participate. Though they largelydid not help with Piazza, the video recording and publication was handledalmost entirely by them. (These videos obviously benefited the undergrads also,but without them there would have been no on-line course at all, so in thatsense the UTAs were indispensable. To wit, I\u2019d like to thank Liam Elberty,Jonah Kagan, Peter Kaufman, Scott Newman, Jon Sailor, and Varun Singh.) COMPARISON TO COURSE GRADES Several people have asked me how these certification levelscorrespond to letter grades. They don\u2019t at all, because the Brown students hadto do additional work (the written home works). However, very loosely, doing areasonable job on the written home works, combined with completing the Sprintrequirements, earned a C; doing better on the written home works and completingthe Ninja requirements at a reasonable level earned a B; and doing well on boththe written home works and the Ninja requirements earned an A. In short, thegrade requirements for Brown students were much higher than for on-linestudents (which is why we created entirely different names rather than usingletter grades). Despite this, Brown students did much better than the on-linestudents: 40 A\u2019s, 7 B\u2019s, 8 C\u2019s, and 8 NC\u2019s (in a non-required course). GRADING Because we only graded the programming-related assignmentsfor on-line students, all their grading could be automated. Most on-lineprogramming courses have students upload programs that are run by gradingscripts. We decided that we didn\u2019t want the headache of dealing withpotentially malicious programs (it may help\u2014or hurt\u2014that Joe and I both docomputer security research), nor the expense of running these programs on acloud provider. We therefore instead handed out a binary program for eachassignment that would run the same checks on the students\u2019 own machine, andreport the results back to us. (As Joe pointed out, this puts the trustrelationship in the right direction: we have no reason to trust them, but ifthey don\u2019t trust us enough to run our program, why are they taking a coursefrom us?) Of course, when the students are reporting their answers tous, it\u2019s too easy for them to cheat. We therefore embedded a little ad hoccryptographic protocol\u2014Joe appositely labeled it \u201ccraptography\u201d\u2014in the gradingprograms to make this difficult. Our goal was not to create somethingimpregnable, but rather to prevent casual and, indeed, all but determined cheating.This process worked well in retrospect. WHO GAINED FROM THIS EXERCISE? I gained the most. I got to experiment with what is clearlyan upcoming challenge to our profession. I got the opportunity to reach out towhole new segments of the computing population. (We already have a new master\u2019sstudent applicant from this on-line audience, and I wouldn\u2019t be surprised ifsome of the participants end up becoming PhD applicants down the road.) Joe and the other course staff also learned a lot about theneeds and demands of on-line teaching platforms. One TA, in particular, has adeep interest in MOOCs, and has been considering job offers from companies suchas Coursera and Khan Academy. For these students it was a valuable real-worldsoftware requirements-gathering experience. The benefits for Brown students were probably fewer, butthat is also because we worked to insulate them from the on-line crowd. I dothink the students benefited some from interactions, especially withprofessionals. For instance, they got to see some important differences betweenhow they and professionals tackled some tasks, and at least some students foundthis thought-provoking. My wife pointed out one subtle benefit for Brown.Overthe years, I\u2019ve found it difficult to explain the chasm between our courses andthose almost everywhere else (in the world). Offerings like this give the worlda window into what we do, and let them judge just how demanding (and good) ourcourses are. This raises the profile of our students with potential employersand others who need to evaluate them. By not only being uncompromising in thequality of our courses but by also showing that there\u2019s more to a Brown coursethan what is offered on-line, we also signal to the best students worldwidethat we are a place where they might feel at home.", "https://blog.cs.brown.edu/2013/07/26/why-coursera/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Why Coursera Posted by Rosemary Simpson on July 26, 2013 What sets Coursera apart from myother experiences with distance learning (MIT's OCW, Stanford's video courses,Khan Academy [1] )?All previous venues shared the essential qualities of being free, providingrich video resources, being available on demand, and not being restricted byprerequisites or tied to a syllabus (although Khan does supply a context graphof recommended relationships). Coursera courses provide, in addition to all ofthis, a focus on interaction among all participants that pervades the structureand experience of the course. UserForums: These are the primary mechanism through which students interactwith each other, the community TAs, and the professor(s). They provide a chanceto ask questions and engage interactively with the answers. In addition, forumusers frequently volunteer their expertise by recommending resources andproviding insights that can be both surprising and very helpful. This is thekey difference between the Coursera student experience and the experience ofwatching videos in other, non-interactive online courses: MIT-OCW and Stanford Video lectures provide nointeraction, no community, while Khan Academy, with its very different focusand granularity, has some minor interactive responses to specific videos.Coursera's user forums are relevant to the entire course and comprise manythousands of highly engaged participants. In the beginning I was interested just in the videos andtended to ignore the forums, feeling I didn't want to waste my time with othersas ignorant as I. However, I found that I was very, very mistaken: the Courseraforums have become a resource that is unique in my experience and has providedboth guidance and enriching ongoing dialogue/debate I've never beforeexperienced. Some forum members have become friends with whom I continue to expandmy understanding. StudyGroups: These provide a second interaction mechanism, and may be online anddistributed or co-located. At the beginning of each course students arestrongly encouraged to form study groups based on whatever criteria they findcongenial. The study groups become in effect small cohesive communities whereideas are explored in a safe space and people get to know each other. Again,initially I scorned the study groups, thinking I preferred to work things outon my own, and again I was wrong. This time around, in Keith Devlin'sIntroduction to Mathematical Thinking, the study group I've formed with afriend who is also taking the course is turning out to be enormously helpful: heand I debate our differing reasons for assignment answers, egg each other on tosupport our positions, and uncover new resources, which we then post to theforum. PeerReview: This is a third form of interaction, one which \u2014 justifiably in myopinion \u2014is very controversial. My experience is that while doing a peer review is quite valuable inthe same way that attempting to teach is a very powerful way to learn, peerreview responses are not so useful. My opinion was unfortunately reinforcedearly on by a disastrous experience with idiotic peer reviews, or non-reviews,of an essay I'd spent a week researching and writing. However, engaging inrebuttal and the subsequent interactive dialogue is quite useful. ISSUES From my perspective as a student, themajor problems involve structural inadequacies in search, forums, andresources. Searches: The most critical defect in Coursera is the brain-dead search facility, whichis a simple string-only search over the titles and text of the forum. Youcannot search on the names of posters \u2014 e.g., you cannot find all posts by aparticular person \u2014 you cannot search the rest of the course site, and youcannot do simple Booleans such as \"find this but not that\", much lesstake advantage of regular expression patterns. Many subject-specific userforums use Google search, which while not perfect is much more useful than thecurrent Coursera search; Coursera should do the same. Searches should be faceted, e.g.,search on post author, date, ..., the scope should be the full course website, andthey should be able to be saved and then used for search refinements. The same automatic visualization tools thatshould illustrate the evolving forum graph structure (see below) could be usedto visualize the results of searches and sub-searches. Structure/relationshipvisualization is a key tool in gaining deep understanding. ForumsStructure: Issues and possible solutions include the following points. 1. It is currently impossible to trackall threads. Forum software needs to automatically assign author-editable tagsto entries, and from that develop an emergent substructure among the threads.Threads should be sortable by tag, creation and modification date, author, andtitle. 2. The current structure is like arigid class hierarchy and needs cross-cutting views; it should be a graphstructure to reflect the emerging multiple POV (point-of-view)s and LOD(level-of-detail)s. 3. The community TAs need a tool fortraversing the forums effectively and adding intermediate structure as needed,beyond the automatic evolution suggested in Point 1. 4. There should be a topics forumthat is independent of lecture and assignment and could have automatic linksinto relevant lectures and other forum threads. Obviously, the topics forumneeds to evolve deep structure as the course proceeds. 5. An evolving linked visualizationof the interacting threads graph would be extremely valuable. The NSDL ScienceLiteracy Maps (http://strandmaps.nsdl.org/) illustrate one possibility.StrandMaps would be a great addition to the courses. In sum, what is needed is acombination of full-faceted search plus an evolving forum structure withmultiple points of view. Resources :In general, the resources are a fairly traditional set of lectures andrecommended readings. The videos I've seen tend to be straightforward, high-qualitylectures; the exception to this pattern is a modern poetry course with videos ofhour-long close reading discussions by the professor and several graduatestudents sitting around a conference table. However, in the courses I've takenso far there is no metalevel visualization of context, no use of 2D or 3Dvisualization of the dynamics of the material, much less the forum threads, noset of relationship graphs among themes, no real integration or connectionswith the larger domain. In short, there is no reference to or exploration ofthe ecology of which the subject is part. It is as if hypertext had never beeninvented. Finally, while forums can be a rich source of recommendations forbooks, people, and websites, they too lack this awareness of any larger frameof reference. STRATEGIES Whypeople take the courses: Reasons for taking the courses, which are especiallydiverse with Coursera due to its heterogeneity and interactivity, include: testingthe waters, curiosity, need for community, opportunity to get questionsanswered, and gaining perspective, as well as a serious intent to complete allthe material.Further, as theCoursera courses have progressed, professors are realizing that their targetaudience is primarily adults, often adults with many other obligations. Thus,the current tendency is to close a course to new enrollments at the end of thecourse but to keep it accessible to those who did enroll at least until thenext time the course is given.Prof.Devlin, for example, has decided to keep the fall 2012 site of his mathematicalthinking course open. It would be nice if Coursera established a policy ofkeeping the course materials on a persistent basis, like the MIT OCW, Stanfordvideo, and Khan Academy materials. Working with the forumsto counteract rigidity: As mentioned above, the forum structures are rigid,like a rigid class structure, and badly need cross-cutting and refactoringcapabilities. In the absence of facilities for doing this, I've developedworkaround strategies that help compensate for and manage the sometimesoverwhelming chaos of thousands of unstructured threads. First of all, from the beginning of a course in which I intendto be seriously involved, I take advantage of the forums' latest posts list onthe forum home page. This lets me track new threads of interest, as well asinteresting people and community TAs (remember that it is not possible tosearch on names). I then subscribe to threads that seem promising and capturecontent I want to save and work with on my local system. In addition, in the General Discussion forum I've establishedthreads for topics, experts, and resources I think are important and keep thesethreads foregrounded by periodically posting to them and providing links torelated forum posts I've discovered during my daily prowls of the forum. Search: Unfortunately, there is little that can be donewith the brain-dead search facility. Afurther frustration is that when you subscribe to a thread and an email arriveswith a new post or comment, clicking on the link takes you not to the post butto the top of the thread, and because you can't search on the name of the poster,you are reduced to attempting to discover where the comment is coming from byeither scrolling down the thread or trying to enter a string from the commentinto the search engine. [1] Coursera is one of three major vendors of MOOC (Massive Open Online Course)courseware that have come to prominence in the last year. Since I have direct experience with justCoursera, I have only referenced it in this article. For a brief overview and comparison of threevendors - Coursera, EdX, and Udacity - see the article \"MOOC vendors: A Comparison Overview\"", "https://awards.cs.brown.edu/2021/12/20/brown-cs-alum-guillaume-marceau-and-professors-fisler-and-krishnamurthi-win-onward-2011-most-notable-paper-award/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Brown CS Alum Guillaume Marceau And Professors Fisler And Krishnamurthi Win The Onward! 2011 Most Notable Paper Award Posted by Eli Pullaro on Dec. 20, 2021 in Awards Click the links that follow for more news about Kathi Fisler , Guillaume Marceau , Shriram Krishnamurthi , and other recent accomplishments by our faculty and alums . Brown CS alum Guillaume Marceau, Professor Kathi Fisler , and Professor Shriram Krishnamurthi have just received the Onward! 2011 Most Notable Paper Award. This honor is given annually to the authors of a paper that was presented at the Onward! conference, an international event focusing on everything to do with programming and software. The papers are judged based on the influence they have had and their impact over the last ten years. The paper, \u201cMind Your Language: On Novices' Interactions with Error Messages,\u201d explored beginning students\u2019 reaction to error messages. Error messages can provide guidance to programmers while working and at the same time frustrate them because of the difficulty that comes with deciphering these messages. Using the programming language DrRacket, the paper studied how students respond to the vocabulary used in error messages. The paper found several problems with the understandability of messages, and presented recommendations to language developers and educators that have since had a significant impact on error message presentation. The paper was originally inspired by a \u201ctalk-aloud study\u201d and in particular, one student\u2019s remark on the confusing error messages they inevitably come across. Guillaume, Kathi, and Shriram\u2019s research on error messages offered valuable insights into \u201cone of the most critical user experience elements for programmers,\u201d according to their paper. To read the full paper, click here . For more information, click the link that follows to contact Brown CS Communication and Outreach Specialist Jesse C. Polhemus.", "https://blog.cs.brown.edu/2013/08/01/new-edition-computer-graphics-principles-and-practice/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) New Edition of Computer Graphics: Principles and Practice Posted by John Hughes on Aug. 1, 2013 Nearly a decade in the writing, the new edition of Computer Graphics: Principles and Practice has finally been published (the first copy is shown here sitting on my somewhat messy desk). The book is 1209 pages, which is slightly shorter than the second edition, but it's in a larger format, which more than compensates for the difference. Several topics (the extensive discussion of user interfaces, the long chapters on spline curves and surfaces) have been substantially trimmed down, since there are now whole fields (computer-human interaction, computer-aided design) in which these topics find their natural home. The discussion of rendering -- especially Monte Carlo methods -- has been enlarged a good deal. There's a big Brown CS representation in the book -- Andy van Dam and I here at Brown, my former Ph.D. student Morgan McGuire of Williams, former adjunct faculty member David Sklar of Vizify, Andy's former Ph.D. student Steve Feiner of Columbia -- along with Jim Foley of Georgia Tech and Kurt Akeley of Lytro. As the lead author on this edition, I'm (a) exhausted, and (b) very happy with the final product. The text is almost entirely new, although it's strongly influenced, of course, by the presentation and order of the earlier editions. What's Different? Hardware by a world expert The third edition contains a chapter on Modern Graphics Hardware by Kurt Akeley, the cofounder of Silicon Graphics, designer of the Reality Engine and GL/OpenGL, and now CTO of Lytro. Kurt uses a recent NVIDIA GPU as a model for analyzing the tradeoffs involved in designing a graphics processor, including the cost/benefit choices involved in parallelizing graphics tasks, and extensive discussion of memory, concentrating on locality of reference and its relationship to caching, and the consequences of the differing constants in the Moore's-Law-like improvements in memory, computation, and bandwidth. He also discusses the tradeoff between implementation simplicity and power provided to the user, and identifies a principle --- The art of architecture design includes identifying conflicts between the interests of implementors and users, and making the best tradeoffs --- early in the chapter, and then illustrates it with numerous examples. Principles galore That design tradeoff principle illustrates something about the book as well: as we designed and revised chapters, we found ourselves repeatedly explaining a single idea in multiple contexts, and began to extract principles that we've found ourselves using over the years. These principles range over many levels of detail. The \"average height principle\" says that the average height of a point on the upper hemisphere of the unit sphere is 1/2, for example. That seems pretty specific, but it's remarkable how often it comes up in discussing rendering topics. At the other extreme, the \"meaning principle\" --- which says that for every number that appears in a graphics program, you need to know the semantics, the meaning, of that number --- applies very widely. This principle might seem completely obvious to you -- of course you need to know what numbers mean! If you're thinking that, let me ask you this: suppose the top left pixel of your color image has colors (r, g, b) = (245, 13, 11). What does that \"245\" mean? If you think the pixel values are describing light as a physical phenomenon, what are the units? Writing a book in a new century The world\u2019s changed a lot since our last edition. Students are used to grabbing code from the internet. The language of choice has changed from Pascal and/or C to \u2026 well, to what? C++? Scheme? Java? C#? Haskell? OCaml? The great thing is that it doesn\u2019t really matter. If you want to learn about, say, ray-intersect-plane computations, you can probably find implementations in any of those languages. That meant two things for us as authors: \u2022 We don\u2019t actually have to include code for many algorithms. The student can grab code from the web in whatever language works best for him or her. \u2022 When we do write code, we can feel free to do it in almost any language. In the book, there\u2019s C, C++, C#, GLSL, pseudocode, and possibly some others I\u2019ve forgotten. The C-like languages are all similar enough that a student who knows one can generally read the others. Much of the early part of the book introduces 2D and basic 3D graphics via Windows Presentation Foundation (WPF), a graphics library accessible through an XML-like format and via C# code, but essentially the same ideas are usable via other libraries. These two mean that if the main ideas are explained simply and clearly enough \u2013 which is, after all, our strength \u2013 then the student can make the most of them. Structure The second edition started with 2D graphics in great detail, including extensive coverage of low-level topics like scan-conversion. Since the modern version of scan-conversion, rasterization, is now generally done in the GPU, it\u2019s no longer the central topic it once was. It\u2019s also usually based on spatial subdivision approaches, which are most naturally delayed until later in the book. In the new edition, we\u2019ve taken a different approach, briefly describing in the first chapter many of the main ideas of graphics, which are then treated in successively greater detail and mathematical sophistication in multiple later chapters. A clock modeled in WPF in Chapter 2 The Durer engraving used in Chapter 3 Pictures early! We start with WPF\u2019s 2D features, which gives students a chance to make pictures \u2013 indeed animated pictures \u2013 in the second chapter, and learn about hierarchical modeling as they build a model of a clock-face. This same 2D foundation is used, in Chapter 3, to produce output for a very basic raytracer based on the famous Durer etching shown above. Almost immediately the student then learns about WPF 3D, and its basic Blinn-Phong shading model, after which we describe a couple of test-bed programs in WPF that the student can use to perform exercises throughout the book. Onion peeling At the end of the introduction we lay out a few basic facts about light, a little mathematics, and something about representation of shape in graphics \u2013 just enough to let a student make a first renderer. As we work through the first several chapters, topics like clipping and transformations arise naturally, and efficiency considerations lead to discussion of how best to represent shapes with meshes. A few chapters further along, we revisit many of these ideas with greater sophistication. Morgan McGuire provides a wonderful mid-book chapter that summarizes the main current representations of light, of shape, and of light-transport, covering each in enough detail to let the student begin to see the big picture of how efficiency in one area may complicate another, etc. It\u2019s the most \u201ccomputer-sciency\u201d chapter the students have seen at this point. It goes into detail on fixed- and floating-point representations of numbers, memory structure in Z-buffers (and other buffers), precomputation and caching for geometric models, etc. The next chapter puts much of this information to use in building a slightly more sophisticated (but not recursive) raytracer, a rasterizing renderer, and a hardware-based renderer, and showing how the three produce identical results, thus emphasizing the critical difference between raytracing and rasterization in the reordering of two main loops, and the consequences this has on caching, memory access patterns, etc. In later chapters, we return to raytracing in its recursive form, together with more sophisticated scattering models for light-surface interaction, and develop a path-tracer and photon-mapping renderer. And in the final chapter, on graphics hardware, we return to hardware-based rendering. This repeated treatment of the same topic allows the student to develop sophistication before facing the full complexities of the topic in its greatest generality. It also lets a teacher select how deeply to address a topic by including some chapters in the syllabus and omitting others. The Fourier transform of a box is a sinc Extramaterial Another feature of writing a book in the internet age isthat we can provide lots more to our readers. We\u2019re working on releasing sourcecode for many of the illustrations in the book, many of which (like the oneillustrating that the Fourier transform of a box-filter is a sinc-function,shamelessly adapted from Bracewell\u2019s Fourier Analysis book) were generated byprograms in Matlab and other environments. We also provide example programs for download, and the basic ideas inWPF are explained using \u201cBrowser Apps\u201d (created by David Sklar) in which thestudent can edit, in a browser, WPF2D XAML code and get instant feedback on theresults without every installing any software on his/her computer at all. Andy hard at work signing books McGuire, Sklar, Hughes, Akeley, van Dam, Foley, Feiner at SIGGRAPH 2013 book-signing event. Launching the book The new edition was launched at SIGGRAPH 2013, with a launchparty followed by a book-signing on the show floor. Judging from the lines atthe signing, people seem eager to have the book, and our first review on Amazongave us five stars\u2026we\u2019re off to a good start!", "https://blog.cs.brown.edu/2013/08/05/pay-you-go-or-how-can-we-get-private-secure-and-efficient-payments-public-transportation/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) PAY-AS-YOU-GO or How can we get private, secure and efficient payments in public transportation Posted by Foteini Baldimtsi on Aug. 5, 2013 In a large metropolitan area such as NYC, the public transportation system is a vital part of the city's day-to-day operation. But transportation systems do not work for free: each of the millions of passengers they serve must pay for their rides. Let's take a look at their underlying payment systems. The simplest, and oldest, payment system is with actual cash, tokens, or tickets. One of its advantages is that the passengers do not leave behind an electronic trail of their comings and goings. However, it also has severe limitations: physical payments require cashiers or customized payment booths or turnstiles; it is hard to adapt the system to variable pricing or to collect statistics that lead to better services, As a result, pre-paid or monthly cards (those that need to be swiped, or sometimes contactless cards) such as MetroCards in NYC and Charlie Cards in Boston have replaced the physical tokens. Contactless devices have also made paying highway tolls easier: systems such as E-ZPass give drivers a device that automatically pays their tolls as they drive through the toll booth. These convenient systems raise concerns about the privacy of their customers. One\u2019s MetroCard or Charlie Card is a persistent identi\ufb01er, and the MTA in New York, or MBTA in Boston, has the ability to locate an individual in a large metropolis based on where they\u2019ve used their card. These devices do not necessarily offer security for the transportation authorities either \u2014 for example, the Charlie Card was shown vulnerable to forgery by three MIT students doing a class project. Thus, current practices are the worst of both worlds since there are no guarantees for either private or secure payments. One may argue that giving up one\u2019s privacy is a small price to pay for such important bene\ufb01ts as ease and convenience, not to mention the fact that the information collected can facilitate advanced traveler information dissemination, traf\ufb01c management, travel time estimation, emergency management, congestion pricing, carbon emissions control, and environmental justice assessments. But is it possible to get the best of both worlds? Can we get the ease and convenience of Metrocards as well as the benefits of data collection without sacrificing privacy? In theory, there exist cryptographic techniques that make this possible. Electronic cash schemes (e-cash) have all the privacy bene\ufb01ts of actual physical cash. But how can we implement them on constrained devices such as a MetroCard? How do we make them work with the same speed and convenience as non-privacy-preserving MetroCards? How do we preserve the ability to collect the same useful information about traf\ufb01c patterns, without sacrificing the privacy of individuals? Pay-As-You-Go (PAYG) is a multi-disciplinary research project funded by the NSF 1 that started in 2010 and seeks to answer these questions. The project includes a diverse team of computer scientists, cryptographers, electrical and computer engineers, and transportation systems researchers from Brown University and the University of Massachusetts. The goal of PAYG is to bridge the gap between theoretical constructions and practical implementations on RFID devices. Starting on the crypto side, we want to construct efficient and provable secure e-cash schemes. On the other end, we want to achieve highly ef\ufb01cient implementations of e-cash in RFID devices that would be appropriate for the transportation scenario. Working from both ends of the problem, the goal of PAYG is to obtain a solution that offers speed and convenience on the one hand, and cryptographic guarantees of security and privacy on the other. By incorporating additional cryptographic techniques, we can derive additional bene\ufb01ts, such as variable pricing and privacy-preserving data collection. The results of the PAYG project are very promising! On the crypto end we managed to construct a new e-cash scheme [1], to be presented at ACM-CCS 2013, that perfectly suits the purpose of payments in public transportation systems. It is very efficient, has a formal proof of security, and allows the encoding of a user\u2019s attributes (such as age, address, etc.) on the coins/tokens withdrawn which is essential for the transportation setting. Encoding users\u2019 attributes in the coins/tokens allows us to implement additional features in our system such as variable pricing (e.g. reduced fare for senior customers) and privacy-preserving data collection. Our new e-cash scheme is a very exciting development in the e-cash research: previous schemes were either not provably secure or too computationally expensive for scenarios where lightweight devices are used and efficiency is crucial. On the implementation end, the biggest challenge is the processing time constraints of transportation payment systems. To avoid congestion in front of turnstiles, a payment transaction should take approximately 300 ms which is a considerable challenge given the computational complexity of advanced payment protocols. The ef\ufb01ciency of loading money on one\u2019s payment device is less critical but should also not take longer than a few seconds. Another set of challenges are related to the payment device itself. First, it should be based on inexpensive hardware due to the potentially very high volume and the need to replace payment cards frequently. Second, it should be able to communicate and work contactlessly and without a battery. These two conditions are seemingly in con\ufb02ict with the need to run very complex cryptographic operations. The results of the PAYG project on the implementation side are also very encouraging. In a work that was recently presented at Privacy Enhancing Technology Symposium (PETS\u201913) we implemented our new e-cash scheme using an NFC enabled smartphone [2]. We managed to take advantage of certain elements of the smartphone\u2019s API in order to speed up our implementation. We implemented loading in 300 milliseconds (including terminal, communication and smartphone execution time) and payment in about 380 milliseconds (when two attributes are revealed; less if no attributes were revealed). In conclusion, our work on the PAYG project shows that private and cryptographically secure payments in public transportation systems are a practical possibility. We managed to use cryptographic techniques that were previously considered prohibitively inefficient for such an application. But, are transportation systems the only possible application area of our results? How can we extend our results to be used in other scenarios where private and efficient transactions are required? ----------------------------------- ^1: NSF grant numbers: 096464, 0964379. [1] \" Anonymous Credentials Light \", Foteini Baldimtsi, Anna Lysyanskaya, ACM Conference on Computer and Communications Security (ACM-CCS), 2013. [2] \" Efficient E-cash in Practice: NFC-based Payments for Intelligent Transportation Systems \", Gesine Hinterw\u00e4lder, Christian T. Zenger, Foteini Baldimtsi, Anna Lysyanskaya, Christof Paar and Wayne P. Burleson, Privacy Enhancing Technologies Symposium - PETS, 2013.", "https://awards.cs.brown.edu/2022/03/21/brown-cs-alum-david-abel-acm-sigai-dissertation-award-runner/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Brown CS Alum David Abel Is A Joint AAAI/ACM SIGAI Doctoral Dissertation Award Runner-Up Posted by Jesse Polhemus on March 21, 2022 in Awards Click the links that follow for more news about David Abel and other recent accomplishments by our alums . The Association for the Advancement for Artificial Intelligence (AAAI) is a nonprofit scientific society devoted to advancing the scientific understanding of the mechanisms underlying thought and intelligent behavior and their embodiment in machines, and ACM SIGAI is the Association for Computing Machinery's Special Interest Group on Artificial Intelligence. Working in concert, they present the Joint AAAI/ACM SIGAI Doctoral Dissertation Award annually to recognize and encourage superior research and writing by doctoral candidates in artificial intelligence, and Brown CS alum David Abel has just been announced as one of only two runners-up for the 2020 prize. Advised by Brown CS Professor Michael Littman , David's thesis (\" A Theory of Abstraction in Reinforcement Learning \") explores the use of abstraction to reduce the complexity of effective reinforcement learning. \"Reinforcement learning,\" he explains, \"defines the problem facing agents that learn to make good decisions through action and observation alone. To be effective problem solvers, such agents must efficiently explore vast worlds, assign credit from delayed feedback, and generalize to new experiences, all while making use of limited data, computational resources, and perceptual bandwidth. Abstraction is essential to all of these endeavors. Through abstraction, agents can form concise models of their environment that support the many practices required of a rational, adaptive decision maker.\" In his dissertation, David starts with three desiderata for functions that carry out the process of abstraction: they should preserve representation of near-optimal behavior, be learned and constructed efficiently, and lower planning or learning time. Abel then presents a suite of new algorithms and analysis that clarify how agents can learn to abstract according to these desiderata. Collectively, he says, these results provide a partial path toward the discovery and use of abstraction that minimizes the complexity of effective reinforcement learning. For more information, click the link that follows to contact Brown CS Communication and Outreach Specialist Jesse C. Polhemus .", "https://awards.cs.brown.edu/2024/01/19/brown-cs-student-mattie-ji-runner-schafer-prize-excellence-mathematics-undergraduate-woman/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Brown CS Student Mattie Ji Is A Runner-Up For The Schafer Prize For Excellence In Mathematics By An Undergraduate Woman Posted by Jesse Polhemus on Jan. 19, 2024 in Awards , Diversity Click the link that follows for more news about other recent accomplishments by our students . Founded in 1971, the Association for Women in Mathematics (AWM) aims to create a community in which women and girls can thrive in their mathematical endeavors, and to promote equitable opportunity and treatment of women and others of marginalized genders and gender identities across the mathematical sciences. Almost twenty-five years ago, they established the Alice T. Schafer Mathematics Prize , named for one of their founding members, to be awarded to an undergraduate woman for excellence in mathematics. This year, Brown CS student Mattie Ji , a senior majoring in Mathematics, Applied Mathematics, and Computer Science, was the prize's runner-up. Mattie describes her interests as wide, and her knowledge of algebraic geometry and topology has allowed her participation in several Research Experience for Undergraduates programs where she contributed to projects that included an investigation into the relationship between the concepts of Euler characteristic transform (ECT) and smooth ECT, fake projective planes, and the study of a class of conic bundle threefolds. She has a keen interest in coding complex problems and has a repository set up on GitHub displaying her work . \"[Mattie] is consistently described,\" the AWM writes, \"as an outstanding student with the initiative to develop her knowledge and understanding and has an infectious passion for mathematics, with a remarkable record of co-authored papers and conference presentations.\" \"While this is an award in mathematics,\" Mattie says, \"I would not have gotten this award without the education and experience I have had within the Department of Computer Science. Many of my research projects that helped me garner this award involved various aspects of computational and data science, and I believe that my background and education in Computer Science were very critical for this award.\" A full list of this year's winners is available here . For more information, click the link that follows to contact Brown CS Communications Manager Jesse C. Polhemus .", "https://awards.cs.brown.edu/2024/01/29/john-hughes-ranks-in-the-top-021-of-stack-exchanges-math-users/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) John Hughes Ranks In The Top 0.21% Of Stack Exchange\u2019s Math Users Posted by Robayet Hossain on Jan. 29, 2024 in Awards Click the links that follow for more news about John Hughes and other recent accomplishments by our faculty . Stack Exchange is a network of question-and-answer websites on subjects in diverse fields, with each site covering a specific topic where users\u2019 questions and answers are input into an online reputation award process. Stack Exchange website areas include knitting, electronics, and especially programming, and users are able to upvote questions and answers that feel relevant and right for them. Brown CS faculty member John Hughes was recently ranked in the top 0.21% of Stack Exchange users in the Mathematics stack exchange for his reputation in answering questions posted online. \u201cWhen someone upvotes the answer, you get 10 magical internet points that are of no value to anyone at all, except you get a little reputation, and when someone accepts your answer, you get 15 points,\u201d John states. \u201cThose of us who like explaining things and showing off how much we know often answer a couple questions on this website now and then.\u201d Hughes explains that he would answer a few questions every morning as a way of practicing exposition and developing the skill of reading a question well enough to fully understand the users\u2019 requests. He first became involved in the Stack Exchange network more than 10 years ago when he used the Computing stack exchange to ask questions regarding Windows for help in writing a graphics book, as well as the Electronics network to ask questions regarding characteristics of certain transistors. \u201cThe Math stack exchange appealed to me because I used to be a mathematician, and I still love doing it, and because there was a sweet spot between the number of questions and the number of answers,\u201d John says. \u201cIf you go and find information about your Android phone on the Android stack exchange, there are 8 billion questions and most of them never get an answer, so the math site is much better about that.\u201d \u201cThe thing I enjoy most is divided into two things: one is helping out someone where I think my help is actually useful to them. That\u2019s very satisfying, knowing that someone is in need, and at the cost of asking them a few leading questions about the problem, I am able to get them on their way, and that is part of the reason why I like teaching,\u201d John says. \u201cThe other thing I really enjoy is this business of learning to read questions carefully, learning to figure out what someone is asking and where they are confused.\u201d When asked about his favorite experiences with answering a question, Hughes referenced a few fond memories. There was one case where a Stack Exchange question thread resulted in him writing a joint paper about combinatorics with the user that eventually was posted to arXiv and became useful for future users. \u201cThere are some things that aren\u2019t worth doing financially; the free market isn\u2019t going to make them happen. But if those are things that I like doing, I\u2019ve gotta make them happen,\u201d John says. \u201cIf you like going to parties, you\u2019d better throw one now and then, and so part of public service for me is self-interest. I like talking about math with people, so I should contribute some time to that.\u201d Hughes believes it is valuable for faculty members to have interesting sidelights such as he\u2019s had throughout the last decade, telling a story of Brown\u2019s old lecture series called Twisted Paths, where faculty in STEM gave talks about the diverse path they took to be doing what they are doing currently. \u201cI think about my former colleague Tom Dean, who was hand-carving parts for furniture\u201d, John says, adding that Dean became interested in selling refurbished metalworking machinery and started wondering about automatically controlling machines for this task, but did not have the necessary knowledge or money to delve into the work with these electronic parts. \u201cThat\u2019s when his wife Jo discovered that the local community college had affordable classes that would give him the education he needed and from there, his career as a scientist got launched,\u201d John says. \u201cHe ended up working on some really fascinating projects at Google, working towards mapping parts of real brains to understand how they worked. So that\u2019s a pretty twisted path: a guy who was carving table-legs ends up being a top AI researcher.\u201d John states that the most interesting scientists he has known have followed a very twisted path and that their former interests informed how they think about what they\u2019re doing now. \u201cThere\u2019s plenty of fuel out there in the world; there just aren\u2019t enough sparks,\u201d John says. \u201cSo I think of public service as one of the ways of being a spark, and that\u2019s why I do it.\u201d For more information, click the link that follows to contact Brown CS Communications Manager Jesse C. Polhemus .", "https://awards.cs.brown.edu/2024/02/07/four-brown-cs-students-receive-cra-outstanding-undergraduate-researcher-honors/": "Awards Categories Awards ( 194 articles ) Diversity ( 11 articles ) Socially Responsible Computing ( 4 articles ) Four Brown CS Students Receive CRA Outstanding Undergraduate Researcher Honors Posted by Jesse Polhemus on Feb. 7, 2024 in Awards Click the links that follow for more news about previous recipients of honors for this award and other recent accomplishments by our students . The Computing Research Association (CRA) is a coalition of more than 200 organizations with the mission of enhancing innovation by joining with industry, government, and academia to strengthen research and advance education in computing. Every year, they recognize North American students who show phenomenal research potential with their Outstanding Undergraduate Researcher Award, and for 2023-2024, four Brown CS students received honors: Megan Frisella (Finalist) and Anh Truong, Qiuhong Anna Wei, and Carolyn Zech (Honorable Mention). Megan Frisella \u201cMy main research project,\u201d Megan says, \u201cis about soft memory, a new form of flexible memory that helps increase server utilization in datacenters. The work is done in the ETOS group under the advising of [Assistant Professor] Malte Schwarzkopf . Traditional memory is inflexible: once memory is allocated to an application, it cannot be reallocated until the application terminates or explicitly frees it. This incentivizes datacenter operators to evict low-priority jobs and run at low memory utilization. Soft memory is a software level abstraction on top of DRAM that makes memory revocable under memory pressure, for reallocation elsewhere. Our system avoids out-of-memory terminations because soft memory can always be reclaimed from an application to fulfill a request elsewhere. We published a paper on Soft Memory at HotOS 2023 . In addition to systems research, I am also interested in programming languages. Last summer, I joined the RiSE group at Microsoft Research where I worked on a domain-specific language in F*, called Pulse, for proof-oriented imperative programming. While most proof-oriented languages are functional, Pulse enables developers to write programs with proofs in a Rust-like syntax. Pulse extends F* with proof automation, custom proof syntax, and imperative programming paradigms like loops. We have a Pulse tutorial in POPL 2024 TutorialFest .\u201d Anh Truong \u201cMy research,\u201d Anh tells us, \u201clies at the intersection of computer graphics and machine learning. I've been working on a project with [Eliot Horowitz Assistant Professor of Computer Science] Daniel Ritchie that aims to achieve few-shot synthesis of 3D shapes: our goal is to help novice users easily generate novel 3D models which borrow geometric features from a small set of example models they may have readily available. Such a system could allow designers to easily populate virtual worlds with varied geometry or iterate by generating many candidate models from which the most desirable can be expanded upon. A highlight of the project for me has been exploring the interface between geometry processing and machine learning and seeing how creatively ideas from these two (seemingly unrelated) fields have mingled. I am immensely grateful to have been able to work with Daniel and my wonderful labmates, and I look forward to exploring much more of computer graphics.\u201d Qiuhong Anna Wei Anna\u2019s research, she explains, centers around building visual reasoning methods and making technology more trustworthy. \u201cI\u2019ve been working,\u201d she says, \u201cwith [Assistant Professor] Srinath Sridhar at Brown IVL and Professor Leonidas Guibas from Stanford University on 3D vision and learning, specifically canonicalization of collections of objects, in the setting of indoor furniture rearrangement when given relatively extensive or limited information. I\u2019ve also worked with Daniel Ritchie recently in exploring the differences and similarities in human and machine understanding of layouts and \u2018regularity\u2019, as part of a larger project on open-universe scene generation with LLM program synthesis. On the other front, I have been working with [Assistant Professor] Peihan Miao and [James A. and Julie N. Brown Professor of Computer Science] Anna Lysyanskaya on private computing on set intersection in cryptography. We\u2019re especially interested in how the key component, oblivious shuffle realized via switching networks, may be optimized to achieve better efficiency or adapted to different frameworks or security settings.\u201d Carolyn Zech \u201cParalegal,\u201d Carolyn explains, \u201cis a static analyzer that verifies Rust applications for compliance with user-specified policies. If an application fails to abide by a policy, Paralegal identifies the problematic code segment(s). Developers leverage Paralegal to prevent vulnerabilities from reaching production. Currently, developers write their Paralegal policies as graph queries, which makes policy-writing laborious and error-prone. My research focuses on developing a natural language interface for Paralegal, so that developers can specify high-level, intuitive policies (for example, \u2018all users are authorized before accessing application data\u2019) and receive quick notification of whether their code is compliant.\u201d Anh, Anna, Carolyn, and Megan join numerous prior Brown CS recipients of Outstanding Undergraduate Researcher Award honors. Most recently, they include Rachel Ma (Honorable Mention, 2022) , Jiaju Ma (Finalist, 2021), Wasu Piriyakulkij (Honorable Mention, 2021), Nitya Thakkar (Honorable Mention, 2021) , Sarah Bawabe (Honorable Mention, 2020), Nishanth Kumar (Finalist, 2020), Dylan Sam (Honorable Mention, 2020), and Homer Walke (Honorable Mention, 2020) . The full list of Outstanding Undergraduate Researcher Award recipients and honorees is available here . For more information, click the link that follows to contact Brown CS Communications Manager Jesse C. Polhemus .", "https://blog.cs.brown.edu/2014/04/16/sorin-istrail-receives-nsf-grant/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Sorin Istrail Receives NSF Grant For Haplotype Reconstruction Algorithms Posted by Sorin Istrail on April 16, 2014 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . Sorin Istrail has received funding for the NSF grant \u201cGenome-Wide Algorithms for Haplotype Reconstruction and Beyond: A Combined Haplotype Assembly and Identical-by-Descent Tracts Approach\u201d. Human genomes are diploids, which means that each human has two haplotypes, one inherited from the mother and one inherited by the father; each haplotype is a set (chromosomes) of sequences of about 3.2 billions of A, C, G, and T. These haplotypes are mosaics of haplotype regions inherited from ancestors as a result of two major forces of evolution: recombination and mutation. When two or more individuals inherit the same haplotype region from a common ancestor, the shared region is called a \u201ctract\u201d and it is said to be inherited \u201cidentical-by-descent\u201d (IBD). Tracts have the same start and end coordinates on genomes sharing them. The \u201clogic\u201d of detection of disease associations is rooted in the inference of tracts. For example, if a set of autistic patients is found to share a tract, and a certain gene is found part of this tract, this gene becomes a candidate gene for an ancestral model of autism inheritance. Preliminary work together with his PhD student Derek Aguiar succeeded in solving a major open problem of the influential Li-Stephens statistical framework (2003) for modeling linkage disequilibrium, recombination hotspots and haplotype phasing; this framework enabled some of the most practical genome-wide association study (GWAS) software tools to date. A major bottleneck was the failure of \u201cexchangeability\u201d of the statistical process (the output of the algorithm depended on the order in which the input was processed). The combinatorial solution that achieved exchangeability led to the first exact sub-quadratic (close to linear) and practical algorithm, Tractatus, for detecting the complete multi-shared identical-by-descent tracts in a GWAS sample of individuals (current GWAS input size is a matrix with several billions entries). The name of the algorithm was inspired by Ludwig Wittgenstein \u2019s Tractatus Logico-Philosophicus. The grant proposes a comprehensive algorithmic framework for haplotype reconstruction using haplotype assembly (the HapCompass framework), haplotype phasing and generalizations of Tractatus to address the problem of haplotype reconstruction in polyploidy organisms and medical aneuploidy.", "https://blog.cs.brown.edu/2014/05/02/students-bootstrap-algebra-video-games/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Students \"Bootstrap\" Algebra From Video Games Posted by Jesse Polhemus on May 2, 2014 in Diversity by Kevin Stacey (Science News Officer, Physical Sciences) Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . Middle school teacher Adam Newall calls it \u201cthe eternal question\u201d of introductory algebra. As students tread water in a sea of variables, functions, and graphs, they\u2019re bound to ask it: \u201cWhen are we ever going to use any of this?\u201d But Newall, who teaches at Pembroke Community Middle School in Pembroke, Mass., is hearing that question a lot less often lately. He\u2019s using a new curriculum in his seventh and eighth grade math classes that answers it right off the bat \u2014 and in a way that kids find hard to resist. The curriculum, called Bootstrap, teaches students to program their own video games \u2014 a task that just happens to require understanding and applying fundamental concepts of algebra. Newall says the approach does wonders, engaging students in a subject from which they might otherwise shy away. \u201cThe idea of making a video game is the allure,\u201d he said. \u201cBut it opens [students] to the idea that they can learn math, and it\u2019s not something that\u2019s meant to torture people. They learn that math is something that is real and relevant and that they can use it.\u201d Bootstrap is a group effort of Emmanuel Schanzer, a former computer programmer turned math teacher and now a Ph.D. student in the Harvard Graduate School of Education; Kathi Fisler, professor of computer science at Worcester Polytechnic Institute; and Shriram Krishnamurthi, professor of computer science at Brown. It builds on two decades of work done at Northeastern, Brown, and other universities. Middle school kids \u201dgo from saying, \u2018Math is hard,\u2019 to saying, \u2018I can\u2019t do math.\u2019 ... We\u2019d like to get to them before they make that decision.\u201d The curriculum started as a 10-week after-school program, which has been taught successfully around the country for six years. Now, based on the success of the after-school experience, Bootstrap is transitioning into an in-school program. The Bootstrap organization has set up training seminars for teachers around the country, and a few schools \u2014 like Newall\u2019s Pembroke Community Middle School \u2014 are already using the curriculum. Two new partnerships promise to bring Bootstrap to many more schools. Code.org , a national nonprofit that aims to expand computer science instruction in public schools, recently named Bootstrap as its official middle school math curriculum. CSNYC, a New York City-based group with similar goals, has adopted Bootstrap as well. This summer, as Code.org rolls out its national curriculum, the Bootstrap team will give additional training seminars to teachers all over the country interested in trying Bootstrap. More than just fun and games While the educators are mostly interested in the underlying math concepts, for the students, it\u2019s the games they create that are the stars of the show. \u201cThe whole curriculum is a sequence of steps that get you to the point where you have a working game at the end,\u201d Krishnamurthi said. \u201cOnce we tell them they\u2019re going to make their own game, the motivation is done. We don\u2019t have to say any more.\u201d Conceptually the games are fairly simple (though surprisingly addictive). Students choose a main character, a goal for that character to reach, and a danger to avoid. Then the students learn a simple programming language to put it all in motion. And that\u2019s where algebra comes in. For example, in order for the program to know if a character has reached her goal or been stymied by an obstacle, the relative positions of objects must be plotted on a Cartesian grid. \u201cTo do that, we\u2019re going to need to know the Pythagorean theorem,\u201d Newall said. \u201cTo understand the Pythagorean theorem we need to know square roots and squares. And [the students] will follow a lesson on how those things work in order to make it work in their game. They\u2019re so eager to own that.\u201d When all is said and done, each student has a game to show off to friends and a working understanding of variables, functions, and other fundamental algebra concepts that align with Common Core math standards. Right skills, right time One of the reasons Krishnamurthi is so eager to get the curriculum into more middle school classes is that it catches kids at a crucial time. \u201cResearch has found that kids change the way they talk about math right around this age,\u201d he said. \u201cThey go from saying, \u2018math is hard,\u2019 to saying, \u2018I can\u2019t do math.\u2019 And that\u2019s the point where kids make the decision to drop out of algebra. When they do, they\u2019ve actually made a career decision without even knowing it, because there\u2019s nothing you can do in a STEM field without algebra. We\u2019d like to get to them before they make that decision to drop out, so they at least have they can keep their options open.\u201d But algebra isn\u2019t the only thing students learn through Bootstrap. They also become familiar with ins and outs of coding, a crucial skill in an increasingly digital world. When students present their games to their classmates, they\u2019re also expected to stand up and explain the code that makes it work \u2014 an exercise software engineers call a code review. \u201cI do code reviews with my college students,\u201d Krishnamurthi said. \u201cThey are one of the most challenging experiences a college student can have. It\u2019s a hard-core professional skill. We teach it to middle schoolers as a natural part of our curricular design.\u201d The first time Newall taught the class, those code reviews were given at a launch party at semester\u2019s end. \u201cThe superintendent came; parents came. Just the amount of celebration from kids making a one-screen, side scrolling video game was more than I had ever anticipated,\u201d Newall said. And as for that eternal math class question, Newall says his Bootstrap students are now asking a new question. \u201cThey go from, \u2018What are we going to use this for?\u2019 to \u2018What are we going to use this for next?\u2019\u201d", "https://blog.cs.brown.edu/2014/01/09/hackbrown/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Hack@Brown Posted by Lauren Clarke on Jan. 9, 2014 Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . A group of Brown CS and RISD students are hosting Hack@Brown, the first annual Brown University hackathon J anuary 24-25 in Alumnae Hall! 250 students from Brown/RISD and other schools in the northeast plus engineers from Dropbox, Google, Venmo (and more) will form teams and build a project in 24 hours. Teams will demo their projects for judges and win prizes. Students of all skill levels, interests, and backgrounds are all extremely welcome and encouraged to participate! For more information and to register, visit the Hack@Brown website . Be sure to like us on Facebook and follow us on Twitter to get the latest information!", "https://blog.cs.brown.edu/2014/03/06/browncs-students-win-best-teamwork-award/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) BrownCS Students Win Best Teamwork Award Posted by John Savage on March 6, 2014 Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . On Friday and Saturday, February 7 and 8, the Atlantic Council hosted their second annual Cyber 9/12 Student Competition in Washington DC. It is an event designed to give students a taste of the challenges that face White House policy makers when responding to national cybersecurity threats. Twenty-two teams participated in the event representing twenty-four universities from as far away as Turkey and Estonia. A team of four Brown sophomores made an excellent showing. They not only advanced to the semifinal stage, they won the prize for Best Teamwork against much older teams. The \u201cBrown Secure\u201d team consisted of Samuel Brebner, Jason Ginsberg, Dan Meyers, and Jared Schober. I was faculty coach. Brown Secure was the youngest team to advance to the semifinal round and probably the youngest team in the competition. The competition consisted of three rounds in which students formulated four alternative responses to a crisis described in an intelligence brief. In each case teams had ten minutes to describe their responses and took ten minutes of questions. Preparation time for the first round lasted one week, the second twelve hours overnight, and the third thirty minutes. The Brown students benefited greatly from the trip, met prominent national security experts, and established a strong reputation for Brown at this event.", "https://blog.cs.brown.edu/2014/03/17/middle-schoolers-get-tour-robotics-lab-brown-250-celebrations/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Middle Schoolers get tour of Robotics Lab for Brown 250+ Celebrations Posted by John Raiti on March 17, 2014 in Diversity Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . The robotics open house was hosted by the Brown Robotics Lab on first floor of the CIT Building. Visitors were greeted in the lobby by Morgan Jenkins using a telepresence robot. Through the telepresence robot, Morgan answered questions about the robotics lab and accompanied visitors to one of two rooms: 1) CIT 121 where Dr. John Raiti demonstrated flight of quad rotor helicopters through web technologies developed at Brown. This project is enabling quadriplegics around the world to fly helicopters around campus. Recent talks by Prof. Chad Jenkins for TED and National Geographic has more information about this project. 2) CIT 134 where Prof. Jenkins demonstrated the PR2 robot recognizing and grasping household objects in an experimental domestic environment. This work is aimed to assist senior citizens and the physically disabled in their activities of daily living (e.g., cleaning, food preparation and consumption). We eventually want to enable more people to live independently at home without requiring institutionalization in assisted living facilities. The Providence Journal has some good pictures of these demonstrations: http://www.providencejournal.com/breaking-news/content/20140307-r.i.-middle-school-students-get-peek-into-the-brown-experience.ece Our continued goal is to advance robotic technology to meet the needs of society towards improving productivity and quality of life across the socioeconomic spectrum. This goal requires perspectives and interdisciplinary collaborations from across the academy, as well as engagement with the community and larger society. Participating in the 250th provided an excellent opportunity to raise awareness about the promise of robotics, engage broader perspectives, and help Brown celebrate an incredible moment in its history.", "https://blog.cs.brown.edu/2013/09/18/artemis-2013/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Artemis 2013 Posted by Angel Murakami on Sept. 18, 2013 in Diversity by Karishma Bhatia and April Tran Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . On the surface, Artemis is a summer program geared towards teaching young girls computer skills, programming, and computer science concepts through a challenging curriculum. Yet to the individuals that actually go through the Artemis experience, we learn that Artemis is much, much more. Yes, the program is about learning the science behind the modern machines we use everyday, but perhaps just as important, it helps the amazing young ladies that attend Artemis to build confidence in themselves, in their ability to build relationships with others, and their capacity to self learn. Though we can only possibly glimpse a portion of what the Artemis experience is like for its students, as directors we have learned life lessons and gleaned inspiration from our young students. As college undergraduates, in the midst of juggling multiple exams, papers, and projects, we often forget what it means to learn. Gone are the days in which making a small mistake for the sake of learning doesn't cost you a letter grade. Many of us no longer have the privilege or courage to test a teacher's or parent's patience with question upon question. We may never again have the opportunity or time to take complete advantage of our curiosity by letting our minds wander for hours or even days. Looking back, we realize just how valuable and precious such experiences were in our growth as students, innovators, and individuals. More broadly, we realize how important it is for our society---especially in academic institutions---to create such learning environments for youth in the community while continuing to encourage them to pursue their interests. Artemis started as a program for inner-city girls entering ninth grade to learn computer science. This year, we focused on making Artemis a program that helped students not only discover computer science, but discover a creative way to use the concepts they learned in their own hobbies and interests. Sometimes that meant a student realizing she had a knack for web-design and building a website featuring the work of her favorite artist--other times it meant a student realizing she was a poet and building a website featuring her own work. Artemis helped these girls build confidence in their own skills and talents while adding to them. How can we put into words the beauty of Iris' glowing smile when her friends praised the personal works she put on her website? The sense of accomplishment Jamie had watching the game she built in Scratch run perfectly? Or the surge of confidence Desiree felt presenting her final project to a crowd of parents? How can we describe the satisfaction of seeing the understanding on our girls' faces after we explained a difficult concept? By creating a positive association to computer science for our Artemis students, we ensure that they will not shy away from using technology to build creative solutions to relevant problems. They will not forgo their passions, they will not forget that they are capable of finding friends in the most unlikely people, and most importantly, they will not fear the challenge of learning something new.", "https://blog.cs.brown.edu/2014/06/09/cs-student-work-habits-revealed-possibly-dangerously-normal/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) CS Student Work/Sleep Habits Revealed As Possibly Dangerously Normal Posted by Jesse Polhemus on June 9, 2014 Imaginea first-year computer science concentrator (let\u2019s call him Luis) e-mailingfriends and family back home after a few weeks with Brown Computer Science (BrownCS). Everything heexpected to be challenging is even tougher than anticipated: generative recursion,writing specifications instead of implementations, learning how to test his codeinstead of just writing it. Worst of all is the workload. On any given night, he\u2019saveraging \u2013this seems too cruel to be possible\u2013 no more than eight or ninehours of sleep. Wait,what? Everyone knows that CS students don't get any sleep, so eight ornine hours is out of the question. Or is it? Recent findings from PhD student Joseph Gibbs Politz , adjunct professor Kathi Fisler , and professor Shriram Krishnamurthi analyze whenstudents completed tasks in two different BrownCS classes, shedding interestinglight on an age-old question: when do our students work, and when (if ever) dothey sleep? The question calls to mind a popular conception of the computerscientist that Luis has likely seen in countless movies and books: Hours are late. (A recent poster to boardgames@lists.cs.brown.edu requests a 2 PM start time in order to avoid being \u201cridiculouslyearly\u201d for prospective players.) Sleep is minimal. BrownCS alumnus AndyHertzfeld, writing about the early days of Apple Computer in Revolution inthe Valley, describes the \u201cgigantic bag of chocolate-covered espressobeans\u201d and \u201cmedicinal quantities of caffeinated beverages\u201d that allowed days ofuninterrupted coding. Part 1: Deadline Experiments Thestory begins a few years before Luis\u2019s arrival, when Shriram would routinely schedulehis assignments to be due at the 11:00 AM start of class. \u201cStudents lookedexhausted,\u201d he remembers. \u201cThey were clearly staying up all night in order tocomplete the assignment just prior to class.\u201d Initially,he moved the deadline to 2:00 AM, figuring that night owl students would finishwork in the early hours of the morning and then get some sleep. This waseffective, but someone pointed out that it was unfair to other professors whotaught earlier classes and were forced to deal with tired students who hadfinished Shriram\u2019s assignment but not slept sufficiently. \u201cMyfinal step,\u201d he explains, \u201cwas to change deadlines to midnight. I also beganpenalizing late assignments on a 24-hour basis instead of an hourly one. Thisencourages students to get a full night\u2019s sleep even if they miss a deadline.\u201d Thiswas the situation when Luis arrives. The next task was to start measuring theresults. Part2: Tracking Events Shriram,Kathi, and Joe analyzed two of Shriram\u2019s classes, CS 019 and CS 1730. For eachclass, Luis must submit test suites at any time he chooses, then read reviewsof his work from fellow students. He then continues working on the solution,eventually producing a final implementation that must be submitted prior to themidnight deadline. Part3: Reality And Mythology Giventhese parameters, what work and sleep patterns would you expect? We asked professorTom Doeppner to reflect on Luis and share his experience of working closelywith students as Director of Undergraduate Studies and Director of the Master\u2019sProgram. \u201cDo students work late? I know I get e-mail from students at all hoursof the night,\u201d he says, \u201cand I found out quickly that morning classes areunpopular, which is why I teach in the afternoon. Maybe it\u2019s associated withage? I liked to work late when I was young, but I got out of the habit in mythirties.\u201d Askedabout the possible mythologizing of late nights and sleeplessness, Tom tells astory from his own teaching: \u201cBefore we broke up CS 169 into two classes, thestudents had t-shirts made: \u2018CS 169: Because There Are Only 168 Hours In AWeek\u2019. I think there\u2019s definitely a widespread belief that you\u2019re not really workinghard unless you\u2019re pulling multiple all-nighters.\u201d Thisdoesn\u2019t exactly sound like Luis\u2019s sleep habits! Take a look at the graphs belowto see how mythology and reality compare. Part4: Results And Conclusions Thegraphs below depict test suite submissions, with time displayed in six-hoursegments. For example, between 6 PM and the midnight deadline (\u201c6-M\u201d), 50 CS173 students are submitting tests. Thisgraph is hypothetical, showing Joe, Kathi, and Shriram\u2019s expectations forsubmission activity. They expected activity to be slow and increase steadily,culminating in frantic late-night activity just before the deadline. Generallytaller \u201cM-6\u201d (midnightto 6 AM) bars indicate late-night work and a corresponding flurryof submissions, followed by generally shorter \u201c6-N\u201d (6 AM to noon) bars whenstudents tried to get a few winks in. Cumulatively, these two trends depict thepopular conception of the computer science student who favors late hours andperpetually lacks sleep. Thesegraphs show actual submissions. Asexpected, activity generally increases over time and the last day contains themajority of submissions. However, unexpectedly, the \u201cN-6\u201d (noon to 6 PM) and \u201c6-M\u201d(6 PM to midnight) segments are universally the most active. In the case of the CS173 graph, this morning segment contains far more submissions than any other ofthe day\u2019s three segments. In both of these graphs, the \u201cM-6\u201d (midnight to 6 AM) segmentsare universally the least active, even the day the assignment is due. For example, the final segment of this type,which represents the last available span of early morning hours, is among thelowest of all segments, with only ten submissions occurring. In contrast, thecorresponding \u201c6-N\u201d (6 AM to noon) shows more than four times as manysubmissions, suggesting that most students do their work before or after thepre-dawn hours but not during them. \u201cIwouldn\u2019t have expected that,\u201d Joe comments. \u201cI think of the stories folks tellof when they work not lining up with that, in terms of staying up late and gettingup just in time for class. Our students have something important to do atmidnight other than work: they cut off their work before midnight and dosomething else. For the majority it\u2019s probably sleep, but it could just besocial time or other coursework. Either way, it\u2019s an interestingacross-the-board behavior.\u201d Ifword of these results gets out, what can Luis and his fellow students expect?\u201cPeople will realize,\u201d Shriram says, \u201cthat despite what everyone likes toclaim, students even in challenging courses really are getting sleep, so it\u2019sokay for them to, too.\u201d Joe agrees: \u201cThere isn\u2019t so much work in CS that youhave to sacrifice normal sleeping hours for it.\u201d Luis,his family, and his well-rested classmates will undoubtedly be glad to hear it.The only question is: will their own descriptions of their work/sleep habitschange to match reality, or are tales of hyper-caffeinated heroics too temptingto resist?", "https://blog.cs.brown.edu/2014/10/01/brown-cs-finds-unique-way-celebrate-impressive-heidelberg-laureate-forum-representation/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Brown CS Finds A Unique Way To Celebrate Impressive Heidelberg Laureate Forum Representation Posted by Jesse Polhemus on Oct. 1, 2014 in Diversity In addition to advancing the field at a local and national level, Brown CS community members have a global impact on education and research. For more articles on Brown CS around the world click here . Thirty-five years after the founding of the department, Brown CS attendance at international conferences is anything but uncommon: strong representation and participation are the norm. But the three students who flew to last week\u2019s Heidelberg Laureate Forum (HLF) took an unusual step to bring Brown CS spirit to the event, expanding departmental tradition and proving themselves right at home in a world-class environment where collaboration thrives. Now in its second year, the HLF provides an annual gathering in which Abel, Fields, and Turing laureates interact with 200 of the world\u2019s best young minds, divided evenly between computer scientists and mathematicians. Irina Calciu , Max Leiserson , and Layla Oesper were selected from a pool of more than 2000 applicants, and they were joined by alumnus Matthew Lease PhD \u201810, providing Brown with an impressive 4% of worldwide CS attendees at the conference and 20% of American ones. They were also accompanied by a chicken. (If you\u2019re not familiar with the rubber chicken tradition at Brown CS, click here .) \u201cIt just seemed like a good idea!\u201d laughs Layla. \u201cWe were so excited about meeting the laureates and the incredible diversity of researchers. There were students from six different continents! We decided it would be fun to take pictures of a Brown CS rubber chicken traveling the world, meeting people, and showing our pride at having four attendees.\u201d The chicken complied, dutifully posing for pictures with Vint Cerf and John Hopcroft, atop castles, on a boat trip, and even during an Oktoberfest celebration. (A selection of photos is available here .) Structured as a mix of presentations and social events, the Forum\u2019s informal talks included sometimes unexpected advice (Leslie Lamport told listeners that since they spend more time sending e-mail than doing anything else, they should edit each message as if looking to publish them) and frequently had a galvanizing effect. \u201cAfter hearing John Hopcroft talk about changes in theory needed to support changes in our field,\u201d Max remembers, \u201cthe whole room was energized, and he was swarmed by people. But we\u2019d already met him when he sat down to have lunch with us the day before, possibly because we were carrying a rubber chicken!\u201d All three students note that while they were interested in finding peers with similar scientific interests (Layla mentions that a new friend may soon be using an algorithm developed by Ben Raphael\u2019s group), delving deeper into one\u2019s own research area wasn\u2019t the conference\u2019s true rationale. \u201cHLF gives you a high-level perspective on worldwide research that you hadn\u2019t known was going on, and how the two disciplines benefit each other, such as computer simulations of mathematical work,\u201d notes Max. \u201cBut the socialization and interaction are what makes it all approachable. It\u2019s where the real learning happens.\u201d Bringing a chicken everywhere also had some unexpected (and positive) consequences. \u201cNot only did the chicken start conversations,\u201d says Irina, \u201cIt caused people to tell us stories about traditions at their universities. That made me proud that tradition is so strong here at Brown CS. It defines us. We have a real commitment to getting to know everybody in the department and collaborating, and we brought that spirit to the Heidelberg Laureate Forum.\u201d The next time you attend a conference, bring a chicken with you, take a picture, and send it to Jesse Polhemus (jcp@cs.brown.edu). We\u2019d be glad to tweet about it with the #BrownCSConferenceChicken hashtag!", "https://blog.cs.brown.edu/2014/06/19/genevieve-patterson-helps-organize-ldv-vision-summit-sees-opportunity-undergrads/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Genevieve Patterson Helps Organize LDV Vision Summit, Sees Opportunity For Undergrads Posted by Jesse Polhemus on June 19, 2014 Brown University Department of Computer Science (Brown CS) PhDstudent Genevieve Patterson has justhelped organize the LDV Vision Summit, a start-up conference held in New YorkCity to address trends and technologies in digital imaging and video technology.Founded by Evan Nisselson of LDV Capital, an investment group interested in technology-focusedprojects across the imaging/video spectrum, the summit brought together top technologistsand investors with the purpose of shaping the future of imaging and video. Genevieve\u2019sprevious work with professor Serge Belongie of Cornell Tech, one of Nisselson\u2019scollaborators, made her a natural choice to help run competitions and pre-judgeentrants for a vibrant and diverse conference. \u201cThe summit featured anincredible variety of startups from all over the world,\u201d she explains. \u201cThey\u2019recreating state-of-the-art solutions for emerging topics, from wearable camerasto object detection to human tracking. Some of the solutions are extremelyhigh-tech, while others are simple and consumer-facing.\u201d Thesummit included multiple keynote addresses (Jan Erik Solem of Mapillary on \u201cCrowdsourcingMap Photos\u201d and Rob Fergus of NYU and Facebook AI on \u201cRecent Progress InComputer Vision Using Deep Learning\u201d as just two examples), panels on such topicsas the future of cameras and image recognition, and two competitions. Thefirst, an entrepreneurial computer vision challenge, allowed experts todemonstrate solutions for problems such as summarizing video, detecting and recognizingwords in YouTube video frames, and predicting the relative attributes for pairsof men and women\u2019s shoes. Thesecond, a startup pitch competition, was won by Alexandre Alahi of VisioSafe,whose company uses networked cameras to analyze human behavior in physicalspaces. \u201cThey went up against some impressive challengers and won,\u201d saysGenevieve. \u201cWhat they\u2019re able to do is anonymously collect patterns of movementand then provide metrics, so their clients can make better use of any location,from malls to public parks. They\u2019re already working with Swiss Rail to improvetheir stations. It\u2019s an exciting example of the opportunities that this fieldhas to offer.\u201d Inparticular, Genevieve wants to point out th at undergraduatecomputer science students are poised to take advantage of the considerableopportunities that are being created. \u201cThe fundamental challenges of computervision are still new to industry,\u201d she says, \u201cand that requires researchers.The dozens of startups seen at LDV Vision Summit need employees. They want studentsto get interested in the field today. The problems are still open, and theproducts that we have yet to see are going to create radical change in so manyaspects of everyday life.\u201d Anyoneinterested in the LDV Vision Summit can click here to follow them on Twitter,click here to go to theirWeb page, or click here to sign up for their newsletter for details on next year\u2019s conference.", "https://blog.cs.brown.edu/2014/07/22/anna-lysyanskaya-offers-ukraine-commentary-wpri/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Anna Lysyanskaya Offers Ukraine Commentary On WPRI Posted by Jesse Polhemus on July 22, 2014 In addition to advancing the field at a local and national level, Brown CS community members have a global impact on education and research. For more articles on Brown CS around the world click here . Brown CS Professor Anna Lysyanskaya was again interviewed by WPRI's Dan Yorke and offered a commentary on the situation in Ukraine. Video of the interview can be found at WPRI's web site .", "https://blog.cs.brown.edu/2014/06/04/michael-littmans-cs-music-videos-go-viral-receive-50000-views/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Michael Littman\u2019s CS Music Videos Go Viral, Receive 50,000+ Views Posted by Jesse Polhemus on June 4, 2014 \u201cSo awesome!\u201d writes oneenthusiastic YouTube commenter. \u201cWay too much fun for machinelearning,\u201d adds another. For the past several years, Brown University Departmentof Computer Science professor Michael Littman has beenextending a family tradition of writing spoof songs by making music videos toreinforce concepts taught in his classes. \u201cI was always a big fan of Weird AlYankovic,\u201d Michael says, \u201cHis gift for wordplay and ear for rhythm areunmatched.\u201d While teaching a class on artificial intelligence back in 2001,Billy Joel\u2019s \u201cWe Didn\u2019t Start The Fire\u201d provided Littman with inspiration tosummarize class topics (\u201cXOR, learning rate, squash the sum and integrate\u201d) andthe string of videos began. They\u2019re rapidly becoming a viralphenomenon. One frequently-retweeted video features Michael, professor CharlesIsbell of Georgia Tech, and a Georgia Tech vocal group. It\u2019s based on MichaelJackson\u2019s \u201cThriller\u201d and focuses on the problem of overfitting in machinelearning. It\u2019s available here ,and is unique in that it was made with the help of a video editor. \u201cMost of mysongs have been weekend hacks with just me, Garage Band, iMovie, and Keynote,\u201dMichael explains. Another video (available here ), for CS 8, spoofsthe Queen song \u201cFlash\u201d and teaches about the programming language Scratch. Itfeatures the undergraduate teaching assistants from the class and a cameo fromMichael. Neither of them are as popular as his \u201cThe Sorter\u201d video, which hasreceived 54, 225 views and is still climbing. \u201cMost of what I know about Englishgrammar and the U.S. Constitution comes from watching \u2018Schoolhouse Rock\u2019 songsas a kid,\u201d Michael says. \u201cThe experience taught me that some concepts stickbetter if they\u2019re put to music. Why not computer science?\u201d The full collection of videos can befound here .Take a look, share them with friends, and as anothercommenter says, \u201cLet your geek fly!\u201d", "https://blog.cs.brown.edu/2014/07/08/brown-cs-and-ccmb-enjoy-record-participation-ismb-2014/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Brown CS And CCMB To Enjoy Record Participation At ISMB 2014 Posted by Jesse Polhemus on July 8, 2014 In addition to advancing the field at a local and national level, Brown CS community members have a global impact on education and research. For more articles on Brown CS around the world click here . Brown University \u2019s Department of Computer Science (Brown CS) and Center for Computational Molecular Biology (CCMB) are looking forward to giving a record number of talks at one of the most prominent conferences in computational biology. Current and former students and post-docs of professor Ben Raphael presenting at the twenty-second annual International Conference on Intelligent Systems for Molecular Biology (ISMB 2014) in Boston include Iman Hajirasouliha , Max Leiserson , Layla Oesper , Anna Ritz , and Hsin-Ta Wu , featuring work co-authored with Ahmad Mahmoody , Gryte Satas , and Suzanne Sindi . Ben credits the strong Brown CS representation to a little bit of fortunate timing and a lot of ongoing effort from a dedicated group of researchers. \u201cIt\u2019s surprising that all these projects came together at the same time,\u201d he says, \u201cbut it shows that we have a hard-working group with a strong culture of mentoring to help each person reach their full potential. Our small size requires excellence across the whole team, and I\u2019m proud that we\u2019re able to compete successfully against much larger groups, not only in CS but also in medical schools and research institutes.\u201d Layla Oesper and Gryte Satas are happy denizens of what they consider to be a technological leading edge. \u201cUnderstanding/analyzing sequencing data from cancer genomes is a difficult task,\u201d they explain. \u201cThere are many factors that make identifying the landscape of mutations in a heterogeneous tumor sample hard. Our algorithms are aimed at quantifying this type of information, an important first step in determining what mutations drive cancer. This wasn\u2019t possible even five years ago, and it lets us make use of the vast amount of data that has been accumulating.\" \u201cWe\u2019re also looking forward to the inaugural Raphael Reunion!\u201d they laugh, explaining that the conference will allow all of Ben\u2019s current and former students to reunite in Boston. What do all these colleagues have in common? \u201cMomentum, collaboration, and energy,\u201d says Layla. They\u2019re qualities that are evidently shared by their mentor. \u201cBen is as passionate about our work as he is about his own,\u201d Gryte says. \u201cHow does he find the time to sleep?\u201d Ben shrugs. \u201cWhat makes me happy is that all these projects include multiple authors who are great team players. Because our group is part of a CS department, we can recruit people with strong skills in algorithm development and program design, which really gives us an edge.\u201d Max Leiserson\u2019s collaborators, in addition to Raphael, include two researchers from Tel Aviv University. His highlight talk focuses on a paper they published a year ago, about an algorithm developed by Brown CS called Multi-Dendrix . Without prior information, it searches for genes with approximately exclusive mutations and high coverage in a cohort of tumors, which enables the identification of \u201cdriver\u201d genetic pathways that cause cancer when mutated. Asked for his goals for the conference, Max says, \u201cI\u2019m looking forward to all the talks, the chance to learn from others. My biggest hope is that people will get excited about our results and even more cancer researchers will use our software.\u201d He explains that external researchers will have an even easier time using Brown CS tools in the future: currently, some of the applications necessary to run Multi-Dendrix are proprietary and need to be purchased, but an upcoming transition to entirely open-source software will allow maximal ease of use. While working under Raphael, Iman Hajirasouliha, Anna Ritz, and Hsin-Ta Wu\u2019s collaborators have included colleagues from the bioscience industry as well as academia (Brown University and elsewhere). Hsin-Ta will present a paper on detecting copy number aberrations in cancer co-authored with Iman, and Iman will present a paper on intra-tumor heterogeneity co-authored with Brown CS\u2019s Ahmad Mahmoody. Both were among 29 papers directly accepted in the first round of peer reviews, out of 204 submissions. \u201cOnly recently,\u201d Iman comments, \u201chave scientists realized that mutations that we formerly thought of collectively, such as breast cancer or lung cancer, actually vary considerably from person to person. Our task now is to characterize heterogeneous mutations across a tumor. It\u2019s a major step forward.\u201d \u201cI\u2019m really eager to introduce people at the conference to our new research about finding driver recurrent copy number aberrations,\u201d adds Hsin-Ta. \u201cOur new method has advantages in not only accurately identifying candidate copy number aberrations which could drive cancer but providing an algorithm which is simple and fast, and readily adaptable for high-throughput sequencing data. For us as computer scientists, in the future it will be exciting to apply this method to larger cancer datasets as more and more cancer patients are sequenced.\u201d Ritz and Hajirasouliha\u2019s shared research into structural variants across a single genome, not specific to a particular disease, was partially aimed at the challenges caused by software limitations. \u201cSecond-generation sequencing platforms,\u201d Anna explains, \u201care slow but quite accurate, with an error rate of one or two percent. Third-generation technology gives a more in-depth analysis, but has a fifteen percent error rate. Our algorithm is probabilistic, and it shows that combining the two platforms allows you to reduce the impact of errors while maximizing the third-generation benefits.\u201d Anna sees real parallels between Brown CS\u2019s progress in computational biology and the field\u2019s increasing opportunities: \u201cBen\u2019s first year at Brown was my first year as a graduate student. His great ability to locate the next big problem is helping us make major contributions to the field. Just as one example, our results are helping overcome the hesitation about third-generation sequencing paradigms. If we can prove their worth, they\u2019ll get used, and medical progress will be made.\u201d Ben agrees. \u201cIt\u2019s so exciting,\u201d he says, addressing prospective ISMB 2014 attendees and celebrating the members of the research group that he\u2019s put together. \u201cWe\u2019re thrilled to be building on our long-term record of strength in this field, to share our results and demonstrate what a great environment we have for students of all levels. I hope my team gets to see the appreciation for their research. I think it will help them understand how much all their effort, day in and day out, has achieved.\u201d", "https://blog.cs.brown.edu/2014/12/17/brown-cs-brings-hour-code-130-kids/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Brown CS Brings An Hour Of Code To 130+ Kids Posted by Elizabeth Hilliard on Dec. 17, 2014 in Diversity Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . For the second year in a row, Brown Computer Science brought an Hour of Code to Providence students at Nathan Bishop Middle School. Hour of Code is a global initiative run by Code.org to bring programming to everyone, especially young students and those that are underrepresented in computing. President Obama kicked off the weeklong event by learning to write some Javascript. This year Professor Amy Greenwald, graduate students David Abel, Amy Becker, Betsy Hilliard, Michael Majzoub (seen in the photo above), and Jeff Rasley, and undergraduate Luke Camery, visited all ten Gateway to Tech classes (more than 130 6th, 7th, and 8th graders) at Nathan Bishop, and introduced them to the Scratch programming language. A handful of the students had some experience, having worked with us last year, but most were new to programming. After about ten minutes of formal instruction, the students were free to work on their own ideas, with us wandering around the classroom giving them input and answering their questions. Mike noted, \"The student projects were incredible -- ranging from cartoons to video games. I was amazed with how much they were able to do in just one class period. They were also great at helping one another out as they gained a greater understanding of the programming interface.\" Even more important than what they made or learned about Scratch, however, was what they realized about themselves. Amy Becker remarked, \u201cThere seemed to be a mentality among the students that there was one right procedure...My favorite part of the experience was witnessing the transition as they went from asking me what the right way was, to exploring what they could make the program do on their own. They experienced the loss of inhibitions and fear of being wrong. It was awesome to watch a student who had been initially hesitant show me what they had figured out and take pride and ownership of their creation.\u201d For me, watching kids hit \u201crun\u201d on their first program is always a special moment. It\u2019s exciting to see the pure joy --joy in the creativity and joy in the empowerment-- when students realize they just programmed a computer. It reminds me why I got into Computer Science in the first place.", "https://blog.cs.brown.edu/2014/10/21/brown-university-hosts-northeast-robotics-colloquium-nerc-delights-scientists-industry-and-children/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Brown University Hosts Northeast Robotics Colloquium (NERC), Delights Scientists, Industry, And Children Posted by David Whitney on Oct. 21, 2014 in Diversity Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . The Brown University Humans To Robots Lab, headed by Professor Stefanie Tellex, hosted the 2014 Northeast Robotics Colloquium last week. Drones that can deliver packages bumped up against robots that have already moved millions of greenhouse plants, and aerospace resins met 3D printers. The event was part conference, part trade-show, with a large poster session for academic groups, and booths for private robotic firms. Keynote speakers were Holly Yanco (UMass Lowell), Bertram Malle (Brown University), Joe Jones (Harvest Automation), and Nicholas Roy (MIT, Google). Each speaker covered a different aspect of moving robotics forward in terms of theoretical ability and practical integration in society. Holly Yanco described the NERVE Center, a 10,000 square-foot indoor testing center for mobile robots. The Center contains a National Institute of Standards and Technology (NIST) compliant course as well as proprietary water and indoor rain environments. Nicholas Roy spoke about accurate SLAM (simultaneous localization and mapping) with small drones, and his practical implementation of such techniques during his stay at Google X. While there, he lead Project Wing, a drone delivery program. Joe Jones, a veteran of both MIT and iRobot (the company behind Roomba), described his new company, Harvest Automation, and its goal to automate jobs in the world's greenhouses and nurseries. Specifically, they address the nurseries\u2019 need to evenly spread thousands of potted plants across a surface. Where this job is considered to be one of the nursery's most unpleasant, Harvest Automation's fleet of HV-100s have moved over 7 million plants without complaint. Attendees prepare for the next speaker Event sponsors were private robotics firms interested in facilitating skill transfer between groups, and recruiting students and researchers looking to move to industry. Turn-out was larger than expected, with over 150 people interacting at the venue, Brown's Alumnae Hall. \"The space was amazing,\" said volunteer coordinator John Oberlin. \"It really allowed for a diversity of research interests to intermingle.\" His favorite moment? \"My favorite demo was a group who were 3D printing using aerospace resins.\" \u200bBrown student Miles Eldon shows off his gesture and speech interpreter Overall, the hosts were very pleased with the strong response. \"I think it was really fun,\" said Stefanie. \u201cI think it's good for undergrads and new graduate students to experience a conference, before they've necessarily published a paper. It shows what research is all about, gets them plugged in.\" Many attendees were also pleased that children and families were invited. Stefanie\u2019s two-year old son, Jay, had a great time at the conference. \u201cI\u2019m so excited that he\u2019s excited about robots. He loved seeing Keepon and Dragonbot, and he got to drive Kinova\u2019s Jaco arm.\u201d Keynote speaker Nicholas Roy, one of several attendees who wouldn\u2019t have come if families hadn\u2019t been invited, brought his wife and three kids to NERC. Their whole family really enjoyed the event. \"The kids now believe that all robots come from Rhode Island,\" he said later. A Keepon robot, which teaches empathy to children, lost in thought as it ruminates on the human condition", "https://blog.cs.brown.edu/2014/11/10/yurtatbrown/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) #YurtAtBrown Posted by Jesse Polhemus on Nov. 10, 2014 For more CS News and CS Blog articles about the Yurt, please click here . \u201cThe #YurtAtBrown hashtag documents a milestone,\u201d says Professor David Laidlaw of Brown University\u2019s Computer Science Department (Brown CS). \u201c2015 will be a landmark year for visualization at Brown and an evolutionary, transformative leap for the field.\u201d This leads to an obvious question: other than a dwelling of the Central Asian steppes, what is the Yurt? The Yurt (YURT Ultimate Reality Theatre) is the vastly-enhanced successor to Brown\u2019s renowned virtual reality display, the Cave (CAVE\u2122 Automatic Virtual Environment), celebrated for its research, computing, and educational advancements in fields as diverse as archaeology, sculpture, and neuroscience. \u201cWith the Yurt,\u201d David explains, \u201cour design goals were to match or exceed human perceptual abilities in every aspect of virtual reality by eliminating gaps, brightening colors, and increasing resolution. Remember how you felt when your phone\u2019s display jumped to retinal quality? Imagine standing in an entire room at that resolution, with pixels that are too small to see individually. It\u2019s world-class virtual reality. If you improved on any of our specifications, the human eye would almost never be able to detect it.\u201d As 2014 winds down, the Yurt is ramping up. The main wall is lit, and the software is blending images well, creating a 24\u2019x8\u2019 56-million-pixel 3D display. As both hardware (doors being hung and protective floor surfaces laid) and software (image alignment, distributed execution, 3D projection, our VRG3D library, and ultimately applications like CavePainting, Cave Writing, and Adviser) come online, Brown CS will chronicle the journey with behind-the-scenes photos, announcements, tweets, and videos that share the exciting progress step by step. You can take part by visiting the Brown CS homepage , Facebook , and Twitter (follow @browncsdept and look for the #YurtAtBrown hashtag). \u201cWe hope people of all backgrounds worldwide will journey with us as we head into, through, and beyond 2015,\u201d says David. \u201cThis will be our year of experimentation, about pushing the limits. We don\u2019t want you to miss any of it, because every step we take is going to offer new ideas and opportunities that previously didn\u2019t exist. We want thought leaders running their software here, finding the best and highest uses for the Yurt so we can share them with the world. Any field can gain from the Yurt\u2019s capabilities, and there\u2019s nobody who benefits from the arts, sciences, education or other disciplines who won\u2019t someday be impacted. Come join us!\u201d", "https://blog.cs.brown.edu/2015/01/14/gryte-satas-creates-new-opportunities-girls-code/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Gryte Satas Creates Opportunities For Girls To Code Posted by Jesse Polhemus on Jan. 14, 2015 in Diversity Described as \u201ca role model\u201d by her new colleagues atProvidence, Rhode Island\u2019s Rochambeau Library, Gryte Satas ,a PhD candidate at BrownUniversity \u2019s Department of ComputerScience , has just made a unique contribution to her community. She\u2019sleading a new Girls Who Code Club, designed to provide young women withcomputer science and programming skills, as well as opportunities to learn abouteverything from cryptography to artificial intelligence to developing mobileapplications. The club\u2019s mission is inspiration and education, equippinggirls with the skills to pursue 21st-century opportunities. Believed to be theonly public club of its kind in the state, it\u2019s open to any girl from gradessix to twelve.The entire story isavailable at ProvidenceBusiness News .", "https://blog.cs.brown.edu/2015/01/28/outstanding-student-work-2014-flick-gabriel-fernandez/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Outstanding Student Work, 2014: Flick, By Gabriel Fernandez Posted by Jesse Polhemus on Jan. 28, 2015 As a department, how do we evaluate our success? Continued innovation from our students means that we've aimed courses at the field's best opportunities, then taught them with real devotion to our craft. Together, that enables students to produce work that advances the state of the art. In this series, we'll showcase some of the outstanding student work of 2014 : Flick designed by Gabriel Fernandez for CS 1300: Designing, Developing and Evaluating User Interfaces taught by Jeff Huang for Brown CS Gabriel describes his project by saying: \"An application that runs on top of every other app on your Mac desktop, Flick answers the question of what a mouse without physical buttons would look like. It follows your mouse around, listening to all movement events. Once it has determined that some specific gesture has been made, it fires a click event that other applications, or even the OS, will capture.\" For a better understanding of how this works, look at the project's repo here: https://github.com/circuitlego/flick . Gabriel also notes that Flick currently supports the most used mouse operations: Click, Double Click, Right Click, and Drag. You can watch a video of Flick being used here: https://www.youtube.com/watch?v=0LWpx5TRWjg .", "https://blog.cs.brown.edu/2014/11/19/aaron-gokaslan-18-wins-hackprinceton-best-ios-app-award/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Aaron Gokaslan \u201918 Wins HackPrinceton Best iOS App Award Posted by Jesse Polhemus on Nov. 19, 2014 in Awards Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . Brown University computer science concentrator Aaron Gokaslan \u201918 and a team of his peers have just won a Best iOS App award from Apple at the recent HackPrinceton hackathon, earning an iPad Mini and the envy of several hundred of the country\u2019s best young computer scientists. The event, which has been held semiannually for a number of years, challenged students of all levels to join together and create unique software applications. \u201cI was confident,\u201d Aaron explains, \u201cbut the competition was intense. I truly enjoyed it, regardless of the outcome, but I only slept a few hours that weekend. I was actually pretty surprised that we won!\u201d For this particular award, participants were required to design the best all-around iOS application that relied solely on software as opposed to hardware. The criteria included functionality, design, and ease of use. Aaron and his teammates won for their application, Rabal , which functions as a universal translator. \u201cThe name is an acronym of our team\u2019s first names: Ryan Dunn, Aaron Gokaslan, Bryan Ngadimin, Alan Liu, and Leo Shimonaka,\u201d Aaron explains. \u201cExcept over Facebook, I didn\u2019t know any of my team members before I arrived, and I met two of them over Chinese food the first night!\u201d Rabal uses text-to-speech APIs (powered by Nuance) to transcribe and then translate audio (powered by Google Translate). A server then posts translations on web pages that are accessible from any Internet-enabled device, including wearables. The application currently features eight languages, and Aaron notes that it could easily be extended to at least twenty-three. \u201cI had a great time meeting new people and seeing old friends,\u201d Aaron says of the event. \u201cIt was exciting throughout: we didn\u2019t even have a working model until a half-hour before the submission deadline and had to re-purpose one of my teammate\u2019s websites to get the setup working. There were some really innovative hacks, and I\u2019m proud that we competed so well among them.\u201d", "https://blog.cs.brown.edu/2015/02/02/cs015-reflection/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) CS015: A Reflection Posted by Jesse Polhemus on Feb. 2, 2015 by Emma Catlin There's a lot of talk about how introductory classes discourage minorities, and making classes more \"friendly\" to those with little prior experience in coding is trending at universities. In one of Brown's introductory computer science classes, CS015, I think a successful effort has been made to encourage women to continue coding. The class provides many women role models in the TAs, of whom about half are women. I also appreciated the fact that in the lecture on the history of computer science, just as many important women figures were included as male. Talking to students in CS017, another introductory computer science class, I heard similar experiences. While women were outnumberd by men, one student told me that she didn't feel like she was at a disadvantage because there were enough other women in the class. Also, she shared that the professor and the TAs made everyone feel included. Perhaps it's necessary in these classes to reach a critical mass, along with other encouraging factors, to make sure minorities are not dissuaded. It seems like the critical mass has been achieved for women in these classes, but not necessarily for other minorities. What is it like to be a minority in an introductory computer science class? When I reflect on my experience in CS015 last semester as someone who identifies as female, a minority among coders, I feel the class was welcoming. There was such a large number of students in the class that there was a diversity in backgrounds such as class year and coding experience (more than 50% had never coded before). But while the amount of women in introductory classes such as CS015 may have reached critical mass, the numbers of other minority groups are still not there yet. Introductory classes still have a way to go to make everyone feel included, but I didn't feel discouraged from coding because I was a woman in CS015.", "https://blog.cs.brown.edu/2015/02/09/providence-journal-reports-hackbrown-2015/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) The Providence Journal Reports On \"Serious Innovation\" At Hack@Brown 2015 Posted by Jesse Polhemus on Feb. 9, 2015 Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . \"It's just about building and doing something you love with people who are supportive and want you to succeed,\" says Hack@Brown contributor Ricky Medina. He and others were interviewed by the Providence Journal , which covered last weekend's second annual Brown hackathon in this morning's edition. Their account of the \"serious innovation\" that occurred includes details of the proceedings, comments from attendees from across the country, and a video. It's available here .", "https://blog.cs.brown.edu/2015/03/16/brown-cs-sponsors-intracity-geeks-teach-programming-middle-school-children/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Brown CS Sponsors Afterschool Program To Teach Programming To Middle-School Children Posted by Jesse Polhemus on March 16, 2015 in Diversity Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . NBC 10 News has just recognized Brown CS and the Providence After School Alliance for their support of IntraCity Geeks, an after-school program that teaches programming skills to local public school children at Nathan Bishop Middle School. The full story is available here .", "https://blog.cs.brown.edu/2015/02/15/brown-cs-supports-browns-first-feminist-conference-ri-high-school-students/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Brown CS Supports Brown's First Feminist Conference For RI High School Students Posted by Jesse Polhemus on Feb. 15, 2015 in Diversity Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . Brown CS is proud to lend financial support to the FLAME Conference, Brown's first feminist conference for Rhode Island high school students. FLAME will take place on Sunday, March 8, 2015 (International Women\u2019s Day) and feature a variety of workshops run by Brown student groups and faculty. Some workshop topics include: gender inequality in the workplace, intersectionality, healthy relationships, and sexuality. The purpose of the conference is to provide an opportunity for feminist education to participants as well as to unite feminist-minded student groups at Brown. To learn more, click here to visit the FLAME Conference web site.", "https://blog.cs.brown.edu/2015/03/10/providence-ranked-americas-eighth-best-college-town-people-who-arent-college/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Providence Ranked America's Eighth Best College Town For People Who Aren't In College Posted by Jesse Polhemus on March 10, 2015 For more stories on why we love calling Providence home, check out our Praise for Providence page here . Cond\u00e9 Nast Traveler has just ranked Providence as America's eighth Best College Town for People Who Aren't in College. The full story is available here . photo by Will Hart, used under Creative Commons", "https://blog.cs.brown.edu/2015/03/24/hcri-and-ri-students-future-announce-second-ri-robot-block-party-showcase-how-robots-are-used-education-research-work-and-play/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) HCRI And RI Students Of The Future Present RI Robot Block Party, A Showcase Of Robots In Education, Research, Work, And Play Posted by Jesse Polhemus on March 24, 2015 in Diversity Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . The Robot Block Party is a celebration of National Robotics Week held on April 11, 2015 at the Pizzitola Center at Brown Uni versity. Organized by Rhode Island Students of the Future, a non-profit organization that engages kids in science, technology, engineering and math through robotics, and the Humanity Centered Robotics Initiative at Brown University, the Robot Block Party showcases how robots are used in education, research, work and play. Exhibitors include: University Exhibits and Demonstrations RISD students will demonstrate the rover they built for the 2015 NASA Human Exploration Rover Challenge. The Brown Robotics Lab will demonstrate cloud robotics technologies and quadrotor and telepresence robots. Brown University Planetary Geosciences and NASA Solar System Exploration Virtual Institute (SSERVI). The SSERVI Evolution and Environment of Exploration Destinations (SEEED) team is hosted by Brown University and MIT. NASA and international space probes are exploring all the planets of the solar system and will reach Pluto this summer. Come see pictures of Mars from the sophisticated Curiosity rover, and share close-up images of the surface of a comet. Meet scientists from Brown University who are exploring the planets and satellites of the Solar System and learn of their discoveries and future plans for human and robotic exploration! Human 2 Robot Lab will demonstrate the pick and place capabilities of the Baxter industrial robot, created by Rethink Robotics. The Laboratory for Engineering Man/Machine Systems (Computer Vision @ LEMS) will display their Blindfind project. The Brown IEEE Robotics Olympiad Micromouse competition will hold their annual competition at the Robot Block Party. University of Rhode Island Graduate School of Oceanography will display the autonomous kayak and Lagrangian floats used to explore shallow coastal waters. The URI RoboBoat team and the Robotics Laboratory for Complex Underwater Environments (R-CUE) will team up to display the URI Autonomous Surface Vehicle; a pair of flying robots; at least two underwater robots; and a variety of 'soft robotics' prototypes use for underwater grasping and manipulation. Roger Williams University School of Engineering, Computing and Construction Management will demonstrate a student built, human scale mobile robot allowing for virtual telepresence. Salve Regina University School of Business Studies and Technology will display student technology projects. New England Institute of Technology will have a demonstration of robotics, quad-copters, and support products. Manufacturing and Community Organizations Hasbro will demonstrate their animatronic toy line, FurReal Friends. igus, inc will display their movement machine and iglide and echain products. The Rhode Island Computer Museum will present \u201cRobots on the Run\u201d an activity that explains basic circuits and programmable electronics in hobby robots. FabNewport will demonstrate ArtBots that create original works of art. IEEE Providence Section will demonstrate their role in the robotics industry and professional development of engineers. The Providence Children\u2019s Museum will provide the Rigamajig play area which encourages hands on exploration of mechanical design concepts. BLT Robotics will display a Robotic Vertical Hydroponic Farm. Members of Make:'s book publishing team will be joining the Robot Block Party to show off projects from some of our recent and soon-to-be-published books. They'll have hands-on interactive projects you can play with from our upcoming Getting Started with littleBits book, some 3d-printed-in-place objects, and some Raspberry Pi demos. AS220 Labs is showing a new line of electronics kits and some drawing machines from the Lab. Robotix Learning Solutions will demonstrate their affordable robot that helps teach kids (4-18 years) how to code in an easy and interactive way. Student Exhibits Coventry: Alan Shawn Feinstein Middle School students built a robotic claw that can pick up a ball and a Chain Reaction Machine. East Greenwich: Our Lady Of Mercy School has over 30 students building autonomous parade floats and interactive robotics projects. The students range from age 6-12. East Providence: Martin Middle School has middle school students building autonomous parade floats and interactive projects. Riverside: Riverside Middle School students are building autonomous parade floats, and interactive projects. Gordon School students are working on interactive robotics projects and a Chain Reaction Machine. Middletown/Newport: Newport Community School is bringing students who built autonomous parade floats. All Saints STEAM Academy students are displaying their Arduino robots and several other interactive projects. Their Jr. FIRST LEGO League team will demonstrate their Think Tank project. The Aquidneck Island 4-H club runs robotics programs for kids aged 9-18. AIR Strike 78, their FIRST Robotics team will demonstrate their award-winning robot. Providence: Providence Career and Tech Academy will demonstrate engineering and robotics projects completed by their engineering students. Wheeler School will exhibit projects built by lower and middle school students. FRC 2780 Robotics Team, based at Wheeler School, will demonstrate their FIRST Robotics Robot. Lincoln School will demonstrate Tetrix robots built by the Robotics I & II classes, plus a demonstration of our FIRST Tech Challenge bot with field elements from the 2015 FTC game, Cascade Effect. Mount Pleasant High School will demonstrate their student robotics projects. Nathan Bishop Middle School will demonstrate their student robotics projects. The College Crusade is a community-based robotics teams, composed of Cranston & Providence youth. They will demonstrate a rover. Narragansett: The Pier School will exhibit classroom robotics projects. Warren: Kickemuit Middle School is building a chain reaction machine. West Warwick: 21st Century Community Learning Center, YMCA at John Deering Middle School will feature students demonstrating autonomous parade floats. Many thanks to our sponsors and supporters: National Grid Humanity Centered Robotics Initiative at Brown University Brown-MIT SSERVI-SEEED SAIC igus, inc. Textron Charitable Trust Polaris MEP MAKE: 3d Printing Providence", "https://blog.cs.brown.edu/2015/03/18/cybersecurity-brown-undergraduates-win-it-all/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Cybersecurity: Brown Undergraduates Win It All Posted by Jesse Polhemus on March 18, 2015 in Awards Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . \"A team of Brown undergraduates from computer science, political science, and international relations has won the Cyber 9/12 Student Challenge, a national cybersecurity policy competition,\" says Science News Officer (Physical Sciences) Kevin Stacey, writing for News from Brown. \"No all-undergraduate team had ever won.\" You can read the full story of their historic win here .", "https://blog.cs.brown.edu/2015/04/23/aaron-gokaslan-18-and-laura-shea-18-take-second-place-award-software-hackprinceton/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) 2nd Place Award For Software At HackPrinceton Goes To Aaron Gokaslan '18 And Laura Shea '18 Posted by Jesse Polhemus on April 23, 2015 by Aaron Gokaslan '18 Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . On April 12, 2015, Brown University students Laura Shea \u201818 (a computer science and math concentrator) and I (also \u201818, a computer science concentrator) came in second place in software at HackPrinceton. Our team, with fellow students Ergeta Muca and Anthony Lobko, designed a website to convert files into videos, which are then uploaded to YouTube. We pitched that this turns YouTube into free, unlimited cloud storage. The website, which we\u2019re calling Osiris, uses python, ffmpeg, x264, Django, and Amazon web services. Osiris--the Egyptian mythological figure--suffered the fate of having his body cut into several pieces, scattered throughout Egypt, and then put back together. As our website supports video hosting sites in addition to YouTube, users can symbolically scatter and retrieve data in a similar manner. The website is currently offline while we work on moving some of the heavy computation. Laura and I met our teammates Ergeta and Anthony at the hackathon, and it was rewarding and enjoyable to work with new people. Coincidentally, I won an award in the fall with a different random team, and several of that team\u2019s members ended up in the same computer lab as we did! To add to the parallelism, they won second place in hardware. All in all, the experience was unforgettable and adds to a successful Hackathon season for both Brown and myself.", "https://blog.cs.brown.edu/2015/04/30/its-never-too-late-try-cs-enthusiastic-undergrads-tell-brown-classmates/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) It's Never Too Late To Try CS, Enthusiastic Undergrads Tell Brown Classmates Posted by Jesse Polhemus on April 30, 2015 in Diversity This year alone, 771 Brown students took introductory CS classes. The rest are probably asking themselves: * What kinds of things can I do with a CS degree? * Can I do CS without concentrating in it? * Do I have to take a ton of math to do CS? * WHAT IS COMPUTER SCIENCE, ANYWAY? To answer these questions, some of our undergraduates who took non-traditional paths in computer science created It's Never Too Late, a panel party designed to share their experiences and answer the questions of prospective CS students. It was held on April 10 at 4 PM, and if you missed it, a video of the entire event is available here . If you have any questions about taking a CS course, please contact Tom Doeppner , Director of Undergraduate Studies.", "https://blog.cs.brown.edu/2015/05/18/artemis-alumna-keeps-looking-opportunities-code/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Artemis Alum Keeps Looking For Opportunities To Code Posted by Jesse Polhemus on May 18, 2015 in Diversity Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . BREAKING NEWS: Brown CS is proud to report that Louisa has just been declared a Kode with Karlie Scholarship winner. Congratulations, Louisa! Profiles of the 2015 scholars are available here . =-=-= \"Most people,\" says 14-year-old Louisa Bay, \"think coding is boring and for boys. I know they're wrong. By winning the Kode with Karlie Scholarship, I will have the tools I need to change the world.\" Few things are more satisfying for the Brown CS family than seeing graduates of the Artemis Project (our free, five-week summer day camp for rising 9th-grade girls in the Providence area who are interested in learning about science and technology) continue what we hope will become a lifelong pursuit of computer science. After an \"awesome\" experience with Artemis, Louisa was inspired to start a Coding Club in her high school, but resources have been scarce. To help turn that around, she's competing for the Kode with Karlie Scholarship, which gives 20 girls across the country free tuition to Flatiron Pre-College Academy's Introduction to Software Engineering course. (You can watch her 90-second video application here .) Brown CS wishes her all the best. Good luck, Louisa!", "https://blog.cs.brown.edu/2015/05/19/cave-and-yurt-featured-ri-nsf-epscor-magazine/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Brown's Cave And Yurt Featured In RI NSF EPSCoR Magazine Posted by Jesse Polhemus on May 19, 2015 For more CS News and CS Blog articles about the Yurt, please click here . As the countdown to the Visualization and Creativity in Immersive 3D Environments -- from Cave to YURT symposium continues and excitement about the Yurt grows, the online magazine of Rhode Island National Science Foundation (NSF)'s Experimental Program to Stimulate Competitive Research (EPSCoR) has taken notice. Take a look at page 22 of The Current to learn more.", "https://blog.cs.brown.edu/2015/06/10/gq-raves-about-providence-worlds-tiniest-state-pops-out-coolest-city/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) GQ Raves About Providence: \"The Coolest City\" Posted by Jesse Polhemus on June 10, 2015 For more stories on why we love calling Providence home, check out our Praise for Providence page here . Continuing a multi-year trend, rave reviews of Providence continue to roll in. This time, GQ cites Brown as one of three contributors to an \"intimidatingly smart\" city, waxing lyrical on the subjects of food, caffeine, and Lovecraft. The full article is available here . Photo by Jef Nickerson, used under Creative Commons License (By 2.0)", "https://blog.cs.brown.edu/2015/05/15/learn-about-yurt-optical-tracking-innovation-80-second-video/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Learn About Yurt Optical Tracking Innovation In An 80-Second Video Posted by Jesse Polhemus on May 15, 2015 For more CS News and CS Blog articles about the Yurt, please click here . As we get ready for next week's Visualization and Creativity in Immersive 3D Environments -- from Cave to YURT symposium (click here for details), we're taking a moment to tell some of the most interesting stories from the Yurt's creation. In this 80-second video , PhD student Johannes Novotny explains a challenge that the team faced with the Yurt's optical tracking system and their profoundly creative solution.", "https://blog.cs.brown.edu/2015/05/28/michael-littman-quoted-libertarian-republic-risks-ai/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Michael Littman Quoted By The Libertarian Republic On The Risks Of AI Posted by Jesse Polhemus on May 28, 2015 Here's a provocative question: \"What do actual AI researchers think of the risks of AI?\" Ramez Naam of The Libertarian Republic notes that Elon Musk, Stephen Hawking, and Bill Gates have all expressed recent concern about \"killer AI\" scenarios despite having a lack of AI expertise. Instead, he turns to Michael Littman of Brown CS and three of his peers in the field. \"Dread predictions of computers suddenly waking up and turning on us,\" Littman comments, \"are simply not realistic.\" The entire article is available here .", "https://blog.cs.brown.edu/2015/05/26/digital-den-cites-brown-cs-well-recognized-vr-leader/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Digital Den Cites Brown CS As A \"Well Recognized\" VR Leader Posted by Jesse Polhemus on May 26, 2015 For more stories on why Brown CS is so great, check out our Praise for Brown CS page here . For more CS News and CS Blog articles about the Yurt, please click here . Digital Den recently toured the Yurt as part of last week's Visualization and Creativity in Immersive 3D Environments \u2014 From Cave to YURT symposium, describing it as \"a wonderful event...fascinating\". You can read the whole article here .", "https://blog.cs.brown.edu/2015/06/12/john-hughes-delivers-invited-lecture-college-de-france/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) John Hughes Delivers An Invited Lecture At The Coll\u00e8ge De France Posted by Jesse Polhemus on June 12, 2015 In addition to advancing the field at a local and national level, Brown CS community members have a global impact on education and research. For more articles on Brown CS around the world click here . There are plants that bloom once a century, and sometimes the right city --this time the one called La Ville Lumi\u00e8re for both its intellectual contributions and early adoption of street lighting-- and the right person can here and now, from blank canvas, evoke the spirit of a science and an art in transition. This time it's John Hughes, who strode the Quartier Latin with the words of Cyrille Aim\u00e9e (and maybe the crumbs of a financier aux pistaches ) on his tongue to deliver an invited lecture (\"The Media Transition in Expressive Rendering and Modeling\") at one of the world's great bastions of pure learning, the Coll\u00e8ge de France. \"This history of expressive rendering and modeling,\" he explains, \"is largely one of imitation: we make paintings in the style of Monet, cartoons like Dr. Seuss, watercolors, mosaic tile images, and so on. In each case, problems in representing or simulating the medium require that we be ingenious or devious or both: line drawings have aliasing problems; watercolors require stable but fast fluid simulation, etc. A few recent papers suggest a new and very promising divergence from this path: a search for media that are intrinsically suited to the kinds of representations and interactions that are natural both for a human and a computer rather than those that are naturally occurring in the physical world. I will discuss this evolution, some of the potentials of such new media in both rendering and modeling, and some of their potential pitfalls as well.\" Photo by LPLT / Wikimedia Commons", "https://blog.cs.brown.edu/2015/08/18/brown-cs-continues-earn-high-ratings/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Read More: Brown CS Alums Continue To Innovate And Pioneer Posted by Jesse Polhemus on Aug. 18, 2015 Brown CS alums continue to earn praise as successful innovators and industry pioneers. Click these links to learn more: Brown CS Student Artem Agvanian And Alum Hannah Gross Earn First And Second Place SOSP Student Research Honors A Guided Tour Of The Brown CS Digital Archive Michael Littman's New Book Recommends That We \"Code To Joy\" In A New Age Of Programming Michael Littman Receives The AAAI/EAAI Patrick Henry Winston Outstanding Educator Award 13 Of 88 Papers In Volume 2 Of SIGGRAPH's \"Seminal Graphics Papers\" Are By Brown CS Faculty, Students, And Alums Brown CS Alum John Stasko Receives An IEEE VGTC Lifetime Achievement Award Philip Klein And Brown CS Alums Receive The 2023 STOC Test Of Time Award Brown CS Alum Atul Butte Has Been Named An AAAS Fellow Look Where Our 2023 Graduates Are Headed! Brown CS Alum Ani Kristo And Collaborators Are 2022 Sort Benchmark Winners Brown CS Alum Nick Leiserson Has Been Named The White House\u2019s Assistant National Cyber Director For Cyber Policy And Programs Seny Kamara And Charalampos Papamanthou Win The 2022 CCS Test-Of-Time Award Laidlaw, van Dam, And Two Brown CS Alums Win An IEEE CG&A Test Of Time Paper Award Diverse Career Paths: How Brown CS Alum Edwina Rissland Has Melded Math, CS, And Law Honored With Endowed Professorships In His Name, Brown CS Alum Ed Lazowska Reflects On His Time At Brown Brown CS Alum Danfeng Yao Has Been Named An IEEE Fellow Brown CS Alums Steven Shi And Alyssa Cantu Receive NSF CSGrad4US Fellowships Diverse Career Paths: Brown CS Alum Tatyana Dyshlova Talks Starting Companies, Building Games Brown CS Adopts Software Created By Alum Gaurav Manek To Improve PhD Visit Logistics Brown CS Graduates Build An Online Learning Community For URM Students Kamara, Moataz, And MongoDB's \"Queryable Encryption\" Lets Data Stay Protected During Search Five Brown CS Students And Alums Receive NSF Graduate Resesarch Fellowships Three Brown CS Alums Join FASPE's 2022 Design And Technology Program Brown CS Adopts Software Created By Alum Gaurav Manek To Improve PhD Visit Logistics Brown CS Alum David Abel Is A Joint AAAI/ACM SIGAI Doctoral Dissertation Award Runner-Up Brown CS Alum Guillaume Marceau And Professors Fisler And Krishnamurthi Win The Onward! 2011 Most Notable Paper Award Brown CS Alum Jina Yoon Receives An NSF CSGrad4US Fellowship Diverse Career Paths: Brown CS Alum Eleanor Tursman's Fellowship Integrates Tech Into Policy Brown CS Alum Irv Lustig Has Been Named An INFORMS Fellow A Brown CS Team Takes Third Place At The Thirteenth AIMMS-MOPTA Optimization Modeling Competition Brown CS Alum Scott A. Smolka Wins The 2021 Edsger W. Dijkstra Prize In Distributed Computing Learnable.ai, Founded By Brown CS Alum Guan Wang, Is Named A World Economic Forum Technology Pioneer Alum Dr. Barbara Gershon Ryder (Brown 1969) Wins NCWIT's Harrold And Notkin Research And Graduate Mentoring Award Diverse Career Paths: Brown CS Alum Sky Adams Aims To Increase Diversity In K-12 CS Diverse Career Paths: Brown CS Alum Sharon Lo Ponders How Products Can Harm Society Alum Entrepreneurs: Genevi\u00e8ve Patterson Brings AI-Powered Video Editing To Millions Diverse Career Paths: Brown CS Alum Karen Smith Catlin Helps Build Better Allies Diverse Career Paths: Brown CS Alum Morgan McGuire Makes An Impact In Academia And Industry Brown CS Alum Mneera Abdullah Saud Is A 2021 Rhodes Scholar Brown CS Alum's Charity Gives K-12 Teachers A Second Monitor To Help During COVID Brown CS Alums And Adjunct Faculty Win The Longuet-Higgins Prize And The PAMI Young Researcher Award Brown CS Students, Faculty, And Alums Publish Seven Papers At SIGMOD 2020 Brown CS Alum Jacob Beck Creates Aggregated Memory For Reinforcement Learning Brown CS Faculty And Alums Win Facebook Privacy Research Awards Brown CS Alum Thomas Dickerson Helps Replicate Brown In Minecraft For Virtual Visitors Brown CS Alum Feng-Hao Liu Wins An NSF CAREER Award New Research May Help Bring About Significant Blockchain Speedups Krishnamurthi And Multiple Alums Win An OOPSLA Most Influential Paper Award For Flapjax Brown CS Alum Evan Wallace Has Been Named An INC 2019 Rising Star Brown CS Alum Victoria Ch\u00e1vez \u201818 Makes An Impact On The Rhode Island Community Brown CS Alum danah boyd Wins An Electronic Frontier Foundation Pioneer Award Alum Aimee Lucido Publishes A Young Adult Novel About Her Two Loves: Coding And Writing Robert Sedgewick, Brown Alum And Former Faculty Member, Wins ACM's Outstanding Educator Award Alum Adventures: Brown CS Alums David Simons, Daniel Wilk, And Michael Natkin Have Won An Academy Award For Work On Adobe After Effects Brown CS Master's Alum Prabhat Breaks The Exaflop Barrier And Wins ACM's Gordon Bell Prize Servan-Schreiber, Riondato, And Zgraggen Have Been Named Runners-Up For ICDM's Best Student Paper Award danah boyd Has Been Named Among Forbes Top 50 Women In Tech Mentor Alum: Deb Mills-Scofield Inspires And Empowers Brown Students PhD Alum Jonathan Mace Earns Honorable Mention For The Dennis M. Ritchie Doctoral Dissertation Award Shriram Krishnamurthi And Collaborators Have Won The SIGPLAN Software Award For Work On Racket Alum Adventures: Harry Li Helps The Chan Zuckerberg Initiative Improve K-12 Education Alum Adventures: Andrew Ayer Keeps Certificate Authorities Honest With Certificate Transparency Brown CS Alum James Hendler Has Been Honored By The Association Of Moving Image Archivists Brown CS Alum Aimee Lucido Speaks Out About Industry Sexism Pedro Felzenszwalb And Alum David Blei Talk About AI With The ACM Alum Sarah Sachs Tackles Impostor Syndrome With A Little Help From Michelle Obama Brown CS Alum Hoon Ik Chang Has Been Named A 2017 Schwarzman Scholar Brown CS PhD Alums Continue To Impress Us With Their Various Accomplishments Brown CS Alum Sridhar Ramaswamy, SVP Of Advertising And Commerce At Google, Receives The Horace Mann Medal The Atlantic Features Brown CS Alum Lyla Fujiwara's Use Of CS In The Peace Corps Brown Alumni Magazine Features CS Alum Scott Anderson TechCrunch Features Former Student Dylan Field's Design Collaboration Tool, Figma Brown CS Alum Jack Stankovic Receives University Of Virginia's Distinguished Scientist Award Brown CS Alum Michael Horn '97 Wins An NSF Grant To Bring Programming To Museums And Homes \"I Learned A Different Definition Of Success\": Peter Norvig '78 Remembers Studying CS At Brown Brown Ranks #8 For Graduating Female Founders Of VC-Funded Companies LinkedIn Rates Brown CS #1 For Launching Graduates Into Successful Software Development Careers Brown Rated #3 In USA For Software Developers At Startups Alum Adventures: Brown CS Alums David Simons, Daniel Wilk, And Michael Natkin Have Won An Academy Award For Work On Adobe After Effects danah boyd Has Been Named Among Forbes Top 50 Women In Tech Brown CS Alums Jacob Beck And Zoe Papakipos Have Been Published In New Scientist For Work On Autonomous Driving Brown CS Alum Victoria Ch\u00e1vez \u201818 Makes An Impact On The Rhode Island Community", "https://blog.cs.brown.edu/2015/08/21/christian-mathiesen-and-teammates-take-first-place-linkedins-intern-hackday/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Christian Mathiesen And Teammates Take First Place At LinkedIn\u2019s Intern Hackday Posted by Jesse Polhemus on Aug. 21, 2015 Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . At LinkedIn\u2019s 5th Annual Intern Hackday this summer, Brown CS graduate student Christian Mathiesen and his teammates competed against 75 other teams to take first place and bring home the $10,000 grand prize scholarship. Their winning design, \u201cHandoff\u201d, is a Google Chrome extension that allows multiple users to share online accounts without compromising each individual\u2019s login information. Services currently supported by Handoff include Netflix, the New York Times , and HBO, among others. For Christian, the LinkedIn Hackday was a valuable extension of the community fostered by Brown CS. \u201cOur team consisted of students I had only known for a few weeks, but somehow we still managed to coordinate, plan, and build our product in less than 24 hours,\u201d he says. The consequent strong bond between team members is \u201cone of the reasons why the Brown CS community also encourages hacking,\u201d suggests Christian. \u201cIt\u2019s not about winning of the product itself. What matters most are the relationships you build.\u201d For Team Handoff, the relationship built during those 24 hours continues beyond the LinkedIn headquarters in Mountain View, California. The group is continuing development on the extension, rechristened \u201cAsterisks\u201d in honor of password fields, which will be released as a beta later this month. You can read more about the full extension on their website and/or download the extension directly from the Chrome Web Store . All five group members remain on board: Eric Brownrout (Northwestern), Clement Fung (Waterloo), George Lok (Harvard), Fernando Trujano (MIT), and Christian. Read more from the team members themselves over at Medium to hear how it all started with a GroupMe message. The official LinkedIn blog release can be found here . From left to right in the photo above: Akshay Kothari (VP of Product, LinkedIn) Christian Mathiesen (Brown), Fernando Trujano (MIT), Eric Brownrout (Northwestern), Matt Huang (Partner at Sequoia Capital), George Lok (Harvard), Clement Fung (Waterloo), James Beshara (CEO, Tilt)", "https://blog.cs.brown.edu/2015/09/11/read-more-community-outreach-connects-brown-cs-students-providence-area/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Read More: Community Outreach Connects Brown CS Students To The Providence Area Posted by Madeline DiGiovanni on Sept. 11, 2015 in Diversity Every year for decades, Brown CS has taught and inspired students in the greater Providence community through outreach to schools and summer programs. To learn more, click on these links: Brown CS Alum's Charity Gives K-12 Teachers A Second Monitor To Help During COVID Tellex's Outreach Inspires A High School Student To Study CS, Then Teach Brown CS Supports Brown's First Feminist Conference For RI High School Students Brown CS Brings An Hour Of Code To 130+ Kids Brown University Hosts Northeast Robotics Colloquium (NERC), Delights Scientists, Industry, And Children Students \"Bootstrap\" Algebra From Video Games Gryte Satas Creates Opportunities For Girls To Code Middle Schoolers get tour of Robotics Lab for Brown 250+ Celebrations Artemis Alum Keeps Looking For Opportunities To Code HCRI And RI Students Of The Future Present RI Robot Block Party, A Showcase Of Robots In Education, Research, Work, And Play Brown CS Sponsors Afterschool Program To Teach Programming To Middle-School Children Artemis 2013 Middle-schoolers are ready, ready, ready for programming adventure Photo courtesy of Brown CS", "https://blog.cs.brown.edu/2015/08/18/brown-ranks-8-graduating-female-founders-vc-funded-companies/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Brown Ranks #8 For Graduating Female Founders Of VC-Funded Companies Posted by Jesse Polhemus on Aug. 18, 2015 in Diversity For more stories on why Brown CS is so great, check out our Praise for Brown CS page here . Brown CS alumni continue to rank highly as industry pioneers. Click here for a list of related stories. CrunchBase has just concluded its first report on female founders of VC-funded companies. Among other findings, it reveals that their representation nearly doubled between 2009 and 2014. After adjustment based on overall enrollment, Brown ranks eighth in schools graduating female founders, eclipsing competitors such as Cornell University and New York University. The entire story is available here .", "https://blog.cs.brown.edu/2015/06/23/vrfocus-praises-yurts-boundless-potential/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) VRFocus Praises The Yurt's \"Boundless\" Potential Posted by Jesse Polhemus on June 23, 2015 For more CS News and CS Blog articles about the Yurt, please click here . Biology, math, computer science, archaeology, astronomy, art, poetry, and video gaming are just some of the areas that Peter Graham of VRFocus sees the Yurt (Brown University's new fully immersive 3D virtual reality environment) benefiting with its \"boundless\" uses. He notes the Yurt's improvements upon its predecessor, explaining how its ability to surround the viewer with imagery from all directions offers opportunities to numerous disciplines \"fully maximise [its] potential\" . VRFocus hopes to devote more of its coverage to the Yurt soon. The entire article is available here .", "https://blog.cs.brown.edu/2015/09/11/read-more-funding-successes-brown-cs-community-members/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Read More: Brown CS Community Members Continue To Win Noteworthy Grants And Awards Posted by Madeline DiGiovanni on Sept. 11, 2015 Brown CS community members continue to win noteworthy grants and awards. To read more, click on these links: Tim Kraska Is The Winner Of The University-Wide Early Career Research Achievement Award Maurice Herlihy Is The Winner Of The University-Wide Research Innovation Award Philip Klein Wins NSF Grant For Optimization In Planar Graphs And Beyond Sorin Istrail Receives NSF Grant For Haplotype Reconstruction Algorithms Ben Raphael and Eli Upfal Receive NSF Grant to Develop Techniques for Analysis of DNA Sequence Variants Stan Zdonik and Ugur Cetintemel Receive NSF Grant to Develop Data Management System for Massive Scale Scientific Data Sharp Labs Provides Grant to Andy van Dam and his Research Team Eli Upfal Receives Faculty Research Grant from Yahoo! Research Ben Raphael Awarded NIH Grant to Develop Computational Techniques to Study Structural Variation Ben Raphael Awarded NSF CAREER Grant Brown awarded $1.5M for new Big Data tools Jeff Huang Wins NSF CRII Grant And Salomon Award Philip Klein, Claire Mathieu and Ph.D. Alum Glencora Borradaile Receive NSF Grant to Develop New Algorithms for Solving Optimization Problems on Planar Networks BU, Brown and UC Irvine receive $3 million NSF grant Photo courtesy of Brown CS", "https://blog.cs.brown.edu/2015/09/11/read-more-brown-around-world/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Read More: Brown CS Around The World Posted by Madeline DiGiovanni on Sept. 11, 2015 In addition to advancing the field at a local and national level, Brown CS community members have a global impact on education and research. To read more, click on these links: Franco Preparata Will Be The Keynote Speaker At An Upcoming Coll\u00e8ge De France Symposium The Humans To Robots Lab Contributes To A New Exhibit At London's Science Museum Shriram Krishnamurthi Will Receive An Honorary Doctorate From Universit\u00e0 Della Svizzera Italiana Foreign Policy Magazine Names Tellex And Oberlin 2016 Global Thinkers John Savage Delivers Remarks On \"Cyberspace As A Medium\" At The Third World Internet Conference John Savage Meets With Vietnam\u2019s President And Thought Leaders To Improve The Country\u2019s Cybersecurity Esha Ghosh And Tarik Moataz Have Been Chosen For The 2017 IEEE Security And Privacy Student Program Committee Tim Edgar Talks With TIME About The Recent Widespread Internet Infrastructure Attacks John Savage Joins Boston Global Forum's Board Of Thinkers And Works To Combat Cyberattacks In Vietnam Seny Kamara Has Been Chosen As A Boston Global Forum Dukakis Fellow Tim Edgar Speaks Out On Behalf Of A Presidential Pardon For Edward Snowden Tim Edgar Travels To Germany To Testify In The Snowden Inquiry Congressional Quarterly Roll Call Documents John Savage's Contribution To A Historic International Cybersecurity Agreement Student\u2019s Senior Thesis Becomes Gates Foundation-Funded Project TAG (Touch Art Gallery): Student And Community Education With A Worldwide Impact John Savage's Recommendations For Securing Cyberspace Have Been Presented To The Japanese Government For The Upcoming G7 Summit New Opportunities In CS: An SMS-Based Commodity Exchange In Ghana The Atlantic Features Brown CS Alum Lyla Fujiwara's Use Of CS In The Peace Corps Encryption Can't Make 2+2=5, Says Anna Lysyanskaya In Le Nouvel Observateur Timothy Edgar Proposes A Review Of Europe's Counterterrorism Policies John Savage Is Awarded A New Patent And Travels To The Munich Security Conference John Savage's Participation At The World Internet Conference's Wuzhen Summit Airs On Chinese Television John Hughes Delivers An Invited Lecture At The Coll\u00e8ge De France Brown CS Finds A Unique Way To Celebrate Impressive Heidelberg Laureate Forum Representation Brown CS And CCMB To Enjoy Record Participation At ISMB 2014 Anna Lysyanskaya Offers Ukraine Commentary On WPRI Pascal Van Hentenryck Receives Docteur Honoris Causa from l'Universite de Nantes Brown University and National University of Singapore Launch Second Concurrent Degree Program Photo by LPLT / Wikimedia Commons", "https://blog.cs.brown.edu/2015/09/11/read-more-students-continue-excel-hackathons/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Read More: Brown CS Students Continue To Excel In Hackathons And Competitions Posted by Madeline DiGiovanni on Sept. 11, 2015 Brown CS students excel in hackathons and other competitions around the nation and have earned numerous accolades. To learn more, click the links below. (If you're looking for news about our students winning awards and fellowships, click here .) Brown CS Undergraduates Advance To The International Collegiate Programming Contest Nationals Brown CS Undergrads Take Third At ACM's International Collegiate Programming Contest Regionals And Advance To The Nationals David Armanious And Jared Siskin Are Among CyberStart's Top 10 Scorers Nationwide Brown CS TAs Of CS 15 Win Second Place At HealthHacks RI Hackathon Brown CS Students Make Another Strong Showing At The Third Annual Cyber 9/12 Student Competition Two Teams Will Represent Brown In Microsoft\u2019s Build The Shield Competition Two Brown CS Teams Win CyberSEED Prizes Brown CS Students Win Three Awards At HackMIT Christian Mathiesen And Teammates Take First Place At LinkedIn\u2019s Intern Hackday Cybersecurity: Brown Undergraduates Win It All Aaron Gokaslan \u201918 Wins HackPrinceton Best iOS App Award The Providence Journal Reports On \"Serious Innovation\" At Hack@Brown 2015 Chad Jenkins And His Team Help Develop NASA Software Hack@Brown 2nd Place Award For Software At HackPrinceton Goes To Aaron Gokaslan '18 And Laura Shea '18 Brown CS Takes First And Ninth Place At CyberSEED Cybersecurity Competition BrownCS Students Win Best Teamwork Award Nakul Gopalan, Eric Rosen, Daniel Ullman, And David Whitney Win The Hyuandai Visionary Challenge", "https://blog.cs.brown.edu/2015/10/26/michael-littman-interviewed-business-insider-about-robot-myths/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Michael Littman Interviewed By Business Insider About Robot Myths Posted by Jesse Polhemus on Oct. 26, 2015 When robots develop feelings, they're probably going to be hurt when they read this article. According to leading artificial intelligence experts, their field is widely misperceived by the general public, perhaps due to movie treatments where vengeful robots decide to turn on their human masters and conquer the planet. In an attempt to set the record straight, Guia Marie Del Prado of Business Insider interviewed Professor Michael Littman of Brown University 's Department of Computer Science and eighteen of his colleagues on the biggest myths about robots. You can read the entire article here .", "https://blog.cs.brown.edu/2015/11/10/we-need-value-each-other-msn-quotes-michael-littman-about-fears-robot-apocalypse/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) \"We Need To Value Each Other\": MSN Asks Michael Littman About Job Automation And Fears Of A Robot Apocalypse Posted by Jesse Polhemus on Nov. 10, 2015 \"My biggest concern at the moment,\" Brown CS Professor Michael Littman says, \"is that we as a society find a way of valuing people not just for the work they do.\" He was recently featured alongside other colleagues in an MSN article on job automation, and his response steps outside the usual questions of processor speed, machine learning, and the definition of sentience. The full article is available here . For more information, please click the link that follows to e-mail Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2015/10/15/i-learned-different-definition-success-peter-norvig-78-remembers-studying-cs-brown/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) \"I Learned A Different Definition Of Success\": Peter Norvig '78 Remembers Studying CS At Brown Posted by Jesse Polhemus on Oct. 15, 2015 Brown CS alumni continue to rank highly as industry pioneers. Click here for a list of related stories. \"Back then,\" Peter Norvig '78, now Director of Research at Google, says of his days at Brown, \"nobody owned their own computer, so people would congregate where the computers were and hang out late at night. There was a real sense of camaraderie. The best things were my fellow students and the faculty members. Some of them, like Professor of Computer Science Andy van Dam and Professor Emeritus of Applied Mathematics Ulf Grenander, are still around. I worked as a teaching assistant, and I learned more from that than from the classes themselves.\" Clarissa Clemm has just interviewed Peter for the Brown Daily Herald. In the wide-ranging piece, he looks back on the days in which \"nobody owned their own computer\", talks about his current work at Google, and even comments on the value of the UTA program. The full article is available here . The photo above is by Derrick Coetzee and used with permission under Creative Commons license.", "https://blog.cs.brown.edu/2015/09/12/read-more-yurtbrown/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Read More: The Yurt At Brown Posted by Madeline DiGiovanni on Sept. 12, 2015 The Yurt, Brown University 's newest 3D virtual reality environment, launched in 2015 and has earned worldwide praise. To read more, click on these links: From Medicine To Mars: Virtual Reality And The Future Of Data Visualization Seeing The World In A New Way: Channing Gray Explores The Yurt Brown Medicine Reports The Yurt To Be Part Of \"The Next Frontier\" In Training Surgeons, Planning Medical Treatment, And More A Brown University Undergraduate Uses The Yurt To More Intuitively Visualize Developmental Biology Tom Sgouros Brings The Yurt To Life For GPU Technology Conference Attendees National Science Foundation Director Visits Brown The NYT Steps Into Virtual Reality And Finds The Yurt \"Inspiring\" \"A Virtual World Ready To Be Utilized,\" Motif Magazine Raves About The Yurt Brown Daily Herald Takes Readers Into \"Another World\" Inside The Yurt Brown News Investigates The Yurt's Advantages For Scientific And Artistic Exploration \"The Future Of Virtual Reality Has Arrived,\" Providence's East Side Monthly Raves About The Yurt \"Dazzling\": The Boston Globe Attends The Yurt's Launch And Inaugural Symposium VRFocus Praises The Yurt's \"Boundless\" Potential Digital Den Cites Brown CS As A \"Well Recognized\" VR Leader Brown's Cave And Yurt Featured In RI NSF EPSCoR Magazine Learn About Yurt Optical Tracking Innovation In An 80-Second Video Visualization And Creativity In Immersive 3D Environments -- From Cave To YURT: May 20-21, 2015 #YurtAtBrown Photo courtesy of Brown CS", "https://blog.cs.brown.edu/2015/11/09/buzzfeed-puts-brown-top-25-most-beautiful-college-campuses-worldwide/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Buzzfeed Puts Brown In The Top 25 Most Beautiful College Campuses Worldwide Posted by Jesse Polhemus on Nov. 9, 2015 We are immensely proud to be part of Brown. For more articles on our parent university check out our Praise for Brown page here . From Australia to Africa to North America, only 25 colleges made Buzzfeed's list of the most beautiful campuses in the world, and Brown University was one of them. Sorry, MIT! The entire article is available here . For more information, please click the following link to e-mail Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2015/11/12/bdh-reports-rising-cs-enrollment-unique-apps-created-cs-students/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) BDH Reports On Rising CS Enrollment, Unique Apps Created By CS Students Posted by Jesse Polhemus on Nov. 12, 2015 To read more stories about the Brown CS department's increasing enrollment click here . Want to find food, collaborate on a song, or send secure, anonymous messages? There's a Brown CS -developed app for that. Today's issue of the Brown Daily Herald notes soaring Brown CS enrollment (over the last five years, our number of degrees awarded has risen by over 200 percent) and highlights four students who have created apps for iOS, Android, and even the new Apple Watch. You can read the full article here . For more information, please click the link that follows to contact Brown CS Communications Outreach Specialist Jesse C. Polhemus . The image above is by Cristiano Betta and used under a Creative Commons license.", "https://blog.cs.brown.edu/2015/11/11/erik-sudderth-and-collaborators-contribute-geoscience-algorithm-helps-predict-landslides/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Erik Sudderth And Collaborators Contribute To Geoscience With An Algorithm That Helps Predict Landslides Posted by Jesse Polhemus on Nov. 11, 2015 Following shortly after his recent contributions to seismic monitoring and nuclear non-prolifereation , Professor Erik Sudderth of Brown University 's Department of Computer Science and his collaborators have developed graph algorithms that use remote sensing data to predict where landslides are most likely to occur. Their work was published in the Journal of Geophysical Research: Earth Surface and was later chosen as a highlight article on EOS . Landslide prevention presents a massive computational task: hillsides are typically modeled as grids, often composed of millions of cells or blocks, each of which has properties such as soil depth, slope, and elevation. The endless possible permutations make determining how unstable cells are arranged enormously demanding, so Sudderth and his collaborators developed an algorithm that analyzes the properties of hillsides and identifies clusters of unstable blocks, which in turn allows analysis of a larger area. They tested their work on a virtual hillside and on data from an Oregon landslide, and in both cases, scientists were able to accurately predict the area and approximate side of the landslides. The paper is available here and the full highlight article is available here . For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2016/01/12/television-commercial-starring-michael-littman-reaches-millions-viewers-nationwide/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Michael Littman Stars In A Television Commercial That Will Reach Millions Of Viewers Nationwide Posted by Jesse Polhemus on Jan. 12, 2016 \u201cOrdinary people are being empowered,\u201d says Professor Michael Littman of Brown University \u2019s Department of Computer Science , \u201cin a way that makes the experts unnecessary.\u201d Coming from a thought leader whose research is helping create household gadgets that can be programmed in a user-friendly and natural way, it's not an unusual statement. Except in this case: he\u2019s talking about his appearance in a recent television commercial . This week, Michael has taken to the air alongside luminaries such as theoretical physicist Michio Kaku and Nobel laureate George Smoot to demonstrate the simplicity of a popular piece of income tax refund software. \"A member of the creative team for the commercial is a family friend,\" he explains, \"and asked for my help in finding notable geeks. I sent a list and slipped in my own name! They watched my [ popular series of YouTube videos using music to reinforce CS concepts and video of a winning performance on Dancing With The Profs with Quynh Tran ] and decided it was worth giving me a shot at it.\" What was the whole experience like? Micahel says, \"It's just such a wonderful opportunity to get a glimpse of another industry. The day of the filming felt like being part of a circus -- there were dozens of trucks and people and machines that all had to work together flawlessly on a very tight schedule. So much of it was planned out, but there were also parts that were incredibly spontaneous and creative. I was very impressed.\" The portrayal of academics as vast, benign, but slightly awkward intellects is interesting (the \"Michael Littman\" of the commercial puts his hand to his forehead to peer in a window and doesn't seem quite sure when to end the conversation with the person he's helping), but Michael finds it a \"balanced\" one. \"I think they're leveraging the perspective of academics as being very bright and talented,\" he explains. \"They use that idea to argue that this particular task, doing your taxes via a software program, doesn't require a high level of talent...Part of the humor comes from the idea that the ordinary people are being empowered in a way that makes the experts unnecessary.\" You can watch the commercial here . For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2015/12/28/providence-declared-best-city-raise-kids-america/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Providence Declared Best City To Raise Kids In America Posted by Monica Zuraw on Dec. 28, 2015 For more stories on why we love calling Providence home, check out our Praise for Providence page here . Destination Tips lists Providence, RI as the number one city to raise children in America. Its safe neighborhoods, historic attractions, and fun zoo are just a few aspects that make the city a great place for families. The entire article is available here . For more information, please click the following link to e-mail Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2015/12/27/datafox-lists-providence-one-2015s-best-cities-found-startup-outside-silicon-valley-and-new-york/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) DataFox Lists Providence As One Of 2015\u2019s Best Cities To Found A Startup Outside Of Silicon Valley And New York Posted by Monica Zuraw on Dec. 27, 2015 For more stories on why we love calling Providence home, check out our Praise for Providence page here . Our hometown, Providence, RI has just been listed as one of the best cities to found a startup. According to DataFox, t he key to Providence\u2019s success is specializing around existing strengths such as art, music, and social entrepreneurship. The low cost of living along with loan forgiveness further establishes Providence as a great city for entrepreneurs who want to start businesses in tech and design. The entire article is available here . For more information, please click the following link to e-mail Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2015/11/12/two-brown-cs-teams-win-cyberseed-prizes/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Two Brown CS Teams Win CyberSEED Prizes Posted by Jesse Polhemus on Nov. 12, 2015 in Awards Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . Recently, two teams from Brown University \u2019s Department of Computer Science extended Brown\u2019s reputation for cybersecurity excellence in a competition at the University of Connecticut, winning prizes for the second consecutive year. CyberSEED features competitive cybersecurity challenges for students and brings together top information security professionals and business leaders to discuss emerging cybersecurity trends and formulate best strategies for tackling current and future threats. This year, a team composed of Dan Haugh, Joshua Liebow-Feeser, Natalie Roe, and Frederick Rice competed in the Capture The Flag (CTF) competition, and a team composed of Kevin Cole, Aaron Gokaslan, and Abdullah Yousufi competed in the Social Engineering competition. Both teams ended the competition in fourth place and received a $3000 prize. They also received an award for being in third place at the end of the first day. \"The students did a great job,\" said Assistant Professor of the Practice Bernardo Palazzi, who coached both teams. \"I also want to recognize Josh and Freddie, who put in a lot of work organizing the teams.\" For more information, please click the link that follows to e-mail Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2016/01/27/new-course-build-next-generation-cs-entrepreneurs/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) A New Brown CS Course Aims To Build The Next Generation Of CS Entrepreneurs Posted by Monica Zuraw on Jan. 27, 2016 in Diversity The number of new startups launched in the US each year is quickly increasing and many successful ones have been founded by recent CS graduates. Current and future students may be wondering how they too can succeed with a startup of their own. Brown CS has this in mind with csciStartup , a new course offered this Spring 2016. The course, taught by Adjunct Assistant Professor John Jannotti , aims to help students overcome the mechanical hurdles of creating a startup and teach them the keys to designing products people want. John says he is very humbled to be teaching the course. \u201cThere are a ton of different aspects that go into running a business that I don\u2019t know everything about,\u201d he says. That\u2019s why he intends to break the course up into two different meetings per week: one where he can help teams directly with their products, and another where experts in different areas give guest lectures. \u201ccsciStartup is different from any other course at Brown because it is very product focused as opposed to just how to build a business,\u201d says John. \u201cThe goal is for each team to have a product ready to hit the ground running by halfway through the semester.\u201d Brown alum Evan Stites-Clayton thinks csciStartup will be really beneficial to students interested in starting a company of their own. Evan is the founder of the successful startup, Teespring, which makes designing and selling apparel easy. He says he would have enjoyed having the option to take a class like csciStartup while at Brown. \u201cIt would have been nice to have a community of other people working on startups and to have the ability to share resources and get advice from experts.\u201d For more information about this course go to http://cs.brown.edu/~jj/startup.html .", "https://blog.cs.brown.edu/2016/04/01/read-more-increased-enrollment/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Read More: More CS Majors And Increased Enrollment Posted by Monica Zuraw on April 1, 2016 To learn about how more and more Brown University students are majoring in CS and enrolling in our classes, click any of the links below: Brown CS Graduates A Record Number Of Undergrads: 39% Are Women Brown CS Addresses Growth and Student Support: Constraints and Challenges In A BDH Op-Ed BDH Cites Faculty Accessibility And Collaboration Even As Brown CS Grows To Become Brown's #1 Concentration More Brown Students Are Majoring In CS Than Any Other Subject Brown CS Is Graduating 38% More Undergraduates Than Last Year, With 232 Predicted to Graduate in 2017 BDH Reports On Rising CS Enrollment, Unique Apps Created By CS Students Brown CS Introductory Course Enrollment Sets Records Enrollment Soars: 1 In 5 Students Is Taking A Brown CS Course", "https://blog.cs.brown.edu/2016/04/14/bootstrap-expands-across-new-york-state-new-partnerships-aimed-enhancing-stem-education/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Bootstrap Announces A New STEM Education Model That Combines Computing, Modeling, And Physics Posted by Jesse Polhemus on April 14, 2016 Bootstrap , one of the nation's leading computer science literacy programs, co-directed by Brown CS faculty members Shriram Krishnamurthi and Kathi Fisler (adjunct), continues to extend its reach. Bootstrap has just announced a partnership to use its approach to building systems to teach modeling in physics, an important component of the Next Generation Science Standards (NGSS). This project is a collaboration with STEMTeachersNYC, the American Association of Physics Teachers, and the American Modeling Teachers Association. This new effort is part of the White House-inspired 100Kin10 initiative, which will create 100,000 new STEM teachers in ten years. A grant of $200,000 from 100Kin10 will fund this new collaboration. The project (\"Modeling Physics, Computational Thinking, and Bootstrap\") will help students learn computational thinking while learning basic physics concepts by writing programs to build models of the physical world. The two-year project will involve 20-24 teachers and reach about 1,000 students each year. It will equip teachers with a hands-on, inquiry-based pedagogy supported by a set of tested, engaging curriculum modules for classroom use. After the project period, all four project partners plan to promulgate the approach through professional development workshops for teachers throughout the country.", "https://blog.cs.brown.edu/2016/04/11/national-science-foundation-director-visits-brown/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) National Science Foundation Director Visits Brown Posted by Jesse Polhemus on April 11, 2016 by Kevin Stacey (Science News Officer, Physical Sciences) For more CS News and CS Blog articles about the Yurt, please click here . PROVIDENCE, R.I. [Brown University] \u2014 National Science Foundation Director France C\u00f3rdova and U.S. Sen. Jack Reed of Rhode Island joined students, faculty and administrators at Brown on April 8 for a firsthand look at some of the NSF-supported research happening at the University. The visit kicked off with a tour of Institute for Computational and Experimental Research in Mathematics (ICERM), Brown\u2019s NSF-funded mathematics center headquartered on South Main Street. Then it was off to College Hill for tours of the Institute at Brown for Environment and Society (IBES), the School of Engineering and the YURT, the University\u2019s immersive virtual reality theater. \u201cThis has been\u2026 a terrific visit,\u201d C\u00f3rdova said following the tour. \u201c[We] got to see a lot of different kinds of science and engineering that\u2019s going on [and] meet a lot of students and some of the award-winning faculty. Brown is just such a highly distinguished university doing quality research, so NSF is proud to support it.\u201d At an ICERM reception, C\u00f3rdova addressed a gathering of some 100 researchers and scholars, some of whom were visiting the institute for one of its weeklong workshops. C\u00f3rdova congratulated ICERM\u2019s leaders on the recent renewal of its NSF funding, a $17.5 million grant that will support activities for the next five years. The institute was founded in 2010 with $15.5 million from NSF. \u201cIt\u2019s one thing to get something off the ground\u2026\u201d C\u00f3rdova said. \u201cBut it\u2019s quite another thing to show that you have impact\u2026 And that\u2019s what ICERM has done.\u201d Jill Pipher, ICERM\u2019s director, discussed some of that impact in a meeting prior to the reception with C\u00f3rdova, Reed, Brown President Christina Paxson, Provost Richard Locke and members of the ICERM\u2019s board and directorate. The institute brings together some of the world\u2019s best mathematical minds to explore topics in pure and applied math, computer science and related disciplines. Recent programs have explored cybersecurity, climate modeling, data analytics and other emerging topics. Pipher discussed a workshop held this summer at ICERM focusing on predictive policing, the use of data and mathematical analysis to understand and predict patterns of criminal activity. The workshop was spawned by a public lecture on the mathematics of crime, hosted in late 2014. Several members of the Providence Police Department attended, and the department will supply some of the data that will be used at the upcoming workshop. The workshop is an example, Pipher said, of how ICERM\u2019s \u201coutreach and research go hand-in-hand.\u201d At IBES, C\u00f3rdova and Reed met with deputy directors Leah VanWey and Dov Sax, as well as researcher Meredith Hastings. Hastings described her work investigating the origin and extent of nitrogen pollution around the world, which has been funded in part by a CAREER award, NSF\u2019s premier honor for early-career faculty. Hastings landed her CAREER grant in 2014, and Brown has had a bumper crop of six new CAREER awardees so far in 2016. C\u00f3rdova said support for early-career researcher is an important part of what NSF does. \u201cNSF prides itself on being the first funder for many young people,\u201d she said. In addition to learning about NSF-funded research, C\u00f3rdova heard about IBES\u2019s approach to interdisciplinary study and engaged scholarship, which combines learning and research opportunities. Brown undergraduates Kari Malkki and Lovinia Reynolds discussed a project they have been working on that investigates strategies for reforesting a key ecological region in Brazil. At the School of Engineering, C\u00f3rdova and Reed met with Sorensen Family Dean Larry Larson and toured the Brown Design Workshop. The space provides students with access to 3-D printers, laser cutters and other tools for independent or class-related design and engineering projects. Also in engineering, C\u00f3rdova met with Daniel Mittleman and his students, whose NSF-supported research focuses on terahertz radiation. \u201cT-waves,\u201d as they are called, make up a relatively unexplored swath of the electromagnetic spectrum, but they may one day support wireless networks with many times the data capacity of current networks. Mittleman is developing the basic terahertz components that will be critical to constructing these next-generation networks. The tour wrapped up with a virtual reality demonstration in the YURT, an immersive facility built with the help of a $2 million NSF grant. Computer science professor David Laidlaw and his students showed Reed and C\u00f3rdova several examples of what the YURT can do. The demonstration included work from a collaboration between Laidlaw\u2019s students and Stephen Gatesy, an anatomist and evolutionary biologist at Brown. Gatesy studies fossilized footprints made by ancient dinosaurs, and he\u2019s worked with Laidlaw\u2019s students in developing 3-D animations of how those tracks may have been made. Laidlaw also discussed how Brown geoscientists use the YURT to study the surfaces of the Moon and Mars, helping to scout locations for potential spacecraft missions. \u201cIt\u2019s a wonderful tool for training, especially in environments\u2026 that are very difficult and expensive to get to,\u201d C\u00f3rdova said. \u201cVirtual reality brings those environments in where you can explore them.\u201d At the conclusion of the visit, Reed stressed the importance of research and development investments to the Rhode Island economy. \u201cIt\u2019s something we have to do to maintain our technological edge and ultimately create the jobs of the next century,\u201d Reed said. \u201cWithout the NSF, we wouldn\u2019t be able to do that.\u201d", "https://blog.cs.brown.edu/2016/05/04/rediscovered-video-documents-browns-revolutionary-1976-use-hypertext-education/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) A Rediscovered Video Documents Brown University's Revolutionary 1976 Use Of Hypertext In Education Posted by Jesse Polhemus on May 4, 2016 Already being described as \"astounding\" and \"visionary\" as it makes its way across the Internet, a short film from forty years ago (\"Hypertext: an Educational Experiment in English and Computer Science at Brown University \") has just surfaced after being lost for decades. It documents an extraordinary early use of computing to enhance the learning experience of students taking a poetry course in 1976. Speaking to us from an era more familiar to the parents of today's digital natives, Professor Andy van Dam of the Department of Computer Science and his collaborators demonstrate the use of responsive software, computer-enabled social learning, and hyperlinks that supplement primary texts with additional material. Seeing the affordances of modern computing made available to the college students of 40 years ago is striking: what's perhaps even more remarkable is the thoughtful analysis and keen insight with which van Dam and his colleagues and students ponder the potential of this \"creative graffiti\" and its impact on education and discourse. Poetry indeed! The film is available here . For more information, please click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2016/05/05/interdisciplinary-team-brown-wins-award-mit-grand-hack-2016/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) An Interdisciplinary Team Including Multiple Brown CS Students Wins An Award At MIT Grand Hack 2016 Posted by Jesse Polhemus on May 5, 2016 in Awards A team that included multiple students from Brown University 's Department of Computer Science (Brown CS) has just won the Best Aging in Place Hack award at MIT's Grand Hack 2016. Inspired by a mentor whose mother suffers from Alzheimer's disease, Sven Eberhardt (Brown University postdoc), Youssef Barhomi (Brown University research engineer), Pankaj Gupta (Brown University research assistant), Nediyana Daskalova (Brown CS PhD candidate), Adrienne Tran (Brown University alum and founder of Neurocurious), and Alejandro Scaffa (Brown University PhD candidate) formed team \"alzEYEmers\" to create a unique solution based on computer vision, AI, and neuroscience. Their project leverages software that can recognize common household objects as well as hazards, then supplies an Alzheimer's patient with a camera worn around the neck. During any unattended hours, the camera serves as a watchdog: if it spies a hazard (for example, a fire), it can redirect the patient with recorded prompts, alert a family member, or even call 911. \"This was a very different hackathon from others I've been to,\" says Nediyana, \"The idea was to talk to many people from diverse backgrounds in order to think about the problem from various points of view before solving it. We spoke to six different people about their experiences with Alzheimer's before we even began hacking. We really found it interesting to spend so much time thinking about a problem before jumping to a technological solution.\" For more information, please click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2016/05/12/john-savages-recommendations-securing-cyberspace-have-been-presented-japanese-government-upcoming-g7-summit/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) John Savage's Recommendations For Securing Cyberspace Have Been Presented To The Japanese Government For The Upcoming G7 Summit Posted by Jesse Polhemus on May 12, 2016 As the G7 Summit, one of the most important and wide-reaching global conferences for trade, climate change, health, and other issues approaches, Professor John Savage of Brown University 's Department of Computer Science (Brown CS) has once again found his cybersecurity expertise in demand. Boston Global Forum (BGF), chaired by former governor Michael Dukakis, was founded to bring together thought leaders and experts from around the globe to participate in open public forums to discuss and illuminate the most critical issues affecting the world at large. In February, their CEO, Tuan Nguyen, asked John to address BGF and prepare an agenda for the G7 Summit, which will be hosted by the government of Japan in Ise-Shima National Park on May 26 and 27. He did so, later working with other individuals affiliated with BGF to develop his presentation into a formal proposal. At the Harvard Club on Monday, BGF met via teleconference with representatives of the Japanese government to discuss the BGF proposals for the G7 Summit Initiative. A video is available here (John's presentation begins twelve minutes in), and the proposal is available in PDF form here . For more information, please click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2016/05/09/undergraduates-share-unique-projects-their-second-research-symposium/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Undergraduates Share Unique Projects At Their Second Research Symposium Posted by Monica Zuraw on May 9, 2016 Brown CS undergraduates recently showcased their hard work at the second annual research symposium. A panel of judges viewed their research projects, and the top three were awarded prizes. \u201cThis symposium is extraordinary,\u201d said one of the judges, Professor Sorin Istrail. \u201cWe are surrounded by a very unique group of students here. They have shown an amazing amount of growth and passion.\u201d The research projects spanned a wide variety of interesting topics. Sam Kortchmar is a singer, but has trouble reading music. He created a solution to this problem by finding a way to learn music through visualization where you can essentially \u201cfly through\u201d the song in virtual reality. \u201cResearching as an undergraduate is a great way to build relationships with professors,\u201d says Sam. \u201cThey can become great role models.\u201d Another one of the undergrads, Advik Iyer Guha, says, \u201cIt is one of the best ways to truly find out if you are passionate enough about a problem or if you want to do a PhD.\u201d His research project focused on finding ways to improve human-robot collaboration with object placement. The three winning projects included Julia Romanski\u2019s process for improving large-scale evacuations during natural disasters, Daniel Seidman\u2019s method for time efficient determination of identical by descent tracts between unphased genotypes, and Emily Wu\u2019s social feedback for robotic collaboration. \u201cThis was definitely the most fun and challenging thing I have done at Brown,\u201d said Emily. \u201cIt gave me a great taste of self-directed study.\u201d For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2016/05/16/providences-risd-museum-tops-architectural-digests-list-americas-best-university-art-museums/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Providence's RISD Museum Tops Architectural Digest's List Of America's Best University Art Museums Posted by Jesse Polhemus on May 16, 2016 For more stories on why we love calling Providence home, check out our Praise for Providence page here . The interdisciplinary academic possiblities to having the Rhode Island School of Design (RISD) as a next-door neighbor are beyond price, but you know what else is pretty niftt? Waving your Brown University ID and walking into a museum that Architectural Digest just called \"the best university art museum in America\". Their permanent collection, ranging across every medium imaginable, contains more than 100,000 objects. The full list is available here . For more information, please contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2016/05/16/travel-and-leisure-calls-providence-americas-third-favorite-city/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Travel And Leisure Calls Providence America's Third Favorite City And Second Best For Food Posted by Jesse Polhemus on May 16, 2016 For more stories on why we love calling Providence home, check out our Praise for Providence page here . The grilled pizza? The coffee milk? The food trucks? The fact that we arguably invented the food truck in 1872? (It was a horse-drawn lunch cart.) It's enough for Travel and Leisure to declare Providence their third favorite city in America and the second best for foodies, leaving behind Chicago, New Orleans, Portland, and dozens of others. The full lists are available here and here . For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2016/06/14/amy-greenwald-helps-coordinate-inaugural-artificial-intelligence-social-good-conference/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Amy Greenwald Helps Coordinate The Inaugural Artificial Intelligence For Social Good Conference Posted by Jesse Polhemus on June 14, 2016 in Diversity Professor Amy Greenwald of Brown University 's Department of Computer Science (Brown CS), along with colleagues from Harvard University, the Computing Community Consortium, the White House Office of Science and Technology Policy, and other organizations, have just returned from the successful Artificial Intelligence for Social Good conference, which they co-organized. Held in Washington, DC, the event discussed the successful deployments and the potential use of AI in various topics that are essential for social good, including but not limited to urban computing, health, environmental sustainability, and public welfare. Amy and the other organizers are presently engaged in preparing a report summarizing the workshop for use by the OSTP as they shape future technology policy. For more information, please click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2016/06/01/professor-eli-upfals-research-group-publishes-three-successful-papers/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Professor Eli Upfal\u2019s Research Group Publishes Three Papers Posted by Monica Zuraw on June 1, 2016 Three papers from Professor Eli Upfal\u2019s research group were recently accepted to Knowledge Discovery and Data Science (KDD\u201916), a top-tier conference in the Big Data research community. A total of 784 papers were submitted to the conference, of which 70 were accepted as full papers and 72 were accepted as poster papers. Eli\u2019s group had two full papers and one poster paper accepted, which is a major achievement. TRIEST: Counting Local and Global Triangles in Fully-dynamic Streams with Fixed Memory Size was a joint publication between Lead Researcher and Brown University PhD Candidate Lorenzo De Stefani, Alessandro Epasto , Matteo Riondato, and Eli. The paper tackles the problem of triangle counting in large massive graph. Their work proposes a new algorithm based on adaptive sampling, which provides high quality approximations of the number of triangles in large networks with probabilistic guarantees. ABRA: Approximating Betweenness Centrality in Static and Dynamic Graphs with Rademacher Averages was co-written by Lead Researcher and Visiting Assistant Professor Matteo Riondato and Eli. The algorithm, ABRA, uses progressive random sampling, which allows it to automatically determine when the obtained approximation has the required quality. In their experimental evaluation, ABRA proved to be much faster than existing state-of-the-art methods. (On September 9, Two Sigma published an online article on ABRA here .) The last paper, Scalable Betweenness Centrality Maximization via Sampling, was written by Lead Researcher and Brown CS PhD Candidate Ahmad Mahmoody , Charalampos Tsourakakis, and Eli. In their work, they considered an extension of the classic betweenness centrality problem, where the goal was to find the most central \"group\" of nodes of a given size. Their method improved the state of the art algorithm by using a more efficient sampling algorithm, and provided a better theoretical guarantee. \u201cI think good team work is a great tool to both increase the quality of the work and maintain high motivation which is then bound to lead to good results,\u201d says Lorenzo when asked why Eli\u2019s research group was so successful in getting their work published. \u201cA well-functioning research group offers the possibility of having other qualified people to bounce off ideas and challenge your understanding of topics. Further, it is a chance of learning new skills working alongside other talented and motivated people.\u201d For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2016/05/19/brown-undergrad-uses-yurt-more-intuitively-visualize-developmental-biology/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) A Brown University Undergraduate Uses The Yurt To More Intuitively Visualize Developmental Biology Posted by Jesse Polhemus on May 19, 2016 For more CS News and CS Blog articles about the Yurt, please click here . Accelerating into its second year of operation, the YURT ( Brown University 's latest 3D virtual reality environment) is adding another entry to the list of fields that have benefited from its capabilities: embryonic developmental biology. Rhode Island NSF EPSCoR, a local branch of the National Science Foundation's experimental program to stimulate competitive research, reports on the work of Brown University student Beatrice Steinert, who set out to document and study the embryonic developmental stages of the slipper snail. Beginning her research with no preconceptions of what she might find, Beatrice (guided by Professor Kristi Wharton, who had used the YURT's predecessor, the CAVE) sought out the Yurt's \"mind-blowing\" tools, using it to manipulate a virtual embryo in 3D: flying over it, rotating it, and even stepping inside. \u201cVisualizing embryos in the YURT allows you to more intuitively understand what is going on,\" she says, \"how cells in the embryo are arranged, and to see things you might not be able to otherwise. And, you can compare models to see how cells have moved or what an experimental manipulation has changed...With a microscope, there is a barrier between you and the embryo. In the YURT, you can just pick it up and turn it around and look.\" Beatrice mentions that she's also interested in the Yurt's possibilities in teaching developmental biology due to the highly visual and spatial nature of the field and the processes through which embryos develop. The full article is available here . For more information, please click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2016/06/22/bootstrap-sells-out-its-june-27-cs4ri-workshop/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Bootstrap Sells Out Its June 27-29 CS4RI Workshop Posted by Jesse Polhemus on June 22, 2016 Bootstrap is a computer science literacy curriculum used worldwide by 10,000 students whose founders include two Brown CS faculty members, Kathi Fisler (adjunct) and Shriram Krishnamurthi . Recently cited by the White House for its efforts to improve the inclusiveness, accessibility, and reach of computer science education , it continues to expand globally, nationally, and within its home state, most recently as part of Governor Gina Raimondo's CS4RI program. Developed in response to President Obama's landmark Computer Science For All initiative, which calls for CS educational funding for all students nationwide, CS4RI is designed to bring computer science to every school in Rhode Island by 2018. Bootstrap is one of the two most popular programs that CS4RI offers to teachers. Next week, as part of CS4RI, Bootstrap is looking forward to a fully-attended workshop on June 27-29. Teachers from every public middle school and high school were eligible to participate, and more than forty enrolled, causing the event to sell out.", "https://blog.cs.brown.edu/2017/05/18/erway-kupcu-papamanthou-tamassia-earn-4-rank-2009-security-papers/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Erway, K\u00fcp\u00e7\u00fc, Papamanthou, Tamassia Earn The #4 Rank For 2009 Security Papers Posted by Jesse Polhemus on May 18, 2017 Click the links that follow for more Brown CS content about C. Christopher Erway , Alptekin K\u00fcp\u00e7\u00fc , Charalampos Papamanthou , and Roberto Tamassia . Professor Konrad Rieck of Technische Universit\u00e4t Braunschweig has released a list of Influential Security Papers, and research (\"Dynamic Provable Data Possession\") from Brown CS PhD alums C. Christopher Erway (now Chief Architect of the SolarWinds Monitoring Cloud), Alptekin K\u00fcp\u00e7\u00fc (now Assistant Professor at Ko\u00e7 University), and Charalampos Papamanthou (now Assistant Professor at University of Maryland, College Park) and Plastech Professor of Computer Science Roberto Tamassia has earned the #4 spot for papers published in 2009. It's also the 50th most cited paper since 1981. The list ranks papers published at the four top-tier security conferences, and their work, originally presented at the ACM Conference on Computer and Communications Security (CCS) has received 907 cites at Google Scholar, putting it 476% above that year's average. The research was completed while Christopher, Alptekin, and Charalampos were PhD students at Brown CS, and it resulted in an issued patent. The full list is available here . For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2016/07/06/brown-cs-student-accomplishments/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Recent Accomplishments By Brown CS Students Posted by Jesse Polhemus on July 6, 2016 For more stories on why Brown CS is a great place to study, check out our Praise For Brown CS page . On any given week, Brown CS students are designing apps to improve parking or combat cancer, earning fellowships from Google and Y Combinator, launching their own hackathons and research symposia, and reaching out into their communities to increase the diversity of our field. These are their stories from recent years: click any link below to read the full article. 2024 Four Brown CS Students Receive CRA Outstanding Undergraduate Researcher Honors Yong Zheng-Xin, Cristina Menghini, And Stephen Bach Earn A Socially Responsible Language Modelling Research (SoLaR) Best Paper Award Brown CS Student Mattie Ji Is A Runner-Up For The Schafer Prize For Excellence In Mathematics By An Undergraduate Woman Brown CS Student Artem Agvanian And Alum Hannah Gross Earn First And Second Place SOSP Student Research Honors 2023 Brown CS Researchers Use Virtual Reality To Control A Robot Proxy With Natural Movements Brown CS Student Joshua Yang Earns First-Place At The ACM CHI \u201823 Student Research Competition Brown CS Student Angel Arrazola Builds A Positive Learning Environment For Providence Middle School Students Brown CS Joint Concentrator Lucas Brito Earns A Goldwater Scholarship WIRED Asks A New Brown CS Research Group About Multilingual Large Language Models Twenty-Seven Students Win 2023 Brown CS Senior Prizes Brown CS Undergraduates Advance To The International Collegiate Programming Contest Nationals Anh Truong And Qiuhong Anna Wei Win The Randy F. Pausch Computer Science Undergraduate Summer Research Award Brown CS Student Rachel Ma Receives A CRA Outstanding Undergraduate Researcher Honorable Mention 2022 Tassallah Amina Abdullahi Wins An ACM SIGHPC Computational and Data Science Fellowship Five Brown CS Students And Alums Receive NSF Graduate Research Fellowships Brown CS PhD Student Denizalp Goktas Becomes A 2022 J.P. Morgan PhD Fellow Kaiyu Zheng, George Konidaris, And Stefanie Tellex Of Brown CS Win The IROS RoboCup Best Paper Award 2021 Brown CS PhD Student Fumeng Yang Wins The Computing Innovation Fellowship 2021 A Brown CS Team Takes Third Place At The Thirteenth AIMMS-MOPTA Optimization Modeling Competition Wrenn, Nelson, And Krishnamurthi Win The <Programming> Editors' Choice Award Brown CS Student Aric Zhuang Wins $15,000 At This Year's Brown Venture Prize Leonhard Spiegelberg Wins A Facebook Fellowship Twenty-Two Students Win Brown CS Senior Prizes Cousins, Lim, Martinez, Wrenn, And Zamanian Win University And ACM Distinctions Ross Briden And Zachary Espiritu Win The Randy F. Pausch Computer Science Undergraduate Summer Research Award Kamara, Moataz, Park, And Qin Explore Possibilities For An Ultra-Secure Gun Registry 2020 Brown CS Students Create A Futuristic Art Exhibition Brown CS Holds Our 5th Annual Research Open House (Recording Available) Full Stack At Brown\u2019s First Hackathon, Datathon, And CTF: Hack@Home Brown CS PhD Student Brandon J. Woodard Wins The NASA RI Space Grant Fellowship Brown CS Students, Faculty, And Alums Publish Seven Papers At SIGMOD 2020 Brown And RISD Undergrads Win A $40K Challenge By MassRobotics Seventeen Students Win Brown CS Senior Prizes PhD Student Jinq Qian And Adobe Add AR Annotations To Physical Documents PhD Student Lucy Qin Receives An NSF Graduate Research Fellowship Brown CS Undergraduate Nishanth Kumar Has Been Named A 2020 Barry M. Goldwater Scholar Deep Learning Day Showcases Student Research Into Adversarial Networks, Sentiment Analysis, And More Brown CS Undergraduate Nishanth Kumar's Student Abstract Has Been Accepted At AAAI-20 Areyan And Greenwald Take Second Place In The International Automated Negotiation Agents Competition Brown CS Undergraduates Dai And Bermudez-Silverman Present Their Work At The Inaugural AAAI Undergraduate Consortium Kai Wang Wins An Adobe Research Fellowship Bayazit, Galgana, Kumar, And Safranchik Win CRA Outstanding Undergraduate Researcher Honorable Mentions 2019 Undergrad Nishanth Kumar Wins Best Plenary Presentation At ILURS Brown CS Undergraduate Atsunobu Kotani Teaches Robots Handwriting And Drawing David Abel Wins A Presidential Award For Excellence In Teaching Evgenios Kornaropoulos Wins The Joukowsky Family Foundation Outstanding Dissertation Award Twenty-Seven Students Win Brown CS Senior Prizes Jiwon Choe Wins The Memsys Best Student Presentation Award Brown CS Student Liyaan Maskati Wins The Association For Women In Mathematics Student Essay Contest For Writing About Ellie Pavlick Fong, Ren, And Weir Win CRA Outstanding Undergraduate Researcher Honorable Mentions 2018 Pombrio, Krishnamurthi Win The PLDI Distinguished Artifact Award For Inferring Rule Types For Syntactic Sugar Brown CS Students Advance To The Second Round Of The Cyber 9/12 Competition Lauren Ho And Nina Polshakova Earn KPCB Fellowships Building News4Good: A First Take At Software Engineering For Four Undergrads Karamcheti, Porncharoenwase, And Rosen Win CRA Outstanding Undergraduate Researcher Honorable Mentions igniteCS @ Brown Kamara, Moataz, And Zhu Use Structured Encryption To Create Pixek, Offering Searchable Privacy For Digital Photos Seeing Theory: Teaching Statistics Through Interactive Web-Based Visualizations Toymaker: A New Seven-Minute Animated Short From Brown CS Novotny And Collaborators Win The VIS Best Poster Award For Visualizing Dinosaur Tracks Natalie Reed Becomes Brown's Tenth Google Women Techmakers Scholar Martha Edwards And Kalvin Lam Win hackNY Fellowships 2017 David Armanious And Jared Siskin Are Among CyberStart's Top Scorers Nationwide New Software From Rosen And Whitney Allows Virtual Reality Control Of Robots Meta-TA Zach Kirschenbaum Helps Represent Brown CS At The Out For Undergraduate Tech Conference Brown Students Win Best Data Visualization Prize At HackMIT Alum Tushar Bhargava Wins A 2017 Undergraduate Award For Work With Tim Edgar The NYT Asks Brawner And Krishnamurthi About CSCI 0030 And Teaching Computational Thinking Arumugam, Karamcheti, Gopalan, Wong, Tellex Help Robots Follow Spoken Commands Esha Ghosh Wins An Inaugural Microsoft Research Dissertation Grant Tiffany Chen Has Been Named A Women Techmakers Scholar Look Where Our 2017 Graduates Are Headed! Brown CS Returns To The Cyber 9/12 Student Challenge Geopipe, Co-Founded By Thomas Dickerson, Wins $100K At The NYU $300K Entrepreneurs Challenge Twelve Brown CS Students Will Be Recognized For Their Achievements With The Senior Prize In Computer Science Markell, Picard, And Tipperman Earn KPCB Fellowships, Setting A Brown CS Record Sorawee Porncharoenwase Wins The Randy F. Pausch Computer Science Undergraduate Summer Research Award Connor Gramazio Will Give An Invited Talk At OpenVis Conf Alexandra Papoutsaki Lands A \"Dream Job\" At Pomona College Tellex, Rosen, And Whitney Use Social Feedback To Help Robots Fetch Objects Intelligently Krishnamurthi And Quay-de la Vallee Look At App Store Insecurity In Fast Company 2016 Sarah Sachs Wins A Distinguished Senior Thesis Prize The Thinking Behind Startup@Brown Pombrio And Krishnamurthi's Work Has Been Selected As One Of ACM SIGPLAN ICFP's Best Papers Professor Eli Upfal\u2019s Research Group Publishes Three Papers Student\u2019s Senior Thesis Becomes Gates Foundation-Funded Project Papoutsaki, Laskey, Huang Advance Eye Tracking Through Webcam, Browser-Based Democratization Andrew Crotty Wins A Google PhD Fellowship TAG (Touch Art Gallery): Student And Community Education With A Worldwide Impact Brown CS Student Youn Kim Is Awarded A Presidential Fellowship At MIT A Brown University Undergraduate Uses The Yurt To More Intuitively Visualize Developmental Biology GeekWire Reviews James MacGlashan And Michael Littman's Work With Training Virtual Agents Like Dogs New Opportunities In CS: An SMS-Based Commodity Exchange In Ghana Undergraduates Share Unique Projects At Their Second Research Symposium Krishna Chaitanya Aluru Wins A Y Combinator Fellowship An Interdisciplinary Team Including Multiple Brown CS Students Wins An Award At MIT Grand Hack 2016 csciStartup Students Develop A Solution To The Horrors Of Parking In Providence With Their New App \u201cSpotter\u201d David Abel Has Been Selected For Brown's Highly Competitive Open Graduate Education Program Brown CS Students Make Another Strong Showing At The Third Annual Cyber 9/12 Student Competition Two Teams Will Represent Brown In Microsoft\u2019s Build The Shield Competition MIT Technology Review Includes Research From The Humans To Robots Laboratory In Its 2016 Ten Breakthrough Technologies \"Inclusiveness And Learning, Rather Than Competition And Prestige\": Three Years In, Hack@Brown Is Bigger And More Diverse Than Ever Jonathan Mace Receives A Facebook Graduate Fellowship 2015 Stefanie Tellex And John Oberlin's Award-Winning Video Earns Brown CS A New Baxter Robot Touch Art Gallery (TAG) Expands Worldwide With A Nobel Museum/Nobel Media Collaboration Mace, Roelke, And Fonseca Win A Best Paper Award At SOSP 2015 Crotty, Galakatos, Zgraggen, Binnig, And Kraska Win Best Demo At VLDB 2015 Four Brown CS Students Recognized As 2015 Google Scholars Brown CS Uses Minecraft To Unboggle The Robot Mind Esha Ghosh, Olya Ohrimenko, And Roberto Tamassia Win The ACNS 2015 Best Student Paper Award Research By Undergraduate Sarah Sachs Gets Attention From Wired, The Today Show, And Others Multiple Brown CS Collaborators Win Two Best Paper Award Runner Up Honors At HCOMP 2015 MIT Tech Review Reports On Oberlin And Tellex's Work In Robot Object Manipulation Touch Art Gallery's Digital Museum Experiences Featured In Campus Technology BDH Reports On Rising CS Enrollment, Unique Apps Created By CS Students Two Brown CS Teams Win CyberSEED Prizes Slashdot And MIT Technology Review Cover A Brown/Cornell Collaboration That Allows Robots To Teach Robots PhD Student Ashley Conard Interviewed About GHC By SiliconANGLE Brown CS Continues Strong Levels Of VIS Participation Oberlin, Meier, Kraska, And Tellex's \"Acquiring Object Experiences At Scale\" Featured On CCC's \"Great Innovative Ideas\" Brown CS HackMIT Winners Featured In Times Square Students Hone Business Ideas At Startup Conference Brown CS Students Win Three Awards At HackMIT Startup@Brown (9/26-27) Brings Together Innovative Startups And Talented Students MongoDB Intern Spotlight Features Benjamin Murphy '18 Christian Mathiesen And Teammates Take First Place At LinkedIn\u2019s Intern Hackday Leiserson, Raphael, And Brown CS Colleagues Create A Web App To Help Researchers Explore Cancer Genetics \"I Had To Hire Henry\": The New Yorker Documents A Brown CS Student's \"Hacking The Humanities\" MIT Technology Review, Smithsonian, And Others Cover The Tellex Lab's Minecraft AI Project Jonathan Mace And Rodrigo Fonseca Develop \"Retro\" To Improve Server Resource Management For Big Data 2nd Place Award For Software At HackPrinceton Goes To Aaron Gokaslan '18 And Laura Shea '18 Brown CS Launches Inaugural Undergraduate Computer Science Research Symposium Cybersecurity: Brown Undergraduates Win It All Michael Chang Wins KPCB Fellowship Victor Naroditskiy PhD '09 Demonstrates Crowdsourcing's Vulnerability To Malicious Behavior East Side Monthly Recognizes Gryte Satas's Efforts In Closing The Gender Gap The Providence Journal Reports On \"Serious Innovation\" At Hack@Brown 2015 Gryte Satas Creates Opportunities For Girls To Code Dana\u00eb Metaxa-Kakavouli Selected As Runner-Up For CRA Award Algorithm Identifies Networks Of Genetic Changes Across Cancers", "https://blog.cs.brown.edu/2016/08/22/fodors-new-england-cites-humanity-centered-robotics-initiative/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Fodor's New England Cites The Humanity-Centered Robotics Initiative Posted by Jesse Polhemus on Aug. 22, 2016 We are immensely proud to be part of Brown. For more articles on our parent university check out our Praise for Brown page here . The size of a travel guide is necessarily limited by the tourist's ability to carry yet another object while exploring or cram it into an overflowing backpack. In the latest edition of Fodor's New England , Brown University gets a mere thirteen lines that mention the university's 40 academic departments, its Gothic and Beaux-Arts structures, the List Art Center, the Haffenreffer Museum of Anthropology. But among the perhaps more expected entries is a noteworthy endorsement for HCRI : \"The Humanity-Centered Robotics Initiative's Robot Block Party, held in April, celebrates robots and how they are being used to solve the world's problems.\" For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2016/10/27/brown-cs-tas-cs-15-win-second-place-healthhacks-hackathon/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Brown CS TAs Of CS 15 Win Second Place At HealthHacks RI Hackathon Posted by Jesse Polhemus on Oct. 27, 2016 Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . At many hackathons, teams assemble according to shared interests among people who have just met. It's part of the appeal. But sometimes, you just want to hack with people that you already love working with. Two weeks ago, the TAs of CS 15 (Katie Chu, Grant Fong, Sarah Kim, Hannah Tipperman, Adrian Turcu, and Zach Kirschenbaum, all sophomores) formed a team called \"The Balcony\" and took second place at HealthHacks RI, a 48-hour hackathon focused on issues in health, wellness, diet/nutrition, and aging. Working alongside fellow students, engineers, researchers, physicians, entrepreneurs, mentors, and others, the Brown CS team's challenge was to create a solution for the health and wellness industry. Their answer was an iOS app called CareConnect that helps streamline communication between caregivers and family. In addition to bragging rights, their second place finish earned them a $1000 prize.", "http://burlap.cs.brown.edu": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc About The Brown-UMBC Reinforcement Learning and Planning ( BURLAP ) java code library is for the use and development of single or multi-agent planning and learning algorithms and domains to accompany them. BURLAP uses a highly flexible system for defining states and and actions of nearly any kind of form, supporting discrete continuous, and relational domains. Planning and learning algorithms range from classic forward search planning to value function-based stochastic planning and learning algorithms. Also included is a set of analysis tools such as a common framework for the visualization of domains and agent performance in various domains. BURLAP is licensed under the permissive Apache 2.0 license. For more background information on the project and the people involved, see the Information page. Where to git it BURALP uses Maven and is available on Maven Central! That means that if you'd like to create a project that uses BURLAP, all you need to do is add the following dependency to the <dependencies> section of your projects pom.xml edu.brown.cs.burlap burlap 3.0.0 and the library will automatically be downloaded and linked to your project! If you do not have Maven installed, you can get it from here . You can also get the full BURLAP source to manually compile/modify from Github at: https://github.com/jmacglashan/burlap Alternatively, you can directly download precompiled jars from Maven Central from here . Use the jar-with-dependencies if you want all dependencies included. Prior versions of BURLAP are also available on Maven Central, and branches on github. Tutorials and Example Code Short video tutorials, longer text tutorials, and example code are available for BURLAP.All code can be found in our examples repository, which also provides the kind of POM file and file sturcture you should consider using for a BURLAP project. The example repository can be found at: https://github.com/jmacglashan/burlap_examples/ Video Tutorials Written Tutorials Hello Grid World! - a tutorial on acquiring and linking with BURLAP Building a Domain Using Basic Planning and Learning Algorithms Creating a Planning and Learning Algorithm Solving Continuous Domains Building an OO-MDP Domain Documentation Java documentation is provided for all of the source code in BURLAP. You can find an online copy of the javadoc at the below location. http://burlap.cs.brown.edu/doc/index.html Features Current A highly felixible state representation in which you define states with regular Java code and only need to implement a short interface. This enables support for discrete, continuous, relational, or any other kind of state representation that you can code! BURLAP also has optional interfaces to provide first class support for the rich OO-MDP state representation [1]. Supported problem formalisms Markov Decision Processes (single agent) Stochastic Games (multi-agent) Partially Observable Markov Decision Processes (single agent) Tools for visualizing and defining visualizations of states, episodes, value functions, and policies. Tools for setting up experiments with multiple learning algorithms and plotting the performance using multiple performance metrics. An extendable shell framework for controlling experiments at runtime. Tools for creating multi-agent tournaments. Classic goal-directed deterministic forward-search planning. Breadth-first Search Depth-first Search A* IDA* Statically Weighted A* [2] Dynamically Weighted A* [3] Stochastic Planning. Value Iteration [4] Policy Iteration Prioritized Sweeping [20] Real-time Dynamic Programming [5] UCT [6] Sparse Sampling [17] Bounded Real-time Dynamic Programming [21] Learning. Q-learning [7] SARSA(\u03bb) [8] Actor Critic [9] Potential Shaped RMax [12] ARTDP [5] Value Function Approximation Gradient Descent SARSA(\u03bb) [8] Least-Squares Policy Iteration [18] Fitted Value Iteration [24] Framework for implementing linear and non-linear VFA CMACs/Tile Coding [10] Radial Basis Functions Fourier Basis Functions [19] The Options framework [11] (supported in most single agent planning and learning algorithms). Reward Shaping Inverse Reinforcement Learning Maximum Margin Apprenticeship Learning [16] Multiple Intentions Maximum-likelihood Inverse Reinforcement Learning [22] Receding Horizon Inverse Reinforcement Learning [23] Multi-agent Q-learning and Value Iteration, supporting Q-learning with an n-step action history memory Friend-Q [13] Foe-Q [13] Correlated-Q [14] Coco-Q [15] Single-agent partially observable planning algorithms Finite horizon optimal tree search QMDP [25] Belief MDP conversion for use with standard MDP algorithms Pre-made domains and domain generators. Grid Worlds Domains represented as graphs Blocks World Lunar Lander Mountain Car Cart Pole Frostbite Blockdude Grid Games (a multi-agent stochastic games domain) Multiple classic Bimatrix games. RLGlue agent and environment interfacing Extensions for controlling ROS -powered robots Extensions for controlling Minecraft Features in development Learning from human feedback algorithms POMDP algorithms like POMCP and PBVI General growth of all other algorithm classes already included References Diuk, C., Cohen, A., and Littman, M.L.. \"An object-oriented representation for efficient reinforcement learning.\" Proceedings of the 25th international conference on Machine learning (2008). 240-270. Pohl, Ira. \"First results on the effect of error in heuristic search\". Machine Intelligence 5 (1970): 219-236. Pohl, Ira. \"The avoidance of (relative) catastrophe, heuristic competence, genuine dynamic weighting and computational issues in heuristic problem solving (August, 1973) Puterman, Martin L., and Moon Chirl Shin. \"Modified policy iteration algorithms for discounted Markov decision problems.\" Management Science 24.11 (1978): 1127-1137. Barto, Andrew G., Steven J. Bradtke, and Satinder P. Singh. \"Learning to act using real-time dynamic programming.\" Artificial Intelligence 72.1 (1995): 81-138. Kocsis, Levente, and Csaba Szepesvari. \"Bandit based monte-carlo planning.\" ECML (2006). 282-293. Watkins, Christopher JCH, and Peter Dayan. \"Q-learning.\" Machine learning 8.3-4 (1992): 279-292. Rummery, Gavin A., and Mahesan Niranjan. On-line Q-learning using connectionist systems. University of Cambridge, Department of Engineering, 1994. Barto, Andrew G., Richard S. Sutton, and Charles W. Anderson. \"Neuronlike adaptive elements that can solve difficult learning control problems.\" Systems, Man and Cybernetics, IEEE Transactions on 5 (1983): 834-846. Albus, James S. \"A theory of cerebellar function.\" Mathematical Biosciences 10.1 (1971): 25-61. Sutton, Richard S., Doina Precup, and Satinder Singh. \"Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning.\" Artificial intelligence 112.1 (1999): 181-211. Asmuth, John, Michael L. Littman, and Robert Zinkov. \"Potential-based Shaping in Model-based Reinforcement Learning.\" AAAI. 2008. Littman, Michael L. \"Markov games as a framework for multi-agent reinforcement learning.\" ICML. Vol. 94. 1994. Greenwald, Amy, Keith Hall, and Roberto Serrano. \"Correlated Q-learning.\" ICML. Vol. 3. 2003. Sodomka, Eric, Hilliard, E., Littman, M., & Greenwald, A. \"Coco-Q: Learning in Stochastic Games with Side Payments.\" Proceedings of the 30th International Conference on Machine Learning (ICML-13). 2013. Abbeel, Pieter, and Andrew Y. Ng. \"Apprenticeship learning via inverse reinforcement learning.\" Proceedings of the twenty-first international conference on Machine learning. ACM, 2004. Kearns, Michael, Yishay Mansour, and Andrew Y. Ng. \"A sparse sampling algorithm for near-optimal planning in large Markov decision processes.\" Machine Learning 49.2-3 (2002): 193-208. Lagoudakis, Michail G., and Ronald Parr. \"Least-squares policy iteration.\" The Journal of Machine Learning Research 4 (2003): 1107-1149 G.D. Konidaris, S. Osentoski and P.S. Thomas. Value Function Approximation in Reinforcement Learning using the Fourier Basis. In Proceedings of the Twenty-Fifth Conference on Artificial Intelligence, pages 380-385, August 2011. Li, Lihong, Michael L. Littman, and L. Littman. Prioritized sweeping converges to the optimal value function. Tech. Rep. DCS-TR-631, 2008. McMahan, H. Brendan, Maxim Likhachev, and Geoffrey J. Gordon. \"Bounded real-time dynamic programming: RTDP with monotone upper bounds and performance guarantees.\" Proceedings of the 22nd international conference on Machine learning. ACM, 2005. Babes, Monica, et al. \"Apprenticeship learning about multiple intentions.\" Proceedings of the 28th International Conference on Machine Learning (ICML-11). 2011. MacGlashan, James and Littman, Micahel, \"Between imitation and intention learning,\" in Proceedings of the International Joint Conference on Artificial Intelligence, 2015. Gordon, Geoffrey J. \"Stable function approximation in dynamic programming.\" Proceedings of the twelfth international conference on machine learning. 1995. Littman, M.L., Cassandra, A.R., Kaelbling, L.P., \"Learning Policies for Partially Observable Environments: Scaling Up,\" in Proceedings of the 12th Internaltion Conference on Machine Learning. 1995.", "https://blog.cs.brown.edu/2017/03/08/brown-cs-graduating-38-more-undergraduates-last-year-232-predicted-graduate-2017/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Brown CS Is Graduating 38% More Undergraduates Than Last Year, With 232 Predicted To Graduate In 2017 Posted by Monica Zuraw on March 8, 2017 Overall enrollment is currently up and introductory course enrollment is up as well. To read more stories about the Brown CS department's increasing enrollment click here . Brown\u2019s Department of Computer Science continues to grow as more students choose concentrations in computer science. This year, the department is predicted to graduate 232 undergraduates, which is a 38% increase from 2016. This growth trend can be seen the year before as well, with 168 students graduating in 2016 (a 28% increase from the previous record year). Brown University offers a wide range of concentrations in computer science, emphasizing the importance of interdisciplinary study. Brown CS is predicted to graduate 232 undergraduates in Spring 2017: Computer Science (Bachelor of Arts): 65 Computer Science (Bachelor of Science): 98 Computer Science- Economics (Bachelor of Arts): 5 Computer Science- Economics (Bachelor of Science): 30 Math- Computer Science: 8 Applied Math- Computer Science: 26 Brown CS graduated 168 undergraduates in Spring 2016: Computer Science (Bachelor of Arts): 46 Computer Science (Bachelor of Science): 75 Computer Science- Economics (Bachelor of Arts): 5 Computer Science- Economics (Bachelor of Science): 4 Math- Computer Science: 11 Applied Math- Computer Science: 13 Computational Biology: 9 Combined Bachelor of Arts and Bachelor of Science: 2 Combined Masters: 3 Brown CS graduated 131 undergraduates in Spring 2015: Computer Science (Bachelor of Arts): 42 Computer Science (Bachelor of Science): 52 Computer Science- Economics (Bachelor of Arts): 3 Computer Science- Economics (Bachelor of Science): 6 Math- Computer Science: 5 Applied Math- Computer Science: 12 Computational Biology: 6 Combined Bachelor of Arts and Bachelor of Science: 2 Math- Computer Science (Bachelor of Arts and Bachelor of Science): 1 Combined Masters: 2 For more information, please click the link that follows to contact Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2017/06/01/read-more-brown-cs-students-continue-win-awards-and-fellowships/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Read More: Brown CS Students Continue To Win Awards And Fellowships Posted by Jesse Polhemus on June 1, 2017 Brown CS is extremely proud of our undergraduate and graduate students, who continue to win significant awards and fellowships at a national and international level. To learn more, click any of the links below. (If you're looking for stories about the awards they've won at hackathons and other competitions, click here .) Bayazit, Galgana, Kumar, And Safranchik Win CRA Outstanding Undergraduate Researcher Honorable Mentions Fong, Ren, And Weir Win CRA Outstanding Undergraduate Researcher Honorable Mentions Novotny And Collaborators Win The VIS Best Poster Award For Visualizing Dinosaur Tracks Natalie Reed Becomes Brown's Tenth Google Women Techmakers Scholar Martha Edwards And Kalvin Lam Win hackNY Fellowships Esha Ghosh Wins An Inaugural Microsoft Research Dissertation Grant Geopipe, Co-Founded By Thomas Dickerson, Wins $100K At The NYU $300K Entrepreneurs Challenge Foreign Policy Magazine Names Tellex And Oberlin 2016 Global Thinkers De Stefani, Epasto, Riondato, And Upfal Win A Best Student Paper Award At KDD 2016 Andrew Crotty Wins A Google PhD Fellowship Krishna Chaitanya Aluru Wins A Y Combinator Fellowship Multiple Brown CS Collaborators Win Two Best Paper Award Runner Up Honors At HCOMP 2015 Mace, Roelke, And Fonseca Win A Best Paper Award At SOSP 2015 Four Brown CS Students Recognized As 2015 Google Scholars Esha Ghosh, Olya Ohrimenko, And Roberto Tamassia Win The ACNS 2015 Best Student Paper Award Dana\u00eb Metaxa-Kakavouli Selected As Runner-Up For CRA Award Molly Long And Layla Oesper Win Google Anita Borg Memorial Scholarship Layla Oesper Wins ISMB Workshop Best Presentation Award", "https://blog.cs.brown.edu/2018/02/05/ignitecs-brown/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) igniteCS @ Brown Posted by Jesse Polhemus on Feb. 5, 2018 in Diversity by Natalie Reed and Eric Rosen As President Obama has said, \u201cComputers are going to be a big part of our future\u2026and that future is yours to shape.\u201d Technology is one of the fastest-growing fields today, solving problems in every industry while impacting our everyday lives. Despite this, computer science is not yet adequately taught in most K-12 schools, particularly not in underserved school districts such as Providence and Central Falls in Rhode Island. Led by Professor Amy Greenwald, a group of undergraduate and graduate students who have a passion for computer science, both as an intellectual pursuit and as a path to a stable financial future, have come together to bridge the education gap by creating Brown\u2019s Google igniteCS Initiative. Serving elementary, middle, and high school students, Brown\u2019s igniteCS chapter focuses on empowering students through skill acquisition, including programming tools and basic algorithmic thinking. Initiatives vary from in-school programs to after-school clubs to district-wide weekend club meetings. The purpose of these initiatives is to provide as many students as possible with knowledgeable mentors who can help them start or continue on their path to learning CS. Brown CS\u2019s igniteCS club ran more than 30 Hour of Code sessions at five local Providence and Central Falls schools (Spaziano Elementary School, Kennedy Elementary School, Ella Risk Elementary School, Veterans Memorial Elementary School, and Jorge Alvarez High School) during CSEd Week, December 4 to 8, 2017. This is the fifth year Brown igniteCS has participated in Hour of Code outreach. Collectively, nearly 40 Brown students (undergraduate and graduate) taught nearly 1,000 K-12 students. Their first objective was to increase student exposure to the computer science discipline, and their second, to demonstrate how computer science has the potential to help make the world a better place. With funding from Google, Brown's igniteCS club expects to continue to have a dedicated and expanded role in future Hour of Code and other outreach initiatives for many years to come. Eric Rosen, one of the student organizers for igniteCS, looks back on the program: \u201cIn the spring of 2017, I volunteered with a fellow mentor at Central Falls Middle School to teach 5th-7th graders about computer science in an after-school club. On our first day, we spent most of our time learning about the students\u2019 favorite subjects, their hobbies, what they enjoyed and disliked, and what their general thoughts were about computers. Mostly we spent the day in an open discussion, which was a lot of fun to joke around with the kids and learn their personalities. We learned pretty quickly that this particular group of students really enjoyed video games, and in particular a lot of them played Minecraft. So my partner and I spent the next week creating a Minecraft-themed curriculum that integrated core CS ideas into it. For example, when we came back the next week, we started the class by breaking down how crafting an item, like a pickaxe, in Minecraft can be thought of as a process of steps (AKA: an algorithm). We were able to actually break out a game of Minecraft and play together as a class, connecting each step of the process to a \u2018step\u2019 in our algorithm. Not only did the students have a ton of fun getting to play with us, they also quickly grasped the idea of an algorithm and started to try applying the concept to other things in the game, such as detailing an algorithm to build a house. As quickly as we were able to write out the steps of our algorithm, students were asking and trying to make their own personal algorithms for things they like to do in Minecraft. It was amazing to teach the students core CS thinking concepts, but I also got to have a lot of fun seeing how to apply algorithmic thinking to problems in Minecraft that I hadn\u2019t considered but the students wanted to know. The kids had a lot of fun playing Minecraft, but they also walked away seeing how ideas from CS and Minecraft were related, which is extremely important for setting the foundation of a passion for STEM \u2013 getting to connect your hobbies with a subject is a really fun way to learn. I like to think that as much information as we teach the students, we as mentors get to learn so much from them since there\u2019s so much freedom to personalize what our clubs teach, and how it\u2019s taught.\u201d Natalie Reed, one of igniteCS\u2019s student teachers, shares her experience: \u201cThis past semester, I helped run Coding Girls with four fellow student mentors. The club met every Sunday for two hours. Though on the surface the club simply taught basic programming concepts like functions and conditionals, the mentors and I really aimed to inspire our students to develop a passion for computer science. Not only were we looking to bridge the computer science education gap, but also the gender gap in computer science by targeted middle-school girls. In order to target a diverse group of students, we partnered with many of the local middle schools and libraries directly to reach our students. We also used the theme of storytelling to try to demystify the foreign and complex field of computer science. Because our goal for the camp was for the students to enjoy computer science, we tried to partner every coding concept with a fun storytelling game or exercise. We started each class with these \u2018unplugged\u2019 storytelling games (no computers involved). Then, the computer science concept was introduced and the students were able to use the stories they had come up with in the exercise to create an animation using the computer science concept of the day. I was amazed at how creative the students were! At the end of the club, the students were able to complete a final project to show off their storytelling and programming skills alike. Each project was amazingly unique to the student. We had projects about mystical dance battles, discovering new worlds, and the cast of Hamilton fighting for supreme control of Mars.\u201d This past year was a great launch of Brown\u2019s Google igniteCS chapter and we\u2019re looking forward to continue to make an impact in the following academic year. Many of our initiatives this past year will become annual events, like our Classical High School After School Club, Calcutt Middle School After School Club, and Coding Girls Camp. We\u2019re also looking to expand our initiatives to reach more students and further inspire our past students. This summer, we launched our website, brownignitecs.wordpress.com , in order to maintain our connection to our students and give them a way to continue to learn after the class. We\u2019re looking forward to continuing our initiative to inspire students to learn computer science this coming fall and can\u2019t wait to get the season started. We\u2019re always looking for more student mentors to organize or teach events, so if you\u2019re interested, please apply by going to https://ignitecs.withgoogle.com/register and using V7L4QWD6 as the Brown CS group code.", "http://burlap.cs.brown.edu/faq.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc F.A.Q. Question Index What is BURLAP? What is BURLAP's software license? Who do I contact if I have a question or comment? Why Java and not language x? What is an object-oriented Markov decision process (OO-MDP)? What is the difference between a PropositionalFunction and a GroundedProp? What is a HashableStateFactory? How are terminal states defined in BURLAP? Domains don't seem to provide access to the entire state space. Why not and how can I get it? Can actions have preconditions? My planning or learning algorithm is running out of memory, is there anything that I can do? Can I have BURLAP control a robot? I heard that you can use BURLAP for AI in Minecraft, how can I do that? How do I cite BURLAP? Is the FAQ and Java doc for version 2 of BURLAP still available? Answers What is BURLAP? BURLAP stands for Brown-UMBC Reinforcement Learning And Planning and is a Java library for the use and development of single or multi-agent planning and learning algorithms and domains to accompany them. What is BURLAP's software license? Prior to BURLAP 3, BURLAP was licensed under LGPL 3 . With the release of BURALP 3, the license was changed to the more permissive Apache 2.0 license . Who do I contact if I have a question or comment? You can either field the question to the community in our Google group or you can send an email to the creator, James MacGlashan, at jmacglashan at cs dot brown dot edu. Why Java and not language x? Java provides a nice balance between high portability and efficiency, while also being fairly well known with a wide range of available libraries. Additionally, many modern languages, such as Scala and Groovy, compile to the JVM, which makes BURLAP instantly compatible with them. What is an object-oriented Markov decision process (OO-MDP)? This topic is more fully described in the Building an OO-MDP Domain tutorial . In short, an OO-MDP defines states as a set of objects, each with their own attribute values, and adds a set of propositional functions that operate on the objects in a state, thereby providing additional high-level information. This representation is very powerful and allows for a range of different kinds of problems to be easily defined. Prior to BURLAP 3, all domains were represented as OO-MDPs. However, with BURLAP 3, domains use arbitrary representations that you define, with OO-MDPs having optional interfaces and tools that you can use if you wish to use that representation. What is the difference between a PropositionalFunction and a GroundedProp ? First, be sure read the Java documentation for these classes which provides a good deal of information. In brief, a PropositionalFunction defines the function and function signature for a propositional function: a function that operates on state objects in an OO-MDP. However, when you evaluate a propositional function, you must specify on which object argument to evaluate it. A GroundedProp is a reference to a PropositionalFunction and a set of parameters/arguments on which to evaluate it. What is a HashableStateFactory? Tabular learning and planning algorithms need a way to quickly look up values or stored actions (or otherwise) for different states, which makes Java HashMaps and HashSets especially appealing. Of course, that requires that we be able to compute hash codes for states and perform equality evaluations between them. We might imagine letting the State object simply implement the standard equals and hashCode methods to handle that. However, it is often the case that different experiments call for different ways of hashing or checking equality (e.g., when providing state abstraction or variable discretization). Therefore, hashing and equality is provided through a HashableStateFactory that can be customized by the client. When you aren't doing anything fancy, you can probably just use the SimpleHashableStateFactory , or if you do want to use a State's equals and hashCode method, you can use ReflectiveHashableStateFactory How are terminal states defined in BURLAP? Terminal states are defined either by an Environment implementation, or for your own simulated domains, the SampleModel. However, often times models in BURLAP are implemented with a FactoredModel that separates the state transition model, reward function, and terminal states, with the latter being defined with an object that implements the TerminalFunction interface. Following the Sutton and Barto paradigm, planning and learning algorithms in BURLAP mathematically interpret terminal states as states from which the agent deterministically transitions back to the same state with a reward of zero. This is equivalent to all action ceasing once a terminal state is reached. Because terminal states are indicated with a flag from the model or Environment, this property of the transition dynamics does not need to be specifically coded into the state transition dynamics, which makes it easy to define various ad hoc tasks for the same domain. Given this interpretation, the value of terminal states should be fixed at zero (and is in the existing BURLAP planning and learning algorithms). If you are are student reading from the Russell Norvig AI textbook and want to implement their small grid world, keep in mind that that their small grid world treats the terminal state has having a non-zero value. Domains don't seem to provide access to the entire state space. Why not and how can I get it? In many MDPs or classes of domains, the state space is infinite, in which case it cannot be defined. Other times, the state space is only finite when considering the states that are reachable from some seed initial state. And even if the state space is always finite and well defined, it's often an undue burden to require the the designer to specify the entire thing manually. However, if you'd like to gather all the possible states from a domain instance that you've created, a good way to go about this is to let BURLAP do the heavy lifting for you by using the StateReachability class, which takes as input a source state and domain, and returns all states that are reachable from the state. If your domain has states that are disconnected from each other, then you may need to run it from multiple seed states in each disconnected component. You may also find the StateEnumerator class helpful, which will let you iteratively add additional states to its set and assign a unique identifier to each. If you are working in a continuous state space, then the number of states is probably uncountably infinite, which obviously makes state enumeration impossible; however, if you want a representation of the space, you may want to consider the FlatStateGridder class, which will sample states in the space along a regular grid that you can define. And if you're using a planning algorithm that needs the full state space, such as value iteration, the implementations in BURLAP will automatically handle enumeration of the states from the source state that you give it. Can actions have preconditions? Yes! This is precisely the role of an ActionType , which lets you define which set of actions are applicable in a given state. My planning or learning algorithm is running out of memory, is there anything that I can do? Possibly. The first thing to do is to make sure that Java's JVM is being given a large enough heap. If it's not, it's possible that it's artificially using less memory than you have. To set the amount of memory Java's JVM can use, you want to add a -Xmx argument when you call java; e.g., java -Xmx2048M [class path here]. The -Xmx argument lets you specify the heap size. In the example, it would provide it with 2048MB (2GB). If you're running in Eclipse or IntelliJ, then in the run configuration you should find a text field that lets you set your VM arguments; that's where you would put that flag. If you're still running out of memory then there are a couple of things to consider. First, try and figure out if there is a more compact way to define your states. For example, do you really need as many data members you've defined, or can they be compressed into a smaller set? Also, you may also want to consider making your states perform shallow copies so that the pool of states reuses the same data. More information about shallow copying can be found in the Building a Domain tutorial. Can I have BURLAP control a robot? Sure! There are two ways you can do this. You can (1) implementyour own Environment class to manage the connection, control, and state perception of your robot; or (2) use our BURLAP library extension ( burlap_rosbridge ) that has a standard Environment implementation for communicating with robots controlled with ROS over Rosbridge . When using burlap_rosbridge it is expected that you will implement the method to turn the ROS message into a State object.Burlap_rosbridge also allows you to handle the execution of action in a variety of ways, including sending direct messages to the ROS controller (e.g., Twist messages) or by sending string messages to a ROS action controller. See burlap_rosbridge's githubpage for more information and examples of how to use it. Burlap_rosbridge is also on Maven Central, so to link to it, simply add the following dependency alongside the BURLAP dependency in your project's pom.xml file: edu.brown.cs.burlap burlap_rosbridge 3.0.0 You can also manually compile from the source on the github page . I heard that you can use BURLAP for AI in Minecraft, how can I do that? Yes, we have been building a mod for Minecraft that allows you to use BURLAP's planning and learning algorithms to control the player. For more information on that project, see its github page and its accompanying wiki page . How do I cite BURLAP? For the moment, you'll have to cite this web page and can use James MacGlashan as the author. An academic publication is forthcoming, which you can use once it's available. Is the FAQ and Java doc for version 2 of BURLAP still available? Yes, you can access the older FAQ here , and the older Java doc here .", "https://blog.cs.brown.edu/2018/03/14/providence-has-been-named-americas-fourth-quirkiest-city/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Providence Has Been Named America's Fourth Quirkiest City Posted by Jesse Polhemus on March 14, 2018 Click the link that follows for more news items about why we love calling Providence home . There's a reason why you see \"Keep Providence Eldritch \" t-shirts around here. Citing our unorthodox founder, inventive puppetry, marching bands, and inimitable foodstuffs, Travel and Leisure has just named Providence the fourth quirkiest city in America. You can read the full article here . The image above is \u00a9 2018 by Craig Fildes and used with permission under a Creative Commons license. For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "http://burlap.cs.brown.edu/faqv1.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc F.A.Q. This is FAQ for version 1 of BURLAP. To go back to the version 2 FAQ, go here . Question Index What is BURLAP? What is BURLAP's software license? Who do I contact if I have a question or comment? Why Java and not language x? What is an object-oriented Markov decision process (OO-MDP)? What is the difference between an Action and a GroundedAction? What about a PropositionalFunction and a GroundedProp? What is an AbstractGroundedAction class? It seems that Action parameters correspond to typed OO-MDP state objects; can I define an action with non-object parameters? What is a StateHashFactory? What is object identifier invariance? If object identifier invariance leads to smaller state spaces, why wouldn't I want to use it? How are terminal states defined in BURLAP? Domains don't seem to provide access to the entire state space. Why not and how can I get it? Where are transition dynamics defined? Can actions have preconditions? What is a SingleAction class? What is a parameter order group? Is there a way to set up an Environment that maintains the current state with which the agent interacts? My planning or learning algorithm is running out of memory, is there anything that I can do? Can I have BURLAP control a robot? I heard that you can use BURLAP for AI in Minecraft, how can I do that? How do I cite BURLAP? Answers What is BURLAP? BURLAP stands for Brown-UMBC Reinforcement Learning And Planning and is a Java library for the use and development of single or multi-agent planning and learning algorithms and domains to accompany them. What is BURLAP's software license? BURLAP is licensed under LGPL. In brief, that means you can use it for free and even link to it in sold software. Who do I contact if I have a question or comment? You can either field the question to the community in our Google group or you can send an email to the creator, James MacGlashan, at jmacglashan at cs dot brown dot edu. Why Java and not language x? Java provides a nice balance between high portability and efficiency, while also being fairly well known with a wide range of available libraries. Additionally, many modern languages, such as Scala and Groovy, compile to the JVM, which makes BURLAP instantly compatible with them. What is an object-oriented Markov decision process (OO-MDP)? This topic is more fully described on page 2 of the Building a Domain tutorial . In short, an OO-MDP defines states as a set of objects, each with their own attribute values, and adds a set of propositional functions that operate on the objects in a state, thereby providing additional high-level information. This representation is very powerful and allows for a range of different kinds of problems to be easily defined. What is the difference between an Action and a GroundedAction ? What about a PropositionalFunction and a GroundedProp ? An Action object defines an action's name, set of parameters, and the code that defines the physics of an action. Because actions can be parameterized, there needs to be a way to refer to each specific application of an action. A GroundedAction serves this purpose by being a reference to an Action object along with a set of parameters with which the action is to be applied. To give an example, in a blocks world, the \"pickup\" Action object defines an action that is parameterized to a block object and how the state changes when it is applied to any given block. In a world with three blocks, there would be three different GroundedAction objects that reference the \"pickup\" Action object; one for each block. If an Action does not define any parameters, then a corresponding GroundedAction for it will have an empty set of specified parameter values. The difference between a PropositionalFunction object and a GroundedProp object is similar. A PropositionalFunction defines how a propositional function evaluates and to which object classes it is parameterized. A GroundedProp is a reference to a propositional function and the parameters with which it should be evaluated. What is an AbstractGroundedAction class? AbstractGroundedAction is an abstract super class for the GroundedAction class and others. The reason it exists is because BURLAP supports a variety of planning and learning problem types, including multi-agent (stochastic games) domains, which require a bit different under-the-hood management. However, because BURLAP seeks to reuse code as much as possible, difference pieces can be connected as long as they inherit from the same super class. For example, the GroundedSingleAction and JointAction objects are also subclasses of AbstractGroundedAction, which means tools like Policy objects can be reused for both single agent domains and multi-agent domains. It seems that Action parameters correspond to typed OO-MDP state objects; can I define an action with non-object parameters? Yes! Although the default behavior for action parameters are to correspond to OO-MDP objects in a state, you can have any kind of parameterization that you want. To have your action use a different kind of parameterization you need to do two things. First, for the Action in question, override the method getAllApplicableGroundedActions(State) to return the list of GroundedAction objects with all parameterizations of your Action possible in the given state. Because the parameters in a GroundedAction are specified with String objects, you can represent any number of parameter data types in their string form. Second, override the method parametersAreObjects() and have it return false (this lets planning and learning algorithms know that because the parameters are not objects, it does not need to account for object identifier invariance in the actions). With those changes, the parameters passed to the standard Action object methods (e.g., performAction(State, String[])), will always be one of the possible parameterizations that you've defined. The parameters always come in String data types, which means you can provide any kind of information that you can represent in a String. What is a StateHashFactory? Tabular learning and planning algorithms need a way to quickly look up values or stored actions (or otherwise) for different states, which makes Java HashMaps and HashSets especially appealing. Of course, that requires that we be able to compute hash codes for OO-MDP State objects and perform equality evaluations between them. Depending the kind of problem you're solving there may be different ways that you need to compute the hash code and perform equality evaluations. For example, perhaps you want to plan in an abstract space that ignores certain objects or attribute values. Or maybe you need to discretize real-valued attributes before comparing the states. Or maybe you don't want to use object identifier invariance. Since different problems may require different ways of hashing and comparing states, different StateHashFactory implementations will produce different StateHashTuple objects that compute hash codes and perform state equality evaluations differently. There are a number of different variants already in BURLAP, but if you need to perform State equality evaluations in an entirely unique way, the power of BURLAP is that you can implement your own and hand it off to the planning and learning algorithm! What is object identifier invariance? For a larger discussion of this topic, see page 2 of the Building a Domain tutorial . In short, if a domain and StateHashFactory is object identifier invariant, then it means that the equality of two states is independent of the order of the objects (or their name) in the states. Instead, two states will be considered equal as long as there is a bijection between their objects such that each matched object is equal to one another. Using object identifier invariance results in a compression of the state space size since you don't have to treat every ordering of the same objects as different states If object identifier invariance leads to smaller state spaces, why wouldn't I want to use it? When you don't! :-) For example, if you want to define a goal in which the condition for a specific object is satisfied, you need to differentiate between objects with different identifiers. Additionally, if you are creating a relational domain, then you must have object identifier dependence, because being invariant to object identifiers in a relational domain would require solving graph isomorphism which is thought to be NP-hard. So while detecting graph isomorphism is doable, BURLAP does not support (by default) object identifier invariance in relational domains since it's not tractable. How are terminal states defined in BURLAP? Terminal states are defined with an object that implements the TerminalFunction interface. Following the Sutton and Barto paradigm, planning and learning algorithms in BURLAP mathematically interpret terminal states as states from which the agent deterministically transitions back to the same state with a reward of zero. This is equivalent to all action ceasing once a terminal state is reached. Because terminal states are indicated with a TerminalFunction class, this property of the transition dynamics does not need to be specifically coded into the action transition dynamics, which makes it easy to define various ad hoc tasks for the same domain. Given this interpretation, the value of terminal states should be fixed at zero (and is in the existing BURLAP planning and learning algorithms). If you are are student reading from the Russell Norvig AI textbook and want to implement their small grid world, keep in mind that that their small grid world treats the terminal state has having a non-zero value. Domains don't seem to provide access to the entire state space. Why not and how can I get it? In an OO-MDP, the state space is infinite because you can always just imagine another world with an additional object. Although in practice your state space may always be well defined, the domain generators in BURLAP can support much more than any single instance, which may make enumerating the state space for any domain instance non-trivial. For example, even in grid worlds you can imagine any number of different grid worlds. In other cases, it can just be hard to manually enumerate all possible state, which would make requiring it for domains a burden on the designer. However, if you'd like to gather all the possible states from a domain instance that you've created, a good way to go about this is to let BURLAP do the heavy lifting for you by using the StateReachability class, which takes as input a source state and domain, and returns all states that are reachable from the state. If your domain has states that are disconnected from each other, then you may need to run it from multiple seed states in each disconnected component. You may also find the StateEnumerator class helpful, which will let you iteratively add additional states to its set and assign a unique identifier to each. If you are working in a continuous state space, then the number of states is probably uncountably infinite, which obviously makes state enumeration impossible; however, if you want a representation of the space, you may want to consider the StateGridder class, which will sample states in the space along a regular grid that you can define. And if you're using a planning algorithm that needs the full state space, such as value iteration, the implementations in BURLAP will automatically handle enumeration of the states from the source state that you give it. Where are transition dynamics defined? Transition dynamics for a single-agent domain are defined in the Action classes that you (or an existing domain) implement. Specifically, there are two Action class methods related to the transition dynamics: performActionHelper(State, String[]) and getTransitions(State String[]). The performActionHelper method, as the name implies performs the action on the given state (and the given parameters, if any, in the String array) and returns the outcome state (the input state can be directly modified and returned safely since the perfomAction method copies the state before passing it to performActionHelper). If the domain is stochastic, then the method should randomly sample an outcome state according to the distribution. Note that this method does not require the probability of the sampled outcome state to be returned, which in some domains may be non-trivial to compute. This method must be overridden to implement an Action. The getTransitions method returns a list of all the possible outcome states with non-zero probability as well as their probability of occurring. Although this method does not need to be implemented, some algorithms, such as dynamic programming variants, require it to be implemented. If you (or the existing domain) do not override the method, then when it is called by an algorithm that requires it, an UnsupportedOperation exception will be thrown. If your action is deterministic, the getTransitions method can be trivially implemented by returning the result of the deterministicTranstion(State, String[]) method, which will get the outcome state by calling the performAction method, wrap it in a TransitionProbability object (with assigned probability 1.0) and insert it in a list with just that element. For multi-agent domains, similar methods that need to be overridden exist in the JointActionModel abstract class: actionHelper(State, JointAction) and transitionProbsFor(State, JointAction), respectively. Can actions have preconditions? Yes! By default, actions are assumed to always be applicable in all states, but you can add preconditions by implementing the Action method applicableInState(State, String[]). For multi-agent domains, you should similarly implement the isApplicableInState(State, String[]) method in the SingleAction class. This method should return true when the Action being implemented can be applied in the given state with the given parameters and false when it cannot be applied. What is a SingleAction class? A SingleAction defines an action that can be taken by single agent in a multi-agent stochastic games domain. For a world with a given set of agents acting the world, each single action selected by each agent makes up the total JointAction that is taken a in single time step of the world. Unlike the Action class in single agent domains, SingleAction objects do not implement transition dynamics, because the change in world state is dependent on the joint action taken by all agents. Instead the multi-agent domain transition dynamics are defined in the JointActionModel abstract class. What is a parameter order group? You will see this term used in the definition of parameters for actions and propositional functions (in particular as possible arguments in some of the possible constructors). Parameters that belong to the same parameter order group (POG) can have their values swapped without changing the effect of the action or evaluation of the propositional function. For example, consider the propositional function prototype touching(X, Y), which returns true when the object assigned to X is touching the object assigned to Y. This evaluation should be be transitive. That is, if touching(a, b) is true, then touching(b, a) is true (and inversely when one evaluates to false, flipping the parameters should still result in a false evaluation). To encode that the parameters are transitive, we assign them to the same POG (which can be named anything as long as it's the same name for both). If they are not transitive, then we would assign different POGs to them. If you use an Action constructor or PropositionalFunction constructor without the POG values argument, it will automatically assign each parameter to a different POG (that is, non-transitivity is the default assumption). Specifying the parameter transitivity with POGs is useful because when you request a list of all grounded versions of an action (with the getAllApplicableGroundedActions(State) method) or propositional function (with the getAllGroundedPropsForState(State) method), it will not produce a grounding that is transitively identical to another already in the list. In our touching(X, Y) example, for instance, it will return a list with only the grounding for touching(a, b), or touching(b, a), but not both. Is there a way to set up an Environment that maintains the current state with which the agent interacts? Yes. In general, the learning algorithms in BURLAP do not require environments to be set up; you can just tell them run a learning episode from a given initial state and they will do so. However, sometimes an environment is useful, especially when the state of the environment can change from external forces (e.g., robotics in which the real world changes on its own, or humans manipulating the state of your environment). For such purposes, you can subclass the Environment class. To have an agent learn in the environment, you can then set up a DomainEnvironmentWrapper , which creates a domain that funnels all perfomAction methods through the Environment. To use a standard BURLAP LearningAgent instance with an Environment, upon construction of the LearningAgent, set its domain to be the DomainEnvironmentWrapper that you created for your environment, and then tell it to learn from whatever the current state of the Environment is (which you can retrieve using the getCurState() method). In general, however, if you do not have outside forces affecting the state of your learning problem, you probably don't need to set up an Environment class. My planning or learning algorithm is running out of memory, is there anything that I can do? Possibly. The first thing to do is to make sure that Java's JVM is being given a large enough heap. If it's not, it's possible that it's artificially using less memory than you have. To set the amount of memory Java's JVM can use, you want to add a -Xmx argument when you call java; e.g., java -Xmx2048M [class path here]. The -Xmx argument lets you specify the heap size. In the example, it would provide it with 2048MB (2GB). If you're running in Eclipse or IntelliJ, then in the run configuration you should find a text field that lets you set your VM arguments; that's where you would put that flag. If you're still running out of memory then there are a couple of things to consider. First, try and figure out if there is a more compact way to define your states. For example, do you really need as many OO-MDP objects you've defined, or can they be compressed into a smaller set? Second, you might want to override the Action class' performAction(State String[]) method. Note, this is *not* the same as the performActionHelper(State String[]) that you're typically required to override. The role of the performAction method is to first copy the input state and then pass it to the performActionHelper method, which ensures that the performActionHelper method can modify the input state without affecting the state of the world in which the action is applied. To save some memory, a trick you can do is instead of calling the State copy() method, call the semiDeepCopy() method. The semiDeepCopy method takes as arguments a list of object instances that need to be deep copied. In the returned state, only the specified objects will have been deep copied and the rest will have been shallow copied. As long as you deep copy the objects that the Action will modify, this semiDeepCopy operation will be safe. The exception is if some other code goes back and edits the value of some previous state's object values that were not deep copied, then all of the shallow copies of it in each state will change. Can I have BURLAP control a robot? Sure! There are three ways you can do this. You can (1) define your domain to directly control the robot (and update the world state) through your Action classes (specifically via your implementations of performActionHelper ); (2) implementan Environment class to manage the connection, control, and state perception of your robot; or (3) use our BURLAP library extension ( burlap_rosbridge ) for communicating with robots controlled with ROS . burlap_rosbridge provides a standard Environment class implementation that maintains the state of the real world and controlsthe physical robot by communicating to ROS over Rosbridge . On the ROS side, it is expected that you create a ROS topic that is publishing BURLAP state messages (formatted according our defined burlap_msgs type) and that there is a topic BURLAP can push to that accepts action commands as a string type. See burlap_rosbridge's githubpage for more information on how to use it. I heard that you can use BURLAP for AI in Minecraft, how can I do that? Yes, we have been building a mod for Minecraft that allows you to use BURLAP's planning and learning algorithms to control the player. For more information on that project, see its github page and its accompanying wiki page . How do I cite BURLAP? For the moment, you'll have to cite this web page and can use James MacGlashan as the author. An academic publication is forthcoming, which you can use once it's available.", "http://burlap.cs.brown.edu/faqv2.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc F.A.Q. Question Index What is BURLAP? What is BURLAP's software license? Who do I contact if I have a question or comment? Why Java and not language x? What is an object-oriented Markov decision process (OO-MDP)? What is the difference between an Action and a GroundedAction? What about a PropositionalFunction and a GroundedProp? What is an AbstractGroundedAction class? What is a HashableStateFactory? What is object independence invariance? If object identifier independence leads to smaller state spaces, why wouldn't I want to use it? How are terminal states defined in BURLAP? Domains don't seem to provide access to the entire state space. Why not and how can I get it? Where are transition dynamics defined? Can actions have preconditions? What is an SGAgentAction class? What is a parameter order group? My planning or learning algorithm is running out of memory, is there anything that I can do? Can I have BURLAP control a robot? I heard that you can use BURLAP for AI in Minecraft, how can I do that? How do I cite BURLAP? Is the FAQ and Java doc for version 1 of BURLAP still available? Answers What is BURLAP? BURLAP stands for Brown-UMBC Reinforcement Learning And Planning and is a Java library for the use and development of single or multi-agent planning and learning algorithms and domains to accompany them. What is BURLAP's software license? BURLAP is licensed under LGPL. In brief, that means you can use it for free and even link to it in sold software. Who do I contact if I have a question or comment? You can either field the question to the community in our Google group or you can send an email to the creator, James MacGlashan, at jmacglashan at cs dot brown dot edu. Why Java and not language x? Java provides a nice balance between high portability and efficiency, while also being fairly well known with a wide range of available libraries. Additionally, many modern languages, such as Scala and Groovy, compile to the JVM, which makes BURLAP instantly compatible with them. What is an object-oriented Markov decision process (OO-MDP)? This topic is more fully described on page 2 of the Building a Domain tutorial . In short, an OO-MDP defines states as a set of objects, each with their own attribute values, and adds a set of propositional functions that operate on the objects in a state, thereby providing additional high-level information. This representation is very powerful and allows for a range of different kinds of problems to be easily defined. What is the difference between an Action and a GroundedAction ? What about a PropositionalFunction and a GroundedProp ? First, be sure read the Java documentation for these classes which provides a good deal of information. In brief, an Action is subclassed and instantiated to define your MDP actions; that means the action name, its preconditions, parameterizations, and transition dynamics. Because actions can be defined to be parameterized, decisions that an agent makes are not only over the space of actions definitions, but the space of possible parameterizations for each action definition. As a consequence, there needs to be a way for agents to refer to which action-parameterization they're considering. The GroundedAction serves this purpose by containing a reference to an Action, as well as parameter assignments with which the action will be applied. When you subclass Action, the kinds of parameterizations your action supports are defined by the getAssociatedGroundedAction() and getAllApplicableGroundedActions(burlap.oomdp.core.states.State) methods, which should return a subclass of GroundedAction that contains the possible parameterizations. Because you can create your own subclasses of GroundedAction, you can define any kind of action parameterization that you'd like! From continuous valued parameters, to STRIPs-like object references. If your action is not parameterized and has no preconditions, you should consider subclassing SimpleAction , which implements many of the Action methods and returns the parameter-free SimpleGroundedAction . The difference between PropositionalFunction and GroundedProp is similar; PropositionalFunction defines the propositional function and GroundedProp is a reference to the PropositionalFunction along with the parameters with which to evaluate it. In this case, however, the parameters to propositional functions are always OO-MDP objects in the state. What is an AbstractGroundedAction class? AbstractGroundedAction is the common interface for the GroundedAction class and other and acton groundings used in other problem types (for example, GroundedSGAgentAction in stochastic games). This common interface allows tools in BURLAP be re-used across different problem types. For example, the Policy class can be used in both single agent problems and stochastic games problems, because it returns AbstractGroundedAction implementations, rather than a single problem type's grounded action. What is a HashableStateFactory? Tabular learning and planning algorithms need a way to quickly look up values or stored actions (or otherwise) for different states, which makes Java HashMaps and HashSets especially appealing. Of course, that requires that we be able to compute hash codes for OO-MDP State objects and perform equality evaluations between them. Depending the kind of problem you're solving there may be different ways that you need to compute the hash code and perform equality evaluations. For example, perhaps you want to plan in an abstract space that ignores certain objects or attribute values. Or maybe you need to discretize real-valued attributes before comparing the states. Or maybe you don't want to use object identifier invariance. Since different problems may require different ways of hashing and comparing states, different HashableStateFactory implementations will produce different HashableState objects that compute hash codes and perform state equality evaluations differently. However, unless you want to do something special, (like state abstraction) use SimpleHashableStateFactory . You can also always implement your own if you need special functionality not already supported in BURLAP! What is object identifier independence? For a larger discussion of this topic, see page 2 of the Building a Domain tutorial . In short, if a domain is object identifier independent, then it means that the equality of two states is independent of the order of the objects (or their name) in the states. Instead, two states will be considered equal as long as there is a bijection between their objects such that each matched object is equal to one another. Using object identifier independence results in a compression of the state space size since you don't have to treat every ordering of the same objects as different states. If object identifier independence leads to smaller state spaces, why wouldn't I want to use it? When you don't! :-) For example, if you want to define a goal in which the condition for a specific object is satisfied, you need to differentiate between objects with different identifiers. Additionally, if you are creating a relational domain, then you must have object identifier dependence, because being invariant to object identifiers in a relational domain would require solving graph isomorphism which is thought to be NP-hard. So while detecting graph isomorphism is doable, BURLAP does not implement object identifier independence in relational domains since it's not tractable. How are terminal states defined in BURLAP? Terminal states are defined with an object that implements the TerminalFunction interface. Following the Sutton and Barto paradigm, planning and learning algorithms in BURLAP mathematically interpret terminal states as states from which the agent deterministically transitions back to the same state with a reward of zero. This is equivalent to all action ceasing once a terminal state is reached. Because terminal states are indicated with a TerminalFunction class, this property of the transition dynamics does not need to be specifically coded into the action transition dynamics, which makes it easy to define various ad hoc tasks for the same domain. Given this interpretation, the value of terminal states should be fixed at zero (and is in the existing BURLAP planning and learning algorithms). If you are are student reading from the Russell Norvig AI textbook and want to implement their small grid world, keep in mind that that their small grid world treats the terminal state has having a non-zero value. Domains don't seem to provide access to the entire state space. Why not and how can I get it? In an OO-MDP, the state space is infinite because you can always just imagine another world with an additional object. Although in practice your state space may always be well defined, the domain generators in BURLAP can support much more than any single instance, which may make enumerating the state space for any domain instance non-trivial. For example, even in grid worlds you can imagine any number of different grid worlds. In other cases, it can just be hard to manually enumerate all possible state, which would make requiring it for domains a burden on the designer. However, if you'd like to gather all the possible states from a domain instance that you've created, a good way to go about this is to let BURLAP do the heavy lifting for you by using the StateReachability class, which takes as input a source state and domain, and returns all states that are reachable from the state. If your domain has states that are disconnected from each other, then you may need to run it from multiple seed states in each disconnected component. You may also find the StateEnumerator class helpful, which will let you iteratively add additional states to its set and assign a unique identifier to each. If you are working in a continuous state space, then the number of states is probably uncountably infinite, which obviously makes state enumeration impossible; however, if you want a representation of the space, you may want to consider the StateGridder class, which will sample states in the space along a regular grid that you can define. And if you're using a planning algorithm that needs the full state space, such as value iteration, the implementations in BURLAP will automatically handle enumeration of the states from the source state that you give it. Where are transition dynamics defined? Transition dynamics for a single-agent domain are defined in the Action classes that you (or an existing domain) implement. Specifically, there are two methods used for defining transition dynamics. The performActionHelper(State, GroundedAction) and, if your Action class implements FullActionModel , getTransitions(State GroundedAction). The performActionHelper method, as the name implies performs the action on the given state (and the given parameters, if any, in the GroundedAction argument) and returns the outcome state. If the domain is stochastic, then the method should randomly sample an outcome state according to the distribution. Note that this method does not require the probability of the sampled outcome state to be returned, which in some domains may be non-trivial to compute. This method must be implemented to implement an Action. The getTransitions method returns a list of all the possible outcome states with non-zero probability as well as their probability of occurring.This method only needs to be implemented if your action implements the optional interface FullActionModel, because for some domains it is impossible to enumerate all possible outcomes. However, some algorithms, such as DynamicProgramming algorithms, require being able to access the fully enumerated transition dynamics. So if you plan on using these algorithms with your domain, your Action will need to implement the interface and method. For stochastic games problems, similar methods that need to be overridden exist in the JointActionModel abstract class: actionHelper(State, JointAction) and transitionProbsFor(State, JointAction), respectively. Can actions have preconditions? Yes! When you subclass Action , one of the methods you must implement is applicableInState(State, GroundedAction), which should return true in states where you preconditions are satisfied and false in states where they are not. For stochastic games, the SGAgentAction has a method with the same name for the same purpose. What is a SGActionACtion class? A SGAgentAction class is used to define stochastic games problems. Stochastic games are formalism for a multi-agent problem. In the definition, each agent in the world has a set of individual actions that they apply and at each time step, they each choose from their set of actions and execute them at the same time. Similar, to the single-agent problem Action class, the SGAgentAction class is used to define the name, preconditions, and parameterizations of an action that an agent in a stochastic games problem can take. Since states in a stochastic game change as a function of joint actions taken by all agents in the world, SGAgentAction does not have transition dynamics defined in it. Instead, transition dynamics for stochastic games are defined in the ` JointActionModel abstract class. What is a parameter order group? You will see this term used in the definition of STRIPs-like ObjectParameterizedAction implementations and the PropositionalFunction class. A parameter order group is used with OO-MDP object parameters to specify whether there is symmetry between parameters. That is, parameters that belong to the same parameter order group (POG) can have their values swapped without changing the effect of the action or evaluation of the propositional function. For example, consider the propositional function prototype touching(X, Y), which returns true when the object assigned to X is touching the object assigned to Y. This evaluation should be be transitive. That is, if touching(a, b) is true, then touching(b, a) is true (and inversely when one evaluates to false, flipping the parameters should still result in a false evaluation). To encode that the parameters are transitive, we assign them to the same POG (which can be named anything as long as it's the same name for both). If they are not transitive, then we would assign different POGs to them. If you use an ObjectParameterizedAction constructor or PropositionalFunction constructor without the POG values argument, it will automatically assign each parameter to a different POG (that is, non-transitivity is the default assumption). Specifying the parameter transitivity with POGs is useful because when you request a list of all grounded versions of an ObjectParameterizedAction (with the getAllApplicableGroundedActions(State) method) or propositional function (with the getAllGroundedPropsForState(State) method), it will not produce a grounding that is transitively identical to another already in the list. In our touching(X, Y) example, for instance, it will return a list with only the grounding for touching(a, b), or touching(b, a), but not both. My planning or learning algorithm is running out of memory, is there anything that I can do? Possibly. The first thing to do is to make sure that Java's JVM is being given a large enough heap. If it's not, it's possible that it's artificially using less memory than you have. To set the amount of memory Java's JVM can use, you want to add a -Xmx argument when you call java; e.g., java -Xmx2048M [class path here]. The -Xmx argument lets you specify the heap size. In the example, it would provide it with 2048MB (2GB). If you're running in Eclipse or IntelliJ, then in the run configuration you should find a text field that lets you set your VM arguments; that's where you would put that flag. If you're still running out of memory then there are a couple of things to consider. First, try and figure out if there is a more compact way to define your states. For example, do you really need as many OO-MDP objects you've defined, or can they be compressed into a smaller set? Finally, if you're still running out memory, you should considering writing your own implementation of the State interface that allows for the most efficient management of your state data. It's possible the standard MutableState implementation that is mostly used in BURLAP domains is too general and is being wasteful for your specific domain. Can I have BURLAP control a robot? Sure! There are two ways you can do this. You can (1) implementyour own Environment class to manage the connection, control, and state perception of your robot; or (2) use our BURLAP library extension ( burlap_rosbridge ) that has a standard Environment implementation for communicating with robots controlled with ROS over Rosbridge . When using burlap_rosbridge it is expected that you create a ROS topic that is publishing BURLAP state messages. By default,these messaged are assumed to adhere our ROS burlap_msgs type. However, you can also subclass the RosEnvironment to implement custom parsing of differently formatted topics. Burlap_rosbridge allows you to handle the execution of action in a variety of ways, including sending direct messages to the ROS controller (e.g., Twist messages) or by sending string messages to a ROS action controller. See burlap_rosbridge's githubpage for more information and examples of how to use it. Burlap_rosbridge is also on Maven Central, so to link to it, simply add the following dependency alongside the BURLAP dependency in your project's pom.xml file: edu.brown.cs.burlap burlap_rosbridge 2.1.0 You can also manually compile from the source on the github page . I heard that you can use BURLAP for AI in Minecraft, how can I do that? Yes, we have been building a mod for Minecraft that allows you to use BURLAP's planning and learning algorithms to control the player. For more information on that project, see its github page and its accompanying wiki page . How do I cite BURLAP? For the moment, you'll have to cite this web page and can use James MacGlashan as the author. An academic publication is forthcoming, which you can use once it's available. Is the FAQ and Java doc for version 1 of BURLAP still available? Yes, you can access the older FAQ here , and the older Java doc here .", "http://burlap.cs.brown.edu/index.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc About The Brown-UMBC Reinforcement Learning and Planning ( BURLAP ) java code library is for the use and development of single or multi-agent planning and learning algorithms and domains to accompany them. BURLAP uses a highly flexible system for defining states and and actions of nearly any kind of form, supporting discrete continuous, and relational domains. Planning and learning algorithms range from classic forward search planning to value function-based stochastic planning and learning algorithms. Also included is a set of analysis tools such as a common framework for the visualization of domains and agent performance in various domains. BURLAP is licensed under the permissive Apache 2.0 license. For more background information on the project and the people involved, see the Information page. Where to git it BURALP uses Maven and is available on Maven Central! That means that if you'd like to create a project that uses BURLAP, all you need to do is add the following dependency to the <dependencies> section of your projects pom.xml edu.brown.cs.burlap burlap 3.0.0 and the library will automatically be downloaded and linked to your project! If you do not have Maven installed, you can get it from here . You can also get the full BURLAP source to manually compile/modify from Github at: https://github.com/jmacglashan/burlap Alternatively, you can directly download precompiled jars from Maven Central from here . Use the jar-with-dependencies if you want all dependencies included. Prior versions of BURLAP are also available on Maven Central, and branches on github. Tutorials and Example Code Short video tutorials, longer text tutorials, and example code are available for BURLAP.All code can be found in our examples repository, which also provides the kind of POM file and file sturcture you should consider using for a BURLAP project. The example repository can be found at: https://github.com/jmacglashan/burlap_examples/ Video Tutorials Written Tutorials Hello Grid World! - a tutorial on acquiring and linking with BURLAP Building a Domain Using Basic Planning and Learning Algorithms Creating a Planning and Learning Algorithm Solving Continuous Domains Building an OO-MDP Domain Documentation Java documentation is provided for all of the source code in BURLAP. You can find an online copy of the javadoc at the below location. http://burlap.cs.brown.edu/doc/index.html Features Current A highly felixible state representation in which you define states with regular Java code and only need to implement a short interface. This enables support for discrete, continuous, relational, or any other kind of state representation that you can code! BURLAP also has optional interfaces to provide first class support for the rich OO-MDP state representation [1]. Supported problem formalisms Markov Decision Processes (single agent) Stochastic Games (multi-agent) Partially Observable Markov Decision Processes (single agent) Tools for visualizing and defining visualizations of states, episodes, value functions, and policies. Tools for setting up experiments with multiple learning algorithms and plotting the performance using multiple performance metrics. An extendable shell framework for controlling experiments at runtime. Tools for creating multi-agent tournaments. Classic goal-directed deterministic forward-search planning. Breadth-first Search Depth-first Search A* IDA* Statically Weighted A* [2] Dynamically Weighted A* [3] Stochastic Planning. Value Iteration [4] Policy Iteration Prioritized Sweeping [20] Real-time Dynamic Programming [5] UCT [6] Sparse Sampling [17] Bounded Real-time Dynamic Programming [21] Learning. Q-learning [7] SARSA(\u03bb) [8] Actor Critic [9] Potential Shaped RMax [12] ARTDP [5] Value Function Approximation Gradient Descent SARSA(\u03bb) [8] Least-Squares Policy Iteration [18] Fitted Value Iteration [24] Framework for implementing linear and non-linear VFA CMACs/Tile Coding [10] Radial Basis Functions Fourier Basis Functions [19] The Options framework [11] (supported in most single agent planning and learning algorithms). Reward Shaping Inverse Reinforcement Learning Maximum Margin Apprenticeship Learning [16] Multiple Intentions Maximum-likelihood Inverse Reinforcement Learning [22] Receding Horizon Inverse Reinforcement Learning [23] Multi-agent Q-learning and Value Iteration, supporting Q-learning with an n-step action history memory Friend-Q [13] Foe-Q [13] Correlated-Q [14] Coco-Q [15] Single-agent partially observable planning algorithms Finite horizon optimal tree search QMDP [25] Belief MDP conversion for use with standard MDP algorithms Pre-made domains and domain generators. Grid Worlds Domains represented as graphs Blocks World Lunar Lander Mountain Car Cart Pole Frostbite Blockdude Grid Games (a multi-agent stochastic games domain) Multiple classic Bimatrix games. RLGlue agent and environment interfacing Extensions for controlling ROS -powered robots Extensions for controlling Minecraft Features in development Learning from human feedback algorithms POMDP algorithms like POMCP and PBVI General growth of all other algorithm classes already included References Diuk, C., Cohen, A., and Littman, M.L.. \"An object-oriented representation for efficient reinforcement learning.\" Proceedings of the 25th international conference on Machine learning (2008). 240-270. Pohl, Ira. \"First results on the effect of error in heuristic search\". Machine Intelligence 5 (1970): 219-236. Pohl, Ira. \"The avoidance of (relative) catastrophe, heuristic competence, genuine dynamic weighting and computational issues in heuristic problem solving (August, 1973) Puterman, Martin L., and Moon Chirl Shin. \"Modified policy iteration algorithms for discounted Markov decision problems.\" Management Science 24.11 (1978): 1127-1137. Barto, Andrew G., Steven J. Bradtke, and Satinder P. Singh. \"Learning to act using real-time dynamic programming.\" Artificial Intelligence 72.1 (1995): 81-138. Kocsis, Levente, and Csaba Szepesvari. \"Bandit based monte-carlo planning.\" ECML (2006). 282-293. Watkins, Christopher JCH, and Peter Dayan. \"Q-learning.\" Machine learning 8.3-4 (1992): 279-292. Rummery, Gavin A., and Mahesan Niranjan. On-line Q-learning using connectionist systems. University of Cambridge, Department of Engineering, 1994. Barto, Andrew G., Richard S. Sutton, and Charles W. Anderson. \"Neuronlike adaptive elements that can solve difficult learning control problems.\" Systems, Man and Cybernetics, IEEE Transactions on 5 (1983): 834-846. Albus, James S. \"A theory of cerebellar function.\" Mathematical Biosciences 10.1 (1971): 25-61. Sutton, Richard S., Doina Precup, and Satinder Singh. \"Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning.\" Artificial intelligence 112.1 (1999): 181-211. Asmuth, John, Michael L. Littman, and Robert Zinkov. \"Potential-based Shaping in Model-based Reinforcement Learning.\" AAAI. 2008. Littman, Michael L. \"Markov games as a framework for multi-agent reinforcement learning.\" ICML. Vol. 94. 1994. Greenwald, Amy, Keith Hall, and Roberto Serrano. \"Correlated Q-learning.\" ICML. Vol. 3. 2003. Sodomka, Eric, Hilliard, E., Littman, M., & Greenwald, A. \"Coco-Q: Learning in Stochastic Games with Side Payments.\" Proceedings of the 30th International Conference on Machine Learning (ICML-13). 2013. Abbeel, Pieter, and Andrew Y. Ng. \"Apprenticeship learning via inverse reinforcement learning.\" Proceedings of the twenty-first international conference on Machine learning. ACM, 2004. Kearns, Michael, Yishay Mansour, and Andrew Y. Ng. \"A sparse sampling algorithm for near-optimal planning in large Markov decision processes.\" Machine Learning 49.2-3 (2002): 193-208. Lagoudakis, Michail G., and Ronald Parr. \"Least-squares policy iteration.\" The Journal of Machine Learning Research 4 (2003): 1107-1149 G.D. Konidaris, S. Osentoski and P.S. Thomas. Value Function Approximation in Reinforcement Learning using the Fourier Basis. In Proceedings of the Twenty-Fifth Conference on Artificial Intelligence, pages 380-385, August 2011. Li, Lihong, Michael L. Littman, and L. Littman. Prioritized sweeping converges to the optimal value function. Tech. Rep. DCS-TR-631, 2008. McMahan, H. Brendan, Maxim Likhachev, and Geoffrey J. Gordon. \"Bounded real-time dynamic programming: RTDP with monotone upper bounds and performance guarantees.\" Proceedings of the 22nd international conference on Machine learning. ACM, 2005. Babes, Monica, et al. \"Apprenticeship learning about multiple intentions.\" Proceedings of the 28th International Conference on Machine Learning (ICML-11). 2011. MacGlashan, James and Littman, Micahel, \"Between imitation and intention learning,\" in Proceedings of the International Joint Conference on Artificial Intelligence, 2015. Gordon, Geoffrey J. \"Stable function approximation in dynamic programming.\" Proceedings of the twelfth international conference on machine learning. 1995. Littman, M.L., Cassandra, A.R., Kaelbling, L.P., \"Learning Policies for Partially Observable Environments: Scaling Up,\" in Proceedings of the 12th Internaltion Conference on Machine Learning. 1995.", "http://burlap.cs.brown.edu/information.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Contact If you would like to contact the creator, send an email to James MacGlashan at: jmacglashan at cs dot brown dot edu. Alternatively, it may be worthwhile to direct your question to the BURLAP Google group at: https://groups.google.com/forum/#!forum/burlap-discussion Obtaining BURLAP BURALP now fully supports Maven and is available on Maven Central! That means that if you'd like to create a project that uses BURLAP, all you need to do is add the following dependency to the <dependencies> section of your projects pom.xml edu.brown.cs.burlap burlap 3.0.0 and the library will automatically be downloaded and linked to your project! If you do not have Maven installed, you can get it from here You can also get thefull BURLAP source to manually compile/modify from Github at: https://github.com/jmacglashan/burlap Alternatively, you can directly download precompiled jars from Maven Central from here , including older versions of Java. Use the jar-with-dependencies if you want all dependencies included. If you are looking for the older version 1 of BURLAP that predated Maven, you can get the pre-compiled jars for it below, or use the v1 branch on git. version 1 pre-compiled jar with dependencies included, or version 1 pre-compiled jar with out dependencies. The Java doc for version 2 can be found here and version 1 Java doc can be here . History and Future The Brown-UMBC Reinforcement Learning and Planning (BURLAP) Java library is primarily developed and maintained by James MacGlashan, a postdoc at Brown University , with a number of contributions from various students. BURLAP originated from James MacGlashan's dissertation work at the University of Maryland, Baltimore County (UMBC) in transfer learning for reinforcement learning (Multi-source Option-based Policy Transfer). This work motivated the need for a reinforcement learning code framework that was built on top of a highly expressive domain representation that could support flexible task definitions. The answer to this demand was the object-oriented Markov Decision process (OO-MDP) formalism, which represents states as a set of objects in the world\u2014each defined by their own attributes\u2014and provides a set of high-level propositional functions that operate on the objects in states. At the time, there were no existing libraries that supported OO-MDPs (in fact, OO-MDPs were a fairly new idea in general); instead, most libraries were restricted to RL's more classic fixed feature vector representation. As a consequence, code to rapidly deploy OO-MDP domains was developed. After James graduated and moved to Brown, the initial OO-MDP code proved to be valuable in being able to quickly generate a variety of different classes of problems to which already implemented algorithms could be trivially applied. The ability to support lots of different problems enabled the code to be easily used for a number of different projects that more typically would have required reimplementation of standard algorithms for a different representation. In response, a decision was made to polish, expand, and document the code base, and make it all available to the public. The result is BURLAP as it is now. If everything goes well, BURLAP will never be \"finished\" because it will continue to have more algorithms found in reinforcement learning and planning literature added to it and grow with the field. Ideally, it will also continue grow to support even more classes of problems. As of writing this, BURLAP supports finite, infinite, continuous, and relational state spaces in single-agent or multi-agent (stochastic game) problem spaces with a finite number of parameterizable actions. (Object-oriented) Partially observable MDPs (POMDPs) is currently in development with a number of POMDP algorithms being implemented. BURLAP could also be trivially extended to support continuous action and time domains, but has not yet since there are currently no implemented algorithms in BURLAP to take advantage of it. In the future, we hope to expand into this space as well. If there is a reinforcement learning or planning problem class that BURLAP cannot support that you would like to see, we would love to hear from you so that we can consider adding in support. The ultimate goal of BURLAP is to be able to pick and choose different algorithms for any number of different problems you might want to solve and stop us from reinventing the wheel every time. BURLAP Extensions Currently there are three BURLAP library extension projects used to connect BURLAP up with other systems. BURLAP Rosbridge This extension allows you to control ROS-powered robots with BURLAP planning and learning algorithms by providing a standard BURLAP Environment class that communicates to ROS over Rosbridge . BURLAP Rosbridge is also on Maven Central, so you can simply add the following dependency along with your BURLAP dependency: edu.brown.cs.burlap burlap_rosbridge 3.0.0 BurlapCraft This extension allows you to use BURLAP planning and learning algorithms to control a player in the video game Minecraft . BURLAP Weka This extensions provides some tools for hooking up BURLAP with Weka , the machine learning library. Weka, however, is licensed under GPL, so if you use this extension, the whole license is GPL. People Organizers Brown University James MacGlashan - Creator and primary maintainer. Contact: jmacglashan at cs dot brown dot edu Michael Littman Stefanie Tellex University of Maryland, Baltimore County Marie desJardins Code Contributers David Abel Izaak Baker Gabriel Barth-Maron Stephen Brawner Spandan Dutta Daniel Fernandez Nakul Gopalan Esha Gosh Ellis Herskowitz Mark Ho Anubhav Malhotra John Meehan Michalis Michaelidis Philippe Morere Takehiro Oyakawa Chan Trau Lei Yang", "http://burlap.cs.brown.edu/tutorials/bd/p1.html": "` Building a Domain MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}}); BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building a Domain Tutorials > Building a Domain > Part 1 Tutorial Contents Introduction Markov Decision Process Java Interfaces for MDP Definitions Defining a Grid World State Defining a GridWorld Model Creating a State Visualizer Testing it Out Conclusion Final Code Next Part You are viewing the tutorial for BURLAP 3; if you'd like the BURLAP 2 tutorial, go here . Introduction This tutorial will cover three topics. First, we will review a little of the theory behind Markov Decision Processes (MDPs), which is the typical decision-making problem formulation that most planning and learning algorithms in BURLAP use. Next, we will discuss how you can implement an MDP definition in BURLAP. Finally, we will show you some basics with how to interact with your MDP and visualize it. Other Problem Types Beyond MDPs, BURLAP also supportsstochastic games and partially observable MDPs. The BURLAP example code repository has some examples with these problems, but a core understanding of the MDP representation will cover a lot of the basics that are shared in those problem types. BURLAP also has first class support for the object-oriented MDP (OO-MDP) state representation. OO-MDPs have a lot of nice properties, but it's easier to first describe how to define general MDP states, and OO-MDPs are not necessary forevery problem. Therefore, we will leave the discussion about OO-MDPs for a subsequent tutorial. If you are alreadyfamiliar with MDPs, or just want to get down to coding, feel free to skip the firstsection that discuss their mathematical description. For more information on how to useplanning and learning algorithms on the MDP domains that you create or that are already in BURLAP, see the Basic Planning and Learning tutorial. Note that all of the code in this tutorial is listed at the end and is also available in the burlap_examples github repository. Markov Decision Process To implement agents that learn how to behave or plan out behaviors for an environment, a formal description of the environment and the decision-making problem must first be defined. One of the most common formalisms used by learning and planning algorithms is the Markov Decisions Process (MDP), which considers the agent making decisions at discrete time steps to maximize a reward signal. In this tutorial, we will formalize a grid world as an MDP. A grid world is a 2D environment in which an agent can move north, south, east or west by one unit each time step, provided there are no walls in the way. The below image shows a simple grid world with the agent's position represented by a gray circle and walls of the environment painted black. Typically, the goal in a grid world is for the agent to navigate to some location, but there are a number of variants. Figure: An example grid world. All MDPs are defined by four components that we will need to specify for our grid world: a set of possible states of the environment ($S$); a set of actions that the agent can take ($A$); a definition of how actions change the state of the environment, known as the transition dynamics ($T$); and the rewards the agent receives for each of its actions ($R$), known as the reward function, which will determine what the best behavior is (that is, the agent will want to act in a way that maximizes the reward it receives). The transition dynamics are formulated as a probabilistic function $T(s' | s, a)$, which defines the probability of the environment changing to state $s'$ in the next discrete timestep when the agent takes action $a$ in the current state $s$. The fact that the environment can change stochastically is one of the unique properties of an MDP compared to more classic AI deterministic planning/decision making problems. The reward function is a function of the last state, the action taken in that last state, and the next state to which the environment transitioned as a result of that action: $R(s, a, s')$. Notice how both the transition dynamics and reward function are temporally independent from everything predating the most recentstate and action? Requiring this temporal independence from everything earlier than the last event makes this a Markov system and is why this formalism is called a Markov decision process. In our grid world, the set of states are the possible locations of the agent. The actions are north, south, east, and west. We will define the transition dynamics to be stochastic so that with high probability (0.8) the agent will move in the intended direction, and with some low probability (0.2) move in a different direction. You can imagine this stochasticity being a model for a robot with slightly unreliable driving capabilities (which, as it turns out, is often the norm!). The transition dynamics will also encode the walls of our grid world by specifying that movement that would lead into a wall will result in returning to the same state. Finally, we will define a reward function that returns a high reward when the agent reaches the top right corner of the environment and zero everywhere else, to motivate movement to that corner. For various kinds of problems, the concept of terminal states is often useful. A terminal state is a state that once reached causes all further action of the agent to cease. This is a useful concept for defining goal-directed tasks (i.e., action stops once the agent achieves a goal), failure conditions, or any number of other reasons. In our grid world, we'll want to specify the top right corner the agent is trying to get to as a terminal state. An MDP definition does not include a specific element for specifying terminal states because they can be implicitly defined in the transition dynamics and reward function. That is, a terminal state can be encoded in an MDP by being a state in which every action causes a deterministic transition back to itself with zero reward. However, for convenience and other practical reasons, terminal states in BURLAP are specified directly with a function (more on that later). The goal of planning or learning in an MDP is to find the behavior that maximizes the reward the agent receives over time. More formally, we'd say that the goal is to find a policy ($\\pi$), that is a mapping from states in the MDP to actions that the agent takes ($\\pi : S \\rightarrow A$). Sometimes, the policy can also be defined as a probability distribution over action selection in each state (and BURLAP supports this represenation), but for the moment we will consider the case when it is a direct mapping from states to actions. To find the policy that maximizes the reward over time, we must first define what it means to maximize reward over time and there are a number of different temporal objectives wecan imagine that change what the optimal policy is. Perhaps the most intuitive way to define the temporal reward maximization is to maximize thethe expected total future reward; that is, the best policy is the one that results in largest possible sum of all future rewards. Although this metric is sometimes appropriate, it's often problematic because it can result in policies that are evaluated to have infinite value or which do not discriminate between policies that receive the rewards more quickly. For example, in our grid world, any path the agent took to reach the top right would have a value 1 (because they all would eventually reach the goal); however, what we'd probably want instead is for the agent to prefer a policy that reaches the goal as fast as possible. Moreover, if we didn't set the top right corner to be a terminal state, the agent could simply move away from it and back into it, resulting in any policy that reaches the goal having an infinite value, which makes comparisons between different policies even more difficult! A commonalternative that is more robust is to define the objective to beto maximize the expected discounted future reward. That is, theagent is trying to maximize expected sum$$\\large \\sum_{t=0}^\\infty \\gamma^t r_t,$$where $r_t$ is the reward received at time $t$ and $\\gamma$ is the discount factor that dictates how much preference an agent has for more immediate rewards; in other words, the agent's patience. With $\\gamma = 1$, the agent values distantrewards that will happen much further in the future as much as the reward the agent will receive in the next time step; therefore, $\\gamma = 1$ results in the same objective of summing all future rewards together and will have the same problems previously mentioned. With $\\gamma = 0$ all the agent values only the next reward and does not care about anything that happens afterwards, thereby resulting in all policies having a finite value. This setting has the inverse effect of the agent never caring about our grid world goal location unless it's one step away. However, a $\\gamma$ value somewhere in between 0 and 1 often results in what we want. That is, for all values of $0 \\lt \\gamma \\lt 1$, the expected future discounted reward in an MDP when following any given policy is finite, while still considering events that happen in the distant future, and with a preference for more immediate satisfaction. If we set $\\gamma$ to 0.99 in our grid world, the result is that the agent would want to get to the goal as fast as possible, because waiting longer would result in the eventual +1 goal reward being more heavily discounted. Although there are still other ways to define the temporal objective of an MDP, current learning and planning algorithms in BURLAP are based on usingthe discounted reward, with the geometric discount factor $\\gamma$ left as a parameter that the user can specify. Next Part", "http://burlap.cs.brown.edu/tutorials/bd/p2.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building a Domain Tutorials > Building a Domain > Part 2 Tutorial Contents Introduction Markov Decision Process Java Interfaces for MDP Definitions Defining a Grid World State Defining a GridWorld Model Creating a State Visualizer Testing it Out Conclusion Final Code Previous Part | Next Part Java Interfaces for MDP Definitions To define your own MDP in BURLAP that can then be used with BURLAP's planning or learning algorithms, you will want to familiarize yourself with the following Java interfaces and data structures. Here we will give a brief review of what each these are, and in the subsequent sections we will be implenting the interfaces to define our grid world. A UML diagram of these elements is shown in the below figure. Figure: UML Digram of the Java interfaces/classes for an MDP definition. SADomain - A data structure that stands for \"single agent domain\". This data structure stores information about an MDP that you will define and is typically passed to different planning or learning algorithms. State - Implement this interface to define the state variables of your MDP state space. An instace of this object will specify a single state from the state space. Action - Implement this interface to define a possible action that the agent can select. If your MDP action set is discrete and unparameterized, you may consider using the provided concrete implementation SimpleAction , which defines an aciton entirely by a single String name ActionType - Implement this interface to define a kind of Java factory for generating your Actions. In particular, this interface allows you define preconditions for actions. Actions with preconditions are actions that the agent can only select/execute in some states, and not others. It also allows you to specify which kinds of parameterizations of your actions are allowable in a state, if your actions are parameterized. Often, MDPs have unparameterized actions that can be executed in any state (no precondtions). In such cases, you should consider the provided concrete implementation UniversalActionType . SampleModel - Implement this interface to define the model of your MDP. This inferface only requires you to implement methods that can sample a transition: spit back out a possible next state and reward given a prior state and action taken. Some planning algorithms, however, require more information; they may require being able to enumerate the set of possible transitions and their probability of occurring. If you wish to support these kinds of algorithms, then you will instead want to implement the FullModel interface that extends the SampleModel interface with a method for enumerating the transition probability distribution. Note that if you are defining a learning problem in which an agent interacts with an external environment from BURLAP, it may not be possible to define even a SampleModel. For example, if you're going to use BURLAP to control robots via reinforcement learning, it might not be possible for you to specify a model of reality in a meanginful way (or it might simply be unncessary). In these cases, the model can be omitted from the MDP description and instead you'll want to implement a custom Environment instance, described next. Environment - An MDP defines the nature of an environment, but ultimately, an agent will want to interact with an actual environment, either through learning or to execute a policy it computed from planning for the MDP. An environment has a specific state of the world that the agent can only modify by using the MDP actions. Implement this interface to provide an environment with which BURLAP agents can interact. If you defined the MDP yourself, then you'll probably don't want to implement Environment yourself and instead use the provided concreate SimulatedEnvironment class, which takes an SADomain with a SampleModel, and simulates an environment for it. EnvironmentOutcome - A tuple that contains a prior state/observation, an action taken in that state, a reward recieved, and a next state/observation to which the environment transitioned. This object is typically returned by an Environment instance when an action is taken, or from a SampleModel when you sample a transition. TransitionProb - A tuple containing a double and an EnvironmentOutcome object, which specifies the probability of the transition specified by EnvironmentOutcome occurring. Typically, a list of these objects is returned by a FullModel instance when querying it for the transition probability distribution. Next Part", "http://burlap.cs.brown.edu/tutorials/bd/p4.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building a Domain Tutorials > Building a Domain > Part 4 Tutorial Contents Introduction Markov Decision Process Java Interfaces for MDP Definitions Defining a Grid World State Defining a GridWorld Model Creating a State Visualizer Testing it Out Conclusion Final Code Previous Part | Next Part Defining a Grid World Model Next, we will define the model of our Grid World; how transitions and rewards are generated from actions. Lets start by defining a map of our grid world, that matches the Grid World image we used earlier in the tutorial (an 11x11 world split into 4 \"rooms\"). We will define this map using a 2D int array, with the first dimension representing x, and the second dimension representing y. Add the following to your ExampleGridWorld domain generator class: //ordered so first dimension is xprotected int [][] map = new int[][]{{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,0,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{1,0,1,1,1,1,1,1,0,1,1},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,0,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},}; To define our Grid World Model, we're going to use a FactoredModel implemention that is provided with BURLAP. A FactoredModel is a model that divides its duties into three components: a SampleStateModel, which defines the state transitions; a RewardFunction, which defines the rewards for given state transitions; and a TerminalFunction, which defines which states are terminal states of the MDP. Most domains in BURLAP use a FactoredModel, because it is often the case that clients will want to change the task of a domain (defined by the reward function and terminal state), but not the \"physics\" of the domain (how state transitions occur). Lets start with the most complex part: the state model. Just as there is a SampleModel and a FullModel for the complete model, where the SampleModel merely samples transitions and a FullModel can also enumerate the probability distribution, a state model also has a SampleStateModel and a FullStateModel. We will implement the FullStateModel. Below, we've defined an inner class to ExampleGridWorld for our FullStateModel, with the required methods left as unimplemented, which we will walk through. protected class GridWorldStateModel implements FullStateModel{@Overridepublic List<StateTransitionProb> stateTransitions(State s, Action a) {return null;}@Overridepublic State sample(State s, Action a) {return null;}} We're going to define our domain so that our four (north, south, east, west) actions are stochastic: with 0.8 probability they will go in the intended direction, and with 0.2 probability, it will randomly go in one of the other directions. To encode this stochasticity, lets define a matrix of direction transition probabilities for each action, so that the first dimension indexes by the selected action, and the next dimension indexes by the actual direction the agent will move, with the values specifying the movement in that direction, given the action selected. We will also implement a constructor that fills out this matrix, which will have 0.8 along the diagonal, and 0.8/3 on the off-diagonal elements. Note that each row will sum to 1, making it a proper probability distribution. protected double [][] transitionProbs;public GridWorldStateModel() {this.transitionProbs = new double[4][4];for(int i = 0; i < 4; i++){for(int j = 0; j < 4; j++){double p = i != j ? 0.2/3 : 0.8;transitionProbs[i][j] = p;}}} Our actions in this domain will be represented with String names (we could alternatively make Actions that are defined by int values, but for simplicity and descriptive reasons, we will use String names). Therefore, we will first want to define a method that converts an action name into an int index for the direction transition matrix we defined: protected int actionDir(Action a){int adir = -1;if(a.actionName().equals(ACTION_NORTH)){adir = 0;}else if(a.actionName().equals(ACTION_SOUTH)){adir = 1;}else if(a.actionName().equals(ACTION_EAST)){adir = 2;}else if(a.actionName().equals(ACTION_WEST)){adir = 3;}return adir;} When we either sample a state transition, or enumerate all possible outcomes, we will want to query the outcome of the agent moving in some direction. Lets add a method for doing that now. protected int [] moveResult(int curX, int curY, int direction){//first get change in x and y from direction using 0: north; 1: south; 2:east; 3: westint xdelta = 0;int ydelta = 0;if(direction == 0){ydelta = 1;}else if(direction == 1){ydelta = -1;}else if(direction == 2){xdelta = 1;}else{xdelta = -1;}int nx = curX + xdelta;int ny = curY + ydelta;int width = ExampleGridWorld.this.map.length;int height = ExampleGridWorld.this.map[0].length;//make sure new position is valid (not a wall or off bounds)if(nx < 0 || nx >= width || ny < 0 || ny >= height ||ExampleGridWorld.this.map[nx][ny] == 1){nx = curX;ny = curY;}return new int[]{nx,ny};} This method will return a 2 element int array, where the first component is the new x position of the agent and the second component is the new y position. Primarily, the method just increments/decrements the x and y values depending on what the action direction was. However, it also checks the map of our world, and if the agent would have moved into a wall, then the agent's position will not change. Now lets implement the sample method. @Overridepublic State sample(State s, Action a) {s = s.copy();EXGridState gs = (EXGridState)s;int curX = gs.x;int curY = gs.y;int adir = actionDir(a);//sample direction with random rolldouble r = Math.random();double sumProb = 0.;int dir = 0;for(int i = 0; i < 4; i++){sumProb += this.transitionProbs[adir][i];if(r < sumProb){dir = i;break; //found direction}}//get resulting positionint [] newPos = this.moveResult(curX, curY, dir);//set the new positiongs.x = newPos[0];gs.y = newPos[1];//return the state we just modifiedreturn gs;} The first thing we do is make a copy of the input state, which will be modified and returned. Then we get the agent's x and y position, by type casting the State to our EXGridState class. We also get the index of our action, and then sample a resulting direction from the direction transition matrix. We then get the resulting new position from our moveResult method, and update the copied state to be at that new position. Next we will implement the transitions method. @Overridepublic List<StateTransitionProb> stateTransitions(State s, Action a) {//get agent current positionEXGridState gs = (EXGridState)s;int curX = gs.x;int curY = gs.y;int adir = actionDir(a);List<StateTransitionProb> tps = new ArrayList<StateTransitionProb>(4);StateTransitionProb noChange = null;for(int i = 0; i < 4; i++){int [] newPos = this.moveResult(curX, curY, i);if(newPos[0] != curX || newPos[1] != curY){//new possible outcomeEXGridState ns = gs.copy();ns.x = newPos[0];ns.y = newPos[1];//create transition probability object and add to our list of outcomestps.add(new StateTransitionProb(ns, this.transitionProbs[adir][i]));}else{//this direction didn't lead anywhere new//if there are existing possible directions//that wouldn't lead anywhere, aggregate with themif(noChange != null){noChange.p += this.transitionProbs[adir][i];}else{//otherwise create this new state and transitionnoChange = new StateTransitionProb(s.copy(), this.transitionProbs[adir][i]);tps.add(noChange);}}}return tps;} In many ways, this method is a lot like our sample method, except instead of randomly sampling a direction, we iterate over each possible outcome direction and consider movement in that direction. For each of those possible directions, we make a copy of the input state, change its position based on our moveResult method, and then put it in a StateTransitionProb tuple, which is a pair consisting of the probability of the outcome (determined from the entry in our transition matrix) and the outcome state we created, and we add each StateTransitionProb to a list to be returned by our method. There is one extra bit of book keeping we perform in this method. If the agent tries to move into a wall, it's position does not change. And if a wall exists on multiple sides of the agent, then there are multiple possible directions that would result in the agent not moving. However, we don't want a separate StateTransitionProb element for multiple occurrences of the agent not changing position. So instead, if the agent's position doesn't change, we simply add the probability mass of the agent attempting to move in that direction to any existing StateTransitionProb element we have created that results in the agent not changing position. We've now completed the state transition model. Next, lets implement a RewardFunction and TerminalFunction. We'll start with the TerminalFunction, which we'll let specify a single location in our grid world to be a terminal (goal) state and we'll let that location be a parameter. public static class ExampleTF implements TerminalFunction {int goalX;int goalY;public ExampleTF(int goalX, int goalY){this.goalX = goalX;this.goalY = goalY;}@Overridepublic boolean isTerminal(State s) {//get location of agent in next stateint ax = (Integer)s.get(VAR_X);int ay = (Integer)s.get(VAR_Y);//are they at goal location?if(ax == this.goalX && ay == this.goalY){return true;}return false;}} Our reward function will work similarly, but return a reward of -1 for all transitions, except the transition to a goal location, which will return +100. public static class ExampleRF implements RewardFunction {int goalX;int goalY;public ExampleRF(int goalX, int goalY){this.goalX = goalX;this.goalY = goalY;}@Overridepublic double reward(State s, Action a, State sprime) {int ax = (Integer)s.get(VAR_X);int ay = (Integer)s.get(VAR_Y);//are they at goal location?if(ax == this.goalX && ay == this.goalY){return 100.;}return -1;}} Note that the reward function operates on the sprime method argument, not the s argument. The sprime argument specifies the state to which the agent transitioned, whereas the argument s specifies the state the agent left, and we want the goal reward to occur on transitions to the goal location, so we evaluate sprime. We're just about ready to finish up our domain. Before we do, lets add two data members and ExampleGridWorld methods to allow a client to set the goal location. Add the data members protected int goalx = 10;protected int goaly = 10; And add the method public void setGoalLocation(int goalx, int goaly){this.goalx = goalx;this.goaly = goaly;} Now lets finish by implementing our generateDomain method! @Overridepublic SADomain generateDomain() {SADomain domain = new SADomain();domain.addActionTypes(new UniversalActionType(ACTION_NORTH),new UniversalActionType(ACTION_SOUTH),new UniversalActionType(ACTION_EAST),new UniversalActionType(ACTION_WEST));GridWorldStateModel smodel = new GridWorldStateModel();RewardFunction rf = new ExampleRF(this.goalx, this.goaly);TerminalFunction tf = new ExampleTF(this.goalx, this.goaly);domain.setModel(new FactoredModel(smodel, rf, tf));return domain;} The generateDomain method starts by making a new SADomain instance. Then we add an ActionType for each of our actions. Our grid world north, south, east, west actions are unparameterized actions that can be applied anywhere in the world, so we can use BURLAP's provided UnviersalActionType implementation, which simply requires a name for each of the actions. We then create an instance of our state model, and a reward function and terminal function using our implemented methods with a goal location set to the ExampleGridWorld instance's goalx and goaly values. The elements are used to define a FactoredModel, which is added to our domain. Then, we return the created domain! We've now created all the elements we need for our grid world MDP and it's now ready to be used with BURLAP algorithms. However, it is often very useful to be able to visualize a domain. In the next section, we will show you have to create a visualizer for our grid world domain. Next Part", "http://burlap.cs.brown.edu/tutorials/bd/p3.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building a Domain Tutorials > Building a Domain > Part 3 Tutorial Contents Introduction Markov Decision Process Java Interfaces for MDP Definitions Defining a Grid World State Defining a GridWorld Model Creating a State Visualizer Testing it Out Conclusion Final Code Previous Part | Next Part Defining a Grid World State The first primary task we will complete in defining our Grid World MDP is to define what states look like. Before doing that though, lets first make a class that will use to generate our ultimate SADomain, and hold constants for various important values. We will then use some of these constants in the definition of our State. Start by creating the below class, which implements DomainGenerator. DomainGenerator is an optional interface commonly used in BURLAP that constains a method for generating a Domain object. Below is the class with the constants we will use throughout this tutorial, as well as the imports it will ultimately be using. import burlap.mdp.auxiliary.DomainGenerator;import burlap.mdp.core.StateTransitionProb;import burlap.mdp.core.TerminalFunction;import burlap.mdp.core.action.Action;import burlap.mdp.core.action.UniversalActionType;import burlap.mdp.core.state.State;import burlap.mdp.singleagent.SADomain;import burlap.mdp.singleagent.environment.SimulatedEnvironment;import burlap.mdp.singleagent.model.FactoredModel;import burlap.mdp.singleagent.model.RewardFunction;import burlap.mdp.singleagent.model.statemodel.FullStateModel;import burlap.shell.visual.VisualExplorer;import burlap.visualizer.StatePainter;import burlap.visualizer.StateRenderLayer;import burlap.visualizer.Visualizer;import java.awt.*;import java.awt.geom.Ellipse2D;import java.awt.geom.Rectangle2D;import java.util.ArrayList;import java.util.List;public static final String VAR_X = \"x\";public static final String VAR_Y = \"y\";public static final String ACTION_NORTH = \"north\";public static final String ACTION_SOUTH = \"south\";public static final String ACTION_EAST = \"east\";public static final String ACTION_WEST = \"west\";public class ExampleGridWorld implements DomainGenerator {public SADomain generateDomain() {return null; //we'll come back to this later}} With this class and its constants defined, lets now create a class for describing Grid World states (we'll place this in a separate file). To do that, we will want our class to implement the State interface. We will actually go one step further, and have it implement MutableState, an extension to the State interface that also provides a method for setting state variables. Start with the below code, which has stubs for each of the required methods and all the imports for what we'll eventually be using. import burlap.mdp.core.state.MutableState;import burlap.mdp.core.state.StateUtilities;import burlap.mdp.core.state.UnknownKeyException;import burlap.mdp.core.state.annotations.DeepCopyState;import java.util.Arrays;import java.util.List;import static edu.brown.cs.burlap.tutorials.domain.simple.ExampleGridWorld.VAR_X;import static edu.brown.cs.burlap.tutorials.domain.simple.ExampleGridWorld.VAR_Y;public class EXGridState implements MutableState{@Overridepublic MutableState set(Object variableKey, Object value) {return this;}@Overridepublic List<Object> variableKeys() {return null;}@Overridepublic Object get(Object variableKey) {return null;}@Overridepublic EXGridState copy() {return null}} Our grid world state will be defined entirely by the agent's x and y location in the world. Lets add data members for that to our class. We'll also add relevant constructors. Serialization To support trivial serialization of states with something like Yaml (the default approach BURLAP uses), you should make sure your State objects are Java Beans , which meanshaving a default constructor and get and set methods for all non-public data fields that follow standard Java getter and setter method name paradigms. public int x;public int y;public EXGridState() {}public EXGridState(int x, int y) {this.x = x;this.y = y;} Although we've now defined our state variables, unless some client code knows exactly what kind of State object it is, it won't be able to access or modify (in the case of MutableState objects) these state variables. Most of the methods of the State and MutableState interface provide a general mechanism for client code to work with a State's variables. The variableKeys method returns a list of Object elements that specify variable keys that can be used to get or state variables; the get method takes a variable key, and returns the variable value for that key; and the setMethod takes a variable key and a value and sets the variable to that value (and is expected to return itself to support method chaining of variable sets). Note that the variable keys, being of type Object, can be of any data type that is most relevant to indexing/specifying a variable. Common choices include String or Integer keys, but it can really be any type. Variable values are also typed to Object, which similarly means that your States variables can be made up any conceivable data type that you want, allowing you to easily represent any kind of state! To implement these three methods, lets first define a class constant list for the variable keys (we don't need a separate copy for each State instance, since the variable keys are always the same, and using a class constant will save on the memory overhead.) private final static List&ltObject> keys = Arrays.<Object>asList(VAR_X, VAR_Y); Note that for keys, we are using Strings for variable names, and the constants for these names were defined in our ExampleGridWorld domain generator. Now lets implement the variableKeys, set, and get methods, which is done mostly as you would expect. @Overridepublic MutableState set(Object variableKey, Object value) {if(variableKey.equals(VAR_X)){this.x = StateUtilities.stringOrNumber(value).intValue();}else if(variableKey.equals(VAR_Y)){this.y = StateUtilities.stringOrNumber(value).intValue();}else{throw new UnknownKeyException(variableKey);}return this;}@Overridepublic List<Object> variableKeys() {return keys;}@Overridepublic Object get(Object variableKey) {if(variableKey.equals(VAR_X)){return x;}else if(variableKey.equals(VAR_Y)){return y;}throw new UnknownKeyException(variableKey);} There are two things to note. First, if client code passes a variable key that is not the x or y key, then we throw a standard BURLAP UnknownKeyException. Second, you will notice that in the set method, we process the variable value through the StateUtilities stringOrNumber method. This method takes as input an Object. If that object is a String, then it returns a Java Number instance of the number that String represents. If it is a Number already, then it simply returns it back, cast as a Number. This method is useful because it allows client code to specify values with string representations of numbers or an actual number. BURLAP Shell And MutableState One piece of client code that benefits from setting state variables with string representations of the value is the BURLAP shell, which is a runtime shell that lets you interact with BURLAP environments with different commands (and you can make your own commands to add to the shell too). If the environment is a simulated BURLAP environment, then one of the shell commands lets you modify the state of the environment from the command line, provided your State's set method supports String representations of keys and values. Later in this tutorial, we will launch a visual BURLAP shell with the domain we create and you can try it out! Next we will want to implement the copy method. The copy method returns, as the name suggests, a State object that is a copy of this state. The copy method is most commonly use when defining the MDP's transition dynamics/model. That is, when the outcome of executing an action in a specific input state is request, we will usually first make a copy of the input state, modify the values that need to be modified, and return the modified copied. We will see how to define transition dynamics that use this approach shortly. We can implement the copy method by simply creating a new EXGridState instance and passing its constructor this object's current x and y values. @Overridepublic EXGridState copy() {return new EXGridState(x, y);} Because our State's data fields are simple Java primitives, the copy we return is a deep copy. Consequently, modifying any data member of a copied state will not affect the values of the state from which it was copied. However, for State implementations with more complex data members, we might instead define our copy operation to do a shallow copy, which simply passes the references of the data members. To help indicate to clients what kind of copy operation a State performs, there are two optional class annotations you can add to your class; DeepCopyState and ShallowCopyState. Since our State is a DeepCopyState, lets add the optional annotation to our class. @DeepCopyStatepublic class EXGridState implements MutableState{...} Why would you ever shallow copy? Recall that the State copy method is typically used when generating the transition dynamics of an MDP (as you will see shortly). Using a shallow copy is often more memory efficient, because it means common data between states that are generated through transitions are shared, rather than replicated for each state. However, it does mean that the transition code needs to make sure that it manually makes a copy of the specific data members that it modifies of the copy, since the copy method itself won't do it. It is also usually a good idea to have the set method of shallow copied states perform a copy on write ; that is, it automatically makes a copy of the value it's modifying first. If you are in doubt, then making your copy method always perform a deep copy will be safe, but if you're looking to improve memory overhead, you may want to consider shallow copies. Many of the included BURLAP domains use shallow copies, with the set method performing a copy on write. We're just about done defining our Grid World State, but lets also add a toString method, so that we can have meaningful string representations of our State. To implement that method, we can simply use the corresponding StateUtilities method, which will iterate through the variable keys (or you can implement it manually yourself, if you wish). @Overridepublic String toString() {return StateUtilities.stateToString(this);} And with that, we're finished defining our GridWorld State! Next Part", "http://burlap.cs.brown.edu/tutorials/bd/p5.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building a Domain Tutorials > Building a Domain > Part 5 Tutorial Contents Introduction Markov Decision Process Java Interfaces for MDP Definitions Defining a Grid World State Defining a GridWorld Model Creating a State Visualizer Testing it Out Conclusion Final Code Previous Part Creating a State Visualizer It is often the case that you will want to visualize states of your domain in various contexts. For example, maybe you want to interact with the environment, acting as the agent yourself, or maybe you want to review episodes generated from a learning agent or a policy. BURLAP provides standard interfaces and tools for doing these kinds of things. Specifically, BURLAP provides a MultiLayerRenderer object that is a JPanel. It maintains a list of RenderLayer objects that paint to the graphics context of the MultiLayerRenderer (or rather, an offscreen buffer of it) in the order of the RenderLayers (i.e., painters algorithm). One of the more common RenderLayer instances is the StateRenderLayer, used to render a state. StateRenderLayer holds a current State to paint, which can be updated externally, and a list of StatePainter instances that, similar to a RenderLayer, are interfaces that are provided a State and Graphics2D context to which an aspect of the state is painted. Also useful is the Visualizer class, an extension of MultiLayerRenderer that is assumed to contain a StateRenderLayer and provides quick access methods for updating the State of the StateRenderLayer to render. A UML diagram of these classes is shown below. Figure: UML Digram of the Java interfaces/classes for visualization. Therefore, the standard way to provide state visualization in BURLAP, is to implement one or more StatePainters, which can then be added to a StateRenderLayer used by a Visualizer. For our grid world, we will create two StatePainter implementations, one for drawing the walls of our grid world, and another for drawing the location of the agent. We'll make these inner classes of our ExampleGridWorld class. public class WallPainter implements StatePainter {public void paint(Graphics2D g2, State s, float cWidth, float cHeight) {//walls will be filled in blackg2.setColor(Color.BLACK);//set up floats for the width and height of our domainfloat fWidth = ExampleGridWorld.this.map.length;float fHeight = ExampleGridWorld.this.map[0].length;//determine the width of a single cell//on our canvas such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;//pass through each cell of our map and if it's a wall, paint a black rectangle on our//cavas of dimension widthxheightfor(int i = 0; i < ExampleGridWorld.this.map.length; i++){for(int j = 0; j < ExampleGridWorld.this.map[0].length; j++){//is there a wall here?if(ExampleGridWorld.this.map[i][j] == 1){//left coordinate of cell on our canvasfloat rx = i*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas//origin is in the top left instead of the bottom rightfloat ry = cHeight - height - j*height;//paint the rectangleg2.fill(new Rectangle2D.Float(rx, ry, width, height));}}}}}public class AgentPainter implements StatePainter {@Overridepublic void paint(Graphics2D g2, State s,float cWidth, float cHeight) {//agent will be filled in grayg2.setColor(Color.GRAY);//set up floats for the width and height of our domainfloat fWidth = ExampleGridWorld.this.map.length;float fHeight = ExampleGridWorld.this.map[0].length;//determine the width of a single cell on our canvas//such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;int ax = (Integer)s.get(VAR_X);int ay = (Integer)s.get(VAR_Y);//left coordinate of cell on our canvasfloat rx = ax*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas//origin is in the top left instead of the bottom rightfloat ry = cHeight - height - ay*height;//paint the rectangleg2.fill(new Ellipse2D.Float(rx, ry, width, height));}} There is nothing fancy going on in this code. In the case of the AgentPainter, we get the x and y variable values of the agent, get their position in screen space, and draw a circle. We do something similar for the wall painter, but iterate over our map drawing black rectangles wherever a wall is present. Finally, lets add some methods to our ExampleGridWorld class for packaging instances of these painters into a StateRenderLayer and a Visualizer. public StateRenderLayer getStateRenderLayer(){StateRenderLayer rl = new StateRenderLayer();rl.addStatePainter(new ExampleGridWorld.WallPainter());rl.addStatePainter(new ExampleGridWorld.AgentPainter());return rl;}public Visualizer getVisualizer(){return new Visualizer(this.getStateRenderLayer());} Testing it Out Now that we've made all the pieces of our domain, lets test it out! A good way to test out a domain is to create a VisualExplorer that lets you act as the agent and see the state of the world through a Visualizer. Add the following main method to our ExampleGridWorldClass. public static void main(String [] args){ExampleGridWorld gen = new ExampleGridWorld();gen.setGoalLocation(10, 10);SADomain domain = gen.generateDomain();State initialState = new EXGridState(0, 0);SimulatedEnvironment env = new SimulatedEnvironment(domain, initialState);Visualizer v = gen.getVisualizer();VisualExplorer exp = new VisualExplorer(domain, env, v);exp.addKeyAction(\"w\", ACTION_NORTH, \"\");exp.addKeyAction(\"s\", ACTION_SOUTH, \"\");exp.addKeyAction(\"d\", ACTION_EAST, \"\");exp.addKeyAction(\"a\", ACTION_WEST, \"\");exp.initGUI();} The first block of code instantiates our domain with the goal state set to 10, 10 (the top right corner); creates an initial state with the agent in location 0, 0; and creates a Simulated Environment around our domain. The environment could be used for any number of purposes, including using it with learning algorithms. Here, we use it as the domain we'll explore with a VisualExplorer that visualizes states with the Visualizer components we defined earlier. The addKeyAction methods let us set up key bindings to execute actions in the environment. The arguments of this method correspond to the key you want to send the action, the name of the ActionType, and a String representation of the parameters of the action, which we leave empty since our actions are unparameterized. (Another variant of this method will let you specify the direct Action object you want it to use, rather than generating the Action from an ActionType identified by its name). Finally, the initGUI() method will start the VisualExplorer. When you run the ExampleGridWorld class, the visual explorer should pop up, which will look like the below image. Figure: Screenshot of the VisualExplorer that will launch. If you use the w-a-s-d keys, you can control the agent's movements in the environment. Note that because we made our grid world stochastic, sometimes the agent will go in a different direction than the action you selected! This is precisely the kind of mechanics that a learning agent would experience, given the definition of the MDP we made. One other element of the VisualExplorer you might want to experiment with is the shell, which you can open with the \"Show Shell\" button, which will bring up a text box and field you can use to send special commands for working with an environment. If you want a list of commands that are available in the shell, enter \"cmds\". Most commands also include help information, which you can get by entering the command with the -h option. To see an example of something you can do with the shell, try changing the agent's position in the environment to 3,2 by entering the command: setVar x 3 y 2 and you should see that the agent in the visualizer appears in the specified location! You can also add your own commands to a BURLAP shell, by implementing the ShellCommand interface, and adding it to the shell. You can get the shell of a VisualExplorer with the method getShell() and you can add ShellCommands to it with the method addCommand(ShellCommand). The shell is a powerful tool for controlling runtime experimentation. Conclusion That's it! We've now walked you through how you can implement your own MDP in BURLAP that can be used with the various learning and planning algorithms. We also showed you how to create a visualizer for them and how to interact with them. There is another tutorial specifically about creating MDPs that use the object-oriented MDP state representation, but this is an advanced optional rich state representation and you should be able to get by fine with standard MDP definitions. Final Code ExampleGridWorld.java import burlap.mdp.auxiliary.DomainGenerator;import burlap.mdp.core.StateTransitionProb;import burlap.mdp.core.TerminalFunction;import burlap.mdp.core.action.Action;import burlap.mdp.core.action.UniversalActionType;import burlap.mdp.core.state.State;import burlap.mdp.singleagent.SADomain;import burlap.mdp.singleagent.environment.SimulatedEnvironment;import burlap.mdp.singleagent.model.FactoredModel;import burlap.mdp.singleagent.model.RewardFunction;import burlap.mdp.singleagent.model.statemodel.FullStateModel;import burlap.shell.visual.VisualExplorer;import burlap.visualizer.StatePainter;import burlap.visualizer.StateRenderLayer;import burlap.visualizer.Visualizer;import java.awt.*;import java.awt.geom.Ellipse2D;import java.awt.geom.Rectangle2D;import java.util.ArrayList;import java.util.List;public class ExampleGridWorld implements DomainGenerator {public static final String VAR_X = \"x\";public static final String VAR_Y = \"y\";public static final String ACTION_NORTH = \"north\";public static final String ACTION_SOUTH = \"south\";public static final String ACTION_EAST = \"east\";public static final String ACTION_WEST = \"west\";protected int goalx = 10;protected int goaly = 10;//ordered so first dimension is xprotected int [][] map = new int[][]{{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,0,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{1,0,1,1,1,1,1,1,0,1,1},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,0,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},};public void setGoalLocation(int goalx, int goaly){this.goalx = goalx;this.goaly = goaly;}@Overridepublic SADomain generateDomain() {SADomain domain = new SADomain();domain.addActionTypes(new UniversalActionType(ACTION_NORTH),new UniversalActionType(ACTION_SOUTH),new UniversalActionType(ACTION_EAST),new UniversalActionType(ACTION_WEST));GridWorldStateModel smodel = new GridWorldStateModel();RewardFunction rf = new ExampleRF(this.goalx, this.goaly);TerminalFunction tf = new ExampleTF(this.goalx, this.goaly);domain.setModel(new FactoredModel(smodel, rf, tf));return domain;}public StateRenderLayer getStateRenderLayer(){StateRenderLayer rl = new StateRenderLayer();rl.addStatePainter(new ExampleGridWorld.WallPainter());rl.addStatePainter(new ExampleGridWorld.AgentPainter());return rl;}public Visualizer getVisualizer(){return new Visualizer(this.getStateRenderLayer());}protected class GridWorldStateModel implements FullStateModel{protected double [][] transitionProbs;public GridWorldStateModel() {this.transitionProbs = new double[4][4];for(int i = 0; i < 4; i++){for(int j = 0; j < 4; j++){double p = i != j ? 0.2/3 : 0.8;transitionProbs[i][j] = p;}}}@Overridepublic List<StateTransitionProb> stateTransitions(State s, Action a) {//get agent current positionEXGridState gs = (EXGridState)s;int curX = gs.x;int curY = gs.y;int adir = actionDir(a);List<StateTransitionProb> tps = new ArrayList<StateTransitionProb>(4);StateTransitionProb noChange = null;for(int i = 0; i < 4; i++){int [] newPos = this.moveResult(curX, curY, i);if(newPos[0] != curX || newPos[1] != curY){//new possible outcomeEXGridState ns = gs.copy();ns.x = newPos[0];ns.y = newPos[1];//create transition probability object and add to our list of outcomestps.add(new StateTransitionProb(ns, this.transitionProbs[adir][i]));}else{//this direction didn't lead anywhere new//if there are existing possible directions//that wouldn't lead anywhere, aggregate with themif(noChange != null){noChange.p += this.transitionProbs[adir][i];}else{//otherwise create this new state and transitionnoChange = new StateTransitionProb(s.copy(), this.transitionProbs[adir][i]);tps.add(noChange);}}}return tps;}@Overridepublic State sample(State s, Action a) {s = s.copy();EXGridState gs = (EXGridState)s;int curX = gs.x;int curY = gs.y;int adir = actionDir(a);//sample direction with random rolldouble r = Math.random();double sumProb = 0.;int dir = 0;for(int i = 0; i < 4; i++){sumProb += this.transitionProbs[adir][i];if(r < sumProb){dir = i;break; //found direction}}//get resulting positionint [] newPos = this.moveResult(curX, curY, dir);//set the new positiongs.x = newPos[0];gs.y = newPos[1];//return the state we just modifiedreturn gs;}protected int actionDir(Action a){int adir = -1;if(a.actionName().equals(ACTION_NORTH)){adir = 0;}else if(a.actionName().equals(ACTION_SOUTH)){adir = 1;}else if(a.actionName().equals(ACTION_EAST)){adir = 2;}else if(a.actionName().equals(ACTION_WEST)){adir = 3;}return adir;}protected int [] moveResult(int curX, int curY, int direction){//first get change in x and y from direction using 0: north; 1: south; 2:east; 3: westint xdelta = 0;int ydelta = 0;if(direction == 0){ydelta = 1;}else if(direction == 1){ydelta = -1;}else if(direction == 2){xdelta = 1;}else{xdelta = -1;}int nx = curX + xdelta;int ny = curY + ydelta;int width = ExampleGridWorld.this.map.length;int height = ExampleGridWorld.this.map[0].length;//make sure new position is valid (not a wall or off bounds)if(nx < 0 || nx >= width || ny < 0 || ny >= height ||ExampleGridWorld.this.map[nx][ny] == 1){nx = curX;ny = curY;}return new int[]{nx,ny};}}public class WallPainter implements StatePainter {public void paint(Graphics2D g2, State s, float cWidth, float cHeight) {//walls will be filled in blackg2.setColor(Color.BLACK);//set up floats for the width and height of our domainfloat fWidth = ExampleGridWorld.this.map.length;float fHeight = ExampleGridWorld.this.map[0].length;//determine the width of a single cell//on our canvas such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;//pass through each cell of our map and if it's a wall, paint a black rectangle on our//cavas of dimension widthxheightfor(int i = 0; i < ExampleGridWorld.this.map.length; i++){for(int j = 0; j < ExampleGridWorld.this.map[0].length; j++){//is there a wall here?if(ExampleGridWorld.this.map[i][j] == 1){//left coordinate of cell on our canvasfloat rx = i*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas//origin is in the top left instead of the bottom rightfloat ry = cHeight - height - j*height;//paint the rectangleg2.fill(new Rectangle2D.Float(rx, ry, width, height));}}}}}public class AgentPainter implements StatePainter {@Overridepublic void paint(Graphics2D g2, State s,float cWidth, float cHeight) {//agent will be filled in grayg2.setColor(Color.GRAY);//set up floats for the width and height of our domainfloat fWidth = ExampleGridWorld.this.map.length;float fHeight = ExampleGridWorld.this.map[0].length;//determine the width of a single cell on our canvas//such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;int ax = (Integer)s.get(VAR_X);int ay = (Integer)s.get(VAR_Y);//left coordinate of cell on our canvasfloat rx = ax*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas//origin is in the top left instead of the bottom rightfloat ry = cHeight - height - ay*height;//paint the rectangleg2.fill(new Ellipse2D.Float(rx, ry, width, height));}}public static class ExampleRF implements RewardFunction {int goalX;int goalY;public ExampleRF(int goalX, int goalY){this.goalX = goalX;this.goalY = goalY;}@Overridepublic double reward(State s, Action a, State sprime) {int ax = (Integer)s.get(VAR_X);int ay = (Integer)s.get(VAR_Y);//are they at goal location?if(ax == this.goalX && ay == this.goalY){return 100.;}return -1;}}public static class ExampleTF implements TerminalFunction {int goalX;int goalY;public ExampleTF(int goalX, int goalY){this.goalX = goalX;this.goalY = goalY;}@Overridepublic boolean isTerminal(State s) {//get location of agent in next stateint ax = (Integer)s.get(VAR_X);int ay = (Integer)s.get(VAR_Y);//are they at goal location?if(ax == this.goalX && ay == this.goalY){return true;}return false;}}public static void main(String [] args){ExampleGridWorld gen = new ExampleGridWorld();gen.setGoalLocation(10, 10);SADomain domain = gen.generateDomain();State initialState = new EXGridState(0, 0);SimulatedEnvironment env = new SimulatedEnvironment(domain, initialState);Visualizer v = gen.getVisualizer();VisualExplorer exp = new VisualExplorer(domain, env, v);exp.addKeyAction(\"w\", ACTION_NORTH, \"\");exp.addKeyAction(\"s\", ACTION_SOUTH, \"\");exp.addKeyAction(\"d\", ACTION_EAST, \"\");exp.addKeyAction(\"a\", ACTION_WEST, \"\");exp.initGUI();}} ExGridState.java import burlap.mdp.core.state.MutableState;import burlap.mdp.core.state.StateUtilities;import burlap.mdp.core.state.UnknownKeyException;import burlap.mdp.core.state.annotations.DeepCopyState;import java.util.Arrays;import java.util.List;import static edu.brown.cs.burlap.tutorials.domain.simple.ExampleGridWorld.VAR_X;import static edu.brown.cs.burlap.tutorials.domain.simple.ExampleGridWorld.VAR_Y;@DeepCopyStatepublic class EXGridState implements MutableState{public int x;public int y;private final static List<Object> keys = Arrays.<Object>asList(VAR_X, VAR_Y);public EXGridState() {}public EXGridState(int x, int y) {this.x = x;this.y = y;}@Overridepublic MutableState set(Object variableKey, Object value) {if(variableKey.equals(VAR_X)){this.x = StateUtilities.stringOrNumber(value).intValue();}else if(variableKey.equals(VAR_Y)){this.y = StateUtilities.stringOrNumber(value).intValue();}else{throw new UnknownKeyException(variableKey);}return this;}public List<Object> variableKeys() {return keys;}@Overridepublic Object get(Object variableKey) {if(variableKey.equals(VAR_X)){return x;}else if(variableKey.equals(VAR_Y)){return y;}throw new UnknownKeyException(variableKey);}@Overridepublic EXGridState copy() {return new EXGridState(x, y);}@Overridepublic String toString() {return StateUtilities.stateToString(this);}} End.", "http://burlap.cs.brown.edu/tutorials/bpl/p1.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Basic Planning and Learning Tutorials > Basic Planning and Learning > Part 1 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A* Planning with Value Iteration Learning with Q-Learning Learning with Sarsa(\u03bb) Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Next Part You are viewing the tutorial for BURLAP 3; if you'd like the BURLAP 2 tutorial, go here . Introduction The purpose of this tutorial is to get you familiar with using some of the planning and learning algorithmsin BURLAP. Specifically, this tutorial will cover instantiating a grid world domain bundled with BURLAP, and having the task solved with Q-learning, Sarsa learning, BFS, DFS, A*, and ValueIteration. This tutorial will also show you how to visualize these results in various ways using tools in BURLAP. The take home message you should get from this tutorial is that using different planningand learning algorithms largely amounts to changing the algorithm Java object you instantiate, with everythingelse being the same. You are encouraged to extend this tutorial on your own using some of the other planningand learning algorithms in BURLAP. The complete set of code written in this tutorial is availabe at the end, and in the burlap_examples github repository. Creating the class shell For this tutorial, we will start by making a class that has data members for all the domain and task relevantproperties. In the tutorial we will call this class \"BasicBehavior\" but feel free to name it to whatever you like.Since we will also be running the examples from this class, we'll include a main method. For convenience, we have also included at the start all of the class the imports that you will need for this tutorial. If you have a good IDE, like IntelliJ or Eclipse, those can auto import the classes as you go so that you never have to write an import line yourself. import burlap.behavior.policy.GreedyQPolicy;import burlap.behavior.policy.Policy;import burlap.behavior.policy.PolicyUtils;import burlap.behavior.singleagent.Episode;import burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizer;import burlap.behavior.singleagent.auxiliary.StateReachability;import burlap.behavior.singleagent.auxiliary.performance.LearningAlgorithmExperimenter;import burlap.behavior.singleagent.auxiliary.performance.PerformanceMetric;import burlap.behavior.singleagent.auxiliary.performance.TrialMode;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.ValueFunctionVisualizerGUI;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.ArrowActionGlyph;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.LandmarkColorBlendInterpolation;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.PolicyGlyphPainter2D;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.StateValuePainter2D;import burlap.behavior.singleagent.learning.LearningAgent;import burlap.behavior.singleagent.learning.LearningAgentFactory;import burlap.behavior.singleagent.learning.tdmethods.QLearning;import burlap.behavior.singleagent.learning.tdmethods.SarsaLam;import burlap.behavior.singleagent.planning.Planner;import burlap.behavior.singleagent.planning.deterministic.DeterministicPlanner;import burlap.behavior.singleagent.planning.deterministic.informed.Heuristic;import burlap.behavior.singleagent.planning.deterministic.informed.astar.AStar;import burlap.behavior.singleagent.planning.deterministic.uninformed.bfs.BFS;import burlap.behavior.singleagent.planning.deterministic.uninformed.dfs.DFS;import burlap.behavior.singleagent.planning.stochastic.valueiteration.ValueIteration;import burlap.behavior.valuefunction.QProvider;import burlap.behavior.valuefunction.ValueFunction;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.GridWorldTerminalFunction;import burlap.domain.singleagent.gridworld.GridWorldVisualizer;import burlap.domain.singleagent.gridworld.state.GridAgent;import burlap.domain.singleagent.gridworld.state.GridLocation;import burlap.domain.singleagent.gridworld.state.GridWorldState;import burlap.mdp.auxiliary.stateconditiontest.StateConditionTest;import burlap.mdp.auxiliary.stateconditiontest.TFGoalCondition;import burlap.mdp.core.TerminalFunction;import burlap.mdp.core.state.State;import burlap.mdp.core.state.vardomain.VariableDomain;import burlap.mdp.singleagent.common.GoalBasedRF;import burlap.mdp.singleagent.common.VisualActionObserver;import burlap.mdp.singleagent.environment.SimulatedEnvironment;import burlap.mdp.singleagent.model.FactoredModel;import burlap.mdp.singleagent.oo.OOSADomain;import burlap.statehashing.HashableStateFactory;import burlap.statehashing.simple.SimpleHashableStateFactory;import burlap.visualizer.Visualizer;import java.awt.*;import java.util.List;public class BasicBehavior {GridWorldDomain gwdg;OOSADomain domain;RewardFunction rf;TerminalFunction tf;StateConditionTest goalCondition;State initialState;HashableStateFactory hashingFactory;SimulatedEnvironment env;public static void main(String[] args) {//we'll fill this in later}} If you're already familiar with MDPs in general, the importance of some of these data members will beobvious. However, we will walk through in detail what each data member is and why we're going to need it. GridWorldDomaingwdg A GridWorldDomain is a DomainGenerator implementation for creating grid worlds. Domain domain An OOSADomain object is a fundamental class for defining problem domains that have OO-MDP state representations (although we will not focus on the OO-MDP aspects here). In short, any Domain object contain all of the elements of an MDP, except the entire state space, which is not included since for many domains it may be infinite. TerminalFunction tf By default, our grid world will use a UniformCostRF , a reward function that returns -1 everywhere. But if we want to specify a goal state, we need to tell our GridWorld generator which states are terminal states, which we do with a TerminalFunction. TerminalFunction is an interface with a boolean method that defines which states are terminal states. StateConditionTest goalCondition Not all planning algorithms are designed to maximize reward functions. Manyare instead defined as search algorithms that seek action sequences that will cause the agent to reach specific goal states. A StateConditionTest is an interface with a boolean method that takes a state as an argument similar to aTerminalFunction, only we use it as a means to specify arbitrary state conditions, rather than just terminal states. We will use StateConditionTest to specify the goal state(s) of search-based planning algorithms. State initialState Since domains are not required to enumerate entire state spaces, we will need to define at least the initial state of our problem, which we hold in this data member. HashableStateFactory hasingFactory In this tutorial we will cover tabular algorithms; algorithms that learn or plan with tabular identifiers for states (in the later Solving Continuous Domains tutorial , we will cover how to use BURLAP to solve continuous domains). Typically, for fast access, tabular algorithms will associate values for states in a HashMap, which means tabular methods need some way to compute hash codes and test equality of states. The obvious solution is for State implementations to implement the Java equals and hashCode methods. However, it is not uncommon that differnet scenarios will require different ways of computing hash codes or state equality that the creator of the State did not anticipate, such as state abstraction or variable discretization. Therefore, BURLAP makes use of HashableStateFactory objects that allows a client to specify how to hash and check state equality for states. There are a number of default implementations also provided in BURLAP. Environment env Learning algorithms address a problem in which the agent observes its environment, makes a decision, and then observes how the environment changes. This is a challenging problem because initially, an agent will not know how the environment works or what a good decision is, but must live with the consequences of their decision. To facilitate the construction of learning problems, all single-agent learning algorithms in BURLAP (algorithms that implement the LearningAgent interface), interact with an implementation of the Environment interface. One of the included concrete implementations is SimulatedEnvironment , which you can use when you're constructing an Environment for a BURLAP domain that has an included model. Other concrete Environment implementations in BURLAP or library extensions to BURLAP include RL Glue hooks using a BURLAP agent with an RL Glue Environment. burlap_rosbridge for using BURLAP with robots embodied in the real world. BurlapCraft , for using BURLAP to control a Minecraft player. Since Environment is an interface, you can also easily implement your own version if you need a BURLAP agent to interact with external code or systems that are not already provided in BURLAP. Next Part", "http://burlap.cs.brown.edu/tutorials/bpl/p2.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Basic Planning and Learning Tutorials > Basic Planning and Learning > Part 2 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A* Planning with Value Iteration Learning with Q-Learning Learning with Sarsa(\u03bb) Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part | Next Part Initializing the data members Now that we have the structure of our class, we'll need to initialize our data membersto instances that will create our domain and define our task. First, create a default constructor. The first thing we'll do in the constructor is create our domain. public BasicBehavior(){gwdg = new GridWorldDomain(11, 11);gwdg.setMapToFourRooms();tf = new GridWorldTerminalFunction(10, 10);gwdg.setTf(tf);goalCondition = new TFGoalCondition(tf);domain = gwdg.generateDomain();//more to come...} The first line will create an 11x11 deterministic GridWorld. The second line sets up the map to a pre-canned layout:the four rooms layout. This domain layout was used in Option learning work from Sutton, Precup, and Singh (1999)and it presents a simple environment for us to do some tests. Alternatively, you could also define your ownmap layout by either passing the constructor a 2D integer array (with 1s specifying the cells with walls and 0sspecifying open cells), or you could simply specify the size of the domain like we did and then use the GridWorldDomainobject's horiztonalWall and verticalWall methods to place walls on it. The GridWorldDomain also supports1 dimensional walls between cells that you can set, if you'd prefer that kind of domain. For simplicity, we'll stick with thefour rooms layout. By default, our grid world will set the reward function a reward function that always returns -1; but we will need to set where the terminal state is, that when paired with the -1 rewards will motivate the agent to get to it as soon as possible and complete the task. For that, we've told the grid world to use a GridWorldTerminalFunction that marks state 10, 10 as a terminal state. Rewards and terminal states are fine for MDP-based algorithms, but some of the algorithms in BURLAP are search-based planning algorithms: algorithms that search for a path in a detemrinistic domain that reaches some goal condition. For that, we create a StateConditionTest that will be passed to these algorithms and set it to be one that marks all terminal states as goal states. StateConditionTest objects are not actually part of a domain definition, but since we will use it conjunction with the terminal states, we'll create it here anyway. At this point we've fully specified the domain and generate it. The next step will be to define the initial state of this task. For GridWorlds, we use the GridWorldState instance. Add the following code initialState = new GridWorldState(new GridAgent(0, 0), new GridLocation(10, 10, \"loc0\")); The GridWorldState uses an OO-MDP representation, which means the state itself consists of multiple objects (see the Building an OO-MDP Domain tutorial for more information). Here we've made it consist of an agent, located at position 0,0, and a location object located at 10,10. We're not actually going to do anything meaningful with the location object and could have ommitted it, but it will give us a nice visual representation of the goal we placed at 10,10 when we visualizer our results. Next we will instantiate the HashableStateFactory that we wish to use. Since we are not doing anything fancy like state abstraction, we will use SimpleHashableStateFactory. hashingFactory = new SimpleHashableStateFactory(); Finally, we will instantiate an Environment with which the agent will interact in our learning algorithm demonstrations. Since we will be using BURLAP's simulation of the environment, we will use a SimulatedEnvironment, which along with the domain, needs to be told which initial state to use for the environment. env = new SimulatedEnvironment(domain, initialState); At this point you should have initialized all of the data members for the class and the final constructor will look something like the below. public BasicBehavior(){gwdg = new GridWorldDomain(11, 11);gwdg.setMapToFourRooms();tf = new GridWorldTerminalFunction(10, 10);gwdg.setTf(tf);goalCondition = new TFGoalCondition(tf);domain = gwdg.generateDomain();initialState = new GridWorldState(new GridAgent(0, 0), new GridLocation(10, 10, \"loc0\"));hashingFactory = new SimpleHashableStateFactory();env = new SimulatedEnvironment(domain, initialState);} Setting up a result visualizer Before we get to actually running planning and learning algorithms, we're going to want a way to visualizethe results that they generate. While there are a few different ways to do this, for now we willdefine an offline visualizer that will allow us to run planning or learning completely, and then visualizethe results after it's finished. Offline visualization has the advantage of not bogging down the runtime of planning/learning algorithms with time allocated for visualization. To create our offline visualizer, we will need to define a state Visualizer and pass it to an EpisodeSequenceVisualizer . A Visualizer is a Java JPanel that can render State objects. An EpisodeSequenceVisualizer lets you view and explore episodes (state-action-reward sequences) and can either load the episodes from files or be provided them programmatically. In this example, we will save results to file and load them back up. To handle this kind of result visualization, create the below method. public void visualize(String outputPath){Visualizer v = GridWorldVisualizer.getVisualizer(gwdg.getMap());new EpisodeSequenceVisualizer(v, domain, outputPath);} Note that the outputPath parameter specifies the directory where our planning/learning results were stored(well get to this when we actually apply a planning/learning algorithm). The state Visualizer we will use is the one designed for rendering grid world states. It takes as input the map of the world (a 2D int array), which we retrieve from our GridWorldDomain instance. Note that other domains included in BURLAP have their own Visualizers that you can use for them. Before moving on to the next part of the tutorial, lets also hook up our class constructor and visualizer methodto the main method. public static void main(String[] args) {BasicBehavior example = new BasicBehavior();String outputPath = \"output/\"; //directory to record results//we will call planning and learning algorithms here//run the visualizerexample.visualize(outputPath);} Note that you can set the output path to whatever you want. If it doesn't already exist, the codethat saves the results will automatically created it (more on that next). Next Part", "http://burlap.cs.brown.edu/tutorials/bpl/p4.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Basic Planning and Learning Tutorials > Basic Planning and Learning > Part 4 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A* Planning with Value Iteration Learning with Q-Learning Learning with Sarsa(\u03bb) Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part | Next Part Planning with Value Iteration A common stochastic domain planner is Value Iteration (VI). An advantage of VI is that it will compute thepolicy for the entire state space that is reachable from the initial state thatis passed to the planFromState method. To set up a VI planner, define the following method. public void valueIterationExample(String outputPath){Planner planner = new ValueIteration(domain, 0.99, hashingFactory, 0.001, 100);Policy p = planner.planFromState(initialState);PolicyUtils.rollout(p, initialState, domain.getModel()).write(outputPath + \"vi\");} Instantiating value iteration works a lot like our deterministic search planning algorithms. However, because Value Iteration is based on solving MDPs, it requires us to specify a discount factor to use; we've chosen 0.99. It also needs stopping criteria specified, because Value Iteration, as the name implies, is an interative algorithm and we need to define when enough iterations for a good solutions have been performed. We've chossen for VI to terminate when either the changes in the value function are no longer than 0.001, or 100 iterations over the state space have been performed. VI computes the optimal value function for the problem, which specifies the expected future discounted reward for taking each action in each state (the Q-function). Therefore, it returns a GreedyQPolicy . This policy looks at the Q-values the planner computes and returns the action with the maximium Q-value (and breaks ties randomly). This policy can be used with any planning or learning algorithm that returns Q-values by implementing the QProvider interface. Trysetting the main method to call our newly defined VI example method now. Learning with Q-Learning All of the previous examples were examples of using planning algorithms to solve our task. In this section,we will diverge from that and use a learning algorithm, Q-learning, to solve the task. Ultimately, learningalgorithms are utilized in much the same way as planning algorithms, except you will run multipleepisodes of learning in which the agent interacts with an Environment instance to solve it (or one very long episode if it is a continuing task rather than an episodictask). The method you should define to utilize Q-learning is shown below. public void QLearningExample(String outputPath){LearningAgent agent = new QLearning(domain, 0.99, hashingFactory, 0., 1.);//run learning for 50 episodesfor(int i = 0; i < 50; i++){Episode e = agent.runLearningEpisode(env);e.write(outputPath + \"ql_\" + i);System.out.println(i + \": \" + e.maxTimeStep());//reset environment for next learning episodeenv.resetEnvironment();}} Lets first look at the constructor. Rather than a planning instance, we're creating a LearningAgent instance which provides some methods for learning with an environment. QLearning is an instance of the LearningAgent interfaceand takes parameters for the domain, a discount factor, a HashableStateFactory, an initial value for the Q-values, and a learning rate (which for a deterministic domain, 1.0 is a good choice). Note that thisconstructor will by default set Q-learning to use a 0.1 epsilon greedy policy. There are other constructorsthat allow you to set which learning policy to use and there is also a setter that allows you to set itif you'd like to use a different policy. Other parameters for Q-learning could also be set, but we will not detail them here. With the QLearning instance created, next we will run 50 learning episodes, so we set up a for loop.To run a learning episode, we call the method runLearningEpisode on the LearningAgent instanceand pass it the Environment in which learning will be performed. The method returns an Episode object (similar to policies) so that a record of the interactions can be examined. As before, we can then write the returned episode to disk for viewing later. Finally, at the end of the loop, we call the resetEnvironment method on the Environment. This method is the typical way to signal that an Environment needs to reset to an initial state from its current state, which may be a terminal state. When the method returns, it is expected that the environment in a non-terminal state from which an agent can act again. After that, you can call this method from your main method and run the agents behavior for each of the 50 episodes of learning! You should find that as learning progessed, the agent got better. By the end, the agent's behavior will still be slightly random since it's following an epislon greedy policy that always takes some random actions. However, since QLearning implements the QFunction interface, you could always wrap a GreedyQPolicy around it, like with VI, to remove random action selection. Learning with Sarsa(\u03bb) A similar learning algorithm to Q-learning is Sarsa(\u03bb). The first difference between the twoalgorithms is that Sarsa(\u03bb) updates Q-values with respect to the Q-value of the next action taken,rather than the maximum Q-value of the next state (see Wikipedia for more information). The second, and larger, difference is that at every time step, Sarsa(\u03bb) will also update the Q-valuesfor state-action pairs experienced previously in an episode with respect to the amount specified by \u03bb and how long ago the experiences occurred. Define the below method to solve ourtask with Sarsa(\u03bb). public void SarsaLearningExample(String outputPath){LearningAgent agent = new SarsaLam(domain, 0.99, hashingFactory, 0., 0.5, 0.3);//run learning for 50 episodesfor(int i = 0; i < 50; i++){Episode e = agent.runLearningEpisode(env);e.write(outputPath + \"sarsa_\" + i);System.out.println(i + \": \" + e.maxTimeStep());//reset environment for next learning episodeenv.resetEnvironment();}} You will notice that this method looks pretty identical to the Q-learning example, except this timea SarsaLam instance is constructed. Additionally, we lowered the learning rate to 0.5 (typicallyyou should use lower learning rates when you have a higher value of \u03bb). The last parameter ofthe constructor is the \u03bb value which we set to 0.3. A value of \u03bb=1.0 effectively makes algorithm run anonline Monte Carlo in which the effects of all future interactions are fully considered in updating each Q-valueof an episode. It is not always a good idea to use a large \u03bb value. Otherwise, the rest is the same; you can call this method from the main method and give it shot! Next Part", "http://burlap.cs.brown.edu/tutorials/bpl/p3.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Basic Planning and Learning Tutorials > Basic Planning and Learning > Part 3 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A* Planning with Value Iteration Learning with Q-Learning Learning with Sarsa(\u03bb) Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part | Next Part Planning with BFS One of the most basic deterministic planning algorithms is breadth-first search, which we will demonstrate first. Since we willbe testing a number of different planning and learning algorithms in this tutorial, we will define a separate methodfor using each planning or learning algorithm and then you can simply select which one you want to try in the mainmethod of the class. We will also pass each of these methods the output path to record itsresults. Lets start by defining the BFS method. public void BFSExample(String outputPath){DeterministicPlanner planner = new BFS(domain, goalCondition, hashingFactory);Policy p = planner.planFromState(initialState);PolicyUtils.rollout(p, initialState, domain.getModel()).write(outputPath + \"bfs\");} The first part of the method creates an instance of the BFS planning algorithm, whichitself is a subclass of the DeterministicPlanner class. To instantiate BFS, it only requires a reference to the domain,the goal condition for which it should search, and the HashableStateFactory. Because BFS implements the Planner interface, planning can be initiated by callingthe planFromState method and passing it the initial state form which it should plan. The planFromState method automatically returns a Policy object. Using the PolicyUtils class, we rollout the policy from an initial state. This method requires the model of the envionrment (or alternatively, you can have it rolled out within an actual environment). The result of the rollout method is an Episode object, which is a record of the state, action, and reward sequence from rolling out the policy. Episode objects can be written to disk, using the write method, which we call here. Using non-default policies Each Planner implementation will return a different kind of Policy from planFromState that is relevant for the results the Planner stores. However, often times, after calling the planFromState method, you can wrap a different policy than the one that is returned around your planner instance to get slightly different behavior. For example, BFS's planFromState will return an SDPlannerPolicy instance, which will return the action the planner selected for any states on its solution path; if the policy is queried for a state not on the solution path, it will throw a runtime exception. However, you might choose to wrap a DDPlannerPolicy around BFS instead of using the returned SDPlannerPolicy. DDPlannerPolicy will act the same as SDPlannerPolicy except rather than throw a runtime exception if an action selection is queried for a state not on the current solution path, it will transparently recall planFromState on the new state to get an action to return; that is, it will perform replanning. And that's all you need to code to plan with BFS on a defined domain and task! Using the EpisodeSequenceVisualizer GUI Now that the method to perform planning with BFS is defined, add a method call to it in your main method. public static void main(String[] args) {BasicBehavior example = new BasicBehavior();String outputPath = \"output/\"; //directory to record results//run exampleexample.BFSExample(outputPath);//run the visualizerexample.visualize(outputPath);} Note that our output path ended with a '/'. Whatever path you use, you should include the trailing '/' since the code we wrote to write the file will automatically append to that path name. With the planning method hooked up, run the code! Because the task is simple, BFS should find a solution veryquickly and print to the standard output the number of nodes it expanded in its search. Following that, the GUIshould be launched for viewing the EpisodeAnalysis object that was recorded to a file. You should see something like the belowimage appear. The main panel in the center of the window is used to render the current state selected. The text box at thebottom of the window will list all of the propositional functions that are true in that state, if the State is an OOState and the domain includes PropositionalFunction definitions. The leftmostlist on the right side of the window lists all of the episode files that were recorded in the directory passed to theEpisodeSequenceVisualizer constructor. After selecting one of those instances, the list of actions taken in theepisode are listed on the right-most list. Note that the actioncorresponds to the action that will be taken in the statethat is currently visualized, so the result of the actionwill be seen in the next state. In the GridWorldDomain visualizer, the black cells represent walls, the grey circlerepresents the agent, and the blue cell represents the location object that we made. Planning with DFS Another common search-based planning algorithm is depth-first search (DFS). Define the below method to providea means to solve the task with DFS. public void DFSExample(String outputPath){DeterministicPlanner planner = new DFS(domain, goalCondition, hashingFactory);Policy p = planner.planFromState(initialState);PolicyUtils.rollout(p, initialState, domain.getModel()).write(outputPath + \"dfs\");} You will notice that the code for DFS is effectively identical to the previous BFS code that we wrote, only this timethe DeterministicPlanner is instantiated with a DFS object instead of a BFS object. DFS has a number of other constructorsthat allow you to specify other parameters such a depth limit, or maintaining a closed list. Feel freeto experiment with them. After you have defined the method, you can call it from the main method like we did the BFS method and visualize theresults in the same way. Since DFS is not an optimal planner, it is likely that the solution it gives you will bemuch worse than the one BFS gave you! Planning with A* One of the most well known optimal search-based planning algorithms is A*. A* is an informed planner because it takesas input an admissible heuristic that estimates the cost to the goal from any given state. We can also use A* to plan a solution for our taskas long as we also take the additional step of defining a heuristic to use (or you can use a NullHeuristic which will make A* uninformed). The below code defines a methodfor using A* with a Manhattan distance to goal heuristic. public void AStarExample(String outputPath){Heuristic mdistHeuristic = new Heuristic() {public double h(State s) {GridAgent a = ((GridWorldState)s).agent;double mdist = Math.abs(a.x-10) + Math.abs(a.y-10);return -mdist;}};DeterministicPlanner planner = new AStar(domain, goalCondition, hashingFactory, mdistHeuristic);Policy p = planner.planFromState(initialState);PolicyUtils.rollout(p, initialState, domain.getModel()).write(outputPath + \"astar\");} To implement our heursitic, we made an annonmous class that implements Heuristic, which requires implementing the h method. We typecast the state to a GridWorldState, pull out the agent, and compute the Manhatten distance to 10, 10, our goal location. The h method then returns the negative value of the distance. We return the negative value, because BURLAP is based on rewards rather than costs . However, negative rewards are equivalent to costs, so the heursitic we give must be a non-positive value (<= 0). Note that A* also only operates on costs (negative rewards), so whenever using A*, you should make sure that the reward function for your domain returns negative values. By default, GridWorldDomain uses a UniformCostRF, which causes all rewards to be -1. Beyond defining a heuristic for A*, instantiating it and using it works mostly the same! Next Part", "http://burlap.cs.brown.edu/tutorials/bpl/p5.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Basic Planning and Learning Tutorials > Basic Planning and Learning > Part 5 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A* Planning with Value Iteration Learning with Q-Learning Learning with Sarsa(\u03bb) Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part | Next Part Live Visualization Although we showed how to visualize learning or planning results after they had been performed, sometimes when setting upa new problem and experiment it is useful to watch what is happening immediately. In this part of the tutorial weshow how to set up a live visualization of learning algorithms interacting with an environment. To present a live visualization we make use of the EnvironmentObserver interface. Objects that implement EnvironmentObserver interface can be told about agent interactions with an Environment. In this example, we will instantiate a VisualActionObserver and which implements both interfaces and visualizes state changes. To add a VisualActionObserver, we can modify our constructor by adding the following lines to the end of it: VisualActionObserver observer = new VisualActionObserver(domain, GridWorldVisualizer.getVisualizer(gwdg.getMap()));observer.initGUI();env.addObservers(observer); The first line creates a VisualActionObserver for visualizing our domain with a provided domain state visualizer(we use the same kind of state visualizer that we used for our EpisodeSequenceVisualizer). The second line initializes the Java GUI for its visualization. The third line is how we set up the VisualActionObserver to receive events from an Environment. You can add EnviornmentObservers to any Environment that implements the EnvironmentServerInterface interface, with the SimulatedEnvironment does. If your environment does not implement that interface, you can always instantiate an EnvironmentServer, which is an Environment delegator that will intercept environment interactions and send them to observers before (or after) calling the underlying Environment. Performance with VisualActionObservers By default, the VisualActionObserver will render frames at about 60FPS. You can modify this rate with thesetFrameDelay(long delay) method, which takes as an argument the number of milliseconds that must pass for the renderingof an event and before the next action can be taken. Note that this delay also places a cap on the speed at which learning or planning occurs since it stalls everything for that frame delay. Typically,learning in BURLAP occurs at speeds orders of magnitude faster than 60FPS, so using the visual observer willslow down your algorithm considerably. For these reasons, you may prefer the offline visualization. Alternatively, you can also visualize interactions in the environment with a VisualExplorer without stalling performance. In previous tutorials, we used VisualExplorer to manually interact with our environment as the agent. Alternatively, you can launch the visual explorer around the environment with which your learning agent is interacting, and then call the stateLiveStatePolling method, with a specified inteval which will cause the visualizer to draw the currnet state of the environment on the interval you specified. This approach allows the agent to take more steps than can be rendered in the rendering interval. Value Function and Policy Visualization While visualizing the agent in the state space is useful, in this next section, we will show you how to visualize the value function that is estimatedfrom value function estimating planning or learning algorithms, along with the corresponding policy. The value function assigns a value to each state that represents the expected future discounted reward when following the optimal policy from that state. In particular,we will show you how to visualize the value function for the ValueIteration results, but you could do the same with Q-Learning, or anyplanning/learning algorithm that implements the ValueFuncton interface (which the QFunction interface extends). We will show you how to construct a value function visualizer in two ways. In the first way, we will make use of a GridWorldDomain method that will put all the pieces together for you and is very simple. However, since not all domains have automated code for that, we will also show you how to put all the pieces together manually. Lets start with the simple way, which requires adding the following method to your code. public void simpleValueFunctionVis(ValueFunction valueFunction, Policy p){List<State> allStates = StateReachability.getReachableStates(initialState, domain, hashingFactory);ValueFunctionVisualizerGUI gui = GridWorldDomain.getGridWorldValueFunctionVisualization(allStates, 11, 11, valueFunction, p);gui.initGUI();} Note that this method takes as input a ValueFunction instance and a Policy object (since along with the value function, we will also render the policy). Before we do anything with it, we are going to have to tell the renderer for which states we'd like to visualize the value function. Although Domain objects are not required to enumerate the entire state space (since for many domains that might be impossible), we can use the BURLAP tool StateReachability to find all states that are reachable from some input state. (Algorithms like ValueIteraiton also have a method to return all states that they enumerated that we could have used.) Next we call the GridWorldDomain method getGridWorldValueFunctionVisualization , which takes the set of states for which the value function will be rendered, the ValueFunction instance, and the Policy to render, and returns a ValueFunctionVisualizationGUI instance that will do it for us. Finally, we launch the return GUI with the initGUI method. The last step is to direct our value iteration method to this method once planning is complete. Your new value iteration method should look like the following. public void valueIterationExample(String outputPath){Planner planner = new ValueIteration(domain, 0.99, hashingFactory, 0.001, 100);Policy p = planner.planFromState(initialState);PolicyUtils.rollout(p, initialState, domain.getModel()).write(outputPath + \"vi\");simpleValueFunctionVis((ValueFunction)planner, p);} If you now point your main method to run the valueIterationExample, you should find that after planning completes, it launches a GUI like the below (note that you can toggle the policy visualization with the check box in the bottom left). Now that we've shown you how to easily create a value function and policy visualization for grid worlds, lets walk through the process of manually creating one so that you know how to do so for other domains. Add the following method to your code. public void manualValueFunctionVis(ValueFunction valueFunction, Policy p){List<State> allStates = StateReachability.getReachableStates(initialState, domain, hashingFactory);//define color functionLandmarkColorBlendInterpolation rb = new LandmarkColorBlendInterpolation();rb.addNextLandMark(0., Color.RED);rb.addNextLandMark(1., Color.BLUE);//define a 2D painter of state values, specifying //which variables correspond to the x and y coordinates of the canvasStateValuePainter2D svp = new StateValuePainter2D(rb);svp.setXYKeys(\"agent:x\", \"agent:y\", new VariableDomain(0, 11), new VariableDomain(0, 11), 1, 1);//create our ValueFunctionVisualizer that paints for all states//using the ValueFunction source and the state value painter we definedValueFunctionVisualizerGUI gui = new ValueFunctionVisualizerGUI(allStates, svp, valueFunction);//define a policy painter that uses arrow glyphs for each of the grid world actionsPolicyGlyphPainter2D spp = new PolicyGlyphPainter2D();spp.setXYKeys(\"agent:x\", \"agent:y\", new VariableDomain(0, 11), new VariableDomain(0, 11), 1, 1);spp.setActionNameGlyphPainter(GridWorldDomain.ACTION_NORTH, new ArrowActionGlyph(0));spp.setActionNameGlyphPainter(GridWorldDomain.ACTION_SOUTH, new ArrowActionGlyph(1));spp.setActionNameGlyphPainter(GridWorldDomain.ACTION_EAST, new ArrowActionGlyph(2));spp.setActionNameGlyphPainter(GridWorldDomain.ACTION_WEST, new ArrowActionGlyph(3));spp.setRenderStyle(PolicyGlyphPainter2D.PolicyGlyphRenderStyle.DISTSCALED);//add our policy renderer to itgui.setSpp(spp);gui.setPolicy(p);//set the background color for places where states are not rendered to greygui.setBgColor(Color.GRAY);//start itgui.initGUI();} The method signature looks the same as before and also as before we will use StateReachability to get all the states for which the value function will be rendered. Since we will be rendering the value of a cell of the grid world with a color that blends from red to blue, we will create an instance of the ColorBlend interface. In particular, we will use the LandmarkColorBlendInterpolation . This class lets you input a real value that spits out a color that is interpolated between various specified colors. So in this case, we defined the interpolation to blend from red to blue (we could have added additional points of color in between; feel free to experiment). The numeric values to which we assign these colors are normalized, so 0 is the minimum value and 1 is the maximum. Next we want to define a StateValuePainter instance, which is an interface that has a method that takes as input a graphics context, a State and a value for that state and renders it to the graphics context. In particular, we will use the StateValuePainter2D implementation, which will rendered colored cells for each state where the color to render is based on a ColorBlend instance (which we defined above). For this class to determine where in a graphics context to render a state's cell, it needs to be told what the x and y state variables are. It also needs to know the variable domain, and how wide in the variable domain each rendered call will span. At this point, we create our ValueFunctionVisualizerGUI instance, which takesthe states for which to render the value, the StateValuePainter to use, and the sourceValueFunction that specifies the value for the states. However, before we finish, we also added a Policy renderer that can overlay the value function visualization. For this rendering, we will need a StatePolicyPainter implementation and in the code we use a PolicyGlyphPainter2D that renders a policy at some position in a 2D graphics context by drawing glyphs for the selected action (or actions if there are a set of actions that the policy selects). Like the StateValuePainter2D, this class needs to be told about the state variables to use for the x and y position. It also needs to be told which ActionGlyphPainter to use to paint a glyph for each action (by action name). Here we used the existing ArrowActionGlyph for each action, where the parameter in its constructor for 0 to 3 indicates a north, south east, and west arrow respectively. The PolicyGlyphPainter2D also have various ways to render the glyphs. Here we use DISTSCALED which means each action glyph is rendered at a size proportional to the probability that the agent will select that action. Finally, we set the ValueFunctionVisualizerGUI to use the StatePolicyPainter we created, and set the Policy it should render. Then we set the background color to gray, and launch the GUI. If you now point the value iteration method to this value function visualization method instead of the simple one, you should find that your get the same visualization. Next Part", "http://burlap.cs.brown.edu/tutorials/bpl/p6.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Basic Planning and Learning Tutorials > Basic Planning and Learning > Part 6 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A* Planning with Value Iteration Learning with Q-Learning Learning with Sarsa(\u03bb) Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part Experimenter Tools and Performance Plotting In the previous section you learned how to use an EnvironmentObserver to perform live visualization of the agentin the state space as it was learning. In this section we will make use another EnvironmentObserver called PerformancePlotter to record a learning algorithm's performance and compare it to another learning algorithm. ThePerformacnePlotter has a lot of powerful tools to display lots of important experimental results. To streamlinethe construction process, we will make use of the LearningAlgorithmExperimenter class, which is convenient for comparingthe performance of multiple learning algorithms over many trials. If you'd prefer to run your own experiment using adifferent design flow, however, you could make use of the PerformancePlotter directly yourself. To demonstrate the LearningAlgorithmExperimenter, we will compare the learning performance of a Q-learning algorithmwith the performance of a SARSA(\u03bb) algorithm. To make the results a bit more interesting to visualize,we will also use a different reward function than we have been that returns a reward of 5 when the goal is reached and -0.1for every other step. Lets then begin by adding a new method to our BasicBehavior class to call totest the experimenter tools. Inside the method, we will change our domain's reward function. To do so, we will exploit the fact that the model for our grid world is a FactoredModel; a model that has individual components for the reward function, terminal states, and state transition model. This is also the kind of model the vast majority of domains in BURLAP use. Since it is a FactoredModel, we can retreive it from our domain, and change its reward function. We'll use a GoalBasedRF that returns a value 5 for transitions to our goal state and -0.1 everywhere else. public void experimenterAndPlotter(){//different reward function for more structured performance plots((FactoredModel)domain.getModel()).setRf(new GoalBasedRF(this.goalCondition, 5.0, -0.1));} For the LearningAlgorithmExperimenter to report an average performance of each algorithm,it will test the algorithm over multiple trials. Therefore, at the start of each trial a cleanagent instance of the algorithm without knowledge of any of the previous trials must be generated. To easily get a clean version of each agent, the LearningAlgorithmExperimenter will request a sequence of LearningAgentFactory objects thatcan be used to generate a clean version of each agent on demand. In the following code, we create aLearningAgentFactory for a Q-learning algorithm and a SARSA(\u03bb) algorithm. /** * Create factories for Q-learning agent and SARSA agent to compare */LearningAgentFactory qLearningFactory = new LearningAgentFactory() {public String getAgentName() {return \"Q-Learning\";}public LearningAgent generateAgent() {return new QLearning(domain, 0.99, hashingFactory, 0.3, 0.1);}};LearningAgentFactory sarsaLearningFactory = new LearningAgentFactory() {public String getAgentName() {return \"SARSA\";}public LearningAgent generateAgent() {return new SarsaLam(domain, 0.99, hashingFactory, 0.0, 0.1, 1.);}}; Note that the factory also requires a getAgentName() method to be implemented. The LearningAgentExperimenter classwill use this name to label the results of each learning algorithm's performance. We are just about ready to create our experimenter, but firstwe will need to decide how many trials we want to test, the length of the trials, and what performance data wewant to plot. There are six possible performance metrics we could plot: cumulative reward per step, cumulative reward per episode, average reward per episode, median reward per episode, cumulative steps per episode, and steps per episode. Furthermore, we could also have our plotter display the results from the most recent trial only,the average performance across all trials, or both. For this tutorial, we will plot both the most recent trial andaverage trial performance for the cumulative steps per episode and the average reward per episode. We will alsotest the algorithms for 10 trials that last 100 episodes each. The below code will create our experimenter,start it, and also save all the data for all six metrics to CSV files. LearningAlgorithmExperimenter exp = new LearningAlgorithmExperimenter(env, 10, 100,qLearningFactory, sarsaLearningFactory);exp.setUpPlottingConfiguration(500, 250, 2, 1000,TrialMode.MOST_RECENT_AND_AVERAGE,PerformanceMetric.CUMULATIVE_STEPS_PER_EPISODE,PerformanceMetric.AVERAGE_EPISODE_REWARD);exp.startExperiment();exp.writeStepAndEpisodeDataToCSV(\"expData\"); Note that in the constructor, the LearningAgent factories are the last parameters, of whicha variable number of factories could be provided; we could have tested just one agent, or we could have tested many more, but thereshould naturally always be at least one LearningAgentFactory provided. The other important part of the code is the setUpPlottingConfiguration method, which is used to define what resultsare plotted and how they are displayed. The first four parameters specify a plot's width and height, the number of columnsof plots, and the maximum window height. In this case, plots are set to be 500x200, with two columns of plots. Plotsare placed columns first, wrapping down to a new row as needed. The window size will be scaled to the width of plots times the number of columns; the height will scale to the height of the plots times the number of rows, unless thatheight is greater than the maximum window height, in which case the plots will be placed in a scroll view. The nextparameter specifies whether to show plots for only the most recent trial, the average performance over all trials, orboth. We have selected to show both. The remaining parameters are variable in size and specify which performance metrics will be plotted. The order of the performance metrics providedalso dictates the order that the plots will fill the window (again, filling columns first). The startExperiment method begins the experiment which will run all trials for all learning algorithms provided. Once you point our BasicBevhavior main method to the new method we've created and run the code, A GUI should appear with the plots requested,displaying the performance as it is available. When the experiment is complete, you should be left with an image like the below. In the trial average plots, you'll note that a translucent filled area around each of the curves is present. This filledarea shows the 95% confidence interval. You can change the significance level used before running the experimentusing the setPlotCISignificance method. Note that these plots are not static and you can interact with them. If you click drag in a region, it will cause the plotto zoom into the selected area. If you right click, you'll find a number of other options that you can set, includingchanging the labels. Another important feature you'll see from the contextual menu is an option to save plot image to disk. Since we also told the LearningAlgorithmExperimenter object to save the data to csv files, you should find two files that it created:expDataSteps.csv and expDataEpisodes.csv. The first contains all trial data for the cumulative reward per stepmetric. The latter contains all of the episode-wise metric data (even for the metrics that we did not plot). Thesefiles will make interacting with the data in another program, such as R, convenient. Conclusion This ends our tutorial on implementing basic planning and learning algorithms in BURLAP. There areother planning and learning algorithms in BURLAP, but hopefully this tutorial has explained the core conceptswell enough that you should be able to try different algorithms easily. As a future exercise, we encourage youto try just that within this code you've created! The complete set of code that we wrote in this tutorial is shownbelow for your convenience. The full code is also in the BURLAP code libary under the examples package. import burlap.behavior.policy.GreedyQPolicy;import burlap.behavior.policy.Policy;import burlap.behavior.policy.PolicyUtils;import burlap.behavior.singleagent.Episode;import burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizer;import burlap.behavior.singleagent.auxiliary.StateReachability;import burlap.behavior.singleagent.auxiliary.performance.LearningAlgorithmExperimenter;import burlap.behavior.singleagent.auxiliary.performance.PerformanceMetric;import burlap.behavior.singleagent.auxiliary.performance.TrialMode;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.ValueFunctionVisualizerGUI;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.ArrowActionGlyph;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.LandmarkColorBlendInterpolation;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.PolicyGlyphPainter2D;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.StateValuePainter2D;import burlap.behavior.singleagent.learning.LearningAgent;import burlap.behavior.singleagent.learning.LearningAgentFactory;import burlap.behavior.singleagent.learning.tdmethods.QLearning;import burlap.behavior.singleagent.learning.tdmethods.SarsaLam;import burlap.behavior.singleagent.planning.Planner;import burlap.behavior.singleagent.planning.deterministic.DeterministicPlanner;import burlap.behavior.singleagent.planning.deterministic.informed.Heuristic;import burlap.behavior.singleagent.planning.deterministic.informed.astar.AStar;import burlap.behavior.singleagent.planning.deterministic.uninformed.bfs.BFS;import burlap.behavior.singleagent.planning.deterministic.uninformed.dfs.DFS;import burlap.behavior.singleagent.planning.stochastic.valueiteration.ValueIteration;import burlap.behavior.valuefunction.QFunction;import burlap.behavior.valuefunction.ValueFunction;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.GridWorldTerminalFunction;import burlap.domain.singleagent.gridworld.GridWorldVisualizer;import burlap.domain.singleagent.gridworld.state.GridAgent;import burlap.domain.singleagent.gridworld.state.GridLocation;import burlap.domain.singleagent.gridworld.state.GridWorldState;import burlap.mdp.auxiliary.stateconditiontest.StateConditionTest;import burlap.mdp.auxiliary.stateconditiontest.TFGoalCondition;import burlap.mdp.core.TerminalFunction;import burlap.mdp.core.state.State;import burlap.mdp.core.state.vardomain.VariableDomain;import burlap.mdp.singleagent.common.GoalBasedRF;import burlap.mdp.singleagent.common.VisualActionObserver;import burlap.mdp.singleagent.environment.SimulatedEnvironment;import burlap.mdp.singleagent.model.FactoredModel;import burlap.mdp.singleagent.oo.OOSADomain;import burlap.statehashing.HashableStateFactory;import burlap.statehashing.simple.SimpleHashableStateFactory;import burlap.visualizer.Visualizer;import java.awt.*;import java.util.List;public class BasicBehavior {GridWorldDomain gwdg;OOSADomain domain;TerminalFunction tf;StateConditionTest goalCondition;State initialState;HashableStateFactory hashingFactory;SimulatedEnvironment env;public BasicBehavior(){gwdg = new GridWorldDomain(11, 11);gwdg.setMapToFourRooms();tf = new GridWorldTerminalFunction(10, 10);gwdg.setTf(tf);goalCondition = new TFGoalCondition(tf);domain = gwdg.generateDomain();initialState = new GridWorldState(new GridAgent(0, 0), new GridLocation(10, 10, \"loc0\"));hashingFactory = new SimpleHashableStateFactory();env = new SimulatedEnvironment(domain, initialState);//VisualActionObserver observer = new VisualActionObserver(domain, //GridWorldVisualizer.getVisualizer(gwdg.getMap()));//observer.initGUI();//env.addObservers(observer);}public void visualize(String outputpath){Visualizer v = GridWorldVisualizer.getVisualizer(gwdg.getMap());new EpisodeSequenceVisualizer(v, domain, outputpath);}public void BFSExample(String outputPath){DeterministicPlanner planner = new BFS(domain, goalCondition, hashingFactory);Policy p = planner.planFromState(initialState);PolicyUtils.rollout(p, initialState, domain.getModel()).write(outputPath + \"bfs\");}public void DFSExample(String outputPath){DeterministicPlanner planner = new DFS(domain, goalCondition, hashingFactory);Policy p = planner.planFromState(initialState);PolicyUtils.rollout(p, initialState, domain.getModel()).write(outputPath + \"dfs\");}public void AStarExample(String outputPath){Heuristic mdistHeuristic = new Heuristic() {public double h(State s) {GridAgent a = ((GridWorldState)s).agent;double mdist = Math.abs(a.x-10) + Math.abs(a.y-10);return -mdist;}};DeterministicPlanner planner = new AStar(domain, goalCondition, hashingFactory, mdistHeuristic);Policy p = planner.planFromState(initialState);PolicyUtils.rollout(p, initialState, domain.getModel()).write(outputPath + \"astar\");}public void valueIterationExample(String outputPath){Planner planner = new ValueIteration(domain, 0.99, hashingFactory, 0.001, 100);Policy p = planner.planFromState(initialState);PolicyUtils.rollout(p, initialState, domain.getModel()).write(outputPath + \"vi\");simpleValueFunctionVis((ValueFunction)planner, p);//manualValueFunctionVis((ValueFunction)planner, p);}public void qLearningExample(String outputPath){LearningAgent agent = new QLearning(domain, 0.99, hashingFactory, 0., 1.);//run learning for 50 episodesfor(int i = 0; i < 50; i++){Episode e = agent.runLearningEpisode(env);e.write(outputPath + \"ql_\" + i);System.out.println(i + \": \" + e.maxTimeStep());//reset environment for next learning episodeenv.resetEnvironment();}}public void sarsaLearningExample(String outputPath){LearningAgent agent = new SarsaLam(domain, 0.99, hashingFactory, 0., 0.5, 0.3);//run learning for 50 episodesfor(int i = 0; i < 50; i++){Episode e = agent.runLearningEpisode(env);e.write(outputPath + \"sarsa_\" + i);System.out.println(i + \": \" + e.maxTimeStep());//reset environment for next learning episodeenv.resetEnvironment();}}public void simpleValueFunctionVis(ValueFunction valueFunction, Policy p){List<State> allStates = StateReachability.getReachableStates(initialState, domain, hashingFactory);ValueFunctionVisualizerGUI gui = GridWorldDomain.getGridWorldValueFunctionVisualization(allStates, 11, 11, valueFunction, p);gui.initGUI();}public void manualValueFunctionVis(ValueFunction valueFunction, Policy p){List<State> allStates = StateReachability.getReachableStates(initialState, domain, hashingFactory);//define color functionLandmarkColorBlendInterpolation rb = new LandmarkColorBlendInterpolation();rb.addNextLandMark(0., Color.RED);rb.addNextLandMark(1., Color.BLUE);//define a 2D painter of state values, //specifying which attributes correspond to the x and y coordinates of the canvasStateValuePainter2D svp = new StateValuePainter2D(rb);svp.setXYKeys(\"agent:x\", \"agent:y\", new VariableDomain(0, 11), new VariableDomain(0, 11), 1, 1);//create our ValueFunctionVisualizer that paints for all states//using the ValueFunction source and the state value painter we definedValueFunctionVisualizerGUI gui = new ValueFunctionVisualizerGUI(allStates, svp, valueFunction);//define a policy painter that uses arrow glyphs for each of the grid world actionsPolicyGlyphPainter2D spp = new PolicyGlyphPainter2D();spp.setXYKeys(\"agent:x\", \"agent:y\", new VariableDomain(0, 11), new VariableDomain(0, 11), 1, 1);spp.setActionNameGlyphPainter(GridWorldDomain.ACTION_NORTH, new ArrowActionGlyph(0));spp.setActionNameGlyphPainter(GridWorldDomain.ACTION_SOUTH, new ArrowActionGlyph(1));spp.setActionNameGlyphPainter(GridWorldDomain.ACTION_EAST, new ArrowActionGlyph(2));spp.setActionNameGlyphPainter(GridWorldDomain.ACTION_WEST, new ArrowActionGlyph(3));spp.setRenderStyle(PolicyGlyphPainter2D.PolicyGlyphRenderStyle.DISTSCALED);//add our policy renderer to itgui.setSpp(spp);gui.setPolicy(p);//set the background color for places where states are not rendered to greygui.setBgColor(Color.GRAY);//start itgui.initGUI();}public void experimentAndPlotter(){//different reward function for more structured performance plots((FactoredModel)domain.getModel()).setRf(new GoalBasedRF(this.goalCondition, 5.0, -0.1));/** * Create factories for Q-learning agent and SARSA agent to compare */LearningAgentFactory qLearningFactory = new LearningAgentFactory() {public String getAgentName() {return \"Q-Learning\";}public LearningAgent generateAgent() {return new QLearning(domain, 0.99, hashingFactory, 0.3, 0.1);}};LearningAgentFactory sarsaLearningFactory = new LearningAgentFactory() {public String getAgentName() {return \"SARSA\";}public LearningAgent generateAgent() {return new SarsaLam(domain, 0.99, hashingFactory, 0.0, 0.1, 1.);}};LearningAlgorithmExperimenter exp = new LearningAlgorithmExperimenter(env, 10, 100, qLearningFactory, sarsaLearningFactory);exp.setUpPlottingConfiguration(500, 250, 2, 1000,TrialMode.MOST_RECENT_AND_AVERAGE,PerformanceMetric.CUMULATIVE_STEPS_PER_EPISODE,PerformanceMetric.AVERAGE_EPISODE_REWARD);exp.startExperiment();exp.writeStepAndEpisodeDataToCSV(\"expData\");}public static void main(String[] args) {BasicBehavior example = new BasicBehavior();String outputPath = \"output/\";example.BFSExample(outputPath);//example.DFSExample(outputPath);//example.AStarExample(outputPath);//example.valueIterationExample(outputPath);//example.qLearningExample(outputPath);//example.sarsaLearningExample(outputPath);//example.experimentAndPlotter();example.visualize(outputPath);}} End.", "http://burlap.cs.brown.edu/tutorials/cpl/p1.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Creating a Planning and Learning Algorithm Tutorials > Creating a Planning and Learning Algorithm > Part 1 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Next Part You are viewing the tutorial for BURLAP 3; if you'd like the BURLAP 2 tutorial, go here . Introduction In the previous tutorials, we walked through how you can use existing planning and learning algorithms in BURLAP and how to create your own domains on which you can use those algorithms. However, you may also want to extend or create your own planning or learning algorithm in BURLAP that can either be used on existing domains or novel BURLAP domains and be easily compared against existing algorithms. In this tutorial, we will show you how to create both a planning algorithm and a learning algorithm. In particular, we will be reimplementing versions of Value Iteration and Q-learning since they are conceptually simple algorithms to implement, but will expose the various properties of BURLAP you would want to use. In general, however, you should defer to using the existing implementations of these algorithms in BURLAP since they will support more features than we will cover here. Value Iteration Overview Value Iteration (VI) is an algorithm that finds the optimal value function (the expected discounted future reward of being in a state and behaving optimally from it), and consequently, the optimal policy, for an MDP's entire state space. Central to the idea of VI is the Bellman Equation, which states that the optimal value of a stateis the value of the action with the maximum expected discounted future return (the action with the maximum Q-value) where the Q-value for a state-action pair is defined as the expected value over allpossible state transitions of the immediate reward summed with the discounted value of the resulting state. In math:$$\\large V(s) = \\max_a Q(s,a)$$$$\\large Q(s,a) = \\sum_{s'} T(s' | s,a) \\left[ R(s, a, s') + \\gamma V(s') \\right],$$ where $T(s' | s, a)$ is the probability of transitioning to state $s'$ when taking action $a$ in state $s$, $R(s, a, s')$ is the reward received for transitioning to state $s'$ after taking action $a$ in state $s$, and $\\gamma$ is a discount factor affecting how much immediate rewards are preferred to later ones. This equation presents some issues in that if an MDP has cycles, it's unclear what the values should be. However, the Value Iteration algorithm will converge to the optimal value function if you simply initialize the value for each state to some arbitrary value, and then iteratively use the Bellman equationto update the the value for each state. Planning algorithms that make use of the Bellman equation to estimate the Value function are known as Dynamic Programming (DP) planning algorithms. Different DP algorithms specify different priorities for when the estimated value of each state is updated with the Bellman equation. In the case of VI, Bellman updates are performed in entire sweeps of the state space. That is, at the start, the value for all states is initialized to some arbitrary value. Then, for each state in the state space, the Bellman equation is used to update the value function estimate. Sweeps over the entire state space are repeated for some fixed number of iterations or until the maximum change in the value function is small. The algorithm is summarized in the below pseudocode. Value Iteration Initialize value function $V(s)$ arbitrarily for all states $s$. Repeat until convergence... For each state $s$ $V(s) := \\max_a \\sum_{s'} T(s' | s, a) \\left[R(s,a,s') + \u03b3 V(s')\\right]$ Since there are a number of different DP algorithms that can be implemented, BURLAP includes a class called DynamicProgramming that includes a number of helpful methods for automatically performing Bellman Updates on states and which is extended by many of the DP algorithms included in BURLAP. However, to give a better sense of howto use the more fundamental parts of a planning algorithm in BURLAP, we will instead write our VI algorithm from scratch without using the DynamicProgramming class. However, we will extend the MDPSolver class since it provides a number of useful data members and setter and getter methods that you will commonly want to have for algorithms that solve MDPs. Next Part", "http://burlap.cs.brown.edu/tutorials/cpl/p2.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Creating a Planning and Learning Algorithm Tutorials > Creating a Planning and Learning Algorithm > Part 2 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Previous Part | Next Part VI Code Lets start by creating our class for VI, which we'll call VITutorial. Our class will extend MDPSolver , to gain many of the useful datastructures used in solving an MDP, and it will implement the Planner and QProvider interfaces. The former because we will implement the planFromState method and the latter because Value Iteration computes the value function from which Q-values can be computed (the QProvider interface extends the QFunction interface, which in turns extends the ValueFunction interface. QFunction adds a method to ValueFunction get the Q-value for a state-action pair, and QProvider provides a method to return all Q-values for an input state). We will also add all the imports we will need in developing this class. import burlap.behavior.policy.GreedyQPolicy;import burlap.behavior.policy.Policy;import burlap.behavior.policy.PolicyUtils;import burlap.behavior.singleagent.Episode;import burlap.behavior.singleagent.MDPSolver;import burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizer;import burlap.behavior.singleagent.auxiliary.StateReachability;import burlap.behavior.singleagent.planning.Planner;import burlap.behavior.valuefunction.ConstantValueFunction;import burlap.behavior.valuefunction.QProvider;import burlap.behavior.valuefunction.QValue;import burlap.behavior.valuefunction.ValueFunction;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.GridWorldTerminalFunction;import burlap.domain.singleagent.gridworld.GridWorldVisualizer;import burlap.domain.singleagent.gridworld.state.GridAgent;import burlap.domain.singleagent.gridworld.state.GridWorldState;import burlap.mdp.core.action.Action;import burlap.mdp.core.state.State;import burlap.mdp.singleagent.SADomain;import burlap.mdp.singleagent.model.FullModel;import burlap.mdp.singleagent.model.TransitionProb;import burlap.statehashing.HashableState;import burlap.statehashing.HashableStateFactory;import burlap.statehashing.simple.SimpleHashableStateFactory;import burlap.visualizer.Visualizer;import java.util.*;public class VITutorial extends MDPSolver implements Planner, QProvider{@Overridepublic double value(State s) {return 0.;}@Overridepublic List<QValue> qValues(State s) {// TODO Auto-generated method stubreturn null;}@Overridepublic double qValue(State s, Action a) {// TODO Auto-generated method stubreturn 0.;}@Overridepublic Policy planFromState(State initialState) {// TODO Auto-generated method stub}@Overridepublic void resetSolver() {// TODO Auto-generated method stub}} Because we are sub classing MDPSolver, this object will auto create data members that define our domain and task (the Domain, discount factor, andHashableStateFactory that is used to hash and check the equality of states). However, the other critical data that VI needs to store are its estimates of the value function! A value function is ultimately a mapping from states to a real value. Therefore, for fast access we can use a HashMap and use a HashableStateFactory to provide HashableState instances from states. One way to make VI run faster is to inititialize its value funciton to something close to the optimal value function. Therefore, we can also accept another ValueFunction to use as the initial value function. We'll also have a parameter that specifies how long value iteration should run before it terminates (there are others to test for convergence that we will not cover here). Lets create datamembers for these elements and create a constructor. protected Map<HashableState, Double> valueFunction;protected ValueFunction vinit;protected int numIterations;public VITutorial(SADomain domain, double gamma, HashableStateFactory hashingFactory, ValueFunction vinit, int numIterations){this.solverInit(domain, gamma, hashingFactory);this.vinit = vinit;this.numIterations = numIterations;this.valueFunction = new HashMap<HashableState, Double>();} Note that since our MDPSolver superclass will hold our data members for the domain, discount factor, and HashableStateFactory, we can initialize them with its solverInit method. There is one other critical component VI needs that isn't part of the data we've given it in the constructor: the full state space! One reason we might not want to demand this upfront is because in an MDP, it is possible for the state space to be infinite even though for any given input state there may only be a finite set of states that are reachable. We could require the user to provide to our algorithm up front what the state space is, but it's much easier on the client if we determine the set of possible reachable states for any given seed state ourself and only perform this procedure when planning is requested for a previously unseen state. Lets define a method to get all reachable states from an input state and initialize the value for them with our ValueFunctionInitialization object. Add the below method. public void performReachabilityFrom(State seedState){Set<HashableState> hashedStates = StateReachability.getReachableHashedStates(seedState, this.domain, this.hashingFactory);//initialize the value function for all statesfor(HashableState hs : hashedStates){if(!this.valueFunction.containsKey(hs)){this.valueFunction.put(hs, this.vinit.value(hs.s()));}}} In the first line, we make use of BURLAP's StateReachability tool to do the heavy lifting of finding all reachable states. Then we simply iterate through the list, and for every HashableState for which we do not already have an entry, we initialize it with the value returned from the ValueFunction we use for initialization. You may notice that the value function is passed hs.s(). Since our set of states are actually a set of HashableState instances, we retrieve the underlying State object stored in the HashableState by its s() method. The other method we'll need to implement is the Bellman Equation. As noted on the previous page, the Bellman Equation is just a max over the Q-values and since we already have methods defined for getting the Q-value of states (a requirement of implementing the QProvider interface), we will implement those methods and a Bellman Equation method next. @Overridepublic List<QValue> qValues(State s) {List<Action> applicableActions = this.applicableActions(s);List<QValue> qs = new ArrayList<QValue>(applicableActions.size());for(Action a : applicableActions){qs.add(new QValue(s, a, this.qValue(s, a)));}return qs;}@Overridepublic double qValue(State s, Action a) {if(this.model.terminal(s)){return 0.;}//what are the possible outcomes?List<TransitionProb> tps = ((FullModel)this.model).transitions(s, a);//aggregate over each possible outcomedouble q = 0.;for(TransitionProb tp : tps){//what is reward for this transition?double r = tp.eo.r;//what is the value for the next state?double vp = this.valueFunction.get(this.hashingFactory.hashState(tp.eo.op));//add contribution weighted by transition probability and//discounting the next stateq += tp.p * (r + this.gamma * vp);}return q;} You'll note that the qValues method returns a list of QValue objects, which are just triples consisting of a State object, an Action object, and a double for the Q-value associated with them. In the qValues method, we simply find all possible grounded actions (using a method inherited from MDPSolver which we extended. Alternatively, we could use an ActionUtils method that takes is list of Action objects and State and returns all applicable groundings), ask our qValue method what the Q-value is, and then return the list of all those Q-values. In the qValue method, we first ask our model whether the input state is terminal. If it is, then the Q-value must be 0, because that is the definition of a terminal state. Otherwise, we find all possible transitions from the input state and weigh the value of those outcomes by the probability of the transition occurring. The value of each outcome is the reward received, and the discounted value we have estimated for the outcome state. You might wonder where the model data member comes from. Because we are extending the MDPSolver class, when we called the solverInit method, it automatically unpacked the model included with the domain into a model data member that we can use. This is convenient, because we also allow a client to change the model the solver uses to something other than when comes out of the domain object with the setModel method. Note that the model cast to the super interface SampleModel. To perform dynamic programming, we require a FullModel, and we assume the model is of that type, so we type cast to that and call the FullModel transitions method. We now have all the tools we need to do planning, so it's time to implement the planFromState method. This method is called whenever a client wants to run planning from a given initial (or seed) state. What we'll do then is first check if we've already performed planning that includes that state. If so, we'll do nothing, having assumed to already have computed the value for it. However, if we haven't seen it before, then we'll first find all reachable states from it, and then run value iteration for a given number of iterations. As a reminder, running value iteration means making iterative sweeps over the entire state space in which the value of each state is re-estimated to what the Bellman equation says it is given the previously estimated value of the states. The Bellman equation is just the maximum Q-value, and we can call the QProvider helper method to get the maximum Q-value from objects that implement QProvider, which our class does! Finally, all planFromState methodsrequire return a suitable Policy object to use the planning results. For value iteration, assuming it converged, the optimal policy is to select the action with the highest Q-value; therefore, we'll return a GreedyQPolicy object. GreedyQPolicy objects need to be told what their QFunction source is, which in this case, is the instance of our class. @Overridepublic GreedyQPolicy planFromState(State initialState) {HashableState hashedInitialState = this.hashingFactory.hashState(initialState);if(this.valueFunction.containsKey(hashedInitialState)){return new GreedyQPolicy(this); //already performed planning here!}//if the state is new, then find all reachable states from it firstthis.performReachabilityFrom(initialState);//now perform multiple iterations over the whole state spacefor(int i = 0; i < this.numIterations; i++){//iterate over each statefor(HashableState sh : this.valueFunction.keySet()){//update its value using the bellman equationthis.valueFunction.put(sh, QProvider.Helper.maxQ(this, sh.s()));}}return new GreedyQPolicy(this);} We're now just about finished! The only thing left is that each MDPSolver instance is asked to implement the method resetSolver, which when called should have the effect of resetting all data so that it's as if no planning calls had ever been made. For our VI implementation, all this requires is clearing our value function. @Overridepublic void resetSolver() {this.valueFunction.clear();} Testing VI To test our code, you can try using this planning algorithm with the grid world task created in the previous Basic Planning and Learning tutorial. Alternatively, below is a main method that you can add to test your VI implementation that creates a stochastic grid world, plans for it, and evaluates a single rollout of the resulting policy and visualizes the results. public static void main(String [] args){GridWorldDomain gwd = new GridWorldDomain(11, 11);gwd.setTf(new GridWorldTerminalFunction(10, 10));gwd.setMapToFourRooms();//only go in intended directon 80% of the timegwd.setProbSucceedTransitionDynamics(0.8);SADomain domain = gwd.generateDomain();//get initial state with agent in 0,0State s = new GridWorldState(new GridAgent(0, 0));//setup vi with 0.99 discount factor, a value//function initialization that initializes all states to value 0, and which will//run for 30 iterations over the state spaceVITutorial vi = new VITutorial(domain, 0.99, new SimpleHashableStateFactory(),new ConstantValueFunction(0.0), 30);//run planning from our initial statePolicy p = vi.planFromState(s);//evaluate the policy with one roll out visualize the trajectoryEpisode ea = PolicyUtils.rollout(p, s, domain.getModel());Visualizer v = GridWorldVisualizer.getVisualizer(gwd.getMap());new EpisodeSequenceVisualizer(v, domain, Arrays.asList(ea));} If you're looking to extend this tutorial on VI a little more, you might consider implementing a more intelligent VI termination condition so that rather than always running VI for a fixed number of iterations, VI terminates if the maximum change in the value function is smaller than some small threshold. Otherwise, it's now time to move on to our Q-learning example! If you'd like to see the full code we wrote all together, jump to the end of this tutorial . Next Part", "http://burlap.cs.brown.edu/tutorials/cpl/p4.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Creating a Planning and Learning Algorithm Tutorials > Creating a Planning and Learning Algorithm > Part 4 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Previous Part Conclusions In this tutorial we showed you how to implement your own planning and learning algorithms. Although these algorithms were simple, they exposed the necessary BURLAP tools and mechanisms you will need to use to implement your own algorithms and should enable you to start writing your own code. In general, we highly recommend that you use BURLAP's existing implementations of Value Iteration and Q-Learning since they support a number of other features (Options, learning rate decay schedules, etc.). If you would like to see all of the code that was written in this tutorial, we have provided it below (first the Value Iteration code , then the Q-learning Code ). The code is also available in the burlap_examples repository. Full VI Code import burlap.behavior.policy.GreedyQPolicy;import burlap.behavior.policy.Policy;import burlap.behavior.policy.PolicyUtils;import burlap.behavior.singleagent.Episode;import burlap.behavior.singleagent.MDPSolver;import burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizer;import burlap.behavior.singleagent.auxiliary.StateReachability;import burlap.behavior.singleagent.planning.Planner;import burlap.behavior.valuefunction.ConstantValueFunction;import burlap.behavior.valuefunction.QProvider;import burlap.behavior.valuefunction.QValue;import burlap.behavior.valuefunction.ValueFunction;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.GridWorldTerminalFunction;import burlap.domain.singleagent.gridworld.GridWorldVisualizer;import burlap.domain.singleagent.gridworld.state.GridAgent;import burlap.domain.singleagent.gridworld.state.GridWorldState;import burlap.mdp.core.action.Action;import burlap.mdp.core.state.State;import burlap.mdp.singleagent.SADomain;import burlap.mdp.singleagent.model.FullModel;import burlap.mdp.singleagent.model.TransitionProb;import burlap.statehashing.HashableState;import burlap.statehashing.HashableStateFactory;import burlap.statehashing.simple.SimpleHashableStateFactory;import burlap.visualizer.Visualizer;import java.util.*;public class VITutorial extends MDPSolver implements Planner, QProvider {protected Map<HashableState, Double> valueFunction;protected ValueFunction vinit;protected int numIterations;public VITutorial(SADomain domain, double gamma, HashableStateFactory hashingFactory, ValueFunction vinit, int numIterations){this.solverInit(domain, gamma, hashingFactory);this.vinit = vinit;this.numIterations = numIterations;this.valueFunction = new HashMap<HashableState, Double>();}@Overridepublic double value(State s) {Double d = this.valueFunction.get(hashingFactory.hashState(s));if(d == null){return vinit.value(s);}return d;}@Overridepublic List<QValue> qValues(State s) {List<Action> applicableActions = this.applicableActions(s);List<QValue> qs = new ArrayList<QValue>(applicableActions.size());for(Action a : applicableActions){qs.add(new QValue(s, a, this.qValue(s, a)));}return qs;}@Overridepublic double qValue(State s, Action a) {if(this.model.terminal(s)){return 0.;}//what are the possible outcomes?List<TransitionProb> tps = ((FullModel)this.model).transitions(s, a);//aggregate over each possible outcomedouble q = 0.;for(TransitionProb tp : tps){//what is reward for this transition?double r = tp.eo.r;//what is the value for the next state?double vp = this.valueFunction.get(this.hashingFactory.hashState(tp.eo.op));//add contribution weighted by transition probability and//discounting the next stateq += tp.p * (r + this.gamma * vp);}return q;}@Overridepublic GreedyQPolicy planFromState(State initialState) {HashableState hashedInitialState = this.hashingFactory.hashState(initialState);if(this.valueFunction.containsKey(hashedInitialState)){return new GreedyQPolicy(this); //already performed planning here!}//if the state is new, then find all reachable states from it firstthis.performReachabilityFrom(initialState);//now perform multiple iterations over the whole state spacefor(int i = 0; i < this.numIterations; i++){//iterate over each statefor(HashableState sh : this.valueFunction.keySet()){//update its value using the bellman equationthis.valueFunction.put(sh, QProvider.Helper.maxQ(this, sh.s()));}}return new GreedyQPolicy(this);}@Overridepublic void resetSolver() {this.valueFunction.clear();}public void performReachabilityFrom(State seedState){Set<HashableState> hashedStates = StateReachability.getReachableHashedStates(seedState, this.domain, this.hashingFactory);//initialize the value function for all statesfor(HashableState hs : hashedStates){if(!this.valueFunction.containsKey(hs)){this.valueFunction.put(hs, this.vinit.value(hs.s()));}}}public static void main(String [] args){GridWorldDomain gwd = new GridWorldDomain(11, 11);gwd.setTf(new GridWorldTerminalFunction(10, 10));gwd.setMapToFourRooms();//only go in intended directon 80% of the timegwd.setProbSucceedTransitionDynamics(0.8);SADomain domain = gwd.generateDomain();//get initial state with agent in 0,0State s = new GridWorldState(new GridAgent(0, 0));//setup vi with 0.99 discount factor, a value//function initialization that initializes all states to value 0, and which will//run for 30 iterations over the state spaceVITutorial vi = new VITutorial(domain, 0.99, new SimpleHashableStateFactory(),new ConstantValueFunction(0.0), 30);//run planning from our initial statePolicy p = vi.planFromState(s);//evaluate the policy with one roll out visualize the trajectoryEpisode ea = PolicyUtils.rollout(p, s, domain.getModel());Visualizer v = GridWorldVisualizer.getVisualizer(gwd.getMap());new EpisodeSequenceVisualizer(v, domain, Arrays.asList(ea));}} Full Q-Learning Code import burlap.behavior.policy.EpsilonGreedy;import burlap.behavior.policy.Policy;import burlap.behavior.singleagent.Episode;import burlap.behavior.singleagent.MDPSolver;import burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizer;import burlap.behavior.singleagent.learning.LearningAgent;import burlap.behavior.valuefunction.ConstantValueFunction;import burlap.behavior.valuefunction.QFunction;import burlap.behavior.valuefunction.QProvider;import burlap.behavior.valuefunction.QValue;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.GridWorldTerminalFunction;import burlap.domain.singleagent.gridworld.GridWorldVisualizer;import burlap.domain.singleagent.gridworld.state.GridAgent;import burlap.domain.singleagent.gridworld.state.GridWorldState;import burlap.mdp.core.action.Action;import burlap.mdp.core.state.State;import burlap.mdp.singleagent.SADomain;import burlap.mdp.singleagent.environment.Environment;import burlap.mdp.singleagent.environment.EnvironmentOutcome;import burlap.mdp.singleagent.environment.SimulatedEnvironment;import burlap.statehashing.HashableState;import burlap.statehashing.HashableStateFactory;import burlap.statehashing.simple.SimpleHashableStateFactory;import burlap.visualizer.Visualizer;import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;public class QLTutorial extends MDPSolver implements LearningAgent, QProvider {Map<HashableState, List<QValue>> qValues;QFunction qinit;double learningRate;Policy learningPolicy;public QLTutorial(SADomain domain, double gamma, HashableStateFactory hashingFactory, QFunction qinit, double learningRate, double epsilon){this.solverInit(domain, gamma, hashingFactory);this.qinit = qinit;this.learningRate = learningRate;this.qValues = new HashMap<HashableState, List<QValue>>();this.learningPolicy = new EpsilonGreedy(this, epsilon);}@Overridepublic Episode runLearningEpisode(Environment env) {return this.runLearningEpisode(env, -1);}@Overridepublic Episode runLearningEpisode(Environment env, int maxSteps) {//initialize our episode object with the initial state of the environmentEpisode e = new Episode(env.currentObservation());//behave until a terminal state or max steps is reachedState curState = env.currentObservation();int steps = 0;while(!env.isInTerminalState() && (steps < maxSteps || maxSteps == -1)){//select an actionAction a = this.learningPolicy.action(curState);//take the action and observe outcomeEnvironmentOutcome eo = env.executeAction(a);//record resulte.transition(eo);//get the max Q value of the resulting state if it's not terminal, 0 otherwisedouble maxQ = eo.terminated ? 0. : this.value(eo.op);//update the old Q-valueQValue oldQ = this.storedQ(curState, a);oldQ.q = oldQ.q + this.learningRate * (eo.r + this.gamma * maxQ - oldQ.q);//update state pointer to next environment state observedcurState = eo.op;steps++;}return e;}@Overridepublic void resetSolver() {this.qValues.clear();}@Overridepublic List<QValue> qValues(State s) {//first get hashed stateHashableState sh = this.hashingFactory.hashState(s);//check if we already have stored valuesList<QValue> qs = this.qValues.get(sh);//create and add initialized Q-values if we don't have them stored for this stateif(qs == null){List<Action> actions = this.applicableActions(s);qs = new ArrayList<QValue>(actions.size());//create a Q-value for each actionfor(Action a : actions){//add q with initialized valueqs.add(new QValue(s, a, this.qinit.qValue(s, a)));}//store this for laterthis.qValues.put(sh, qs);}return qs;}@Overridepublic double qValue(State s, Action a) {return storedQ(s, a).q;}protected QValue storedQ(State s, Action a){//first get all Q-valuesList<QValue> qs = this.qValues(s);//iterate through stored Q-values to find a match for the input actionfor(QValue q : qs){if(q.a.equals(a)){return q;}}throw new RuntimeException(\"Could not find matching Q-value.\");}@Overridepublic double value(State s) {return QProvider.Helper.maxQ(this, s);}public static void main(String[] args) {GridWorldDomain gwd = new GridWorldDomain(11, 11);gwd.setMapToFourRooms();gwd.setProbSucceedTransitionDynamics(0.8);gwd.setTf(new GridWorldTerminalFunction(10, 10));SADomain domain = gwd.generateDomain();//get initial state with agent in 0,0State s = new GridWorldState(new GridAgent(0, 0));//create environmentSimulatedEnvironment env = new SimulatedEnvironment(domain, s);//create Q-learningQLTutorial agent = new QLTutorial(domain, 0.99, new SimpleHashableStateFactory(),new ConstantValueFunction(), 0.1, 0.1);//run Q-learning and store results in a listList<Episode> episodes = new ArrayList<Episode>(1000);for(int i = 0; i < 1000; i++){episodes.add(agent.runLearningEpisode(env));env.resetEnvironment();}Visualizer v = GridWorldVisualizer.getVisualizer(gwd.getMap());new EpisodeSequenceVisualizer(v, domain, episodes);}} End.", "http://burlap.cs.brown.edu/tutorials/cpl/p3.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Creating a Planning and Learning Algorithm Tutorials > Creating a Planning and Learning Algorithm > Part 3 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Previous Part | Next Part Q-Learning Overview For our learning algorithm example, we'll be implementing Q-learning. The difference between a learning algorithm and a planning algorithm is that a planning algorithm has access to a model of the world, or at least a simulator, whereas a learning algorithm involves determining behavior when the agent does not know how the world works and must learn how to behave from direct experience with the world. In general, there are two approaches to reinforcement learning: (1) to learn a model of the world from experience and then use planning with that learned model to dictate behavior (model-based) and (2) to learn a policy or value function directly from experience (model-free). Q-learning belongs to the latter. As the name suggests, Q-learning learns estimates of the optimal Q-values of an MDP, which means that behavior can be dictated by taking actions greedily with respect to the learned Q-values. Q-learning can be summarized in the following pseudocode. Q-Learning Initialize Q-values ($Q(s,a)$) arbitrarily for all state-action pairs. For life or until learning is stopped... Choose an action ($a$) in the current world state ($s$) based on current Q-value estimates ($Q(s,\\cdot)$). Take the action ($a$) and observe the the outcome state ($s'$) and reward ($r$). Update $Q(s,a) := Q(s,a) + \\alpha \\left[ r + \\gamma \\max_{a'} Q(s', a') - Q(s,a) \\right]$ The two key steps in the above pseudocode are steps 3 and 5. There are many ways to choose actions based on the current Q-value estimates (step 3), but one of the most common is to use an $\\epsilon$-greedy policy. In this policy, the action is selected greedily with respect to the Q-value estimates a fraction ($1-\\epsilon$) of the time (where $\\epsilon$ is a fraction between 0 and 1), and randomly selected among all actions a fraction $\\epsilon$ of the time. In general, you want a policy that has some randomness to it so that it promotes exploration of the state space. The update rule:$$\\large Q(s,a) := Q(s,a) + \\alpha \\left[ r + \\gamma \\max_{a'} Q(s', a') - Q(s,a) \\right]$$updates the Q-value of the last state-action pair ($s,a$) with respect to the observed outcome state ($s'$) and reward ($r$), where $\\alpha \\in (0, 1)$ is a learning rate parameter. To unpack this update, recall from the Bellman equation that the Value of a state is the maximum Q-value and the Q-value is the expected sum of the reward and discounted value of the next state, where the expectation is with respect to the probability of each state transition. In the Q-learning update rule, the reward plus the discounted max Q-value in the observed next state is effectively what the Bellman equation tells us the Q-value is, except in this case, we're not marginalizing over all possible outcome states, we only have the one observed state and reward that we happened to get. However, because our learning rate only allows our Q-value to change slightly from its old estimate to a new estimate in the direction of the observed state and reward, as long as we keep retrying that action in the same state, we'll see the other possible states that could have occurred and move in their direction too. In aggregate over multiple tries of the action then, the Q-value will move toward the true expected value, even though we never directly used the transition probabilities. To have guaranteed convergence to the true Q-value, we should actually be slowly decreasing the learning rate parameter over time. However, in practice, it's often sufficient to simply use a small learning rate parameter, so for simplicity in our implementation, we'll use a fixed value for the learning rate rather that one that changes with time (though in the full Q-learning algorithm provided in BURLAP, you can use different schedules for decreasing the learning rate, including client-provided custom schedules with the LearningRate interface). Q-Learning Code Lets begin implementing our Q-learning algorithm code. Our class, called QLTutorial, will extend MDPSolver and implement the LearningAgent and QProvider interfaces. The LearningAgent interface specifies the common methods a learning algorithm is expected to implement so that it can be used by other BURLAP tools. Below is the skeleton code that is created when we created our class. import burlap.behavior.policy.EpsilonGreedy;import burlap.behavior.policy.Policy;import burlap.behavior.singleagent.Episode;import burlap.behavior.singleagent.MDPSolver;import burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizer;import burlap.behavior.singleagent.learning.LearningAgent;import burlap.behavior.valuefunction.ConstantValueFunction;import burlap.behavior.valuefunction.QFunction;import burlap.behavior.valuefunction.QProvider;import burlap.behavior.valuefunction.QValue;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.GridWorldTerminalFunction;import burlap.domain.singleagent.gridworld.GridWorldVisualizer;import burlap.domain.singleagent.gridworld.state.GridAgent;import burlap.domain.singleagent.gridworld.state.GridWorldState;import burlap.mdp.core.action.Action;import burlap.mdp.core.state.State;import burlap.mdp.singleagent.SADomain;import burlap.mdp.singleagent.environment.Environment;import burlap.mdp.singleagent.environment.EnvironmentOutcome;import burlap.mdp.singleagent.environment.SimulatedEnvironment;import burlap.statehashing.HashableState;import burlap.statehashing.HashableStateFactory;import burlap.statehashing.simple.SimpleHashableStateFactory;import burlap.visualizer.Visualizer;import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;public class QLTutorial extends MDPSolver implements LearningAgent, QProvider {@Overridepublic Episode runLearningEpisode(Environment env) {return null;}@Overridepublic Episode runLearningEpisode(Environment env, int maxSteps) {return null;}@Overridepublic void resetSolver() {}@Overridepublic List<QValue> qValues(State s) {return null;}@Overridepublic double qValue(State s, Action a) {return 0.;}@Overridepublic double value(State s) {return 0.;} Similar to VI, the primary data we will want to store is a set of estimated Q-values for each state and action pair. We'll also again let the user specify the Q-value function initialization with a QFunction object. We'll also need a learning rate parameter to be set. Finally, we'll need a learning policy to follow; that is, a policy that dictates how the agent chooses actions at each step. For this tutorial, we'll assume an $\\epsilon$-greedy policy and let the client specify the value for $\\epsilon$. Lets add data members for those elements now. Map<HashableState, List<QValue>> qValues;QFunction qinit;double learningRate;Policy learningPolicy; Lets also add a constructor to initialize our data members and some of those that we inherit from MDPSolver. public QLTutorial(SADomain domain, double gamma, HashableStateFactory hashingFactory, QFunction qinit, double learningRate, double epsilon){this.solverInit(domain, gamma, hashingFactory);this.qinit = qinit;this.learningRate = learningRate;this.qValues = new HashMap<HashableState, List<QValue>>();this.learningPolicy = new EpsilonGreedy(this, epsilon);} Note that the EpsilonGreedy policy object we create takes as input a QProvider, which this class implements, and the value for epsilon to use. Getting and storing Q-values is the primary tool we'll need for our algorithm, so lets implement the value function methods now. @Overridepublic List<QValue> qValues(State s) {//first get hashed stateHashableState sh = this.hashingFactory.hashState(s);//check if we already have stored valuesList<QValue> qs = this.qValues.get(sh);//create and add initialized Q-values if we don't have them stored for this stateif(qs == null){List<Action> actions = this.applicableActions(s);qs = new ArrayList<QValue>(actions.size());//create a Q-value for each actionfor(Action a : actions){//add q with initialized valueqs.add(new QValue(s, a, this.qinit.qValue(s, a)));}//store this for laterthis.qValues.put(sh, qs);}return qs;}@Overridepublic double qValue(State s, Action a) {return storedQ(s, a).q;}protected QValue storedQ(State s, Action a){//first get all Q-valuesList qs = this.qValues(s);//iterate through stored Q-values to find a match for the input actionfor(QValue q : qs){if(q.a.equals(a)){return q;}}throw new RuntimeException(\"Could not find matching Q-value.\");}@Overridepublic double value(State s) {return QProvider.Helper.maxQ(this, s);} Note that the qValues method checks if we've already stored Q-values for the given state. If not, we create them with the initial Q-value defined by our QFunction initialization object. For the qValue method, we go through a helper method that returnes the stored QValue object for a given action; this storedQ method will be useful for updating our Q-values for the actual learning algorithm. The value method, like for our value iteration example, can simply return the result of the QProvider Helper class method maxQ. Now that we have all of our helper methods, lets implement the learning algorithm. The LearningAgent interface requires us to implement two methods that cause learning to be run for one episode in some Environment ; one that will run learning until the agent reaches a terminal state and one that will run learning for a maximum number of steps or until a terminal state is reached. We will have the former call the latter with a -1 for the maximum number of steps to indicate that it should never stop until the agent reaches a terminal state. Both methods also require returning an Episode object, which is a recording of all the states, actions, and rewards that occurred in an episode, so as we write the code to have the agent iteratively select actions, we'll record the results to an Episode object. Below is the learning algorithm code for Q-learning. @Overridepublic Episode runLearningEpisode(Environment env) {return this.runLearningEpisode(env, -1);}@Overridepublic Episode runLearningEpisode(Environment env, int maxSteps) {//initialize our episode object with the initial state of the environmentEpisode e = new Episode(env.currentObservation());//behave until a terminal state or max steps is reachedState curState = env.currentObservation();int steps = 0;while(!env.isInTerminalState() && (steps < maxSteps || maxSteps == -1)){//select an actionAction a = this.learningPolicy.action(curState);//take the action and observe outcomeEnvironmentOutcome eo = env.executeAction(a);//record resulte.transition(eo);//get the max Q value of the resulting state if it's not terminal, 0 otherwisedouble maxQ = eo.terminated ? 0. : this.value(eo.op);//update the old Q-valueQValue oldQ = this.storedQ(curState, a);oldQ.q = oldQ.q + this.learningRate * (eo.r + this.gamma * maxQ - oldQ.q);//update state pointer to next environment state observedcurState = eo.op;steps++;}return e;} The beginning of the code is fairly straightforward; we construct a new Episode object rooted in the current state of the environment, which we get back from the Environment method getCurrentObservation(). We then begin an execution loop that lasts either until the Environment reaches a terminal state or until the number of steps we've taken exceeds the number requested. Inside the execution loop, we first select an action using our learning policy. Then we execute the action in the environment using the GroundedAction method executeIn(Environment),which returns to us an EnvironmentOutcome object. Environment Observations You may have noticed that the Environment uses \"observation\" terminology instead of \"state\" terminology. This choice is because Environment objects are not under obligation to return to the agent a full state, only an observation. Typically, for MDPdomains you can expect it to be a full State, and regardless of whether it is a partial observation or not, the observation itself will always be represnted by a BURLAP State object. Note that the use of this terminology is especially useful if you begin using BURLAP's POMDP framework. Using the new observations from the environment, we record the transition in our Episode and update the previous Q-Value. To update the previous Q-value, we need to get the maximum Q-value for the next state we encounted. However, if that state is a terminal state, then the value should always be zero, because the agent cannot act further from that state. Otherwise, we can get the maximum value by using value method that we previously defined. Finally, we can implement the resetSover method, which only needs to clear our Q-values. @Overridepublic void resetSolver() {this.qValues.clear();} Testing Q-Learning As before, you can now test your learning algorithm with the previous code developed in the Basic Planning and Learning tutorial . Alternatively, you can use the below main method which creates a similar Grid World domain and task as the test code we wrote for our VI implementation, except applies the Q-Learning algorithm to it in a simulated environment. The results of each leaning episode will be presented for you after learning completes. Note that because the domain is stochastic (and follows a nosiy exploration policy), it can take much longer to learn and the resulting policy will not be a straight shot to the goal. public static void main(String[] args) {GridWorldDomain gwd = new GridWorldDomain(11, 11);gwd.setMapToFourRooms();gwd.setProbSucceedTransitionDynamics(0.8);gwd.setTf(new GridWorldTerminalFunction(10, 10));SADomain domain = gwd.generateDomain();//get initial state with agent in 0,0State s = new GridWorldState(new GridAgent(0, 0));//create environmentSimulatedEnvironment env = new SimulatedEnvironment(domain, s);//create Q-learningQLTutorial agent = new QLTutorial(domain, 0.99, new SimpleHashableStateFactory(),new ConstantValueFunction(), 0.1, 0.1);//run Q-learning and store results in a listList<Episode> episodes = new ArrayList<Episode>(1000);for(int i = 0; i < 1000; i++){episodes.add(agent.runLearningEpisode(env));env.resetEnvironment();}Visualizer v = GridWorldVisualizer.getVisualizer(gwd.getMap());new EpisodeSequenceVisualizer(v, domain, episodes);} Next Part", "http://burlap.cs.brown.edu/tutorials/hgw/p1.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Hello Grid World! Tutorials > Hello Grid World! > Part 1 Tutorial Contents Introduction Compiling from Source Hello Grid World Project Conclusion You are viewing the tutorial for BURLAP 3 with Maven. If you'd like the BURLAP 2 tutorial, go here . Introduction In this tutorial we will walk you through getting started with BURLAP. We will assume that you have Maven installed for this process, since it will make management of dependencies very straightforward. If you do not already have Maven installed, you can probably get it from your favorite package manager. For example, on Debian systems, sudo apt-get install maven Or on Mac OS with homebrew: brew install maven Alternatively, you can manually install it from https://maven.apache.org/download.cgi . Be sure to follow their installtion instructions. To verify that you have maven installed try the following from the command line mvn -v We also highly recommend that you use an IDE for your work, which will make working with the library substantially easier. If you do not have an IDE we recommend either IntelliJ or Eclipse . Both will have tools for working with Maven projects. That said, for this tutorial we will give instructions using just the command line and your favorite text editor. You can probably follow along in an IDE if you prefer. In this tutorial you will have two options. You can either build and install BURLAP from its source, or you can simply use the released version of BURLAP from Maven Central. The latter will require the least work, but if you'd like to be able to modify BURLAP at all or want to make sure you always have the most update to date version, it may be worth it to checkout out the code and manually compile it. If you prefer to simply use the Maven Central copy, skip the next section. We will make use of the command line to test things out and compile everything. On the Mac and Linux you can just use the terminal. If you are on windows, you can use either use the command prompt something like Cygwin . Compiling from Source To compile the code from source, you will probably want to have git installed, or you can manually download the source from github. If you have git installed, navigate from your command line to a directory where you would like to place the code. Then type the following: git clone https://github.com/jmacglashan/burlap.git If you do not have git installed on your computer, then you can manually download the files by navigating to the website https://github.com/jmacglashan/burlap and clicking on \"download zip\" to save it and unarchive it at a desired location. Whether you used git to clone the source, or manually downloaded it, navigate into the directory with your command line. The directory should look something like the following: LICENSEREADME.mdburlap-repopom.xmlsrc Now we can compile using Maven, which you should have installed on the previous step. You can use the standard Maven methods for compilation. That is, to simply compile the code, use mvn compile To create a jar file and Java doc in the target directory (as well as jar file that includes all dependencies) use mvn package And to install BURLAP to your local Maven repository, use mvn install And if you want to skip the tests (which may take a while), use the command mvn install -DskipTests That's it! Hello Grid World Project Whether you compiled and installed BURLAP from source in the prior step or not, this next section is the same because BURLAP is available on Maven Central, which means Maven will automatically download it and install it if you did not compile it from source. To begin our example project, create a directory somewhere on your file system where you will store the project code and navigate into it on your command line. If you've used Maven before, you may want to create your project by generating an archetype. Feel free to do so if you, like. However, we will manually set up the project from the command line and text editors here. First create a file named pom.xml. With your favorite text editor, insert the following 4.0.0 com.mycompany.app myProj 1 edu.brown.cs.burlap burlap 3.0.0 org.codehaus.mojo exec-maven-plugin 1.2.1 java You should set the group id at the top to anything that seems relevant for you, and you can also rename the artifact id to something else if you prefer. Note the <dependencies> section with the BURLAP dependency, which tells Maven that your project depends on BURALP. As of writing this tutorial, the latest version of BURLAP is 3.1.0. However, you may want to change this value to whatever the latest is, or to a version you prefer (especially if you've installed your own custom version with its own version number). You can see the list of all release versions of BURLAP from here . The plugin we added will also allow us to use Maven to easily run code that we write. Now create the following directory tree: src/main/java/myProj. Inside the nested myProj folder, we will create two text files, HelloGridWorld.java and PlotTest.java. HelloGridWorld.java should have the following contents. package myProj;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.GridWorldVisualizer;import burlap.domain.singleagent.gridworld.state.GridAgent;import burlap.domain.singleagent.gridworld.state.GridLocation;import burlap.domain.singleagent.gridworld.state.GridWorldState;import burlap.mdp.core.state.State;import burlap.mdp.singleagent.SADomain;import burlap.shell.visual.VisualExplorer;import burlap.visualizer.Visualizer;public class HelloGridWorld {public static void main(String[] args) {GridWorldDomain gw = new GridWorldDomain(11,11); //11x11 grid worldgw.setMapToFourRooms(); //four rooms layoutgw.setProbSucceedTransitionDynamics(0.8); //stochastic transitions with 0.8 success rateSADomain domain = gw.generateDomain(); //generate the grid world domain//setup initial stateState s = new GridWorldState(new GridAgent(0, 0), new GridLocation(10, 10, \"loc0\"));//create visualizer and explorerVisualizer v = GridWorldVisualizer.getVisualizer(gw.getMap());VisualExplorer exp = new VisualExplorer(domain, v, s);//set control keys to use w-s-a-dexp.addKeyAction(\"w\", GridWorldDomain.ACTION_NORTH, \"\");exp.addKeyAction(\"s\", GridWorldDomain.ACTION_SOUTH, \"\");exp.addKeyAction(\"a\", GridWorldDomain.ACTION_WEST, \"\");exp.addKeyAction(\"d\", GridWorldDomain.ACTION_EAST, \"\");exp.initGUI();}} And PlotTest.java should have the contents package myProj;import burlap.behavior.singleagent.auxiliary.performance.LearningAlgorithmExperimenter;import burlap.behavior.singleagent.auxiliary.performance.PerformanceMetric;import burlap.behavior.singleagent.auxiliary.performance.TrialMode;import burlap.behavior.singleagent.learning.LearningAgent;import burlap.behavior.singleagent.learning.LearningAgentFactory;import burlap.behavior.singleagent.learning.tdmethods.QLearning;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.state.GridAgent;import burlap.domain.singleagent.gridworld.state.GridLocation;import burlap.domain.singleagent.gridworld.state.GridWorldState;import burlap.mdp.auxiliary.common.ConstantStateGenerator;import burlap.mdp.auxiliary.common.SinglePFTF;import burlap.mdp.auxiliary.stateconditiontest.TFGoalCondition;import burlap.mdp.core.TerminalFunction;import burlap.mdp.core.oo.propositional.PropositionalFunction;import burlap.mdp.singleagent.common.GoalBasedRF;import burlap.mdp.singleagent.environment.SimulatedEnvironment;import burlap.mdp.singleagent.model.RewardFunction;import burlap.mdp.singleagent.oo.OOSADomain;import burlap.statehashing.simple.SimpleHashableStateFactory;public class PlotTest {public static void main(String [] args){GridWorldDomain gw = new GridWorldDomain(11,11); //11x11 grid worldgw.setMapToFourRooms(); //four rooms layoutgw.setProbSucceedTransitionDynamics(0.8); //stochastic transitions with 0.8 success rate//ends when the agent reaches a locationfinal TerminalFunction tf = new SinglePFTF(PropositionalFunction.findPF(gw.generatePfs(), GridWorldDomain.PF_AT_LOCATION));//reward function definitionfinal RewardFunction rf = new GoalBasedRF(new TFGoalCondition(tf), 5., -0.1);gw.setTf(tf);gw.setRf(rf);final OOSADomain domain = gw.generateDomain(); //generate the grid world domain//setup initial stateGridWorldState s = new GridWorldState(new GridAgent(0, 0), new GridLocation(10, 10, \"loc0\"));//initial state generatorfinal ConstantStateGenerator sg = new ConstantStateGenerator(s);//set up the state hashing system for looking up statesfinal SimpleHashableStateFactory hashingFactory = new SimpleHashableStateFactory();/** * Create factory for Q-learning agent */LearningAgentFactory qLearningFactory = new LearningAgentFactory() {public String getAgentName() {return \"Q-learning\";}public LearningAgent generateAgent() {return new QLearning(domain, 0.99, hashingFactory, 0.3, 0.1);}};//define learning environmentSimulatedEnvironment env = new SimulatedEnvironment(domain, sg);//define experimentLearningAlgorithmExperimenter exp = new LearningAlgorithmExperimenter(env,10, 100, qLearningFactory);exp.setUpPlottingConfiguration(500, 250, 2, 1000, TrialMode.MOST_RECENT_AND_AVERAGE,PerformanceMetric.CUMULATIVE_STEPS_PER_EPISODE, PerformanceMetric.AVERAGE_EPISODE_REWARD);//start experimentexp.startExperiment();}} Your directory structure should now look like the following. pom.xmlsrc/main/java/myProj/HelloGridWorld.javaPlotTest.java We're now ready to compile and run! In the command line, make sure you're in the same directory as your pom.xml file. Then, to compile, run mvn compile Maven should download BURLAP (if you did not manually compile and install it) and other information, and then compile your two sources. To run the HelloGridWorld code, use the following command mvn exec:java -Dexec.mainClass=\"myProj.HelloGridWorld\" Running this code should launch a GUI with a grid world, similar to the image below. If you click on the image and then use the w-a-s-d keys, you'll be able to control the agent's movements. Note, however, that we made this a stochastic grid world in the code, which means some of the time you may find the agent going in a different direction than the one you intended! We can similarly run our PlotTest code with mvn exec:java -Dexec.mainClass=\"myProj.PlotTest\" Which will run Q-learning on the same grid world 10 times, plotting the most recent trial and average performance. It should look something like the below image. Conclusion In this tutorial we walked you through compiling BURLAP and setting up your own Maven project that uses BURLAP. We used the command line to set everything up, but we strongly encourage you to use a full IDE for most projects, such as IntelliJ or Eclipse . You can initialize your projects the way we did here and then import the code into the IDE, or you can have these IDE's create a new Maven project themselves. Now that you've completed this tutorial, you are encouraged to check out the other BURLAP tutorials that are available. Happy coding! End.", "http://burlap.cs.brown.edu/tutorials/index.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorials You are viewing the tutorials for BURLAP 2; if you'd like the BURLAP version 1 tutorials, go here . This page provides a list of all available BURLAP tutorials. There are both short video tutorials and more explanatory and detailed text tutorials. You can find code for all of the tutorials and more in our examples repository: https://github.com/jmacglashan/burlap_examples/ Video Tutorials Text Tutorials Hello Grid World! - a tutorial on acquiring and linking with BURLAP Building a Domain Using Basic Planning and Learning Algorithms Creating a Planning and Learning Algorithm Solving Continuous Domains Building an OO-MDP Domain", "http://burlap.cs.brown.edu/tutorials/oomdp/p1.html": "` Building a Domain MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}}); BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building an OO-MDP Domain Tutorials > Building an OO-MDP Domain > Part 1 Tutorial Contents Introduction Java Interfaces for OO-MDPs Object Identifier Independence Grid World OO-MDP States Grid World OO-MDP Model OO-MDP Visualization Testing it Out Conclusion Final Code Next Part Introduction In the Building a Domain tutorial, we showed you how to construct an MDP. In this tutorial, we will show you how to construct an Object-oriented MDP (OO-MDP). OO-MDPs are MDPs that have a specific kind of rich state representation and BURLAP provides first class support for defining MDPs as OO-MDPs; many of the existing domains in BURLAP are in fact implemented as OO-MDPs themselves. Although you can probably do fine defining your domains without using the OO-MDP interfaces provided in BURLAP, you may find that the extra richness is useful, or you may be able to write learning algorithms that can exploit this kind of structured state. OO-MDPs represent states as an unordered collection of objects. Each object has its own set of state variables that are defined by an OO-MDP object class from which the object is instantiated. Additionally, OO-MDPs can also include a set of propositional functions; functions that take as input state objects that belong to certain typed state classes, and evaluate properties of, or relationships between, the object arguments. Since Java is an object-oriented programming language, we can make the definition of OO-MDP state objects as simple as defining a Java class for them that implements an interface! In this tutorial we will review the Java interfaces involved in defining OO-MDPs and review an important invariance of states that we can exploit through the OO-MDP definitions: object identifier independence. We will then walk through how to define the Grid World we made in the previous Building a Domain tutorial as an OO-MDP with additional OO-MDP objects for marking important goal locations and a propositional function that will evaluate whether an agent is at one of those locations. As usual, all example code is provided at the end of this tutorial, and is available in the burlap_examples , github repository. Java Interfaces for OO-MDPs A UML diagram of the Java interfaces and classes related to creating OO-MDPs is shown in the below figure. Figure: UML Digram of OO-MDP interfaces/classes. OO-MDP States As indicated by the UML diagram, implementing an OO-MDP state involves implementing the OOState interface. An OOState is ultimately defined by a collection of objects that implement the ObjectInstance interface. ObjectInstance is itself an extension to the State interface, which means objects of an OO-MDP are also just states and can be treated entirely as such, allowing for composition of various tools. Defining the Java class for an ObjectInstance simultaneously serves as defining the OO-MDP object class. To implement an ObjectInstance, in addition to the standard State methods, you must also implement a method for returning the name of the OO-MDP object class, a name that uniquely identifies the object from other objects that will appear alongside it in the same OOState, and a method that can produce a copy of the object with a different identifying name. In addition to implementing an OOState that it is made up of ObjectInstances, you will also need to implement methods for querying the number of ObjectInstances, retrieving an ObjectInstance by name, retrieving a list of all the objects, and retrieving a list of Objects belonging to a specified OO-MDP class. When implementing the State get and variableKeys methods for an OOState, it is recommended that you use keys that are OOVariableKey objects, which is a pair specifying a name of an object and its variable key, which is the information a client would need to query about each variable in the entire OOState. If an ObjectInstance accepts string representations of variable keys, an OOVariableKey can also be constructed from a String representation following the format \"obName:variableKey\". If you would like a mutable state that is also an OOState, then you may also want to consider implementing the MutableOOState interface, which provides methods for adding objects to the state, removing objects, and renaming an object's identifier. For maximum performance and minimum memory overhead, you should consider implementing your own OOState classes; however, BURLAP also provides a general purpose concrete OOState implementation: GenericOOState. GenericOOState implements MutableOOState and uses ShallowCopying of the ObjectInstances to minimize some of the memory overhead, with the set method using copy-on-write to prevent contamination of ancestor states from which it was copied. GenericOOState also provides some additional methods for causing an object belonging to the state to be replaced with a copy, so that you can directly modify copied ObjectInstances without going through the set method. DeepOOState is a concrete extension of GenericOOState that always performs deep copies so you can directly modify ObjectInstances without having to manually manage the copying of ObjectInstances. In this tutorial, we will make use of GenericOOState and show you how to work with it. Propositional Functions In addition to OO-MDP states being made up of collections of objects, OO-MDPs can also have an associated set of propositional functions that provide high-level state information in the form of boolean properties and relationships between objects in the State. In BURLAP, you can create these propositional functions by extending the abstract class PropositionalFunction . Extending a PropositionalFunction requires giving it a name, a function signature, and implementing the isTrue method. The function signature is the OO-MDP object class types to which the object parameters of the function must belong. The isTrue method defines the function. Since the PropositionalFunction class defines the function, it is useful to have an object that specifies a certain set of parameters on which you can evaluate the function. The GroundedProp class provides that; it is a pair that references a PropositionalFunction and the parameters (names of objects in an OO-MDP state) on which to evaluate the function. It also has a shortcut method, isTrue, that will return the result of the PropositionalFunction isTrue method given the GroundedProp parameters. The PropositionalFunction class also includes the method allGroundings that given a state, will determine all possible parameter assignments on which the PropositionalFunction can be evaluated (given its function signature) and returns the possible assignments as a list of GroundedProp objects. Similarly, there is a static method, allGorundingsFromList, which will take a list of PropositionalFunction objects and return the concatenated list of GroundedProp objects that results from applying the allGroundings method on each of them. Finally, Propositional functions can also have special signature information, called parameter order groups, specified. This is advanced functionality that allows you to specify whether the order of certain parameters matters. For example, if we defined a proposition function for testing whether two objects were touching, then it follows that touching(ob1, ob2) = touching(ob2, ob1) and you wouldn't need to evaluate both orders of the parameter assignments. By setting both parameters to the same order group, this symmetry is defined and the allGroundings method will only return one grounding for each set of equivalent parameter assignments. By default, the parameter order groups are all set to be different for each parameter; that is, by default, it is assumed that different orderings of parameters can affect the result of the function. OO-MDP Domains Finally, OODomain is a special domain interface for OO-MDP domains, with OOSADomain being a concrete implementation of it for single agent domains (and it accordingly also extends SADomain). OODomain implementations should contain the set of PropositionalFunctons for the domain and also provide a method for getting the Java class that is used to define a specific OO-MDP object class (that is, a map from the String name of an OO-MDP object class to the ObjectInstance Java class used to define it). Object Identifier Independence One useful aspect of using OO-MDPs is the ability to use a state invariance that we call object identifier independence . To understand object identifier independence, consider the following scenario where we have a domain made up of block objects. Each block resides in some location on a 2D grid. Suppose the environment state consists of two blocks identified as block0 and block1 that are otherwise identical, but in different positions. Now suppose an action was taken that swapped the locations of the blocks, as shown in the below figure. Figure: Swapping the location of two blocks The question is, is the state before the swap and after the swap the same? The only thing that is different is the identifier we use to refer to the blocks at each location. If we used a more standard representation where states were defined by different state variables for each block, these states would be treated differently. But in practice, the difference in these states might not matter. In fact, if the transition dynamics and reward function are independent of the identifier of the blocks, then in fact we don't want to treat these states as different. By exploiting the structure of the OO-MDP representation, we can provide this desired invariance where these two states are treated as the same, thereby decreasing the size of the state space that must be examined by a planning or learning algorithm. In BURLAP, tabular planning and learning methods rely on a method to hash states and test equality that is provided by a HashableStateFactory implementation. The concrete provided SimpleHashableStateFactory , and its derivatives, will automatically perform the necessary work to provide this kind of identifier independent state invariance for states that implement the OOState interface. However, if it turns out that your reward function or transition dynamics do depend on object identifiers, then you can optionally set the SimpleHashableStateFactory and its derivatives to not perform the invariance. Next Part", "http://burlap.cs.brown.edu/tutorials/oomdp/p2.html": "` Building a Domain MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}}); BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building an OO-MDP Domain Tutorials > Building an OO-MDP Domain > Part 2 Tutorial Contents Introduction Java Interfaces for OO-MDPs Object Identifier Independence Grid World OO-MDP States Grid World OO-MDP Model OO-MDP Visualization Testing it Out Conclusion Final Code Previous Part | Next Part Grid World OO-MDP States In the remaining sections, we will be reimplementing our previous Grid World from the Building a Domain tutorial as an OO-MDP. Much of the code will remain the same, so in this tutorial, we will assume you are familiar with the work in the previous tutorial, and just describe the aspects that we've changed. Lets start by creating an OO-MDP Grid World DomainGenerator that will hold constants and generate our domain. Lets call this class ExampleOOGridWorld. import burlap.mdp.auxiliary.DomainGenerator;import burlap.mdp.auxiliary.common.SinglePFTF;import burlap.mdp.core.StateTransitionProb;import burlap.mdp.core.TerminalFunction;import burlap.mdp.core.action.Action;import burlap.mdp.core.action.UniversalActionType;import burlap.mdp.core.oo.OODomain;import burlap.mdp.core.oo.propositional.PropositionalFunction;import burlap.mdp.core.oo.state.OOState;import burlap.mdp.core.oo.state.ObjectInstance;import burlap.mdp.core.oo.state.generic.GenericOOState;import burlap.mdp.core.state.State;import burlap.mdp.singleagent.common.SingleGoalPFRF;import burlap.mdp.singleagent.environment.SimulatedEnvironment;import burlap.mdp.singleagent.model.FactoredModel;import burlap.mdp.singleagent.model.RewardFunction;import burlap.mdp.singleagent.model.statemodel.FullStateModel;import burlap.mdp.singleagent.oo.OOSADomain;import burlap.shell.visual.VisualExplorer;import burlap.visualizer.*;import java.awt.*;import java.awt.geom.Ellipse2D;import java.awt.geom.Rectangle2D;import java.util.ArrayList;import java.util.Arrays;import java.util.List;public class ExampleOOGridWorld implements DomainGenerator{public static final String VAR_X = \"x\";public static final String VAR_Y = \"y\";public static final String VAR_TYPE = \"type\";public static final String CLASS_AGENT = \"agent\";public static final String CLASS_LOCATION = \"location\";public static final String ACTION_NORTH = \"north\";public static final String ACTION_SOUTH = \"south\";public static final String ACTION_EAST = \"east\";public static final String ACTION_WEST = \"west\";public static final String PF_AT = \"at\";//ordered so first dimension is xprotected int [][] map = new int[][]{{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,0,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{1,0,1,1,1,1,1,1,0,1,1},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,0,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},};@Overridepublic OOSADomain generateDomain() {//we'll fill this in later}} Lets now implement our Grid World State as an OO-MDP. Previously, we had a single ExGridState that we implemented. In our OO-MDP, we will define the OO-MDP to consist of an \"agent\" object, and any number of \"location\" objects that we'll use to mark places of interest. Our agent object will look much like our previous ExGridState class that tracks an x and y location. Create the below file for our agent object, named ExGridAgent. import burlap.mdp.core.oo.state.ObjectInstance;import burlap.mdp.core.state.MutableState;import burlap.mdp.core.state.StateUtilities;import burlap.mdp.core.state.UnknownKeyException;import burlap.mdp.core.state.annotations.DeepCopyState;import java.util.Arrays;import java.util.List;import static edu.brown.cs.burlap.tutorials.domain.oo.ExampleOOGridWorld.CLASS_AGENT;import static edu.brown.cs.burlap.tutorials.domain.oo.ExampleOOGridWorld.VAR_X;import static edu.brown.cs.burlap.tutorials.domain.oo.ExampleOOGridWorld.VAR_Y;@DeepCopyStatepublic class ExGridAgent implements ObjectInstance, MutableState {public int x;public int y;public String name = \"agent\";private final static List<Object> keys = Arrays.<Object>asList(VAR_X, VAR_Y);public ExGridAgent() {}public ExGridAgent(int x, int y) {this.x = x;this.y = y;}public ExGridAgent(int x, int y, String name) {this.x = x;this.y = y;this.name = name;}@Overridepublic String className() {return CLASS_AGENT;}@Overridepublic String name() {return name;}@Overridepublic ObjectInstance copyWithName(String objectName) {return new ExGridAgent(x, y, objectName);}@Overridepublic MutableState set(Object variableKey, Object value) {if(variableKey.equals(VAR_X)){this.x = StateUtilities.stringOrNumber(value).intValue();}else if(variableKey.equals(VAR_Y)){this.y = StateUtilities.stringOrNumber(value).intValue();}else{throw new UnknownKeyException(variableKey);}return this;}@Overridepublic List<Object> variableKeys() {return keys;}@Overridepublic Object get(Object variableKey) {if(variableKey.equals(VAR_X)){return x;}else if(variableKey.equals(VAR_Y)){return y;}throw new UnknownKeyException(variableKey);}@Overridepublic ExGridAgent copy() {return new ExGridAgent(x, y, name);}@Overridepublic String toString() {return StateUtilities.stateToString(this);}} The first change to notice from our ExGridState is that in addition to implementing MutableState, we also implement ObjectInstance to declare this an OO-MDP object that makes up an OO-MDP state. We also added a data member, name, to track this object's name, which we default to the value \"agent\". The className method simply returns the class name constant we defined in our domain generator; the name method returns the name data member for this object; and the copyWithName method returns a new instance of the object with the same x and y values, and the new name. Otherwise the rest is the same as our previous ExGridState! Now lets define a ObjectInstance for locations. Our location object will also be marked by an x and y position, as well as a type, so that we could have locations of different types. To implement this class, we will simply extend our ExGridAgent, add a type data type, and modify the methods to return a different class, handle the new type key, and return copies of the ExGridLocation instance instead of ExGridAgent in the copy methods. import burlap.mdp.core.oo.state.ObjectInstance;import burlap.mdp.core.state.MutableState;import burlap.mdp.core.state.StateUtilities;import java.util.Arrays;import java.util.List;import static edu.brown.cs.burlap.tutorials.domain.oo.ExampleOOGridWorld.*;public class EXGridLocation extends ExGridAgent{public int type;private final static List<Object> keys = Arrays.<Object>asList(VAR_X, VAR_Y, VAR_TYPE);public EXGridLocation() {}public EXGridLocation(int x, int y, String name) {super(x, y, name);}public EXGridLocation(int x, int y, int type, String name) {super(x, y, name);this.type = type;}@Overridepublic List<Object> variableKeys() {return keys;}@Overridepublic Object get(Object variableKey) {if(variableKey.equals(VAR_TYPE)){return this.type;}return super.get(variableKey);}@Overridepublic MutableState set(Object variableKey, Object value) {if(variableKey.equals(VAR_TYPE)){this.type = StateUtilities.stringOrNumber(value).intValue();}else{super.set(variableKey, value);}return this;}@Overridepublic String className() {return CLASS_LOCATION;}@Overridepublic ObjectInstance copyWithName(String objectName) {return new EXGridLocation(x, y, type, objectName);}@Overridepublic EXGridLocation copy() {return new EXGridLocation(x, y, type, name);}} So far we've defined the ObjectInstances for our State, but we haven't define the OOState that will be made up of these ObjectInstances. However, for this tutorial we will be making use of BURLAP's provided GenericOOState implementation, so at this point we're done with the explicit state definition code. However, we will now add a propositional function to our domain that evaluates whether the agent object is at a location, indicated by their x and y location being the same. Add the following code to the ExampleOOGridWorld class. protected class AtLocation extends PropositionalFunction {public AtLocation(){super(PF_AT, new String []{CLASS_AGENT, CLASS_LOCATION});}@Overridepublic boolean isTrue(OOState s, String... params) {ObjectInstance agent = s.object(params[0]);ObjectInstance location = s.object(params[1]);int ax = (Integer)agent.get(VAR_X);int ay = (Integer)agent.get(VAR_Y);int lx = (Integer)location.get(VAR_X);int ly = (Integer)location.get(VAR_Y);return ax == lx && ay == ly;}} The constructor we added calls the super constructor that will define the PropositionalFunction's signature: that is, its name (the PF_AT constant), and OO-MDP classes to which its parameters must belong. In this case, our \"at\" propositional function will operate on an agent object and a location object, so we provided parameters with those types. The isTrue method takes as input a OOState to evaluate, and the names of the objects on which to evaluate the function in the variable length String argument params. The first step is to get the agent and location ObjectInstances from the state for the parameters provided to function. Because we defined the function to operate on two parameters, an agent and then a location, we know the params argument passed to the isTrue method has two elements. Then we get the agent and location ObjectInstance by by using the OOState method object on the first and second elements of the params argument. Next, we get the x and y values for each of the objects using the standard State get method, and then check if the agent and location positions are equal to determine whether the agent is at the location. Lets also add a method to our ExampleOOGridWorld class to generate a list of all our propositional functions. In this case we only have one, but this is often a useful method to include. public List<PropositionalFunction> generatePfs(){return Arrays.<PropositionalFunction>asList(new AtLocation());} We are now finished defining the OO-MDP state information and next will implement the grid world model. Next Part", "http://burlap.cs.brown.edu/tutorials/oomdp/p3.html": "` Building a Domain MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}}); BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building an OO-MDP Domain Tutorials > Building an OO-MDP Domain > Part 3 Tutorial Contents Introduction Markov Decision Process Java Interfaces for MDP Definitions Defining a Grid World State Grid World OO-MDP Model Creating a State Visualizer Testing it Out Conclusion Final Code Previous Part | Next Part Grid World OO-MDP Model Lets now implement our OO-MDP grid world model. Once again, we will basically have the same FactoredModel implementation for state transitions that we implemented in the Building a Domain tutorial, except with slight modifications to work with state that is a GenericOOState . Add the following code to your ExampleOOGridWorld class. protected class OOGridWorldStateModel implements FullStateModel {protected double [][] transitionProbs;public OOGridWorldStateModel() {this.transitionProbs = new double[4][4];for(int i = 0; i < 4; i++){for(int j = 0; j < 4; j++){double p = i != j ? 0.2/3 : 0.8;transitionProbs[i][j] = p;}}}public List<StateTransitionProb> stateTransitions(State s, Action a) {//get agent current positionGenericOOState gs = (GenericOOState)s;ExGridAgent agent = (ExGridAgent)gs.object(CLASS_AGENT);int curX = agent.x;int curY = agent.y;int adir = actionDir(a);List<StateTransitionProb> tps = new ArrayList<StateTransitionProb>(4);StateTransitionProb noChange = null;for(int i = 0; i < 4; i++){int [] newPos = this.moveResult(curX, curY, i);if(newPos[0] != curX || newPos[1] != curY){//new possible outcomeGenericOOState ns = gs.copy();ExGridAgent nagent = (ExGridAgent)ns.touch(CLASS_AGENT);nagent.x = newPos[0];nagent.y = newPos[1];//create transition probability object and add to our list of outcomestps.add(new StateTransitionProb(ns, this.transitionProbs[adir][i]));}else{//this direction didn't lead anywhere new//if there are existing possible directions//that wouldn't lead anywhere, aggregate with themif(noChange != null){noChange.p += this.transitionProbs[adir][i];}else{//otherwise create this new state and transitionnoChange = new StateTransitionProb(s.copy(), this.transitionProbs[adir][i]);tps.add(noChange);}}}return tps;}public State sample(State s, Action a) {s = s.copy();GenericOOState gs = (GenericOOState)s;ExGridAgent agent = (ExGridAgent)gs.touch(CLASS_AGENT);int curX = agent.x;int curY = agent.y;int adir = actionDir(a);//sample direction with random rolldouble r = Math.random();double sumProb = 0.;int dir = 0;for(int i = 0; i < 4; i++){sumProb += this.transitionProbs[adir][i];if(r < sumProb){dir = i;break; //found direction}}//get resulting positionint [] newPos = this.moveResult(curX, curY, dir);//set the new positionagent.x = newPos[0];agent.y = newPos[1];//return the state we just modifiedreturn gs;}protected int actionDir(Action a){int adir = -1;if(a.actionName().equals(ACTION_NORTH)){adir = 0;}else if(a.actionName().equals(ACTION_SOUTH)){adir = 1;}else if(a.actionName().equals(ACTION_EAST)){adir = 2;}else if(a.actionName().equals(ACTION_WEST)){adir = 3;}return adir;}protected int [] moveResult(int curX, int curY, int direction){//first get change in x and y from direction using 0: north; 1: south; 2:east; 3: westint xdelta = 0;int ydelta = 0;if(direction == 0){ydelta = 1;}else if(direction == 1){ydelta = -1;}else if(direction == 2){xdelta = 1;}else{xdelta = -1;}int nx = curX + xdelta;int ny = curY + ydelta;int width = ExampleOOGridWorld.this.map.length;int height = ExampleOOGridWorld.this.map[0].length;//make sure new position is valid (not a wall or off bounds)if(nx < 0 || nx >= width || ny < 0 || ny >= height ||ExampleOOGridWorld.this.map[nx][ny] == 1){nx = curX;ny = curY;}return new int[]{nx,ny};}} The first main difference form our Building a Domain tutorial implementation to note is that we cast our state to a GenericOOState . Then, to get the agent x and y, we pull out the ExGridAgent object. We assume that our agent objects always have the same name as the agent class defined by the CLASS_AGENT constant. When we make a copy of states and modify the x and y value of the agent, note that we get the agent object through the touch method, which is a special method defined for GenericOOState. Recall that GenericOOState uses shallow copying; whenever a copy is made, the new state contains the same references to the ObjectInstances Java objects as the ancestor state; that is, the ObjectInstances are not copied themselves (thereby saving on memory overhead). The touch method returns the object with the given name, but first causes the state to changes its reference to a copy of that ObjectInstance. As a result, any changes to an ObjectInsance returned by the touch method will not contaminate the values of the object in the previous state from which the new state was copied. Lets now implement our generateDomain method. @Overridepublic OOSADomain generateDomain() {OOSADomain domain = new OOSADomain();domain.addStateClass(CLASS_AGENT, ExGridAgent.class).addStateClass(CLASS_LOCATION, EXGridLocation.class);domain.addActionTypes(new UniversalActionType(ACTION_NORTH),new UniversalActionType(ACTION_SOUTH),new UniversalActionType(ACTION_EAST),new UniversalActionType(ACTION_WEST));OODomain.Helper.addPfsToDomain(domain, this.generatePfs());OOGridWorldStateModel smodel = new OOGridWorldStateModel();RewardFunction rf = this.rf;TerminalFunction tf = this.tf;if(rf == null){rf = new SingleGoalPFRF(domain.propFunction(PF_AT), 100, -1);;}if(tf == null){tf = new SinglePFTF(domain.propFunction(PF_AT));}domain.setModel(new FactoredModel(smodel, rf, tf));return domain;} First note that unlike the Building a Domain tutorial, we have our domain be an instance of OOSADomain. One of the pieces of information an OOSADomain tracks is a mapping from the name of an OO-MDP class to the Java class that defines it, so in this case we set the map from the CLASS_AGENT string constant to our ExGridAgent class, and the CLASS_LOCATION constant to the EXGridLocation class. We also add to our OOSADomain the propositional function that we created. We also construct the reward function and terminal function, differently than we did in the Building a Domain tutorial. Rather than have a custom reward function and terminal function, we make use of our propositional function. The SingleGoalPFRF reward function provided with BURLAP takes as input a propositional function, a goal reward, and default reward. It returns the goal reward whenever any parameter assignment satisfies the propositional function in the state to which the agent transitions and otherwise returns the default reward. The SinglePFTF function takes a propositional function and similarly classifies terminal states as any state for which there exists a parameter assignment that causes the propositional function to be true. Since we've provided these objects our \"at\" propositional function, it means a goal terminal state is any state in which an agent is at a location. OO-MDP Visualization To visualize states of an OO-MDP, we could implement state StatePainter instances, just like we did for a regular MDP. However, BURLAP also provides some additional tools for rendering OO-MDP states. Specifically, BURLAP provides an OOStatePainter that takes as input a set of ObjectPainters that are tasked with painting objects from the OO-MDP state, allowing you to define a different painter for different object classes. To demonstrate, lets implement visualization of our domain by creating a wall painter, just like the one in the previous domain, and then an ObjectPainter for the agent class and an ObjectPainter for the location class. public class WallPainter implements StatePainter {public void paint(Graphics2D g2, State s, float cWidth, float cHeight) {//walls will be filled in blackg2.setColor(Color.BLACK);//set up floats for the width and height of our domainfloat fWidth = ExampleOOGridWorld.this.map.length;float fHeight = ExampleOOGridWorld.this.map[0].length;//determine the width of a single cell//on our canvas such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;//pass through each cell of our map and if it's a wall, paint a black rectangle on our//cavas of dimension widthxheightfor(int i = 0; i < ExampleOOGridWorld.this.map.length; i++){for(int j = 0; j < ExampleOOGridWorld.this.map[0].length; j++){//is there a wall here?if(ExampleOOGridWorld.this.map[i][j] == 1){//left coordinate of cell on our canvasfloat rx = i*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas//origin is in the top left instead of the bottom rightfloat ry = cHeight - height - j*height;//paint the rectangleg2.fill(new Rectangle2D.Float(rx, ry, width, height));}}}}}public class AgentPainter implements ObjectPainter {@Overridepublic void paintObject(Graphics2D g2, OOState s, ObjectInstance ob,float cWidth, float cHeight) {//agent will be filled in grayg2.setColor(Color.GRAY);//set up floats for the width and height of our domainfloat fWidth = ExampleOOGridWorld.this.map.length;float fHeight = ExampleOOGridWorld.this.map[0].length;//determine the width of a single cell on our canvas//such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;int ax = (Integer)ob.get(VAR_X);int ay = (Integer)ob.get(VAR_Y);//left coordinate of cell on our canvasfloat rx = ax*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas//origin is in the top left instead of the bottom rightfloat ry = cHeight - height - ay*height;//paint the rectangleg2.fill(new Ellipse2D.Float(rx, ry, width, height));}}public class LocationPainter implements ObjectPainter {@Overridepublic void paintObject(Graphics2D g2, OOState s, ObjectInstance ob,float cWidth, float cHeight) {//agent will be filled in blueg2.setColor(Color.BLUE);//set up floats for the width and height of our domainfloat fWidth = ExampleOOGridWorld.this.map.length;float fHeight = ExampleOOGridWorld.this.map[0].length;//determine the width of a single cell on our canvas//such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;int ax = (Integer)ob.get(VAR_X);int ay = (Integer)ob.get(VAR_Y);//left coordinate of cell on our canvasfloat rx = ax*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas//origin is in the top left instead of the bottom rightfloat ry = cHeight - height - ay*height;//paint the rectangleg2.fill(new Rectangle2D.Float(rx, ry, width, height));}} Note that the ObjectPainter paintObject method not only receives the OOState for which painting should be performed, but the specific ObjectInstance from that state it is being asked to paint. For the AgentPainter, we will draw a gray circle, just like we did in the Building a Domain tutorial for the ExGridState. For the location painter, we'll do something similar, but instead paint a blue rectangle wherever the input location object is positioned. Lets now add methods to package up a Visualizer for our domain. public Visualizer getVisualizer(){return new Visualizer(this.getStateRenderLayer());}public StateRenderLayer getStateRenderLayer(){StateRenderLayer rl = new StateRenderLayer();rl.addStatePainter(new ExampleOOGridWorld.WallPainter());OOStatePainter ooStatePainter = new OOStatePainter();ooStatePainter.addObjectClassPainter(CLASS_LOCATION, new LocationPainter());ooStatePainter.addObjectClassPainter(CLASS_AGENT, new AgentPainter());rl.addStatePainter(ooStatePainter);return rl;} Note that this time we created a OOStatePainter and assigned it a LocationPainter instance for painting objects of class CLASS_LOCATION, and an AgentPainter for objects of class CLASS_AGENT. We provided it the location painter first, because the OOStatePainter will paint objects in the order that the ObjectPainters are provided to it. By having locations painted before the agent, it will cause the agent to be painted on top of the blue rectangle when the agent enters the same cell as the location. Testing it Out Lets now write some code to test our OO-MDP grid world out by adding a main method. public static void main(String [] args){ExampleOOGridWorld gen = new ExampleOOGridWorld();OOSADomain domain = gen.generateDomain();State initialState = new GenericOOState(new ExGridAgent(0, 0), new EXGridLocation(10, 10, \"loc0\"));SimulatedEnvironment env = new SimulatedEnvironment(domain, initialState);Visualizer v = gen.getVisualizer();VisualExplorer exp = new VisualExplorer(domain, env, v);exp.addKeyAction(\"w\", ACTION_NORTH, \"\");exp.addKeyAction(\"s\", ACTION_SOUTH, \"\");exp.addKeyAction(\"d\", ACTION_EAST, \"\");exp.addKeyAction(\"a\", ACTION_WEST, \"\");exp.initGUI();} This main method looks pretty similar to the one in the Building a Domain tutorial, but this time our state is a GenericOOState and we construct it with an ExGridAgent object, (started in position 0,0), and a single ExGridLocation object (named \"loc0\" and positioned at 10,10). If you now run the main method, you should get a visual explorer that shows the agent and the location of our location object, just like in the image below. Figure: A VisualExplorer for our OO-MDP Grid World. Next Part", "http://burlap.cs.brown.edu/tutorials/oomdp/p4.html": "` Building a Domain MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}}); BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building an OO-MDP Domain Tutorials > Building an OO-MDP Domain > Part 4 Tutorial Contents Introduction Markov Decision Process Java Interfaces for MDP Definitions Defining a Grid World State Grid World OO-MDP Model Creating a State Visualizer Testing it Out Conclusion Final Code Previous Part Conclusion We've now walked you through what an OO-MDP is and how to make your OO-MDP domains using our previous MDP Grid World example from our Building a Domain tutorial as a starting point. We also showed you how to make use of the OO-MDP visualization tools. All of the code from this tutorial is included below and as always can also be found in the burlap_examples repository. Final Code ExGridAgent.java import burlap.mdp.core.oo.state.ObjectInstance;import burlap.mdp.core.state.MutableState;import burlap.mdp.core.state.StateUtilities;import burlap.mdp.core.state.UnknownKeyException;import burlap.mdp.core.state.annotations.DeepCopyState;import java.util.Arrays;import java.util.List;import static edu.brown.cs.burlap.tutorials.domain.oo.ExampleOOGridWorld.CLASS_AGENT;import static edu.brown.cs.burlap.tutorials.domain.oo.ExampleOOGridWorld.VAR_X;import static edu.brown.cs.burlap.tutorials.domain.oo.ExampleOOGridWorld.VAR_Y;@DeepCopyStatepublic class ExGridAgent implements ObjectInstance, MutableState {public int x;public int y;public String name = \"agent\";private final static List<Object> keys = Arrays.<Object>asList(VAR_X, VAR_Y);public ExGridAgent() {}public ExGridAgent(int x, int y) {this.x = x;this.y = y;}public ExGridAgent(int x, int y, String name) {this.x = x;this.y = y;this.name = name;}@Overridepublic String className() {return CLASS_AGENT;}@Overridepublic String name() {return name;}@Overridepublic ObjectInstance copyWithName(String objectName) {return new ExGridAgent(x, y, objectName);}@Overridepublic MutableState set(Object variableKey, Object value) {if(variableKey.equals(VAR_X)){this.x = StateUtilities.stringOrNumber(value).intValue();}else if(variableKey.equals(VAR_Y)){this.y = StateUtilities.stringOrNumber(value).intValue();}else{throw new UnknownKeyException(variableKey);}return this;}@Overridepublic List<Object> variableKeys() {return keys;}@Overridepublic Object get(Object variableKey) {if(variableKey.equals(VAR_X)){return x;}else if(variableKey.equals(VAR_Y)){return y;}throw new UnknownKeyException(variableKey);}@Overridepublic ExGridAgent copy() {return new ExGridAgent(x, y, name);}@Overridepublic String toString() {return StateUtilities.stateToString(this);}} ExGridLocation.java import burlap.mdp.core.oo.state.ObjectInstance;import burlap.mdp.core.state.MutableState;import burlap.mdp.core.state.StateUtilities;import java.util.Arrays;import java.util.List;import static edu.brown.cs.burlap.tutorials.domain.oo.ExampleOOGridWorld.*;public class EXGridLocation extends ExGridAgent{public int type;private final static List<Object> keys = Arrays.<Object>asList(VAR_X, VAR_Y, VAR_TYPE);public EXGridLocation() {}public EXGridLocation(int x, int y, String name) {super(x, y, name);}public EXGridLocation(int x, int y, int type, String name) {super(x, y, name);this.type = type;}@Overridepublic List<Object> variableKeys() {return keys;}@Overridepublic Object get(Object variableKey) {if(variableKey.equals(VAR_TYPE)){return this.type;}return super.get(variableKey);}@Overridepublic MutableState set(Object variableKey, Object value) {if(variableKey.equals(VAR_TYPE)){this.type = StateUtilities.stringOrNumber(value).intValue();}else{super.set(variableKey, value);}return this;}@Overridepublic String className() {return CLASS_LOCATION;}@Overridepublic ObjectInstance copyWithName(String objectName) {return new EXGridLocation(x, y, type, objectName);}@Overridepublic EXGridLocation copy() {return new EXGridLocation(x, y, type, name);}} ExampleOOGridWorld.java import burlap.mdp.auxiliary.DomainGenerator;import burlap.mdp.auxiliary.common.SinglePFTF;import burlap.mdp.core.StateTransitionProb;import burlap.mdp.core.TerminalFunction;import burlap.mdp.core.action.Action;import burlap.mdp.core.action.UniversalActionType;import burlap.mdp.core.oo.OODomain;import burlap.mdp.core.oo.propositional.PropositionalFunction;import burlap.mdp.core.oo.state.OOState;import burlap.mdp.core.oo.state.ObjectInstance;import burlap.mdp.core.oo.state.generic.GenericOOState;import burlap.mdp.core.state.State;import burlap.mdp.singleagent.common.SingleGoalPFRF;import burlap.mdp.singleagent.environment.SimulatedEnvironment;import burlap.mdp.singleagent.model.FactoredModel;import burlap.mdp.singleagent.model.RewardFunction;import burlap.mdp.singleagent.model.statemodel.FullStateModel;import burlap.mdp.singleagent.oo.OOSADomain;import burlap.shell.visual.VisualExplorer;import burlap.visualizer.*;import java.awt.*;import java.awt.geom.Ellipse2D;import java.awt.geom.Rectangle2D;import java.util.ArrayList;import java.util.Arrays;import java.util.List;public class ExampleOOGridWorld implements DomainGenerator{public static final String VAR_X = \"x\";public static final String VAR_Y = \"y\";public static final String VAR_TYPE = \"type\";public static final String CLASS_AGENT = \"agent\";public static final String CLASS_LOCATION = \"location\";public static final String ACTION_NORTH = \"north\";public static final String ACTION_SOUTH = \"south\";public static final String ACTION_EAST = \"east\";public static final String ACTION_WEST = \"west\";public static final String PF_AT = \"at\";//ordered so first dimension is xprotected int [][] map = new int[][]{{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,0,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{1,0,1,1,1,1,1,1,0,1,1},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,0,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},};public List<PropositionalFunction> generatePfs(){return Arrays.<PropositionalFunction>asList(new AtLocation());}@Overridepublic OOSADomain generateDomain() {OOSADomain domain = new OOSADomain();domain.addStateClass(CLASS_AGENT, ExGridAgent.class).addStateClass(CLASS_LOCATION, EXGridLocation.class);domain.addActionTypes(new UniversalActionType(ACTION_NORTH),new UniversalActionType(ACTION_SOUTH),new UniversalActionType(ACTION_EAST),new UniversalActionType(ACTION_WEST));OODomain.Helper.addPfsToDomain(domain, this.generatePfs());OOGridWorldStateModel smodel = new OOGridWorldStateModel();RewardFunction rf = new SingleGoalPFRF(domain.propFunction(PF_AT), 100, -1);TerminalFunction tf = new SinglePFTF(domain.propFunction(PF_AT));domain.setModel(new FactoredModel(smodel, rf, tf));return domain;}protected class OOGridWorldStateModel implements FullStateModel {protected double [][] transitionProbs;public OOGridWorldStateModel() {this.transitionProbs = new double[4][4];for(int i = 0; i < 4; i++){for(int j = 0; j < 4; j++){double p = i != j ? 0.2/3 : 0.8;transitionProbs[i][j] = p;}}}public List<StateTransitionProb> stateTransitions(State s, Action a) {//get agent current positionGenericOOState gs = (GenericOOState)s;ExGridAgent agent = (ExGridAgent)gs.object(CLASS_AGENT);int curX = agent.x;int curY = agent.y;int adir = actionDir(a);List<StateTransitionProb> tps = new ArrayList<StateTransitionProb>(4);StateTransitionProb noChange = null;for(int i = 0; i < 4; i++){int [] newPos = this.moveResult(curX, curY, i);if(newPos[0] != curX || newPos[1] != curY){//new possible outcomeGenericOOState ns = gs.copy();ExGridAgent nagent = (ExGridAgent)ns.touch(CLASS_AGENT);nagent.x = newPos[0];nagent.y = newPos[1];//create transition probability object and add to our list of outcomestps.add(new StateTransitionProb(ns, this.transitionProbs[adir][i]));}else{//this direction didn't lead anywhere new//if there are existing possible directions//that wouldn't lead anywhere, aggregate with themif(noChange != null){noChange.p += this.transitionProbs[adir][i];}else{//otherwise create this new state and transitionnoChange = new StateTransitionProb(s.copy(), this.transitionProbs[adir][i]);tps.add(noChange);}}}return tps;}public State sample(State s, Action a) {s = s.copy();GenericOOState gs = (GenericOOState)s;ExGridAgent agent = (ExGridAgent)gs.touch(CLASS_AGENT);int curX = agent.x;int curY = agent.y;int adir = actionDir(a);//sample direction with random rolldouble r = Math.random();double sumProb = 0.;int dir = 0;for(int i = 0; i < 4; i++){sumProb += this.transitionProbs[adir][i];if(r < sumProb){dir = i;break; //found direction}}//get resulting positionint [] newPos = this.moveResult(curX, curY, dir);//set the new positionagent.x = newPos[0];agent.y = newPos[1];//return the state we just modifiedreturn gs;}protected int actionDir(Action a){int adir = -1;if(a.actionName().equals(ACTION_NORTH)){adir = 0;}else if(a.actionName().equals(ACTION_SOUTH)){adir = 1;}else if(a.actionName().equals(ACTION_EAST)){adir = 2;}else if(a.actionName().equals(ACTION_WEST)){adir = 3;}return adir;}protected int [] moveResult(int curX, int curY, int direction){//first get change in x and y from direction using 0: north; 1: south; 2:east; 3: westint xdelta = 0;int ydelta = 0;if(direction == 0){ydelta = 1;}else if(direction == 1){ydelta = -1;}else if(direction == 2){xdelta = 1;}else{xdelta = -1;}int nx = curX + xdelta;int ny = curY + ydelta;int width = ExampleOOGridWorld.this.map.length;int height = ExampleOOGridWorld.this.map[0].length;//make sure new position is valid (not a wall or off bounds)if(nx < 0 || nx >= width || ny < 0 || ny >= height ||ExampleOOGridWorld.this.map[nx][ny] == 1){nx = curX;ny = curY;}return new int[]{nx,ny};}}public Visualizer getVisualizer(){return new Visualizer(this.getStateRenderLayer());}public StateRenderLayer getStateRenderLayer(){StateRenderLayer rl = new StateRenderLayer();rl.addStatePainter(new ExampleOOGridWorld.WallPainter());OOStatePainter ooStatePainter = new OOStatePainter();ooStatePainter.addObjectClassPainter(CLASS_LOCATION, new LocationPainter());ooStatePainter.addObjectClassPainter(CLASS_AGENT, new AgentPainter());rl.addStatePainter(ooStatePainter);return rl;}protected class AtLocation extends PropositionalFunction {public AtLocation(){super(PF_AT, new String []{CLASS_AGENT, CLASS_LOCATION});}@Overridepublic boolean isTrue(OOState s, String... params) {ObjectInstance agent = s.object(params[0]);ObjectInstance location = s.object(params[1]);int ax = (Integer)agent.get(VAR_X);int ay = (Integer)agent.get(VAR_Y);int lx = (Integer)location.get(VAR_X);int ly = (Integer)location.get(VAR_Y);return ax == lx && ay == ly;}}public class WallPainter implements StatePainter {public void paint(Graphics2D g2, State s, float cWidth, float cHeight) {//walls will be filled in blackg2.setColor(Color.BLACK);//set up floats for the width and height of our domainfloat fWidth = ExampleOOGridWorld.this.map.length;float fHeight = ExampleOOGridWorld.this.map[0].length;//determine the width of a single cell//on our canvas such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;//pass through each cell of our map and if it's a wall, paint a black rectangle on our//cavas of dimension widthxheightfor(int i = 0; i < ExampleOOGridWorld.this.map.length; i++){for(int j = 0; j < ExampleOOGridWorld.this.map[0].length; j++){//is there a wall here?if(ExampleOOGridWorld.this.map[i][j] == 1){//left coordinate of cell on our canvasfloat rx = i*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas//origin is in the top left instead of the bottom rightfloat ry = cHeight - height - j*height;//paint the rectangleg2.fill(new Rectangle2D.Float(rx, ry, width, height));}}}}}public class AgentPainter implements ObjectPainter {@Overridepublic void paintObject(Graphics2D g2, OOState s, ObjectInstance ob,float cWidth, float cHeight) {//agent will be filled in grayg2.setColor(Color.GRAY);//set up floats for the width and height of our domainfloat fWidth = ExampleOOGridWorld.this.map.length;float fHeight = ExampleOOGridWorld.this.map[0].length;//determine the width of a single cell on our canvas//such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;int ax = (Integer)ob.get(VAR_X);int ay = (Integer)ob.get(VAR_Y);//left coordinate of cell on our canvasfloat rx = ax*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas//origin is in the top left instead of the bottom rightfloat ry = cHeight - height - ay*height;//paint the rectangleg2.fill(new Ellipse2D.Float(rx, ry, width, height));}}public class LocationPainter implements ObjectPainter {@Overridepublic void paintObject(Graphics2D g2, OOState s, ObjectInstance ob,float cWidth, float cHeight) {//agent will be filled in blueg2.setColor(Color.BLUE);//set up floats for the width and height of our domainfloat fWidth = ExampleOOGridWorld.this.map.length;float fHeight = ExampleOOGridWorld.this.map[0].length;//determine the width of a single cell on our canvas//such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;int ax = (Integer)ob.get(VAR_X);int ay = (Integer)ob.get(VAR_Y);//left coordinate of cell on our canvasfloat rx = ax*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas//origin is in the top left instead of the bottom rightfloat ry = cHeight - height - ay*height;//paint the rectangleg2.fill(new Rectangle2D.Float(rx, ry, width, height));}}public static void main(String [] args){ExampleOOGridWorld gen = new ExampleOOGridWorld();OOSADomain domain = gen.generateDomain();State initialState = new GenericOOState(new ExGridAgent(0, 0), new EXGridLocation(10, 10, \"loc0\"));SimulatedEnvironment env = new SimulatedEnvironment(domain, initialState);Visualizer v = gen.getVisualizer();VisualExplorer exp = new VisualExplorer(domain, env, v);exp.addKeyAction(\"w\", ACTION_NORTH, \"\");exp.addKeyAction(\"s\", ACTION_SOUTH, \"\");exp.addKeyAction(\"d\", ACTION_EAST, \"\");exp.addKeyAction(\"a\", ACTION_WEST, \"\");exp.initGUI();}} End.", "http://burlap.cs.brown.edu/tutorials/scd/p1.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Solving Continuous Domains Tutorials > Solving Continuous Domains > Part 1 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA(\u03bb) Conclusions Final Code Next Part You are viewing the tutorial for BURLAP 3; if you'd like the BURLAP 2 tutorial, go here . Introduction In the Basic Planning and Learning tutorial we walked through how to use a number of different planning and learning algorithms. However, all the algorithms we covered were exclusively for finite state planning/learning problems and it is not uncommon in real world problems to have to deal with an infinite or continuous state space. Continuous state problems are challenging because there is an infinite number of possible states, which means you're unlikely to ever visit the same state twice. Since many of the previous algorithms rely on being able to exhaustively enumerate the states or revisit them multiple times to estimate a value function for each state, having an infinite number of states presents a problem that requires a different set of algorithms. For example, methods that generalize the value function to unseen \"near by\" states is one approach to handling continuous state space problems. In this tutorial, we will explain how to solve continuous domains, using the example domains Mountain Car , Inverted Pendulum , and Lunar Lander , with three different algorithms implemented in BURLAP that are capable of handling continuous domains: Least-Squares Policy Iteration , Sparse Sampling , and Gradient Descent Sarsa Lambda . As usual, if you would like to see all the finished code that we will write in this tutorial, you can jump to the Final Code section at the end, or you can get it from the burlap_examples respoistory. Solving Mountain Car with Least-Squares Policy Iteration The Mountain Car domain is a classic continuous state RL domain in which an under-powered carmust drive up a steep mountain. However, because the mountain is so steep, the car cannot justaccelerate straight up to the top. Since car is in a valley, it can, however, make it to its destination by first moving backwards up the opposite slope, and then accelerate down to gain enoughmomentum to get up the intended slope. An illustration of the Mountain Car problem, courtesy of Wikipedia . To solve this problem, we will use Least-Squares Policy Iteration (LSPI). LSPI requires a collection of state-action-reward-state (SARS) transition tuples that are sampled from the domain. In some domains, like Mountain car, this data can be collected rather straight forwardly with random sampling of actions in the world. In other domains, the set of SARS data (and therefore how it is collected) is critical to getting good results out of LSPI, so it is important to keep that in mind. LSPI starts by initializing with a random policy and then uses the collected SARS samples to approximate the Q-value function of that policy for the continuous state space. Afterwards, the policy is updated by choosing actions that have the highest Q-values (this change in policy is known as policy improvement ). This process repeats until the approximate Q-value function (and consequently the policy) stops changing much. LSPI approximates the Q-value function for its current policy by fitting a linear function of state basis features to the SARS data it collected, similar to a typical regression problem, which is what enables the value function to generalize to unseen states. Choosing a good set of state basis functions that can be used to accurately represent the value function is also critical to getting good performance out of LSPI. In this tutorial, we will show you how to set up Fourier basis functions and radial basis functions , which tend to be good starting places. Lets start coding now. We'll begin by making a class shell, called ContinuousDomainTutorial. In it, we will create a different static methods that demonstrates solving each domain and algorithm in this tutorial, so we'll start with our method for solving Mountain Car with LSPI using Fourier basis functions (MCLSPIFB). As usual, we've preemptively included all imports that you'll use in the rest of this tutorial. import burlap.behavior.functionapproximation.DifferentiableStateActionValue;import burlap.behavior.functionapproximation.dense.ConcatenatedObjectFeatures;import burlap.behavior.functionapproximation.dense.DenseCrossProductFeatures;import burlap.behavior.functionapproximation.dense.NormalizedVariableFeatures;import burlap.behavior.functionapproximation.dense.NumericVariableFeatures;import burlap.behavior.functionapproximation.dense.fourier.FourierBasis;import burlap.behavior.functionapproximation.dense.rbf.DistanceMetric;import burlap.behavior.functionapproximation.dense.rbf.RBFFeatures;import burlap.behavior.functionapproximation.dense.rbf.functions.GaussianRBF;import burlap.behavior.functionapproximation.dense.rbf.metrics.EuclideanDistance;import burlap.behavior.functionapproximation.sparse.tilecoding.TileCodingFeatures;import burlap.behavior.functionapproximation.sparse.tilecoding.TilingArrangement;import burlap.behavior.policy.GreedyQPolicy;import burlap.behavior.policy.Policy;import burlap.behavior.policy.PolicyUtils;import burlap.behavior.singleagent.Episode;import burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizer;import burlap.behavior.singleagent.auxiliary.gridset.FlatStateGridder;import burlap.behavior.singleagent.learning.lspi.LSPI;import burlap.behavior.singleagent.learning.lspi.SARSCollector;import burlap.behavior.singleagent.learning.lspi.SARSData;import burlap.behavior.singleagent.learning.tdmethods.vfa.GradientDescentSarsaLam;import burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSampling;import burlap.domain.singleagent.cartpole.CartPoleVisualizer;import burlap.domain.singleagent.cartpole.InvertedPendulum;import burlap.domain.singleagent.cartpole.states.InvertedPendulumState;import burlap.domain.singleagent.lunarlander.LLVisualizer;import burlap.domain.singleagent.lunarlander.LunarLanderDomain;import burlap.domain.singleagent.lunarlander.state.LLAgent;import burlap.domain.singleagent.lunarlander.state.LLBlock;import burlap.domain.singleagent.lunarlander.state.LLState;import burlap.domain.singleagent.mountaincar.MCRandomStateGenerator;import burlap.domain.singleagent.mountaincar.MCState;import burlap.domain.singleagent.mountaincar.MountainCar;import burlap.domain.singleagent.mountaincar.MountainCarVisualizer;import burlap.mdp.auxiliary.StateGenerator;import burlap.mdp.core.TerminalFunction;import burlap.mdp.core.state.State;import burlap.mdp.core.state.vardomain.VariableDomain;import burlap.mdp.singleagent.SADomain;import burlap.mdp.singleagent.common.VisualActionObserver;import burlap.mdp.singleagent.environment.SimulatedEnvironment;import burlap.mdp.singleagent.model.RewardFunction;import burlap.mdp.singleagent.oo.OOSADomain;import burlap.statehashing.simple.SimpleHashableStateFactory;import burlap.visualizer.Visualizer;import java.util.ArrayList;import java.util.Arrays;import java.util.List;public class ContinuousDomainTutorial {public static void main(String [] args){MCLSPIFB();}public static void MCLSPIFB(){//we'll fill this in in a moment...}} Next we'll create an instance of the Mountain car domain and We'll use the standard reward function, physics, and termination conditions, so we don't need to adjust any parameters. (These return a reward of 100 when reaching the top of the mountain on the right side and zero everywhere else.) MountainCar mcGen = new MountainCar();SADomain domain = mcGen.generateDomain(); Other Mountain Car Parameters We could have also changed parameters of the Mountain car domain, such as the strength of gravity, which is found in the physParams MountainCar data member, but without any modifications, it will automatically use the default parameterizations. The next thing we will want to do is collect SARS data from the Mountain Car domain for LSPI to use for fitting its linear function approximator. For Mountain car, it is sufficient to randomly draw a state from the Mountain Car state space, sample a trajectory from it by selecting actions uniformly randomly, and then repeat the process over again from another random state. Lets collect data in this way until we have 5000 SARS tuple instances for our dataset. To accomplish this data collection, we can make use of a random StateGenerator to select random initial states, and perform random trajectory roll outs from them using a UniformRandomSARSCollector . Lets add code for that now. StateGenerator rStateGen = new MCRandomStateGenerator(mcGen.physParams);SARSCollector collector = new SARSCollector.UniformRandomSARSCollector(domain);SARSData dataset = collector.collectNInstances(rStateGen, domain.getModel(), 5000, 20, null); The MCRandomStateGenerator class provides a means to generate Mountain Car states with random positions and velocities. The collectNInstances methods will collect our SARS data for us. Specifically, we've told it to perform rollouts from states generated from our Mountain Car state generator for no more than 20 steps at a time or until we hit a terminal state. This process of generating a random state, rolling out a random trajectory for it, and collecting all the observed SARS tuples repeats until we have 5000 SARS instances. The null parameter at the end of the method call means we want it to create a new SARSData instance and fill it up with the results (and return it) rather than adding to an existing SARSData instance. LSPI as a LearningAgent In this case we're opting to collect all the data LSPI will use ahead of time. Alternatively, LSPI can be used like a standard learning algorithm (it does implement the LearningAgent interface) in which it starts with no data, acts in the world from whatever the world's current state is and reruns LSPI as it experiences more transitions (thereby improving the policy that it follows). However, this approach to acquiring SARS data is often not as efficient and there may be better means to acquire data when the agent is forced to experience the world as it comes rather than being able to manually sample the state space as we have in this tutorial. Therefore, if you are facing a problem in which you cannot manually control how states are sampled ahead of time, you may want to consider subclassing and overriding LSPI's runLearningEpisode method to use an approach that is a better fit for your domain. To learn more about how LSPI's default runLearningEpisode method is used, see the class's documentation . The next thing we will want to define is the state basis features LSPI will use for its linear estimator of the value function. As noted previously, we will use Fourier basis functions. Fourier basis functions are very easy to implement without having to set many parameters, which makes it a good first approach to try. Each Fourier basis function takes as input a state variable vector, where each element is a normalized scalar value. Each basis function corresponds to a state feature that LSPI will use for its linear function. The BURLAP FourierBasis class is an implementation of the DenseStateFeatures interface and will automatically make multiple Fourier basis functions based on the order you choose. The larger the order, the more basis functions (which grow exponentially with the dimension of input state feature vector) and the more fine grained the representation becomes, allowing for a more precise linear value function approximation. Fourier basis features will ultimately give us a dense vectorized representation of states, but to construct them we will first need to turn our state objects into a normalized numeric vector of state variables. We can construct that using some standard BURLAP tools: NormalizedVariableFeatures inputFeatures = new NormalizedVariableFeatures().variableDomain(\"x\", new VariableDomain(mcGen.physParams.xmin, mcGen.physParams.xmax)).variableDomain(\"v\", new VariableDomain(mcGen.physParams.vmin, mcGen.physParams.vmax)); NormalizedVariableFeatures is an implementation of DenseStateFeatures, which provides a method to take an input State object and turn it into a double array. To construct it, it needs to be told which variable keys to use and what the numeric variable domain of that variable is. The double array output for states is then a array equal to the number of variables we specified with the normalized value according to the variable domain we gave it. Here, we're telling it to use the x and v variable keys from mountain car (specifying the x position and velocity of the car) and we gave it the variable domain by the values in our mountain car physics parameters. With a method of producing a normalized state variable vector, we can now construct our Fourier basis features, using the FourierBasis class, an implementation of DenseStateFeatures itself. FourierBasis fb = new FourierBasis(inputFeatures, 4); In particular, we opted to use 4th order Fourier basis features, which is what the second parameter specifies. Now lets instantiate LSPI on our Mountain Car domain and task with our Fourier basis functions; tell it to use a 0.99 discount factor; set its SARS dataset to the datasetwe collected; and run LSPI until the weight values of its fitted linear function change no more than 10^-6 between iterations or until 30 iterationshave passed. LSPI lspi = new LSPI(domain, 0.99, new DenseCrossProductFeatures(fb, 3), dataset);Policy p = lspi.runPolicyIteration(30, 1e-6); One thing to note is that we gave LSPI DenseCrossProductFeatures on our constructed FourierBassis object. Note that FourierBasis features are just a mapping from states to features. But to actual learn a control mechanism, LSPI needs state-action features; that is, separate features for each action so that the value of actions can be modeled, from which a policy can be constructed. It is not uncommon in RL to first define a state feature representation, and then construct state-action features by taking the cross product of those features with each action. That is precisely what the DenseCrossProductFeatures will do: it takes as input the state features and creates a cross product of them with the actions actions. The '3' argument we provided it tells it how many actions there are. After LSPI has run until convergence, we will want to analyze the policy is produced. To analyze the resulting policy, we could roll it out and load an EpisodeSequenceVisualizer, as we have in prior tutorials. But for fun, lets watch it in real time. To visualize the animated results, we can simply grab the existing visualizer from the domain ( MountainCarVisualizer ), create a SimulatedEnvironment in which to evaluate the policy, and add a VisualActionObserver to the to the environment. Note that we can add an EnvironmentObserver to a SimulatedEnvironment, because it implements the EnvironmentServerInterface (otherwise we could use an EnvironmentServer wrapper for Environment instances that do not implement the observer interface). Specifically, we'll let it run for five policy rollouts. Visualizer v = MountainCarVisualizer.getVisualizer(mcGen);VisualActionObserver vob = new VisualActionObserver(v);vob.initGUI();SimulatedEnvironment env = new SimulatedEnvironment(domain, new MCState(mcGen.physParams.valleyPos(), 0.));env.addObservers(vob);for(int i = 0; i < 5; i++){PolicyUtils.rollout(p, env);env.resetEnvironment();}System.out.println(\"Finished\"); We also set the initial state of the environment to start in the bottom of the valley. We can get the x position value for the bottom of the valley, but calling the valleyPos() method on mountain car physics parameters object (we also set the initial velocity to zero). If you now run the main method, you see at the start a bunch of print outs to the terminal specifying the maximum change in weight values after each policy iteration. When the change is small enough, LSPI will end and you'll get a window animating the the mountain car task using the results of LSPI. That is, you should see something like the below image. A screen cap from the animation of the Mountain car task Although the settings we used are pretty robust to failure, it is possible (even if unlikely) that the car won't make it to the right side, which indicates that LSPI failed to find a good policy from the valley of the hill. LSPI can fail if your dataset collection happened to be unluckily bad. However, if you rerun the code (resulting in a a new random data collection), you should find that it works. Radial Basis Functions Before we leave Mountain Car and LSPI for the next example, lets consider running LSPI on Mountain Car with a different kind of state basis features; specifically, lets consider using radial basis functions. A radial basis function is defined with a \"center\" state, a distance metric, and a bandwidth parameter. Given an input query state, the basis function returns a value between 0 and 1 with a value of 1 when the query state has a distance of zero from the function's \"center\" state. As the query state gets further away, the basis function's returned value degrades to a value of zero. The sensitivity of the basis function to the distance is defined by its bandwidth parameter; as the bandwidth value increases, the less sensitive the function is to distance (that is, a large bandwidth will result in it returning a value near 1 even when the query state is far away). A set of state features defined by a set of radial basis functions distributed across the state space gives an approximation of where a given state is. You can think of the set of radial basis function outputs as compressing the state space. As a consequence, a common approach to using radial basis functions is set up a coarse multi-dimensional grid over the state space with a separate radial basis function centered at each intersection point of the grid. BURLAP provides us tools to easily accomplish such a construction of radial basis functions. Lets start by a creating a new method for running LSPI with radial basis functions. It will look almost identical to the previous Fourier Basis LSPI method we created, except instead of defining Fourier basis functions, we'll define radial basis functions. For the moment, the code below will create an instance of a radial basis features ( RBFFeatures ), but we will need to add code to actually add the set of radial basis functions it uses. Also note that we moved the initial state object instantiation to earlier in the code, because we will use it to help define the center states of the radial basis functions we will create. The differencesare highlighted with comments in the code. public static void MCLSPIRBF(){MountainCar mcGen = new MountainCar();SADomain domain = mcGen.generateDomain();MCState s = new MCState(mcGen.physParams.valleyPos(), 0.);NormalizedVariableFeatures inputFeatures = new NormalizedVariableFeatures().variableDomain(\"x\", new VariableDomain(mcGen.physParams.xmin, mcGen.physParams.xmax)).variableDomain(\"v\", new VariableDomain(mcGen.physParams.vmin, mcGen.physParams.vmax));StateGenerator rStateGen = new MCRandomStateGenerator(mcGen.physParams);SARSCollector collector = new SARSCollector.UniformRandomSARSCollector(domain);SARSData dataset = collector.collectNInstances(rStateGen, domain.getModel(), 5000, 20, null);RBFFeatures rbf = new RBFFeatures(inputFeatures, true);//we will add rbfs nextLSPI lspi = new LSPI(domain, 0.99, new DenseCrossProductFeatures(rbf, 3), dataset);Policy p = lspi.runPolicyIteration(30, 1e-6);Visualizer v = MountainCarVisualizer.getVisualizer(mcGen);VisualActionObserver vob = new VisualActionObserver(v);vob.initGUI();SimulatedEnvironment env = new SimulatedEnvironment(domain, s);env.addObservers(vob);for(int i = 0; i < 5; i++){PolicyUtils.rollout(p, env);env.resetEnvironment();}System.out.println(\"Finished\");} You'll notice that we passed \"true\" to our RBFeatures constructor. The true flag indicates that that the feature database should include a constant feature that is always on. This provides a Q-value \"y intercept\" value to the linear function that will be estimated. This is often not necessary, but it doesn't hurt. Since RBF features compute distances between states, it too will operate on a numeric vector of state variables. Here we've opted to use our NormalizedVariableFeatures class to provide that since we don't want different domain sizes of the variables to affect the state distance calculation. To construct a set of radial basis functions over a grid, we will first want to generate the states that lie at the intersection of grid points on a grid. To construct the set of states, we will make use of the FlatStateGridder class in BURLAP. FlatStateGridder allows you to set up arbitrarily specified grids over a state space and return the set of states that lie on the intersection points of the grid. FlatStateGridder can even do things like include constant values for some variables. (There is also an OOStateGridder for gridding OO-MDP states.) For our current purposes, we just want a fairly simple grid that spans the full state space of Mountain Car. To use StateGridder, it does require that the State objects implement MutableState, which our mountain car states do (as do the states for just about all standard BURLAP domains). To get the set of states that span a 5x5 grid over the car position and velocity attributes (for a total of 25 states), add the below code right below the instantiation of the RBFFeatures. If you want to know how to set up a more specific grid (e.g., an asymmetric grid like a 3x7), see the class's documentation FlatStateGridder gridder = new FlatStateGridder().gridDimension(\"x\", mcGen.physParams.xmin, mcGen.physParams.xmax, 5).gridDimension(\"v\", mcGen.physParams.vmin, mcGen.physParams.vmax, 5);List<State> griddedStates = gridder.gridState(s); Notice that the gridInputState method requires an example State object? An example state is required because it tells the gridder (1) what the input State Java class is; and (2) only will grid over the values you specified with calls to gridDimension, leaving any other variables in the input state left unchanged in the gridded states. Now that we have a bunch of states distributed over a uniform grid of the state space, we will want to create radial basis functions centered at each of those states. Specifically, we'll use Gaussian RBFs with a 0.2 bandwidth parameter and a Euclidean distance metric; BURLAP has implementation for both these. However, to define the \"center\" point of these states, we'll need to convert the state into its numeric state vector representation, which we provided by passing each of our Gridded states through the NormalizedVariableFeatures object we constructed. DistanceMetric metric = new EuclideanDistance();for(State g : griddedStates){rbf.addRBF(new GaussianRBF(inputFeatures.features(g), metric, 0.2));} Our final Mountain Car LSPI radial basis function method should now look like the below. public static void MCLSPIRBF(){MountainCar mcGen = new MountainCar();SADomain domain = mcGen.generateDomain();MCState s = new MCState(mcGen.physParams.valleyPos(), 0.);NormalizedVariableFeatures inputFeatures = new NormalizedVariableFeatures().variableDomain(\"x\", new VariableDomain(mcGen.physParams.xmin, mcGen.physParams.xmax)).variableDomain(\"v\", new VariableDomain(mcGen.physParams.vmin, mcGen.physParams.vmax));StateGenerator rStateGen = new MCRandomStateGenerator(mcGen.physParams);SARSCollector collector = new SARSCollector.UniformRandomSARSCollector(domain);SARSData dataset = collector.collectNInstances(rStateGen, domain.getModel(), 5000, 20, null);RBFFeatures rbf = new RBFFeatures(inputFeatures, true);FlatStateGridder gridder = new FlatStateGridder().gridDimension(\"x\", mcGen.physParams.xmin, mcGen.physParams.xmax, 5).gridDimension(\"v\", mcGen.physParams.vmin, mcGen.physParams.vmax, 5);List<State> griddedStates = gridder.gridState(s);DistanceMetric metric = new EuclideanDistance();for(State g : griddedStates){rbf.addRBF(new GaussianRBF(inputFeatures.features(g), metric, 0.2));}LSPI lspi = new LSPI(domain, 0.99, new DenseCrossProductFeatures(rbf, 3), dataset);Policy p = lspi.runPolicyIteration(30, 1e-6);Visualizer v = MountainCarVisualizer.getVisualizer(mcGen);VisualActionObserver vob = new VisualActionObserver(v);vob.initGUI();SimulatedEnvironment env = new SimulatedEnvironment(domain, s);env.addObservers(vob);for(int i = 0; i < 5; i++){PolicyUtils.rollout(p, env);env.resetEnvironment();}System.out.println(\"Finished\");} If you now point your main method to call the MCLSPIRBF method, you should see similar results as before, only this time we've used radial basis functions! Now that we've demonstrated how to use LSPI on the mountain car domain with Fourier basis functions and radial basis functions, we'll move on to a different algorithm (Sparse Sampling) and a different domain (the Inverted Pendulum). Next Part", "http://burlap.cs.brown.edu/tutorials/scd/p4.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Solving Continuous Domains Tutorials > Solving Continuous Domains > Part 4 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA(\u03bb) Conclusions Final Code Previous Part Conclusions In this tutorial we showed you how to solve continuous state problems with three different algorithms implemented in BURLAP: LSPI, Sparse Sampling, and gradient descent SARSA(\u03bb). We also demonstrated how to use these algorithms on three different continuous state domains: Mountain Car, Inverted Pendulum, and Lunar Lander. And finally, we also explained how to use three different basis functions (which can be used with LSPI and gradient descent SARSA(\u03bb)): Fourier basis functions, radial basis functions and Tile coding. Hopefully these examples have made clear the kinds of tools you need to use solve any other continuous state problems. As usual, you can find all of the code developed in this tutorial below or in the burlap_examples repository. Final Code import burlap.behavior.functionapproximation.DifferentiableStateActionValue;import burlap.behavior.functionapproximation.dense.ConcatenatedObjectFeatures;import burlap.behavior.functionapproximation.dense.DenseCrossProductFeatures;import burlap.behavior.functionapproximation.dense.NormalizedVariableFeatures;import burlap.behavior.functionapproximation.dense.NumericVariableFeatures;import burlap.behavior.functionapproximation.dense.fourier.FourierBasis;import burlap.behavior.functionapproximation.dense.rbf.DistanceMetric;import burlap.behavior.functionapproximation.dense.rbf.RBFFeatures;import burlap.behavior.functionapproximation.dense.rbf.functions.GaussianRBF;import burlap.behavior.functionapproximation.dense.rbf.metrics.EuclideanDistance;import burlap.behavior.functionapproximation.sparse.tilecoding.TileCodingFeatures;import burlap.behavior.functionapproximation.sparse.tilecoding.TilingArrangement;import burlap.behavior.policy.GreedyQPolicy;import burlap.behavior.policy.Policy;import burlap.behavior.policy.PolicyUtils;import burlap.behavior.singleagent.Episode;import burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizer;import burlap.behavior.singleagent.auxiliary.gridset.FlatStateGridder;import burlap.behavior.singleagent.learning.lspi.LSPI;import burlap.behavior.singleagent.learning.lspi.SARSCollector;import burlap.behavior.singleagent.learning.lspi.SARSData;import burlap.behavior.singleagent.learning.tdmethods.vfa.GradientDescentSarsaLam;import burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSampling;import burlap.domain.singleagent.cartpole.CartPoleVisualizer;import burlap.domain.singleagent.cartpole.InvertedPendulum;import burlap.domain.singleagent.cartpole.states.InvertedPendulumState;import burlap.domain.singleagent.lunarlander.LLVisualizer;import burlap.domain.singleagent.lunarlander.LunarLanderDomain;import burlap.domain.singleagent.lunarlander.state.LLAgent;import burlap.domain.singleagent.lunarlander.state.LLBlock;import burlap.domain.singleagent.lunarlander.state.LLState;import burlap.domain.singleagent.mountaincar.MCRandomStateGenerator;import burlap.domain.singleagent.mountaincar.MCState;import burlap.domain.singleagent.mountaincar.MountainCar;import burlap.domain.singleagent.mountaincar.MountainCarVisualizer;import burlap.mdp.auxiliary.StateGenerator;import burlap.mdp.core.TerminalFunction;import burlap.mdp.core.state.State;import burlap.mdp.core.state.vardomain.VariableDomain;import burlap.mdp.singleagent.SADomain;import burlap.mdp.singleagent.common.VisualActionObserver;import burlap.mdp.singleagent.environment.SimulatedEnvironment;import burlap.mdp.singleagent.model.RewardFunction;import burlap.mdp.singleagent.oo.OOSADomain;import burlap.statehashing.simple.SimpleHashableStateFactory;import burlap.visualizer.Visualizer;import java.util.ArrayList;import java.util.Arrays;import java.util.List;public class ContinuousDomainTutorial {private ContinuousDomainTutorial() {// do nothing}public static void MCLSPIFB(){MountainCar mcGen = new MountainCar();SADomain domain = mcGen.generateDomain();StateGenerator rStateGen = new MCRandomStateGenerator(mcGen.physParams);SARSCollector collector = new SARSCollector.UniformRandomSARSCollector(domain);SARSData dataset = collector.collectNInstances(rStateGen, domain.getModel(), 5000, 20, null);NormalizedVariableFeatures inputFeatures = new NormalizedVariableFeatures().variableDomain(\"x\", new VariableDomain(mcGen.physParams.xmin, mcGen.physParams.xmax)).variableDomain(\"v\", new VariableDomain(mcGen.physParams.vmin, mcGen.physParams.vmax));FourierBasis fb = new FourierBasis(inputFeatures, 4);LSPI lspi = new LSPI(domain, 0.99, new DenseCrossProductFeatures(fb, 3), dataset);Policy p = lspi.runPolicyIteration(30, 1e-6);Visualizer v = MountainCarVisualizer.getVisualizer(mcGen);VisualActionObserver vob = new VisualActionObserver(v);vob.initGUI();SimulatedEnvironment env = new SimulatedEnvironment(domain, new MCState(mcGen.physParams.valleyPos(), 0.));env.addObservers(vob);for(int i = 0; i < 5; i++){PolicyUtils.rollout(p, env);env.resetEnvironment();}System.out.println(\"Finished\");}public static void MCLSPIRBF(){MountainCar mcGen = new MountainCar();SADomain domain = mcGen.generateDomain();MCState s = new MCState(mcGen.physParams.valleyPos(), 0.);NormalizedVariableFeatures inputFeatures = new NormalizedVariableFeatures().variableDomain(\"x\", new VariableDomain(mcGen.physParams.xmin, mcGen.physParams.xmax)).variableDomain(\"v\", new VariableDomain(mcGen.physParams.vmin, mcGen.physParams.vmax));StateGenerator rStateGen = new MCRandomStateGenerator(mcGen.physParams);SARSCollector collector = new SARSCollector.UniformRandomSARSCollector(domain);SARSData dataset = collector.collectNInstances(rStateGen, domain.getModel(), 5000, 20, null);RBFFeatures rbf = new RBFFeatures(inputFeatures, true);FlatStateGridder gridder = new FlatStateGridder().gridDimension(\"x\", mcGen.physParams.xmin, mcGen.physParams.xmax, 5).gridDimension(\"v\", mcGen.physParams.vmin, mcGen.physParams.vmax, 5);List<State> griddedStates = gridder.gridState(s);DistanceMetric metric = new EuclideanDistance();for(State g : griddedStates){rbf.addRBF(new GaussianRBF(inputFeatures.features(g), metric, 0.2));}LSPI lspi = new LSPI(domain, 0.99, new DenseCrossProductFeatures(rbf, 3), dataset);Policy p = lspi.runPolicyIteration(30, 1e-6);Visualizer v = MountainCarVisualizer.getVisualizer(mcGen);VisualActionObserver vob = new VisualActionObserver(v);vob.initGUI();SimulatedEnvironment env = new SimulatedEnvironment(domain, s);env.addObservers(vob);for(int i = 0; i < 5; i++){PolicyUtils.rollout(p, env);env.resetEnvironment();}System.out.println(\"Finished\");}public static void IPSS(){InvertedPendulum ip = new InvertedPendulum();ip.physParams.actionNoise = 0.;RewardFunction rf = new InvertedPendulum.InvertedPendulumRewardFunction(Math.PI/8.);TerminalFunction tf = new InvertedPendulum.InvertedPendulumTerminalFunction(Math.PI/8.);ip.setRf(rf);ip.setTf(tf);SADomain domain = ip.generateDomain();State initialState = new InvertedPendulumState();SparseSampling ss = new SparseSampling(domain, 1, new SimpleHashableStateFactory(), 10, 1);ss.setForgetPreviousPlanResults(true);ss.toggleDebugPrinting(false);Policy p = new GreedyQPolicy(ss);Episode e = PolicyUtils.rollout(p, initialState, domain.getModel(), 500);System.out.println(\"Num steps: \" + e.maxTimeStep());Visualizer v = CartPoleVisualizer.getCartPoleVisualizer();new EpisodeSequenceVisualizer(v, domain, Arrays.asList(e));}public static void LLSARSA(){LunarLanderDomain lld = new LunarLanderDomain();OOSADomain domain = lld.generateDomain();LLState s = new LLState(new LLAgent(5, 0, 0), new LLBlock.LLPad(75, 95, 0, 10, \"pad\"));ConcatenatedObjectFeatures inputFeatures = new ConcatenatedObjectFeatures().addObjectVectorizion(LunarLanderDomain.CLASS_AGENT, new NumericVariableFeatures());int nTilings = 5;double resolution = 10.;double xWidth = (lld.getXmax() - lld.getXmin()) / resolution;double yWidth = (lld.getYmax() - lld.getYmin()) / resolution;double velocityWidth = 2 * lld.getVmax() / resolution;double angleWidth = 2 * lld.getAngmax() / resolution;TileCodingFeatures tilecoding = new TileCodingFeatures(inputFeatures);tilecoding.addTilingsForAllDimensionsWithWidths(new double []{xWidth, yWidth, velocityWidth, velocityWidth, angleWidth},nTilings,TilingArrangement.RANDOM_JITTER);double defaultQ = 0.5;DifferentiableStateActionValue vfa = tilecoding.generateVFA(defaultQ/nTilings);GradientDescentSarsaLam agent = new GradientDescentSarsaLam(domain, 0.99, vfa, 0.02, 0.5);SimulatedEnvironment env = new SimulatedEnvironment(domain, s);List<Episode> episodes = new ArrayList<Episode>();for(int i = 0; i < 5000; i++){Episode ea = agent.runLearningEpisode(env);episodes.add(ea);System.out.println(i + \": \" + ea.maxTimeStep());env.resetEnvironment();}Visualizer v = LLVisualizer.getVisualizer(lld.getPhysParams());new EpisodeSequenceVisualizer(v, domain, episodes);}public static void main(String[] args) {//MCLSPIFB();//MCLSPIRBF();//IPSS();LLSARSA();} End.", "http://burlap.cs.brown.edu/tutorials/scd/p3.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Solving Continuous Domains Tutorials > Solving Continuous Domains > Part 3 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA(\u03bb) Conclusions Final Code Previous Part | Next Part Solving Lunar Lander with SARSA(\u03bb) In our final example of this tutorial we will solve a simplified Lunar Lander domain using gradient descent Sarsa Lambda and Tile coding basis functions. The Lunar Lander domain is a simplified version of the classic 1979 Atari arcade game by the same name. In this domain the agent pilots a ship that must take off from the ground and land on a landing pad. The agent can either use a strong rocket thruster to push the ship in the direction the ship is facing, use a weak rocket thruster that is equal magnitude to the force of gravity, rotate clockwise or counterclockwise, or coast. The agent will receive a large reward for landing on the landing pad, a large negative reward for colliding with the ground or an obstacle, and a small negative reward for all other transitions. As with the previous examples, let us begin by making a method for this example (LLSARSA) and instantiating a Lunar Lander domain , task, and initial state. public static void LLSARSA(){LunarLanderDomain lld = new LunarLanderDomain();OOSADomain domain = lld.generateDomain();LLState s = new LLState(new LLAgent(5, 0, 0), new LLBlock.LLPad(75, 95, 0, 10, \"pad\"));} Most of this code should be fairly self explanatory. Using a default construct for LunarLanderDomain and not setting anything else with it will use default parameters for the domain (but you can change various properties such as the force of gravity, thrust, etc.). The default reward function returns +1000 for landing, -100 for collisions, and -1 for regular transitions (you can also change the reward function for the domain in the usual ways). The terminal function sets all states in which the ship has landed on the landing pad as terminal states. The initial state sets the agent at location 5, 0, with facing up, and with zero velocity (the 0 velocity is implict with the 3 argument constructor); and sets a goal landing pad rectange spanning 75-90 along the x dimension and 0-10 along the y dimension. This will create an initial state that looks like the below (as visualized in BURLAP). The initial stated used in Lunar Lander. The red box is the ship, the blue box the landing pad. We're going to solve this problem with gradient descent SARSA(\u03bb) , which is a learning algorithm that behaves much like conventional tabular SARSA(\u03bb) (discussed in previous tutorials), except it learns an approximation of the value function, much like LSPI. Unlike LSPI, gradient descent SARSA(\u03bb) does not need to use a linear approximator; however, in practice it is usually a good idea to use a linear approximator because there are much stronger learning convergence guarantees with linear approximators. When using a linear approximator, it is a good idea then to use some kind of basis functions. Like in the LSPI example, we could use the same Fourier basis or radial basis functions for gradient descent SARSA(\u03bb). However, this time we'll use a different basis function: Tile coding. Tile coding creates a set of features by generating multiple tilings over the state space. Each tile represents a features and that feature is \"on\" if the state falls within that tile. Tile coding in detail Tile coding address learning in continuous domains in an only slightly more complex way than merely discretizing the state space, yet also diminishes the aliasing effects that discretization can incur. To describe how it works, lets start by thinking about how a state discretization can be used to create a set of binary basis functions. First imagine a discretization of the state space as a process that creates large bins, or tiles , across the entire state space. We'll let each tile represent a different binary basis function. For a given input continuous state, all basis functions return a value of 0, except the function for the tile in which the continuous state is contained, which will return a value of 1. By then estimating a linear function over these features, we generalize the observed rewards and transitions for one state to all states that are contained in the same tile. The larger the tiles we use, the larger the generalization. A disadvantage of using such a simple discretization is that it produces aliasing effects. That is, two states may be very similar but reside on opposite sides of the edge of a tile, which results in none of their experience being shared, despite the fact that they are similar and do share experiences with other states that are more distant but happen to be in the same tile. Tile coding diminishes this aliasing effect by instead creating multiple offset tilings over the state space and creating a basis function for each tile in each of the tilings. If there are n tilings, then any given input state will have n basis functions with a value 1 (one for each active tile in each tiling). Because the tilings are offset from each other, two states may be contained in the same tile of one tiling, but in different tiles for a different tiling. As a consequence, experience generalization still occurs between states in the same tiling, but the differences between different tilings regains specificity and removes aliasing effects. For more information on tile coding with some good illustrations, we recommend the Generalization and Function Approximation chapter in the book Reinforcement Learning: An Introduction , by Sutton and Barto. An online version of the chapter can be found here . An advantage of using tile coding is that you only need to store weight values in the fitted linear function for tiles that are associated with states that the agent has experienced thus far (the basis function for all other tiles would return a value of zero and therefore contribute nothing to the value function approximation). Morever, when computing the value for a given input state, you only need to add the weights for the active tiles and can ignore all other tiles; that is, tile coding can be represented sparsely. Lets continue our code implementation by instantiating a TileCodingFeatures object (and implementation of SparseStateFeatures ) and define the tiling of our state space. To implement tile coding basis functions, we will need to decide on the number of tilings that we use and the width of each tile along each variable. In this case, we will use 5 tilings with a width for each variable that produces 10 tiles along each variable range. We will limit this tiling to the Lunar Lander ship variables values and ignore variables for the landing pad. Since the agent's ship is defined by 5 variables (x position, y position, x velocity, y velocity, and rotation angle from the vertical axis), this will produce 5 tilings that each define at most 10^5 tiles (since tiling coding can be represtently sparsely though, we don't necessarily have to store weights for all tiles if the agent never visits them!) To do so, add the below code. ConcatenatedObjectFeatures inputFeatures = new ConcatenatedObjectFeatures().addObjectVectorizion(LunarLanderDomain.CLASS_AGENT, new NumericVariableFeatures());int nTilings = 5;double resolution = 10.;double xWidth = (lld.getXmax() - lld.getXmin()) / resolution;double yWidth = (lld.getYmax() - lld.getYmin()) / resolution;double velocityWidth = 2 * lld.getVmax() / resolution;double angleWidth = 2 * lld.getAngmax() / resolution;TileCodingFeatures tilecoding = new TileCodingFeatures(inputFeatures);tilecoding.addTilingsForAllDimensionsWithWidths(new double []{xWidth, yWidth, velocityWidth, velocityWidth, angleWidth},nTilings,TilingArrangement.RANDOM_JITTER); To specify our tilings on the state variables, we will first want to convert our states into a variable vector. Lunar lander states are OO-MDP representations, so to vectorize the state, we use the ConcatenatedObjectFeatures class. This class lets us specify a variable vectorization for certain object classes, and then produce a state variable vector by concatenating the vectors for each object of those classes. In this case, we set it to create a state vector consisting of just the agent object class, and the agent object class is vectorized by assuming each of its variables are numeric and filling them out into an array (functionality provided by the NumericVariableFeatures class, a DesneStateFeatures implementation). Next we create some local variable for specifying our tiling configuration. We choose to 5 tilings and we set the \"resolution\" to be 10; which is how many tiles will span a variable dimension. Then, we set the width of the tiles along each dimension by dividing the range of the variable by our resolution. Our LunarLanderDomain object has methods for getting these variable range values. Finally, we instantiate our TileCodingFeatures, an implementation of SparseStateFeatures, which means it provides a method that will return a list of of any non-zero state features for a given state input. We give it the state vectorization we're using for states, and provide it tile widths along each of those dimensions, tell it to create 5 tilings along that space, and that those 5 tilings should be randomly offset from each other. If you wanted, you could also add additional tilings that operated on different sets of state variables--an advanced functionality of tile coding. Now that we have the TileCodingFeatures set up, we can create a linear value function approximator for it and pass it along to gradient descent SARSA(\u03bb). double defaultQ = 0.5;DifferentiableStateActionValue vfa = tilecoding.generateVFA(defaultQ/nTilings);GradientDescentSarsaLam agent = new GradientDescentSarsaLam(domain, 0.99, vfa, 0.02, 0.5); SARSA lambda, like LSPI, requires state-action features, and TileCoding only provides state features. However, by default the generateVFA method of TileCoding will produce a function approximator that will cross product its features with the actions, if it is used for state-action value function approximation (it also implements DifferentiableStateValue to provide state value function approximation). Note that to set the initial default Q-values to be predicted to 0.5, we set the value of each feature weight to 0.5 divided by the number of tilings. We divide the desired initial Q-value (0.5) by the number of tilings (5), because for any given state there will only be n features with a value of 1 and the rest 0, where n is the number of tilings. Therefore, if the initial weight value for all those features is 0.5/5, the linear estimate will predict our desired initial Q-value: 0.5. We also set the learning rate for gradient descent SARSA(\u03bb) to 0.02 (in general, you should decrease the learning rate as the number of features increases), and set \u03bb to 0.5. With gradient descent SARSA(\u03bb) instantiated, we can run learning episodes wtih an Environment just like we do for typical SARSA(\u03bb). Lets create a SimulatedEnvironment, run learning for 5000 episodes, and then visualize the results with an EpisodeSequenceVisualizer. SimulatedEnvironment env = new SimulatedEnvironment(domain, s);List episodes = new ArrayList ();for(int i = 0; i < 5000; i++){Episode ea = agent.runLearningEpisode(env);episodes.add(ea);System.out.println(i + \": \" + ea.maxTimeStep());env.resetEnvironment();}Visualizer v = LLVisualizer.getVisualizer(lld.getPhysParams());new EpisodeSequenceVisualizer(v, domain, episodes); If you now point your main method to LLSARSA() and run it, you should initially see a bunch of text after each episode stating how long the learning episode lasted followed by the EpisodeSequenceVisualizerGUI, which should look something like the below. The EpisodeSequenceVisualizer GUI showing the learning results on Lunar Lander You should find that as more learning episodes are performed, the agent becomes progressively better at piloting to the landing pad. That concludes all of our examples for this tutorial! Closing remarks and the full code we created can be found on the next page. Next Part", "http://burlap.cs.brown.edu/tutorials/scd/p2.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Solving Continuous Domains Tutorials > Solving Continuous Domains > Part 2 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA(\u03bb) Conclusions Final Code Previous Part | Next Part Solving the Inverted Pendulum with Sparse Sampling In this part of the tutorial we will be solving the Inverted Pendulum problem. There are actually a number of different versions of this problem (for other variants, see the CartPoleDomain and its parameters), but in this example we'll be using one of the more simple forms. The problem is as follows; a cart exists on an infinite track on which force can be applied to move the cart left or right on the track. On top of the cart is a pole (the inverted pendulum) and the goal is to keep the pole balanced and pointing up by using left, right, or no force actions. If the angle between the pole and the vertical axis is larger than some threshold, the task is considered to have been failed. The state is defined by the pole angle and its angular velocity. An illustration of the problem, as visualized in BURLAP, is shown below. The BURLAP visualization of the Inverted Pendulum problem We are going to solve this problem using Sparse Sampling (more on that in a moment). Let us start by making a method (IPSS) for solving this problem and filling it in with code to instantiate the InvertedPendulum domain and task. public static void IPSS(){InvertedPendulum ip = new InvertedPendulum();ip.physParams.actionNoise = 0.;RewardFunction rf = new InvertedPendulum.InvertedPendulumRewardFunction(Math.PI/8.);TerminalFunction tf = new InvertedPendulum.InvertedPendulumTerminalFunction(Math.PI/8.);ip.setRf(rf);ip.setTf(tf);SADomain domain = ip.generateDomain();State initialState = new InvertedPendulumState();} Here we're using a non-default configuration for demonstration purposes. The line \"ip.physParams.actionNoise = 0.;\" sets our domain to have no noise in the actions. ( physParams is a data member containing all physics parameters that you can modify.) We also set the reward function and terminal function specify task failure conditions to be when the angle between the pole and vertical axis is greater than \u03c0/8 radians. Specifically, the agent will receive zero reward everywhere except when the pole's angle is greater than \u03c0/8, at which point it will receive -1 reward. The initial state we retrieved from the InvertedPendulum class will return a state in which the pole is balanced with no initial angular velocity. The algorithm we're going to use to solve this problem is Sparse Sampling. Instead of trying to approximate the value function for all states, Sparse Sampling will estimate Q-values for only one state a time, with the exception that the Q-values estimated are for a finite horizon , which means it only considers the possible reward received up to a specific number of steps from the current state and then ignores everything that might happen after that point. The approach is called Sparse Sampling, because if the set of possible transition dynamics are very large or infinite, it will only use a small sample from the transition dynamics when computing the Q-values. A disadvantage of Sparse Sampling is that for every new state encountered in the real world, planning needs to happen all over again (unless the agent happens to arrive in the same exact state, which is often uncommon in continuous state spaces). Furthermore, the computational complexity grows exponentially with the size of the horizon used, so if a large horizon is necessary to achieve a reasonable policy, Sparse Sampling may be prohibitively expensive. However, for our Inverted Pendulum domain, failing the task is only a few easy mistakes away, which means we can use a tractably small horizon to solve the problem. Lets now instantiate SparseSampling and set up a GreedyQ policy to follow from it. SparseSampling ss = new SparseSampling(domain, 1, new SimpleHashableStateFactory(), 10, 1);ss.setForgetPreviousPlanResults(true);ss.toggleDebugPrinting(false);Policy p = new GreedyQPolicy(ss); Note that we're using a discount factor of 1 because we are computing the Q-values for a finite horizon (rather than computing an infinite horizon) and a discount factor of 1 with a finite horizon will always result in finite Q-values. The method call setForgetPreviousPlanResults(true) tells Sparse Sampling to forget the previous planning tree it created every time planning for a new state is begun. Since we don't expect to see the same state twice, this is useful to free up memory that we don't expect to use again. The last parameters of the SparseSampling constructor are the horizon size and the number of transition samples. We set the horizon to 10 and the number of transition samples to 1. Using only 1 transition sampling might be problematic in general, but since we simplified by the problem by removing action noise, everything is deterministic and so we only need one sample anyway! (Later, feel free to add back noise and increase the number samples, though you will find that a fair bit more computation time is needed). The final thing you'll notice in the code is that we never make an explicit call to planning from a state. There is a lack of an explicit planning call because whenever the GreedyQPolicy queries for the Q-values of a state, SparseSampling will automatically plan from that state first (unless we had let it remember past planning results and it was the same state as a state for which it's planned before). At this point, we're basically done!. All we need to do now is evaluate the policy that we created. We could have an animated visualization, like we did for the Mountain Car domain with LSPI, but since Sparse Sampling requires a bit more computation per step, lets let it cache an episode (with a maximum of 500 steps) and then visualize the episode using an EpisodeSequnceVisualizer like we've used in previous tutorials. Add the following code to evaluate the policy for at most 500 steps from the initial state, create a visualizer, and load up a EpisodeSequenceVisualizer to review the results. Episode e = PolicyUtils.rollout(p, initialState, domain.getModel(), 500);System.out.println(\"Num steps: \" + e.maxTimeStep());Visualizer v = CartPoleVisualizer.getCartPoleVisualizer();new EpisodeSequenceVisualizer(v, domain, Arrays.asList(e)); If you now point the main method to IPSS and run it, you should first see printed to the console the number of Bellman backups that were performed in the planning for each step of the episode. After 500 steps, it will launch the EpisodeSequenceVisualizer that you can use to review the steps it took. You should have found that it successfully balanced the pole for all 500 steps and the interface should look something like the below. The EpisodeSequenceVisualizer GUI after solving the Inverted Pendulum with Sparse Sampling. We're now finished with the Sparse Sampling example! If you're looking for an additional exercise, consider trying to solve this problem with LSPI using what you learned from the previous part of the tutorial. If you do so, we recommend using 5th order Fourier basis functions and collecting 5000 SARS instances by performing random trajectories from the initial balanced state. (To create a StateGenerator that always returns the same initial state for use with the SARS collector, see the ConstantStateGenerator class.) In the final part of this tutorial, we will show how to solve the Lunar Lander domain with gradient descent SARSA lambda. Next Part", "http://burlap.cs.brown.edu/tutorials_v1/bd/p2.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building a Domain Tutorials (v1) > Building a Domain > Part 2 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Previous Part | Next Part OO-MDPs In the classic MDP formalism, each state is simply described by its identity. The cell in the bottom left corner of the grid world would simply be state \"0\" and the one above it might simply be state \"11.\" This is known as a flat state representation because there is no other information about the states other than their identity. Although many planning/learning algorithms work just fine with flat representations, using a flat state representation makes defining transition dynamics and reward functions inconvenient. In fact, when we described the gridworld in the previous section, we used words regarding spatial adjacency and direction to explain it. It would similarly be nice to define the states, transitions, etc. using such concepts. For these reasons (and others), it is oftenmuch easier to use a factored state representation, which can be exploited when defining the MDP transition dynamics and other properties. A classic way to define a factored state representation is with a set of state variables or attributes . In our grid world, for example, we would define the state by an x-position attribute and a y-position attribute. The bottom left cell of the world would be state (0, 0); the cell directly above it would be (0, 1); and so on. The factored representation that BURAP uses is the object-oriented MDP (OO-MDP), which rather than representing states by a set of attributes, states are represented by a set of objects . Each object belongs to an object class, and each object class has an associated set of attributes. Each attribute can be of a different type with its own value domain. An object in a state is simply a value assignment to its class' attributes. In our grid world, we can define an \"agent\" class that has two integer attributes associated with it with a value domain spanning the width and height of the grid world. In this definition, a state would contain an object instance belonging to the agent class with a value assignment specifying the agent's x and y position. Although grid worlds are simple enough to describe without using an OO-MDP representation, there are a number of reasons why the OO-MDP representation is useful. For example, it's trivial to define transition dynamics that create new objects in the world or remove them, merely by having the objects added or removed from the list of objects present in a state. If there are multiple objects belonging to the same class, states can also be defined invariantly to the reference or order of the objects in the state. For instance, consider a state (s0) with block objects defined by 2D spatial positions. Now imagine a new state (s1) that is the result of swapping the positions of the block objects as show in the below image. Even though the object identifiers associated with the blocks is different between s0 and s1, the states are isomorphic (that is, if block0 was renamed to block1 and block1 to block0, the states would be the same); therefore, from a decision making algorithm perspective it may be useful to treat the states as equal, rather than distinct states that each require independent computation and reasoning. In an OO-MDP paradigm it is possible to treat these states as equal and BURLAP will do that automatically (unless otherwise specified)! Another advantage to the OO-MDP paradigm is that it leverages the object-oriented nature to provide additional high-level state features in the form of propositional functions that operate on objects in the world. In our grid world, we can introduce an additional object class for location objects (similarly defined by x,y position attributes) and then define a propositional function called \"at\" that operates on the agent object and a location object and evaluates to true when they are in the same location. Including propositional functions is useful for bridging the gap between MDPs and more classic AI approaches that are based on logical representations. In this tutorial we will implement the \"at\" propositional function in our grid world to demonstrate how to create them. BURLAP OO-MDP Java Class Overview BURLAP implements the OO-MDP paradigm in Java with the following class structure, which can be found in the packages burlap.oomdp.core and burlap.oomdp.singleagent . Attribute - this class defines an attribute name, data type, and value range. Attribute data types can be discrete (categorical or integers), real-valued, relational, strings, or int and double arrays for very large data. ObjectClass - this class defines an object class name and is defined with an associated set of Attribute objects. Value - this class provides a value assignment for a specific attribute. There is a different Value subclass for each attribute data type, but management of it is handled behind the scenes. ObjectInstance - this class is used to represent an OO-MDP object, which is defined by an ObjectClass and a set of Value assignments to each of the class' Attribute objects. State - this class provides an OO-MDP state definition, which is specified as a list of ObjectInstance objects. PropositionalFunction - this abstract class is subclassed to define propositional functions of an OO-MDP that operate on objects in State objects. Action - this abstract class is subclassed to provide the actions an agent can take in the world. The action subclass defines the transition dynamics for the action, preconditions (if any), and parameters the action takes (if any). TransitionProbability - this class is a pair that defines the probability of transitioning to another state and is returned by the Action class when querying for its transition dynamics. GroundedAction - this class provides a reference to an action and the specific parameters (if any) with which it should be applied. GroundedProp - this class provides a reference to a PropositionalFunction and the parameters with which it will be evaluated. SADomain - this class provides the definition of an OO-MDP domain, and includes the references to all of the ObjectClass objects, Attribute objects, PropositionalFunction objects, and Action objects that define the domain. TerminalFunction - this interface is implemented to specify the terminal states of a task in a specific OO-MDP domain. RewardFunction - this interface is implemented to specify the rewards received for any state, action, next state transition. Next Part", "http://burlap.cs.brown.edu/tutorials_v1/bd/p1.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building a Domain Tutorials (v1) > Building a Domain > Part 1 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Next Part You are viewing the tutorial for BURLAP 1; if you'd like the BURLAP 2 tutorial, go here . Introduction This tutorial will cover three topics. First, we will discuss Markov Decision Processes (MDPs) and more specifically, Object-oriented MDPs (OO-MDPs): the decision making process that BURLAP uses to express single agent domains and decision making problems; then we will discuss how BURLAP implements that OO-MDPs. Finally, we will cover how to create a domain, so that the planning and learning algorithms in BURLAP can be used on it, as well as how to visualize it, which is useful for testing and reviewing results. Note Beyond MDPs, BURLAP also supportsstochastic games, but a discussion of stochastic games will be left for a different tutorial and many of the coreelements of the OO-MDP code that BURLAP uses is reused in the stochastic games package of BURLAP as well. That is, BURLAP implements a form of Object-oriented Stochastic games. If you are alreadyfamiliar with MDPs or OO-MDPs, or just want to get down to coding, feel free to skip the firstsections that discuss their mathematical description. For more information on how to useplanning and learning algorithms on the OO-MDP domains that you create or that are already in BURLAP, see the Basic Planning and Learning tutorial. Markov Decision Process To define worlds in which an agent can plan or learn, BURLAP uses the object-oriented Markov Decision Process (OO-MDP) formalism, which is an extension of the classic Markov Decision Process (MDP) formalism.A MDP provides a formal definition of a world, how it works, and how the agent who will be making decisions interacts with the world in a series of discretetime steps. In this tutorial we will formalize a grid world as an MDP. A grid world is a 2D world in which an agent can move north, south, east or west by one unit, provided there are no walls in the way. The below image shows a simple grid world with the agent's position represented by a gray circle and walls of the world painted black. Typically, the goal in a grid world is for the agent to navigate to some location, but there are a number of variants. An example grid world. To define any world and task as an MDP, we will need to break down the problem into four components: a set of possible states of the world ( S ); a set of actions that the agent can apply ( A ); a definition of how actions change the state of the world, known as the transition dynamics ( T ); and the rewards the agent receives for each of its actions ( R ), known as the reward function, which will determine what the best behavior is (that is, the agent will want to act in a way that maximizes the reward it receives). The transition dynamics are formulated as a probabilistic function T ( s' | s, a ), which defines the probability of the world changing to state s' in the next discrete timestep when the agent takes action a in the current state s . The fact that the world can change stochastically is one of the unique properties of an MDP compared to more classic planning/decision making problems. The reward function is defined as R ( s, a, s' ), which returns the reward received for the agent taking action a in state s and then transitioning to state s' . Notice how both the transition dynamics and reward function are temporally independent from everything predating the most recentstate and action? Requiring this level of temporal independence makes this a Markov system and is why this formalism is called a Markov decision process. In our grid world, the set of states are the possible locations of the agent. The actions are north, south, east, and west. We will make the transition dynamics stochastic so that with high probability (0.8) the agent will move in the intended direction, and with some low probability (0.2) move in a different direction. The transition dynamics will also encode the walls of our grid world by specifying that movement that would lead into a wall will result in returning to the same state. Finally, we can define a reward function that returns a high reward when the agent reaches the top right corner of the world and zero everywhere else. For various kinds of problems, the concept of terminal states is often useful. A terminal state is a state that once reached causes all further action of the agent to cease. This is a useful concept for defining goal-directed tasks (i.e., action stops once the agent achieves a goal), failure conditions, or any number of other reasons. In our grid world, we'll want to specify the top right corner the agent is trying to get to as a terminal state. An MDP definition does not include a specific element for specifying terminal states because they can be implicitly defined in the transition dynamics and reward function. That is, a terminal state can be encoded in an MDP by being a state in which every action causes a deterministic transition back to itself with zero reward. However, for convenience and other practical reasons, terminal states in BURLAP are specified directly with a function (more on that later). The goal of planning or learning in an MDP is to find the behavior that maximizes the reward the agent receives over time. More formally, we'd say that the goal is to find a policy , which is a mapping from states in the MDP to actions that the agent takes. To find the policy that maximizes the reward over time, we must first define what it means to maximize reward over time and there are a number of different temporal objectives wecan imagine that change what the optimal policy is. Perhaps the most intuitive way to define the temporal reward maximization is to maximize thethe expected total future reward; that is, the best policy is the one that results in largest possible sum of all future rewards. Although this metric is sometimes appropriate, it's often problematic because it can result in policies that are evaluated to have infinite value or which do not discriminate between policies that receive the rewards more quickly. For example, in our grid world, any path the agent took to reach the top right would have a value 1 (because they all would eventually reach the goal); however, what we'd probably want instead is for the agent to prefer a policy that reaches the goal as fast as possible. Moreover, if we didn't set the top right corner to be a terminal state, the agent could simply move away from it and back into it, resulting in any policy that reaches the goal having an infinite value, which makes comparisons between different policies even more difficult! A commonalternative temporal objective that is more robust is to define the objective to beto maximize the expected discounted future reward. That is, theagent is trying to maximize expected sum where r_t is the reward received at time t and \u03b3 is the discount factor that dictates how much preference an agent has for more immediate rewards, or in other words, the agent's patience. With \u03b3 = 1, the agent values distantrewards that will happen much further in the future as much as the reward the agent will receive in the next time step; therefore, \u03b3 = 1 results in the same objective of summing all future rewards together and will have the same problems previously mentioned. With \u03b3 = 0 all the agent values only the next reward and does not care about anything that happens afterwards, thereby resulting in all policies having a finite value. This setting has the inverse effect of the agent never caring about our grid world goal location unless it's one step away. However, a \u03b3 value somewhere in between 0 and 1 often results in what we want. That is, for all values of 0 <= \u03b3 < 1, the expected reward in an MDP when following any given policy is finite and the agent will value future rewards at least somewhat. If we set \u03b3 to 0.99 in our grid world, the result is that the agent would want to get to the goal as fast as possible, because waiting longer would result in the eventual +1 goal reward being more heavily discounted. Although there are still other ways to define the temporal objective of an MDP, current learning and planning algorithms in BURLAP are based on usingthe discounted reward with \u03b3 left as a parameter that the user can specify. Next Part", "http://burlap.cs.brown.edu/tutorials_v1/bd/p5.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building a Domain Tutorials (v1) > Building a Domain > Part 5 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Previous Part Reward Functions and Terminal Functions Now that you've created a world, you'll want to definetasks for the world so that you can run planning and learningalgorithms on it. Tasks in BURLAP are typically defined with RewardFunction and TerminalFunction implementations. The former specifies the reward received by the agent for transition tuples (previous state, action taken, resulting state); the later specifies which states are terminal states that cause all further action to cease. While we won't be using any planning or learning algorithms in this tutorial, we will briefly cover how to create your own reward functions and terminal state functions so that you can run planning and learning algorithms on your domain. Before you make your own RewardFunction and TerminalFunction,it is sometimes worth checking to see if BURLAP already has an implementation that you can use. For example, many different problems use a reward function that returns -1 everywhere.For problems like these, you can use the UniformCostRF object. If your domain is continuing (i.e., non-terminating), thenyou can use the NullTermination object. It also not uncommon to have a goal condition that is satisfied whenever any object grounding of a propositional function returns true. In our grid world, for example, if we let location objects indicate goal locations, we might want a terminal function that returns true for any state in which the agent is at a location. In such a case you can use the SinglePFTF TerminalFunction and point it to the atLocation propositional function. If none of the existing RewardFunction or TerminalFunction objects in BURLAP suit your needs, you can always create your own. For example, suppose we wanted a reward function that returned -1 everywhere, except when the agent reached designated (x, y) position at which point it returned a reward of +100. We can implement such a reward function as shown below. public static class ExampleRF implements RewardFunction{int goalX;int goalY;public ExampleRF(int goalX, int goalY){this.goalX = goalX;this.goalY = goalY;}@Overridepublic double reward(State s, GroundedAction a, State sprime) {//get location of agent in next stateObjectInstance agent = sprime.getFirstObjectOfClass(CLASSAGENT);int ax = agent.getDiscValForAttribute(ATTX);int ay = agent.getDiscValForAttribute(ATTY);//are they at goal location?if(ax == this.goalX && ay == this.goalY){return 100.;}return -1;}} Notice that when we get the agent position, we get it from the \"sprime\" variable? That's because parameter \"s\" represents the previous state, \"a\" represents the action the agent took in the previous state, and \"sprime\" represents the state the agent ended up in as a result. Since we want to return +100 when the agent reaches our goal location, we care about where the agent ended up, which is held in sprime. If we wanted to make a similar TerminalFunction that marked our goal state as a terminal state, we would do so with the similar below code. public static class ExampleTF implements TerminalFunction{int goalX;int goalY;public ExampleTF(int goalX, int goalY){this.goalX = goalX;this.goalY = goalY;}@Overridepublic boolean isTerminal(State s) {//get location of agent in next stateObjectInstance agent = s.getFirstObjectOfClass(CLASSAGENT);int ax = agent.getDiscValForAttribute(ATTX);int ay = agent.getDiscValForAttribute(ATTY);//are they at goal location?if(ax == this.goalX && ay == this.goalY){return true;}return false;}} And that is all there is to defining reward functions and terminal states! Conclusions In this tutorial we showed you how to create a domain, visualize it, interact with it, and how to define tasks for it. With a domain and task in hand you're now ready to use the planning and learning algorithms in BURLAP on it, which you will learn about in the next tutorial . Although we showed you how to create a grid world domain in this tutorial, if you do want to run experiments on a grid world, we highly recommend that you use the GridWorldDomain already in BURLAP. It will support many more features than we covered in this tutorial including 1 dimensional walls, location types, and more flexible transition dynamics. Final Code For reference, you can find all of the code we wrote below. import java.awt.Color;import java.awt.Graphics2D;import java.awt.geom.Ellipse2D;import java.awt.geom.Rectangle2D;import java.util.ArrayList;import java.util.List;import burlap.oomdp.auxiliary.DomainGenerator;import burlap.oomdp.core.Attribute;import burlap.oomdp.core.Attribute.AttributeType;import burlap.oomdp.core.Domain;import burlap.oomdp.core.ObjectClass;import burlap.oomdp.core.ObjectInstance;import burlap.oomdp.core.PropositionalFunction;import burlap.oomdp.core.State;import burlap.oomdp.core.TerminalFunction;import burlap.oomdp.core.TransitionProbability;import burlap.oomdp.singleagent.Action;import burlap.oomdp.singleagent.GroundedAction;import burlap.oomdp.singleagent.RewardFunction;import burlap.oomdp.singleagent.SADomain;import burlap.oomdp.singleagent.explorer.TerminalExplorer;import burlap.oomdp.singleagent.explorer.VisualExplorer;import burlap.oomdp.visualizer.ObjectPainter;import burlap.oomdp.visualizer.StateRenderLayer;import burlap.oomdp.visualizer.StaticPainter;import burlap.oomdp.visualizer.Visualizer;public class ExampleGridWorld implements DomainGenerator {public static final String ATTX = \"x\";public static final String ATTY = \"y\";public static final String CLASSAGENT = \"agent\";public static final String CLASSLOCATION = \"location\";public static final String ACTIONNORTH = \"north\";public static final String ACTIONSOUTH = \"south\";public static final String ACTIONEAST = \"east\";public static final String ACTIONWEST = \"west\";public static final String PFAT = \"at\";//ordered so first dimension is xprotected int [][] map = new int[][]{{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,0,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{1,0,1,1,1,1,1,1,0,1,1},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,0,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},};@Overridepublic Domain generateDomain() {SADomain domain = new SADomain();Attribute xatt = new Attribute(domain, ATTX, AttributeType.INT);xatt.setLims(0, 10);Attribute yatt = new Attribute(domain, ATTY, AttributeType.INT);yatt.setLims(0, 10);ObjectClass agentClass = new ObjectClass(domain, CLASSAGENT);agentClass.addAttribute(xatt);agentClass.addAttribute(yatt);ObjectClass locationClass = new ObjectClass(domain, CLASSLOCATION);locationClass.addAttribute(xatt);locationClass.addAttribute(yatt);new Movement(ACTIONNORTH, domain, 0);new Movement(ACTIONSOUTH, domain, 1);new Movement(ACTIONEAST, domain, 2);new Movement(ACTIONWEST, domain, 3);new AtLocation(domain);return domain;}public static State getExampleState(Domain domain){State s = new State();ObjectInstance agent = new ObjectInstance(domain.getObjectClass(CLASSAGENT), \"agent0\");agent.setValue(ATTX, 0);agent.setValue(ATTY, 0);ObjectInstance location = new ObjectInstance(domain.getObjectClass(CLASSLOCATION), \"location0\");location.setValue(ATTX, 10);location.setValue(ATTY, 10);s.addObject(agent);s.addObject(location);return s;}public StateRenderLayer getStateRenderLayer(){StateRenderLayer rl = new StateRenderLayer();rl.addStaticPainter(new WallPainter());rl.addObjectClassPainter(CLASSLOCATION, new LocationPainter());rl.addObjectClassPainter(CLASSAGENT, new AgentPainter());return rl;}public Visualizer getVisualizer(){return new Visualizer(this.getStateRenderLayer());}protected class Movement extends Action{//0: north; 1: south; 2:east; 3: westprotected double [] directionProbs = new double[4];public Movement(String actionName, Domain domain, int direction){super(actionName, domain, \"\");for(int i = 0; i < 4; i++){if(i == direction){directionProbs[i] = 0.8;}else{directionProbs[i] = 0.2/3.;}}}@Overrideprotected State performActionHelper(State s, String[] params) {//get agent and current positionObjectInstance agent = s.getFirstObjectOfClass(CLASSAGENT);int curX = agent.getDiscValForAttribute(ATTX);int curY = agent.getDiscValForAttribute(ATTY);//sample directon with random rolldouble r = Math.random();double sumProb = 0.;int dir = 0;for(int i = 0; i < this.directionProbs.length; i++){sumProb += this.directionProbs[i];if(r < sumProb){dir = i;break; //found direction}}//get resulting positionint [] newPos = this.moveResult(curX, curY, dir);//set the new positionagent.setValue(ATTX, newPos[0]);agent.setValue(ATTY, newPos[1]);//return the state we just modifiedreturn s;}@Overridepublic List<TransitionProbability> getTransitions(State s, String [] params){//get agent and current positionObjectInstance agent = s.getFirstObjectOfClass(CLASSAGENT);int curX = agent.getDiscValForAttribute(ATTX);int curY = agent.getDiscValForAttribute(ATTY);List<TransitionProbability> tps = new ArrayList<TransitionProbability>(4);TransitionProbability noChangeTransition = null;for(int i = 0; i < this.directionProbs.length; i++){int [] newPos = this.moveResult(curX, curY, i);if(newPos[0] != curX || newPos[1] != curY){//new possible outcomeState ns = s.copy();ObjectInstance nagent = ns.getFirstObjectOfClass(CLASSAGENT);nagent.setValue(ATTX, newPos[0]);nagent.setValue(ATTY, newPos[1]);//create transition probability object and add to our list of outcomestps.add(new TransitionProbability(ns, this.directionProbs[i]));}else{//this direction didn't lead anywhere new//if there are existing possible directions//that wouldn't lead anywhere, aggregate with themif(noChangeTransition != null){noChangeTransition.p += this.directionProbs[i];}else{//otherwise create this new state and transitionnoChangeTransition = new TransitionProbability(s.copy(), this.directionProbs[i]);tps.add(noChangeTransition);}}}return tps;}protected int [] moveResult(int curX, int curY, int direction){//first get change in x and y from direction using 0: north; 1: south; 2:east; 3: westint xdelta = 0;int ydelta = 0;if(direction == 0){ydelta = 1;}else if(direction == 1){ydelta = -1;}else if(direction == 2){xdelta = 1;}else{xdelta = -1;}int nx = curX + xdelta;int ny = curY + ydelta;int width = ExampleGridWorld.this.map.length;int height = ExampleGridWorld.this.map[0].length;//make sure new position is valid (not a wall or off bounds)if(nx < 0 || nx >= width || ny < 0 || ny >= height || ExampleGridWorld.this.map[nx][ny] == 1){nx = curX;ny = curY;}return new int[]{nx,ny};}}protected class AtLocation extends PropositionalFunction{public AtLocation(Domain domain){super(PFAT, domain, new String []{CLASSAGENT,CLASSLOCATION});}@Overridepublic boolean isTrue(State s, String[] params) {ObjectInstance agent = s.getObject(params[0]);ObjectInstance location = s.getObject(params[1]);int ax = agent.getDiscValForAttribute(ATTX);int ay = agent.getDiscValForAttribute(ATTY);int lx = location.getDiscValForAttribute(ATTX);int ly = location.getDiscValForAttribute(ATTY);return ax == lx && ay == ly;}}public class WallPainter implements StaticPainter{@Overridepublic void paint(Graphics2D g2, State s, float cWidth, float cHeight) {//walls will be filled in blackg2.setColor(Color.BLACK);//set up floats for the width and height of our domainfloat fWidth = ExampleGridWorld.this.map.length;float fHeight = ExampleGridWorld.this.map[0].length;//determine the width of a single cell //on our canvas such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;//pass through each cell of our map and if it's a wall, paint a black rectangle on our //cavas of dimension widthxheightfor(int i = 0; i < ExampleGridWorld.this.map.length; i++){for(int j = 0; j < ExampleGridWorld.this.map[0].length; j++){//is there a wall here?if(ExampleGridWorld.this.map[i][j] == 1){//left coordinate of cell on our canvasfloat rx = i*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas//origin is in the top left instead of the bottom rightfloat ry = cHeight - height - j*height;//paint the rectangleg2.fill(new Rectangle2D.Float(rx, ry, width, height));}}}}}public class AgentPainter implements ObjectPainter{@Overridepublic void paintObject(Graphics2D g2, State s, ObjectInstance ob,float cWidth, float cHeight) {//agent will be filled in grayg2.setColor(Color.GRAY);//set up floats for the width and height of our domainfloat fWidth = ExampleGridWorld.this.map.length;float fHeight = ExampleGridWorld.this.map[0].length;//determine the width of a single cell on our canvas //such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;int ax = ob.getDiscValForAttribute(ATTX);int ay = ob.getDiscValForAttribute(ATTY);//left coordinate of cell on our canvasfloat rx = ax*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas //origin is in the top left instead of the bottom rightfloat ry = cHeight - height - ay*height;//paint the rectangleg2.fill(new Ellipse2D.Float(rx, ry, width, height));}}public class LocationPainter implements ObjectPainter{@Overridepublic void paintObject(Graphics2D g2, State s, ObjectInstance ob,float cWidth, float cHeight) {//agent will be filled in blueg2.setColor(Color.BLUE);//set up floats for the width and height of our domainfloat fWidth = ExampleGridWorld.this.map.length;float fHeight = ExampleGridWorld.this.map[0].length;//determine the width of a single cell on our canvas //such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;int ax = ob.getDiscValForAttribute(ATTX);int ay = ob.getDiscValForAttribute(ATTY);//left coordinate of cell on our canvasfloat rx = ax*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas //origin is in the top left instead of the bottom rightfloat ry = cHeight - height - ay*height;//paint the rectangleg2.fill(new Rectangle2D.Float(rx, ry, width, height));}}public static class ExampleRF implements RewardFunction{int goalX;int goalY;public ExampleRF(int goalX, int goalY){this.goalX = goalX;this.goalY = goalY;}@Overridepublic double reward(State s, GroundedAction a, State sprime) {//get location of agent in next stateObjectInstance agent = sprime.getFirstObjectOfClass(CLASSAGENT);int ax = agent.getDiscValForAttribute(ATTX);int ay = agent.getDiscValForAttribute(ATTY);//are they at goal location?if(ax == this.goalX && ay == this.goalY){return 100.;}return -1;}}public static class ExampleTF implements TerminalFunction{int goalX;int goalY;public ExampleTF(int goalX, int goalY){this.goalX = goalX;this.goalY = goalY;}@Overridepublic boolean isTerminal(State s) {//get location of agent in next stateObjectInstance agent = s.getFirstObjectOfClass(CLASSAGENT);int ax = agent.getDiscValForAttribute(ATTX);int ay = agent.getDiscValForAttribute(ATTY);//are they at goal location?if(ax == this.goalX && ay == this.goalY){return true;}return false;}}public static void main(String [] args){ExampleGridWorld gen = new ExampleGridWorld();Domain domain = gen.generateDomain();State initialState = ExampleGridWorld.getExampleState(domain);//TerminalExplorer exp = new TerminalExplorer(domain);//exp.exploreFromState(initialState);Visualizer v = gen.getVisualizer();VisualExplorer exp = new VisualExplorer(domain, v, initialState);exp.addKeyAction(\"w\", ACTIONNORTH);exp.addKeyAction(\"s\", ACTIONSOUTH);exp.addKeyAction(\"d\", ACTIONEAST);exp.addKeyAction(\"a\", ACTIONWEST);exp.initGUI();}} End.", "http://burlap.cs.brown.edu/tutorials_v1/bd/p4.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building a Domain Tutorials (v1) > Building a Domain > Part 4 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Previous Part | Next Part The Components of a Visualizer Different visualization components in BURLAP are built around implementing the RenderLayer interface, which requires being passed a graphics context on which the implementing class will paint. Having everything built around RenderLayer objectsmeans you can trivially stack different kinds of information ontop of each other. For example, you might have a render layer to display a state, and another one to display value function information, layered on top. In this tutorial we will focus onrendering the state, for which there is a specific implementation of the RenderLayer interface that we can use called StateRenderLayer , which after constructing we can pass to the Visualizer class, which will create a Java canvas to which are StateRenderLayer can paint. The StateRenderLayer is provided a number of different subpainters that it will call sequentially to paint to the canvas. Each subpainter is either a StaticPainter or an ObjectPainter . The StaticPainter is an interface that requires implementing a method that takes a graphics context, an OO-MDP State object, and the width and height of the canvas that then paints to the canvas information about the overall state or the domain to which the state belongs. For example, in the grid world we've been creating, walls are not explicitly represented in our OO-MDP state object, but when rendering a state, we'd like to paint where the walls are. The ObjectPainter is an interface that requires implementing a method that takes a graphics context, an OO-MDP state, a specific OO-MDP ObjectInstance from that state, and the width and height of the canvas that then paints to the canvas information about that specific object instance. In our GridWorld, we would want to provide a different ObjectPainter forthe agent class objects and location class objects. When our StateRenderLayer object is provided a bunch of StaticPainter and ObjectPainter objects, during it's state paint method it will first paint to the graphics context with the StaticPainter objects. Then for each OO-MDP object in the state, it will paint to the canvas using the corresponding ObjectPainterthat we will associate with that class. Implementing the Painters To implement a StaticPainter for painting the walls of our grid world as black rectangles, add the below class inside the ExampleGridWord class code we've been writing. public class WallPainter implements StaticPainter{@Overridepublic void paint(Graphics2D g2, State s, float cWidth, float cHeight) {//walls will be filled in blackg2.setColor(Color.BLACK);//set up floats for the width and height of our domainfloat fWidth = ExampleGridWorld.this.map.length;float fHeight = ExampleGridWorld.this.map[0].length;//determine the width of a single cell on our canvas //such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;//pass through each cell of our map and if it's a wall, paint a black //rectangle on our cavas of dimension widthxheightfor(int i = 0; i < ExampleGridWorld.this.map.length; i++){for(int j = 0; j < ExampleGridWorld.this.map[0].length; j++){//is there a wall here?if(ExampleGridWorld.this.map[i][j] == 1){//left corrdinate of cell on our canvasfloat rx = i*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas//origin is in the top left instead of the bottom rightfloat ry = cHeight - height - j*height;//paint the rectangleg2.fill(new Rectangle2D.Float(rx, ry, width, height));}}}}} The main idea of this code is to first determine how wide and tall cells in our grid world will be rendered on a canvas of the given size. This is simply with width/height of the canvas dividedby the number of cells in our grid world along each dimension.Then we iterate through our map and draw a rectangle in the corresponding position when the map has a wall listed as being there. The only extra thing to take care of is that the Javapainting coordinate system is in the top left corner, whereaswe've defined our map with a bottom left coordinate system, so we perform a coordinate system switch in the rendering as shown. Now lets create a painter for the OO-MDP agent class, which we'll represent as a gray circle in the word. This codewill look almost identical to our map painter code except instead of iterating through the map, we'll get the agent x and y position from the OO-MDP ObjectInstance our painter is provided and instead of painting a black rectangle we'll paint a gray circle. As before add the below class inside our ExampleGridWorld class. public class AgentPainter implements ObjectPainter{@Overridepublic void paintObject(Graphics2D g2, State s, ObjectInstance ob,float cWidth, float cHeight) {//agent will be filled in grayg2.setColor(Color.GRAY);//set up floats for the width and height of our domainfloat fWidth = ExampleGridWorld.this.map.length;float fHeight = ExampleGridWorld.this.map[0].length;//determine the width of a single cell on our canvas //such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;int ax = ob.getDiscValForAttribute(ATTX);int ay = ob.getDiscValForAttribute(ATTY);//left coordinate of cell on our canvasfloat rx = ax*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas //origin is in the top left instead of the bottom rightfloat ry = cHeight - height - ay*height;//paint the rectangleg2.fill(new Ellipse2D.Float(rx, ry, width, height));}} We'll also do the same for a location object, but we'll use a blue rectangle instead. public class LocationPainter implements ObjectPainter{@Overridepublic void paintObject(Graphics2D g2, State s, ObjectInstance ob,float cWidth, float cHeight) {//agent will be filled in blueg2.setColor(Color.BLUE);//set up floats for the width and height of our domainfloat fWidth = ExampleGridWorld.this.map.length;float fHeight = ExampleGridWorld.this.map[0].length;//determine the width of a single cell on our canvas //such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;int ax = ob.getDiscValForAttribute(ATTX);int ay = ob.getDiscValForAttribute(ATTY);//left coordinate of cell on our canvasfloat rx = ax*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas //origin is in the top left instead of the bottom rightfloat ry = cHeight - height - ay*height;//paint the rectangleg2.fill(new Rectangle2D.Float(rx, ry, width, height));}} Finally, we'll want to add some methods to our ExampleGridWorld domain generator to create a StateRenderLayer and correspondingVisualizer to hold it. The StateRenderLayer merely needs to be given a WallPainter instance and told to use a AgentPainter instance for objects of OO-MDP class agent and a LocationPainter instance for objects of OO-MDP class location. Once a StateRenderLayer object is created, a Visualizer object merely needs to be pointed to it. To do so, add the following methods to our ExampleGridWorld class. public StateRenderLayer getStateRenderLayer(){StateRenderLayer rl = new StateRenderLayer();rl.addStaticPainter(new WallPainter());rl.addObjectClassPainter(CLASSLOCATION, new LocationPainter());rl.addObjectClassPainter(CLASSAGENT, new AgentPainter());return rl;}public Visualizer getVisualizer(){return new Visualizer(this.getStateRenderLayer());} Note that in the getStateRenderLayer method we added the location object painter before the agent object painter. This implicitly tells the StateRenderLayer the order in which objects should be painted; first objects of class location and then objects of class agent. The result is that when an agent is at the same position as a location, the agent will be rendered on top of it. Now that we can construct a visualizer, lets swap out our TermainalExplorer in our main method for a VisualExplorer . The VisualExplorer can be controlled by manually typing in actions into a text field, but it's often easier to control the agent with the keyboard. To do so, we can specify a binding between a key press and an action name with the addKeyAction method. In this case, we'll set 'w' to correspond to north; 's' south; 'd' east; and 'a' west. Change your main method to now look like the below. public static void main(String [] args){ExampleGridWorld gen = new ExampleGridWorld();Domain domain = gen.generateDomain();State initialState = ExampleGridWorld.getExampleState(domain);//TerminalExplorer exp = new TerminalExplorer(domain);//exp.exploreFromState(initialState);Visualizer v = gen.getVisualizer();VisualExplorer exp = new VisualExplorer(domain, v, initialState);exp.addKeyAction(\"w\", ACTIONNORTH);exp.addKeyAction(\"s\", ACTIONSOUTH);exp.addKeyAction(\"d\", ACTIONEAST);exp.addKeyAction(\"a\", ACTIONWEST);exp.initGUI();} Now when you run your code, you'll be presented a visualization of the state and you can interact with it with the \"wasd\" keys, similar to what you see in the below image. Note that you may need to click on the image for it to begin accepting key presses. Remember, since we made movement stochastic, you may find the agent moving in unintended directions some of the time. Also note that when the agent enters the same position as the location object that in the bottom text box in the window you'll see \"at(agent0, location0)\" appear. This text box always lists all propositional functions that are true in the current state automatically. Next Part", "http://burlap.cs.brown.edu/tutorials_v1/bd/p3.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building a Domain Tutorials (v1) > Building a Domain > Part 3 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Previous Part | Next Part Defining GridWorld Object Classes To begin implementing our grid world domain in BURLAP, we will create a class that in this tutorial we will call ExampleGridWorld. Furthermore, we will make it implement the DomainGenerator interface, which is a common convention in BURLAP when developing domains and requires implementing the generateDomain() method. In that method, we will also create an SADomain object that will keep track of all of our attributes, object classes, etc. that we define. (Note that the Domain class that is returned by the method is the abstract superclass of SADomain. It is abstract because for stochastic games we will have a different domain subclass that contains different and shared information.) You should have code that looks like the below; to make things easier for the future, the below code has all of the library imports that you'll need for the rest of the tutorial. import java.awt.Color;import java.awt.Graphics2D;import java.awt.geom.Ellipse2D;import java.awt.geom.Rectangle2D;import java.util.ArrayList;import java.util.List;import burlap.oomdp.auxiliary.DomainGenerator;import burlap.oomdp.core.Attribute;import burlap.oomdp.core.Attribute.AttributeType;import burlap.oomdp.core.Domain;import burlap.oomdp.core.ObjectClass;import burlap.oomdp.core.ObjectInstance;import burlap.oomdp.core.PropositionalFunction;import burlap.oomdp.core.State;import burlap.oomdp.core.TerminalFunction;import burlap.oomdp.core.TransitionProbability;import burlap.oomdp.singleagent.Action;import burlap.oomdp.singleagent.GroundedAction;import burlap.oomdp.singleagent.RewardFunction;import burlap.oomdp.singleagent.SADomain;import burlap.oomdp.singleagent.explorer.TerminalExplorer;import burlap.oomdp.singleagent.explorer.VisualExplorer;import burlap.oomdp.visualizer.ObjectPainter;import burlap.oomdp.visualizer.StateRenderLayer;import burlap.oomdp.visualizer.StaticPainter;import burlap.oomdp.visualizer.Visualizer;public class ExampleGridWorld implements DomainGenerator {@Overridepublic Domain generateDomain() {SADomain domain = new SADomain();return domain;}} The first thing that we will want to decide in the construction of our domain is what the object classes and attributes that define the domain are. For our grid world, we will define two object classes: an agent class, to represent the agent in the world; and a location class, which we can use to refer to special places in the world. The location class isn't necessary to define grid world problems, but we're going to include it to help illustratehow to define propositional functions in BURLAP. Both the agent and location class will be defined by their x and y position in the 2D world. For convenience, it is often useful to define the names of all attributes, object classes, etc. that the domain definesas string constants so that they can be precisely referenced by code that uses the domain, so lets add those to our code now. public static final String ATTX = \"x\";public static final String ATTY = \"y\";public static final String CLASSAGENT = \"agent\";public static final String CLASSLOCATION = \"location\"; Next we will create the actual Attribute objects and the classes associated with them. Since grid worlds have discrete states, but our attributes represent numeric positions, we willset our attributes to be of type int. We will also construct a world that is 11x11 in size, so we will set the attribute limits to be from 0 to 10 inclusively. @Overridepublic Domain generateDomain() {SADomain domain = new SADomain();Attribute xatt = new Attribute(domain, ATTX, AttributeType.INT);xatt.setLims(0, 10);Attribute yatt = new Attribute(domain, ATTY, AttributeType.INT);yatt.setLims(0, 10);ObjectClass agentClass = new ObjectClass(domain, CLASSAGENT);agentClass.addAttribute(xatt);agentClass.addAttribute(yatt);ObjectClass locationClass = new ObjectClass(domain, CLASSLOCATION);locationClass.addAttribute(xatt);locationClass.addAttribute(yatt);return domain;} Notice how we never directly told the domain about the attributes or object classes that we created? That's because the constructor of the attributes and object classes will tell the domain about themselves automatically to streamline construction. With that code written, we're already finished defining the state representation of the domain! The next step will be to define actions. Defining GridWorld Actions Defining actions in BURLAP means specifying the actions the agent can take, their preconditions (if any), their parameters (if any), and their transition dynamics. We will construct four actions: north, south, east, and west. None of these actions will have preconditions and they will not take any parameters. The transition dynamics we define for them will depend on the location of walls in the world. We could have potentially made the walls objects of the OO-MDP themselves,but for simplifying the state representation we will keep the walls embedded in our transition dynamics without explicit state representation. To facilitate the definition of the transition dynamics, we will create a 2D int matrix specifying the location of walls in each cell. We will also create a world withthe same wall layout shown in the image at the beginning of this tutorial. To do so, add the following code. //ordered so first dimension is xprotected int [][] map = new int[][]{{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,0,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{1,0,1,1,1,1,1,1,0,1,1},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,0,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},}; Next we will create our actions. We will define north, south, east, and west actions that have a probability of 0.8 of going in the intended direction and a probability of 0.2 of going in any other direction. To create these actions, we will define a single subclass of the Action class that we will call Movement and instantiate it multiple times for each action. Subclassing Action requires us to implement the method performActionHelper, which is called whenever an action is applied and must return the resulting state from applying the action. We will also want to override the method getTransitions, which specifies the probability of transitioning to each possible next state when applying the action in the provided state (and with the provided parameters). Overriding this method is not required if the domain is not going to be used with planning or learning algorithms that require exact and fully enumerated transition dynamics, and for some domains, it may not even be possible to enumerate all possible outcomes. However, if you do not override the method and a planning or learning algorithm tries to use it, an UnsupportedOperation exception will be thrown. Since the number of possible outcomes is trivial to enumerate for our grid world and since we'd like to be able to use algorithms like Value Iteration that require the fully enumerated transition dynamics, we will implement the method. If our actions had preconditions and were only applicable in certain states, we would also have to override the applicableInState method. Since our actions can be taken anywhere, however, we will not override it, which has the default behavior of making the actions applicable everywhere. protected class Movement extends Action{@Overrideprotected State performActionHelper(State s, String[] params) {return null;}@Overridepublic List getTransitions(State s, String [] params){return null;}} So that we can reuse this Action class for each movement direction, lets define a data member that specifies the probability of going in each direction and let the intended direction (which will succeed with probability 0.8) be specified in the constructor, along with a name for the action and the domain to which it belongs. protected class Movement extends Action{//0: north; 1: south; 2:east; 3: westprotected double [] directionProbs = new double[4];public Movement(String actionName, Domain domain, int direction){super(actionName, domain, \"\");for(int i = 0; i < 4; i++){if(i == direction){directionProbs[i] = 0.8;}else{directionProbs[i] = 0.2/3.;}}}@Overrideprotected State performActionHelper(State s, String[] params) {return null;}@Overridepublic List<TransitionProbability> getTransitions(State s, String [] params){return null;}} Notice how we called a super constructor with the action name, domain, and empty quotes? Calling the super constructor will automatically connect the action with the domain object and set its name. The empty quotes are used to specify that this action takes no parameters. Now we'll want to start defining our performActionHelper and getTransitions methods. To do so, lets add a helper method for getting the result of moving in a given direction. As long as the cell is free (that is, there is no wall), the agent will move to that position; if there is a wall there, the agent will stay in the same place. This method will then return the resulting x and y position of the agent. protected int [] moveResult(int curX, int curY, int direction){//first get change in x and y from direction using 0: north; 1: south; 2:east; 3: westint xdelta = 0;int ydelta = 0;if(direction == 0){ydelta = 1;}else if(direction == 1){ydelta = -1;}else if(direction == 2){xdelta = 1;}else{xdelta = -1;}int nx = curX + xdelta;int ny = curY + ydelta;int width = ExampleGridWorld.this.map.length;int height = ExampleGridWorld.this.map[0].length;//make sure new position is valid (not a wall or out of bounds)if(nx < 0 || nx >= width || ny < 0 || ny >= height || ExampleGridWorld.this.map[nx][ny] == 1){nx = curX;ny = curY;}return new int[]{nx,ny};} With this helper method defined, all the performActionHelper method needs to do is determine the current position of the agent, sample from the direction distribution, call the moveResult method to get the new position, and set the agent attribute values to the new position. Getting the direction and setting the values can be performed by grabbing agent object instance in the state and using the pertinent value getter and setter methods. Since there is only ever one agent object instance in the state, we can retrieve the agent ObjectInstance using the getFirstObjectOfClass method that returns the first object instance of an object belonging to a specified class in the state. @Overrideprotected State performActionHelper(State s, String[] params) {//get agent and current positionObjectInstance agent = s.getFirstObjectOfClass(CLASSAGENT);int curX = agent.getDiscValForAttribute(ATTX);int curY = agent.getDiscValForAttribute(ATTY);//sample directon with random rolldouble r = Math.random();double sumProb = 0.;int dir = 0;for(int i = 0; i < this.directionProbs.length; i++){sumProb += this.directionProbs[i];if(r < sumProb){dir = i;break; //found direction}}//get resulting positionint [] newPos = this.moveResult(curX, curY, dir);//set the new positionagent.setValue(ATTX, newPos[0]);agent.setValue(ATTY, newPos[1]);//return the state we just modifiedreturn s;} Note You might be wondering why we can modify the state directly and then return it, since it seems like that might cause problems if the passed in State object was used elsewhere in a planning or learning algorithm. Notice how the method we are overriding has a \"Helper\" qualifier at the end and is marked as protected? That's because there is a public method called \"performAction\" that will first copy any input state and then pass the copied state to the performActionHelper method that we are overriding. This copying ensures that you're never modifying a State object that is used for something else. For the getTransition method, we'll do something similar, except in this case, we create a copy of the input state for each possible outcome, modify the copied state to the possible results, and return a List that couples the probability with each of those possible outcomes. In general, each possible outcome from a movement action is the result of the agent moving in each direction with the probability of the action making the agent move in that direction. However, moving in multiple directions may result in the agent not changing position at all if there are walls in those directions. Therefore, we should merge the result and probability of directions that result in the same outcome before returning our set of outcome states. @Overridepublic List<TransitionProbability> getTransitions(State s, String [] params){//get agent and current positionObjectInstance agent = s.getFirstObjectOfClass(CLASSAGENT);int curX = agent.getDiscValForAttribute(ATTX);int curY = agent.getDiscValForAttribute(ATTY);List<TransitionProbability> tps = new ArrayList<TransitionProbability>(4);TransitionProbability noChangeTransition = null;for(int i = 0; i < this.directionProbs.length; i++){int [] newPos = this.moveResult(curX, curY, i);if(newPos[0] != curX || newPos[1] != curY){//new possible outcomeState ns = s.copy();ObjectInstance nagent = ns.getFirstObjectOfClass(CLASSAGENT);nagent.setValue(ATTX, newPos[0]);nagent.setValue(ATTY, newPos[1]);//create transition probability object and add to our list of outcomestps.add(new TransitionProbability(ns, this.directionProbs[i]));}else{//this direction didn't lead anywhere new//if there are existing possible directions that wouldn't lead anywhere, //aggregate with themif(noChangeTransition != null){noChangeTransition.p += this.directionProbs[i];}else{//otherwise create this new state outcomenoChangeTransition = new TransitionProbability(s.copy(), this.directionProbs[i]);tps.add(noChangeTransition);}}}return tps;} With the Action class defined, we'll want to hook it up to our domain. First, lets add some string constants for the names of the actions. public static final String ACTIONNORTH = \"north\";public static final String ACTIONSOUTH = \"south\";public static final String ACTIONEAST = \"east\";public static final String ACTIONWEST = \"west\"; Then we just need to call the constructor in our generateDomain method. As with the object classes and attributes, calling the constructor will automatically tell our domain about it, so we don't need to do anything further. new Movement(ACTIONNORTH, domain, 0);new Movement(ACTIONSOUTH, domain, 1);new Movement(ACTIONEAST, domain, 2);new Movement(ACTIONWEST, domain, 3);; Defining Propositional Functions Although we have a functioning domain at this point, we're going to add an optional propositional function to it to demonstrate how to use them. The propositional function we will create is at(agent, location). Notice that it will take two parameters, one which is an OO-MDP object belonging to OO-MDP class \"agent\" and the other an OO-MDP object belonging to OO-MDP class \"location.\" The function should evaluate to true when the provided agent object's position is equal to the provided location object's position. To implement this function, we will need to subclass the PropositionalFunction class. Lets first create another string constant for the name of the function. public static final String PFAT = \"at\"; And then lets make the shell of the class implementation with a constructor. protected class AtLocation extends PropositionalFunction{public AtLocation(Domain domain){super(PFAT, domain, new String []{CLASSAGENT,CLASSLOCATION});}@Overridepublic boolean isTrue(State s, String[] params) {// TODO Auto-generated method stubreturn false;}} Inside the constructor we called a super constructor that takes as arguments the name of the propositional function, the domain with which it will be associated, and an array specifying the OO-MDP class types to which its parameters must adhere. Now lets implement the isTrue method, which is as simple as getting the object instances of the provided parameters and checking if the attributes are equal. The parameters that are provided to the method are the names (or identifiers) of the objects in the world that it's referencing, so we can retrieve the objects from the provided state object by simply querying for the object with the given identifier. @Overridepublic boolean isTrue(State s, String[] params) {ObjectInstance agent = s.getObject(params[0]);ObjectInstance location = s.getObject(params[1]);int ax = agent.getDiscValForAttribute(ATTX);int ay = agent.getDiscValForAttribute(ATTY);int lx = location.getDiscValForAttribute(ATTX);int ly = location.getDiscValForAttribute(ATTY);return ax == lx && ay == ly;} Finally, lets call the constructors from our generateDomain method. As before, the constructor will automatically tell the domain about the propositional function. Our final generateDomain method will look like the below. @Overridepublic Domain generateDomain() {SADomain domain = new SADomain();Attribute xatt = new Attribute(domain, ATTX, AttributeType.INT);xatt.setLims(0, 10);Attribute yatt = new Attribute(domain, ATTY, AttributeType.INT);yatt.setLims(0, 10);ObjectClass agentClass = new ObjectClass(domain, CLASSAGENT);agentClass.addAttribute(xatt);agentClass.addAttribute(yatt);ObjectClass locationClass = new ObjectClass(domain, CLASSLOCATION);locationClass.addAttribute(xatt);locationClass.addAttribute(yatt);new Movement(ACTIONNORTH, domain, 0);new Movement(ACTIONSOUTH, domain, 1);new Movement(ACTIONEAST, domain, 2);new Movement(ACTIONWEST, domain, 3);new AtLocation(domain);return domain;} Note Although we have defined a propositional function, you might be wondering how you can find all possible parameters in a state with which it can be evaluated. The PropositionalFunction super class provides a method for doing just this called getAllGroundedPropsForState(State) , which will return a list of GroundedProp objects that can be evaluated. A GroundedProp is simply a PropositionalFunction object reference and parameters with which to evaluate it. Similarly, if you want all possible GroundedProp objects for a list of different PropositionalFunction objects, you can use the PropositionalFunction static method getAllGroundedPropsForState(State) . Testing the Domain We now have a functional domain! However, it's probably important to test that the domain actually works as expected. By the end of this tutorial we will have created a visualizer for our domain that we can use to interactively visualize and test it, but we can also test it in the command line. To test our domain, lets first add a method to generate a state with the agent in the bottom left corner and a location object in the top right. public static State getExampleState(Domain domain){State s = new State();ObjectInstance agent = new ObjectInstance(domain.getObjectClass(CLASSAGENT), \"agent0\");agent.setValue(ATTX, 0);agent.setValue(ATTY, 0);ObjectInstance location = new ObjectInstance(domain.getObjectClass(CLASSLOCATION), \"location0\");location.setValue(ATTX, 10);location.setValue(ATTY, 10);s.addObject(agent);s.addObject(location);return s;} Note that we made this method static and had it take as a parameter the domain object. We made the method static because the domain object is only ever created once the generateDomain method is called and that method can produce different Domain objects each time it is called. (Although not especially important for our example, this is useful if you have parameterizable domains.) Since ObjectInstance objects have to belong to a specific ObjectClass, we have to have the have the corresponding domain object from which to retrieve the ObjectClass. In addition to taking an ObjectClass, the ObjectInstance constructor also takes as a parameter the name or identifier of the object instance. This name will be used to identify the object from other objects in the state and to further disambiguate it from multiple objects of the same class. This name is also what will be passed to the PropositionalFunction isTrue method parameters and for actions that are parameterized to objects (though in our Grid World, our Actions are not parameterized). Lets now add a main method that we will launch into to test our domain. To do the testing, we will make use the TerminalExplorer which lets us act as the agent through the command line. Create the main method as shown below. public static void main(String [] args){ExampleGridWorld gen = new ExampleGridWorld();Domain domain = gen.generateDomain();State initialState = ExampleGridWorld.getExampleState(domain);TerminalExplorer exp = new TerminalExplorer(domain);exp.exploreFromState(initialState);} When you run main in the command line/terminal you should see a print out describing the example state. If you now type the name of an action (such as \"north\") and hit enter, it will change state and print out the new state. Remember that our actions are stochastic, so 20% of the time you'll find yourself going in a different direction! While using the TerminalExplorer works for all domains that you might create, as your domains get more complex it be can be difficult to make sense of them from text alone. Having a visualizer makes understanding what's happening in your domain much easier. Furthermore, you can reuse a visualizer not just for interacting in the world yourself, but for visualizing results of learning and planning algorithms. In the next sections, we will walk through how to create a state visualizer for this domain. Next Part", "https://blog.cs.brown.edu/2019/09/24/alum-aimee-lucido-publishes-young-adult-novel-about-her-two-loves-coding-and-writing/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Alum Aimee Lucido Publishes A Novel About Her Two Loves, Coding And Writing Posted by Jesse Polhemus on Sept. 24, 2019 Click the links that follow for more news items about recent accomplishments by our alums. Brown CS alums are often known for the diversity of their career paths and pursuing multidisciplinary work, and Aimee Lucido is no exception. A former software engineer and continuing crossword puzzle creator (she's been featured five times by The New York Times ), she's recently finished a middle grade novel, Emmy in the Key of Code . The story of a 12-year-old girl finding her voice in programming class, it's been published by Houghton Mifflin Harcourt/Versify and is available today. \"It's the book of my heart,\" she says. \"In so many ways it feels like a culmination of everything that has ever mattered to me: music, friendships, family, and finally, the combination of writing and code.\" As an undergraduate, Aimee majored in both computer science and literary arts, and says that she spent much of her life during Brown and after wanting to pursue both tech and writing. \"In a way,\" she explains, \"I tried to make the real world mimic Brown's open curriculum.\" Already the recipient of wide-ranging praise and a starred Kirkus review, Aimee says that writing her novel taught her that coding and writing have more in common than she'd thought. \"When it comes down to it, both use words, symbols, and whitespace to convey meaning. Both are little more than a language used to encapsulate an idea, story or iPhone app.\" Initially intended as just a break from hours spent in the CIT, writing began to occupy more and more of Aimee's life, eventually leading her to augment her \"Real Job\" as a software engineer with an MFA in writing and, more recently, leaving her tech job entirely to focus on writing full time. \"Both are things that are such a part of me,\" she says, \"that combining them \u2013once I gave myself permission\u2013 felt as natural as breathing.\" You can read an excerpt from Emmy in the Key of Code and learn more about Aimee at her web site here . For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "http://burlap.cs.brown.edu/tutorials_v1/bpl/p1.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Basic Planning and Learning Tutorials (v1) > Basic Planning and Learning > Part 1 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A* Planning with Value Iteration Learning with Q-Learning Learning with Sarsa(\u03bb) Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Next Part You are viewing the tutorial for BURLAP 1; if you'd like the BURLAP 2 tutorial, go here . Introduction The purpose of this tutorial is to get you familiar with using some of the planning and learning algorithmsin BURLAP. Specifically, this tutorial will cover instantiating a GridWorld domain bundled with BURLAP,creating a task for it, having the task solved with Q-learning, Sarsa learning, BFS, DFS, A*, and ValueIteration. The tutorial will also show you how to visualize these results in various ways using tools in BURLAP. The take home message you should get from this tutorial is that using different planningand learning algoritms largely amounts to just changing the algorithm object you instantiate, with everythingelse being the same. You are encouraged to extend this tutorial on your own using some of the other planningand learning algorithms in BURLAP. At the conclusion section of this tutorial, you will find all of the code we created, so if you'd prefer to jumpt rightin, only coming back to this tutorial as questions arise, feel free to do so! Creating the class shell For this tutorial, we will start by making a class that has data members for all the domain and task relevantproperties. In the tutorial we will call this class \"BasicBehavior\" but feel free to name it to whatever you like.Since we will also be running the examples from this class, we'll include a main method. import burlap.behavior.singleagent.*;import burlap.domain.singleagent.gridworld.*;import burlap.oomdp.core.*;import burlap.oomdp.singleagent.*;import burlap.oomdp.singleagent.common.*;import burlap.behavior.statehashing.DiscreteStateHashFactory;public class BasicBehavior {GridWorldDomaingwdg;Domaindomain;StateParsersp;RewardFunctionrf;TerminalFunctiontf;StateConditionTestgoalCondition;StateinitialState;DiscreteStateHashFactoryhashingFactory;public static void main(String[] args) {//we'll fill this in later}} If you're already familiar with MDPs in general, the importance of some of these data members will beobvious. However, we will walk through in detail what data member is and why we're going to need it. GridWorldDomaingwdg This object is a DomainGenerator provided in the domains package. We will use thisobject to create a basic grid world domain for our demonstration. Domain domain The domain object is an fundamental OO-MDP object. The domain object defines a set ofattributes, object classes, propositional functions, and actions (along with the actions transition dynamics). Youcan imagine domain objects as holding information regarding how states in a problem are representedand how the physics of the problem work. StateParser sp A StateParser object is used to convert OO-MDP states to and from string representations. This is usefulif you want to be be able to record planning and learning results to files, which we will be doing in this tutorial. RewardFunction rf A RewardFunction is an object that returns a double valued reward for any given state-action-state sequence. This is a fundamental component of every MDP and its what an agent tries to maximize. That is, the goalof an agent is acquire as much reward from the world as possible. TerminalFunction tf A common form of MDPs are episodic MDPs: MDPs that end in some specific state or set of states. A typicalreason to define an episodic MDP is when there is a goal state the agent is trying to reach. In such cases, the goalstate is a terminal state, because once the agent reaches it, there is nothing left to do. Inversely, some states may be fail states that prevent the agent continuing; these too would be terminal states. There may also be other reasons to provide termination states, but whatever you reason may be, theTerminalFunction object defines which states are terminal states. StateConditionTest goalCondition Not all planning algorithms are designed to maximize reward functions. Manyare instead defined as search algorithms that seek action sequences to reach specific goal states. A StateConditionTest object operates muchlike a TerminalFunction, only it can be used as a means to specify any kind of state check. In this tutorial we willuse it to specify goal states for planning algorithms that search for action sequences to reach goals rather thanplanning algorithms that try to maximize reward. State initialState To perform any planning or learning, we will generally need to specify an initial statefrom which to perform it. An OO-MDP state consists of an arbitrary set of instantiated object classes from a givendomain. An instantiated object of an object class means that there is a value is defined for each attribute ofthe object class. A state may also consist of an arbitrary number of object instances for any given class, but insome domains you may typically only have one instance for each. In the GridWorld domain, for instance, there willbe one instance of the agent object (which is defined by an x and y position) and one instance of a location object(which is also defined by an x and y position),which will be used to specify a goal location where the agent needs to go. Not all planning algorithms directly care about an initial state. For instance, while classic planners are designedaround finding an action sequence from an initial state to a goal state, planners like Value Iteration (VI) are concernedwith finding a policy, a mapping from states to actions, that tells the agent how act in every conceivablestate in the world. Nevertheless, the BURLAP implementations of VI (and other complete policy-computing planning algorithms) will still require that an initial state isprovided to it for planning. The reason BURLAP's VI will ask for an initial state is because technically an OO-MDP'sstate space is infinite. Because an OO-MDP state consists of a set of objects, you can always imagine another stateby simply adding another instance of one of the objects in the domain. By passing to VI an initial state, however,it asks VI to be performed in world with some given initial number of objects instances with some initial set of values.BURLAP's VI will then find all reachable states from that initial state and use that as the effective state space for a whicha policy will be returned. Note Even when VI is passed an initial state it's possible for the state space to be infinite.For instance, perhaps there are actions in the domain that allow an indefinite number of new object instances to be created, or perhaps the valuesof object attributes are continuous with an infinite number of reachable values. The fact is that some problems are inherentlyinfinite in their state space and Value Iteration isn't an algorithm that can handle these kinds of problems. DiscreteStateHashFactory hasingFactory To perform planning and learning, there will need to be some wayto look up previously examined states in data structures and to do so efficiently will require some way to computehash codes for states and to compare them for equality. The DiscreteStateHashFactory provides a general means to do this for any discrete and non-relationalOO-MDP domain. A nice property of the DiscreteStateHashFactory object is that hashing results are invariantto specific object references. For instance, consider a state (s0) with block objects defined by spatial positioninformation. Now imagine a new state (s1) that is the result of swapping the positions of the blocks objects.Even though the object idenitifers associated with the block positions is different between s0 and s1, these really are the same state. The below illustration helps clarify this property. An advantageof the DiscreteStateHashFactory is that it will treat s0 and s1 identically; that is, it recognizesthat s0 == s1 and the same hash code will also be computed for each state. In BURLAP, we refer to this kindof state invariance as object identifier invariance . Note There may be some problems in which you do not want to use object identifier invariance. For instance, maybe the taskof a problem is to move a specific block to a specific location and it does matter which block is in that location.For such a task, using object identifier invariance will break the planning/learning algorithms ability to correctly findthe solution. In cases like these, a different state hashing factory should be used, such as NameDependentStateHashFactory . The Power of the StateHashFactory objects is that you can define your ownnew equality and hashing mechanisms for states and simply pass them along to your planning and learning algorithm. Next Part", "http://burlap.cs.brown.edu/tutorials_v1/bpl/p2.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Basic Planning and Learning Tutorials (v1) > Basic Planning and Learning > Part 2 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A* Planning with Value Iteration Learning with Q-Learning Learning with Sarsa(\u03bb) Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part | Next Part Initializing the data members Now that we have the structure of our class, we'll need to initialize our data membersto instances that will create our domain and define our task. First, create a default constructor. The first thing we'll do in the constructor is create our domain. public BasicBehavior(){gwdg = new GridWorldDomain(11, 11);gwdg.setMapToFourRooms(); domain = gwdg.generateDomain();//more to come...} The first line will create an 11x11 deterministic GridWorld. The second line sets up the map to a pre-canned layout:the four rooms layout. This domain layout was used in Option learning work from Sutton, Precup, and Singh (1999)and it presents a simple environment for us to do some tests. Alternatively, you could also define your ownmap layout by either passing the constructor a 2D integer array (with 1s specifying the cells with walls and 0sspecifying open cells), or you could simply specify the size of the domain like we did and then use the GridWorldobject's horiztonalWall and verticalWall methods to place walls on it. The GridWorld domain also supports1 dimensional walls between cells that you can set, if you'd prefer that kind of domain. For simplicity, we'll stick with thefour rooms layout. The third line will produce the Domain object for the GridWorld. Recall from the previouspart of the tutorial that Domain objects hold references to all the attributes, object classes, propositional functions, and actions(along with the actions' transition dynamics). In our GridWorld's case, there are two attributes, an X attribute anda Y attribute. There are also two classes: an AGENT class and a LOCATION class, each of which is defined by theX and Y attributes. While there could potentially be any number of AGENT object instantiations in a state, inthis domain we expect only one to ever be defined. The location objects will be used for points of interest.Specifically, we will use a single location object to represent a goal location. The GridWorld domain also definesfive propositional functions: agentAtLocation(AGENT, LOCATION); wallToNorth(AGENT); wallToSouth(AGENT);wallToEast(AGENT); wallToWest(AGENT). The first of those returns true when the specified AGENT object is at thesame location as the specified LOCATION object. The latter four propositional functions return true when there is a wall in the immediate cell of the defined direction of the specified AGENT object. Finally, the GridWorld domain defines four actions to move north, south, east, or west of the agent's current position.Although we could have told the GridWorldDomain generator to make these movements stochastic (that is, specify a probability in which the agent moves in an unintended direction), in our specific examplewe have left them as the default deterministic actions. If an agent moves into a wall, then its position does notchange. Although this domain instantiation has specific settings for grid worlds, differentdomains in BURLAP follow similar conventions. That is, you create an instanceof a domain generator; specify the parameters of the domain through mutators,and then finally extract the domain with a call to a generateDomain method.For example, the LunarLander domain generator lets you set properties like themaximum velocity and the force of gravity. Next we will create a state parser: sp = new GridWorldStateParser(domain); This state parser is a custom state parser that is part of the GridWorld package. We could have alsoused the UniversalStateParser , StateYAMLParser , or StateJSONParser , all which can provide state parsingfor any possible OO-MDP domain; however, the UniversalStateParser is verbose in its String output, which can beundesirable if you are recording thousands of learning results. In such cases, a custom parser, such as the onewe used here, can be more compact. The next thing we will want to do is define the actual task to be solved for this domain. We will do this by specifyinga reward function, a termination function, and a goal condition, the latter of which we will use exclusively for search-based deterministic planners that this tutorial will cover. In general,you can always define your own reward functions, terminal functions, and goal conditions by implementing the RewardFunction , TerminalFunction , and StateConditionTest interfaces, respectively, yourself. However, BURLAPalso comes packaged with a bunch of standard instances (as well as various domain-specific functions) that we will use here. If you want to know moreabout defining your own, consult the Building a Domain tutorial. rf = new UniformCostRF(); tf = new SinglePFTF(domain.getPropFunction(GridWorldDomain.PFATLOCATION)); goalCondition = new TFGoalCondition(tf); The first line will create a reward function that always returns -1 for every state-action-state transition.This might seem like a problem; it may seem like we would need to define a reward function that returns agreater reward when the agent reaches the goal (and there are existing reward function classes in the burlap.oomdp.singleagent.common package to do so). However, the next line which defines the termination function makesspecifying a reward function that returns a greater reward at the goal unnecessary. Before explaining why, lets examine thecreation of the TerminalFunction, which is specified as an instance of the SinglePFTF class (that stands for single propositional function terminal function). This is a classwhich is provided a single propositional function of the domain. Any state for which any object binding ofthat propositional function is true will be marked as a terminal state. In the constructor parameters, thepropositional function is retrieved by querying the domain for the propositional function with the name GridWorldDomain.PFATLOCATION which is a constant field of the Gridworld domain referencing the nameused for the atLocation propositional function. Note that if there were multiple LOCATION objects in the world,this TerminalFunction would mark any state in which the agent was at any of the locationsas a terminal state. Note We are using a terminal function and set of statesthat include location objects to highlight the OO-MDPway of working with objects and propositional functionsin BURLAP.If you'd prefer a more classic method of defininggrid world reward functions and terminal functionsbased on the location of the agent, you can do so usingthe GridWorldRewardFunction and GridWorldTerminalFunction classes that are part of the burlap.domain.singleagent.gridworld package. The final line sets up the goal condition to be synonymous with the termination function. Note that goal stateswill not always be the same as terminal states (there may beterminal states that are not goal states), but in this example they are. Let us now return to why our reward function does not need to return a greater reward when reaching the goal condition.Since we defined a terminal function that marks goal states as terminal states, it means that once an agent reachesthis state, it can no longer receive any reward. Since all rewards are negative,the best way to maximize reward will be to run to the goal as fast as possible, after which no more negative reward willbe received. The next step will be to define the initial state of this task. We could either do thisby creating an empty State object and then manually adding object instantiations for each object class,or we could use some methods of the GridWorldDomain class to facilitate the process. We will do the latterfor brevity, but if you want a more complete description of creating astate object by hand, consider looking in the Building a Domain tutorial. initialState = GridWorldDomain.getOneAgentOneLocationState(domain);GridWorldDomain.setAgent(initialState, 0, 0);GridWorldDomain.setLocation(initialState, 0, 10, 10); The first line will return a state object with a single instance of the AGENT class and a single instanceof the LOCATION class. The second line of code then sets the agent to be at position 0,0. The third line ofcode sets the location to be at position 10,10. The first zero you see in the parameters indicates whichLOCATION object index position to set. Since there is only one LOCATION object, we are setting the positionof the 0th indexed LOCATION object. The last part of the constructor is to define a method for computing state hash codes that can be used toefficiently look up state objects in various planning and learning algorithm data structures. Since this domain isdiscrete, we will use the common DiscreteStateHashFactory class. hashingFactory = new DiscreteStateHashFactory();hashingFactory.setAttributesForClass(GridWorldDomain.CLASSAGENT, domain.getObjectClass(GridWorldDomain.CLASSAGENT).attributeList); Note that the second line is optional. If we did not include that line, state hash codes would be computedwith respect to all attributes of all objects. However, in this task, the location object position will be constant,therefore, there is no reason to use the location object attributes for computing hash codes. Instead the hashing only needs to be computedwith respect to the X and Y attributes of the AGENT object, which will vary between states in the task. The second line of code tells the hashing factorythat we are going to manually define the set of attributes to be used for computing hashing codes and it tells itto use all of the attributes used in the AGENT class for hashing. We could have also told it to use only the Xattribute, or we could have specified attributes for other classes as well by adding additional calls to the setAttributesForClass method. Regardless of a choice of which attributes to usefor computing hash codes, it's important to note that when states are compared for equality, all attributeswill be checked for equality. For instance, if two states with different positions for the location objectwere compared with our above definition of the hashing factory, they would produce identical hash codes, butbe evaluated as different states. If you wanted to not only limit which attributes were used for computing hashcodes, but also which ones were used for checking state equality, then instead you should use theDiscreteMaskHashingFactory class. Note that GridWorldDomain.CLASSAGENT is a constant field of theGridWorldDomain class that points to the name of AGENT class. The domain.getObjectClass methodwill return the object class with the specified name and the attributeList field of will return the list ofattributes associated with that object class. At this point you should have initialized all of the data members for the class and the final constructor will look something like the below. public BasicBehavior(){//create the domaingwdg = new GridWorldDomain(11, 11);gwdg.setMapToFourRooms(); domain = gwdg.generateDomain();//create the state parsersp = new GridWorldStateParser(domain); //define the taskrf = new UniformCostRF(); tf = new SinglePFTF(domain.getPropFunction(GridWorldDomain.PFATLOCATION)); goalCondition = new TFGoalCondition(tf);//set up the initial state of the taskinitialState = GridWorldDomain.getOneAgentOneLocationState(domain);GridWorldDomain.setAgent(initialState, 0, 0);GridWorldDomain.setLocation(initialState, 0, 10, 10);//set up the state hashing systemhashingFactory = new DiscreteStateHashFactory();hashingFactory.setAttributesForClass(GridWorldDomain.CLASSAGENT, domain.getObjectClass(GridWorldDomain.CLASSAGENT).attributeList); } Setting up a result visualizer Before we get to actually running planning and learning algorithms, we're going to want a way to visualizethe results that they generate. While there are a few different ways to do this, for now we willdefine an offline visualizer that will allow us to run planning or learning completely, and then visualizethe results after it's finished. Offline visualization has the advantage of not bogging down the runtime of planning/learning algorithms with time allocated for visualization. To create our offline visualizer, we will need to define a state visualizer and pass it to an EpisodeSequenceVisualizer . To do so, first add the following imports. import burlap.oomdp.visualizer.Visualizer;import burlap.behavior.singleagent.EpisodeSequenceVisualizer; Then create the below method. public void visualize(String outputPath){Visualizer v = GridWorldVisualizer.getVisualizer(gwdg.getMap());EpisodeSequenceVisualizer evis = new EpisodeSequenceVisualizer(v, domain, sp, outputPath);} Note that the outputPath parameter specifies the directory where our planning/learning results were stored(well get to this when we actually apply a planning/learning algorithm). In order to visualize states, the domain will need to have a Visualizer defined for it, because it is impossible to tell how a domain should be visualized byattributes alone! In this case, however, a class to generate a GridWorldDomain Visualizer, called GridWorldVisualizer already exists as part of the domains package. This specific Visualizer class willrequire the 2D int array specifying the layout of the map (since different grid worldscan use different layouts). This map is retrieved from our GridWorldDomain generator object using the getMap() method. The final line will construct and load the EpisodeSequenceVisualizer. Note that in order to visualize episoderesults with this class, you will need to pass it a visualizer, the domain, the state parser (which will be usedto extract the states out of stored files), and the path to which all the episodes you wish to visualize are located.Later in this tutorial, we will examine how to use the GUI of the EpisdoeSequenceVisualizer. Before moving on to the next part of the tutorial, lets also hook up our class constructor and visualizer methodto the main class. public static void main(String[] args) {BasicBehavior example = new BasicBehavior();String outputPath = \"output/\"; //directory to record results//we will call planning and learning algorithms here//run the visualizerexample.visualize(outputPath);} Note that you can set the output path to whatever you want. If it doesn't already exist, the codethat will follow will automatically create it for you. Next Part", "http://burlap.cs.brown.edu/tutorials_v1/bpl/p4.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Basic Planning and Learning Tutorials (v1) > Basic Planning and Learning > Part 4 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A* Planning with Value Iteration Learning with Q-Learning Learning with Sarsa(\u03bb) Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part | Next Part Planning with Value Iteration A common stochastic planner is Value Iteration (VI). An advantage of VI is that it will compute thepolicy for the entire state space that is reachable from the initial state thatis passed to the planFromState method. To set up a VI planner, define the following method. public void ValueIterationExample(String outputPath){if(!outputPath.endsWith(\"/\")){outputPath = outputPath + \"/\";}OOMDPPlanner planner = new ValueIteration(domain, rf, tf, 0.99, hashingFactory, 0.001, 100);planner.planFromState(initialState);//create a Q-greedy policy from the plannerPolicy p = new GreedyQPolicy((QComputablePlanner)planner);//record the plan results to a filep.evaluateBehavior(initialState, rf, tf).writeToFile(outputPath + \"planResult\", sp);} VI is a planning method defined for the classic MDP formalism, so unlike the previousdeterministic planners, its constructor takes as input the reward function and termination function,rather than a goal condition. VI also takes as a parameter a discount factor which specifies how much future rewards are favored over immediate rewards. In this case,a fairly large value of 0.99 is set (which means the agent will prefer later future rewards almost as much asimmediate rewards). The last two parameters to the constructor specify stopping conditions for theplanning. The second to last parameter specifies that when the maximumchange in the value function of any state is less than that specified threshold value (0.001 in this case), planning will stop. The last parameter specifies a maximumnumber of updates for each state that can happen before planning is stopped (100 in this case), regardlessof whether the maximum value function change threshold was crossed. Since VI is a stochastic planning algorithm, rather than a deterministic one like the previous algorithms weused, we cannot capture its planning results in a SDPlannerPolicy Policy class. Instead, a policy can be derivedfrom the value function the planner estimates for each state using the GreedyQPolicy class that canbe defined for any planner that adheres to the QComputablePlanner interface, which the VI algorithm does. Once the solution is captured in a Policy class object, the results can be captured and visualized in the same way. Trysetting the main method to call our newly defined VI example method now. Learning with Q-Learning All of the previous examples were examples of using planning algorithms to solve our task. In this section,we will diverge from that and use a learning algorithm, Q-learning, to solve the task. Ultimately, learningalgorithms are utilized in much the same way as planning algorithms, except you run will run multipleepisodes of learning to solve it (or one very long episode if it is a continuing task rather than an episodictask). The method you should define to utilize Q-learning is shown below. public void QLearningExample(String outputPath){if(!outputPath.endsWith(\"/\")){outputPath = outputPath + \"/\";}//creating the learning algorithm object; discount= 0.99; initialQ=0.0; learning rate=0.9LearningAgent agent = new QLearning(domain, rf, tf, 0.99, hashingFactory, 0., 0.9);//run learning for 100 episodesfor(int i = 0; i < 100; i++){EpisodeAnalysis ea = agent.runLearningEpisodeFrom(initialState);ea.writeToFile(String.format(\"%se%03d\", outputPath, i), sp); System.out.println(i + \": \" + ea.numTimeSteps());}} Lets first look at the constructor. Rather than a planning instance, we're creating a LearningAgent instance which provides some methods for learning. QLearning is an instance of the LearningAgent classand like the Value Iteration planner, takes a parameters the reward function, termination function, anddiscount factor rather than a goal condition. The last two parameters of the constructor represent theinitial Q-value to use for previously untaken state-action pairs (which we set to 0.0) and the last parameteris the learning rate, which we set fairly high since this is a simple deterministic task. Note that thisconstructor will by default set Q-learning to use a 0.1 epsilon greedy policy. There are other constructorsthat allow you to set which learning policy to use and there is also a mutator that allows you to set itif you'd like to use a different policy. Alternatively, you could also pass Q-learning an object thatspecifies how the Q-value for each state-action pair should be initialized, rather than initializing them all to the samevalue as we did here. For this tutorial, we will not bother with that, however. With the QLearning instance created, next we will run learning episodes rather than tell it to plan a solution.To make sure a decent solution is learned, we will let learning run for 100 episodes, so we set up a loop to doso. To run a learning episode, we call the method runLearningEpisodeFrom on the LearningAgent instanceand pass it the initial state from which it should begin the learning episode. Since this method will performlearning for an entire episode, the method will return an EpisodeAnalysis object that stores the resultsof the episode. Once we have this episode, we simple save it to a file like we did the planning results in previousexamples (with care to give each episode a different name so that we can view them all). We also added a lineto print the number of steps taken in each learning episode to the terminal so that we can follow its overallprogress as it learns. After that, you can call this method from your main method and run the results! This time, in theEpisodeSequenceVisualizer launcher you will find there are 100 episode files in the list, one for eachepisode of learning that occurred. You should find that in the earlier episodes behavior was quite bad, butas the agent experiences the world, its performance became better. You may find that even after a large amountof learning that the behavior is slightly random; this randomness is a result of learning using the epsilon greedypolicy which always takes a random action with some probability. Alternatively, you could also capture the finallearning results in a GreedyQPolicy like we did with VI and record those results, instead of the resultswith the learning policy. Note While QLearning adheres to the LearningAgent interface, it is also aninstance of the OOMDPPlanner, which means we could have called the planFromState method on it. For the QLearningalgorithm, the planFromState method will run some number of learning episodes automatically for you. By default it will only run one (which is unlikely to yield very good results!), but you can adjust the number of episodesit would run, similar to how the VI planner decides to stop planning. Specifically, you can set a maximum number of learningepisodes to run with the setMaxEpisodesForPlanning method, or you can specify a Q-value changethreshold with the setMaxQChangeForPlanningTerminaiton method that will terminate planning when the maximum Q-value change within an episode less than the threshold. Learning with Sarsa(\u03bb) A similar learning algorithm to Q-learning is Sarsa(\u03bb). The first difference between the twoalgorithms is that Sarsa(\u03bb) updates Q-values with respect to the Q-value of the next action taken,rather than the maximum Q-value of the next state (see Wikipedia for more information). The second, and larger, difference is that at every time step, Sarsa(\u03bb) will also update the Q-valuesfor state-action pairs experienced previously in an episode with respect to the amount specified by \u03bb and how long ago the experiences occurred. Define the below method to solve ourtask with Sarsa(\u03bb). public void SarsaLearningExample(String outputPath){if(!outputPath.endsWith(\"/\")){outputPath = outputPath + \"/\";}//discount= 0.99; initialQ=0.0; learning rate=0.5; lambda=1.0LearningAgent agent = new SarsaLam(domain, rf, tf, 0.99, hashingFactory, 0., 0.5, 1.0);//run learning for 100 episodesfor(int i = 0; i < 100; i++){EpisodeAnalysis ea = agent.runLearningEpisodeFrom(initialState);ea.writeToFile(String.format(\"%se%03d\", outputPath, i), sp);System.out.println(i + \": \" + ea.numTimeSteps());}} You will notice that this method looks pretty identical to the Q-learning example, except this timea SarsaLam instance is constructed. Additionally, we lowered the learning rate to 0.5 (typicallyyou should use lower learning rates when you have a higher value of \u03bb). The last parameter ofthe constructor is the \u03bb value which we set to 1.0. A value of \u03bb=1.0 effectively makes algorithm run anonline Monte Carlo in which the effects of all future interactions are fully considered in updating each Q-valueof an episode. Otherwise, the rest is the same; you can call this method from the main method and give it shot! You should findthat learning is much faster than Q-learning when the higher value of \u03bb is used. Like QLearning, theSarsaLam instance also supports the planning method and the conditions for planning termination can be set in the sameway (SarsaLam is actually a subclass of QLearning). Next Part", "http://burlap.cs.brown.edu/tutorials_v1/bpl/p3.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Basic Planning and Learning Tutorials (v1) > Basic Planning and Learning > Part 3 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A* Planning with Value Iteration Learning with Q-Learning Learning with Sarsa(\u03bb) Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part | Next Part Planning with BFS One of the most basic deterministic planning algorithms is breadth-first search, which we will demonstrate first. Since we willbe testing a number of different planning and learning algorithms in this tutorial, we will define a separate methodfor using each planning or learning algorithm and then you can simply select which one you want to try in the mainmethod of the class. We will also pass each of these methods the output path to record itsresults. Before we begin, lets import a few more packages and classes that we will use for all the planning and learningalgorithms. import burlap.behavior.singleagent.learning.*;import burlap.behavior.singleagent.learning.tdmethods.*;import burlap.behavior.singleagent.planning.*;import burlap.behavior.singleagent.planning.commonpolicies.GreedyQPolicy;import burlap.behavior.singleagent.planning.deterministic.*;import burlap.behavior.singleagent.planning.deterministic.informed.Heuristic;import burlap.behavior.singleagent.planning.deterministic.informed.astar.AStar;import burlap.behavior.singleagent.planning.deterministic.uninformed.bfs.BFS;import burlap.behavior.singleagent.planning.deterministic.uninformed.dfs.DFS;import burlap.behavior.singleagent.planning.stochastic.valueiteration.ValueIteration; With those classes imported, lets start by defining the BFS method. public void BFSExample(String outputPath){if(!outputPath.endsWith(\"/\")){outputPath = outputPath + \"/\";}//BFS ignores reward; it just searches for a goal condition satisfying stateDeterministicPlanner planner = new BFS(domain, goalCondition, hashingFactory); planner.planFromState(initialState);//capture the computed plan in a partial policyPolicy p = new SDPlannerPolicy(planner);//record the plan results to a filep.evaluateBehavior(initialState, rf, tf).writeToFile(outputPath + \"planResult\", sp);} The first 'if' condition regarding the outputPath is just to make sure the string is well formed and ends with a '/'and is not very important. The next part of the method actually creates an instance of the BFS planning algorithm, whichitself is a subclass of the DeterministicPlanner class. To instantiate BFS, it only requires a reference to the domain,the goal condition for which it should search, and the hashing factory. Planning is then performed by simply callingthe planFromState method on the planner and passing it the initial state form which it should plan. After thismethod completes, the plan will be stored inside the BFS object. It might seem a little strange that this methoddoes not simply return a sequence of actions or something of the sort. The reason it does not is becausenot all planning and learning algorithms compute a sequence of actions. In particular, stochastic planners and plannersthat compute solutions for non-terminating tasks compute a policy rather than a sequence of actions. Because theDeterministicPlanner class is also a subclass of the OOMDPPlanner class, which is used as a superclass for allplanning algorithms, the common planFromState method does not return anything. Since the planFromState method does not explicitly return the plan results, we will instead capture it using aPolicy class, which is more general for capturing solutions with any number of planners and allows flexibility indetermining how the solution is captured. For capturing the plan solution of deterministic planners, the SDPlannerPolicy class may be used, whose constructor takes as a parameter a DeterministicPlanner object. Sincemany deterministic planners will compute a sequence of actions to take from the initialstate, the SDPlannerPolicy will only be defined for states along the path to the solution. If you wanted somethingslightly more general that will return an answer for states not on the solution path,you could instead use the DDPlannerPolicy class which will compute the solution using the specifiedplanner if the planner had not yet computed the solution for the state for which the policy was queried. Once you have a Policy object, you can extract an entire episode from it by calling the evaluateBehavior method. There are a few different versions of the evaluateBehavior method which take different parameters to determine theanalysis and stopping criteria. In this case, however, we are passing it the initial state from which the policy shouldstart being followed, the reward function used to assess the performance and the the termination function whichspecifies when the policy should stop. The method will return an EpisodeAnalysis object which will containall of the states visited, actions taken, and rewards received when following that policy. You can investigate these individual elements of the episode if you like,but for this tutorial we're just going to save the results of this episode to a file and then use the offlinevisualizer we previously defined to view it. An EpisodeAnalysis objectcan be written to a file by calling the writeToFile method on it and passing it a path to the file andthe state parser to use.Note that the method will automatically append a '.episode' extension to the file path if you did not specify it yourself. And that's all you need to code to plan with BFS on a defined domain and task! Using the EpisodeSequenceVisualizer GUI Now that the method to perform planning with BFS is defined, add a method call to it in your main method. public static void main(String[] args) {BasicBehavior example = new BasicBehavior();String outputPath = \"output/\"; //directory to record results//run exampleexample.BFSExample(outputPath);//run the visualizerexample.visualize(outputPath);} And with the planning method hooked up, run the code! Because the task is simple, BFS should find a solution veryquickly and print to the standard output the number of nodes it expanded in its search. Following that, the GUIshould be launched for viewing the EpisodeAnalysis object that was recorded to a file. You should see something like the belowimage appear. The main panel in the center of the window is used to render the current state selected. The text box at thebottom of the window will list all of the propositional functions that are true in that state. The leftmostlist on the right side of the window lists all of the episode files that were recorded in the directory passed to theEpisodeSequenceVisualizer constructor. After selecting one of those instances, the list of actions taken in theepisode are listed on the right-most list. Note that the actioncorresponds to the action that will be taken in the statethat is currently visualized, so the result of the actionwill be seen in the next state. In the GridWorldDomain visualizer, the black cells represent walls, the grey circlerepresents the agent, and the blue cell represents the location object that we made. Planning with DFS Another common search-based planning algorithm is depth-first search (DFS). Define the below method to providea means to solve the task with DFS. public void DFSExample(String outputPath){if(!outputPath.endsWith(\"/\")){outputPath = outputPath + \"/\";}//DFS ignores reward; it just searches for a goal condition satisfying stateDeterministicPlanner planner = new DFS(domain, goalCondition, hashingFactory);planner.planFromState(initialState);//capture the computed plan in a partial policyPolicy p = new SDPlannerPolicy(planner);//record the plan results to a filep.evaluateBehavior(initialState, rf, tf).writeToFile(outputPath + \"planResult\", sp);} You will notice that the code for DFS is effectively identical to the previous BFS code that we wrote, only this timethe DeterministicPlanner is instantiated with a DFS object instead of BFS object. DFS has a number of other constructorsthat allow you to specify other parameters such a depth limit, or maintaining a closed list. Feel freeto experiment with them. After you have defined the method, you can call it from the main method like we did the BFS method and visualize theresults in the same way. Since DFS is not an optimal planner, it is likely that the solution it gives you will bemuch worse than the one BFS gave you! Planning with A* One of the most well known optimal search-based planning algorithms is A*. A* is an informed planner because it takesas input an admissible heuristic which estimates the cost to the goal from any given state. We can also use A* to plan a solution for our taskas long as we also take the additional step of defining a heuristic to use. The below code defines a methodfor using A* with a Manhattan distance to goal heuristic. public void AStarExample(String outputPath){if(!outputPath.endsWith(\"/\")){outputPath = outputPath + \"/\";}Heuristic mdistHeuristic = new Heuristic() {@Overridepublic double h(State s) {String an = GridWorldDomain.CLASSAGENT;String ln = GridWorldDomain.CLASSLOCATION;ObjectInstance agent = s.getObjectsOfTrueClass(an).get(0); ObjectInstance location = s.getObjectsOfTrueClass(ln).get(0); //get agent positionint ax = agent.getDiscValForAttribute(GridWorldDomain.ATTX);int ay = agent.getDiscValForAttribute(GridWorldDomain.ATTY);//get location positionint lx = location.getDiscValForAttribute(GridWorldDomain.ATTX);int ly = location.getDiscValForAttribute(GridWorldDomain.ATTY);//compute Manhattan distancedouble mdist = Math.abs(ax-lx) + Math.abs(ay-ly);return -mdist;}};//provide A* the heuristic as well as the reward function so that it can keep//track of the actual costDeterministicPlanner planner = new AStar(domain, rf, goalCondition, hashingFactory, mdistHeuristic);planner.planFromState(initialState);//capture the computed plan in a partial policyPolicy p = new SDPlannerPolicy(planner);//record the plan results to a filep.evaluateBehavior(initialState, rf, tf).writeToFile(outputPath + \"planResult\", sp);} There are two main differences between this method and the methods that we wrote for BFS and DFSplanning. The smaller difference is that the A* constructor takes the reward function andheuristic as parameters. The reward function is needed because it is what A* uses to keep trackof the actual cost of any path it is exploring. Note A* is an algorithm that operates on costs and is not an algorithm that can workwith negative costs. BURLAP in general represents state-action evaluations as rewards ,rather than costs. However, a cost can be represented as a negative reward; therefore,the reward function provided to A* should return negative values. If the rewardfunction returns any positive values, A* will not function properly. Since our example's reward functionreturns only negative values (it returns -1 for every state-action pair), our reward function will workfine with A*. The bigger difference between the previous planning code and A* is in defining theheuristic, which we will explain in more detail. First note that the heuristic follows a standard interface for which we have may an anonymous java class. The h method of the classis passed a state object and the method should return the estimated reward to the goal fromthat state. Since we have opted to use the Manhattan distance as our heuristic, this will involvecomputing the distance between the agent position and the location position (for which we will assumethere is only one). To compute this difference, the method will first need to extract the agentobject instance and the location object instance out of the state, which is done in lines 16 and 17.Specifically, the getObjectsOfTrueClass method of a state will return the list of objectsin the state that belong to the class with the specified name. Since the task we are solving willonly have one agent object and one location object, we can then just return the 0th indexedobjects in each of those respective lists. Lines 20-25 then extract the integer values for theX and Y attributes of both objects. Once those attribute values are retrieved, the Manhattan distanceis computed and returned in lines 28-30. Note that the negative distance is returned, because our reward functionreturns -1 for each step. With the rest of the code being the same, you can have the main method call the A* method for planningand view the results in the usual way! Next Part", "http://burlap.cs.brown.edu/tutorials_v1/bpl/p6.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Basic Planning and Learning Tutorials (v1) > Basic Planning and Learning > Part 6 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A* Planning with Value Iteration Learning with Q-Learning Learning with Sarsa(\u03bb) Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part Experimenter Tools and Performance Plotting In the previous section you learned how to use an ActionObserver to perform live visualization of the agentin the state space as it was learning. In this section we will make use another ActionObserver calledPerformancePlotter to record a learning algorithm's performance and compare it to another learning algorithm. ThePerformacnePlotter has a lot of powerful tools to display lots of important experimental results. To streamlinethe process, we will make use of the LearningAlgorithmExperimenter class, which is convenient for comparingthe performance of multiple learning algorithms over many trials. If you'd prefer to run your own experiment using adifferent design flow, however, you could make use of the PerformancePlotter directly yourself. To demonstrate the LearningAlgorithmExperimenter, we will compare the learning performance of a Q-learning algorithmwith the performance of a SARSA(\u03bb) algorithm. To make the results a bit more interesting to visualize,we will also use a different reward function than we have been that returns a reward of 5 when the goal is reached and -0.1for every other step. First, add the following imports: import burlap.oomdp.auxiliary.StateGenerator;import burlap.oomdp.auxiliary.common.ConstantStateGenerator;import burlap.behavior.singleagent.auxiliary.performance.LearningAlgorithmExperimenter;import burlap.behavior.singleagent.auxiliary.performance.PerformanceMetric;import burlap.behavior.singleagent.auxiliary.performance.TrialMode; Lets then begin by adding a new method to our BasicBehavior class to call totest the experimenter tools. Inside the method, we will setup the new reward function using aninstance of the GoalBasedRF which takes a StateCondition test object to specify goal conditions (which we have already set up previously in the tutorial for our search algorithms like BFS), a goal reward, and a default reward for all non-goal states. public void experimenterAndPlotter(){//custom reward function for more interesting resultsfinal RewardFunction rf = new GoalBasedRF(this.goalCondition, 5., -0.1);} For the LearningAlgorithmExperimenter to report an average performance of each algorithm,it will test the algorithm over multiple trials. Therefore, at the start of each trial a cleanagent instance of the algorithm without knowledge of any of the previous trials must be generated. To be able to easily get a clean version of each agent the LearningAlgorithmExperimenter will request a sequence of LearningAgentFactory objects thatcan be used to generate a clean version of each agent on demand. In the following code, we create aLearningAgentFactory for a Q-learning algorithm and a SARSA(\u03bb) algorithm. /** * Create factories for Q-learning agent and SARSA agent to compare */LearningAgentFactory qLearningFactory = new LearningAgentFactory() {@Overridepublic String getAgentName() {return \"Q-learning\";}@Overridepublic LearningAgent generateAgent() {return new QLearning(domain, rf, tf, 0.99, hashingFactory, 0.3, 0.1);}};LearningAgentFactory sarsaLearningFactory = new LearningAgentFactory() {@Overridepublic String getAgentName() {return \"SARSA\";}@Overridepublic LearningAgent generateAgent() {return new SarsaLam(domain, rf, tf, 0.99, hashingFactory, 0.0, 0.1, 1.);}}; Note that the factory also requires a getAgentName() method to be implemented. The LearningAgentExperimenter classwill use this name to label the results of each learning algorithm's performance. For experimentation, the LearningAlgorithmExperimenter will also need to able to generate a new state for the beginningof each episode. In some tasks we might consider generating a random start state for each episode, but for simplifyingpurposes we will consider a task that always starts in the bottom left hand corner of the world, like we didin our previous planning and learning examples of the this tutorial. We can make a state generator that alwaysreturns the same initial state using the BURLAP provided ConstantStateGenerator. StateGenerator sg = new ConstantStateGenerator(this.initialState); With the task and learning algorithms now decided, we are just about ready to create our experimenter, but firstwe will need to decide how many trials we want to test, the length of the trials, and what performance data wewant to plot. There are six possible performance metrics we could plot: cumulative reward per step, cumulative reward per episode, average reward per episode, median reward per episode, cumulative steps per episode, and steps per episode. Furthermore, we could also have our plotter display the results from the most recent trial only,the average performance across all trials, or both. For this tutorial, we will plot both the most recent trial andaverage trial performance for the cumulative steps per episode and the average reward per episode. We will alsotest the algorithms for 10 trials that last 100 episodes each. The below code will create our experimenter,start it, and also save all the data for all six metrics to CSV files. LearningAlgorithmExperimenter exp = new LearningAlgorithmExperimenter(this.domain, rf, sg, 10, 100, qLearningFactory, sarsaLearningFactory);exp.setUpPlottingConfiguration(500, 250, 2, 1000, TrialMode.MOSTRECENTANDAVERAGE, PerformanceMetric.CUMULATIVESTEPSPEREPISODE, PerformanceMetric.AVERAGEEPISODEREWARD);exp.startExperiment();exp.writeStepAndEpisodeDataToCSV(\"expData\"); Note that in the constructor, the LearningAgent factories are the last parameters, of whicha variable number of factories could be provided; we could have tested just one agent, or we could have tested many more, but thereshould naturally always be at least one LearningAgentFactory provided. The other important part of the code is the setUpPlottingConfiguration method, which is used to define what resultsare plotted and how they are displayed. The first four parameters specify a plot's width and height, the number of columnsof plots, and the maximum window height. In this case, plots are set to be 500x200, with two columns of plots. Plotsare placed columns first, wrapping down to a new row as needed. The window size will be scaled to the width of plots times the number of columns; the height will scale to the height of the plots times the number of rows, unless thatheight is greater than the maximum window height, in which case the plots will be placed in a scroll view. The nextparameter specifies whether to show plots for only the most recent trial, the average performance over all trials, orboth. We have selected to show both. The remaining parameters are variable in size and specify which performance metrics will be plotted. The order of the performance metrics providedalso dictates the order that the plots will fill the window (again, filling columns first). The startExperiment method begins the experiment which will run all trials for all learning algorithms provided. Once you point our BasicBevhavior main method to the new method we've created and run the code, A GUI should appear with the plots requested,displaying the performance as it is available. When the experiment is complete, you should be left with an image like the below. In the trial average plots, you'll note that a translucent filled area around each of the curves is present. This filledarea shows the 95% confidence interval. You can change the significance level used before running the experimentusing the setPlotCISignificance method. Note that these plots are not static and you can interact with them. If you click drag in a region, it will cause the plotto zoom into the selected area. If you right click, you'll find a number of other options that you can set, includingchanging the labels. Another important feature you'll see from the contextual menu is an option to save plot image to disk. Since we also told the LearningAlgorithmExperimenter object to save the data to csv files, you should find two files that it created:expDataSteps.csv and expDataEpisodes.csv. The first contains all trial data for the cumulative reward per stepmetric. The latter contains all of the episode-wise metric data (even for the metrics that we did not plot). Thesefiles will make interacting with the data in another program, such as R, convenient. Conclusion This ends our tutorial on implementing basic planning and learning algorithms in BURLAP. There areother planning and learning algorithms in BURLAP, but hopefully this tutorial has explained the core conceptswell enough that you should be able to try different algorithms easily. As a future exercise, we encourage youto try just that within this code you've created! The complete set of code that we wrote in this tutorial is shownbelow for your convenience. You can also download the .java file direction from here . import java.awt.Color;import java.util.List;import burlap.behavior.singleagent.*;import burlap.domain.singleagent.gridworld.*;import burlap.oomdp.core.*;import burlap.oomdp.singleagent.*;import burlap.oomdp.singleagent.common.*;import burlap.behavior.statehashing.DiscreteStateHashFactory;import burlap.behavior.singleagent.learning.*;import burlap.behavior.singleagent.learning.tdmethods.*;import burlap.behavior.singleagent.planning.*;import burlap.behavior.singleagent.planning.commonpolicies.GreedyQPolicy;import burlap.behavior.singleagent.planning.deterministic.*;import burlap.behavior.singleagent.planning.deterministic.informed.Heuristic;import burlap.behavior.singleagent.planning.deterministic.informed.astar.AStar;import burlap.behavior.singleagent.planning.deterministic.uninformed.bfs.BFS;import burlap.behavior.singleagent.planning.deterministic.uninformed.dfs.DFS;import burlap.behavior.singleagent.planning.stochastic.valueiteration.ValueIteration;import burlap.oomdp.visualizer.Visualizer;import burlap.oomdp.auxiliary.StateGenerator;import burlap.oomdp.auxiliary.StateParser;import burlap.oomdp.auxiliary.common.ConstantStateGenerator;import burlap.behavior.singleagent.EpisodeSequenceVisualizer;import burlap.behavior.singleagent.auxiliary.StateReachability;import burlap.behavior.singleagent.auxiliary.performance.LearningAlgorithmExperimenter;import burlap.behavior.singleagent.auxiliary.performance.PerformanceMetric;import burlap.behavior.singleagent.auxiliary.performance.TrialMode;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.ValueFunctionVisualizerGUI;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.*;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.PolicyGlyphPainter2D.PolicyGlyphRenderStyle;import burlap.oomdp.singleagent.common.VisualActionObserver;public class BasicBehavior {GridWorldDomain gwdg;Domaindomain;StateParser sp;RewardFunction rf;TerminalFunctiontf;StateConditionTestgoalCondition;State initialState;DiscreteStateHashFactoryhashingFactory;public static void main(String[] args) {BasicBehavior example = new BasicBehavior();String outputPath = \"output/\"; //uncomment the example you want to see (and comment-out the rest)example.BFSExample(outputPath);//example.DFSExample(outputPath);//example.AStarExample(outputPath);//example.ValueIterationExample(outputPath);//example.QLearningExample(outputPath);//example.SarsaLearningExample(outputPath);//example.experimenterAndPlotter();//run the visualizer (only use if you don't use the experiment plotter example)example.visualize(outputPath);}public BasicBehavior(){//create the domaingwdg = new GridWorldDomain(11, 11);gwdg.setMapToFourRooms(); domain = gwdg.generateDomain();//create the state parsersp = new GridWorldStateParser(domain); //define the taskrf = new UniformCostRF(); tf = new SinglePFTF(domain.getPropFunction(GridWorldDomain.PFATLOCATION)); goalCondition = new TFGoalCondition(tf);//set up the initial state of the taskinitialState = GridWorldDomain.getOneAgentOneLocationState(domain);GridWorldDomain.setAgent(initialState, 0, 0);GridWorldDomain.setLocation(initialState, 0, 10, 10);//set up the state hashing systemhashingFactory = new DiscreteStateHashFactory();hashingFactory.setAttributesForClass(GridWorldDomain.CLASSAGENT, domain.getObjectClass(GridWorldDomain.CLASSAGENT).attributeList); //add visual observerVisualActionObserver observer = new VisualActionObserver(domain, GridWorldVisualizer.getVisualizer(gwdg.getMap()));((SADomain)this.domain).setActionObserverForAllAction(observer);observer.initGUI();}public void visualize(String outputPath){Visualizer v = GridWorldVisualizer.getVisualizer(gwdg.getMap());EpisodeSequenceVisualizer evis = new EpisodeSequenceVisualizer(v, domain, sp, outputPath);}public void BFSExample(String outputPath){if(!outputPath.endsWith(\"/\")){outputPath = outputPath + \"/\";}//BFS ignores reward; it just searches for a goal condition satisfying stateDeterministicPlanner planner = new BFS(domain, goalCondition, hashingFactory); planner.planFromState(initialState);//capture the computed plan in a partial policyPolicy p = new SDPlannerPolicy(planner);//record the plan results to a filep.evaluateBehavior(initialState, rf, tf).writeToFile(outputPath + \"planResult\", sp);}public void DFSExample(String outputPath){if(!outputPath.endsWith(\"/\")){outputPath = outputPath + \"/\";}//DFS ignores reward; it just searches for a goal condition satisfying stateDeterministicPlanner planner = new DFS(domain, goalCondition, hashingFactory);planner.planFromState(initialState);//capture the computed plan in a partial policyPolicy p = new SDPlannerPolicy(planner);//record the plan results to a filep.evaluateBehavior(initialState, rf, tf).writeToFile(outputPath + \"planResult\", sp);}public void AStarExample(String outputPath){if(!outputPath.endsWith(\"/\")){outputPath = outputPath + \"/\";}Heuristic mdistHeuristic = new Heuristic() {@Overridepublic double h(State s) {String an = GridWorldDomain.CLASSAGENT;String ln = GridWorldDomain.CLASSLOCATION;ObjectInstance agent = s.getObjectsOfTrueClass(an).get(0); ObjectInstance location = s.getObjectsOfTrueClass(ln).get(0); //get agent positionint ax = agent.getDiscValForAttribute(GridWorldDomain.ATTX);int ay = agent.getDiscValForAttribute(GridWorldDomain.ATTY);//get location positionint lx = location.getDiscValForAttribute(GridWorldDomain.ATTX);int ly = location.getDiscValForAttribute(GridWorldDomain.ATTY);//compute Manhattan distancedouble mdist = Math.abs(ax-lx) + Math.abs(ay-ly);return -mdist;}};//provide A* the heuristic as well as the reward function so that it can keep//track of the actual costDeterministicPlanner planner = new AStar(domain, rf, goalCondition, hashingFactory, mdistHeuristic);planner.planFromState(initialState);//capture the computed plan in a partial policyPolicy p = new SDPlannerPolicy(planner);//record the plan results to a filep.evaluateBehavior(initialState, rf, tf).writeToFile(outputPath + \"planResult\", sp);}public void ValueIterationExample(String outputPath){if(!outputPath.endsWith(\"/\")){outputPath = outputPath + \"/\";}OOMDPPlanner planner = new ValueIteration(domain, rf, tf, 0.99, hashingFactory,0.001, 100);planner.planFromState(initialState);//create a Q-greedy policy from the plannerPolicy p = new GreedyQPolicy((QComputablePlanner)planner);//record the plan results to a filep.evaluateBehavior(initialState, rf, tf).writeToFile(outputPath + \"planResult\", sp);//visualize the value function and policythis.valueFunctionVisualize((QComputablePlanner)planner, p);}public void QLearningExample(String outputPath){if(!outputPath.endsWith(\"/\")){outputPath = outputPath + \"/\";}//discount= 0.99; initialQ=0.0; learning rate=0.9LearningAgent agent = new QLearning(domain, rf, tf, 0.99, hashingFactory, 0., 0.9);//run learning for 100 episodesfor(int i = 0; i < 100; i++){EpisodeAnalysis ea = agent.runLearningEpisodeFrom(initialState);ea.writeToFile(String.format(\"%se%03d\", outputPath, i), sp); System.out.println(i + \": \" + ea.numTimeSteps());}}public void SarsaLearningExample(String outputPath){if(!outputPath.endsWith(\"/\")){outputPath = outputPath + \"/\";}//discount= 0.99; initialQ=0.0; learning rate=0.5; lambda=1.0LearningAgent agent = new SarsaLam(domain, rf, tf, 0.99, hashingFactory,0., 0.5, 1.0);//run learning for 100 episodesfor(int i = 0; i < 100; i++){EpisodeAnalysis ea = agent.runLearningEpisodeFrom(initialState);ea.writeToFile(String.format(\"%se%03d\", outputPath, i), sp);System.out.println(i + \": \" + ea.numTimeSteps());}}public void valueFunctionVisualize(QComputablePlanner planner, Policy p){List <State> allStates = StateReachability.getReachableStates(initialState, (SADomain)domain, hashingFactory);LandmarkColorBlendInterpolation rb = new LandmarkColorBlendInterpolation();rb.addNextLandMark(0., Color.RED);rb.addNextLandMark(1., Color.BLUE);StateValuePainter2D svp = new StateValuePainter2D(rb);svp.setXYAttByObjectClass(GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTX, GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTY);PolicyGlyphPainter2D spp = new PolicyGlyphPainter2D();spp.setXYAttByObjectClass(GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTX, GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTY);spp.setActionNameGlyphPainter(GridWorldDomain.ACTIONNORTH, new ArrowActionGlyph(0));spp.setActionNameGlyphPainter(GridWorldDomain.ACTIONSOUTH, new ArrowActionGlyph(1));spp.setActionNameGlyphPainter(GridWorldDomain.ACTIONEAST, new ArrowActionGlyph(2));spp.setActionNameGlyphPainter(GridWorldDomain.ACTIONWEST, new ArrowActionGlyph(3));spp.setRenderStyle(PolicyGlyphRenderStyle.DISTSCALED);ValueFunctionVisualizerGUI gui = new ValueFunctionVisualizerGUI(allStates, svp, planner);gui.setSpp(spp);gui.setPolicy(p);gui.setBgColor(Color.GRAY);gui.initGUI();}public void experimenterAndPlotter(){//custom reward function for more interesting resultsfinal RewardFunction rf = new GoalBasedRF(this.goalCondition, 5., -0.1);/** * Create factories for Q-learning agent and SARSA agent to compare */LearningAgentFactory qLearningFactory = new LearningAgentFactory() {@Overridepublic String getAgentName() {return \"Q-learning\";}@Overridepublic LearningAgent generateAgent() {return new QLearning(domain, rf, tf, 0.99, hashingFactory, 0.3, 0.1);}};LearningAgentFactory sarsaLearningFactory = new LearningAgentFactory() {@Overridepublic String getAgentName() {return \"SARSA\";}@Overridepublic LearningAgent generateAgent() {return new SarsaLam(domain, rf, tf, 0.99, hashingFactory, 0.0, 0.1, 1.);}};StateGenerator sg = new ConstantStateGenerator(this.initialState);LearningAlgorithmExperimenter exp = new LearningAlgorithmExperimenter((SADomain)this.domain, rf, sg, 10, 100, qLearningFactory, sarsaLearningFactory);exp.setUpPlottingConfiguration(500, 250, 2, 1000, TrialMode.MOSTRECENTANDAVERAGE, PerformanceMetric.CUMULATIVESTEPSPEREPISODE, PerformanceMetric.AVERAGEEPISODEREWARD);exp.startExperiment();exp.writeStepAndEpisodeDataToCSV(\"expData\");}} End.", "http://burlap.cs.brown.edu/tutorials_v1/bpl/p5.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Basic Planning and Learning Tutorials (v1) > Basic Planning and Learning > Part 5 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A* Planning with Value Iteration Learning with Q-Learning Learning with Sarsa(\u03bb) Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part | Next Part Live Visualization Although we showed how to visualize learning or planning results after they had been performed, sometimes when setting upa new problem and experiment it is useful to watch what is happening immediately. In this part of the tutorial weshow how to set up a live visualization of learning algorithms or planning algorithms that operate by trying actions in theworld (more on that in a bit). To present a live visualization we make use of the ActionObserver interface.Objects that adhere to the ActionObserver interface can be passed to Action objects in a domain. Whenever the actionis executed in a state, the action will automatically inform the the observer of the state, action, nextState eventbefore returning the result to the code that executed the action. You can use this interface to do any kind of analysisyou want, but in this tutorial we will show how we can use a built in VisualActionObserver class to watch learningor planning unfold as it is happening. Note The action observer class only works when the performAction method is called on an action.This means that ActionObservers will work for learning algorithms, in which the agent must sequentiallyinteract with the world, and planning algorithms that try executions of actions. However, you cannot usean ActionObserver to intercept what a planning algorithm like VI does, because VI uses the Actiontransition dynamics to perform planning, rather than taking actions in states. It is worth noting further that theforward search deterministic planning algorithms do work with ActionObserver objects,because the planners operate by applying actions to states. This may have some interesting visualizations,since forward search planning algorithms like A* will hop around the state space. To use our VisualActionObserver, first add the necessary import. import burlap.oomdp.singleagent.common.VisualActionObserver; Then, we can modify our constructor by adding the following lines to then end of it: VisualActionObserver observer = new VisualActionObserver(domain, GridWorldVisualizer.getVisualizer(gwdg.getMap()));((SADomain)this.domain).setActionObserverForAllAction(observer);observer.initGUI(); The first line creates a VisualActionObserver for visualizing our domain with a provided domain state visualizer(we use the same state visualizer that we used for our EpisodeSequenceVisualizer). The second linetells the domain to add this observer for all actions in the domain. We could have alternatively only added theobserver to specific actions that we wanted to observe, but since we want to watch everything that happens,we added to all actions. The last line will cause a GUI showing the viewer to appear. Now that the observer is set up, try running one of the learning algorithms that weset up previously. You should have a visualizerpop up showing what the agent is doing at each step of learning! Note By default, the VisualActionObserver will render frames at about 60FPS. You can modify this rate with thesetFrameDelay(long delay) method, which takes as an argument the number of ms that must pass for the renderingof an event and before the next action can be taken. Note that this delay also places a cap on the speed at which learning occurs. Typically,learning in BURLAP occurs at speeds orders of magnitude faster than 60FPS, so using the visual observer willslow down your algorithm considerably. Nevertheless, it is often useful as a way to confirm that your experimentis working as planned. Value Function and Policy Visualization While visualizing the agent in the state space is useful, in this next section, we will show how to visualize the value function that is estimatedfrom value function estimating planning or learning algorithms, along with the corresponding policy. In particularlywe will show how to visualize it for ValueIteration, but you could do the same with Q-Learning, or anyplanning/learning algorithm that implements the QComputablePlanner interface. The first step will be to add our necessary imports. import java.awt.Color;import java.util.List;import burlap.behavior.singleagent.auxiliary.StateReachability;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.ValueFunctionVisualizerGUI;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.ArrowActionGlyph; Then we will define a new method in our class to perform this visualization. The method will takea QComputablePlanner object and a policy for it that we wish to visualize. public void valueFunctionVisualize(QComputablePlanner planner, Policy p){List <State> allStates = StateReachability.getReachableStates(initialState, (SADomain)domain, hashingFactory);LandmarkColorBlendInterpolation rb = new LandmarkColorBlendInterpolation();rb.addNextLandMark(0., Color.RED);rb.addNextLandMark(1., Color.BLUE);StateValuePainter2D svp = new StateValuePainter2D(rb);svp.setXYAttByObjectClass(GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTX, GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTY);PolicyGlyphPainter2D spp = new PolicyGlyphPainter2D();spp.setXYAttByObjectClass(GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTX, GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTY);spp.setActionNameGlyphPainter(GridWorldDomain.ACTIONNORTH, new ArrowActionGlyph(0));spp.setActionNameGlyphPainter(GridWorldDomain.ACTIONSOUTH, new ArrowActionGlyph(1));spp.setActionNameGlyphPainter(GridWorldDomain.ACTIONEAST, new ArrowActionGlyph(2));spp.setActionNameGlyphPainter(GridWorldDomain.ACTIONWEST, new ArrowActionGlyph(3));spp.setRenderStyle(PolicyGlyphRenderStyle.DISTSCALED);ValueFunctionVisualizerGUI gui = new ValueFunctionVisualizerGUI(allStates, svp, planner);gui.setSpp(spp);gui.setPolicy(p);gui.setBgColor(Color.GRAY);gui.initGUI();} In the first line, we first define a set of states for which we want the value function and policy visualized.In our example, we'd like to simply visualize all the states in our domain, which means we want to findall the states in our domain. We can do this by using the StateReachability tool, which takes as inputan initial state, a single agent domain, a hashing factory to identify and perform equality checks between states, and returnsa list of all states that are reachable from the provided initial state. Note that the GridWorld domainis an instance of the single agent domain class (SADomain), so we can type cast it in this way (the alternativeis a domain for stochastic games, which involve multiple simultaneously acting agents). For our visualization we're going to render the value of a state with a color between red (for low values) andblue (for high values). The LandmarkColorBlendInterpolation class can be used to do this, which you can notehas a landmark added first for red and then for blue. If we wanted to render across more colors (like a rainbow scale)we could have continued adding more colors. Following our color blend definition, we then create a 2D value function visualizer, which requires a color blendobject (which we just created) to define the color shown for the value of states. This class also requiresit to be told which attributes for which class should be used to determine the x and y coordinates to rendereach state. In this case, we want to use the agent's X and Y attributes to determine the location on a screen thata state is rendered. We could stop here and only visualize the value function, but it may also be useful to visualize the policyderived. In this case, we will render the policy using a PolicyGlyphPainter2D. Similar to the value functionpainter we defined above, this class needs to be told which attributes for which class correspond to where a state'spolicy will be rendered on the screen; again we use the agent X and Y attributes. This class alsowants to be told which glyph to paint for each action. We will use the prebuilt ArrowActionGlyph class,which takes as input a direction for an arrow with 0,1,2, and 3 corresponding to a north, south, east, and west arrow glyph,respectively. Finally, The PolicyGlyphPainter2D class also needs to be told how to render a policy. That is, some policiesare stochastic, which requires the painter to determine how to render each glyph for each action based on the probability of thataction being taken by the agent. The PolicyGlyphRenderStyle.MAXACTION specification tells the painter to only render the glyph for the action withthe maximum probability of being selected; if there are ties for the max, then all actions that tied for max will be rendered.See the class documentation for the other policy render modes. The final lines of this method create our ValueFunctionVisualizerGUI, which takes the states to render, the objectthat defines how the value function is rendered, and the QComputablePlanner which specifies the value function. The policy and policy painter are optional, so they are passed as arguments through the subsequent method calls. We also setthe background color of the canvas to be grey and then launch the GUI. Try calling this method from the VI method we created earlier, passing it the VI object and its policy, and see what happens. //visualize the value function and policythis.valueFunctionVisualize((QComputablePlanner)planner, p); You may also want to disable in main the method that activates the offline EpisodeSequenceVisualizer, so that youdo not have two different GUIs floating around. You should get a GUI with colors in each cell of the of the world representing the value function in that state as well as the numeric value written in text (the text rendering can be disable if desired, or have its font properties and position manipulated ). Additionally,if you check the \"Show Policy\" check box at the bottom of the window you'll see arrows indicating the policy. The below imageshould resemble what you see. Next Part", "https://blog.cs.brown.edu/2018/04/04/providence-will-be-shiru-cafes-first-us-location/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Providence Will Be Shiru Cafe's First US Location Posted by Jesse Polhemus on April 4, 2018 Click the link that follows for more news items about why we love calling Providence home . Providence is Shiru Cafe's first US location. As noted on their website, the international chain has opened on the Brown University campus ahead of Amherst College, Harvard University, Princeton University, and Yale University, which will follow. Shiru is known for its unconventional business model, which provides free drinks, Wi-FI, electrical outlets, and study spaces to students (faculty and staff are required to pay $1 for most items) that are paid for by sponsor companies whose promotions appear on cups, smart devices of customers, and the cafe's digital signage. The new location is on 165 Angell Street, near Brown's CareerLAB. The image above is \u00a9 2018 by Craig Fildes and used with permission under a Creative Commons license. For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "http://burlap.cs.brown.edu/tutorials_v1/cpl/p2.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Creating a Planning and Learning Algorithm Tutorials (v1) > Creating a Planning and Learning Algorithm > Part 2 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Previous Part | Next Part VI Code Lets start by creating our class for VI, which we'll call VITutorial, and all the methods it will need to implement to satisfy the OOMDPPlanner and QComputablePlanner class/interface. import burlap.behavior.singleagent.QValue;import burlap.behavior.singleagent.planning.OOMDPPlanner;import burlap.behavior.singleagent.planning.QComputablePlanner;import burlap.oomdp.core.AbstractGroundedAction;import burlap.oomdp.core.State;public class VITutorial extends OOMDPPlanner implements QComputablePlanner {@Overridepublic List<QValue> getQs(State s) {// TODO Auto-generated method stubreturn null;}@Overridepublic QValue getQ(State s, AbstractGroundedAction a) {// TODO Auto-generated method stubreturn null;}@Overridepublic void planFromState(State initialState) {// TODO Auto-generated method stub}@Overridepublic void resetPlannerResults() {// TODO Auto-generated method stub}} Because we are sub classing OOMDPPlanner, this object will auto create data members that define our domain and task (the domain, reward function, terminal function, discount factor, andstate hashing factory that is used to hash and check the equality of states). However, the other critical data that VI needs to store are its estimates of the value function! We can store the value function as a mapping from states to double values and we can use a provided StateHashFactory to create fast hashable states ( StateHashTuple s). Furthermore, it might be useful to have the value of each state be initialized to something sensible that the client can specify. We can accept a procedure for initializing the value function by using a ValueFunctionInitialization object. Lets add those data members to our class, and make sure you also add the requisite imports. Finally, as a parameter to the algorithm, we'll let the client specify for many iterations VI will run, so we'll also need a data member for that. (We could also specify what the maximum allowable change in the value function was, but for simplicity for this tutorial we'll just use a fixed number of iterations.) import java.util.Map;import java.util.HashMap;import burlap.behavior.singleagent.ValueFunctionInitialization; protected Map<StateHashTuple, Double> valueFunction;protected ValueFunctionInitialization vinit;protected int numIterations; Now lets add a constructor to accept and initialize all our data. Again, we'll need to add some imports too. import burlap.behavior.statehashing.StateHashFactory;import burlap.oomdp.core.Domain;import burlap.oomdp.core.TerminalFunction;import burlap.oomdp.singleagent.RewardFunction; public VITutorial(Domain domain, RewardFunction rf, TerminalFunction tf, double gamma, StateHashFactory hashingFactory, ValueFunctionInitialization vinit, int numIterations){this.plannerInit(domain, rf, tf, gamma, hashingFactory);this.vinit = vinit;this.numIterations = numIterations;this.valueFunction = new HashMap<StateHashTuple, Double>();} Note that since our OOMDPPlanner superclass will hold our data members for the domain, reward function, terminal function, discount factor, and state hashing factory, we can initialize them with its plannerInit method. There is one other critical component VI needs that isn't part of the data we've given it in the constructor: the full state space! One reason we might not want to demand this upfront is because in an OO-MDP, it might be possible for the state space to be infinite even though for any given input state there may only be a finite set of states that are reachable. We could require the user to provide to our algorithm up front what the state space is, but it's much easier on the client if we determine the set of possible reachable states for any given seed state ourself and only perform this procedure when planning is requested for a previously unseen state. In fact, there are planning algorithm independent tools in BURLAP that can find all reachable states from a seed state for us (see the StateReachabilityClass for this purpose); however, for the purposes of illustration, we will not make use of those tools and instead implement the reachability code ourselves. To find all possibly reachable states from a source seed state, we need to do a kind of breadth-first search where we start with a queue containing only our seed state. We then dequeue a state from the queue and expand it by checking what all the possible outcomes states are from all possible actions and add those states to our queue if we've never seen them before. The search is complete when the queue is empty and every expanded state represents a state in our reachable state space. VI will then be able to iterate over this space. Lets implement that method now. In our code, we will use our valueFunction data member to effectively be our test for whether a state has been seen before and add each expanded node with its value function initialization as we see it. We will also need to add a few new imports for this method. import java.util.LinkedList;import java.util.List;import burlap.oomdp.core.TransitionProbability;import burlap.oomdp.singleagent.GroundedAction; public void performReachabilityFrom(State seedState){StateHashTuple hashedSeed = this.hashingFactory.hashState(seedState);//mark our seed state as seen and set its initial value function valuethis.valueFunction.put(hashedSeed, this.vinit.value(hashedSeed.s));LinkedList<StateHashTuple> open = new LinkedList<StateHashTuple>();open.offer(hashedSeed);while(open.size() > 0){//pop off a state and expand itStateHashTuple sh = open.poll();//which actions can be applied on this state?List<GroundedAction> appliactionActions = this.getAllGroundedActions(sh.s);//for each action...for(GroundedAction ga : appliactionActions){//what are the possible outcomes?List<TransitionProbability> tps = ga.action.getTransitions(sh.s, ga.params);//for each possible outcome...for(TransitionProbability tp : tps){//add previously unseed states to our open queue and //set their initial value functionStateHashTuple shp = this.hashingFactory.hashState(tp.s);if(!this.valueFunction.containsKey(shp)){this.valueFunction.put(shp, this.vinit.value(shp.s));open.offer(shp);}}}}} With the inline comments, most of this code should be self explanatory. However, there are a couple of things to which you should pay closer attention. In each state we want to know what all the possible actions are. For this, we're using the OOMDPPlanner super class method getAllGroundedActions. We could have used the Action static method getAllApplicableActionsFromActionList in conjunction with the action list provided from our domain to get all grounded actions; however, it possible to add high-level (or otherwise) actions to a planner that are not strictly part of the domain (like options) and using our OOMDPPlanner method will always return the possible actions it was given instead of the primitives defined with the domain, using its method is preferable. The other thing to pay attention to is how we get all possible state outcomes from applying an action in the state. For this request, we can get from our GroundedAction object the Action object reference and ask it to return a list of transition probabilities given the source state in question (and any possible action parameters specified if there are any) using the getTransitions method. The returned list from getTransitions is made up of TransitionProbability objects, which specify an outcome state and the probability of transitioning to it. As you may recall from our Building a Domain tutorial the getTransitons method will only return transitions to states that have non-zero probability so you don't have to worry about iterating over an unnecessarily large list of impossible transitions. However, it is worth pointing out that some domains may not implement the getTransitions method, particularly if there are an infinite number of states. Planners such as VI are not equipped to handle such domains (especially since we will use the full set of possible transitions to compute Q-values), so we must assume that that method is implemented. The other method we'll need to implement is the Bellman Equation. As noted on the previous page, the Bellman Equation is just a max over the Q-values and since we already have methods defined for getting the Q-value of states (a requirement of implementing the QComputablePlannerInterface), we will implement those methods and a Bellman Equation method next. We will also need to add an import for ArrayList for these methods. import java.util.ArrayList; @Overridepublic List<Value> getQs(State s) {List<GroundedAction> applicableActions = this.getAllGroundedActions(s);List<QValue> qs = new ArrayList<Value>(applicableActions.size());for(GroundedAction ga : applicableActions){qs.add(this.getQ(s, ga));}return qs;}@Overridepublic QValue getQ(State s, AbstractGroundedAction a) {//type cast to the type of grounded action we're usingGroundedAction ga = (GroundedAction)a;//what are the possible outcomes?List<TransitionProbability> tps = ga.action.getTransitions(s, ga.params);//aggregate over each possible outcomedouble q = 0.;for(TransitionProbability tp : tps){//what is reward for this transition?double r = this.rf.reward(s, ga, tp.s);//what is the value for the next state?double vp = this.valueFunction.get(this.hashingFactory.hashState(tp.s));//add contribution weighted by transition probabiltiy and //discounting the next stateq += tp.p * (r + this.gamma * vp);}//create Q-value wrapperQValue qValue = new QValue(s, ga, q);return qValue;}protected double bellmanEquation(State s){if(this.tf.isTerminal(s)){return 0.;}List<QValue> qs = this.getQs(s);double maxQ = Double.NEGATIVE_INFINITY;for(QValue q : qs){maxQ = Math.max(maxQ, q.q);}return maxQ;} You'll note that the Q-value methods return QValue objects, which are just triples consisting of a State object, an AbstractGroundedAction object, and a double for the Q-value associated with them. In the getQs method, we simply find all possible grounded actions, ask our getQ method what the Q-value is, and then return the list of all those Q-values. In the getQ method, we find all possible transitions from the input state and weigh the value of those outcomes by the probability of the transition occurring. The value of each outcome is the reward received, and the discounted value we have estimated for the outcome state. In the bellmanEquation method, we in general just return the maximum Q-value for the state; however, there is a catch. That is, if the input state is a terminal state, then by definition of it being a terminal state the value is zero, because the idea of a terminal state is that no action can follow from it. Therefore, if the state is a terminal state, we return a value of 0 and ignore whatever the domain object would say the possible transitions would be. Note that this check is not just a performance saver; all terminal states are specified by the TerminalFunction interface, so we must always refer to it to handle terminal states and cannot expect that a domain's transition dynamics have it baked in. We now have all the tools we need to do planning, so it's time to implement the planFromStateMethod. This method is called whenever a client wants to run planning from a given initial (or seed) state. What we'll do then is first check if we've already performed planning that includes that state. If so, we'll do nothing, having assumed to already have computed the value for it. However, if we haven't seen it before, then we'll first find all reachable states from it, and then run value iteration for a given number of iterations. As a reminder, running value iteration means making iterative sweeps over the entire state space in which the value of each state is re-estimated to what the Bellman equation says it is given the previously estimated value of the states. @Overridepublic void planFromState(State initialState) {StateHashTuple hashedInitialState = this.hashingFactory.hashState(initialState);if(this.valueFunction.containsKey(hashedInitialState)){return; //already performed planning here!}//if the state is new, then find all reachable states from it firstthis.performReachabilityFrom(initialState);//now perform multiple iterations over the whole state spacefor(int i = 0; i < this.numIterations; i++){//iterate over each statefor(StateHashTuple sh : this.valueFunction.keySet()){//update its value using the bellman equationthis.valueFunction.put(sh, this.bellmanEquation(sh.s));}}} We're now just about finished! The only thing left is that each OOMDPPlanner instance is asked to implement the method resetPlannerResults, which when called should have the effect of resetting all data so that it's as if no planning calls had ever been made. For our VI implementation, all this requires is clearing our value function. @Overridepublic void resetPlannerResults() {this.valueFunction.clear();} Testing VI To test our code, you can try using this planning algorithm with the grid world task created in the previous Basic Planning and Learning tutorial. You'll note that since we implement the QComputablePlanner interface, we can use any existing Q-value derived policy, such as GreedyQ, EpsilonGreedy, etc. Alternatively, below is a main method that you can add to test your VI implementation that creates a stochastic grid world, plans for it, and evaluates a single rollout of the resulting policy. You should find that the agent takes north and east actions exclusively. import burlap.behavior.singleagent.EpisodeAnalysis;import burlap.behavior.singleagent.Policy;import burlap.behavior.singleagent.planning.commonpolicies.GreedyQPolicy;import burlap.behavior.statehashing.DiscreteStateHashFactory;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.GridWorldTerminalFunction;import burlap.oomdp.singleagent.common.UniformCostRF; public static void main(String [] args){GridWorldDomain gwd = new GridWorldDomain(11, 11);gwd.setMapToFourRooms();//only go in intended directon 80% of the timegwd.setProbSucceedTransitionDynamics(0.8);Domain domain = gwd.generateDomain();//get initial state with agent in 0,0State s = GridWorldDomain.getOneAgentNoLocationState(domain);GridWorldDomain.setAgent(s, 0, 0);//all transitions return -1RewardFunction rf = new UniformCostRF();//terminate in top right cornerTerminalFunction tf = new GridWorldTerminalFunction(10, 10);//setup vi with 0.99 discount factor, discrete state hashing factory, a value//function initialization that initializes all states to value 0, and which will//run for 30 iterations over the state spaceVITutorial vi = new VITutorial(domain, rf, tf, 0.99, new DiscreteStateHashFactory(), new ValueFunctionInitialization.ConstantValueFunctionInitialization(0.0), 30);//run planning from our initial statevi.planFromState(s);//get the greedy policy from itPolicy p = new GreedyQPolicy(vi);//evaluate the policy with one roll out and print out the action sequenceEpisodeAnalysis ea = p.evaluateBehavior(s, rf, tf);System.out.println(ea.getActionSequenceString(\"\\n\"));} If you're looking to extend this tutorial on VI a little more, you might consider implementing a more intelligent VI termination condition so that rather than always running VI for a fixed number of iterations, VI terminates if the maximum change in the value function is smaller than some small threshold. Otherwise, it's now time to move on to our Q-learning example! If you'd like to see the full code we wrote all together, jump to the end of this tutorial . Next Part", "http://burlap.cs.brown.edu/tutorials_v1/cpl/p1.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Creating a Planning and Learning Algorithm Tutorials (v1) > Creating a Planning and Learning Algorithm > Part 1 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Next Part You are viewing the tutorial for BURLAP 1; if you'd like the BURLAP 2 tutorial, go here . Introduction In the previous tutorials, we walked through how you can use existing planning and learning algorithms in BURLAP on domains in BURLAP and how to create your own domains on which you can use those algorithms. However, you may also want to extend or create your own planning or learning algorithm in BURLAP that can either be used on existing domains or novel BURLAP domains and easily compared against existing algorithms. In this tutorial, we will show you how to create both a planning algorithm and a learning algorithm. In particular, we will be reimplementing versions of Value Iteration and Q-learning since they are conceptually simple algorithms to implement, but will expose the various properties of BURLAP you would want to use. In general, however, you should defer to using the existing implementations of these algorithms in BURLAP since they will support more features than we will cover here, such as support for planning and learning with Options (temporally extended actions). Using options in BURLAP will be left for a future tutorial. Value Iteration Overview Value Iteration (VI) is an algorithm that finds the optimal value function (the expected discounted future reward of being in a state an behaving optimally from it), and consequentially the optimal policy, for an MDP's entire state space. Central to the idea of VI is the Bellman Equation, which states that the optimal value of a stateis the value of the action with the maximum expected discounted future return (the action with the maximum Q-value) where the Q-value for a state-action pair is defined as the expected value over allpossible state transitions of the immediate reward summed with the discounted value of the resulting state. In math: where T(s' | s, a) is the probability of transitioning to state s' when taking action a in state s, R(s, a, s') is the reward received for transitioning to state s' after taking action a in state s, and gamma is a discount factor affecting how much immediate rewards are preferred to later ones. This equation presents some issues in that if an MDP has cycles, it's unclear what the values should be. However, the Value Iteration algorithm will converge to the optimal Value function if you simply initialize the value for each state to some arbitrary value, and then iteratively use the Bellman equationto update the the value for each state. Planning algorithms that make use of the Bellman equation to estimate the Value function are known as Dynamic Programming (DP) planning algorithms. Different DP algorithms specify different priorities for when the estimated value of each state is updated with the Bellman equation. In the case of VI, Bellman updates are performed in entire sweeps of the state space. That is, at the start, the value for all states is initialized to some arbitrary value. Then, for each state in the state space, the Bellman equation is used to update the value function estimate. Sweeps over the entire state space are repeated for some fixed number of iterations or until the maximum change in the value function is small. The algorithm is summarized in the below pseudocode. Value Iteration Initialize value function V(s) arbitrarily for all states s. Repeat until convergence... For each state s V(s) := max_a sum_s' T(s' | s, a) [R(s,a,s') + \u03b3 V(s')] Since there are a number of different DP algorithms that can be implemented, BURLAP includes a macro abstract planning algorithm class called ValueFunctionPlanner that includes a number of helpful methods for automatically performing Bellman Updates on states. However, to give a better sense of howto use the more fundamental parts of a planning algorithm in BURLAP, we will instead write our VI algorithm from scratch. The only classes and interfaces we'll use are the OOMDPPlanner abstract class and the QComputablePlanner interface, which will set up a bunch of common data members for us and provide the common planning method interfaces that will let our planning algorithm implementation talk to other BURLAP tools. Next Part", "http://burlap.cs.brown.edu/tutorials_v1/cpl/p3.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Creating a Planning and Learning Algorithm Tutorials (v1) > Creating a Planning and Learning Algorithm > Part 3 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Previous Part | Next Part Q-Learning Overview For our learning algorithm example, we'll be implementing Q-learning. The difference between a learning algorithm and a planning algorithm is that a planning algorithm has access to a model of the world, or at least a simulator, whereas a learning algorithm involves determining behavior when the agent does not know how the world works and must learn how to behave from direct experience with the world. In general, there are two approaches to reinforcement learning: (1) to learn a model of the world from experience and then use planning with that learned model to dictate behavior (model-based) and (2) to learn a policy or value function directly from experience (model-free). Q-learning belongs to the latter. As the name suggests, Q-learning learns estimates of the optimal Q-values of an MDP, which means that behavior can be dictated by taking actions greedily with respect to the learned Q-values. Q-learning can be summarized in the following pseudocode. Q-Learning Initialize Q-values (Q(s,a)) arbitrarily for all state-action pairs. For life or until learning is stopped... Choose an action (a) in the current world state (s) based on current Q-value estimates (Q(s,\u2022)). Take the action (a) and observe the the outcome state (s') and reward (r). Update Q-value estimate for previous state-action pair (Q(s,a)) based on observed next state (s') and reward (r). The two key steps in the above pseudocode are steps 3 and 5. There are many ways to choose actions based on the current Q-value estimates (step 3), but one of the most common is to use an \u03b5-greedy policy. In this policy, the action is selected greedily with respect to the Q-value estimates a fraction (1-\u03b5) of the time (where \u03b5 is a fraction between 0 and 1), and randomly selected among all actions a fraction \u03b5 of the time. In general, you want a policy that has some randomness to it so that it promotes exploration of the state space. For updating the Q-value of the last state-action pair (s,a) with respect to the observed outcome state (s') and reward (r), Q-learning uses the following update rule: where \u03b1 is a learning rate parameter between 0 and 1. Recall from the Bellman equation that the Value of a state is the maximum Q-value and the Q-value is the expected sum of the reward and discounted value of the next state, where the expectation is with respect to the probability of each state transition. In the Q-learning update rule, the reward plus the max Q-value in the observed next state is effectively what the Bellman equation tells us the Q-value is, except in this case, we're not marginalizing over all possible outcome states, we only have the one observed state and reward that we happened to get. However, because our learning rate only allows our Q-value to change slightly from its old estimate to a new estimate in the direction of the observed state and reward, as long as we keep retrying that action in the same state, we'll see the other possible states that could have occurred and move in their direction too. In aggregate over multiple tries of the action then, the Q-value will move toward the true expected value, even though we never directly used the transition probabilities. To have guaranteed convergence to the true Q-value, we should actually be slowly decreasing the learning rate parameter over time. However, in practice, it's often sufficient to simply use a small learning rate parameter, so for simplicity in our implementation, we'll use a fixed value for the learning rate rather that one that changes with time (though in the full Q-learning algorithm provided in BURLAP, you can use different schedules for decreasing the learning rate, including client-provided custom schedules with the LearningRate interface). Q-Learning Code Lets begin implementing our Q-learning algorithm code. Our class, called QLTutorial, will extend OOMDPPlaner and implement the QComputablePlanner and LearningAgent interfaces. It might seem strange that we will extend the OOMDPPlanner class, since this is a learning algorithm; however, we sub class OOMDPPlanner because the class provides us a number of the same data members and methods we'll need. Moreover, Although not all planning algorithms could be used for learning, all learning algorithms can be used for planning, since learning problems could always be applied in simulation. Since Q-learning estimates Q-values, the QComputablePlanner interface lets that knowledge be conveyed to other BURLAP tools (like Q-derived policies). Finally, the LearningAgent interface specifies the common methods a learning algorithm is expected to implement so that it can be used by other BURLAP tools. Below is the skeleton code that is created when we created our class, with the exception that we added an UnsupportedOperation exception to the planFromStateMethod. As noted above, we could implement planning by just simulating multiple learning episodes from the input state, but for this tutorial we will not bother. import java.util.List;import burlap.behavior.singleagent.EpisodeAnalysis;import burlap.behavior.singleagent.QValue;import burlap.behavior.singleagent.learning.LearningAgent;import burlap.behavior.singleagent.planning.OOMDPPlanner;import burlap.behavior.singleagent.planning.QComputablePlanner;import burlap.oomdp.core.AbstractGroundedAction;import burlap.oomdp.core.State;public class QLTutorial extends OOMDPPlanner implements QComputablePlanner,LearningAgent {@Overridepublic EpisodeAnalysis runLearningEpisodeFrom(State initialState) {// TODO Auto-generated method stubreturn null;}@Overridepublic EpisodeAnalysis runLearningEpisodeFrom(State initialState,int maxSteps) {// TODO Auto-generated method stubreturn null;}@Overridepublic EpisodeAnalysis getLastLearningEpisode() {// TODO Auto-generated method stubreturn null;}@Overridepublic void setNumEpisodesToStore(int numEps) {// TODO Auto-generated method stub}@Overridepublic List<EpisodeAnalysis> getAllStoredLearningEpisodes() {// TODO Auto-generated method stubreturn null;}@Overridepublic List<QValue> getQs(State s) {// TODO Auto-generated method stubreturn null;}@Overridepublic QValue getQ(State s, AbstractGroundedAction a) {// TODO Auto-generated method stubreturn null;}@Overridepublic void planFromState(State initialState) {throw new UnsupportedOperationException(\"We are not supporting planning for this tutorial.\");}@Overridepublic void resetPlannerResults() {// TODO Auto-generated method stub}} Similar to ValueIteration, the primary data we will want to store is a set of estimated Q-values for each state. We'll also again let the user specify the Q-value function initialization with a ValueFunctionInitialization object. We'll also need a learning rate parameter to be set. Finally, we'll need a learning policy to follow; that is, a policy that dictates how the agent chooses actions at each step. For this tutorial, we'll assume an \u03b5-greedy policy and let the client specify the value for \u03b5. Lets add data members for those elements now. import java.util.Map;import burlap.behavior.singleagent.ValueFunctionInitialization;import burlap.behavior.statehashing.StateHashTuple;import burlap.behavior.singleagent.Policy; protected Map<StateHashTuple, List<QValue>> qValues;protected ValueFunctionInitialization qinit;protected double learningRate;protected Policy learningPolicy; Lets also add a constructor for all our data members. import java.util.HashMap;import burlap.oomdp.core.Domain;import burlap.oomdp.core.TerminalFunction;import burlap.oomdp.singleagent.RewardFunction;import burlap.behavior.statehashing.StateHashFactory; public QLTutorial(Domain domain, RewardFunction rf, TerminalFunction tf, double gamma, StateHashFactory hashingFactory, ValueFunctionInitialization qinit, double learningRate, double epsilon){this.plannerInit(domain, rf, tf, gamma, hashingFactory);this.qinit = qinit;this.learningRate = learningRate;this.qValues = new HashMap<StateHashTuple, List<QValue>>();this.learningPolicy = new EpsilonGreedy(this, epsilon);} Note that the EpsilonGreedy policy object we create takes as input the planning/learning algorithm that implements the QComputablePlanner interface, and the value for epsilon to use. One of the primary tools we'll need is a method that grabs our Q-values, or creates and stores them with the proper initialization value if it's for an unseen state. Lets implement our Q-Value methods now. import java.util.ArrayList;import burlap.oomdp.singleagent.GroundedAction; @Overridepublic List<QValue> getQs(State s) {//first get hashed stateStateHashTuple sh = this.hashingFactory.hashState(s);//check if we already have stored valuesList<QValue> qs = this.qValues.get(sh);//create and add initialized Q-values if we don't have them stored for this stateif(qs == null){List<GroundedAction> actions = this.getAllGroundedActions(s);qs = new ArrayList<QValue>(actions.size());//create a Q-value for each actionfor(GroundedAction ga : actions){//add q with initialized valueqs.add(new QValue(s, ga, this.qinit.qValue(s, ga)));}//store this for laterthis.qValues.put(sh, qs);}return qs;}@Overridepublic QValue getQ(State s, AbstractGroundedAction a) {//first get all Q-valuesList<QValue> qs = this.getQs(s);//translate action parameters to source state for Q-values if neededa = a.translateParameters(s, qs.get(0).s);//iterate through stored Q-values to find a match for the input actionfor(QValue q : qs){if(q.a.equals(a)){return q;}}throw new RuntimeException(\"Could not find matching Q-value.\");} The only part of that code that probably needs any additional elaboration is the translate action parameters part. Recall that in an OO-MDP (unless otherwise specified), two states can be identical even if the object names/references are different as long as there is a bijection between the objects of the states. (refer back to the Building a Domain tutorial for more information). Therefore, it's possible that the input state for which we're trying to get the Q-values is equal to a stored state that has different object identifiers. If our actions are not parameterized, there is no issue here. However, if actions are parameterized to objects in the world, we may need to map the parameters from the input state/action to the stored/state action before we can determine which corresponding action is a match. For example, if we were learning in a blocks world and the action was pickup block0 in our input state, but block0 corresponded to block6 in our stored stated, then we'd want to return the Q-value for pickup block6 . The translateParameters method of our action takes as input a source state and a target state; then it finds a mapping for the parameters of the action in the source state to the target state and returns a new GroundedAction using those parameters. That is, if applied to \"pickup block0\", it would return \"pickup block6\". For code clarity, lets also implement a method that takes a state and returns the maximum Q-value for the state. protected double maxQ(State s){if(this.tf.isTerminal(s)){return 0.;}List<QValue> qs = this.getQs(s);double max = Double.NEGATIVE_INFINITY;for(QValue q : qs){max = Math.max(q.q, max);}return max;} One important element in that method to pay attention to is the fact that we first check if the input state is a terminal state and return 0 if it is. Like with our previous VI code, this check is important, because the definition of a terminal state is a state from which all action stops and we need to make sure they return max Q-values of of 0 when we update the Q-values for state action-pairs that lead to them. Now that we have all of our helper methods, lets implement the learning algorithm. The LearningAgent interface requires us to implement two methods that cause learning to be run for one episode; one that will run learning until the agent reaches a terminal state and one that will run learning for a maximum number of steps or until a terminal state is reached. We well have the former call the latter with a -1 for the maximum number of steps to indicate that it should never stop until the agent reaches a terminal state. Both methods also require returning an EpisodeAnalysis object, which is a recording of all the states, actions, and rewards that occurred in an episode, so as we write the code to have the agent iteratively select actions, we'll record the results to an EpisodeAnalysis object. Below is the learning algorithm code for Q-learning. @Overridepublic EpisodeAnalysis runLearningEpisodeFrom(State initialState) {return this.runLearningEpisodeFrom(initialState, -1);}@Overridepublic EpisodeAnalysis runLearningEpisodeFrom(State initialState,int maxSteps) {//initialize our episode analysis object with the given initial stateEpisodeAnalysis ea = new EpisodeAnalysis(initialState);//behave until a terminal state or max steps is reachedState curState = initialState;int steps = 0;while(!this.tf.isTerminal(curState) && (steps < maxSteps || maxSteps == -1)){//select an actionAbstractGroundedAction a = this.learningPolicy.getAction(curState);//take the action and observe outcomeState nextState = a.executeIn(curState);double r = this.rf.reward(curState, (GroundedAction)a, nextState);//record resultea.recordTransitionTo((GroundedAction)a, nextState, r);//update the old Q-valueQValue oldQ = this.getQ(curState, a);oldQ.q = oldQ.q + this.learningRate * (r + (this.gamma * this.maxQ(nextState) - oldQ.q));//move on to next statecurState = nextState;steps++;}return ea;} You should notice that the code reflects our earlier written pseudocode for Q-learning quite closely! One thing you might be wondering is whether any action parameter translation might have needed to occur in the action selection, similar to how it needed to happen when matching Q-values up with a given action. It would; however, we actually do not have to worry, because our Q-value derived Policy classes (e.g., EpsilonGreedy) handle any necessary parameter translation from the Q-values to the input state automatically for us! With that out of the way, we're just about finished. The last things we want to do are largely auxiliary. In particular, LearningAgent classes are asked to store the last N learning episodes so that they can be retrieved later. Lets add a data member for storing a list of the last set of learning episodes, how many to store, and then add to the end of our runLearningEpisode method code that adds the last episode to the list of most recent episodes (and removes old episodes if our storage is over the requested limit). import java.util.LinkedList; protected LinkedList<EpisodeAnalysis> storedEpisodes = new LinkedList<EpisodeAnalysis>();protected int maxStoredEpisodes = 1; while(this.storedEpisodes.size() >= this.maxStoredEpisodes){this.storedEpisodes.poll();}this.storedEpisodes.offer(ea); Now we can implement the methods related to getting previous learning episodes. @Overridepublic EpisodeAnalysis getLastLearningEpisode() {return this.storedEpisodes.getLast();}@Overridepublic void setNumEpisodesToStore(int numEps) {this.maxStoredEpisodes = numEps;while(this.storedEpisodes.size() > this.maxStoredEpisodes){this.storedEpisodes.poll();}}@Overridepublic List<EpisodeAnalysis> getAllStoredLearningEpisodes() {return this.storedEpisodes;} Finally, we can implement the resetPlannerResults method, which only needs to clear our Q-values. @Overridepublic void resetPlannerResults() {this.qValues.clear();} Testing Q-Learning As before, you can now test your learning algorithm with the previous code developed in the Basic Planning and Learning tutorial . Alternatively, you can use the below main method which creates the same Grid World domain and task as the test code we wrote for our VI implementation. Also as before, after learning for a number of episodes, it will take the greedy policy, roll it out once, and print out the actions taken. You should again find that only north and east actions are taken. import burlap.behavior.singleagent.EpisodeAnalysis;import burlap.behavior.singleagent.Policy;import burlap.behavior.singleagent.planning.commonpolicies.GreedyQPolicy;import burlap.behavior.statehashing.DiscreteStateHashFactory;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.GridWorldTerminalFunction;import burlap.oomdp.singleagent.common.UniformCostRF; public static void main(String [] args){GridWorldDomain gwd = new GridWorldDomain(3, 3);gwd.setMapToFourRooms();//only go in intended directon 80% of the timegwd.setProbSucceedTransitionDynamics(0.8);Domain domain = gwd.generateDomain();//get initial state with agent in 0,0State s = GridWorldDomain.getOneAgentNoLocationState(domain);GridWorldDomain.setAgent(s, 0, 0);//all transitions return -1RewardFunction rf = new UniformCostRF();//terminate in top right cornerTerminalFunction tf = new GridWorldTerminalFunction(10, 10);//setup Q-learning with 0.99 discount factor, discrete state hashing factory, a value//function initialization that initializes all Q-values to value 0, a learning rate//of 0.1 and an epsilon value of 0.1.QLTutorial ql = new QLTutorial(domain, rf, tf, 0.99, new DiscreteStateHashFactory(), new ValueFunctionInitialization.ConstantValueFunctionInitialization(1.), 0.1, 0.1);//run learning for 1000 episodesfor(int i = 0; i < 1000; i++){EpisodeAnalysis ea = ql.runLearningEpisodeFrom(s);System.out.println(\"Episode \" + i + \" took \" + ea.numTimeSteps() + \" steps.\");}//get the greedy policy from itPolicy p = new GreedyQPolicy(ql);//evaluate the policy with one roll out and print out the action sequenceEpisodeAnalysis ea = p.evaluateBehavior(s, rf, tf);System.out.println(ea.getActionSequenceString(\"\\n\"));} Next Part", "http://burlap.cs.brown.edu/tutorials_v1/cpl/p4.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Creating a Planning and Learning Algorithm Tutorials (v1) > Creating a Planning and Learning Algorithm > Part 4 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Previous Part Conclusions In this tutorial we showed you how to implement your own planning and learning algorithms. Although these algorithms were simple, they exposed the necessary BURLAP tools and mechanisms you will need to use to implement your own algorithms and should enable you to start writing your own code. In general, we highly recommend that you use BURLAP's existing implementations of Value Iteration and Q-Learning since they support a number of other features (Options, learning rate decay schedules, etc.). If you would like to see all of the code that was written in this tutorial, we have provided it below (first the Value Iteration code , then the Q-learning Code ). Full VI Code import java.util.ArrayList;import java.util.HashMap;import java.util.LinkedList;import java.util.List;import java.util.Map;import burlap.behavior.singleagent.EpisodeAnalysis;import burlap.behavior.singleagent.Policy;import burlap.behavior.singleagent.QValue;import burlap.behavior.singleagent.ValueFunctionInitialization;import burlap.behavior.singleagent.planning.OOMDPPlanner;import burlap.behavior.singleagent.planning.QComputablePlanner;import burlap.behavior.singleagent.planning.commonpolicies.GreedyQPolicy;import burlap.behavior.statehashing.DiscreteStateHashFactory;import burlap.behavior.statehashing.StateHashFactory;import burlap.behavior.statehashing.StateHashTuple;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.GridWorldTerminalFunction;import burlap.oomdp.core.AbstractGroundedAction;import burlap.oomdp.core.Domain;import burlap.oomdp.core.State;import burlap.oomdp.core.TerminalFunction;import burlap.oomdp.core.TransitionProbability;import burlap.oomdp.singleagent.GroundedAction;import burlap.oomdp.singleagent.RewardFunction;import burlap.oomdp.singleagent.common.UniformCostRF;public class VITutorial extends OOMDPPlanner implements QComputablePlanner {protected Map<StateHashTuple, Double> valueFunction;protected ValueFunctionInitialization vinit;protected int numIterations;public VITutorial(Domain domain, RewardFunction rf, TerminalFunction tf, double gamma, StateHashFactory hashingFactory, ValueFunctionInitialization vinit, int numIterations){this.plannerInit(domain, rf, tf, gamma, hashingFactory);this.vinit = vinit;this.numIterations = numIterations;this.valueFunction = new HashMap<StateHashTuple, Double>();}@Overridepublic List<QValue> getQs(State s) {List<GroundedAction> applicableActions = this.getAllGroundedActions(s);List<QValue> qs = new ArrayList<QValue>(applicableActions.size());for(GroundedAction ga : applicableActions){qs.add(this.getQ(s, ga));}return qs;}@Overridepublic QValue getQ(State s, AbstractGroundedAction a) {//type cast to the type we're usingGroundedAction ga = (GroundedAction)a;//what are the possible outcomes?List<TransitionProbability> tps = ga.action.getTransitions(s, ga.params);//aggregate over each possible outcomedouble q = 0.;for(TransitionProbability tp : tps){//what is reward for this transition?double r = this.rf.reward(s, ga, tp.s);//what is the value for the next state?double vp = this.valueFunction.get(this.hashingFactory.hashState(tp.s));//add contribution weighted by transition probabiltiy and //discounting the next stateq += tp.p * (r + this.gamma * vp);}//create Q-value wrapperQValue qValue = new QValue(s, ga, q);return qValue;}protected double bellmanEquation(State s){if(this.tf.isTerminal(s)){return 0.;}List<QValue> qs = this.getQs(s);double maxQ = Double.NEGATIVE_INFINITY;for(QValue q : qs){maxQ = Math.max(maxQ, q.q);}return maxQ;}@Overridepublic void planFromState(State initialState) {StateHashTuple hashedInitialState = this.hashingFactory.hashState(initialState);if(this.valueFunction.containsKey(hashedInitialState)){return; //already performed planning here!}//if the state is new, then find all reachable states from it firstthis.performReachabilityFrom(initialState);//now perform multiple iterations over the whole state spacefor(int i = 0; i < this.numIterations; i++){//iterate over each statefor(StateHashTuple sh : this.valueFunction.keySet()){//update its value using the bellman equationthis.valueFunction.put(sh, this.bellmanEquation(sh.s));}}}@Overridepublic void resetPlannerResults() {this.valueFunction.clear();}public void performReachabilityFrom(State seedState){StateHashTuple hashedSeed = this.hashingFactory.hashState(seedState);//mark our seed state as seen and set its initial value function valuethis.valueFunction.put(hashedSeed, this.vinit.value(hashedSeed.s));LinkedList<StateHashTuple> open = new LinkedList<StateHashTuple>();open.offer(hashedSeed);while(open.size() > 0){//pop off a state and expand itStateHashTuple sh = open.poll();//which actions can be applied on this state?List<GroundedAction> appliactionActions = this.getAllGroundedActions(sh.s);//for each action...for(GroundedAction ga : appliactionActions){//what are the possible outcomes?List<TransitionProbability> tps = ga.action.getTransitions(sh.s, ga.params);//for each possible outcome...for(TransitionProbability tp : tps){//add previously unseed states to our open queue and //set their initial value functionStateHashTuple shp = this.hashingFactory.hashState(tp.s);if(!this.valueFunction.containsKey(shp)){this.valueFunction.put(shp, this.vinit.value(shp.s));open.offer(shp);}}}}}public static void main(String [] args){GridWorldDomain gwd = new GridWorldDomain(3, 3);gwd.setMapToFourRooms();//only go in intended directon 80% of the timegwd.setProbSucceedTransitionDynamics(0.8);Domain domain = gwd.generateDomain();//get initial state with agent in 0,0State s = GridWorldDomain.getOneAgentNoLocationState(domain);GridWorldDomain.setAgent(s, 0, 0);//all transitions return -1RewardFunction rf = new UniformCostRF();//terminate in top right cornerTerminalFunction tf = new GridWorldTerminalFunction(10, 10);//setup vi with 0.99 discount factor, discrete state hashing factory, a value//function initialization that initializes all states to value 0, and which will//run for 30 iterations over the state spaceVITutorial vi = new VITutorial(domain, rf, tf, 0.99, new DiscreteStateHashFactory(), new ValueFunctionInitialization.ConstantValueFunctionInitialization(0.0), 30);//run planning from our initial statevi.planFromState(s);//get the greedy policy from itPolicy p = new GreedyQPolicy(vi);//evaluate the policy with one roll out and print out the action sequenceEpisodeAnalysis ea = p.evaluateBehavior(s, rf, tf);System.out.println(ea.getActionSequenceString(\"\\n\"));}} Full Q-Learning Code import java.util.ArrayList;import java.util.HashMap;import java.util.LinkedList;import java.util.List;import java.util.Map;import burlap.behavior.singleagent.EpisodeAnalysis;import burlap.behavior.singleagent.Policy;import burlap.behavior.singleagent.QValue;import burlap.behavior.singleagent.ValueFunctionInitialization;import burlap.behavior.singleagent.learning.LearningAgent;import burlap.behavior.singleagent.planning.OOMDPPlanner;import burlap.behavior.singleagent.planning.QComputablePlanner;import burlap.behavior.singleagent.planning.commonpolicies.EpsilonGreedy;import burlap.behavior.singleagent.planning.commonpolicies.GreedyQPolicy;import burlap.behavior.statehashing.DiscreteStateHashFactory;import burlap.behavior.statehashing.StateHashFactory;import burlap.behavior.statehashing.StateHashTuple;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.GridWorldTerminalFunction;import burlap.oomdp.core.AbstractGroundedAction;import burlap.oomdp.core.Domain;import burlap.oomdp.core.State;import burlap.oomdp.core.TerminalFunction;import burlap.oomdp.singleagent.GroundedAction;import burlap.oomdp.singleagent.RewardFunction;import burlap.oomdp.singleagent.common.UniformCostRF;public class QLTutorial extends OOMDPPlanner implements QComputablePlanner,LearningAgent {protected Map<StateHashTuple, List<QValue>> qValues;protected ValueFunctionInitialization qinit;protected double learningRate;protected Policy learningPolicy;protected LinkedList<EpisodeAnalysis> storedEpisodes = new LinkedList<EpisodeAnalysis>();protected int maxStoredEpisodes = 1;public QLTutorial(Domain domain, RewardFunction rf, TerminalFunction tf, double gamma, StateHashFactory hashingFactory, ValueFunctionInitialization qinit,double learningRate, double epsilon){this.plannerInit(domain, rf, tf, gamma, hashingFactory);this.qinit = qinit;this.learningRate = learningRate;this.qValues = new HashMap<StateHashTuple, List<QValue>>();this.learningPolicy = new EpsilonGreedy(this, epsilon);}@Overridepublic EpisodeAnalysis runLearningEpisodeFrom(State initialState) {return this.runLearningEpisodeFrom(initialState, -1);}@Overridepublic EpisodeAnalysis runLearningEpisodeFrom(State initialState,int maxSteps) {//initialize our episode analysis object with the given initial stateEpisodeAnalysis ea = new EpisodeAnalysis(initialState);//behave until a terminal state or max steps is reachedState curState = initialState;int steps = 0;while(!this.tf.isTerminal(curState) && (steps < maxSteps || maxSteps == -1)){//select an actionAbstractGroundedAction a = this.learningPolicy.getAction(curState);//take the action and observe outcomeState nextState = a.executeIn(curState);double r = this.rf.reward(curState, (GroundedAction)a, nextState);//record resultea.recordTransitionTo((GroundedAction)a, nextState, r);//update the old Q-valueQValue oldQ = this.getQ(curState, a);oldQ.q = oldQ.q + this.learningRate * (r + (this.gamma * this.maxQ(nextState) - oldQ.q));//move on to next statecurState = nextState;steps++;}while(this.storedEpisodes.size() >= this.maxStoredEpisodes){this.storedEpisodes.poll();}this.storedEpisodes.offer(ea);return ea;}@Overridepublic EpisodeAnalysis getLastLearningEpisode() {return this.storedEpisodes.getLast();}@Overridepublic void setNumEpisodesToStore(int numEps) {this.maxStoredEpisodes = numEps;while(this.storedEpisodes.size() > this.maxStoredEpisodes){this.storedEpisodes.poll();}}@Overridepublic List<EpisodeAnalysis> getAllStoredLearningEpisodes() {return this.storedEpisodes;}@Overridepublic List<QValue> getQs(State s) {//first get hashed stateStateHashTuple sh = this.hashingFactory.hashState(s);//check if we already have stored valuesList<QValue> qs = this.qValues.get(sh);//create and add initialized Q-values if we don't have them stored for this stateif(qs == null){List<GroundedAction> actions = this.getAllGroundedActions(s);qs = new ArrayList<QValue>(actions.size());//create a Q-value for each actionfor(GroundedAction ga : actions){//add q with initialized valueqs.add(new QValue(s, ga, this.qinit.qValue(s, ga)));}//store this for laterthis.qValues.put(sh, qs);}return qs;}@Overridepublic QValue getQ(State s, AbstractGroundedAction a) {//first get all Q-valuesList<QValue> qs = this.getQs(s);//translate action parameters to source state for Q-values if neededa = a.translateParameters(s, qs.get(0).s);//iterate through stored Q-values to find a match for the input actionfor(QValue q : qs){if(q.a.equals(a)){return q;}}throw new RuntimeException(\"Could not find matching Q-value.\");}protected double maxQ(State s){if(this.tf.isTerminal(s)){return 0.;}List<QValue> qs = this.getQs(s);double max = Double.NEGATIVE_INFINITY;for(QValue q : qs){max = Math.max(q.q, max);}return max;}@Overridepublic void planFromState(State initialState) {throw new UnsupportedOperationException(\"We are not supporting planning for this tutorial.\");}@Overridepublic void resetPlannerResults() {this.qValues.clear();}public static void main(String [] args){GridWorldDomain gwd = new GridWorldDomain(3, 3);gwd.setMapToFourRooms();//only go in intended directon 80% of the timegwd.setProbSucceedTransitionDynamics(0.8);Domain domain = gwd.generateDomain();//get initial state with agent in 0,0State s = GridWorldDomain.getOneAgentNoLocationState(domain);GridWorldDomain.setAgent(s, 0, 0);//all transitions return -1RewardFunction rf = new UniformCostRF();//terminate in top right cornerTerminalFunction tf = new GridWorldTerminalFunction(10, 10);//setup Q-learning with 0.99 discount factor, discrete state hashing factory, a value//function initialization that initializes all Q-values to value 0, a learning rate//of 0.1 and an epsilon value of 0.1.QLTutorial ql = new QLTutorial(domain, rf, tf, 0.99, new DiscreteStateHashFactory(), new ValueFunctionInitialization.ConstantValueFunctionInitialization(1.), 0.1, 0.1);//run learning for 1000 episodesfor(int i = 0; i < 1000; i++){EpisodeAnalysis ea = ql.runLearningEpisodeFrom(s);System.out.println(\"Episode \" + i + \" took \" + ea.numTimeSteps() + \" steps.\");}//get the greedy policy from itPolicy p = new GreedyQPolicy(ql);//evaluate the policy with one roll out and print out the action sequenceEpisodeAnalysis ea = p.evaluateBehavior(s, rf, tf);System.out.println(ea.getActionSequenceString(\"\\n\"));}} End.", "http://burlap.cs.brown.edu/tutorials_v1/index.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorials (v1) You are viewing the tutorials for BURLAP 1; if you'd like the BURLAP 2 tutorials, go here . This page provides a list of all available BURLAP tutorials. There are both short video tutorials and more explanatory and detailed text tutorials. Video Tutorials Text Tutorials Hello Grid World! - a tutorial on acquiring and linking with BURLAP Building a Domain Using Basic Planning and Learning Algorithms Creating a Planning and Learning Algorithm Solving Continuous Domains", "http://burlap.cs.brown.edu/tutorials_v1/hgw/p1.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Hello Grid World! Tutorials (v1) > Hello Grid World! > Part 1 Tutorial Contents Introduction Acquiring BURLAP Dependencies Running the JAR Hello Grid World Code Testing Plotting Tools Notes on the Java Heap Size Conclusions You are viewing the tutorial for BURLAP 1; if you'd like the BURLAP 2 tutorial, go here . Introduction In this tutorial we will walk you through downloading BURLAP and making sure you can run it. We willwalk through the instructions to both download the JAR from the precompiled source as wellas how to get the source code and compile it yourself. If you only want to do it one way, feel free to only look at that section. Either way, it should be very straightforward! After thecode has been downloaded, we'll show you a simple way to make sure it's working and then showyou how to easily create code that links to it. For more instructions on how write meaningfulcode with BURLAP and what it does, you should see the other tutorials. We will make use of the command line to test things out and compile everything. On the Mac and Linux you can just use the terminal. If you are windows, you can use either the command prompt something like Cygwin . Acquiring BURLAP There are two ways to acquire BURLAP. You can either download the pre-compiled JAR file (either with or without dependencies included)or compile it from the source code. In general, the source code will have the latest versionand the pre-compiled JAR may be a bit older, but should be stable. Downloading the Pre-compiled JAR For the prec-compiled jar, you can either get one with the dependencies includein the jar, or without them included. You can get either from these locations: the pre-compiled jar with dependencies included; the pre-compiled jar with out dependencies. Use the jar without the dependencies if you are having library conflictsand need to manage them yourself. If you use the jar without dependencies,we will walk through how to include them manually in the below dependencies section . After downloading the BURLAP jar file, you can either install it into a system level path that java will always search or your can place it in a local directory. In this tutorial we will just use it locally and point java to it. Create a directory in which you will run your tests. In this tutorial,we will name it \"testcode,\" but you can name it anything you want. Within that directory, create a new subdirectory called \"lib\" and place the burlap.jar file that you downloaded inside it. The directory structure should look like the following: testcodelibburlap.jar Or \"burlap_no_dep.jar\" instead of \"burlap.jar\" if you downloaded the version without dependencies. Compiling From the source The easiest way to get the source is with git . If you do not have git installed, install it now. You can download git from here . To compile the code,you will also need ant installed, which you can get from here if you do not already have it. Create a directory where you will place the git distribution. You might have a git directory in your home directory already created for this, which you can use. From the command line, change directories there now. Now enter the following command: git clone https://github.com/jmacglashan/burlap.git You should have found that this created the directory named \"burlap\". Change into that directory now and you should find the following files and subdirectories: libsrcLICENSEREADME.mdbuild.xml Now type ant dist And you should find new subdirectories appear; in particular, the \"dist\" directory whichwill contain the BURLAP JAR file. If there were compilation errors (warnings should not be a concern) it's possible that you will need to re-download the dependencies. For convenience,BURLAP's git repository includes the dependencies that it needs, but it's possible you may haveto install them yourself (see the Dependencies section and place all the JARs on which BURLAP depends in the lib directory and try ant again.) With the burlap.jar file created we'll now try working with it. You can either install it into a system level path that java will always search or your can place it in a local directory. In this tutorial we will just use it locally and point java to it. Create a directory in which you will run your tests. In this tutorial,we will name it \"testcode,\" but you can name it anything you want. Within that directory, create a new subdirectory called \"lib\" and place the burlap.jar file that you downloaded inside it. The directory structure should look like the following: testcodelibburlap.jar Dependencies Most of BURLAP can be run without any of its dependencies,but some of the algorithms and advanced tools will requireother libraries to be present. For example, the RLGluedependency allows BURLAP to communicate with other RLsoftware. If you are using the pre-compiled BURLAP jar that has dependencies included,you can skip this step. If you are using a compiled version of BURLAP or the jar without dependencesand you want to use all of BURLAP's features you should get the relevant JAR files and put them in the lib directory of the \"testcode\" directory thatwe created. If you compiled BURLAP from source, you can just copy the files in the BURLAP source lib directory into our testcode lib directory. Otherwise, you can download the dependencies (and their dependencies) from the below locations RLGlue Java Codec - You will need this if you plan on interfacing BURLAP with RLGLue . Apache Math Commons - For performance plotting tools. JFree Chart - For Performance Plotting tools. Snake YAML - For reading and writing states into the YAML format. Jackson - For reading and writing states into the JSON format. JOptimizer - For Max Margin Apprenticeship Learning SCPSolver - For Minmax, Coco-Q, and Correlated-Q algorithms. (Our choice of underlying LP solver that it uses is lpsolve.) After putting all the relevant dependencies in the lib folder,your directory structure should look something like the following. testcodelibburlap.jarJavaRLGlueCodec.jarLPSOLVESolverPack.jarSCPSolver.jarcolt-1.2.0.jarcommons-beanutils-1.6.jarcommons-collections-2.1.jarcommons-lang3-3.1.jarcommons-logging-1.1.1.jarcommons-math3-3.2.jarcsparsej-1.1.1.jarejml-0.25.jarhamcrest-core-1.3.jarjackson-annotations-2.2.3.jarjackson-core-2.2.3.jarjackson-databind-2.2.3.jarjcommon-1.0.21.jarjfreechart-1.0.17.jarjoptimizer-3.2.0.jarjoptimizer-3.3.0.jarjunit-4.11.jarlog4j-1.2.14.jarservlet.jarsnakeyaml-1.13.jarxml-apis-1.0.b2.jar Running the JAR The simplest way to test BURLAP is to run the default main method in the GridWorld domain generator, which will launch a simple interactive visualization of the GridWorld. From the command line, change directory into your \"testcode\" directory if you're not already there. Then enter: java -cp lib/*:. burlap.domain.singleagent.gridworld.GridWorldDomain Note the the \":.\" after \"lib/*\" which adds the current directory the class path. Some users have reported errors unless that is included, even though we haven't actually written any of our own code yet! If you're in the Windows command prompt (and not cygwin), you may need to change the colon character to a semicolon. If a GUI of a simple GridWorld appears, as shown below, then everything is working! There are two ways to control the agent in the GUI. One way is to use keystrokes, whichyou can perform by clicking on the visualization and then pressing either the w, a, s, or d keys (you only need to click on the visualization once to get it to start acceptingkey strokes). Alternatively, you can use the \"execute\" text field and button. In the executetext field you can enter the name of the action you want the agent to perform and then pressthe \"execute\" button to have it performed. In GridWorld, the actions you can have the agentperform are named \"north,\" \"south,\" \"east,\" and \"west.\" Hello Grid World Code We're now going to write a simple BURLAP hello world program for you to test. We're not going to spend any time really explaining what the code does, it's just a way to make sure that you can link to BURLAP with your own code. For a much more thorough explanation of the code, see the BURLAP java doc and other tutorials available. In your testcode directory, create a new file named \"HelloGridWorld.java\". Inside the file, place the following code. import burlap.domain.singleagent.gridworld.*;import burlap.oomdp.core.*;import burlap.oomdp.singleagent.explorer.VisualExplorer;import burlap.oomdp.visualizer.Visualizer;public class HelloGridWorld{public static void main(String [] args){GridWorldDomain gw = new GridWorldDomain(11,11); //11x11 grid worldgw.setMapToFourRooms(); //four rooms layoutgw.setProbSucceedTransitionDynamics(0.8); //stochastic transitions with 0.8 success rateDomain domain = gw.generateDomain(); //generate the grid world domain//setup initial stateState s = GridWorldDomain.getOneAgentOneLocationState(domain);GridWorldDomain.setAgent(s, 0, 0);GridWorldDomain.setLocation(s, 0, 10, 10);//create visualizer and explorerVisualizer v = GridWorldVisualizer.getVisualizer(gw.getMap());VisualExplorer exp = new VisualExplorer(domain, v, s);//set control keys to use w-s-a-dexp.addKeyAction(\"w\", GridWorldDomain.ACTIONNORTH);exp.addKeyAction(\"s\", GridWorldDomain.ACTIONSOUTH);exp.addKeyAction(\"a\", GridWorldDomain.ACTIONWEST);exp.addKeyAction(\"d\", GridWorldDomain.ACTIONEAST);exp.initGUI();}} This code will effectively recreate the same GridWorld GUI that we launched straight from the BURLAP jar, with the exception that we made the GridWorld have stochastic transitions. This means that as you control the agent with the w-s-a-d keys, you may find that it sometimes goes in the wrong direction! After saving the file, we will compile it with the command javac -cp lib/*:. HelloGridWorld.java Now lets run it! java -cp lib/*:. HelloGridWorld If you're in the Windows command prompt (and not cygwin), you may need to change the colon character to a semicolon and if you're using cygwin, then you need to specify it as a cygwin path: java -cp `cygpath -wp lib/*:.` HelloGridWorld If everything worked, then you should have seen the same GUI as the one you saw when we ran codedirectly from the BURLAP jar. Testing Plotting Tools In these section we'll provide some code to make sure that your dependencies for the BURLAP plotting tools are working correctly. If you don't care about this, naturally you can skip this section. Create a new file named \"PlotTest.java\" and put the following code in it. import burlap.domain.singleagent.gridworld.*;import burlap.oomdp.core.*;import burlap.behavior.singleagent.auxiliary.performance.*;import burlap.oomdp.core.TerminalFunction;import burlap.oomdp.singleagent.RewardFunction;import burlap.behavior.singleagent.learning.*;import burlap.behavior.singleagent.learning.tdmethods.QLearning;import burlap.behavior.singleagent.planning.deterministic.TFGoalCondition;import burlap.oomdp.auxiliary.common.ConstantStateGenerator;import burlap.behavior.statehashing.DiscreteStateHashFactory;import burlap.oomdp.singleagent.*;import burlap.oomdp.singleagent.common.SinglePFTF;public class PlotTest{public static void main(String [] args){GridWorldDomain gw = new GridWorldDomain(11,11); //11x11 grid worldgw.setMapToFourRooms(); //four rooms layoutgw.setProbSucceedTransitionDynamics(0.8); //stochastic transitions with 0.8 success ratefinal Domain domain = gw.generateDomain(); //generate the grid world domain//setup initial stateState s = GridWorldDomain.getOneAgentOneLocationState(domain);GridWorldDomain.setAgent(s, 0, 0);GridWorldDomain.setLocation(s, 0, 10, 10);//ends when the agent reaches a locationfinal TerminalFunction tf = new SinglePFTF(domain.getPropFunction(GridWorldDomain.PFATLOCATION)); //reward function definitionfinal RewardFunction rf = new GoalBasedRF(new TFGoalCondition(tf), 5., -0.1);//initial state generatorfinal ConstantStateGenerator sg = new ConstantStateGenerator(s);//set up the state hashing system for looking up statesfinal DiscreteStateHashFactory hashingFactory = new DiscreteStateHashFactory();/** * Create factory for Q-learning agent */LearningAgentFactory qLearningFactory = new LearningAgentFactory() {@Overridepublic String getAgentName() {return \"Q-learning\";}@Overridepublic LearningAgent generateAgent() {return new QLearning(domain, rf, tf, 0.99, hashingFactory, 0.3, 0.1);}};//define experimentLearningAlgorithmExperimenter exp = new LearningAlgorithmExperimenter((SADomain)domain, rf, sg, 10, 100, qLearningFactory);exp.setUpPlottingConfiguration(500, 250, 2, 1000, TrialMode.MOSTRECENTANDAVERAGE, PerformanceMetric.CUMULATIVESTEPSPEREPISODE, PerformanceMetric.AVERAGEEPISODEREWARD);//start experimentexp.startExperiment();}} Then compile and run as before, except this time we'll specify the PlotTest class that we created: javac -cp lib/*:. PlotTest.javajava -cp lib/*:. PlotTest If everything worked, then you should have seen a bunch of plots showing the performance of a Q-learning algorithm that were updated in (semi) real time, similar to what is shown below. If you did not see something like the above, you may need to make sure that you have all the dependencies you need in the lib folder (see the Dependencies section for more details). Notes on the Java Heap Size Planning and learning algorithms often require a lot of memory for large problems, more than what java will typically use by default. Therefore, you may want to make sure that you increase java's heap size whenever you run BURLAP. You can do this with the -Xmx argument. For instance, to give java 2GB of memory to use, change the previous run commands to the following: java -cp lib/*:. -Xmx2048M HelloGridWorld Conclusions In this tutorial we walked you through acquiring BURLAP and provided some simple code to make sure you can compile your own code with it. We strongly encourage you to use a full IDE, however, such as Eclipse . Just make sure that you add the jar files that we put in the lib folder to your Eclipse project's build path. Since all of the BURLAP java doc comes with the jar,Eclipse will autocomplete methods and explain the parameters, which should be very helpful. Now that you've completed this tutorial, you are encouraged to check out the other BURLAP tutorials that are available. Happy coding! End.", "http://burlap.cs.brown.edu/tutorials_v1/scd/p2.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Solving Continuous Domains Tutorials (v1) > Solving Continuous Domains > Part 2 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA(\u03bb) Conclusions Final Code Previous Part | Next Part Solving the Inverted Pendulum with Sparse Sampling In this part of the tutorial we will be solving the Inverted Pendulum problem. There are actually a number of different versions of this problem (for other variants, see the CartPoleDomain and its parameters), but in this example we'll be using one of the more simple forms. The problem is as follows; a cart exists on an infinite track on which force can be applied to move the cart left or right on the track. On top of the cart is a pole (the inverted pendulum) and the goal is to keep the pole balanced and pointing up by using left, right, or no force actions. If the angle between the pole and the vertical axis is larger than some threshold, the task is considered to have been failed. The state is defined by a single object which is defined by the pole angle and its angular velocity. An illustration of the problem, as visualized in BURLAP, is shown below. The BURLAP visualization of the Inverted Pendulum problem We are going to solve this problem using Sparse Sampling (more on that in a moment). Let us start by making a method (IPSS) for solving this problem and filling it in with code to instantiate the InvertedPendulum domain and task. import burlap.domain.singleagent.cartpole.InvertedPendulum; public static void IPSS(){InvertedPendulum ip = new InvertedPendulum();ip.physParams.actionNoise = 0.;Domain domain = ip.generateDomain();RewardFunction rf = new InvertedPendulum.InvertedPendulumRewardFunction(Math.PI/8.);TerminalFunction tf = new InvertedPendulum.InvertedPendulumTerminalFunction(Math.PI/8.);State initialState = InvertedPendulum.getInitialState(domain);} The line \"ip.physParams.actionNoise = 0.;\" sets our domain to have no noise in the actions. ( physParams is a data member containing all physics parameters that you can modify.) The created reward function and terminal function specify task failure conditions to be when the angle between the pole and vertical axis is greater than \u03c0/8 radians. Specifically, the agent will receive zero reward everywhere except when the pole's angle is greater than \u03c0/8, at which point it will receive -1 reward. The initial state we retrieved from the InvertedPendulum class will return a state in which the pole is balanced with no initial angular velocity. The algorithm we're going to use to solve this problem is Sparse Sampling. Instead of trying to approximate the value function for all states, Sparse Sampling will estimate Q-values for only one state a time, with the exception that the Q-values estimated are for a finite horizon , which means it only considers the possible reward received up to a specific number of steps from the current state and then ignores everything that might happen after that point. The approach is called Sparse Sampling, because if the set of possible transition dynamics are very large or infinite, it will only use a small sample from the transition dynamics when computing the Q-values. A disadvantage of Sparse Sampling is that for every state, planning needs to happen all over again (unless the agent happens to arrive in the same exact state, which is often uncommon in continuous state spaces). Furthermore, the computational complexity grows exponentially with the size of the horizon used, so if a large horizon is necessary to achieve a reasonable policy, Sparse Sampling may be prohibitively expensive. However, for our Inverted Pendulum domain, failing the task is only a few easy mistakes away, which means we can use a tractably small horizon to solve the problem. Lets now instantiate SparseSampling and set up a GreedyQ policy to follow from it. import burlap.behavior.singleagent.Policy;import burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSampling;import burlap.behavior.statehashing.NameDependentStateHashFactory; SparseSampling ss = new SparseSampling(domain, rf, tf, 1, new NameDependentStateHashFactory(), 10, 1);ss.setForgetPreviousPlanResults(true);Policy p = new GreedyQPolicy(ss); Note that we're using a discount factor of 1; because we are computing the Q-values for a finite horizon (rather than computing an infinite horizon), a discount factor of 1 will always result in finite Q-values. The state hashing factory that we're using is a NameDependentStateHashFactory , which is a hashing factory that does not support object identifier invariance, but does support state equality for continuous attribute domains, provided the continuous values of each attribute between states are exactly the same. Since states of this domain only consist of a single object, losing object identifier invariance is irrelevant. Also note that we don't expect to ever see the same state twice in a continuous domain, even within the same planning horizon, but this hashing factory will provide detection of the same states should they ever been seen. The method call setForgetPreviousPlanResults(true) tells Sparse Sampling to forget the previous planning tree it created every time planning for a new state is begun. Since we don't expect to see the same state twice, this is useful to clean up memory that we don't expect to use again. The last parameters of the SparseSampling constructor are the horizon size and the number of transition samples. We set the horizon to 10 and the number of transition samples to 1. Using only 1 transition sampling might be problematic in general, but since we simplified by the problem by removing action noise, everything is deterministic and so we only need one sample anyway! (Later, feel free to add back noise and increase the number samples, though you will find that a fair bit more computation time is needed). The final thing you'll notice in the code is that we never make an explicit call to planning from a state. There is a lack of an explicit planning call because whenever the GreedyQPolicy queries for the Q-values of a state, SparseSampling will automatically plan from that state first (unless we had let it remember past planning results and it was the same state as a state for which it's planned before). At this point, we're basically done!. All we need to do now is evaluate the policy that we created. We could have an animated visualization, like we did for the Mountain Car domain with LSPI, but since Sparse Sampling requires a bit more computation per step, lets let it cache an episode (with a maximum of 500 steps) to a file, and then visualize the episode using an EpisodeSequnceVisualizer like we've used in previous tutorials. Add the following code to evaluate the policy for at most 500 steps from the initial state, create a visualizer, and load up a EpisodeSequenceVisualizer to review the results. import burlap.behavior.singleagent.EpisodeAnalysis;import burlap.behavior.singleagent.EpisodeSequenceVisualizer;import burlap.domain.singleagent.cartpole.InvertedPendulumStateParser;import burlap.domain.singleagent.cartpole.InvertedPendulumVisualizer;import burlap.oomdp.auxiliary.StateParser; EpisodeAnalysis ea = p.evaluateBehavior(initialState, rf, tf, 500);StateParser sp = new InvertedPendulumStateParser(domain);ea.writeToFile(\"ip/ssPlan\", sp);System.out.println(\"Num Steps: \" + ea.numTimeSteps());Visualizer v = InvertedPendulumVisualizer.getInvertedPendulumVisualizer();new EpisodeSequenceVisualizer(v, domain, sp, \"ip\"); If you now point the main method to IPSS and run it, you should first see printed to the console the number of Bellman backups that were performed in the planning for each step of the episode. After 500 steps, it will launch the EpisodeSequenceVisualizer that you can use to review the steps it took. You should have found that it successfully balanced the pole for all 500 steps and the interface should look something like the below. The EpisodeSequenceVisualizer GUI after solving the Inverted Pendulum with Sparse Sampling. We're now finished with the Sparse Sampling example! If you're looking for an additional exercise, consider trying to solve this problem with LSPI using what you learned from the previous part of the tutorial. If you do so, we recommend using 5th order Fourier basis functions and collecting 5000 SARS instances by performing random trajectories from the initial balanced state. (To create a StateGenerator that always returns the same initial state for use with the SARS collector, see the ConstantStateGenerator class.) In the final part of this tutorial, we will show how to solve the Lunar Lander domain with gradient descent SARSA lambda. Next Part", "http://burlap.cs.brown.edu/tutorials_v1/scd/p3.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Solving Continuous Domains Tutorials (v1) > Solving Continuous Domains > Part 3 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA(\u03bb) Conclusions Final Code Previous Part | Next Part Solving Lunar Lander with SARSA(\u03bb) In our final example of this tutorial we will solve a simplified Lunar Lander domain using gradient descent Sarsa Lambda and CMAC/Tiling coding basis functions. The Lunar Lander domain is a simplified version of the classic 1979 Atari arcade game by the same name. In this domain the agent pilots a ship that must take off from the ground and land on a landing pad. The agent can either use a strong rocket thruster to push the ship in the direction the ship is facing, use a weak rocket thruster that is equal magnitude to the force of gravity, rotate clockwise or counterclockwise, or coast. The agent will receive a large reward for landing on the landing pad, a large negative reward for colliding with the ground or an obstacle, and a small negative reward for all other transitions. As with the previous examples, let us begin by making a method for this example (LLSARSA) and instantiating a Lunar Lander domain , task, and initial state. import burlap.domain.singleagent.lunarlander.LLStateParser;import burlap.domain.singleagent.lunarlander.LunarLanderDomain;import burlap.domain.singleagent.lunarlander.LunarLanderRF;import burlap.domain.singleagent.lunarlander.LunarLanderTF; public static void LLSARSA(){LunarLanderDomain lld = new LunarLanderDomain();Domain domain = lld.generateDomain();RewardFunction rf = new LunarLanderRF(domain);TerminalFunction tf = new LunarLanderTF(domain);StateParser sp = new LLStateParser(domain);State s = LunarLanderDomain.getCleanState(domain, 0);LunarLanderDomain.setAgent(s, 0., 5.0, 0.0);LunarLanderDomain.setPad(s, 75., 95., 0., 10.);} Most of this code should be fairly self explanatory. Using a default construct for LunarLanderDomain and not setting anything else with it will use default parameters for the domain (but you can change various properties such as the force of gravity, thrust, etc.). The default reward function returns +1000 for landing, -100 for collisions, and -1 for regular transitions (though these values can be changed with a different constructor ). The terminal function sets all states in which the ship has landed on the landing pad as terminal states. The getCleanState method, with the parameter 0 creates a state with an agent object (the ship) a landing pad object, and 0 obstacle objects. The setAgent method parameters specify the angle of the ship from the vertical axis in radians, the x position of the ship (5), and the y position of the ship (0, on the ground), respectively. The setPad method parameters define the landing pad dimensions in terms of the rectangular left, right, bottom, top boundaries, respectively. This will create an initial state that looks like the below (as visualized in BURLAP). The initial stated used in Lunar Lander. The red box is the ship, the blue box the landing pad. We're going to solve this problem with gradient descent SARSA(\u03bb) , which is a learning algorithm that behaves much like conventional tabular SARSA(\u03bb) (discussed in previous tutorials), except it learns an approximation of the value function, much like LSPI. Unlike LSPI, gradient descent SARSA(\u03bb) does not need to use a linear approximator; however, in practice it is usually a good idea to use a linear approximator because there are much stronger learning convergence guarantees with linear approximators. When using a linear approximator, it is as with LSPI, a good idea then to use some kind of basis functions. Like in the LSPI example, we could use the same Fourier basis or radial basis functions for gradient descent SARSA(\u03bb). However, this time we'll use a different basis function: CMACs, also know in reinforcement learning literature as Tile Coding. CMACs address learning in continuous domains in a only slightly more complex way than merely discretizing the state space, yet also diminish the aliasing effects that discretization can incur. To describe how they work, lets start by thinking about how a state discretization can be used to create a set of binary basis functions. First imagine a discretization of the state space as a process that creates large bins, or tiles , across the entire state space. We'll let each tile represent a different binary basis function. For a given input continuous state, all basis functions return a value of 0, except the function for the tile in which the continuous state is contained, which will return a value of 1. By then estimating a linear function over these features, we generalize the observed rewards and transitions for one state to all states that are contained in the same tile; the larger the tiles we use, the larger the generalization. A disadvantage of using such a simple discretization is that it produces aliasing effects. That is, two states may be very similar but reside on opposite sides of the edge of a tile, which results in none of their experience being shared, despite the fact that they are similar and do share experiences with other states that are more distant but happen to be in the same tile. CMACs diminish this aliasing effect by instead creating multiple offset tilings over the state space and creating a basis function for each tile in each of the tilings. If there are n tilings, then any given input state will have n basis functions with a value 1 (one for the tile in which the query state is contained for each tiling). Because the tilings are offset from each other, two states may be contained in the same tile of one tiling, but in different tiles for a different tiling. As a consequence, experience generalization still occurs between states in the same tiling, but the differences between different tilings regains specificity and removes aliasing effects. For more information on CMACs with some good illustrations, we recommend the Generalization and Function Approximation chapter in the book Reinforcement Learning: An Introduction , by Sutton and Barto. An online version of the chapter can be found here . An advantage of using CMACs is that you only need to store weight values in the fitted linear function for tiles that are associated with states that the agent has experienced thus far (the basis function for all other tiles would return a value of zero and therefore contribute nothing to the value function approximation). Another advantage specific to OO-MDPs is that because each tile represents a discretized state, we can maintain object identifier independence, which is otherwise not always possible to do with a number of value function approximation methods. If you don't need object identifier independence, there is another implementation of CMACs in BURLAP called FVCMACFeatureDatabase that is slightly more CPU efficient and operates on state feature vectors (which as before are produced with StateToFeatureVectorGenerator objects). For this tutorial, however, we will use the version that provides object identifier independence, which is called CMACFeatureDatabase . Lets continue our code implementation by instantiating a CMACFeatureDatabase object and defining the tiling of our state space. To implement CMAC basis functions, we will need to decide on the number of tilings that we use and the width of each tile along each attribute. In this case, we will use 5 tilings with a width for each attribute that produces 10 tiles along each attribute range. We will limit this tiling to the Lunar Lander ship attribute values and ignore attributes for the landing pad. Since the agent's ship is defined by 5 attributes (x position, y position, x velocity, y velocity, and rotation angle from the vertical axis), this will produce 5 tilings that each define at most 10^5 tiles (again though, we don't necessarily have to store weights for all tiles if the agent never visits them!) To do so, add the below code. import burlap.behavior.singleagent.vfa.cmac.CMACFeatureDatabase; int nTilings = 5;CMACFeatureDatabase cmac = new CMACFeatureDatabase(nTilings, CMACFeatureDatabase.TilingArrangement.RANDOMJITTER);double resolution = 10.;double angleWidth = 2 * lld.getAngmax() / resolution;double xWidth = (lld.getXmax() - lld.getXmin()) / resolution;double yWidth = (lld.getYmax() - lld.getYmin()) / resolution;double velocityWidth = 2 * lld.getVmax() / resolution;cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS, domain.getAttribute(LunarLanderDomain.AATTNAME), angleWidth);cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS, domain.getAttribute(LunarLanderDomain.XATTNAME), xWidth);cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS, domain.getAttribute(LunarLanderDomain.YATTNAME), yWidth);cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS, domain.getAttribute(LunarLanderDomain.VXATTNAME), velocityWidth);cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS, domain.getAttribute(LunarLanderDomain.VYATTNAME), velocityWidth); In the first line, we instantiate the CMACFeatureDatabase with 5 tilings, each offset by a random amount. Then we compute tile widths along each attribute such that it would produce at most 10 tile margins along each attribute. The methods lld.getXMin() simply return the minimum x-value for our LunarLander instance (and the other methods return their respective attribute's value ranges). Finally, we inform the CMACFeatureDatabase of the width for each attribute that will be included in the tiling for each object class. In this case, we will only produce tilings over the agent class for its rotation angle; x, y position; and x, y velocity attributes and ignore the attributes for other object classes like the landing pad. Now that we have the CMACFeatureDatabase set up, we can create a linear value function approximator for it and pass it along to gradient descent SARSA(\u03bb). import burlap.behavior.singleagent.learning.tdmethods.vfa.GradientDescentSarsaLam; double defaultQ = 0.5;ValueFunctionApproximation vfa = cmac.generateVFA(defaultQ/nTilings);GradientDescentSarsaLam agent = new GradientDescentSarsaLam(domain, rf, tf, 0.99, vfa, 0.02, 10000, 0.5); Note that to set the initial default Q-values to be predicted to 0.5, we set the value of each feature weight to 0.5 divided by the number of tilings. We divide the desired initial Q-value (0.5) by the number of tilings (5), because for any given state there will only be n features with a value of 1 and the rest 0, where n is the number of tilings. Therefore, if the initial weight value for all those features is 0.5/5, the linear estimate will predict our desired initial Q-value: 0.5. We also set the learning rate for gradient descent SARSA(\u03bb) to 0.02 (in general, you should decrease the learning rate as the number of features increases), set a maximum learning episode size of 10000, and set \u03bb to 0.5. With gradient descent SARSA(\u03bb) instantiated, we can run learning episodes just like we do for typical SARSA(\u03bb). Lets run learning for 5000 episodes, record the episodes to files, and then visualize the results with an EpisodeSequenceVisualizer. import burlap.oomdp.visualizer.Visualizer; for(int i = 0; i < 5000; i++){EpisodeAnalysis ea = agent.runLearningEpisodeFrom(s); //run learning episodeea.writeToFile(String.format(\"lunarLander/e%04d\", i), sp); //record episode to a fileSystem.out.println(i + \": \" + ea.numTimeSteps()); //print the performance of this episode}Visualizer v = LLVisualizer.getVisualizer(lld);new EpisodeSequenceVisualizer(v, domain, sp, \"lunarLander\"); If you now point your main method to LLSARSA() and run it, you should initially see a punch of text after each episode stating how long the learning episode lasted followed by the EpisodeSequenceVisualizer GUI, which should look something like the below. The EpisodeSequenceVisualizer GUI showing the learning results on Lunar Lander You should find that as more learning episodes are performed, the agent becomes progressively better at piloting to the landing pad. That concludes all of our examples for this tutorial! Closing remarks and the full code we created can be found on the next page. Next Part", "http://burlap.cs.brown.edu/tutorials_v1/scd/p1.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Solving Continuous Domains Tutorials (v1) > Solving Continuous Domains > Part 1 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA(\u03bb) Conclusions Final Code Next Part You are viewing the tutorial for BURLAP 1; if you'd like the BURLAP 2 tutorial, go here . Introduction In the Basic Planning and Learning tutorial we walked through how to use a number of different planning and learning algorithms. However, all the algorithms we covered were exclusively for finite state planning/learning problems and it is not uncommon in real world problems to have to deal with an infinite or continuous state space. Continuous state problems are challenging because there is an infinite number of possible states, which means you're unlikely to ever visit the same state twice. Since many of the previous algorithms rely on being ably to exhaustively enumerate the states or revisit them multiple times to estimate a value function for each state, having an infinite number of states presents a problem that requires a different set of algorithms. For example, methods that generalize the value function to unseen \"near by\" states is one approach to handling continuous state space problems. In this tutorial, we will explain how to solve continuous domains, using the example domains Mountain Car , Inverted Pendulum , and Lunar Lander , with three different algorithms implemented in BURLAP that are capable of handling continuous domains: Least-Squares Policy Iteration , Sparse Sampling , and Gradient Descent Sarsa Lambda . As usual, if you would like to see all the finished code that we will write in this tutorial, you can jump to the Final Code section at the end. Solving Mountain Car with Least-Squares Policy Iteration The Mountain Car domain is a classic continuous state RL domain in which an under-powered carmust drive up a steep mountain. However, because the mountain is so steep, the car cannot justaccelerate straight up to the top. Since car is in valley, it can, however, make it to its destination by first moving backwards up the opposite slope, and then accelerate down to gain enoughmomentum to get up the intended slope. An illustration of the Mountain Car problem, courtesy of Wikipedia . To solve this problem, we will use Least-Squares Policy Iteration (LSPI). LSPI requires a collection of state-action-reward-state (SARS) transition tuples that are sampled from the domain. In some domains, like Mountain car, this data can be collected rather straight forwardly with random sampling of actions in the world. In other domains, the set of SARS data (and therefore how it is collected) is critical to getting good results out of LSPI, so it is important to keep that in mind. LSPI starts by initializing with a random policy and then uses the collected SARS samples to approximate the Q-value function of that policy for the continuous state space. Afterwards, the policy is updated by choosing actions that have the highest Q-values (this change in policy is known as policy improvement ). This process repeats until the approximate Q-value function (and consequentially the policy) stops changing much. LSPI approximates the Q-value function for its current policy by fitting a linear function of state basis features to the SARS data it collected, similar to a typical regression problem, which is what enables the value function to generalize to unseen states. Choosing a good set of state basis functions that can be used to accurately represent the value function is also critical to getting good performance out of LSPI. In this tutorial, we will show you how to set up Fourier basis functions and radial basis functions , which tend to be good starting places. Lets start coding now. We'll begin by making a class shell, called ContinuousDomainTutorial. In it, we will create a different static method that demonstrates solving each domain and algorithm in this tutorial, so we'll start with our method for solving Mountain Car with LSPI using Fourier basis functions (MCLSPIFB). public class ContinuousDomainTutorial {public static void main(String [] args){MCLSPIFB();}public static void MCLSPIFB(){//we'll fill this in in a moment...}} Next we'll create an instance of the Mountain car domain and the typical reward function and terminal function that defines the task in our MCLSPIFB method. We'll also need to add the requisite imports for this code. import burlap.behavior.singleagent.learning.GoalBasedRF;import burlap.domain.singleagent.mountaincar.MountainCar;import burlap.oomdp.core.Domain;import burlap.oomdp.core.TerminalFunction;import burlap.oomdp.singleagent.RewardFunction; MountainCar mcGen = new MountainCar();Domain domain = mcGen.generateDomain();TerminalFunction tf = new MountainCar.ClassicMCTF();RewardFunction rf = new GoalBasedRF(tf, 100); Our MountainCar instance provides us a means to get a TerminalFunction that sets states in which the car is on the top of the slope on the right-side as terminal states. We then define a Goal-based reward function that returns a reward of 100 when the agent reaches the terminal state and 0 everywhere else (0 is the default reward for a GoalBasedRF , but that value can be changed with a different constructor). Note We could have also changed parameters of the Mountain car domain, such as the strength of gravity, which is found in the physParams MountainCar data member, but without any modifications, it will automatically use the default parameterizations. The next thing we will want to do is collect SARS data from the Mountain Car domain for LSPI to use for fitting its linear function approximator. For Mountain car, it is sufficient to randomly draw a state from the Mountain Car state space, sample a trajectory from it by selecting actions uniformly randomly, and then repeat the process over again from another random state. Lets collect data in this way until we have 5000 SARS tuple instances for our dataset. To accomplish this data collection, we can make use of a random StateGenerator to select random initial states, and perform random trajectory roll outs from them using a UniformRandomSARSCollector . Lets add code and the imports for that now. import burlap.behavior.singleagent.learning.lspi.SARSCollector;import burlap.behavior.singleagent.learning.lspi.SARSData;import burlap.domain.singleagent.mountaincar.MCRandomStateGenerator;import burlap.oomdp.auxiliary.StateGenerator; StateGenerator rStateGen = new MCRandomStateGenerator(domain);SARSCollector collector = new SARSCollector.UniformRandomSARSCollector(domain);SARSData dataset = collector.collectNInstances(rStateGen, rf, 5000, 20, tf, null); The MCRandomStateGenerator class provides a means to generate Mountain Car states with random positions and velocities. The collectNInstances methods will collect our SARS data for us. Specifically, we've told it to perform rollouts from states generated from our Mountain Car state generator for no more than 20 steps at a time or until we hit a terminal state. This processing a generating a random state, rolling out a random trajectory for it, and collecting all the observed SARS tuples repeats until we have 5000 SARS instances. The null parameter at the end of the method call means we want it to create a new SARSData instance and fill it up with the results (and return it) rather than adding to an existing SARSData instance. Note In this case we're opting to collect all the data LSPI will use ahead of time. Alternatively, LSPI can be used like a standard learning algorithm (it does implement the LearningAgent interface) in which it starts with no data, acts in the world from whatever the world's current state is and reruns LSPI as it experiences more transitions (thereby improving the policy that it follows). However, this approach to acquiring SARS data is often not as efficient and there may be better means to acquire data when the agent is forced to experience the world as it comes rather than being able to manually sample the state space as we have in this tutorial. Therefore, if you are facing a problem in which you cannot manually control how states are sampled ahead of time, you may want to consider overriding LSPI's runLearningEpisodeFrom method to use an approach that is a better fit for your domain. To learn more about how LSPI's default runLearningEpisodeFrom method is used, see the class's documentation . The next thing we will want to define is the state basis features LSPI will use for its linear estimator of the value function. As noted previously, we will use Fourier basis functions. Fourier basis functions are very easy to implement without having to set many parameters, which makes it a good first approach to try. Each Fourier basis function takes as input a feature vector defining the state, where each attribute is normalized, and produces scalar value. Each basis function corresponds to a state feature that LSPI will use for its linear function. The BURLAP FourierBasis class is an implementation of the FeatureDatabase interface and will automatically make multiple Fourier basis functions based on the order you choose. The larger the order, the more basis functions (which grow exponentially with the dimension of input state feature vector) and the more granular the representation becomes, allowing for a more precise linear value function approximation. Recall that BURLAP states are not defined with feature vectors, but with sets of objects (adhering to the OO-MDP paradigm); however, we can convert an OO-MDP state into a feature vector trivially since OO-MDPs tend to provide more information than a standard feature vector definition does. The simplest way to convert an OO-MDP state into a feature vector is to simply concatenate the feature vector of each object in the state into a single large feature vector. To do so, we can make use of the ConcatenatedObjectFeatureVectorGenerator , which asks for which object classes to concatenate (and their concatenation order) and whether to normalize the values or not (which for Fourier basis functions we will want to do). Note If you need to define the feature vector conversion differently (perhaps, for instance, you want to use relative features, or ignore certain attributes of the objects), you can always make your own feature vector conversion definition by implementing a StateToFeatureVectorGenerator , which takes as input a State object and returns a double array. In the Mountain Car domain, there is only one object class\u2014the agent\u2014which defines the car's position and velocity, so we only need to tell the ConcatenatedObjectFeatureVectorGenerator to use the \"agent\" class values and to normalize its attribute values. With a feature vector conversion method in hand, lets create a set of 4th order Fourier basis functions to use as our state features for LSPI. import burlap.behavior.singleagent.vfa.common.ConcatenatedObjectFeatureVectorGenerator;import burlap.behavior.singleagent.vfa.fourier.FourierBasis; ConcatenatedObjectFeatureVectorGenerator featureVectorGenerator = new ConcatenatedObjectFeatureVectorGenerator(true, MountainCar.CLASSAGENT);FourierBasis fb = new FourierBasis(featureVectorGenerator, 4); Note that the \"true\" parameter in the ConcatenatedObjectFeatureVectorGenerator constructor tells it that all dimensions should be normalized in the returned feature vector, which is what Fourier basis functions expect. Now lets instantiate LSPI on our Mountain Car domain and task with our Fourier basis functions; tell it to use a 0.99 discount factor; set its SARS dataset to the datasetwe collected; and run LSPI until the weight values of its fitted linear function change no more than 10^-6 between iterations or until 30 iterationshave passed. import burlap.behavior.singleagent.learning.lspi.LSPI; LSPI lspi = new LSPI(domain, rf, tf, 0.99, fb);lspi.setDataset(dataset);lspi.runPolicyIteration(30, 1e-6); After LSPI has run until convergence, we will want to analyze the policy is produced. Since LSPI implements QComputablePlanner (which means it can return Q-values for state-action pairs), we can capture its policy by creating GreedyQ policy around it. To analyze the resulting policy, lets evaluate it from a start state in the bottom of the valley and animate the results (say 5 times). To visualize the animated results, we can simply grab the existing visualizer from the domain ( MountainCarVisualizer ), add a VisualActionObserver to the domain, and evaluate the policy from a start state. The state state in the valley can be retrieved from our Mountain Car domain generator instance. The code to do all that is provided below. import burlap.behavior.singleagent.planning.commonpolicies.GreedyQPolicy;import burlap.domain.singleagent.mountaincar.MountainCarVisualizer;import burlap.oomdp.singleagent.SADomain;import burlap.oomdp.core.State;import burlap.oomdp.singleagent.common.VisualActionObserver;import burlap.oomdp.visualizer.Visualizer; GreedyQPolicy p = new GreedyQPolicy(lspi);Visualizer v = MountainCarVisualizer.getVisualizer(mcGen);VisualActionObserver vexp = new VisualActionObserver(domain, v);vexp.initGUI();((SADomain)domain).addActionObserverForAllAction(vexp);State s = mcGen.getCleanState(domain);for(int i = 0; i < 5; i++){p.evaluateBehavior(s, rf, tf);}System.out.println(\"Finished.\"); If you now run the main method, you see at the start a bunch of print outs to the terminal specifying the maximum change in weight values after each policy iteration. When the change is small enough, LSPI will end and you'll get a window animating the the mountain car task using the results of LSPI. That is, you should see something like the below image. A screen cap from the animation of the Mountain car task Although the settings we used are pretty robust to failure, it is possible (even if unlikely) that the car won't make it to the right side, which indicates that LSPI failed to find a good policy from the valley of the hill. LSPI can fail if your dataset collection happened to be unluckily bad. However, if you rerun the code (resulting in a a new random data collection), you should find that it works. Radial Basis Functions Before we leave Mountain Car and LSPI for the next example, lets consider running LSPI on Mountain Car with a different kind of state basis features; specifically, lets consider using radial basis functions. A radial basis function is defined with a \"center\" state, a distance metric, and a bandwidth parameter. Given an input query state, the basis function returns a value between 0 and 1 with a value of 1 when the query state has a distance of zero from the function's \"center\" state. As the query state gets further away, the basis function's returned value degrades to a value of zero. The sensitivity of the basis function to the distance is defined by its bandwidth parameter; as the bandwidth value increases, the less sensitive the function is to distance (that is, a large bandwidth will result in it returning a value near 1 even when the query state is far away). A set of state features defined by a set of radial basis functions distributed across the state space gives an approximation of where a given state is. You can think of the set of radial basis function outputs as compressing the state space. As a consequence, a common approach to using radial basis functions is set up a coarse multi-dimensional grid over the state space with a separate radial basis function centered at each intersection point of the grid. BURLAP provides us tools to easily accomplish such a construction of radial basis functions. Lets start by a creating a new method for running LSPI with radial basis functions. It will look almost identical to the previous Fourier Basis LSPI method we created, except instead of defining Fourier basis functions, we'll define radial basis functions. For the moment, the code below will create in instance of a radial basis function state feature database ( RBFFeatureDatabase ), but we will need to add code to actually add the set of radial basis functions it uses. Also note that we moved the initial state object instantiation to earlier in the code, because we will use it to help define the center states of the radial basis functions we will create. The differencesare highlighted with comments in the code. import burlap.behavior.singleagent.vfa.rbf.RBFFeatureDatabase; public static void MCLSPIRBF(){MountainCar mcGen = new MountainCar();Domain domain = mcGen.generateDomain();TerminalFunction tf = new MountainCar.ClassicMCTF();RewardFunction rf = new GoalBasedRF(tf, 100);//get a state definition earlier, we'll use it soon.State s = mcGen.getCleanState(domain);StateGenerator rStateGen = new MCRandomStateGenerator(domain);SARSCollector collector = new SARSCollector.UniformRandomSARSCollector(domain);SARSData dataset = collector.collectNInstances(rStateGen, rf, 5000, 20, tf, null);//instantiate an RBF feature database, we'll define it more in a momentRBFFeatureDatabase rbf = new RBFFeatureDatabase(true);//notice we pass LSPI our RBF features this timeLSPI lspi = new LSPI(domain, rf, tf, 0.99, rbf);lspi.setDataset(dataset);lspi.runPolicyIteration(30, 1e-6);GreedyQPolicy p = new GreedyQPolicy(lspi);Visualizer v = MountainCarVisualizer.getVisualizer(mcGen);VisualActionObserver vexp = new VisualActionObserver(domain, v);vexp.initGUI();((SADomain)domain).addActionObserverForAllAction(vexp);for(int i = 0; i < 5; i++){p.evaluateBehavior(s, rf, tf);}System.out.println(\"Finished.\");} You'll notice that we passed \"true\" to our RBFFeatureDatabase constructor. The true flag indicates that that the feature database should include a constant feature that is always on. This is typically a good idea because it provides a Q-value \"y intercept\" value to the linear function that will be estimated. Note We did not need to specify the inclusions of a constant feature for the Fourier basis function feature database like we did for RBFs because the 0th order Fourier function is a constant \"always on\" feature. To construct a set of radial basis functions over a grid, we will first want to generate the states that lie at the intersection of grid points on a grid. To construct the set of states, we will make use of the StateGridder class in BURLAP. StateGridder allows you to set up arbitrarily specified grids over a state space and return the set of states that lie on the intersection points of the grid. StateGridder can even do things like include constant values for some attributes or objects (that is, attribute values that remain fixed for every state in the grid). For our current purposes, we just want a fairly simple grid that spans the full state space of Mountain Car. To get the set of states that span a 5x5 grid over the car position and velocity attributes (for a total of 25 states), add the below code right below the instantiation of the RBFFeatureDatabase (with the requisite imports going at the top of the file, of course). If you want to know how to set up a more specific grid (e.g., an asymmetric grid like a 3x7), see the class's documentation import burlap.behavior.singleagent.auxiliary.StateGridder;import java.util.List; RBFFeatureDatabase rbf = new RBFFeatureDatabase(true);StateGridder gridder = new StateGridder();gridder.gridEntireDomainSpace(domain, 5);List<State> griddedStates = gridder.gridInputState(s); Notice that the gridInputState method requires an example State object? An example state is required because it's what tells the gridder how many objects of each object class need to be gridded (and what any constant ungridded objects/values are). Now that we have a bunch of states distributed over a uniform grid of the state space, we will want to create radial basis functions centered at each of those states. Since a radial basis function also needs a distance metric between states, let us use a Euclidean distance metric. BURLAP already has an Euclidean distance metric implementation, but it requires that a state first be converted to a feature vector, which we can again do using the ConcatenatedObjectFeatureVectorGenerator (and we will again normalize the attribute values). To instantiate the distance metric, add the below code. import burlap.behavior.singleagent.vfa.rbf.DistanceMetric;import burlap.behavior.singleagent.vfa.rbf.metrics.EuclideanDistance; DistanceMetric metric = new EuclideanDistance( new ConcatenatedObjectFeatureVectorGenerator(true, MountainCar.CLASSAGENT)); Now we will add a radial basis function to our RBFFeatureDatabase for each state on the grid using the Euclidean distance metric and setting the bandwidth parameter to 0.2. In particular, we will use Gaussian radial basis functions . import burlap.behavior.singleagent.vfa.rbf.functions.GaussianRBF; for(State g : griddedStates){rbf.addRBF(new GaussianRBF(g, metric, .2));} Our final Mountain Car LSPI radial basis function method should now look like the below. public static void MCLSPIRBF(){MountainCar mcGen = new MountainCar();Domain domain = mcGen.generateDomain();TerminalFunction tf = mcGen.new ClassicMCTF();RewardFunction rf = new GoalBasedRF(tf, 100);//get a state definition earlier, we'll use it soon.State s = mcGen.getCleanState(domain);StateGenerator rStateGen = new MCRandomStateGenerator(domain);SARSCollector collector = new SARSCollector.UniformRandomSARSCollector(domain);SARSData dataset = collector.collectNInstances(rStateGen, rf, 5000, 20, tf, null);//set up RBF feature databaseRBFFeatureDatabase rbf = new RBFFeatureDatabase(true);StateGridder gridder = new StateGridder();gridder.gridEntireDomainSpace(domain, 5);List<State> griddedStates = gridder.gridInputState(s);DistanceMetric metric = new EuclideanDistance( new ConcatenatedObjectFeatureVectorGenerator(true, MountainCar.CLASSAGENT));for(State g : griddedStates){rbf.addRBF(new GaussianRBF(g, metric, .2));}//notice we pass LSPI our RBF features this timeLSPI lspi = new LSPI(domain, rf, tf, 0.99, rbf);lspi.setDataset(dataset);lspi.runPolicyIteration(30, 1e-6);GreedyQPolicy p = new GreedyQPolicy(lspi);Visualizer v = MountainCarVisualizer.getVisualizer(mcGen);VisualActionObserver vexp = new VisualActionObserver(domain, v);vexp.initGUI();((SADomain)domain).addActionObserverForAllAction(vexp);for(int i = 0; i < 5; i++){p.evaluateBehavior(s, rf, tf);}System.out.println(\"Finished.\");} If you now point your main method to call the MCLSPIRBF method, you should see similar results as before, only this time we've used radial basis functions! Now that we've demonstrated how to use LSPI on the mountain car domain with Fourier basis functions and radial basis functions, we'll move on to a different algorithm, Sparse Sampling, and a different domain, the Inverted Pendulum. Next Part", "http://burlap.cs.brown.edu/tutorials_v1/scd/p4.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Solving Continuous Domains Tutorials (v1) > Solving Continuous Domains > Part 4 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA(\u03bb) Conclusions Final Code Previous Part Conclusions In this tutorial we showed you how to solve continuous state problems with three different algorithms implemented in BURLAP: LSPI, Sparse Sampling, and gradient descent SARSA(\u03bb). We also demonstrated how to use these algorithms on three different continuous state domains: Mountain Car, Inverted Pendulum, and Lunar Lander. And finally, we also explained how to use three different basis functions (which can be used with LSPI and gradient descent SARSA(\u03bb)): Fourier basis functions, radial basis functions and CMACs/Tile coding. Hopefully these examples have made clear the kinds of tools you need to use solve any other continuous state problems. As usual, you can find all of the code developed in this tutorial below. Final Code import burlap.behavior.singleagent.EpisodeAnalysis;import burlap.behavior.singleagent.EpisodeSequenceVisualizer;import burlap.behavior.singleagent.Policy;import burlap.behavior.singleagent.auxiliary.StateGridder;import burlap.behavior.singleagent.learning.GoalBasedRF;import burlap.behavior.singleagent.learning.lspi.LSPI;import burlap.behavior.singleagent.learning.lspi.SARSCollector;import burlap.behavior.singleagent.learning.lspi.SARSData;import burlap.behavior.singleagent.learning.tdmethods.vfa.GradientDescentSarsaLam;import burlap.behavior.singleagent.planning.commonpolicies.GreedyQPolicy;import burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSampling;import burlap.behavior.singleagent.vfa.ValueFunctionApproximation;import burlap.behavior.singleagent.vfa.cmac.CMACFeatureDatabase;import burlap.behavior.singleagent.vfa.common.ConcatenatedObjectFeatureVectorGenerator;import burlap.behavior.singleagent.vfa.fourier.FourierBasis;import burlap.behavior.singleagent.vfa.rbf.DistanceMetric;import burlap.behavior.singleagent.vfa.rbf.RBFFeatureDatabase;import burlap.behavior.singleagent.vfa.rbf.functions.GaussianRBF;import burlap.behavior.singleagent.vfa.rbf.metrics.EuclideanDistance;import burlap.behavior.statehashing.NameDependentStateHashFactory;import burlap.domain.singleagent.cartpole.InvertedPendulum;import burlap.domain.singleagent.cartpole.InvertedPendulumStateParser;import burlap.domain.singleagent.cartpole.InvertedPendulumVisualizer;import burlap.domain.singleagent.lunarlander.*;import burlap.domain.singleagent.mountaincar.MCRandomStateGenerator;import burlap.domain.singleagent.mountaincar.MountainCar;import burlap.domain.singleagent.mountaincar.MountainCarVisualizer;import burlap.oomdp.auxiliary.StateGenerator;import burlap.oomdp.auxiliary.StateParser;import burlap.oomdp.core.Domain;import burlap.oomdp.core.State;import burlap.oomdp.core.TerminalFunction;import burlap.oomdp.singleagent.RewardFunction;import burlap.oomdp.singleagent.SADomain;import burlap.oomdp.singleagent.common.VisualActionObserver;import burlap.oomdp.visualizer.Visualizer;import java.util.List;public class ContinuousDomainTutorial {public static void main(String [] args){//uncomment the example you want to see and comment out the rest.//MCLSPIFB();//MCLSPIRBF();//IPSS();LLSARSA();}public static void MCLSPIFB(){MountainCar mcGen = new MountainCar();Domain domain = mcGen.generateDomain();TerminalFunction tf = new MountainCar.ClassicMCTF();RewardFunction rf = new GoalBasedRF(tf, 100);StateGenerator rStateGen = new MCRandomStateGenerator(domain);SARSCollector collector = new SARSCollector.UniformRandomSARSCollector(domain);SARSData dataset = collector.collectNInstances(rStateGen, rf, 5000, 20, tf, null);ConcatenatedObjectFeatureVectorGenerator featureVectorGenerator =new ConcatenatedObjectFeatureVectorGenerator(true, MountainCar.CLASSAGENT);FourierBasis fb = new FourierBasis(featureVectorGenerator, 4);LSPI lspi = new LSPI(domain, rf, tf, 0.99, fb);lspi.setDataset(dataset);lspi.runPolicyIteration(30, 1e-6);GreedyQPolicy p = new GreedyQPolicy(lspi);Visualizer v = MountainCarVisualizer.getVisualizer(mcGen);VisualActionObserver vexp = new VisualActionObserver(domain, v);vexp.initGUI();((SADomain)domain).addActionObserverForAllAction(vexp);State s = mcGen.getCleanState(domain);for(int i = 0; i < 5; i++){p.evaluateBehavior(s, rf, tf);}System.out.println(\"Finished.\");}public static void MCLSPIRBF(){MountainCar mcGen = new MountainCar();Domain domain = mcGen.generateDomain();TerminalFunction tf = new MountainCar.ClassicMCTF();RewardFunction rf = new GoalBasedRF(tf, 100);//get a state definition earlier, we'll use it soon.State s = mcGen.getCleanState(domain);StateGenerator rStateGen = new MCRandomStateGenerator(domain);SARSCollector collector = new SARSCollector.UniformRandomSARSCollector(domain);SARSData dataset = collector.collectNInstances(rStateGen, rf, 5000, 20, tf, null);//set up RBF feature databaseRBFFeatureDatabase rbf = new RBFFeatureDatabase(true);StateGridder gridder = new StateGridder();gridder.gridEntireDomainSpace(domain, 5);List<State> griddedStates = gridder.gridInputState(s);DistanceMetric metric = new EuclideanDistance(new ConcatenatedObjectFeatureVectorGenerator(true, MountainCar.CLASSAGENT));for(State g : griddedStates){rbf.addRBF(new GaussianRBF(g, metric, .2));}//notice we pass LSPI our RBF features this timeLSPI lspi = new LSPI(domain, rf, tf, 0.99, rbf);lspi.setDataset(dataset);lspi.runPolicyIteration(30, 1e-6);GreedyQPolicy p = new GreedyQPolicy(lspi);Visualizer v = MountainCarVisualizer.getVisualizer(mcGen);VisualActionObserver vexp = new VisualActionObserver(domain, v);vexp.initGUI();((SADomain)domain).addActionObserverForAllAction(vexp);for(int i = 0; i < 5; i++){p.evaluateBehavior(s, rf, tf);}System.out.println(\"Finished.\");}public static void IPSS(){InvertedPendulum ip = new InvertedPendulum();ip.physParams.actionNoise = 0.;Domain domain = ip.generateDomain();RewardFunction rf = new InvertedPendulum.InvertedPendulumRewardFunction(Math.PI/8.);TerminalFunction tf = new InvertedPendulum.InvertedPendulumTerminalFunction(Math.PI/8.);State initialState = InvertedPendulum.getInitialState(domain);SparseSampling ss = new SparseSampling(domain, rf, tf, 1,new NameDependentStateHashFactory(), 10, 1);ss.setForgetPreviousPlanResults(true);Policy p = new GreedyQPolicy(ss);EpisodeAnalysis ea = p.evaluateBehavior(initialState, rf, tf, 500);StateParser sp = new InvertedPendulumStateParser(domain);ea.writeToFile(\"ip/ssPlan\", sp);System.out.println(\"Num Steps: \" + ea.numTimeSteps());Visualizer v = InvertedPendulumVisualizer.getInvertedPendulumVisualizer();new EpisodeSequenceVisualizer(v, domain, sp, \"ip\");}public static void LLSARSA(){LunarLanderDomain lld = new LunarLanderDomain();Domain domain = lld.generateDomain();RewardFunction rf = new LunarLanderRF(domain);TerminalFunction tf = new LunarLanderTF(domain);StateParser sp = new LLStateParser(domain);State s = LunarLanderDomain.getCleanState(domain, 0);LunarLanderDomain.setAgent(s, 0., 5.0, 0.0);LunarLanderDomain.setPad(s, 75., 95., 0., 10.);int nTilings = 5;CMACFeatureDatabase cmac = new CMACFeatureDatabase(nTilings,CMACFeatureDatabase.TilingArrangement.RANDOMJITTER);double resolution = 10.;double angleWidth = 2 * lld.getAngmax() / resolution;double xWidth = (lld.getXmax() - lld.getXmin()) / resolution;double yWidth = (lld.getYmax() - lld.getYmin()) / resolution;double velocityWidth = 2 * lld.getVmax() / resolution;cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS,domain.getAttribute(LunarLanderDomain.AATTNAME),angleWidth);cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS,domain.getAttribute(LunarLanderDomain.XATTNAME),xWidth);cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS,domain.getAttribute(LunarLanderDomain.YATTNAME),yWidth);cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS,domain.getAttribute(LunarLanderDomain.VXATTNAME),velocityWidth);cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS,domain.getAttribute(LunarLanderDomain.VYATTNAME),velocityWidth);double defaultQ = 0.5;ValueFunctionApproximation vfa = cmac.generateVFA(defaultQ/nTilings);GradientDescentSarsaLam agent = new GradientDescentSarsaLam(domain, rf, tf, 0.99,vfa, 0.02, 10000, 0.5);for(int i = 0; i < 5000; i++){EpisodeAnalysis ea = agent.runLearningEpisodeFrom(s); //run learning episodeea.writeToFile(String.format(\"lunarLander/e%04d\", i), sp); //record episode to a fileSystem.out.println(i + \": \" + ea.numTimeSteps()); //print the performance}Visualizer v = LLVisualizer.getVisualizer(lld);new EpisodeSequenceVisualizer(v, domain, sp, \"lunarLander\");}} End.", "http://burlap.cs.brown.edu/tutorials_v2/bd/p1.html": "` Building a Domain MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}}); BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building a Domain Tutorials > Building a Domain > Part 1 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Next Part You are viewing the tutorial for BURLAP 2; if you'd like the BURLAP version 1 tutorial, go here . Introduction This tutorial will cover three topics. First, we will discuss Markov Decision Processes (MDPs) and more specifically, Object-oriented MDPs (OO-MDPs): the decision making process that BURLAP uses to express single agent domains and decision making problems; then we will discuss how BURLAP implements that OO-MDPs. Finally, we will cover how to create a domain, so that the planning and learning algorithms in BURLAP can be used on it, as well as how to visualize it, which is useful for testing and reviewing results. Other Problem Types Beyond MDPs, BURLAP also supportsstochastic games and partially observable MDPs, but a discussion of those problem types will be left for a different tutorial and many of the coreelements of the OO-MDP code that BURLAP uses is reused with the other problem types. If you are alreadyfamiliar with MDPs or OO-MDPs, or just want to get down to coding, feel free to skip the firstsections that discuss their mathematical description. For more information on how to useplanning and learning algorithms on the OO-MDP domains that you create or that are already in BURLAP, see the Basic Planning and Learning tutorial. Markov Decision Process To define worlds in which an agent can plan or learn, BURLAP uses the object-oriented Markov Decision Process (OO-MDP) formalism, which is an extension of the classic Markov Decision Process (MDP) formalism.An MDP provides a formal definition of a world, how it works, and how the agent who will be making decisions interacts with the world in a series of discretetime steps. In this tutorial we will formalize a grid world as an MDP. A grid world is a 2D world in which an agent can move north, south, east or west by one unit, provided there are no walls in the way. The below image shows a simple grid world with the agent's position represented by a gray circle and walls of the world painted black. Typically, the goal in a grid world is for the agent to navigate to some location, but there are a number of variants. An example grid world. To define any world and task as an MDP, we will need to break down the problem into four components: a set of possible states of the world ($S$); a set of actions that the agent can apply ($A$); a definition of how actions change the state of the world, known as the transition dynamics ($T$); and the rewards the agent receives for each of its actions ($R$), known as the reward function, which will determine what the best behavior is (that is, the agent will want to act in a way that maximizes the reward it receives). The transition dynamics are formulated as a probabilistic function $T(s' | s, a)$, which defines the probability of the world changing to state $s'$ in the next discrete timestep when the agent takes action $a$ in the current state $s$. The fact that the world can change stochastically is one of the unique properties of an MDP compared to more classic planning/decision making problems. The reward function is defined as $R(s, a, s')$, which returns the reward received for the agent taking action $a$ in state $s$ and then transitioning to state $s'$. Notice how both the transition dynamics and reward function are temporally independent from everything predating the most recentstate and action? Requiring this level of temporal independence makes this a Markov system and is why this formalism is called a Markov decision process. In our grid world, the set of states are the possible locations of the agent. The actions are north, south, east, and west. We will make the transition dynamics stochastic so that with high probability (0.8) the agent will move in the intended direction, and with some low probability (0.2) move in a different direction. The transition dynamics will also encode the walls of our grid world by specifying that movement that would lead into a wall will result in returning to the same state. Finally, we can define a reward function that returns a high reward when the agent reaches the top right corner of the world and zero everywhere else. For various kinds of problems, the concept of terminal states is often useful. A terminal state is a state that once reached causes all further action of the agent to cease. This is a useful concept for defining goal-directed tasks (i.e., action stops once the agent achieves a goal), failure conditions, or any number of other reasons. In our grid world, we'll want to specify the top right corner the agent is trying to get to as a terminal state. An MDP definition does not include a specific element for specifying terminal states because they can be implicitly defined in the transition dynamics and reward function. That is, a terminal state can be encoded in an MDP by being a state in which every action causes a deterministic transition back to itself with zero reward. However, for convenience and other practical reasons, terminal states in BURLAP are specified directly with a function (more on that later). The goal of planning or learning in an MDP is to find the behavior that maximizes the reward the agent receives over time. More formally, we'd say that the goal is to find a policy ($\\pi$), that is a mapping from states in the MDP to actions that the agent takes ($\\pi : S \\rightarrow A$). Sometimes, the policy can also be defined as a probability distribution over action selection in each state (and BURLAP supports this represenation), but for the moment we will consider the case when it is a direct mapping from states to actions. To find the policy that maximizes the reward over time, we must first define what it means to maximize reward over time and there are a number of different temporal objectives wecan imagine that change what the optimal policy is. Perhaps the most intuitive way to define the temporal reward maximization is to maximize thethe expected total future reward; that is, the best policy is the one that results in largest possible sum of all future rewards. Although this metric is sometimes appropriate, it's often problematic because it can result in policies that are evaluated to have infinite value or which do not discriminate between policies that receive the rewards more quickly. For example, in our grid world, any path the agent took to reach the top right would have a value 1 (because they all would eventually reach the goal); however, what we'd probably want instead is for the agent to prefer a policy that reaches the goal as fast as possible. Moreover, if we didn't set the top right corner to be a terminal state, the agent could simply move away from it and back into it, resulting in any policy that reaches the goal having an infinite value, which makes comparisons between different policies even more difficult! A commonalternative that is more robust is to define the objective to beto maximize the expected discounted future reward. That is, theagent is trying to maximize expected sum$$\\large \\sum_{t=0}^\\infty \\gamma^t r_t,$$where $r_t$ is the reward received at time $t$ and $\\gamma$ is the discount factor that dictates how much preference an agent has for more immediate rewards; in other words, the agent's patience. With $\\gamma = 1$, the agent values distantrewards that will happen much further in the future as much as the reward the agent will receive in the next time step; therefore, $\\gamma = 1$ results in the same objective of summing all future rewards together and will have the same problems previously mentioned. With $\\gamma = 0$ all the agent values only the next reward and does not care about anything that happens afterwards, thereby resulting in all policies having a finite value. This setting has the inverse effect of the agent never caring about our grid world goal location unless it's one step away. However, a $\\gamma$ value somewhere in between 0 and 1 often results in what we want. That is, for all values of $0 \\le \\gamma \\lt 1$, the expected future discounted reward in an MDP when following any given policy is finite. If we set $\\gamma$ to 0.99 in our grid world, the result is that the agent would want to get to the goal as fast as possible, because waiting longer would result in the eventual +1 goal reward being more heavily discounted. Although there are still other ways to define the temporal objective of an MDP, current learning and planning algorithms in BURLAP are based on usingthe discounted reward, with the geometric discout factor $\\gamma$ left as a parameter that the user can specify. Next Part", "http://burlap.cs.brown.edu/tutorials_v2/bd/p3.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building a Domain Tutorials > Building a Domain > Part 3 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Previous Part | Next Part Defining GridWorld Object Classes To begin implementing our grid world domain in BURLAP, we will create a class that in this tutorial we will call ExampleGridWorld. Furthermore, we will make it implement the DomainGenerator interface, which is a common convention in BURLAP when developing domains and requires implementing the generateDomain() method. In that method, we will create an SADomain object that will keep track of all of our attributes, object classes, etc. that we define. (Note that the Domain class that is returned by the method is the abstract superclass of SADomain.) You should have code that looks like the below; to make things easier for the future, the below code has all of the library imports that you'll need for the rest of the tutorial. import burlap.oomdp.auxiliary.DomainGenerator;import burlap.oomdp.core.*;import burlap.oomdp.core.objects.MutableObjectInstance;import burlap.oomdp.core.objects.ObjectInstance;import burlap.oomdp.core.states.MutableState;import burlap.oomdp.core.states.State;import burlap.oomdp.singleagent.*;import burlap.oomdp.singleagent.common.SimpleAction;import burlap.oomdp.singleagent.environment.SimulatedEnvironment;import burlap.oomdp.singleagent.explorer.TerminalExplorer;import burlap.oomdp.singleagent.explorer.VisualExplorer;import burlap.oomdp.visualizer.ObjectPainter;import burlap.oomdp.visualizer.StateRenderLayer;import burlap.oomdp.visualizer.StaticPainter;import burlap.oomdp.visualizer.Visualizer;import java.awt.*;import java.awt.geom.Ellipse2D;import java.awt.geom.Rectangle2D;import java.util.*;import java.util.List;public class ExampleGridWorld implements DomainGenerator {@Overridepublic Domain generateDomain() {SADomain domain = new SADomain();return domain;}} The first thing that we will want to decide in the construction of our domain is what the object classes and attributes that define the domain are. For our grid world, we will define two object classes: an agent class, to represent the agent in the world; and a location class, which we can use to refer to special places in the world. The location class isn't necessary to define grid world problems, but we're going to include it to help illustratehow to define propositional functions in BURLAP. Both the agent and location class will be defined by their x and y position in the 2D world. For convenience, it is often useful to define the names of all attributes, object classes, etc. that the domain definesas string constants so that they can be precisely referenced by code that uses the domain, so lets add those to our code now. public static final String ATTX = \"x\";public static final String ATTY = \"y\";public static final String CLASSAGENT = \"agent\";public static final String CLASSLOCATION = \"location\"; Next we will create the actual Attribute objects and the classes associated with them. Since grid worlds have discrete states, but our attributes represent numeric positions, we willset our attributes to be of type int. We will also construct a world that is 11x11 in size, so we will set the attribute limits to be from 0 to 10 inclusively. @Overridepublic Domain generateDomain() {SADomain domain = new SADomain();Attribute xatt = new Attribute(domain, ATTX, AttributeType.INT);xatt.setLims(0, 10);Attribute yatt = new Attribute(domain, ATTY, AttributeType.INT);yatt.setLims(0, 10);ObjectClass agentClass = new ObjectClass(domain, CLASSAGENT);agentClass.addAttribute(xatt);agentClass.addAttribute(yatt);ObjectClass locationClass = new ObjectClass(domain, CLASSLOCATION);locationClass.addAttribute(xatt);locationClass.addAttribute(yatt);return domain;} Notice how we never directly told the domain about the attributes or object classes that we created? That's because the constructor of the attributes and object classes will tell the domain about themselves automatically to streamline construction. With that code written, we're already finished defining the state representation of the domain! The next step will be to define actions. Defining GridWorld Actions Defining actions in BURLAP means specifying the actions the agent can take, their preconditions (if any), their parameters (if any), and their transition dynamics. We will construct four actions: north, south, east, and west. None of these actions will have preconditions and they will not take any parameters. The transition dynamics we define for them will depend on the location of walls in the world. We could have potentially made the walls objects of the OO-MDP themselves,but for simplifying the state representation we will keep the walls embedded in our transition dynamics without explicit state representation. To facilitate the definition of the transition dynamics, we will create a 2D int matrix specifying the location of walls in each cell. We will also create a world withthe same wall layout shown in the image at the beginning of this tutorial. To do so, add the following code. //ordered so first dimension is xprotected int [][] map = new int[][]{{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,0,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{1,0,1,1,1,1,1,1,0,1,1},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,0,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},}; Next we will create our actions. We will define north, south, east, and west actions that have a probability of 0.8 of going in the intended direction and a probability of 0.2 of going in any other direction. To define single agent actions in BURLAP, we subclass the Action class. In this case, we will create a single subclass, called Movement, and instantiate it multiple times for each movement direction. Subclassing Action requires us to implement a number of abstract methods that describe and operationalize the action, such preconditions, parameters, and transition dynamics. Since movement acitons will not have any preconditions or parameters, we can subclass SimpleAction , which will handle the methods for no preconditions or parameters requiring us only to implement the performActionHelper method of Action. The method performActionHelper method is called whenever an action is applied in simulation to a State and must return the resulting state from applying the action. If our action is stochastic, then this method should randomly sample and return an outcome state according to the probability distribution. In addition to being able sample action transitions from our Action, we would like to specify the full probability distribution of action effects from our action, which means we will want to have our Action implement the FullActionModel interface. This interface requires implementing a getTransitions method, which returns a list of all possible outcome states when an action is applied and their probabiltiy of occurring. Implementing this interface will allow our domain to be solved by dynamic programming methods and other algorithms that require enumerating the full probability distribution, so it's useful to implement. However, not all domains will be able to enumerate the full probabiltiy distribution (for example, when it's infinite) so this remains an optional interface. In our case, the number of outcomes is finte and easy to specify, so we will implement it. Let us now write the skeleton of our Movement class as an inner class of our GridWorldExample: protected class Movement extends SimpleAction implements FullActionModel {@Overrideprotected State performActionHelper(State s, GroundedAction groundedAction) {return null;}@Overridepublic List<TransitionProbability> getTransitions(State s, GroundedAction groundedAction) {return null;}} So that we can reuse this Action class for each movement direction, lets define a data member that specifies the probability of going in each direction and let the intended direction (which will succeed with probability 0.8) be specified in the constructor, along with a name for the action and the domain to which it belongs. protected class Movement extends SimpleAction implements FullActionModel {//0: north; 1: south; 2:east; 3: westprotected double [] directionProbs = new double[4];public Movement(String actionName, Domain domain, int direction){super(actionName, domain);for(int i = 0; i < 4; i++){if(i == direction){directionProbs[i] = 0.8;}else{directionProbs[i] = 0.2/3.;}}}@Overrideprotected State performActionHelper(State s, GroundedAction groundedAction) {return null;}@Overridepublic List<TransitionProbability> getTransitions(State s, GroundedAction groundedAction) {return null;}} Notice how we called a super constructor with the action name and domain? Calling the super constructor will automatically connect the action with the domain object and set its name. Now we'll want to start defining our performActionHelper and getTransitions methods. To do so, lets add a helper method for getting the result of moving in a given direction. As long as the cell is free (that is, there is no wall), the agent will move to that position; if there is a wall there, the agent will stay in the same place. This method will then return the resulting x and y position of the agent. protected int [] moveResult(int curX, int curY, int direction){//first get change in x and y from direction using 0: north; 1: south; 2:east; 3: westint xdelta = 0;int ydelta = 0;if(direction == 0){ydelta = 1;}else if(direction == 1){ydelta = -1;}else if(direction == 2){xdelta = 1;}else{xdelta = -1;}int nx = curX + xdelta;int ny = curY + ydelta;int width = ExampleGridWorld.this.map.length;int height = ExampleGridWorld.this.map[0].length;//make sure new position is valid (not a wall or out of bounds)if(nx < 0 || nx >= width || ny < 0 || ny >= height || ExampleGridWorld.this.map[nx][ny] == 1){nx = curX;ny = curY;}return new int[]{nx,ny};} With this helper method defined, all the performActionHelper method needs to do is determine the current position of the agent, sample from the direction distribution, call the moveResult method to get the new position, and set the agent attribute values to the new position. Getting the direction and setting the values can be performed by grabbing agent object instance in the state and using the pertinent value getter and setter methods. Since there is only ever one agent object instance in the state, we can retrieve the agent ObjectInstance using the getFirstObjectOfClass method that returns the first object instance of an object belonging to a specified class in the state. @Overrideprotected State performActionHelper(State s, GroundedAction groundedAction) {//get agent and current positionObjectInstance agent = s.getFirstObjectOfClass(CLASSAGENT);int curX = agent.getIntValForAttribute(ATTX);int curY = agent.getIntValForAttribute(ATTY);//sample directon with random rolldouble r = Math.random();double sumProb = 0.;int dir = 0;for(int i = 0; i < this.directionProbs.length; i++){sumProb += this.directionProbs[i];if(r < sumProb){dir = i;break; //found direction}}//get resulting positionint [] newPos = this.moveResult(curX, curY, dir);//set the new positionagent.setValue(ATTX, newPos[0]);agent.setValue(ATTY, newPos[1]);//return the state we just modifiedreturn s;} The anatomy of performActionHelper You might have two questions about the performActionHelper method that we didn't explain; first you might wonder what the GroundedAction method argument is for; second you might wonder if it's safe to directly modify the input State and return it, rather than making a new state and returning it. The GroundedAction argument is provided because BURLAP supports parameterized actions; that is, actions that require the agent to select parameter values to execute the action. For example, in a blocks world, we can imagine a parameterized \"stack\" action that requires two block parameters to be specified: which block to pick up and on which block to stack it. Since our Action definition is not parameterized, we do not have to worry about which parameter values were specified, but if it was, the GroundedAction class (or rather subclasses of it that depend on the kind of parameterization used) would contain all the parameter information needed to apply the action and in the performActionHelper method, we would look inside the provided GroundedAction to determine the outcome. Note that this paradigm is used for many other Action methods as well (though they are not implemented here since we extended SimpleAction). Regarding modifying the input state directly, this is safe to do because performActionHelper is always called indirectly through the method perfomAction. The performAction method first makes a copy of its input state and then passes that to performActionHelper, thereby ensuring that performActionHelper cannot modify an important state used by the calling code. For the getTransition method, we'll do something similar, except in this case, we'll enumerate all possible outcomes, not just sample one, and create a new state object for each possible outcome. Each outcome will be also be associated with its probability of occurring, and we use the TransitionProbability class to store this paired outcome-probability association. As we assign the probabilities, we need to make sure they sum to one. We need to be careful here, because it's possible for two directions to result in the same outcome state. For example, if the agent is adjacent to a wall to the west and south, then movements in the west and south direction would result in the same outcome: no movement. Therefore, we sum together the probabilities of all movement directions that go into a wall and therefore result in no movement. @Overridepublic List<TransitionProbability> getTransitions(State s, GroundedAction groundedAction) {//get agent and current positionObjectInstance agent = s.getFirstObjectOfClass(CLASSAGENT);int curX = agent.getIntValForAttribute(ATTX);int curY = agent.getIntValForAttribute(ATTY);List<TransitionProbability> tps = new ArrayList<TransitionProbability>(4);TransitionProbability noChangeTransition = null;for(int i = 0; i < this.directionProbs.length; i++){int [] newPos = this.moveResult(curX, curY, i);if(newPos[0] != curX || newPos[1] != curY){//new possible outcomeState ns = s.copy();ObjectInstance nagent = ns.getFirstObjectOfClass(CLASSAGENT);nagent.setValue(ATTX, newPos[0]);nagent.setValue(ATTY, newPos[1]);//create transition probability object and add to our list of outcomestps.add(new TransitionProbability(ns, this.directionProbs[i]));}else{//this direction didn't lead anywhere new//if there are existing possible directions//that wouldn't lead anywhere, aggregate with themif(noChangeTransition != null){noChangeTransition.p += this.directionProbs[i];}else{//otherwise create this new state and transitionnoChangeTransition = new TransitionProbability(s.copy(),this.directionProbs[i]);tps.add(noChangeTransition);}}}return tps;} With the Action class defined, we'll want to hook it up to our domain. First, lets add some string constants for the names of the actions. public static final String ACTIONNORTH = \"north\";public static final String ACTIONSOUTH = \"south\";public static final String ACTIONEAST = \"east\";public static final String ACTIONWEST = \"west\"; Then we just need to call the constructor in our generateDomain method. As with the object classes and attributes, calling the constructor will automatically tell our domain about it, so we don't need to do anything further. new Movement(ACTIONNORTH, domain, 0);new Movement(ACTIONSOUTH, domain, 1);new Movement(ACTIONEAST, domain, 2);new Movement(ACTIONWEST, domain, 3);; Defining Propositional Functions Although we have a functioning domain at this point, we're going to add an optional propositional function to it to demonstrate how to use them. The propositional function we will create is at(agent, location). Notice that it will take two parameters, one which is an OO-MDP object belonging to OO-MDP class \"agent\" and the other an OO-MDP object belonging to OO-MDP class \"location.\" The function should evaluate to true when the provided agent object's position is equal to the provided location object's position. To implement this function, we will need to subclass the PropositionalFunction class. Lets first create another string constant for the name of the function. public static final String PFAT = \"at\"; And then lets make the shell of the class implementation with a constructor. protected class AtLocation extends PropositionalFunction{public AtLocation(Domain domain){super(PFAT, domain, new String []{CLASSAGENT,CLASSLOCATION});}@Overridepublic boolean isTrue(State s, String[] params) {// TODO Auto-generated method stubreturn false;}} Inside the constructor we called a super constructor that takes as arguments the name of the propositional function, the domain with which it will be associated, and an array specifying the OO-MDP class types to which its parameters must adhere. Now lets implement the isTrue method, which is as simple as getting the object instances of the provided parameters and checking if the attributes are equal. The parameters that are provided to the method are the names (or identifiers) of the objects in the world that it's referencing, so we can retrieve the objects from the provided state object by simply querying for the object with the given identifier. @Overridepublic boolean isTrue(State s, String[] params) {ObjectInstance agent = s.getObject(params[0]);ObjectInstance location = s.getObject(params[1]);int ax = agent.getIntValForAttribute(ATTX);int ay = agent.getIntValForAttribute(ATTY);int lx = location.getIntValForAttribute(ATTX);int ly = location.getIntValForAttribute(ATTY);return ax == lx && ay == ly;} Finally, lets call the constructors from our generateDomain method. As before, the constructor will automatically tell the domain about the propositional function. Our final generateDomain method will look like the below. @Overridepublic Domain generateDomain() {SADomain domain = new SADomain();Attribute xatt = new Attribute(domain, ATTX, AttributeType.INT);xatt.setLims(0, 10);Attribute yatt = new Attribute(domain, ATTY, AttributeType.INT);yatt.setLims(0, 10);ObjectClass agentClass = new ObjectClass(domain, CLASSAGENT);agentClass.addAttribute(xatt);agentClass.addAttribute(yatt);ObjectClass locationClass = new ObjectClass(domain, CLASSLOCATION);locationClass.addAttribute(xatt);locationClass.addAttribute(yatt);new Movement(ACTIONNORTH, domain, 0);new Movement(ACTIONSOUTH, domain, 1);new Movement(ACTIONEAST, domain, 2);new Movement(ACTIONWEST, domain, 3);new AtLocation(domain);return domain;} Getting all propositional function bindings Although we have defined a propositional function, you might be wondering how you can find all possible parameters in a state with which it can be evaluated. The PropositionalFunction super class provides a method for doing just this called getAllGroundedPropsForState(State) , which will return a list of GroundedProp objects that can be evaluated. A GroundedProp is simply a PropositionalFunction object reference and parameters with which to evaluate it. Similarly, if you want all possible GroundedProp objects for a list of different PropositionalFunction objects, you can use the PropositionalFunction static method getAllGroundedPropsForState(State) . Testing the Domain We now have a functional domain! However, it's probably important to test that the domain actually works as expected. By the end of this tutorial we will have created a visualizer for our domain that we can use to interactively visualize and test it, but we can also test it in the command line. To test our domain, lets first add a method to generate a state with the agent in the bottom left corner and a location object in the top right. public static State getExampleState(Domain domain){State s = new MutableState();ObjectInstance agent = new MutableObjectInstance(domain.getObjectClass(CLASSAGENT), \"agent0\");agent.setValue(ATTX, 0);agent.setValue(ATTY, 0);ObjectInstance location = new MutableObjectInstance(domain.getObjectClass(CLASSLOCATION), \"location0\");location.setValue(ATTX, 10);location.setValue(ATTY, 10);s.addObject(agent);s.addObject(location);return s;} Note that we made this method static and had it take as a parameter the domain object. We made the method static because the domain object is only ever created once the generateDomain method is called and that method can produce different Domain objects each time it is called. (Although not especially important for our example, this is useful if you have parameterizable domains.) Since ObjectInstance objects have to belong to a specific ObjectClass, we have to have the have the corresponding domain object from which to retrieve the ObjectClass. Since State and ObjectInstance are interface that can have any number of implementation, we need to choose one. Since we're no doing anything fancy, we can use the simple MutableState and MutableObjectInstance implementations . In addition to taking an ObjectClass, the MutableObjectInstance constructor also takes as a parameter the name or identifier of the object instance. This name will be used to identify the object from other objects in the state and to further disambiguate it from multiple objects of the same class. This name is also what will be passed to the PropositionalFunction isTrue method parameters. Lets now add a main method that we will launch into to test our domain. To do the testing, we will make use the TerminalExplorer which lets us act as the agent through the command line. Create the main method as shown below. public static void main(String [] args){ExampleGridWorld gen = new ExampleGridWorld();Domain domain = gen.generateDomain();State initialState = ExampleGridWorld.getExampleState(domain);TerminalExplorer exp = new TerminalExplorer(domain, initialState);exp.explore();} TerminalExplorer and Environment instances It's worth noting that the terminal explorer works by taking command line commands from a user, interpreting them into actions, and feeding them into an Environment (it also has some other special commands you can give which you'll see when you start it). When we use a constructor with just a domain and initial state, it creates a SimulatedEnvironment instance using that domain, but we could have provided any other Environment instead using a different constructor. When you run main in the command line/terminal you should see a print out describing the example state. If you now type the name of an action (such as \"north\") and hit enter, it will change state and print out the new state. Remember that our actions are stochastic, so 20% of the time you'll find yourself going in a different direction! While using the TerminalExplorer works for all domains that you might create, as your domains get more complex it be can be difficult to make sense of them from text alone. Having a visualizer makes understanding what's happening in your domain much easier. Furthermore, you can reuse a visualizer not just for interacting in the world yourself, but for visualizing results of learning and planning algorithms. In the next sections, we will walk through how to create a state visualizer for this domain. Next Part", "http://burlap.cs.brown.edu/tutorials_v2/bd/p2.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building a Domain Tutorials > Building a Domain > Part 2 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Previous Part | Next Part OO-MDPs In the classic MDP formalism, each state is simply described by its identity. The cell in the bottom left corner of the grid world would simply be state \"0\" and the one above it might simply be state \"11.\" This is known as a flat state representation because there is no other information about the states other than their identity. Although many planning/learning algorithms work just fine with flat representations, using a flat state representation makes defining transition dynamics and reward functions inconvenient. In fact, when we described the gridworld in the previous section, we used words regarding spatial adjacency and direction to explain it. It would similarly be nice to define the states, transitions, etc. using such concepts. For these reasons (and others), it is oftenmuch easier to use a factored state representation, which can be exploited when defining the MDP transition dynamics and other properties. A classic way to define a factored state representation is with a set of state variables or attributes . In our grid world, for example, we would define the state by an x-position attribute and a y-position attribute. The bottom left cell of the world would be state (0, 0); the cell directly above it would be (0, 1); and so on. The factored representation that BURAP uses is the object-oriented MDP (OO-MDP), which rather than representing states by a set of attributes, states are represented by a set of objects . Each object belongs to an object class, and each object class has an associated set of attributes. Each attribute can be of a different type with its own value domain. An object in a state is simply a value assignment to its class' attributes. In our grid world, we can define an \"agent\" class that has two integer attributes associated with it with a value domain spanning the width and height of the grid world. In this definition, a state would contain an object instance belonging to the agent class with a value assignment specifying the agent's x and y position. Although grid worlds are simple enough to describe without using an OO-MDP representation, there are a number of reasons why the OO-MDP representation is useful. For example, it's trivial to define transition dynamics that create new objects in the world or remove them, merely by having the objects added or removed from the list of objects present in a state. If there are multiple objects belonging to the same class, states can also be defined invariantly to the identifier or order of the objects in the state. We call this kind of invariance object identifier independence . For example, consider a state (s0) made up of two block objects (block0 and block1) that are each defined by spatial position information (an x and y attribute). Now imagine a new state (s1) that is the result of swapping the positions of block0 and block1. Even though the object identifiers associated with the block positions (block0 and block1) are different between s0 and s1, these really are the same state and when equality is object identifier independent they will be considered equal. The below illustration helps clarify this property. BURLAP supports both object idenitifer independence and dependence, depending on your needs. See the Basic Planning and Learning Tutorial for more information on using object identifier independence. Another advantage to the OO-MDP paradigm is that it leverages the object-oriented nature to provide additional high-level state features in the form of propositional functions that operate on objects in the world. In our grid world, we can introduce an additional object class for location objects (similarly defined by x,y position attributes) and then define a propositional function called \"at\" that operates on the agent object and a location object and evaluates to true when they are in the same location. Including propositional functions is useful for bridging the gap between MDPs and more classic AI approaches that are based on logical representations. In this tutorial we will implement the \"at\" propositional function in our grid world to demonstrate how to create them. BURLAP OO-MDP Java Class Overview BURLAP implements the OO-MDP paradigm in Java with the following class structure, which can be found in the packages burlap.oomdp.core and burlap.oomdp.singleagent . Attribute - this class defines an attribute name, data type, and value range. Attribute data types can be discrete (categorical or integers), real-valued, relational, strings, or int and double arrays for very large data. ObjectClass - this class defines an object class name and is defined with an associated set of Attribute objects. Value - this class provides a value assignment for a specific attribute. There is a different Value subclass for each attribute data type, but management of it is handled behind the scenes. ObjectInstance - this interface is used to represent an OO-MDP object, which is defined by an ObjectClass and a set of Value assignments to each of the class' Attribute objects. State - this interface provides methods to retrieve infromation about an OO-MDP state, such as getting the vairous ObjectInstance elements that define it. PropositionalFunction - this abstract class is subclassed to define propositional functions of an OO-MDP that operate on objects in State objects. Action - this abstract class is subclassed to provide the definitions of actions that an agent can take in the world. The action subclass defines the transition dynamics for the action, preconditions (if any), and parameters the action takes (if any). TransitionProbability - this class is a pair that defines the probability of transitioning to another state and is returned by the Action class when querying for its transition dynamics. GroundedAction - this class provides a reference to an action and the specific parameters (if any) with which it should be applied. GroundedProp - this class provides a reference to a PropositionalFunction and the parameters with which it will be evaluated. SADomain - this class provides the definition of an OO-MDP domain, and includes the references to all of the ObjectClass objects, Attribute objects, PropositionalFunction objects, and Action objects that define the domain. TerminalFunction - this interface is implemented to specify the terminal states of a task in a specific OO-MDP domain. RewardFunction - this interface is implemented to specify the rewards received for any state, action, next state transition. State implementations Because State and ObjectInstance are interfaces, you must choose a specific implementaiton that handles how they manage memory and datastructures for storing the information. All the included Domain's in BURLAP make use of the MutableState and MuableObjectInstance implemenations, which is a good place to start. However, if your domain is computationally demanding, you may want to consider writing your own implementation that handles memory and allows access to information in the most efficient way possible. Next Part", "http://burlap.cs.brown.edu/tutorials_v2/bd/p4.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building a Domain Tutorials > Building a Domain > Part 4 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Previous Part | Next Part The Components of a Visualizer Different visualization components in BURLAP are built around implementing the RenderLayer interface, which requires being passed a graphics context on which the implementing class will paint. Having everything built around RenderLayer objectsmeans you can trivially stack different kinds of information ontop of each other. For example, you might have a render layer to display a state, and another one to display value function information, layered on top. In this tutorial we will focus onrendering the state, for which there is a specific implementation of the RenderLayer interface that we can use called StateRenderLayer , which after constructing we can pass to the Visualizer class, which will create a Java canvas to which are StateRenderLayer can paint. The StateRenderLayer is provided a number of different subpainters that it will call sequentially to paint to the canvas. Each subpainter is either a StaticPainter or an ObjectPainter . The StaticPainter is an interface that requires implementing a method that takes a graphics context, an OO-MDP State object, and the width and height of the canvas that then paints to the canvas information about the overall state or the domain to which the state belongs. For example, in the grid world we've been creating, walls are not explicitly represented in our OO-MDP state object, but when rendering a state, we'd like to paint where the walls are. The ObjectPainter is an interface that requires implementing a method that takes a graphics context, an OO-MDP state, a specific OO-MDP ObjectInstance from that state, and the width and height of the canvas that then paints to the canvas information about that specific object instance. In our GridWorld, we would want to provide a different ObjectPainter forthe agent class objects and location class objects. When our StateRenderLayer object is provided a bunch of StaticPainter and ObjectPainter objects, during it's state paint method it will first paint to the graphics context with the StaticPainter objects. Then for each OO-MDP object in the state, it will paint to the canvas using the corresponding ObjectPainterthat we will associate with that class. Implementing the Painters To implement a StaticPainter for painting the walls of our grid world as black rectangles, add the below inner class to the ExampleGridWord class code we've been writing. public class WallPainter implements StaticPainter{@Overridepublic void paint(Graphics2D g2, State s, float cWidth, float cHeight) {//walls will be filled in blackg2.setColor(Color.BLACK);//set up floats for the width and height of our domainfloat fWidth = ExampleGridWorld.this.map.length;float fHeight = ExampleGridWorld.this.map[0].length;//determine the width of a single cell on our canvas //such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;//pass through each cell of our map and if it's a wall, paint a black //rectangle on our cavas of dimension widthxheightfor(int i = 0; i < ExampleGridWorld.this.map.length; i++){for(int j = 0; j < ExampleGridWorld.this.map[0].length; j++){//is there a wall here?if(ExampleGridWorld.this.map[i][j] == 1){//left corrdinate of cell on our canvasfloat rx = i*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas//origin is in the top left instead of the bottom rightfloat ry = cHeight - height - j*height;//paint the rectangleg2.fill(new Rectangle2D.Float(rx, ry, width, height));}}}}} The main idea of this code is to first determine how wide and tall cells in our grid world will be rendered on a canvas of the given size. This is simply with width/height of the canvas dividedby the number of cells in our grid world along each dimension.Then we iterate through our map and draw a rectangle in the corresponding position when the map has a wall listed as being there. The only extra thing to take care of is that the Javapainting coordinate system is in the top left corner, whereaswe've defined our map with a bottom left coordinate system, so we perform a coordinate system switch in the rendering as shown. Now lets create a painter for the OO-MDP agent class, which we'll represent as a gray circle in the word. This codewill look almost identical to our map painter code except instead of iterating through the map, we'll get the agent x and y position from the OO-MDP ObjectInstance our painter is provided and instead of painting a black rectangle we'll paint a gray circle. As before add the below class inside our ExampleGridWorld class. public class AgentPainter implements ObjectPainter{@Overridepublic void paintObject(Graphics2D g2, State s, ObjectInstance ob,float cWidth, float cHeight) {//agent will be filled in grayg2.setColor(Color.GRAY);//set up floats for the width and height of our domainfloat fWidth = ExampleGridWorld.this.map.length;float fHeight = ExampleGridWorld.this.map[0].length;//determine the width of a single cell on our canvas //such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;int ax = ob.getIntValForAttribute(ATTX);int ay = ob.getIntValForAttribute(ATTY);//left coordinate of cell on our canvasfloat rx = ax*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas //origin is in the top left instead of the bottom rightfloat ry = cHeight - height - ay*height;//paint the rectangleg2.fill(new Ellipse2D.Float(rx, ry, width, height));}} We'll also do the same for a location object, but we'll use a blue rectangle instead. public class LocationPainter implements ObjectPainter{@Overridepublic void paintObject(Graphics2D g2, State s, ObjectInstance ob,float cWidth, float cHeight) {//agent will be filled in blueg2.setColor(Color.BLUE);//set up floats for the width and height of our domainfloat fWidth = ExampleGridWorld.this.map.length;float fHeight = ExampleGridWorld.this.map[0].length;//determine the width of a single cell on our canvas //such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;int ax = ob.getIntValForAttribute(ATTX);int ay = ob.getIntValForAttribute(ATTY);//left coordinate of cell on our canvasfloat rx = ax*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas //origin is in the top left instead of the bottom rightfloat ry = cHeight - height - ay*height;//paint the rectangleg2.fill(new Rectangle2D.Float(rx, ry, width, height));}} Finally, we'll want to add some methods to our ExampleGridWorld domain generator to create a StateRenderLayer and correspondingVisualizer to hold it. The StateRenderLayer merely needs to be given a WallPainter instance and told to use a AgentPainter instance for objects of OO-MDP class agent and a LocationPainter instance for objects of OO-MDP class location. Once a StateRenderLayer object is created, a Visualizer object merely needs to be pointed to it. To do so, add the following methods to our ExampleGridWorld class. public StateRenderLayer getStateRenderLayer(){StateRenderLayer rl = new StateRenderLayer();rl.addStaticPainter(new WallPainter());rl.addObjectClassPainter(CLASSLOCATION, new LocationPainter());rl.addObjectClassPainter(CLASSAGENT, new AgentPainter());return rl;}public Visualizer getVisualizer(){return new Visualizer(this.getStateRenderLayer());} Note that in the getStateRenderLayer method we added the location object painter before the agent object painter. This implicitly tells the StateRenderLayer the order in which objects should be painted; first objects of class location and then objects of class agent. The result is that when an agent is at the same position as a location, the agent will be rendered on top of it. Now that we can construct a visualizer, lets swap out our TermainalExplorer in our main method for a VisualExplorer . The VisualExplorer can be controlled by manually typing in actions into a text field, but it's often easier to control the agent with the keyboard. To do so, we can specify a binding between a key press and an action name with the addKeyAction method. In this case, we'll set 'w' to correspond to north; 's' south; 'd' east; and 'a' west. Change your main method to now look like the below. public static void main(String [] args){ExampleGridWorld gen = new ExampleGridWorld();Domain domain = gen.generateDomain();State initialState = ExampleGridWorld.getExampleState(domain);//TerminalExplorer exp = new TerminalExplorer(domain);//exp.exploreFromState(initialState);Visualizer v = gen.getVisualizer();VisualExplorer exp = new VisualExplorer(domain, v, initialState);exp.addKeyAction(\"w\", ACTIONNORTH);exp.addKeyAction(\"s\", ACTIONSOUTH);exp.addKeyAction(\"d\", ACTIONEAST);exp.addKeyAction(\"a\", ACTIONWEST);exp.initGUI();} Now when you run your code, you'll be presented a visualization of the state and you can interact with it with the \"wasd\" keys, similar to what you see in the below image. Note that you may need to click on the image for it to begin accepting key presses. Remember, since we made movement stochastic, you may find the agent moving in unintended directions some of the time. Also note that when the agent enters the same position as the location object that in the bottom text box in the window you'll see \"at(agent0, location0)\" appear. This text box always lists all propositional functions that are true in the current state automatically. Next Part", "http://burlap.cs.brown.edu/tutorials_v2/bd/p5.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Building a Domain Tutorials > Building a Domain > Part 5 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Previous Part Reward Functions and Terminal Functions Now that you've created a world, you'll want to definetasks for the world so that you can run planning and learningalgorithms on it. Tasks in BURLAP are typically defined with RewardFunction and TerminalFunction implementations. The former specifies the reward received by the agent for transition tuples (previous state, action taken, resulting state); the later specifies which states are terminal states that cause all further action to cease. While we won't be using any planning or learning algorithms in this tutorial, we will briefly cover how to create your own reward functions and terminal state functions so that you can run planning and learning algorithms on your domain. Before you make your own RewardFunction and TerminalFunction,it is sometimes worth checking to see if BURLAP already has an implementation that you can use. For example, many different problems use a reward function that returns -1 everywhere.For problems like these, you can use the UniformCostRF object. If your domain is continuing (i.e., non-terminating), thenyou can use the NullTermination object. It also not uncommon to have a goal condition that is satisfied whenever any object grounding of a propositional function returns true. In our grid world, for example, if we let location objects indicate goal locations, we might want a terminal function that returns true for any state in which the agent is at a location. In such a case you can use the SinglePFTF TerminalFunction and point it to the atLocation propositional function. If none of the existing RewardFunction or TerminalFunction objects in BURLAP suit your needs, you can always create your own. For example, suppose we wanted a reward function that returned -1 everywhere, except when the agent reached a designated (x, y) position at which point it returned a reward of +100. We can implement such a reward function as shown below. public static class ExampleRF implements RewardFunction{int goalX;int goalY;public ExampleRF(int goalX, int goalY){this.goalX = goalX;this.goalY = goalY;}@Overridepublic double reward(State s, GroundedAction a, State sprime) {//get location of agent in next stateObjectInstance agent = sprime.getFirstObjectOfClass(CLASSAGENT);int ax = agent.getIntValForAttribute(ATTX);int ay = agent.getIntValForAttribute(ATTY);//are they at goal location?if(ax == this.goalX && ay == this.goalY){return 100.;}return -1;}} Notice that when we get the agent position, we get it from the \"sprime\" variable? That's because parameter \"s\" represents the previous state, \"a\" represents the action the agent took in the previous state, and \"sprime\" represents the state the agent ended up in as a result. Since we want to return +100 when the agent reaches our goal location, we care about where the agent ended up, which is held in sprime. If we wanted to make a similar TerminalFunction that marked our goal state as a terminal state, we would do so with the similar below code. public static class ExampleTF implements TerminalFunction{int goalX;int goalY;public ExampleTF(int goalX, int goalY){this.goalX = goalX;this.goalY = goalY;}@Overridepublic boolean isTerminal(State s) {//get location of agent in next stateObjectInstance agent = s.getFirstObjectOfClass(CLASSAGENT);int ax = agent.getIntValForAttribute(ATTX);int ay = agent.getIntValForAttribute(ATTY);//are they at goal location?if(ax == this.goalX && ay == this.goalY){return true;}return false;}} And that is all there is to defining reward functions and terminal states! If you'd like to test them, you can use the TerminalExplorer and VisualExploer to do so since they ultimately interact with Environment instances. To do that, we'll first create an instance of SimulatedEnvironment using our reward function and terminal function, and then we'll provide the TerminalExplorer and VisualExplorer the Environment instance. For the TerminalExporler it will print out the last reward receieved and whether the current state is terminal. For the VisualExplorer, you can open up the console (by pressing the button at the bottom) and you'll find at the bottom of the print the last reward received and whether the current state is terminal. Adjust your main method to the below to test that. public static void main(String [] args){ExampleGridWorld gen = new ExampleGridWorld();Domain domain = gen.generateDomain();State initialState = ExampleGridWorld.getExampleState(domain);RewardFunction rf = new ExampleRF(10, 10);TerminalFunction tf = new ExampleTF(10, 10);SimulatedEnvironment env = new SimulatedEnvironment(domain, rf, tf, initialState);//TerminalExplorer exp = new TerminalExplorer(domain, env);//exp.explore();Visualizer v = gen.getVisualizer();VisualExplorer exp = new VisualExplorer(domain, env, v);exp.addKeyAction(\"w\", ACTIONNORTH);exp.addKeyAction(\"s\", ACTIONSOUTH);exp.addKeyAction(\"d\", ACTIONEAST);exp.addKeyAction(\"a\", ACTIONWEST);exp.initGUI();} You may now notice that when you reach the goal location in the VisualExplorer that you can no longer act. This frezzing occurs because now that we've defined a TerminalFunction, you can no longer act once you reach it! However, you can press the \"`\" key to send the resetEnvironment message to the Environment, which will place you back in the beginning. Conclusions In this tutorial we showed you how to create a domain, visualize it, interact with it, and how to define tasks for it. With a domain and task in hand you're now ready to use the planning and learning algorithms in BURLAP on it, which you will learn about in the next tutorial . Although we showed you how to create a grid world domain in this tutorial, if you do want to run experiments on a grid world, we highly recommend that you use the GridWorldDomain already in BURLAP. It will support many more features than we covered in this tutorial including 1 dimensional walls, location types, and more flexible transition dynamics. Final Code For reference, you can find all of the code we wrote below. import burlap.oomdp.auxiliary.DomainGenerator;import burlap.oomdp.core.*;import burlap.oomdp.core.objects.MutableObjectInstance;import burlap.oomdp.core.objects.ObjectInstance;import burlap.oomdp.core.states.MutableState;import burlap.oomdp.core.states.State;import burlap.oomdp.singleagent.*;import burlap.oomdp.singleagent.common.SimpleAction;import burlap.oomdp.singleagent.environment.SimulatedEnvironment;import burlap.oomdp.singleagent.explorer.TerminalExplorer;import burlap.oomdp.singleagent.explorer.VisualExplorer;import burlap.oomdp.visualizer.ObjectPainter;import burlap.oomdp.visualizer.StateRenderLayer;import burlap.oomdp.visualizer.StaticPainter;import burlap.oomdp.visualizer.Visualizer;import java.awt.*;import java.awt.geom.Ellipse2D;import java.awt.geom.Rectangle2D;import java.util.*;import java.util.List;public class ExampleGridWorld implements DomainGenerator{public static final String ATTX = \"x\";public static final String ATTY = \"y\";public static final String CLASSAGENT = \"agent\";public static final String CLASSLOCATION = \"location\";public static final String ACTIONNORTH = \"north\";public static final String ACTIONSOUTH = \"south\";public static final String ACTIONEAST = \"east\";public static final String ACTIONWEST = \"west\";public static final String PFAT = \"at\";//ordered so first dimension is xprotected int [][] map = new int[][]{{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,0,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{0,0,0,0,0,1,0,0,0,0,0},{1,0,1,1,1,1,1,1,0,1,1},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,0,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},{0,0,0,0,1,0,0,0,0,0,0},};@Overridepublic Domain generateDomain() {SADomain domain = new SADomain();Attribute xatt = new Attribute(domain, ATTX, Attribute.AttributeType.INT);xatt.setLims(0, 10);Attribute yatt = new Attribute(domain, ATTY, Attribute.AttributeType.INT);yatt.setLims(0, 10);ObjectClass agentClass = new ObjectClass(domain, CLASSAGENT);agentClass.addAttribute(xatt);agentClass.addAttribute(yatt);ObjectClass locationClass = new ObjectClass(domain, CLASSLOCATION);locationClass.addAttribute(xatt);locationClass.addAttribute(yatt);new Movement(ACTIONNORTH, domain, 0);new Movement(ACTIONSOUTH, domain, 1);new Movement(ACTIONEAST, domain, 2);new Movement(ACTIONWEST, domain, 3);new AtLocation(domain);return domain;}public static State getExampleState(Domain domain){State s = new MutableState();ObjectInstance agent = new MutableObjectInstance(domain.getObjectClass(CLASSAGENT), \"agent0\");agent.setValue(ATTX, 0);agent.setValue(ATTY, 0);ObjectInstance location = new MutableObjectInstance(domain.getObjectClass(CLASSLOCATION), \"location0\");location.setValue(ATTX, 10);location.setValue(ATTY, 10);s.addObject(agent);s.addObject(location);return s;}public StateRenderLayer getStateRenderLayer(){StateRenderLayer rl = new StateRenderLayer();rl.addStaticPainter(new WallPainter());rl.addObjectClassPainter(CLASSLOCATION, new LocationPainter());rl.addObjectClassPainter(CLASSAGENT, new AgentPainter());return rl;}public Visualizer getVisualizer(){return new Visualizer(this.getStateRenderLayer());}protected class Movement extends SimpleAction implements FullActionModel {//0: north; 1: south; 2:east; 3: westprotected double [] directionProbs = new double[4];public Movement(String actionName, Domain domain, int direction){super(actionName, domain);for(int i = 0; i < 4; i++){if(i == direction){directionProbs[i] = 0.8;}else{directionProbs[i] = 0.2/3.;}}}@Overrideprotected State performActionHelper(State s, GroundedAction groundedAction) {//get agent and current positionObjectInstance agent = s.getFirstObjectOfClass(CLASSAGENT);int curX = agent.getIntValForAttribute(ATTX);int curY = agent.getIntValForAttribute(ATTY);//sample directon with random rolldouble r = Math.random();double sumProb = 0.;int dir = 0;for(int i = 0; i < this.directionProbs.length; i++){sumProb += this.directionProbs[i];if(r < sumProb){dir = i;break; //found direction}}//get resulting positionint [] newPos = this.moveResult(curX, curY, dir);//set the new positionagent.setValue(ATTX, newPos[0]);agent.setValue(ATTY, newPos[1]);//return the state we just modifiedreturn s;}@Overridepublic List<TransitionProbability> getTransitions(State s, GroundedAction groundedAction) {//get agent and current positionObjectInstance agent = s.getFirstObjectOfClass(CLASSAGENT);int curX = agent.getIntValForAttribute(ATTX);int curY = agent.getIntValForAttribute(ATTY);List<TransitionProbability> tps = new ArrayList<TransitionProbability>(4);TransitionProbability noChangeTransition = null;for(int i = 0; i < this.directionProbs.length; i++){int [] newPos = this.moveResult(curX, curY, i);if(newPos[0] != curX || newPos[1] != curY){//new possible outcomeState ns = s.copy();ObjectInstance nagent = ns.getFirstObjectOfClass(CLASSAGENT);nagent.setValue(ATTX, newPos[0]);nagent.setValue(ATTY, newPos[1]);//create transition probability object and add to our list of outcomestps.add(new TransitionProbability(ns, this.directionProbs[i]));}else{//this direction didn't lead anywhere new//if there are existing possible directions//that wouldn't lead anywhere, aggregate with themif(noChangeTransition != null){noChangeTransition.p += this.directionProbs[i];}else{//otherwise create this new state and transitionnoChangeTransition = new TransitionProbability(s.copy(),this.directionProbs[i]);tps.add(noChangeTransition);}}}return tps;}protected int [] moveResult(int curX, int curY, int direction){//first get change in x and y from direction using 0: north; 1: south; 2:east; 3: westint xdelta = 0;int ydelta = 0;if(direction == 0){ydelta = 1;}else if(direction == 1){ydelta = -1;}else if(direction == 2){xdelta = 1;}else{xdelta = -1;}int nx = curX + xdelta;int ny = curY + ydelta;int width = ExampleGridWorld.this.map.length;int height = ExampleGridWorld.this.map[0].length;//make sure new position is valid (not a wall or off bounds)if(nx < 0 || nx >= width || ny < 0 || ny >= height ||ExampleGridWorld.this.map[nx][ny] == 1){nx = curX;ny = curY;}return new int[]{nx,ny};}}protected class AtLocation extends PropositionalFunction {public AtLocation(Domain domain){super(PFAT, domain, new String []{CLASSAGENT,CLASSLOCATION});}@Overridepublic boolean isTrue(State s, String[] params) {ObjectInstance agent = s.getObject(params[0]);ObjectInstance location = s.getObject(params[1]);int ax = agent.getIntValForAttribute(ATTX);int ay = agent.getIntValForAttribute(ATTY);int lx = location.getIntValForAttribute(ATTX);int ly = location.getIntValForAttribute(ATTY);return ax == lx && ay == ly;}}public class WallPainter implements StaticPainter {@Overridepublic void paint(Graphics2D g2, State s, float cWidth, float cHeight) {//walls will be filled in blackg2.setColor(Color.BLACK);//set up floats for the width and height of our domainfloat fWidth = ExampleGridWorld.this.map.length;float fHeight = ExampleGridWorld.this.map[0].length;//determine the width of a single cell//on our canvas such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;//pass through each cell of our map and if it's a wall, paint a black rectangle on our//cavas of dimension widthxheightfor(int i = 0; i < ExampleGridWorld.this.map.length; i++){for(int j = 0; j < ExampleGridWorld.this.map[0].length; j++){//is there a wall here?if(ExampleGridWorld.this.map[i][j] == 1){//left coordinate of cell on our canvasfloat rx = i*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas//origin is in the top left instead of the bottom rightfloat ry = cHeight - height - j*height;//paint the rectangleg2.fill(new Rectangle2D.Float(rx, ry, width, height));}}}}}public class AgentPainter implements ObjectPainter{@Overridepublic void paintObject(Graphics2D g2, State s, ObjectInstance ob,float cWidth, float cHeight) {//agent will be filled in grayg2.setColor(Color.GRAY);//set up floats for the width and height of our domainfloat fWidth = ExampleGridWorld.this.map.length;float fHeight = ExampleGridWorld.this.map[0].length;//determine the width of a single cell on our canvas//such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;int ax = ob.getIntValForAttribute(ATTX);int ay = ob.getIntValForAttribute(ATTY);//left coordinate of cell on our canvasfloat rx = ax*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas//origin is in the top left instead of the bottom rightfloat ry = cHeight - height - ay*height;//paint the rectangleg2.fill(new Ellipse2D.Float(rx, ry, width, height));}}public class LocationPainter implements ObjectPainter {@Overridepublic void paintObject(Graphics2D g2, State s, ObjectInstance ob,float cWidth, float cHeight) {//agent will be filled in blueg2.setColor(Color.BLUE);//set up floats for the width and height of our domainfloat fWidth = ExampleGridWorld.this.map.length;float fHeight = ExampleGridWorld.this.map[0].length;//determine the width of a single cell on our canvas//such that the whole map can be paintedfloat width = cWidth / fWidth;float height = cHeight / fHeight;int ax = ob.getIntValForAttribute(ATTX);int ay = ob.getIntValForAttribute(ATTY);//left coordinate of cell on our canvasfloat rx = ax*width;//top coordinate of cell on our canvas//coordinate system adjustment because the java canvas//origin is in the top left instead of the bottom rightfloat ry = cHeight - height - ay*height;//paint the rectangleg2.fill(new Rectangle2D.Float(rx, ry, width, height));}}public static class ExampleRF implements RewardFunction {int goalX;int goalY;public ExampleRF(int goalX, int goalY){this.goalX = goalX;this.goalY = goalY;}@Overridepublic double reward(State s, GroundedAction a, State sprime) {//get location of agent in next stateObjectInstance agent = sprime.getFirstObjectOfClass(CLASSAGENT);int ax = agent.getIntValForAttribute(ATTX);int ay = agent.getIntValForAttribute(ATTY);//are they at goal location?if(ax == this.goalX && ay == this.goalY){return 100.;}return -1;}}public static class ExampleTF implements TerminalFunction {int goalX;int goalY;public ExampleTF(int goalX, int goalY){this.goalX = goalX;this.goalY = goalY;}@Overridepublic boolean isTerminal(State s) {//get location of agent in next stateObjectInstance agent = s.getFirstObjectOfClass(CLASSAGENT);int ax = agent.getIntValForAttribute(ATTX);int ay = agent.getIntValForAttribute(ATTY);//are they at goal location?if(ax == this.goalX && ay == this.goalY){return true;}return false;}}public static void main(String [] args){ExampleGridWorld gen = new ExampleGridWorld();Domain domain = gen.generateDomain();State initialState = ExampleGridWorld.getExampleState(domain);RewardFunction rf = new ExampleRF(10, 10);TerminalFunction tf = new ExampleTF(10, 10);SimulatedEnvironment env = new SimulatedEnvironment(domain, rf, tf, initialState);//TerminalExplorer exp = new TerminalExplorer(domain, env);//exp.explore();Visualizer v = gen.getVisualizer();VisualExplorer exp = new VisualExplorer(domain, env, v);exp.addKeyAction(\"w\", ACTIONNORTH);exp.addKeyAction(\"s\", ACTIONSOUTH);exp.addKeyAction(\"d\", ACTIONEAST);exp.addKeyAction(\"a\", ACTIONWEST);exp.initGUI();}} End.", "http://burlap.cs.brown.edu/tutorials_v2/bpl/p1.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Basic Planning and Learning Tutorials > Basic Planning and Learning > Part 1 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A* Planning with Value Iteration Learning with Q-Learning Learning with Sarsa(\u03bb) Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Next Part You are viewing the tutorial for BURLAP 2; if you'd like the BURLAP version 1 tutorial, go here . Introduction The purpose of this tutorial is to get you familiar with using some of the planning and learning algorithmsin BURLAP. Specifically, this tutorial will cover instantiating a GridWorld domain bundled with BURLAP,creating a task for it, having the task solved with Q-learning, Sarsa learning, BFS, DFS, A*, and ValueIteration. The tutorial will also show you how to visualize these results in various ways using tools in BURLAP. The take home message you should get from this tutorial is that using different planningand learning algoritms largely amounts to just changing the algorithm object you instantiate, with everythingelse being the same. You are encouraged to extend this tutorial on your own using some of the other planningand learning algorithms in BURLAP. At the conclusion section of this tutorial, you will find all of the code we created, so if you'd prefer to jumpt rightin, only coming back to this tutorial as questions arise, feel free to do so! Creating the class shell For this tutorial, we will start by making a class that has data members for all the domain and task relevantproperties. In the tutorial we will call this class \"BasicBehavior\" but feel free to name it to whatever you like.Since we will also be running the examples from this class, we'll include a main method. For convenience, we have also included at the start all of the class imports you will need for this tutorial. If you have a good IDE, like IntelliJ or Eclipse, those can auto importing the classes as you go so that you never have to write an import line yourself. import burlap.behavior.policy.GreedyQPolicy;import burlap.behavior.policy.Policy;import burlap.behavior.singleagent.EpisodeAnalysis;import burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizer;import burlap.behavior.singleagent.auxiliary.StateReachability;import burlap.behavior.singleagent.auxiliary.performance.LearningAlgorithmExperimenter;import burlap.behavior.singleagent.auxiliary.performance.PerformanceMetric;import burlap.behavior.singleagent.auxiliary.performance.TrialMode;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.ValueFunctionVisualizerGUI;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.ArrowActionGlyph;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.LandmarkColorBlendInterpolation;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.PolicyGlyphPainter2D;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.StateValuePainter2D;import burlap.behavior.singleagent.learning.LearningAgent;import burlap.behavior.singleagent.learning.LearningAgentFactory;import burlap.behavior.singleagent.learning.tdmethods.QLearning;import burlap.behavior.singleagent.learning.tdmethods.SarsaLam;import burlap.behavior.singleagent.planning.Planner;import burlap.behavior.singleagent.planning.deterministic.DeterministicPlanner;import burlap.behavior.singleagent.planning.deterministic.informed.Heuristic;import burlap.behavior.singleagent.planning.deterministic.informed.astar.AStar;import burlap.behavior.singleagent.planning.deterministic.uninformed.bfs.BFS;import burlap.behavior.singleagent.planning.deterministic.uninformed.dfs.DFS;import burlap.behavior.singleagent.planning.stochastic.valueiteration.ValueIteration;import burlap.behavior.valuefunction.QFunction;import burlap.behavior.valuefunction.ValueFunction;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.GridWorldVisualizer;import burlap.oomdp.auxiliary.common.SinglePFTF;import burlap.oomdp.auxiliary.stateconditiontest.StateConditionTest;import burlap.oomdp.auxiliary.stateconditiontest.TFGoalCondition;import burlap.oomdp.core.Domain;import burlap.oomdp.core.TerminalFunction;import burlap.oomdp.core.objects.ObjectInstance;import burlap.oomdp.core.states.State;import burlap.oomdp.singleagent.RewardFunction;import burlap.oomdp.singleagent.SADomain;import burlap.oomdp.singleagent.common.GoalBasedRF;import burlap.oomdp.singleagent.common.UniformCostRF;import burlap.oomdp.singleagent.common.VisualActionObserver;import burlap.oomdp.singleagent.environment.Environment;import burlap.oomdp.singleagent.environment.EnvironmentServer;import burlap.oomdp.singleagent.environment.SimulatedEnvironment;import burlap.oomdp.statehashing.HashableStateFactory;import burlap.oomdp.statehashing.SimpleHashableStateFactory;import burlap.oomdp.visualizer.Visualizer;public class BasicBehavior {GridWorldDomain gwdg;Domain domain;RewardFunction rf;TerminalFunction tf;StateConditionTest goalCondition;State initialState;HashableStateFactory hashingFactory;Environment env;public static void main(String[] args) {//we'll fill this in later}} If you're already familiar with MDPs in general, the importance of some of these data members will beobvious. However, we will walk through in detail what each data member is and why we're going to need it. GridWorldDomaingwdg A GridWorldDomain is a DomainGenerator implementation for creating grid worlds. Domain domain A Domain object is a fundamental class for defining problem domains. In short Domain objects define how states in a problem are representedand how the physics of the problem environment work. BURLAP represents states in a problem as a collection of objects, each with their own state. Therefore, a Domain object defines a set ofattributes, object classes, propositional functions, and actions (along with the actions transition dynamics) that define the problem. RewardFunction rf A RewardFunction is an interface that has a method for returning a double valued reward for any given state-action-state sequence. This is a fundamental component of every MDP and its what an agent tries to maximize. That is, the goalof an agent is acquire as much reward from the world as possible. TerminalFunction tf A common form of MDPs are episodic MDPs: MDPs that end in some specific state or set of states. A typicalreason to define an episodic MDP is when there is a goal state the agent is trying to reach. In such cases, the goalstate is a terminal state, because once the agent reaches it, there is nothing left to do. Inversely, some states may be fail states that prevent the agent continuing; these too would be terminal states. There may also be other reasons to provide termination states, but whatever you reason may be, a TerminalFunction is an interface with a boolean method that defines which states are terminal states. StateConditionTest goalCondition Not all planning algorithms are designed to maximize reward functions. Manyare instead defined as search algorithms that seek action sequences that will cause the agent to reach specific goal states. A StateConditionTest is an interface with a boolean method that takes a state as an argument similar to aTerminalFunction, only it can be used as a means to specify any kind of state test rather than just terminal states. In this tutorial we willuse it to specify goal states for planning algorithms that search for action sequences to reach goals rather thanplanning algorithms that try to maximize reward. State initialState To perform any planning or learning, we will generally need to specify an initial statefrom which to perform it and to reason about the different states that the agent encounters as it acts. In BURLAP, we use the State interface for providing this information, which has various methods for accessing information about the state. In particular, BURLAP uses the object-oriented MDP representation formalism, which represents states as a collection of objects, each which belongs to an object class and has a set of attributes. This is a very powerful representation that can handle a number of different kinds of problems. In this tutorial, you will not need to think much about the internal structure of the state, because we will use the GridWorldDomain class to produce initial state objects for us. For more information on it, see the State Java doc , or read the Building a Domain tutorial. HashableStateFactory hasingFactory In this tutorial, we will be covering planning and learning algorithms that solve problems that have a finite number of states that the algorithm can enumerate and reason about directly (these are sometimes called tabular algorithms). To enumerate and look up different states efficiently, algorithms typically store them in a hash-backed data structure (like a HashMap, or a \"dictionary\" for those of you who are new to Java). Using these data structures requires a means to compute hash codes for States and, depending on the kind of problem, some ways of computing hash codes may be more efficient than others. Furthermore, It is not uncommon that your may want handle state equality in different ways depending on the problem (for example, maybe you want to perform an abstraction that ignores certain attribute values or objects in the state). For these reasons, BURLAP allows you to provide tabular algorithms a HashableStateFactory . A HashableStateFactory has a method that takes as input a State object and returns a HashableState . A HashableState stores a reference to the source state and can compute an efficient hash code for the state and perform state equality checks with other HashableState instances. More on HashableStateFactory While BURLAP provides a number of different HashableStateFactory classes for handling common ways of performing hashing and state equality checking (see the statehashing package Java doc for a list), when it doubt you can typically use the SimpleHashableStateFactory , which we will use in this tutorial. One of the advantages of SimpleHashableStateFactory is that when it checks state equality between two states (or computes the hash code for a state), it will by default be object identifier independent . Object identifier independence means that when a state is made up of multiple objects of the same class, the order of the objects and the names that identify them does not affect whether two states are equal. That is, as long as the states have a set of equivalent objects, they will be considered the same state. For example, consider a state (s0) made up of two block objects (block0 and block1) that are defined by spatial positioninformation. Now imagine a new state (s1) that is the result of swapping the positions of block0 and block1.Even though the object identifiers associated with the block positions (block0 and block1) are different between s0 and s1, these really are the same state and when equality is object identifier independent they will be considered equal. The below illustration helps clarify this property. Sometimes the name of objects does matter, for example in relational domains in which the goal state refers to a specific object. In these cases, SimpleHashableStateFactory can be told in a constructor not to use object identifier independence. And since many of the HashableStateFactory classes in BURLAP inherit from SimpleHashableStateFactory, they can all have object identifier independence toggled. Environment env Learning algorithms address a problem in which the agent observes its environment, makes a decision, and then observes how the environment changes. This is a challenging problem because initially, an agent will not know how the environment works or what a good decision is, but must live with the consequences of their decision. To facilitate the construction of this problems, all learning algorithms in BURLAP (algorithms that implement the LearningAgent interface), interact with an implementation of the Environment interface. In BURLAP, there exists a SimulatedEnvironment implementation for when the environment dynamics are defined by a BURLAP Domain, but since Environment is an interface, you can easily implement your own version if you need a BURLAP agent to interact with external code or systems (for example, robotics, which BURLAP has an extension for supporting on ROS.). Next Part", "http://burlap.cs.brown.edu/tutorials_v2/bpl/p2.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Basic Planning and Learning Tutorials > Basic Planning and Learning > Part 2 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A* Planning with Value Iteration Learning with Q-Learning Learning with Sarsa(\u03bb) Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part | Next Part Initializing the data members Now that we have the structure of our class, we'll need to initialize our data membersto instances that will create our domain and define our task. First, create a default constructor. The first thing we'll do in the constructor is create our domain. public BasicBehavior(){gwdg = new GridWorldDomain(11, 11);gwdg.setMapToFourRooms(); domain = gwdg.generateDomain();//more to come...} The first line will create an 11x11 deterministic GridWorld. The second line sets up the map to a pre-canned layout:the four rooms layout. This domain layout was used in Option learning work from Sutton, Precup, and Singh (1999)and it presents a simple environment for us to do some tests. Alternatively, you could also define your ownmap layout by either passing the constructor a 2D integer array (with 1s specifying the cells with walls and 0sspecifying open cells), or you could simply specify the size of the domain like we did and then use the GridWorldDomainobject's horiztonalWall and verticalWall methods to place walls on it. The GridWorldDomain also supports1 dimensional walls between cells that you can set, if you'd prefer that kind of domain. For simplicity, we'll stick with thefour rooms layout. The third line will produce the Domain object for the grid world. Recall from the previouspart of the tutorial that Domain objects hold references to all the attributes, object classes, propositional functions, and actions(along with the actions' transition dynamics). How a GridWorldDomain Domain is defined A GridWorldDomain has two primary attributes, an X attribute anda Y attribute. There are also two classes: an AGENT class and a LOCATION class, each of which is defined by theX and Y attributes. While there could potentially be any number of AGENT object instantiations in a state, inthis domain we expect only one to ever be defined. The location objects will be used for points of interest.Specifically, we will use a single location object to represent a goal location. The GridWorld domain also definesfive propositional functions: atLocation(AGENT, LOCATION); wallToNorth(AGENT); wallToSouth(AGENT);wallToEast(AGENT); wallToWest(AGENT). The first of those returns true when the specified AGENT object is at thesame location as the specified LOCATION object. The latter four propositional functions return true when there is a wall in the immediate cell of the defined direction of the specified AGENT object. Finally, the GridWorld domain defines four actions to move north, south, east, or west of the agent's current position.Although we could have told the GridWorldDomain generator to make these movements stochastic (that is, specify a probability in which the agent moves in an unintended direction), in our specific examplewe have left them as the default deterministic actions. If an agent moves into a wall, then its position does notchange. Although this domain instantiation has specific settings for grid worlds, differentdomains in BURLAP follow similar conventions. That is, you create an instanceof a domain generator; specify the parameters of the domain through mutators,and then finally extract the domain with a call to a generateDomain method.For example, the LunarLander domain generator lets you set properties like themaximum velocity and the force of gravity. Next we will want to define the actual task to be solved for this domain. We will do this by specifyinga reward function, a termination function, and a goal condition; the latter of which we will use exclusively for search-based deterministic planners that this tutorial will cover. In general,you can always define your own reward functions, terminal functions, and goal conditions by implementing the RewardFunction , TerminalFunction , and StateConditionTest interfaces, respectively, yourself. However, BURLAPalso comes packaged with a bunch of standard instances (as well as various domain-specific implementations) that we will use here. If you want to know moreabout defining your own, consult the Building a Domain tutorial. rf = new UniformCostRF(); tf = new SinglePFTF(domain.getPropFunction(GridWorldDomain.PFATLOCATION)); goalCondition = new TFGoalCondition(tf); The first line will create a reward function that always returns -1 for every state-action-state transition. The next line defines a terminal function that identifies terminal states as states in which the agent is at the same position as locaion object. When the reward function (-1 everywhere) is taken together with this terminal function (everything ends when the agent reaches a location), it motivates the agent to reach a location object as soon as possible. How SinglePFTF works The TerminalFunction is created as an instance of SinglePFTF . SinglePFTF is a terminal function that takes as input a PropositionalFunction and sets any state in which the propositional function is true for any valid objects as terminal states. In this case, we provided it the GridWorldDomain's atLocation propositional function. This propositional function operates on two objects: the agent and a location object. For example, we might see the function evaluated on agent0 and location2: atLocation(agent0, location2). The propositional function returns true whenever the input agent is at the same position as the input location object. Therefore, for any input state, SinglePFTF finds all possible agent and location pairs and checks whether atLocation is true for any of them. If it is, then SinglePFTF returns evaluates that state as a terminal state. Note that we are using UniformCostRF and SinglePFTF to illustrate some of the more general approaches in BURLAP to defining reward functions and terminal functions. However, GridWorldDomain also has specific reward function ( GridWorldRewardFunction ) and terminal function ( GridWorldTerminalFunction ) designed for grid world problems that in practice you may want to use instead for grid worlds. The final line sets up the goal condition to be synonymous with the termination function. Note that goal stateswill not always be the same as terminal states (there may beterminal states that are not goal states, such as failure states), but in this example they are. The next step will be to define the initial state of this task. We could either do thisby creating an empty State object and then manually adding object instantiations for each object class,or we could use some methods of the GridWorldDomain class to facilitate the process. We will do the latterfor brevity, but if you want a more complete description of creating astate object by hand, consider looking in the Building a Domain tutorial. initialState = GridWorldDomain.getOneAgentOneLocationState(domain);GridWorldDomain.setAgent(initialState, 0, 0);GridWorldDomain.setLocation(initialState, 0, 10, 10); The first line will return a state object with a single instance of the AGENT class and a single instanceof the LOCATION class. The second line of code then sets the agent to be at position 0,0. The third line ofcode sets the location to be at position 10,10. The first zero you see in the parameters indicates whichLOCATION object index position to set. Since there is only one LOCATION object, we are setting the positionof the 0th indexed LOCATION object. Next we will instantiate the HashableStateFactory that we wish to use. Since we are not doing anything fancy like state abstraction, we will use SimpleHashableStateFactory, which when we provide no constructor arguments will also use object identifier independence as discussed previously. hashingFactory = new SimpleHashableStateFactory(); Finally, we will instantiate an Environment with which the agent will interact in our learning algorithm demonstrations. Since we will be using BURLAP's simulation of the environment, we will use a SimulatedEnvironment, which along with the domain, needs to be told about the reward function, terminal function and initial state for the environment. env = new SimulatedEnvironment(domain, rf, tf, initialState); At this point you should have initialized all of the data members for the class and the final constructor will look something like the below. public BasicBehavior(){//create the domaingwdg = new GridWorldDomain(11, 11);gwdg.setMapToFourRooms();domain = gwdg.generateDomain();//define the taskrf = new UniformCostRF();tf = new SinglePFTF(domain.getPropFunction(GridWorldDomain.PFATLOCATION));goalCondition = new TFGoalCondition(tf);//set up the initial state of the taskinitialState = GridWorldDomain.getOneAgentNLocationState(domain, 1);GridWorldDomain.setAgent(initialState, 0, 0);GridWorldDomain.setLocation(initialState, 0, 10, 10);//set up the state hashing system for tabular algorithmshashingFactory = new SimpleHashableStateFactory();//set up the environment for learning algorithmsenv = new SimulatedEnvironment(domain, rf, tf, initialState);} Setting up a result visualizer Before we get to actually running planning and learning algorithms, we're going to want a way to visualizethe results that they generate. While there are a few different ways to do this, for now we willdefine an offline visualizer that will allow us to run planning or learning completely, and then visualizethe results after it's finished. Offline visualization has the advantage of not bogging down the runtime of planning/learning algorithms with time allocated for visualization. To create our offline visualizer, we will need to define a state Visualizer and pass it to an EpisodeSequenceVisualizer . A Visualizer is a Java canvas that can render State objects. An EpisodeSequenceVisualizer lets you view and explore episode (state-action-reward sequences) that an agent took and can either load the episodes from files or be provided them programmatically. In this example, we will save results to file and load them back up. To handle this kind of result visualization, create the below method. public void visualize(String outputPath){Visualizer v = GridWorldVisualizer.getVisualizer(gwdg.getMap());new EpisodeSequenceVisualizer(v, domain, outputPath);} Note that the outputPath parameter specifies the directory where our planning/learning results were stored(well get to this when we actually apply a planning/learning algorithm). The state Visualizer we will use is the one designed for rendering grid world states. It takes as input the map of the world (a 2D int array), which we retrieve from our GridWorldDomain instance. Note that other domains included in BURLAP have their own Visualizers that you can use for them. Before moving on to the next part of the tutorial, lets also hook up our class constructor and visualizer methodto the main method. public static void main(String[] args) {BasicBehavior example = new BasicBehavior();String outputPath = \"output/\"; //directory to record results//we will call planning and learning algorithms here//run the visualizerexample.visualize(outputPath);} Note that you can set the output path to whatever you want. If it doesn't already exist, the codethat saves the results will automatically created it (more on that next). Next Part", "http://burlap.cs.brown.edu/tutorials_v2/bpl/p3.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Basic Planning and Learning Tutorials > Basic Planning and Learning > Part 3 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A* Planning with Value Iteration Learning with Q-Learning Learning with Sarsa(\u03bb) Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part | Next Part Planning with BFS One of the most basic deterministic planning algorithms is breadth-first search, which we will demonstrate first. Since we willbe testing a number of different planning and learning algorithms in this tutorial, we will define a separate methodfor using each planning or learning algorithm and then you can simply select which one you want to try in the mainmethod of the class. We will also pass each of these methods the output path to record itsresults. Lets start by defining the BFS method. public void BFSExample(String outputPath){DeterministicPlanner planner = new BFS(domain, goalCondition, hashingFactory);Policy p = planner.planFromState(initialState);p.evaluateBehavior(initialState, rf, tf).writeToFile(outputPath + \"bfs\");} The first part of the method creates an instance of the BFS planning algorithm, whichitself is a subclass of the DeterministicPlanner class. To instantiate BFS, it only requires a reference to the domain,the goal condition for which it should search, and the HashableStateFactory. Because BFS implements the Planner interface, planning can be initiated by callingthe planFromState method and passing it the initial state form which it should plan. The planFromState method automatically returns a Policy object, which can be used to query and execute the results of the planning in simulation or in an environment. Using non-default policies Each Planner implementation will return a different kind of Policy from planFromState that is relevant for the results the Planner stores. However, often times, after calling the planFromState method, you can wrap a different policy than the one that is returned around your planner instance to get slightly different behavior. For example, BFS's planFromState will return an SDPlannerPolicy instance, which will return the action the planner selected for any states on its solution path; if the policy is queried for a state not on the solution path, it will throw a runtime exception. However, you might choose to wrap a DDPlannerPolicy around BFS instead of using the returned SDPlannerPolicy, it will act the same except rather than throw a runtime exception if an action selection is queried for a state not on the current solution path, it will transparently recall planFromState on the new state to get an action to return; that is, it will perform replanning. Once you have a Policy object, you can roll out the behavior and extract the resulting episode (sequence of state-action-reward tuples) from it in simulation by calling the evaluateBehavior method. There are a few different versions of the evaluateBehavior method which take different parameters to determine theanalysis and stopping criteria. In this case, however, we are passing it the initial state from which the policy shouldstart being followed, the reward function used to assess the performance and the the termination function whichspecifies when the policy should stop. The method will return an EpisodeAnalysis object which will containall of the states visited, actions taken, and rewards received when following that policy. You can investigate these individual elements of the episode if you like,but for this tutorial we're just going to save the results of this episode to a file and then use the offlinevisualizer we previously defined to view it. An EpisodeAnalysis objectcan be written to a file by calling the writeToFile method on it and passing it a path to the file.Note that the method will automatically append a '.episode' extension to the file path if you did not specify it yourself and will create any directories in the path that do not already exist. Executing policies in environments The evaluateBehavior method can also take as input an Environment rather than a State. When given an environment, the policy is followed in the environment rather than simulation (unless of course the environment is a simulation itself!). This is very useful if you need to run planning in a model of the world, and then execute the results of that plan on something \"real\" or external from your model. And that's all you need to code to plan with BFS on a defined domain and task! Using the EpisodeSequenceVisualizer GUI Now that the method to perform planning with BFS is defined, add a method call to it in your main method. public static void main(String[] args) {BasicBehavior example = new BasicBehavior();String outputPath = \"output/\"; //directory to record results//run exampleexample.BFSExample(outputPath);//run the visualizerexample.visualize(outputPath);} Note that our output path ended with a '/'. Whatever path you use, you should include the trailing '/' since the code we wrote to write the file will automatically append to that path name. With the planning method hooked up, run the code! Because the task is simple, BFS should find a solution veryquickly and print to the standard output the number of nodes it expanded in its search. Following that, the GUIshould be launched for viewing the EpisodeAnalysis object that was recorded to a file. You should see something like the belowimage appear. The main panel in the center of the window is used to render the current state selected. The text box at thebottom of the window will list all of the propositional functions that are true in that state. The leftmostlist on the right side of the window lists all of the episode files that were recorded in the directory passed to theEpisodeSequenceVisualizer constructor. After selecting one of those instances, the list of actions taken in theepisode are listed on the right-most list. Note that the actioncorresponds to the action that will be taken in the statethat is currently visualized, so the result of the actionwill be seen in the next state. In the GridWorldDomain visualizer, the black cells represent walls, the grey circlerepresents the agent, and the blue cell represents the location object that we made. Planning with DFS Another common search-based planning algorithm is depth-first search (DFS). Define the below method to providea means to solve the task with DFS. public void DFSExample(String outputPath){DeterministicPlanner planner = new DFS(domain, goalCondition, hashingFactory);Policy p = planner.planFromState(initialState);p.evaluateBehavior(initialState, rf, tf).writeToFile(outputPath + \"dfs\");} You will notice that the code for DFS is effectively identical to the previous BFS code that we wrote, only this timethe DeterministicPlanner is instantiated with a DFS object instead of a BFS object. DFS has a number of other constructorsthat allow you to specify other parameters such a depth limit, or maintaining a closed list. Feel freeto experiment with them. After you have defined the method, you can call it from the main method like we did the BFS method and visualize theresults in the same way. Since DFS is not an optimal planner, it is likely that the solution it gives you will bemuch worse than the one BFS gave you! Planning with A* One of the most well known optimal search-based planning algorithms is A*. A* is an informed planner because it takesas input an admissible heuristic which estimates the cost to the goal from any given state. We can also use A* to plan a solution for our taskas long as we also take the additional step of defining a heuristic to use (or you can use a NullHeuristic which will make A* uninformed). The below code defines a methodfor using A* with a Manhattan distance to goal heuristic. public void AStarExample(String outputPath){Heuristic mdistHeuristic = new Heuristic() {@Overridepublic double h(State s) {ObjectInstance agent = s.getFirstObjectOfClass(GridWorldDomain.CLASSAGENT);ObjectInstance location = s.getFirstObjectOfClass(GridWorldDomain.CLASSLOCATION);int ax = agent.getIntValForAttribute(GridWorldDomain.ATTX);int ay = agent.getIntValForAttribute(GridWorldDomain.ATTY);int lx = location.getIntValForAttribute(GridWorldDomain.ATTX);int ly = location.getIntValForAttribute(GridWorldDomain.ATTY);double mdist = Math.abs(ax-lx) + Math.abs(ay-ly);return -mdist;}};DeterministicPlanner planner = new AStar(domain, rf, goalCondition, hashingFactory, mdistHeuristic);Policy p = planner.planFromState(initialState);p.evaluateBehavior(initialState, rf, tf).writeToFile(outputPath + \"astar\");} There are two main differences between this method and the methods that we wrote for BFS and DFSplanning. The smaller difference is that the A* constructor includes a reward function in its parameters. The reward function is needed because it is what A* uses to keep trackof the actual cost of any path it is exploring. Rewards and Costs A* is an algorithm that operates on costs and is not an algorithm that can workwith negative costs. BURLAP in general represents state-action evaluations as rewards ,rather than costs. However, a cost can be represented as a negative reward; therefore,the reward function provided to A* should return negative values. If the rewardfunction returns any positive values, A* will not function properly. Since our example's reward functionreturns only negative values (it returns -1 for every state-action pair), our reward function will workfine with A*. The bigger difference between the previous planning code and A* is in defining theheuristic, which we do by implementing the Heuristic interface. The h method of the Heuristic interfaceis passed a state object and the method should return the estimated reward to the goal fromthat state (which should be a non-positive value). Since we have opted to use the Manhattan distance as our heuristic, this will involvecomputing the distance between the agent position and the location position (for which we will assumethere is only one). To compute this difference, the method will first need to extract the agentobject instance and the location object instance out of the state, which is done in lines 7 and 8.Specifically, the getFirstObjectOfClass method of a state will return the first object in the state that belongs to the OO-MDP class with the given name. Lines 10-14 then extract the integer values for theX and Y attributes of both the agent and location objects. Once those attribute values are retrieved, the Manhattan distanceis computed and returned in lines 16 and 17. Note that the negative distance is returned, because our reward functionreturns -1 for each step. With the rest of the code being the same, you can have the main method call the A* method for planningand view the results in the usual way! Next Part", "http://burlap.cs.brown.edu/tutorials_v2/bpl/p4.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Basic Planning and Learning Tutorials > Basic Planning and Learning > Part 4 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A* Planning with Value Iteration Learning with Q-Learning Learning with Sarsa(\u03bb) Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part | Next Part Planning with Value Iteration A common stochastic domain planner is Value Iteration (VI). An advantage of VI is that it will compute thepolicy for the entire state space that is reachable from the initial state thatis passed to the planFromState method. To set up a VI planner, define the following method. public void valueIterationExample(String outputPath){Planner planner = new ValueIteration(domain, rf, tf, 0.99, hashingFactory, 0.001, 100);Policy p = planner.planFromState(initialState);p.evaluateBehavior(initialState, rf, tf).writeToFile(outputPath + \"vi\");} VI is a planning method defined for the classic MDP formalism, so unlike the previousdeterministic planners, its constructor takes as input the reward function and terminal function,rather than a goal condition. VI also takes as a parameter a discount factor which specifies how much future rewards are favored over immediate rewards. In this case,a fairly large value of 0.99 is set (which means the agent will prefer later future rewards almost as much asimmediate rewards). The last two parameters to the constructor specify stopping conditions for theplanning. The second to last parameter specifies that when the maximumchange in the value function of any state is less than that specified threshold value (0.001 in this case), planning will stop. The last parameter specifies a maximumnumber of updates for each state that can happen before planning is stopped (100 in this case), regardlessof whether the maximum value function change threshold was crossed. Since VI is a stochastic domain planning algorithm, rather than a deterministic one like the previous algorithms weused, it's planFromState method returns a GreedyQPolicy . This policy looks at the Q-values the planner computes and returns the action with the maximium Q-value (and breaks ties randomly). A Q-value represents the expected future discounted reward for taking each action in each state and then following the optimal policy thereafter and this policy can be used with any planning or learning algorithm that returns Q-values by implementing the QFunction interface. Trysetting the main method to call our newly defined VI example method now. Learning with Q-Learning All of the previous examples were examples of using planning algorithms to solve our task. In this section,we will diverge from that and use a learning algorithm, Q-learning, to solve the task. Ultimately, learningalgorithms are utilized in much the same way as planning algorithms, except you will run multipleepisodes of learning in which the agent interacts with an Environment instance to solve it (or one very long episode if it is a continuing task rather than an episodictask). The method you should define to utilize Q-learning is shown below. public void QLearningExample(String outputPath){LearningAgent agent = new QLearning(domain, 0.99, hashingFactory, 0., 1.);//run learning for 50 episodesfor(int i = 0; i < 50; i++){EpisodeAnalysis ea = agent.runLearningEpisode(env);ea.writeToFile(outputPath + \"ql_\" + i);System.out.println(i + \": \" + ea.maxTimeStep());//reset environment for next learning episodeenv.resetEnvironment();}} Lets first look at the constructor. Rather than a planning instance, we're creating a LearningAgent instance which provides some methods for learning with an environment. QLearning is an instance of the LearningAgent interfaceand takes parameters for the domain, a discount factor, a HashableStateFactory, an initial value for the Q-values, and a learning rate (which for a deterministic domain, 1.0 is a good choice). Note that unlike the planning algorithms we did not have to specify the reward function or terminal function. These elements can be omitted because the agent will learn by interacting with an Environment that is responsible for telling the agent about the reward it received for an interaction and whether that next state is a terminal state. Also note that thisconstructor will by default set Q-learning to use a 0.1 epsilon greedy policy. There are other constructorsthat allow you to set which learning policy to use and there is also a setter that allows you to set itif you'd like to use a different policy. Other parameters for Q-learning could also be set, but we will not detail them here. With the QLearning instance created, next we will run 50 learning episodes, so we set up a for loop.To run a learning episode, we call the method runLearningEpisode method on the LearningAgent instanceand pass it the Environment in which learning will be performed. The method also returns an EpisodeAnalysis object (similar to policies) so that a record of the interactions can be examined. As before, we can then write the returned episode to disk for viewing later. Finally, at the end of the loop, we call the resetEnvironment method on the Environment. This method is the typical way to signal that an Environment needs to reset to an initial state from its current state, which may be a terminal state. When the method returns, it is expected that the environment in a non-terminal state from which an agent can act again. After that, you can call this method from your main method and run the agents behavior for each of the 50 episodes of learning! Should find that as learning progessed, the agent got better. By the end, the agent's behavior will still be slightly random since it's follow an epislon greedy policy that always takes some random actions. However, since QLearning implements the QFunction interface, you could always wrap a GreedyQPolicy around it, like with VI, and gets its performance from that. Learning with Sarsa(\u03bb) A similar learning algorithm to Q-learning is Sarsa(\u03bb). The first difference between the twoalgorithms is that Sarsa(\u03bb) updates Q-values with respect to the Q-value of the next action taken,rather than the maximum Q-value of the next state (see Wikipedia for more information). The second, and larger, difference is that at every time step, Sarsa(\u03bb) will also update the Q-valuesfor state-action pairs experienced previously in an episode with respect to the amount specified by \u03bb and how long ago the experiences occurred. Define the below method to solve ourtask with Sarsa(\u03bb). public void SarsaLearningExample(String outputPath){LearningAgent agent = new SarsaLam(domain, 0.99, hashingFactory, 0., 0.5, 0.3);//run learning for 50 episodesfor(int i = 0; i < 50; i++){EpisodeAnalysis ea = agent.runLearningEpisode(env);ea.writeToFile(outputPath + \"sarsa_\" + i);System.out.println(i + \": \" + ea.maxTimeStep());//reset environment for next learning episodeenv.resetEnvironment();}} You will notice that this method looks pretty identical to the Q-learning example, except this timea SarsaLam instance is constructed. Additionally, we lowered the learning rate to 0.5 (typicallyyou should use lower learning rates when you have a higher value of \u03bb). The last parameter ofthe constructor is the \u03bb value which we set to 1.0. A value of \u03bb=1.0 effectively makes algorithm run anonline Monte Carlo in which the effects of all future interactions are fully considered in updating each Q-valueof an episode. Otherwise, the rest is the same; you can call this method from the main method and give it shot! Next Part", "http://burlap.cs.brown.edu/tutorials_v2/bpl/p5.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Basic Planning and Learning Tutorials > Basic Planning and Learning > Part 5 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A* Planning with Value Iteration Learning with Q-Learning Learning with Sarsa(\u03bb) Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part | Next Part Live Visualization Although we showed how to visualize learning or planning results after they had been performed, sometimes when setting upa new problem and experiment it is useful to watch what is happening immediately. In this part of the tutorial weshow how to set up a live visualization of learning algorithms or planning algorithms that operate by trying actions in theworld (more on that in a bit). To present a live visualization we make use of the ActionObserver and EnvironmentObserver interfaces. Objects that implement the ActionObserver interface can be notified about action execution results in simulation; objects that implement the EnvironmentObserver interface can be told about agent interactions with an Environment. In this example, we will instantiate a VisualActionObserver and which implements both interfaces and visualizes state changes. The scope of ActionObserver It is worth noting that an ActionObserver is only notifed when the performAction method ofAction instances is called. This method is used by various sample based planning algorithms and detemrinistic planning algorithms. However, algorithms like VI do not use this method because they instead operate on the full action probability distribution (returned by the getTransitions method) rather than simulating actions. To add a VisualActionObserver, we can modify our constructor by adding the following lines to then end of it: VisualActionObserver observer = new VisualActionObserver(domain, GridWorldVisualizer.getVisualizer(gwdg.getMap()));observer.initGUI();env = new EnvironmentServer(env, observer);//((SADomain)domain).addActionObserverForAllAction(observer); The first line creates a VisualActionObserver for visualizing our domain with a provided domain state visualizer(we use the same kind of state visualizer that we used for our EpisodeSequenceVisualizer). The second line initializes the Java GUI for its visualization. You can then choose whether to use the third line or the commented out fourth line. The third line is how we set up the VisualActionObserver to receive events from an Environment and requires changing our Environment to an EnvironmentServer . An EnvironmentServer takes as input a source environment, and a list of EnvironmentObservers. Normal operations for the environment are delegated to the source environment, but the outcomes of the interaction are intercepted and sent to all observers before returning control to the client. The commented out fourth line would tell all the Action objects in the domain to add the action observer that is notified whenever the action is run in simulation. If you want to test the action observer out with a learning algorithm use the EnvironmentObserver paradigm (third line). If you want to test it with one of the deterministic planners, comment out the third line and uncomment the fourth. Which ever you choose, you should find that when you run the algorithm you observe the agent moving through the environment! Performance with VisualActionObservers By default, the VisualActionObserver will render frames at about 60FPS. You can modify this rate with thesetFrameDelay(long delay) method, which takes as an argument the number of milliseconds that must pass for the renderingof an event and before the next action can be taken. Note that this delay also places a cap on the speed at which learning or planning occurs since it stalls everything for that frame delay. Typically,learning in BURLAP occurs at speeds orders of magnitude faster than 60FPS, so using the visual observer willslow down your algorithm considerably. For these reasons, you may prefer the offline visualization. Nevertheless, live visualization is often a useful as a way to confirm that your experimentis working as planned. Value Function and Policy Visualization While visualizing the agent in the state space is useful, in this next section, we will show how to visualize the value function that is estimatedfrom value function estimating planning or learning algorithms, along with the corresponding policy. The value function assigns a value to each state that represents the expected future discounted reward when following the optimal policy from that state. In particular,we will show how to visualize the value function for the ValueIteration results, but you could do the same with Q-Learning, or anyplanning/learning algorithm that implements the ValueFuncton interface (which the QFunction interface extends). We will show you how to construct a value function visualizer in two ways. In the first way, we will make use of a GridWorldDomain method that will put all the pieces together for you and is very simple. However, since not all domains have automated code for that, we will also show you how to put all the pieces together manually. Lets start with the simple way, which requires adding the following method to your code. public void simpleValueFunctionVis(ValueFunction valueFunction, Policy p){List<State> allStates = StateReachability.getReachableStates(initialState, (SADomain)domain, hashingFactory);ValueFunctionVisualizerGUI gui = GridWorldDomain.getGridWorldValueFunctionVisualization(allStates, valueFunction, p);gui.initGUI();} Note that this method takes as input a ValueFunction instance and a Policy object (since along with the value function, we will also render the policy). Before we do anything with it, we are going to have to tell the renderer for which states we'd like to visualize the value function. Although Domain objects are not required to enumerate the entire state space (since for many domains that might be impossible), we can use the BURLAP tool StateReachability to find all states that are reachable from some input state. (Algorithms like ValueIteraiton also have a method to return all states that they enumerated that we could have used.) Next we call the GridWorldDomain method getGridWorldValueFunctionVisualization , which takes the set of states for which the value function will be rendered, the ValueFunction instance, and the Policy to render and returns a ValueFunctionVisualizationGUI instance that will do it for us. Finally, we launch the return GUI with the initGUI method. The last step is to direct our value iteration method to this method once planning is complete. Your new value iteration method should look like the following. public void valueIterationExample(String outputPath){Planner planner = new ValueIteration(domain, rf, tf, 0.99, hashingFactory, 0.001, 100);Policy p = planner.planFromState(initialState);p.evaluateBehavior(initialState, rf, tf).writeToFile(outputPath + \"vi\");//visualize the value function and policy.simpleValueFunctionVis((ValueFunction)planner, p);} If you now point your main method to run the valueIterationExample, you should find that after planning completes, it launches a GUI like the below (note that you can toggle the policy visualization with the check box in the bottom left). Now that we've shown you how to easily create a value function and policy visualization for grid worlds, lets walk through the process of manually creating one so that you know how to do so for other domains. Add the following method to your code. public void manualValueFunctionVis(ValueFunction valueFunction, Policy p){List<State> allStates = StateReachability.getReachableStates(initialState, (SADomain)domain, hashingFactory);//define color functionLandmarkColorBlendInterpolation rb = new LandmarkColorBlendInterpolation();rb.addNextLandMark(0., Color.RED);rb.addNextLandMark(1., Color.BLUE);//define a 2D painter of state values, specifying which attributes correspond //to the x and y coordinates of the canvasStateValuePainter2D svp = new StateValuePainter2D(rb);svp.setXYAttByObjectClass(GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTX,GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTY);//create our ValueFunctionVisualizer that paints for all states//using the ValueFunction source and the state value painter we definedValueFunctionVisualizerGUI gui = new ValueFunctionVisualizerGUI(allStates, svp, valueFunction);//define a policy painter that uses arrow glyphs for each of the grid world actionsPolicyGlyphPainter2D spp = new PolicyGlyphPainter2D();spp.setXYAttByObjectClass(GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTX,GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTY);spp.setActionNameGlyphPainter(GridWorldDomain.ACTIONNORTH, new ArrowActionGlyph(0));spp.setActionNameGlyphPainter(GridWorldDomain.ACTIONSOUTH, new ArrowActionGlyph(1));spp.setActionNameGlyphPainter(GridWorldDomain.ACTIONEAST, new ArrowActionGlyph(2));spp.setActionNameGlyphPainter(GridWorldDomain.ACTIONWEST, new ArrowActionGlyph(3));spp.setRenderStyle(PolicyGlyphPainter2D.PolicyGlyphRenderStyle.DISTSCALED);//add our policy renderer to itgui.setSpp(spp);gui.setPolicy(p);//set the background color for places where states are not rendered to greygui.setBgColor(Color.GRAY);//start itgui.initGUI();} The method signature looks the same as before and also as before we will use StateReachability to get all the states for which the value function will be rendered. Since we will be rendering the value of a cell of the grid world with a color that blends from red to blue, we will create an instance of the ColorBlend interface. In particular, we will use the LandmarkColorBlendInterpolation . This class lets you input a real value that spits out a color that is interpolated between various specified colors. So in this case, we defined the interpolation to blend from red to blue (we could have added additional points of color in between; feel free to experiment). The numeric values to which we assign these colors are normalized, so 0 is the minimum value and 1 is the maximum. Next we want to define a StateValuePainter instance, which is an interface that has a method that takes as input a graphics context, a State and a value for that state and renders it to the graphics context. In particular, we will use the StateValuePainter2D implementation, which will rendered colored cells for each state where the color to render is based on a ColorBlend instance (which we defined above). For this class to determine where in a graphics context to render a state's cell, it needs to be told what object class and attributes in the state represent the x and y position in the 2D world. So in this case, we tell it to use the agent's x and y positions. At this point, we create our ValueFunctionVisualizerGUI instance, which takesthe states for which to render the value, the StateValuePainter to use, and the sourceValueFunction that specifies the value for the states. However, before we finish, we also added a Policy renderer that can overlay the value function visualization. For this rendering, we will need a StatePolicyPainter implementation and in the code we use a PolicyGlyphPainter2D that renders a policy at some position in a 2D graphics context by drawing glyphs for the selected action (or actions if there are a set of actions that the policy selects). Like the StateValuePainter2D, this class needs to be told what the object class attributes in a State indicate the 2D position in the graphics context. It also needs to be told which ActionGlyphPainter to use to paint a glyph for each action (by action name). Here we used the existing ArrowActionGlyph for each action, where the parameter in its constructor for 0 to 3 indicates a north, south east, and west arrow respectively. The PolicyGlyphPainter2D also have various ways to render the glyphs. Here we use DISTSCALED which means each action glyph is rendered at a size proportional to the probability that the agent will select that action. Finally, we set the ValueFunctionVisualizerGUI to use the StatePolicyPainter we created, and set the Policy it should render. Then we set the background color to gray, and launch the GUI. If you now point the value iteration method to this value function visualization method instead of the simple one, you should find that your get the same visualization. Next Part", "http://burlap.cs.brown.edu/tutorials_v2/bpl/p6.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Basic Planning and Learning Tutorials > Basic Planning and Learning > Part 6 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A* Planning with Value Iteration Learning with Q-Learning Learning with Sarsa(\u03bb) Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part Experimenter Tools and Performance Plotting In the previous section you learned how to use an EnvironmentObserver to perform live visualization of the agentin the state space as it was learning. In this section we will make use another EnvironmentObserver called PerformancePlotter to record a learning algorithm's performance and compare it to another learning algorithm. ThePerformacnePlotter has a lot of powerful tools to display lots of important experimental results. To streamlinethe construction process, we will make use of the LearningAlgorithmExperimenter class, which is convenient for comparingthe performance of multiple learning algorithms over many trials. If you'd prefer to run your own experiment using adifferent design flow, however, you could make use of the PerformancePlotter directly yourself. To demonstrate the LearningAlgorithmExperimenter, we will compare the learning performance of a Q-learning algorithmwith the performance of a SARSA(\u03bb) algorithm. To make the results a bit more interesting to visualize,we will also use a different reward function than we have been that returns a reward of 5 when the goal is reached and -0.1for every other step. Lets then begin by adding a new method to our BasicBehavior class to call totest the experimenter tools. Inside the method, we will change our SimulateEnvironment object's reward function to an instance of the GoalBasedRF which takes a StateConditionTest object to specify goal conditions (which we have already set up previously in the tutorial for our search algorithms like BFS), a goal reward, and a default reward for all non-goal states. public void experimenterAndPlotter(){//different reward function for more interesting results((SimulatedEnvironment)env).setRf(new GoalBasedRF(this.goalCondition, 5.0, -0.1));} For the LearningAlgorithmExperimenter to report an average performance of each algorithm,it will test the algorithm over multiple trials. Therefore, at the start of each trial a cleanagent instance of the algorithm without knowledge of any of the previous trials must be generated. To easily get a clean version of each agent, the LearningAlgorithmExperimenter will request a sequence of LearningAgentFactory objects thatcan be used to generate a clean version of each agent on demand. In the following code, we create aLearningAgentFactory for a Q-learning algorithm and a SARSA(\u03bb) algorithm. /** * Create factories for Q-learning agent and SARSA agent to compare */LearningAgentFactory qLearningFactory = new LearningAgentFactory() {@Overridepublic String getAgentName() {return \"Q-Learning\";}@Overridepublic LearningAgent generateAgent() {return new QLearning(domain, 0.99, hashingFactory, 0.3, 0.1);}};LearningAgentFactory sarsaLearningFactory = new LearningAgentFactory() {@Overridepublic String getAgentName() {return \"SARSA\";}@Overridepublic LearningAgent generateAgent() {return new SarsaLam(domain, 0.99, hashingFactory, 0.0, 0.1, 1.);}}; Note that the factory also requires a getAgentName() method to be implemented. The LearningAgentExperimenter classwill use this name to label the results of each learning algorithm's performance. We are just about ready to create our experimenter, but firstwe will need to decide how many trials we want to test, the length of the trials, and what performance data wewant to plot. There are six possible performance metrics we could plot: cumulative reward per step, cumulative reward per episode, average reward per episode, median reward per episode, cumulative steps per episode, and steps per episode. Furthermore, we could also have our plotter display the results from the most recent trial only,the average performance across all trials, or both. For this tutorial, we will plot both the most recent trial andaverage trial performance for the cumulative steps per episode and the average reward per episode. We will alsotest the algorithms for 10 trials that last 100 episodes each. The below code will create our experimenter,start it, and also save all the data for all six metrics to CSV files. LearningAlgorithmExperimenter exp = new LearningAlgorithmExperimenter(env, 10, 100, qLearningFactory, sarsaLearningFactory);exp.setUpPlottingConfiguration(500, 250, 2, 1000,TrialMode.MOSTRECENTANDAVERAGE,PerformanceMetric.CUMULATIVESTEPSPEREPISODE,PerformanceMetric.AVERAGEEPISODEREWARD);exp.startExperiment();exp.writeStepAndEpisodeDataToCSV(\"expData\"); Note that in the constructor, the LearningAgent factories are the last parameters, of whicha variable number of factories could be provided; we could have tested just one agent, or we could have tested many more, but thereshould naturally always be at least one LearningAgentFactory provided. The other important part of the code is the setUpPlottingConfiguration method, which is used to define what resultsare plotted and how they are displayed. The first four parameters specify a plot's width and height, the number of columnsof plots, and the maximum window height. In this case, plots are set to be 500x200, with two columns of plots. Plotsare placed columns first, wrapping down to a new row as needed. The window size will be scaled to the width of plots times the number of columns; the height will scale to the height of the plots times the number of rows, unless thatheight is greater than the maximum window height, in which case the plots will be placed in a scroll view. The nextparameter specifies whether to show plots for only the most recent trial, the average performance over all trials, orboth. We have selected to show both. The remaining parameters are variable in size and specify which performance metrics will be plotted. The order of the performance metrics providedalso dictates the order that the plots will fill the window (again, filling columns first). The startExperiment method begins the experiment which will run all trials for all learning algorithms provided. Once you point our BasicBevhavior main method to the new method we've created and run the code, A GUI should appear with the plots requested,displaying the performance as it is available. When the experiment is complete, you should be left with an image like the below. In the trial average plots, you'll note that a translucent filled area around each of the curves is present. This filledarea shows the 95% confidence interval. You can change the significance level used before running the experimentusing the setPlotCISignificance method. Note that these plots are not static and you can interact with them. If you click drag in a region, it will cause the plotto zoom into the selected area. If you right click, you'll find a number of other options that you can set, includingchanging the labels. Another important feature you'll see from the contextual menu is an option to save plot image to disk. Since we also told the LearningAlgorithmExperimenter object to save the data to csv files, you should find two files that it created:expDataSteps.csv and expDataEpisodes.csv. The first contains all trial data for the cumulative reward per stepmetric. The latter contains all of the episode-wise metric data (even for the metrics that we did not plot). Thesefiles will make interacting with the data in another program, such as R, convenient. Conclusion This ends our tutorial on implementing basic planning and learning algorithms in BURLAP. There areother planning and learning algorithms in BURLAP, but hopefully this tutorial has explained the core conceptswell enough that you should be able to try different algorithms easily. As a future exercise, we encourage youto try just that within this code you've created! The complete set of code that we wrote in this tutorial is shownbelow for your convenience. The full code is also in the BURLAP code libary under the examples package. import burlap.behavior.policy.GreedyQPolicy;import burlap.behavior.policy.Policy;import burlap.behavior.singleagent.EpisodeAnalysis;import burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizer;import burlap.behavior.singleagent.auxiliary.StateReachability;import burlap.behavior.singleagent.auxiliary.performance.LearningAlgorithmExperimenter;import burlap.behavior.singleagent.auxiliary.performance.PerformanceMetric;import burlap.behavior.singleagent.auxiliary.performance.TrialMode;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.ValueFunctionVisualizerGUI;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.ArrowActionGlyph;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.LandmarkColorBlendInterpolation;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.PolicyGlyphPainter2D;import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.StateValuePainter2D;import burlap.behavior.singleagent.learning.LearningAgent;import burlap.behavior.singleagent.learning.LearningAgentFactory;import burlap.behavior.singleagent.learning.tdmethods.QLearning;import burlap.behavior.singleagent.learning.tdmethods.SarsaLam;import burlap.behavior.singleagent.planning.Planner;import burlap.behavior.singleagent.planning.deterministic.DeterministicPlanner;import burlap.behavior.singleagent.planning.deterministic.informed.Heuristic;import burlap.behavior.singleagent.planning.deterministic.informed.astar.AStar;import burlap.behavior.singleagent.planning.deterministic.uninformed.bfs.BFS;import burlap.behavior.singleagent.planning.deterministic.uninformed.dfs.DFS;import burlap.behavior.singleagent.planning.stochastic.valueiteration.ValueIteration;import burlap.behavior.valuefunction.QFunction;import burlap.behavior.valuefunction.ValueFunction;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.GridWorldVisualizer;import burlap.oomdp.auxiliary.common.SinglePFTF;import burlap.oomdp.auxiliary.stateconditiontest.StateConditionTest;import burlap.oomdp.auxiliary.stateconditiontest.TFGoalCondition;import burlap.oomdp.core.Domain;import burlap.oomdp.core.TerminalFunction;import burlap.oomdp.core.objects.ObjectInstance;import burlap.oomdp.core.states.State;import burlap.oomdp.singleagent.RewardFunction;import burlap.oomdp.singleagent.SADomain;import burlap.oomdp.singleagent.common.GoalBasedRF;import burlap.oomdp.singleagent.common.UniformCostRF;import burlap.oomdp.singleagent.common.VisualActionObserver;import burlap.oomdp.singleagent.environment.Environment;import burlap.oomdp.singleagent.environment.EnvironmentServer;import burlap.oomdp.singleagent.environment.SimulatedEnvironment;import burlap.oomdp.statehashing.HashableStateFactory;import burlap.oomdp.statehashing.SimpleHashableStateFactory;import burlap.oomdp.visualizer.Visualizer;import java.awt.*;import java.util.List;public class BasicBehavior {GridWorldDomain gwdg;Domain domain;RewardFunction rf;TerminalFunction tf;StateConditionTest goalCondition;State initialState;HashableStateFactory hashingFactory;Environment env;public BasicBehavior(){gwdg = new GridWorldDomain(11, 11);gwdg.setMapToFourRooms();domain = gwdg.generateDomain();rf = new UniformCostRF();tf = new SinglePFTF(domain.getPropFunction(GridWorldDomain.PFATLOCATION));goalCondition = new TFGoalCondition(tf);initialState = GridWorldDomain.getOneAgentNLocationState(domain, 1);GridWorldDomain.setAgent(initialState, 0, 0);GridWorldDomain.setLocation(initialState, 0, 10, 10);hashingFactory = new SimpleHashableStateFactory();env = new SimulatedEnvironment(domain, rf, tf, initialState);/*VisualActionObserver observer = new VisualActionObserver(domain, GridWorldVisualizer.getVisualizer(gwdg.getMap()));observer.initGUI();env = new EnvironmentServer(env, observer);//((SADomain)domain).addActionObserverForAllAction(observer);*/}public void visualize(String outputpath){Visualizer v = GridWorldVisualizer.getVisualizer(gwdg.getMap());new EpisodeSequenceVisualizer(v, domain, outputpath);}public void BFSExample(String outputPath){DeterministicPlanner planner = new BFS(domain, goalCondition, hashingFactory);Policy p = planner.planFromState(initialState);p.evaluateBehavior(initialState, rf, tf).writeToFile(outputPath + \"bfs\");}public void DFSExample(String outputPath){DeterministicPlanner planner = new DFS(domain, goalCondition, hashingFactory);Policy p = planner.planFromState(initialState);p.evaluateBehavior(initialState, rf, tf).writeToFile(outputPath + \"dfs\");}public void AStarExample(String outputPath){Heuristic mdistHeuristic = new Heuristic() {@Overridepublic double h(State s) {ObjectInstance agent = s.getFirstObjectOfClass(GridWorldDomain.CLASSAGENT);ObjectInstance location = s.getFirstObjectOfClass(GridWorldDomain.CLASSLOCATION);int ax = agent.getIntValForAttribute(GridWorldDomain.ATTX);int ay = agent.getIntValForAttribute(GridWorldDomain.ATTY);int lx = location.getIntValForAttribute(GridWorldDomain.ATTX);int ly = location.getIntValForAttribute(GridWorldDomain.ATTY);double mdist = Math.abs(ax-lx) + Math.abs(ay-ly);return -mdist;}};DeterministicPlanner planner = new AStar(domain, rf, goalCondition, hashingFactory, mdistHeuristic);Policy p = planner.planFromState(initialState);p.evaluateBehavior(initialState, rf, tf).writeToFile(outputPath + \"astar\");}public void valueIterationExample(String outputPath){Planner planner = new ValueIteration(domain, rf, tf, 0.99, hashingFactory, 0.001, 100);Policy p = planner.planFromState(initialState);p.evaluateBehavior(initialState, rf, tf).writeToFile(outputPath + \"vi\");//simpleValueFunctionVis((ValueFunction)planner, p);manualValueFunctionVis((ValueFunction)planner, p);}public void qLearningExample(String outputPath){LearningAgent agent = new QLearning(domain, 0.99, hashingFactory, 0., 1.);//run learning for 50 episodesfor(int i = 0; i < 50; i++){EpisodeAnalysis ea = agent.runLearningEpisode(env);ea.writeToFile(outputPath + \"ql_\" + i);System.out.println(i + \": \" + ea.maxTimeStep());//reset environment for next learning episodeenv.resetEnvironment();}}public void sarsaLearningExample(String outputPath){LearningAgent agent = new SarsaLam(domain, 0.99, hashingFactory, 0., 0.5, 0.3);//run learning for 50 episodesfor(int i = 0; i < 50; i++){EpisodeAnalysis ea = agent.runLearningEpisode(env);ea.writeToFile(outputPath + \"sarsa_\" + i);System.out.println(i + \": \" + ea.maxTimeStep());//reset environment for next learning episodeenv.resetEnvironment();}}public void simpleValueFunctionVis(ValueFunction valueFunction, Policy p){List<State> allStates = StateReachability.getReachableStates(initialState, (SADomain)domain, hashingFactory);ValueFunctionVisualizerGUI gui = GridWorldDomain.getGridWorldValueFunctionVisualization(allStates, valueFunction, p);gui.initGUI();}public void manualValueFunctionVis(ValueFunction valueFunction, Policy p){List<State> allStates = StateReachability.getReachableStates(initialState, (SADomain)domain, hashingFactory);//define color functionLandmarkColorBlendInterpolation rb = new LandmarkColorBlendInterpolation();rb.addNextLandMark(0., Color.RED);rb.addNextLandMark(1., Color.BLUE);//define a 2D painter of state values, specifying which attributes correspond //to the x and y coordinates of the canvasStateValuePainter2D svp = new StateValuePainter2D(rb);svp.setXYAttByObjectClass(GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTX,GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTY);//create our ValueFunctionVisualizer that paints for all states//using the ValueFunction source and the state value painter we definedValueFunctionVisualizerGUI gui = new ValueFunctionVisualizerGUI(allStates, svp, valueFunction);//define a policy painter that uses arrow glyphs for each of the grid world actionsPolicyGlyphPainter2D spp = new PolicyGlyphPainter2D();spp.setXYAttByObjectClass(GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTX,GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTY);spp.setActionNameGlyphPainter(GridWorldDomain.ACTIONNORTH, new ArrowActionGlyph(0));spp.setActionNameGlyphPainter(GridWorldDomain.ACTIONSOUTH, new ArrowActionGlyph(1));spp.setActionNameGlyphPainter(GridWorldDomain.ACTIONEAST, new ArrowActionGlyph(2));spp.setActionNameGlyphPainter(GridWorldDomain.ACTIONWEST, new ArrowActionGlyph(3));spp.setRenderStyle(PolicyGlyphPainter2D.PolicyGlyphRenderStyle.DISTSCALED);//add our policy renderer to itgui.setSpp(spp);gui.setPolicy(p);//set the background color for places where states are not rendered to greygui.setBgColor(Color.GRAY);//start itgui.initGUI();}public void experimentAndPlotter(){//different reward function for more interesting results((SimulatedEnvironment)env).setRf(new GoalBasedRF(this.goalCondition, 5.0, -0.1));/** * Create factories for Q-learning agent and SARSA agent to compare */LearningAgentFactory qLearningFactory = new LearningAgentFactory() {@Overridepublic String getAgentName() {return \"Q-Learning\";}@Overridepublic LearningAgent generateAgent() {return new QLearning(domain, 0.99, hashingFactory, 0.3, 0.1);}};LearningAgentFactory sarsaLearningFactory = new LearningAgentFactory() {@Overridepublic String getAgentName() {return \"SARSA\";}@Overridepublic LearningAgent generateAgent() {return new SarsaLam(domain, 0.99, hashingFactory, 0.0, 0.1, 1.);}};LearningAlgorithmExperimenter exp = new LearningAlgorithmExperimenter(env, 10, 100, qLearningFactory, sarsaLearningFactory);exp.setUpPlottingConfiguration(500, 250, 2, 1000,TrialMode.MOSTRECENTANDAVERAGE,PerformanceMetric.CUMULATIVESTEPSPEREPISODE,PerformanceMetric.AVERAGEEPISODEREWARD);exp.startExperiment();exp.writeStepAndEpisodeDataToCSV(\"expData\");}public static void main(String[] args) {BasicBehavior example = new BasicBehavior();String outputPath = \"output/\";example.BFSExample(outputPath);//example.DFSExample(outputPath);//example.AStarExample(outputPath);//example.valueIterationExample(outputPath);//example.qLearningExample(outputPath);//example.sarsaLearningExample(outputPath);//example.experimentAndPlotter();example.visualize(outputPath);}} End.", "http://burlap.cs.brown.edu/tutorials_v2/cpl/p1.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Creating a Planning and Learning Algorithm Tutorials > Creating a Planning and Learning Algorithm > Part 1 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Next Part You are viewing the tutorial for BURLAP 2; if you'd like the BURLAP version 1 tutorial, go here . Introduction In the previous tutorials, we walked through how you can use existing planning and learning algorithms in BURLAP on domains in BURLAP and how to create your own domains on which you can use those algorithms. However, you may also want to extend or create your own planning or learning algorithm in BURLAP that can either be used on existing domains or novel BURLAP domains and be easily compared against existing algorithms. In this tutorial, we will show you how to create both a planning algorithm and a learning algorithm. In particular, we will be reimplementing versions of Value Iteration and Q-learning since they are conceptually simple algorithms to implement, but will expose the various properties of BURLAP you would want to use. In general, however, you should defer to using the existing implementations of these algorithms in BURLAP since they will support more features than we will cover here. Value Iteration Overview Value Iteration (VI) is an algorithm that finds the optimal value function (the expected discounted future reward of being in a state an behaving optimally from it), and consequentially the optimal policy, for an MDP's entire state space. Central to the idea of VI is the Bellman Equation, which states that the optimal value of a stateis the value of the action with the maximum expected discounted future return (the action with the maximum Q-value) where the Q-value for a state-action pair is defined as the expected value over allpossible state transitions of the immediate reward summed with the discounted value of the resulting state. In math:$$\\large V(s) = \\max_a Q(s,a)$$$$\\large Q(s,a) = \\sum_{s'} T(s' | s,a) \\left[ R(s, a, s') + \\gamma V(s') \\right],$$ where $T(s' | s, a)$ is the probability of transitioning to state $s'$ when taking action $a$ in state $s$, $R(s, a, s')$ is the reward received for transitioning to state $s'$ after taking action $a$ in state $s$, and $\\gamma$ is a discount factor affecting how much immediate rewards are preferred to later ones. This equation presents some issues in that if an MDP has cycles, it's unclear what the values should be. However, the Value Iteration algorithm will converge to the optimal Value function if you simply initialize the value for each state to some arbitrary value, and then iteratively use the Bellman equationto update the the value for each state. Planning algorithms that make use of the Bellman equation to estimate the Value function are known as Dynamic Programming (DP) planning algorithms. Different DP algorithms specify different priorities for when the estimated value of each state is updated with the Bellman equation. In the case of VI, Bellman updates are performed in entire sweeps of the state space. That is, at the start, the value for all states is initialized to some arbitrary value. Then, for each state in the state space, the Bellman equation is used to update the value function estimate. Sweeps over the entire state space are repeated for some fixed number of iterations or until the maximum change in the value function is small. The algorithm is summarized in the below pseudocode. Value Iteration Initialize value function $V(s)$ arbitrarily for all states $s$. Repeat until convergence... For each state $s$ $V(s) := \\max_a \\sum_{s'} T(s' | s, a) \\left[R(s,a,s') + \u03b3 V(s')\\right]$ Since there are a number of different DP algorithms that can be implemented, BURLAP includes a class called DynamicProgramming that includes a number of helpful methods for automatically performing Bellman Updates on states and which is extended by many of the DP algorithms included in BURLAP. However, to give a better sense of howto use the more fundamental parts of a planning algorithm in BURLAP, we will instead write our VI algorithm from scratch without using the DynamicProgramming class. However, we will extend the MDPSolver class since it provides a number of useful datamemb ers and setter and getting methods that you will commonly want to have for algorithms that solve MDPs. Next Part", "http://burlap.cs.brown.edu/tutorials_v2/cpl/p2.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Creating a Planning and Learning Algorithm Tutorials > Creating a Planning and Learning Algorithm > Part 2 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Previous Part | Next Part VI Code Lets start by creating our class for VI, which we'll call VITutorial. Our class will extend MDPSolver , to gain many of the useful datastructures used in solving an MDP, and it will implement the Planner and QFunction interfaces. The former because we will implement the planFromState method and the latter because ValueIteration computes and ValueFunction and QFunction (the QFunction interface extends the ValueFunction interface). We will also add all the imports we will need in developing this class. import burlap.behavior.policy.GreedyQPolicy;import burlap.behavior.policy.Policy;import burlap.behavior.singleagent.EpisodeAnalysis;import burlap.behavior.singleagent.MDPSolver;import burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizer;import burlap.behavior.singleagent.auxiliary.StateReachability;import burlap.behavior.singleagent.planning.Planner;import burlap.behavior.valuefunction.QFunction;import burlap.behavior.valuefunction.QValue;import burlap.behavior.valuefunction.ValueFunctionInitialization;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.GridWorldTerminalFunction;import burlap.domain.singleagent.gridworld.GridWorldVisualizer;import burlap.oomdp.core.AbstractGroundedAction;import burlap.oomdp.core.Domain;import burlap.oomdp.core.TerminalFunction;import burlap.oomdp.core.TransitionProbability;import burlap.oomdp.core.states.State;import burlap.oomdp.singleagent.GroundedAction;import burlap.oomdp.singleagent.RewardFunction;import burlap.oomdp.singleagent.SADomain;import burlap.oomdp.singleagent.common.UniformCostRF;import burlap.oomdp.statehashing.HashableState;import burlap.oomdp.statehashing.HashableStateFactory;import burlap.oomdp.statehashing.SimpleHashableStateFactory;import burlap.oomdp.visualizer.Visualizer;import java.util.*;public class VITutorial extends MDPSolver implements Planner, QFunction{@Overridepublic double value(State s) {return 0.;}@Overridepublic List<QValue> getQs(State s) {// TODO Auto-generated method stubreturn null;}@Overridepublic QValue getQ(State s, AbstractGroundedAction a) {// TODO Auto-generated method stubreturn null;}@Overridepublic Policy planFromState(State initialState) {// TODO Auto-generated method stub}@Overridepublic void resetSolverResults() {// TODO Auto-generated method stub}} Because we are sub classing MDPSolver, this object will auto create data members that define our domain and task (the Domain, RewardFunction, TerminalFunction, discount factor, andHashableStateFactory that is used to hash and check the equality of states). However, the other critical data that VI needs to store are its estimates of the value function! A value function is ultimately a mapping from states to a real value. Therefore, for fast access we can use a HashMap and use a HashableStateFactory to provide HashableState instances from states. One way to make VI run faster is to inititialize its value funciton to something close to the optimal value function. BURLAP has a ValueFuncitonInitialization interface that can be provided to our code for choosing initialization values. We'll also have a parameter that specifies how long value iteration should run before it terminates (there are others to test for convergence that we will not cover here). Lets create datamembers for these elements and create a constructor. protected Map<HashableState, Double> valueFunction;protected ValueFunctionInitialization vinit;protected int numIterations;public VITutorial(Domain domain, RewardFunction rf, TerminalFunction tf, double gamma, HashableStateFactory hashingFactory, ValueFunctionInitialization vinit, int numIterations){this.solverInit(domain, rf, tf, gamma, hashingFactory);this.vinit = vinit;this.numIterations = numIterations;this.valueFunction = new HashMap<HashableState, Double>();} Note that since our MDPSolver superclass will hold our data members for the domain, reward function, terminal function, discount factor, and HashableStateFactory, we can initialize them with its solverInit method. There is one other critical component VI needs that isn't part of the data we've given it in the constructor: the full state space! One reason we might not want to demand this upfront is because in an OO-MDP, it is possible for the state space to be infinite even though for any given input state there may only be a finite set of states that are reachable. We could require the user to provide to our algorithm up front what the state space is, but it's much easier on the client if we determine the set of possible reachable states for any given seed state ourself and only perform this procedure when planning is requested for a previously unseen state. Lets define a method to get all reachable states from an input state and initialize the value for them with our ValueFunctionInitialization object. Add the below method. public void performReachabilityFrom(State seedState){Set<HashableState> hashedStates = StateReachability.getReachableHashedStates(seedState, (SADomain) this.domain, this.hashingFactory);//initialize the value function for all statesfor(HashableState hs : hashedStates){if(!this.valueFunction.containsKey(hs)){this.valueFunction.put(hs, this.vinit.value(hs.s));}}} In the first line, we make use of BURLAP's StateReachability tool to do the heavy lifting of finding all reachable states. Then we simply iterate through the list, and for every HashableState for which we do not already have an entry, we initialize it with the value returned from the ValueFunctionInitialization. You may notice that the value function is passed hs.s. Since our set of states are actually a set of HashableState instances, we retrieve the underlying State object stored in the HashableState by its .s member. The other method we'll need to implement is the Bellman Equation. As noted on the previous page, the Bellman Equation is just a max over the Q-values and since we already have methods defined for getting the Q-value of states (a requirement of implementing the QFunction interface), we will implement those methods and a Bellman Equation method next. @Overridepublic List<QValue> getQs(State s) {List<GroundedAction> applicableActions = this.getAllGroundedActions(s);List<QValue> qs = new ArrayList<QValue>(applicableActions.size());for(GroundedAction ga : applicableActions){qs.add(this.getQ(s, ga));}return qs;}@Overridepublic QValue getQ(State s, AbstractGroundedAction a) {//type cast to the type we're usingGroundedAction ga = (GroundedAction)a;//what are the possible outcomes?List<TransitionProbability> tps = ga.getTransitions(s);//aggregate over each possible outcomedouble q = 0.;for(TransitionProbability tp : tps){//what is reward for this transition?double r = this.rf.reward(s, ga, tp.s);//what is the value for the next state?double vp = this.valueFunction.get(this.hashingFactory.hashState(tp.s));//add contribution weighted by transition probabiltiy and//discounting the next stateq += tp.p * (r + this.gamma * vp);}//create Q-value wrapperQValue qValue = new QValue(s, ga, q);return qValue;}protected double bellmanEquation(State s){if(this.tf.isTerminal(s)){return 0.;}List<QValue> qs = this.getQs(s);double maxQ = Double.NEGATIVE_INFINITY;for(QValue q : qs){maxQ = Math.max(maxQ, q.q);}return maxQ;} You'll note that the Q-value methods return QValue objects, which are just triples consisting of a State object, an AbstractGroundedAction object, and a double for the Q-value associated with them. AbstractGroundedAction versus Action You might wonder why we're using AbstractGroundedAction references for actions, rather than a Action instance that we subclassed to define actions in the Building a Domain Tutorial . However, recall that the Action class is used for defining actions, whereas the GroundedAction class is a reference to an Action definition that also contains any action parameter selections necessary to execute the action. Since actions could be parameterized, we use implementations of the general AbstractGroundedAction interface, of which GroundedAction is an implementation, to reason about decisions, or in this case, estimate the Q-value for the action selection. In the getQs method, we simply find all possible grounded actions (using a method ineheretied from MDPSolver which we extended; alternatively, we could use an Action static method that takes is list of Aciton objects and State and returns all applicable groundings), ask our getQ method what the Q-value is, and then return the list of all those Q-values. In the getQ method, we find all possible transitions from the input state and weigh the value of those outcomes by the probability of the transition occurring. The value of each outcome is the reward received, and the discounted value we have estimated for the outcome state. In the bellmanEquation method, we in general just return the maximum Q-value for the state; however, there is a catch. That is, if the input state is a terminal state, then by definition of it being a terminal state the value is zero, because the idea of a terminal state is that no action can follow from it. Therefore, if the state is a terminal state, we return a value of 0 and ignore whatever the domain object would say the possible transitions would be. Note that this check is not just a performance saver; all terminal states are specified by the TerminalFunction interface, so we must always refer to it to handle terminal states and cannot expect that a domain's transition dynamics have it baked in. We now have all the tools we need to do planning, so it's time to implement the planFromStateMethod. This method is called whenever a client wants to run planning from a given initial (or seed) state. What we'll do then is first check if we've already performed planning that includes that state. If so, we'll do nothing, having assumed to already have computed the value for it. However, if we haven't seen it before, then we'll first find all reachable states from it, and then run value iteration for a given number of iterations. As a reminder, running value iteration means making iterative sweeps over the entire state space in which the value of each state is re-estimated to what the Bellman equation says it is given the previously estimated value of the states. Finally, all planFromState methodsrequire return a suitable Policy object to use the planning results. For value iteration, assuming it converged, the optimal policy is to select the action with the highest Q-value; therefore we'll return a GreedyQPolicy object. GreedyQPolicy objects need to be told what their QFunction source is, which in this case, is the instance of our class. @Overridepublic GreedyQPolicy planFromState(State initialState) {HashableState hashedInitialState = this.hashingFactory.hashState(initialState);if(this.valueFunction.containsKey(hashedInitialState)){return new GreedyQPolicy(this); //already performed planning here!}//if the state is new, then find all reachable states from it firstthis.performReachabilityFrom(initialState);//now perform multiple iterations over the whole state spacefor(int i = 0; i < this.numIterations; i++){//iterate over each statefor(HashableState sh : this.valueFunction.keySet()){//update its value using the bellman equationthis.valueFunction.put(sh, this.bellmanEquation(sh.s));}}return new GreedyQPolicy(this);} We're now just about finished! The only thing left is that each MDPSolver instance is asked to implement the method resetSolverResults, which when called should have the effect of resetting all data so that it's as if no planning calls had ever been made. For our VI implementation, all this requires is clearing our value function. @Overridepublic void resetSolverResults() {this.valueFunction.clear();} Testing VI To test our code, you can try using this planning algorithm with the grid world task created in the previous Basic Planning and Learning tutorial.Alternatively, below is a main method that you can add to test your VI implementation that creates a stochastic grid world, plans for it, and evaluates a single rollout of the resulting policy and visualizes the results. public static void main(String [] args){GridWorldDomain gwd = new GridWorldDomain(11, 11);gwd.setMapToFourRooms();//only go in intended directon 80% of the timegwd.setProbSucceedTransitionDynamics(0.8);Domain domain = gwd.generateDomain();//get initial state with agent in 0,0State s = GridWorldDomain.getOneAgentNoLocationState(domain);GridWorldDomain.setAgent(s, 0, 0);//all transitions return -1RewardFunction rf = new UniformCostRF();//terminate in top right cornerTerminalFunction tf = new GridWorldTerminalFunction(10, 10);//setup vi with 0.99 discount factor, a value//function initialization that initializes all states to value 0, and which will//run for 30 iterations over the state spaceVITutorial vi = new VITutorial(domain, rf, tf, 0.99, new SimpleHashableStateFactory(),new ValueFunctionInitialization.ConstantValueFunctionInitialization(0.0), 30);//run planning from our initial statePolicy p = vi.planFromState(s);//evaluate the policy with one roll out visualize the trajectoryEpisodeAnalysis ea = p.evaluateBehavior(s, rf, tf);Visualizer v = GridWorldVisualizer.getVisualizer(gwd.getMap());new EpisodeSequenceVisualizer(v, domain, Arrays.asList(ea));} If you're looking to extend this tutorial on VI a little more, you might consider implementing a more intelligent VI termination condition so that rather than always running VI for a fixed number of iterations, VI terminates if the maximum change in the value function is smaller than some small threshold. Otherwise, it's now time to move on to our Q-learning example! If you'd like to see the full code we wrote all together, jump to the end of this tutorial . Next Part", "http://burlap.cs.brown.edu/tutorials_v2/cpl/p3.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Creating a Planning and Learning Algorithm Tutorials > Creating a Planning and Learning Algorithm > Part 3 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Previous Part | Next Part Q-Learning Overview For our learning algorithm example, we'll be implementing Q-learning. The difference between a learning algorithm and a planning algorithm is that a planning algorithm has access to a model of the world, or at least a simulator, whereas a learning algorithm involves determining behavior when the agent does not know how the world works and must learn how to behave from direct experience with the world. In general, there are two approaches to reinforcement learning: (1) to learn a model of the world from experience and then use planning with that learned model to dictate behavior (model-based) and (2) to learn a policy or value function directly from experience (model-free). Q-learning belongs to the latter. As the name suggests, Q-learning learns estimates of the optimal Q-values of an MDP, which means that behavior can be dictated by taking actions greedily with respect to the learned Q-values. Q-learning can be summarized in the following pseudocode. Q-Learning Initialize Q-values ($Q(s,a)$) arbitrarily for all state-action pairs. For life or until learning is stopped... Choose an action ($a$) in the current world state ($s$) based on current Q-value estimates ($Q(s,\\cdot)$). Take the action ($a$) and observe the the outcome state ($s'$) and reward ($r$). Update $Q(s,a) := Q(s,a) + \\alpha \\left[ r + \\gamma \\max_{a'} Q(s', a') - Q(s,a) \\right]$ The two key steps in the above pseudocode are steps 3 and 5. There are many ways to choose actions based on the current Q-value estimates (step 3), but one of the most common is to use an $\\epsilon$-greedy policy. In this policy, the action is selected greedily with respect to the Q-value estimates a fraction ($1-\\epsilon$) of the time (where $\\epsilon$ is a fraction between 0 and 1), and randomly selected among all actions a fraction $\\epsilon$ of the time. In general, you want a policy that has some randomness to it so that it promotes exploration of the state space. The update rule:$$\\large Q(s,a) := Q(s,a) + \\alpha \\left[ r + \\gamma \\max_{a'} Q(s', a') - Q(s,a) \\right]$$updates the Q-value of the last state-action pair ($s,a$) with respect to the observed outcome state ($s'$) and reward ($r$), where $\\alpha \\in (0, 1)$ is a learning rate parameter. To unpack this update, recall from the Bellman equation that the Value of a state is the maximum Q-value and the Q-value is the expected sum of the reward and discounted value of the next state, where the expectation is with respect to the probability of each state transition. In the Q-learning update rule, the reward plus the discounted max Q-value in the observed next state is effectively what the Bellman equation tells us the Q-value is, except in this case, we're not marginalizing over all possible outcome states, we only have the one observed state and reward that we happened to get. However, because our learning rate only allows our Q-value to change slightly from its old estimate to a new estimate in the direction of the observed state and reward, as long as we keep retrying that action in the same state, we'll see the other possible states that could have occurred and move in their direction too. In aggregate over multiple tries of the action then, the Q-value will move toward the true expected value, even though we never directly used the transition probabilities. To have guaranteed convergence to the true Q-value, we should actually be slowly decreasing the learning rate parameter over time. However, in practice, it's often sufficient to simply use a small learning rate parameter, so for simplicity in our implementation, we'll use a fixed value for the learning rate rather that one that changes with time (though in the full Q-learning algorithm provided in BURLAP, you can use different schedules for decreasing the learning rate, including client-provided custom schedules with the LearningRate interface). Q-Learning Code Lets begin implementing our Q-learning algorithm code. Our class, called QLTutorial, will extend MDPSolver and implement the LearningAgent and QFunction interfaces. The LearningAgent interface specifies the common methods a learning algorithm is expected to implement so that it can be used by other BURLAP tools. Below is the skeleton code that is created when we created our class. import burlap.behavior.singleagent.EpisodeAnalysis;import burlap.behavior.singleagent.MDPSolver;import burlap.behavior.singleagent.learning.LearningAgent;import burlap.behavior.valuefunction.QFunction;import burlap.behavior.valuefunction.QValue;import burlap.oomdp.core.AbstractGroundedAction;import burlap.oomdp.core.states.State;import burlap.oomdp.singleagent.environment.Environment;import java.util.List;public class QLTutorial extends MDPSolver implements LearningAgent, QFunction {@Overridepublic EpisodeAnalysis runLearningEpisode(Environment env) {return null;}@Overridepublic EpisodeAnalysis runLearningEpisode(Environment env, int maxSteps) {return null;}@Overridepublic void resetSolver() {}@Overridepublic List getQs(State s) {return null;}@Overridepublic QValue getQ(State s, AbstractGroundedAction a) {return null;}@Overridepublic double value(State s) {return 0;}} Similar to VI, the primary data we will want to store is a set of estimated Q-values for each state and action pair. We'll also again let the user specify the Q-value function initialization with a ValueFunctionInitialization object. We'll also need a learning rate parameter to be set. Finally, we'll need a learning policy to follow; that is, a policy that dictates how the agent chooses actions at each step. For this tutorial, we'll assume an $\\epsilon$-greedy policy and let the client specify the value for $\\epsilon$. Lets add data members for those elements now, as well as the value function which needs to return the maximum Q-value. protected Map<StateHashTuple, List<QValue>> qValues;protected ValueFunctionInitialization qinit;protected double learningRate;protected Policy learningPolicy; Lets also add a constructor to initialize our data members and some of those that we inherit from MDPSolver. public QLTutorial(Domain domain, double gamma, HashableStateFactory hashingFactory, ValueFunctionInitialization qinit, double learningRate, double epsilon){this.solverInit(domain, null, null, gamma, hashingFactory);this.qinit = qinit;this.learningRate = learningRate;this.qValues = new HashMap >();this.learningPolicy = new EpsilonGreedy(this, epsilon);} Note that we did not have to initialize the reward function or terminal function for the MDPSolver (the two null parameters) since these will be handled by the Environment object with which the learning algorithm will interact. The EpsilonGreedy policy object we create takes as input a QFunction, which this class will provide, and the value for epsilon to use. One of the primary tools we'll need is a method that grabs our Q-values, or creates and stores them with the proper initialization value if it's for an unseen state. Lets implement our Q-Value methods now as well as the value method which returns the state value: the maximum Q-value of all actions applicable in the state. @Overridepublic List<QValue> getQs(State s) {//first get hashed stateStateHashTuple sh = this.hashingFactory.hashState(s);//check if we already have stored valuesList<QValue> qs = this.qValues.get(sh);//create and add initialized Q-values if we don't have them stored for this stateif(qs == null){List<GroundedAction> actions = this.getAllGroundedActions(s);qs = new ArrayList<QValue>(actions.size());//create a Q-value for each actionfor(GroundedAction ga : actions){//add q with initialized valueqs.add(new QValue(s, ga, this.qinit.qValue(s, ga)));}//store this for laterthis.qValues.put(sh, qs);}return qs;}@Overridepublic QValue getQ(State s, AbstractGroundedAction a) {//first get all Q-valuesList qs = this.getQs(s);//iterate through stored Q-values to find a match for the input actionfor(QValue q : qs){if(q.a.equals(a)){return q;}}throw new RuntimeException(\"Could not find matching Q-value.\");}@Overridepublic double value(State s) {return QFunctionHelper.getOptimalValue(this, s);} Note that for the value method, we used the QFunciton helper class QFunctionHelper whose method getOptimalValue will return the maximum Q-value in a QFunction object by querying its getQs method and returning the maximum Q-value value. Now that we have all of our helper methods, lets implement the learning algorithm. The LearningAgent interface requires us to implement two methods that cause learning to be run for one episode in some Environment ; one that will run learning until the agent reaches a terminal state and one that will run learning for a maximum number of steps or until a terminal state is reached. We will have the former call the latter with a -1 for the maximum number of steps to indicate that it should never stop until the agent reaches a terminal state. Both methods also require returning an EpisodeAnalysis object, which is a recording of all the states, actions, and rewards that occurred in an episode, so as we write the code to have the agent iteratively select actions, we'll record the results to an EpisodeAnalysis object. Below is the learning algorithm code for Q-learning. @Overridepublic EpisodeAnalysis runLearningEpisode(Environment env) {return this.runLearningEpisode(env, -1);}@Overridepublic EpisodeAnalysis runLearningEpisode(Environment env, int maxSteps) {//initialize our episode analysis object with the initial state of the environmentEpisodeAnalysis ea = new EpisodeAnalysis(env.getCurrentObservation());//behave until a terminal state or max steps is reachedState curState = env.getCurrentObservation();int steps = 0;while(!env.isInTerminalState() && (steps < maxSteps || maxSteps == -1)){//select an actionGroundedAction a = (GroundedAction)this.learningPolicy.getAction(curState);//take the action and observe outcomeEnvironmentOutcome eo = a.executeIn(env);//record resultea.recordTransitionTo(a, eo.o, eo.r);//get the max Q value of the resulting state if it's not terminal, 0 otherwisedouble maxQ = eo.terminated ? 0. : this.value(eo.op);//update the old Q-valueQValue oldQ = this.getQ(curState, a);oldQ.q = oldQ.q + this.learningRate * (eo.r + this.gamma * maxQ - oldQ.q);//move on to next statecurState = eo.op;steps++;}return ea;} The beginning of the code is fairly straightforward; we construct a new EpisodeAnalysis object rooted in the current state of the environment, which we get back from the Environment method getCurrentObservation(). We then begin an execution loop that lasts either until the Environment reaches a terminal state or until the number of steps we've taken exceeds the number requested. Inside the execution loop, we first select an action using our learning policy. Then we execute the action in the environment using the GroundedAction method executeIn(Environment),which returns to us an EnvironmentOutcome object. This object is tuple with the following datamembers. a - a GroundedAction specifying the action taken in the Environment o - the observation, represented by a State, from the Environment when the action was taken. op - the next observation from the Environment after the action was taken. r - a double value specifying the reward returned from the Environment terminated - a boolean specifying whether the Environment is now in a terminal state Environment Observations You may have noticed that the Environment uses \"observation\" terminology instead of \"state\" terminology. This choice is because Environment objects are not under obligation to return to the agent a full state, only an observation. Typically, for MDPdomains you can expect it to be a full State, and regardless of whether it is a partial observation or not, the observation itself will always be represnted by a BURLAP State object. Note that the use of this terminology is especially useful if you begin using BURLAP's POMDP framework. Using the new observations from the environment, we record the transition in our EpisodeAnalysis and update the previous Q-Value. To update the previous Q-value, we need to get the maximum Q-value for the next state we encounted. However, if that state is a terminal state, then the value should always be zero, because the agent cannot act further from that state. Otherwise, we can get the maximum value by using value method that we previously defined. Finally, we can implement the resetSoverResults method, which only needs to clear our Q-values. @Overridepublic void resetSolverResults() {this.qValues.clear();} Testing Q-Learning As before, you can now test your learning algorithm with the previous code developed in the Basic Planning and Learning tutorial . Alternatively, you can use the below main method which creates a similar Grid World domain and task as the test code we wrote for our VI implementation, except applies the Q-Learning algorithm to it in a simulated environment. The results of each leaning episode will be presented for you after learning completes. Note that because the domain is stochastic (and follows a nosiy exploration policy), it can take much longer to learn and the resulting policy will not be a straight shot to the goal. public static void main(String [] args){GridWorldDomain gwd = new GridWorldDomain(11, 11);gwd.setMapToFourRooms();gwd.setProbSucceedTransitionDynamics(0.8);Domain domain = gwd.generateDomain();//get initial state with agent in 0,0State s = GridWorldDomain.getOneAgentNoLocationState(domain);GridWorldDomain.setAgent(s, 0, 0);//all transitions return -1RewardFunction rf = new UniformCostRF();//terminate in top right cornerTerminalFunction tf = new GridWorldTerminalFunction(10, 10);//create environmentSimulatedEnvironment env = new SimulatedEnvironment(domain,rf, tf, s);//create Q-learningQLTutorial agent = new QLTutorial(domain, 0.99, new SimpleHashableStateFactory(),new ValueFunctionInitialization.ConstantValueFunctionInitialization(), 0.1, 0.1);//run Q-learning and store results in a listList episodes = new ArrayList (1000);for(int i = 0; i < 1000; i++){episodes.add(agent.runLearningEpisode(env));env.resetEnvironment();}Visualizer v = GridWorldVisualizer.getVisualizer(gwd.getMap());new EpisodeSequenceVisualizer(v, domain, episodes);} Next Part", "http://burlap.cs.brown.edu/tutorials_v2/cpl/p4.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Creating a Planning and Learning Algorithm Tutorials > Creating a Planning and Learning Algorithm > Part 4 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Previous Part Conclusions In this tutorial we showed you how to implement your own planning and learning algorithms. Although these algorithms were simple, they exposed the necessary BURLAP tools and mechanisms you will need to use to implement your own algorithms and should enable you to start writing your own code. In general, we highly recommend that you use BURLAP's existing implementations of Value Iteration and Q-Learning since they support a number of other features (Options, learning rate decay schedules, etc.). If you would like to see all of the code that was written in this tutorial, we have provided it below (first the Value Iteration code , then the Q-learning Code ). Full VI Code import burlap.behavior.policy.GreedyQPolicy;import burlap.behavior.policy.Policy;import burlap.behavior.singleagent.EpisodeAnalysis;import burlap.behavior.singleagent.MDPSolver;import burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizer;import burlap.behavior.singleagent.auxiliary.StateReachability;import burlap.behavior.singleagent.planning.Planner;import burlap.behavior.valuefunction.QFunction;import burlap.behavior.valuefunction.QValue;import burlap.behavior.valuefunction.ValueFunctionInitialization;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.GridWorldTerminalFunction;import burlap.domain.singleagent.gridworld.GridWorldVisualizer;import burlap.oomdp.core.AbstractGroundedAction;import burlap.oomdp.core.Domain;import burlap.oomdp.core.TerminalFunction;import burlap.oomdp.core.TransitionProbability;import burlap.oomdp.core.states.State;import burlap.oomdp.singleagent.GroundedAction;import burlap.oomdp.singleagent.RewardFunction;import burlap.oomdp.singleagent.SADomain;import burlap.oomdp.singleagent.common.UniformCostRF;import burlap.oomdp.statehashing.HashableState;import burlap.oomdp.statehashing.HashableStateFactory;import burlap.oomdp.statehashing.SimpleHashableStateFactory;import burlap.oomdp.visualizer.Visualizer;import java.util.*;public class VITutorial extends MDPSolver implements Planner, QFunction{protected Map<HashableState, Double> valueFunction;protected ValueFunctionInitialization vinit;protected int numIterations;public VITutorial(Domain domain, RewardFunction rf, TerminalFunction tf, double gamma, HashableStateFactory hashingFactory, ValueFunctionInitialization vinit, int numIterations){this.solverInit(domain, rf, tf, gamma, hashingFactory);this.vinit = vinit;this.numIterations = numIterations;this.valueFunction = new HashMap<HashableState, Double>();}@Overridepublic double value(State s) {Double d = this.valueFunction.get(hashingFactory.hashState(s));if(d == null){return vinit.value(s);}return d;}@Overridepublic List<QValue> getQs(State s) {List<GroundedAction> applicableActions = this.getAllGroundedActions(s);List<QValue> qs = new ArrayList<QValue>(applicableActions.size());for(GroundedAction ga : applicableActions){qs.add(this.getQ(s, ga));}return qs;}@Overridepublic QValue getQ(State s, AbstractGroundedAction a) {//type cast to the type we're usingGroundedAction ga = (GroundedAction)a;//what are the possible outcomes?List<TransitionProbability> tps = ga.getTransitions(s);//aggregate over each possible outcomedouble q = 0.;for(TransitionProbability tp : tps){//what is reward for this transition?double r = this.rf.reward(s, ga, tp.s);//what is the value for the next state?double vp = this.valueFunction.get(this.hashingFactory.hashState(tp.s));//add contribution weighted by transition probabiltiy and//discounting the next stateq += tp.p * (r + this.gamma * vp);}//create Q-value wrapperQValue qValue = new QValue(s, ga, q);return qValue;}protected double bellmanEquation(State s){if(this.tf.isTerminal(s)){return 0.;}List<QValue> qs = this.getQs(s);double maxQ = Double.NEGATIVE_INFINITY;for(QValue q : qs){maxQ = Math.max(maxQ, q.q);}return maxQ;}@Overridepublic GreedyQPolicy planFromState(State initialState) {HashableState hashedInitialState = this.hashingFactory.hashState(initialState);if(this.valueFunction.containsKey(hashedInitialState)){return new GreedyQPolicy(this); //already performed planning here!}//if the state is new, then find all reachable states from it firstthis.performReachabilityFrom(initialState);//now perform multiple iterations over the whole state spacefor(int i = 0; i < this.numIterations; i++){//iterate over each statefor(HashableState sh : this.valueFunction.keySet()){//update its value using the bellman equationthis.valueFunction.put(sh, this.bellmanEquation(sh.s));}}return new GreedyQPolicy(this);}@Overridepublic void resetSolver() {}public void performReachabilityFrom(State seedState){Set<HashableState> hashedStates = StateReachability.getReachableHashedStates(seedState, (SADomain) this.domain, this.hashingFactory);//initialize the value function for all statesfor(HashableState hs : hashedStates){if(!this.valueFunction.containsKey(hs)){this.valueFunction.put(hs, this.vinit.value(hs.s));}}}public static void main(String [] args){GridWorldDomain gwd = new GridWorldDomain(11, 11);gwd.setMapToFourRooms();//only go in intended directon 80% of the timegwd.setProbSucceedTransitionDynamics(0.8);Domain domain = gwd.generateDomain();//get initial state with agent in 0,0State s = GridWorldDomain.getOneAgentNoLocationState(domain);GridWorldDomain.setAgent(s, 0, 0);//all transitions return -1RewardFunction rf = new UniformCostRF();//terminate in top right cornerTerminalFunction tf = new GridWorldTerminalFunction(10, 10);//setup vi with 0.99 discount factor, a value//function initialization that initializes all states to value 0, and which will//run for 30 iterations over the state spaceVITutorial vi = new VITutorial(domain, rf, tf, 0.99, new SimpleHashableStateFactory(),new ValueFunctionInitialization.ConstantValueFunctionInitialization(0.0), 30);//run planning from our initial statePolicy p = vi.planFromState(s);//evaluate the policy with one roll out visualize the trajectoryEpisodeAnalysis ea = p.evaluateBehavior(s, rf, tf);Visualizer v = GridWorldVisualizer.getVisualizer(gwd.getMap());new EpisodeSequenceVisualizer(v, domain, Arrays.asList(ea));}} Full Q-Learning Code import burlap.behavior.policy.EpsilonGreedy;import burlap.behavior.policy.Policy;import burlap.behavior.singleagent.EpisodeAnalysis;import burlap.behavior.singleagent.MDPSolver;import burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizer;import burlap.behavior.singleagent.learning.LearningAgent;import burlap.behavior.valuefunction.QFunction;import burlap.behavior.valuefunction.QValue;import burlap.behavior.valuefunction.ValueFunctionInitialization;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.GridWorldTerminalFunction;import burlap.domain.singleagent.gridworld.GridWorldVisualizer;import burlap.oomdp.core.AbstractGroundedAction;import burlap.oomdp.core.Domain;import burlap.oomdp.core.TerminalFunction;import burlap.oomdp.core.states.State;import burlap.oomdp.singleagent.GroundedAction;import burlap.oomdp.singleagent.RewardFunction;import burlap.oomdp.singleagent.common.UniformCostRF;import burlap.oomdp.singleagent.environment.Environment;import burlap.oomdp.singleagent.environment.EnvironmentOutcome;import burlap.oomdp.singleagent.environment.SimulatedEnvironment;import burlap.oomdp.statehashing.HashableState;import burlap.oomdp.statehashing.HashableStateFactory;import burlap.oomdp.statehashing.SimpleHashableStateFactory;import burlap.oomdp.visualizer.Visualizer;import java.util.*;public class QLTutorial extends MDPSolver implements LearningAgent, QFunction {Map<HashableState, List<QValue>> qValues;ValueFunctionInitialization qinit;double learningRate;Policy learningPolicy;public QLTutorial(Domain domain, double gamma, HashableStateFactory hashingFactory, ValueFunctionInitialization qinit, double learningRate, double epsilon){this.solverInit(domain, null, null, gamma, hashingFactory);this.qinit = qinit;this.learningRate = learningRate;this.qValues = new HashMap<HashableState, List<QValue>>();this.learningPolicy = new EpsilonGreedy(this, epsilon);}@Overridepublic EpisodeAnalysis runLearningEpisode(Environment env) {return this.runLearningEpisode(env, -1);}@Overridepublic EpisodeAnalysis runLearningEpisode(Environment env, int maxSteps) {//initialize our episode analysis object with the initial state of the environmentEpisodeAnalysis ea = new EpisodeAnalysis(env.getCurrentObservation());//behave until a terminal state or max steps is reachedState curState = env.getCurrentObservation();int steps = 0;while(!env.isInTerminalState() && (steps < maxSteps || maxSteps == -1)){//select an actionGroundedAction a = (GroundedAction)this.learningPolicy.getAction(curState);//take the action and observe outcomeEnvironmentOutcome eo = a.executeIn(env);//record resultea.recordTransitionTo(a, eo.op, eo.r);//get the max Q value of the resulting state if it's not terminal, 0 otherwisedouble maxQ = eo.terminated ? 0. : this.value(eo.op);//update the old Q-valueQValue oldQ = this.getQ(curState, a);oldQ.q = oldQ.q + this.learningRate * (eo.r + this.gamma * maxQ - oldQ.q);//move on to next statecurState = eo.op;steps++;}return ea;}@Overridepublic void resetSolver() {this.qValues.clear();}@Overridepublic List<QValue> getQs(State s) {//first get hashed stateHashableState sh = this.hashingFactory.hashState(s);//check if we already have stored valuesList<QValue> qs = this.qValues.get(sh);//create and add initialized Q-values if we don't have them stored for this stateif(qs == null){List<GroundedAction> actions = this.getAllGroundedActions(s);qs = new ArrayList<QValue>(actions.size());//create a Q-value for each actionfor(GroundedAction ga : actions){//add q with initialized valueqs.add(new QValue(s, ga, this.qinit.qValue(s, ga)));}//store this for laterthis.qValues.put(sh, qs);}return qs;}@Overridepublic QValue getQ(State s, AbstractGroundedAction a) {//first get all Q-valuesList<QValue> qs = this.getQs(s);//translate action parameters to source state for Q-values if neededa = ((GroundedAction)a).translateParameters(s, qs.get(0).s);//iterate through stored Q-values to find a match for the input actionfor(QValue q : qs){if(q.a.equals(a)){return q;}}throw new RuntimeException(\"Could not find matching Q-value.\");}@Overridepublic double value(State s) {return QFunctionHelper.getOptimalValue(this, s);}public static void main(String[] args) {GridWorldDomain gwd = new GridWorldDomain(11, 11);gwd.setMapToFourRooms();gwd.setProbSucceedTransitionDynamics(0.8);Domain domain = gwd.generateDomain();//get initial state with agent in 0,0State s = GridWorldDomain.getOneAgentNoLocationState(domain);GridWorldDomain.setAgent(s, 0, 0);//all transitions return -1RewardFunction rf = new UniformCostRF();//terminate in top right cornerTerminalFunction tf = new GridWorldTerminalFunction(10, 10);//create environmentSimulatedEnvironment env = new SimulatedEnvironment(domain,rf, tf, s);//create Q-learningQLTutorial agent = new QLTutorial(domain, 0.99, new SimpleHashableStateFactory(),new ValueFunctionInitialization.ConstantValueFunctionInitialization(), 0.1, 0.1);//run Q-learning and store results in a listList<EpisodeAnalysis> episodes = new ArrayList<EpisodeAnalysis>(1000);for(int i = 0; i < 1000; i++){episodes.add(agent.runLearningEpisode(env));env.resetEnvironment();}Visualizer v = GridWorldVisualizer.getVisualizer(gwd.getMap());new EpisodeSequenceVisualizer(v, domain, episodes);}} End.", "http://burlap.cs.brown.edu/tutorials_v2/hgw/p1.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Hello Grid World! Tutorials > Hello Grid World! > Part 1 Tutorial Contents Introduction Compiling from Source Hello Grid World Project Conclusion You are viewing the tutorial for BURLAP 2 with Maven. If you'd like the BURLAP 2 ant compiling and manual execution instructions, go here . If you'd like the BURLAP version 1 tutorial, go here . Introduction In this tutorial we will walk you through getting started with BURLAP. We will assume that you have Maven installed for this process, since it will make management of dependencies very straightforward. If you do not already have Maven installed, you can probably get it from your favorite package manager. For example, on Debian systems, sudo apt-get install maven Or on Mac OS with homebrew: brew install maven Alternatively, you can manually install it from https://maven.apache.org/download.cgi . Be sure to follow their installtion instructions. To verify that you have maven installed try the following from the command line mvn -v We also highly recommend that you use an IDE for your work, which will make working with the library substantially easier. If you do not have an IDE we recommend either IntelliJ or Eclipse . Both will have tools for working with Maven projects. That said, for this tutorial we will give instructions using just the command line and your favorite text editor. You can probably follow along in an IDE if you prefer. In this tutorial you will have two options. You can either build and install BURLAP from its source, or you can simply use the released version of BURLAP from Maven Central. The latter will require the least work, but if you'd like to be able to modify BURLAP at all, it may be worth checkout out the code and manually compiling it. If you prefer to simply use the Maven Central copy, skip the next section. We will make use of the command line to test things out and compile everything. On the Mac and Linux you can just use the terminal. If you are windows, you can use either the command prompt something like Cygwin . Compiling from Source To compile the code from source, you will probably want to have git installed, or you can manually download the source from github. If you have git installed, navigate from your command line to a directory where you would like to place the code. Then type the following: git clone https://github.com/jmacglashan/burlap.git If you do not have git installed on your computer, then you can manually download the files by navigating to the website https://github.com/jmacglashan/burlap and clicking on \"download zip\" to save it and unarchive it at a desired location. Whether you used git to clone the source, or manually downloaded it, navigate into the directory with your command line. The directory should look something like the following: LICENSEREADME.mdbuild.xmlburlap-repolibpom.xmlsrctesting Now we can compile using Maven, which you should have installed on the previous step. You can use the standard Maven methods for compilation. That is, to simply compile the code, use mvn compile To create a jar file and Java doc in the target directory (as well as jar file that includes all dependencies) use mvn package And to install BURLAP to your local Maven repository, use mvn install That's it! Hello Grid World Project Whether you compiled and installed BURLAP from source in the prior step or not, this next section is the same because BURLAP is available on Maven Central, which means Maven will automatically download it and install it if you did not compile it from source. To begin our example project, create a directory somewhere on your file system where you will store the project code and navigate into it on your command line. If you've used Maven before, you may want to create your project by generating an archetype. Feel free to do so if you, like. However, we will manually set up the project from the command line and text editors here. First create a file named pom.xml. With your favorite text editor, insert the following 4.0.0 com.mycompany.app myProj 1 edu.brown.cs.burlap burlap 2.1.0 org.codehaus.mojo exec-maven-plugin 1.2.1 java You should set the group id at the top to anything that seems relevant for you, and you can also rename the artifact id to something else if you prefer. Note the <dependencies> section with the BURLAP dependency, which tells Maven that your project depends on BURALP. As of writing this tutorial, the latest version of BURLAP is 2.1.0. However, you may want to change this value to whatever the latest is, or to a version you prefer (especially if you've installed your own custom version with its own version number). You can see the list of all release versions of BURLAP from here . The plugin we added will also allow us to use Maven to easily run code that we write. Now create the following directory tree: src/main/java/myProj. Inside the nested myProj folder, we will create two text files, HelloGridWorld.java and PlotTest.java. HelloGridWorld.java should have the following contents. package myProj;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.GridWorldVisualizer;import burlap.oomdp.core.Domain;import burlap.oomdp.core.states.State;import burlap.oomdp.singleagent.explorer.VisualExplorer;import burlap.oomdp.visualizer.Visualizer;public class HelloGridWorld{public static void main(String [] args){GridWorldDomain gw = new GridWorldDomain(11,11); //11x11 grid worldgw.setMapToFourRooms(); //four rooms layoutgw.setProbSucceedTransitionDynamics(0.8); //stochastic transitions with 0.8 success rateDomain domain = gw.generateDomain(); //generate the grid world domain//setup initial stateState s = GridWorldDomain.getOneAgentOneLocationState(domain);GridWorldDomain.setAgent(s, 0, 0);GridWorldDomain.setLocation(s, 0, 10, 10);//create visualizer and explorerVisualizer v = GridWorldVisualizer.getVisualizer(gw.getMap());VisualExplorer exp = new VisualExplorer(domain, v, s);//set control keys to use w-s-a-dexp.addKeyAction(\"w\", GridWorldDomain.ACTIONNORTH);exp.addKeyAction(\"s\", GridWorldDomain.ACTIONSOUTH);exp.addKeyAction(\"a\", GridWorldDomain.ACTIONWEST);exp.addKeyAction(\"d\", GridWorldDomain.ACTIONEAST);exp.initGUI();}} And PlotTest.java should have the contents package myProj;import burlap.behavior.singleagent.auxiliary.performance.LearningAlgorithmExperimenter;import burlap.behavior.singleagent.auxiliary.performance.PerformanceMetric;import burlap.behavior.singleagent.auxiliary.performance.TrialMode;import burlap.behavior.singleagent.learning.LearningAgent;import burlap.behavior.singleagent.learning.LearningAgentFactory;import burlap.behavior.singleagent.learning.tdmethods.QLearning;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.oomdp.auxiliary.common.ConstantStateGenerator;import burlap.oomdp.auxiliary.common.SinglePFTF;import burlap.oomdp.auxiliary.stateconditiontest.TFGoalCondition;import burlap.oomdp.core.Domain;import burlap.oomdp.core.TerminalFunction;import burlap.oomdp.core.states.State;import burlap.oomdp.singleagent.RewardFunction;import burlap.oomdp.singleagent.common.GoalBasedRF;import burlap.oomdp.singleagent.environment.SimulatedEnvironment;import burlap.oomdp.statehashing.SimpleHashableStateFactory;public class PlotTest {public static void main(String [] args){GridWorldDomain gw = new GridWorldDomain(11,11); //11x11 grid worldgw.setMapToFourRooms(); //four rooms layoutgw.setProbSucceedTransitionDynamics(0.8); //stochastic transitions with 0.8 success ratefinal Domain domain = gw.generateDomain(); //generate the grid world domain//setup initial stateState s = GridWorldDomain.getOneAgentOneLocationState(domain);GridWorldDomain.setAgent(s, 0, 0);GridWorldDomain.setLocation(s, 0, 10, 10);//ends when the agent reaches a locationfinal TerminalFunction tf = new SinglePFTF(domain.getPropFunction(GridWorldDomain.PFATLOCATION));//reward function definitionfinal RewardFunction rf = new GoalBasedRF(new TFGoalCondition(tf), 5., -0.1);//initial state generatorfinal ConstantStateGenerator sg = new ConstantStateGenerator(s);//set up the state hashing system for looking up statesfinal SimpleHashableStateFactory hashingFactory = new SimpleHashableStateFactory();/** * Create factory for Q-learning agent */LearningAgentFactory qLearningFactory = new LearningAgentFactory() {@Overridepublic String getAgentName() {return \"Q-learning\";}@Overridepublic LearningAgent generateAgent() {return new QLearning(domain, 0.99, hashingFactory, 0.3, 0.1);}};//define learning environmentSimulatedEnvironment env = new SimulatedEnvironment(domain, rf, tf, sg);//define experimentLearningAlgorithmExperimenter exp = new LearningAlgorithmExperimenter(env,10, 100, qLearningFactory);exp.setUpPlottingConfiguration(500, 250, 2, 1000, TrialMode.MOSTRECENTANDAVERAGE,PerformanceMetric.CUMULATIVESTEPSPEREPISODE, PerformanceMetric.AVERAGEEPISODEREWARD);//start experimentexp.startExperiment();}} Your directory structure should now look like the following. pom.xmlsrc/main/java/myProj/HelloGridWorld.javaPlotTest.java We're now ready to compile and run! In the command line, make sure you're in the same directory as your pom.xml file. Then, to compile, run mvn compile Maven should download BURLAP (if you did not manually compile it) and other information, and then compile your two sources. To run the HelloGridWorld code, use the following command mvn exec:java -Dexec.mainClass=\"myProj.HelloGridWorld\" Running this code should launch a GUI with a grid world, similar to the image below. If you click on the image and then use the w-a-s-d keys, you'll be able to control the agent's movements. Note, however, that we made this a stochastic grid world in the code, which means some of the time you may find the agent going in a different direction than the one you intended! We can similarly run our PlotTest code with mvn exec:java -Dexec.mainClass=\"myProj.PlotTest\" Which will run Q-learning on the same grid world 10 times, plotting the most recent trial and average performance. It should look something like the below image. Conclusion In this tutorial we walked you through compiling BURLAP and setting up your own Maven project that uses BURLAP. We used the command line to set everything up, but we strongly encourage you to use a full IDE for most projects, such as IntelliJ or Eclipse . You can initialize your projects the way we did here and then import the code into the IDE, or you can have these IDE's create a new Maven project themselves. Now that you've completed this tutorial, you are encouraged to check out the other BURLAP tutorials that are available. Happy coding! End.", "http://burlap.cs.brown.edu/tutorials_v2/hgw/p1_ant.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Hello Grid World! Tutorials > Hello Grid World! > Part 1 Tutorial Contents Introduction Acquiring BURLAP Dependencies Running the JAR Hello Grid World Code Testing Plotting Tools Notes on the Java Heap Size Conclusions You are viewing the tutorial for BURLAP 2 with ant compilation and manual execution. If you'd like the BURLAP 2 Maven instructions, go here . If you'd like the BURLAP version 1 tutorial, go here . Introduction In this tutorial we will walk you through downloading BURLAP and making sure you can run it. We willwalk through the instructions to both download the JAR from the precompiled source as wellas how to get the source code and compile it yourself. If you only want to do it one way, feel free to only look at that section. Either way, it should be very straightforward! After thecode has been downloaded, we'll show you a simple way to make sure it's working and then showyou how to easily create code that links to it. For more instructions on how write meaningfulcode with BURLAP and what it does, you should see the other tutorials. We will make use of the command line to test things out and compile everything. On the Mac and Linux you can just use the terminal. If you are windows, you can use either the command prompt something like Cygwin . Acquiring BURLAP There are two ways to acquire BURLAP. You can either download the pre-compiled JAR file (either with or without dependencies included)or compile it from the source code. In general, the source code will have the latest versionand the pre-compiled JAR may be a bit older, but should be stable. Downloading the Pre-compiled JAR For the prec-compiled jar, you can either get one with the dependencies includein the jar, or without them included. You can get either from these locations: the pre-compiled jar with dependencies included; the pre-compiled jar with out dependencies. Use the jar without the dependencies if you are having library conflictsand need to manage them yourself. If you use the jar without dependencies,we will walk through how to include them manually in the below dependencies section . After downloading the BURLAP jar file, you can either install it into a system level path that java will always search or your can place it in a local directory. In this tutorial we will just use it locally and point java to it. Create a directory in which you will run your tests. In this tutorial,we will name it \"testcode,\" but you can name it anything you want. Within that directory, create a new subdirectory called \"lib\" and place the burlap.jar file that you downloaded inside it. The directory structure should look like the following: testcodelibburlap.jar Or \"burlap_no_dep.jar\" instead of \"burlap.jar\" if you downloaded the version without dependencies. Compiling From the source The easiest way to get the source is with git . If you do not have git installed, install it now. You can download git from here . To compile the code,you will also need ant installed, which you can get from here if you do not already have it. Create a directory where you will place the git distribution. You might have a git directory in your home directory already created for this, which you can use. From the command line, change directories there now. Now enter the following command: git clone https://github.com/jmacglashan/burlap.git You should have found that this created the directory named \"burlap\". Change into that directory now and you should find the following files and subdirectories: libsrcLICENSEREADME.mdbuild.xml Now type ant dist And you should find new subdirectories appear; in particular, the \"dist\" directory whichwill contain the BURLAP JAR file. If there were compilation errors (warnings should not be a concern) it's possible that you will need to re-download the dependencies. For convenience,BURLAP's git repository includes the dependencies that it needs, but it's possible you may haveto install them yourself (see the Dependencies section and place all the JARs on which BURLAP depends in the lib directory and try ant again.) With the burlap.jar file created we'll now try working with it. You can either install it into a system level path that java will always search or your can place it in a local directory. In this tutorial we will just use it locally and point java to it. Create a directory in which you will run your tests. In this tutorial,we will name it \"testcode,\" but you can name it anything you want. Within that directory, create a new subdirectory called \"lib\" and place the burlap.jar file that you downloaded inside it. The directory structure should look like the following: testcodelibburlap.jar Dependencies Most of BURLAP can be run without any of its dependencies,but some of the algorithms and advanced tools will requireother libraries to be present. For example, the RLGluedependency allows BURLAP to communicate with other RLsoftware. If you are using the pre-compiled BURLAP jar that has dependencies included,you can skip this step. If you are using a compiled version of BURLAP or the jar without dependencesand you want to use all of BURLAP's features you should get the relevant JAR files and put them in the lib directory of the \"testcode\" directory thatwe created. If you compiled BURLAP from source, you can just copy the files in the BURLAP source lib directory into our testcode lib directory. Otherwise, you can download the dependencies (and their dependencies) from the below locations RLGlue Java Codec - You will need this if you plan on interfacing BURLAP with RLGLue . Apache Math Commons - For performance plotting tools. JFree Chart - For Performance Plotting tools. Snake YAML - For reading and writing states into the YAML format. Jackson - For reading and writing states into the JSON format. JOptimizer - For Max Margin Apprenticeship Learning SCPSolver - For Minmax, Coco-Q, and Correlated-Q algorithms. (Our choice of underlying LP solver that it uses is lpsolve.) Weka - For providing a range of regression algorithms for Fitted Value Iteration. JOptSimple - For handling command line arguments in the BURLAP shell. After putting all the relevant dependencies in the lib folder,your directory structure should look something like the following. testcodelibburlap.jarJavaRLGlueCodec.jarLPSOLVESolverPack.jarSCPSolver.jarcolt-1.2.0.jarcommons-beanutils-1.6.jarcommons-collections-2.1.jarcommons-lang3-3.1.jarcommons-logging-1.1.1.jarcommons-math3-3.2.jarcsparsej-1.1.1.jarejml-0.25.jarguava-18.0.jarhamcrest-core-1.3.jarjackson-annotations-2.2.3.jarjackson-core-2.2.3.jarjackson-databind-2.2.3.jarjcommon-1.0.21.jarjfreechart-1.0.17.jarjopt-simple-4.9.jarjoptimizer-3.2.0.jarjoptimizer-3.3.0.jarjunit-4.11.jarlog4j-1.2.14.jarservlet.jarsnakeyaml-1.13.jartrove.jarweka-src.jarweka.jarxml-apis-1.0.b2.jar Running the JAR The simplest way to test BURLAP is to run the default main method in the GridWorld domain generator, which will launch a simple interactive visualization of the GridWorld. From the command line, change directory into your \"testcode\" directory if you're not already there. Then enter: java -cp lib/*:. burlap.domain.singleagent.gridworld.GridWorldDomain Note the the \":.\" after \"lib/*\" which adds the current directory the class path. Some users have reported errors unless that is included, even though we haven't actually written any of our own code yet! If you're in the Windows command prompt (and not cygwin), you may need to change the colon character to a semicolon. If a GUI of a simple GridWorld appears, as shown below, then everything is working! There are two ways to control the agent in the GUI. One way is to use keystrokes, whichyou can perform by clicking on the visualization and then pressing either the w, a, s, or d keys (you only need to click on the visualization once to get it to start acceptingkey strokes). Alternatively, you can use the \"execute\" text field and button. In the executetext field you can enter the name of the action you want the agent to perform and then pressthe \"execute\" button to have it performed. In GridWorld, the actions you can have the agentperform are named \"north,\" \"south,\" \"east,\" and \"west.\" Hello Grid World Code We're now going to write a simple BURLAP hello world program for you to test. We're not going to spend any time really explaining what the code does, it's just a way to make sure that you can link to BURLAP with your own code. For a much more thorough explanation of the code, see the BURLAP java doc and other tutorials available. In your testcode directory, create a new file named \"HelloGridWorld.java\". Inside the file, place the following code. import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.domain.singleagent.gridworld.GridWorldVisualizer;import burlap.oomdp.core.Domain;import burlap.oomdp.core.states.State;import burlap.oomdp.singleagent.explorer.VisualExplorer;import burlap.oomdp.visualizer.Visualizer;public class HelloGridWorld{public static void main(String [] args){GridWorldDomain gw = new GridWorldDomain(11,11); //11x11 grid worldgw.setMapToFourRooms(); //four rooms layoutgw.setProbSucceedTransitionDynamics(0.8); //stochastic transitions with 0.8 success rateDomain domain = gw.generateDomain(); //generate the grid world domain//setup initial stateState s = GridWorldDomain.getOneAgentOneLocationState(domain);GridWorldDomain.setAgent(s, 0, 0);GridWorldDomain.setLocation(s, 0, 10, 10);//create visualizer and explorerVisualizer v = GridWorldVisualizer.getVisualizer(gw.getMap());VisualExplorer exp = new VisualExplorer(domain, v, s);//set control keys to use w-s-a-dexp.addKeyAction(\"w\", GridWorldDomain.ACTIONNORTH);exp.addKeyAction(\"s\", GridWorldDomain.ACTIONSOUTH);exp.addKeyAction(\"a\", GridWorldDomain.ACTIONWEST);exp.addKeyAction(\"d\", GridWorldDomain.ACTIONEAST);exp.initGUI();}} This code will effectively recreate the same GridWorld GUI that we launched straight from the BURLAP jar, with the exception that we made the GridWorld have stochastic transitions. This means that as you control the agent with the w-s-a-d keys, you may find that it sometimes goes in the wrong direction! After saving the file, we will compile it with the command javac -cp lib/*:. HelloGridWorld.java Now lets run it! java -cp lib/*:. HelloGridWorld If you're in the Windows command prompt (and not cygwin), you may need to change the colon character to a semicolon and if you're using cygwin, then you need to specify it as a cygwin path: java -cp `cygpath -wp lib/*:.` HelloGridWorld If everything worked, then you should have seen the same GUI as the one you saw when we ran codedirectly from the BURLAP jar. Testing Plotting Tools In these section we'll provide some code to make sure that your dependencies for the BURLAP plotting tools are working correctly. If you don't care about this, naturally you can skip this section. Create a new file named \"PlotTest.java\" and put the following code in it. import burlap.behavior.singleagent.auxiliary.performance.LearningAlgorithmExperimenter;import burlap.behavior.singleagent.auxiliary.performance.PerformanceMetric;import burlap.behavior.singleagent.auxiliary.performance.TrialMode;import burlap.behavior.singleagent.learning.LearningAgent;import burlap.behavior.singleagent.learning.LearningAgentFactory;import burlap.behavior.singleagent.learning.tdmethods.QLearning;import burlap.domain.singleagent.gridworld.GridWorldDomain;import burlap.oomdp.auxiliary.common.ConstantStateGenerator;import burlap.oomdp.auxiliary.common.SinglePFTF;import burlap.oomdp.auxiliary.stateconditiontest.TFGoalCondition;import burlap.oomdp.core.Domain;import burlap.oomdp.core.TerminalFunction;import burlap.oomdp.core.states.State;import burlap.oomdp.singleagent.RewardFunction;import burlap.oomdp.singleagent.common.GoalBasedRF;import burlap.oomdp.singleagent.environment.SimulatedEnvironment;import burlap.oomdp.statehashing.SimpleHashableStateFactory;public class PlotTest {public static void main(String [] args){GridWorldDomain gw = new GridWorldDomain(11,11); //11x11 grid worldgw.setMapToFourRooms(); //four rooms layoutgw.setProbSucceedTransitionDynamics(0.8); //stochastic transitions with 0.8 success ratefinal Domain domain = gw.generateDomain(); //generate the grid world domain//setup initial stateState s = GridWorldDomain.getOneAgentOneLocationState(domain);GridWorldDomain.setAgent(s, 0, 0);GridWorldDomain.setLocation(s, 0, 10, 10);//ends when the agent reaches a locationfinal TerminalFunction tf = new SinglePFTF(domain.getPropFunction(GridWorldDomain.PFATLOCATION));//reward function definitionfinal RewardFunction rf = new GoalBasedRF(new TFGoalCondition(tf), 5., -0.1);//initial state generatorfinal ConstantStateGenerator sg = new ConstantStateGenerator(s);//set up the state hashing system for looking up statesfinal SimpleHashableStateFactory hashingFactory = new SimpleHashableStateFactory();/** * Create factory for Q-learning agent */LearningAgentFactory qLearningFactory = new LearningAgentFactory() {@Overridepublic String getAgentName() {return \"Q-learning\";}@Overridepublic LearningAgent generateAgent() {return new QLearning(domain, 0.99, hashingFactory, 0.3, 0.1);}};//define learning environmentSimulatedEnvironment env = new SimulatedEnvironment(domain, rf, tf, sg);//define experimentLearningAlgorithmExperimenter exp = new LearningAlgorithmExperimenter(env,10, 100, qLearningFactory);exp.setUpPlottingConfiguration(500, 250, 2, 1000, TrialMode.MOSTRECENTANDAVERAGE,PerformanceMetric.CUMULATIVESTEPSPEREPISODE, PerformanceMetric.AVERAGEEPISODEREWARD);//start experimentexp.startExperiment();}} Then compile and run as before, except this time we'll specify the PlotTest class that we created: javac -cp lib/*:. PlotTest.javajava -cp lib/*:. PlotTest If everything worked, then you should have seen a bunch of plots showing the performance of a Q-learning algorithm that were updated in (semi) real time, similar to what is shown below. If you did not see something like the above, you may need to make sure that you have all the dependencies you need in the lib folder (see the Dependencies section for more details). Notes on the Java Heap Size Planning and learning algorithms often require a lot of memory for large problems, more than what java will typically use by default. Therefore, you may want to make sure that you increase java's heap size whenever you run BURLAP. You can do this with the -Xmx argument. For instance, to give java 2GB of memory to use, change the previous run commands to the following: java -cp lib/*:. -Xmx2048M HelloGridWorld Conclusions In this tutorial we walked you through acquiring BURLAP and provided some simple code to make sure you can compile your own code with it. We strongly encourage you to use a full IDE, however, such as IntelliJ or Eclipse . Just make sure that you add the jar files that we put in the lib folder to your Eclipse project's build path. Since all of the BURLAP java doc comes with the jar,Eclipse will autocomplete methods and explain the parameters, which should be very helpful. Now that you've completed this tutorial, you are encouraged to check out the other BURLAP tutorials that are available. Happy coding! End.", "http://burlap.cs.brown.edu/tutorials_v2/index.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorials You are viewing the tutorials for BURLAP 2; if you'd like the BURLAP version 1 tutorials, go here . This page provides a list of all available BURLAP tutorials. There are both short video tutorials and more explanatory and detailed text tutorials. You can find code for all of the tutorials and more in our examples repository: https://github.com/jmacglashan/burlap_examples/ Video Tutorials Text Tutorials Hello Grid World! - a tutorial on acquiring and linking with BURLAP Building a Domain Using Basic Planning and Learning Algorithms Creating a Planning and Learning Algorithm Solving Continuous Domains", "http://burlap.cs.brown.edu/tutorials_v2/scd/p1.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Solving Continuous Domains Tutorials > Solving Continuous Domains > Part 1 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA(\u03bb) Conclusions Final Code Next Part You are viewing the tutorial for BURLAP 2; if you'd like the BURLAP version 1 tutorial, go here . Introduction In the Basic Planning and Learning tutorial we walked through how to use a number of different planning and learning algorithms. However, all the algorithms we covered were exclusively for finite state planning/learning problems and it is not uncommon in real world problems to have to deal with an infinite or continuous state space. Continuous state problems are challenging because there is an infinite number of possible states, which means you're unlikely to ever visit the same state twice. Since many of the previous algorithms rely on being ably to exhaustively enumerate the states or revisit them multiple times to estimate a value function for each state, having an infinite number of states presents a problem that requires a different set of algorithms. For example, methods that generalize the value function to unseen \"near by\" states is one approach to handling continuous state space problems. In this tutorial, we will explain how to solve continuous domains, using the example domains Mountain Car , Inverted Pendulum , and Lunar Lander , with three different algorithms implemented in BURLAP that are capable of handling continuous domains: Least-Squares Policy Iteration , Sparse Sampling , and Gradient Descent Sarsa Lambda . As usual, if you would like to see all the finished code that we will write in this tutorial, you can jump to the Final Code section at the end. Solving Mountain Car with Least-Squares Policy Iteration The Mountain Car domain is a classic continuous state RL domain in which an under-powered carmust drive up a steep mountain. However, because the mountain is so steep, the car cannot justaccelerate straight up to the top. Since car is in valley, it can, however, make it to its destination by first moving backwards up the opposite slope, and then accelerate down to gain enoughmomentum to get up the intended slope. An illustration of the Mountain Car problem, courtesy of Wikipedia . To solve this problem, we will use Least-Squares Policy Iteration (LSPI). LSPI requires a collection of state-action-reward-state (SARS) transition tuples that are sampled from the domain. In some domains, like Mountain car, this data can be collected rather straight forwardly with random sampling of actions in the world. In other domains, the set of SARS data (and therefore how it is collected) is critical to getting good results out of LSPI, so it is important to keep that in mind. LSPI starts by initializing with a random policy and then uses the collected SARS samples to approximate the Q-value function of that policy for the continuous state space. Afterwards, the policy is updated by choosing actions that have the highest Q-values (this change in policy is known as policy improvement ). This process repeats until the approximate Q-value function (and consequentially the policy) stops changing much. LSPI approximates the Q-value function for its current policy by fitting a linear function of state basis features to the SARS data it collected, similar to a typical regression problem, which is what enables the value function to generalize to unseen states. Choosing a good set of state basis functions that can be used to accurately represent the value function is also critical to getting good performance out of LSPI. In this tutorial, we will show you how to set up Fourier basis functions and radial basis functions , which tend to be good starting places. Lets start coding now. We'll begin by making a class shell, called ContinuousDomainTutorial. In it, we will create a different static method that demonstrates solving each domain and algorithm in this tutorial, so we'll start with our method for solving Mountain Car with LSPI using Fourier basis functions (MCLSPIFB). As usual, we've preemptively included all imports that you'll use in the rest of this tutorial. import burlap.behavior.policy.GreedyQPolicy;import burlap.behavior.policy.Policy;import burlap.behavior.singleagent.EpisodeAnalysis;import burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizer;import burlap.behavior.singleagent.auxiliary.StateGridder;import burlap.behavior.singleagent.learning.lspi.LSPI;import burlap.behavior.singleagent.learning.lspi.SARSCollector;import burlap.behavior.singleagent.learning.lspi.SARSData;import burlap.behavior.singleagent.learning.tdmethods.vfa.GradientDescentSarsaLam;import burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSampling;import burlap.behavior.singleagent.vfa.DifferentiableStateActionValue;import burlap.behavior.singleagent.vfa.cmac.CMACFeatureDatabase;import burlap.behavior.singleagent.vfa.common.ConcatenatedObjectFeatureVectorGenerator;import burlap.behavior.singleagent.vfa.fourier.FourierBasis;import burlap.behavior.singleagent.vfa.rbf.DistanceMetric;import burlap.behavior.singleagent.vfa.rbf.RBFFeatureDatabase;import burlap.behavior.singleagent.vfa.rbf.functions.GaussianRBF;import burlap.behavior.singleagent.vfa.rbf.metrics.EuclideanDistance;import burlap.domain.singleagent.cartpole.InvertedPendulum;import burlap.domain.singleagent.cartpole.InvertedPendulumVisualizer;import burlap.domain.singleagent.lunarlander.LLVisualizer;import burlap.domain.singleagent.lunarlander.LunarLanderDomain;import burlap.domain.singleagent.lunarlander.LunarLanderRF;import burlap.domain.singleagent.lunarlander.LunarLanderTF;import burlap.domain.singleagent.mountaincar.MCRandomStateGenerator;import burlap.domain.singleagent.mountaincar.MountainCar;import burlap.domain.singleagent.mountaincar.MountainCarVisualizer;import burlap.oomdp.auxiliary.StateGenerator;import burlap.oomdp.core.Domain;import burlap.oomdp.core.TerminalFunction;import burlap.oomdp.core.states.State;import burlap.oomdp.singleagent.RewardFunction;import burlap.oomdp.singleagent.common.GoalBasedRF;import burlap.oomdp.singleagent.common.VisualActionObserver;import burlap.oomdp.singleagent.environment.EnvironmentServer;import burlap.oomdp.singleagent.environment.SimulatedEnvironment;import burlap.oomdp.statehashing.SimpleHashableStateFactory;import burlap.oomdp.visualizer.Visualizer;import java.util.ArrayList;import java.util.Arrays;import java.util.List;public class ContinuousDomainTutorial {public static void main(String [] args){MCLSPIFB();}public static void MCLSPIFB(){//we'll fill this in in a moment...}} Next we'll create an instance of the Mountain car domain and the typical reward function and terminal function that defines the task in our MCLSPIFB method. MountainCar mcGen = new MountainCar();Domain domain = mcGen.generateDomain();TerminalFunction tf = new MountainCar.ClassicMCTF();RewardFunction rf = new GoalBasedRF(tf, 100); Our MountainCar instance provides us a means to get a TerminalFunction that sets states in which the car is on the top of the slope on the right-side as terminal states. We then define a Goal-based reward function that returns a reward of 100 when the agent reaches the terminal state and 0 everywhere else (0 is the default reward for a GoalBasedRF , but that value can be changed with a different constructor). Other Mountain Car Parameters We could have also changed parameters of the Mountain car domain, such as the strength of gravity, which is found in the physParams MountainCar data member, but without any modifications, it will automatically use the default parameterizations. The next thing we will want to do is collect SARS data from the Mountain Car domain for LSPI to use for fitting its linear function approximator. For Mountain car, it is sufficient to randomly draw a state from the Mountain Car state space, sample a trajectory from it by selecting actions uniformly randomly, and then repeat the process over again from another random state. Lets collect data in this way until we have 5000 SARS tuple instances for our dataset. To accomplish this data collection, we can make use of a random StateGenerator to select random initial states, and perform random trajectory roll outs from them using a UniformRandomSARSCollector . Lets add code for that now. StateGenerator rStateGen = new MCRandomStateGenerator(domain);SARSCollector collector = new SARSCollector.UniformRandomSARSCollector(domain);SARSData dataset = collector.collectNInstances(rStateGen, rf, 5000, 20, tf, null); The MCRandomStateGenerator class provides a means to generate Mountain Car states with random positions and velocities. The collectNInstances methods will collect our SARS data for us. Specifically, we've told it to perform rollouts from states generated from our Mountain Car state generator for no more than 20 steps at a time or until we hit a terminal state. This process of generating a random state, rolling out a random trajectory for it, and collecting all the observed SARS tuples repeats until we have 5000 SARS instances. The null parameter at the end of the method call means we want it to create a new SARSData instance and fill it up with the results (and return it) rather than adding to an existing SARSData instance. LSPI as a LearningAgent In this case we're opting to collect all the data LSPI will use ahead of time. Alternatively, LSPI can be used like a standard learning algorithm (it does implement the LearningAgent interface) in which it starts with no data, acts in the world from whatever the world's current state is and reruns LSPI as it experiences more transitions (thereby improving the policy that it follows). However, this approach to acquiring SARS data is often not as efficient and there may be better means to acquire data when the agent is forced to experience the world as it comes rather than being able to manually sample the state space as we have in this tutorial. Therefore, if you are facing a problem in which you cannot manually control how states are sampled ahead of time, you may want to consider subclassing and overriding LSPI's runLearningEpisode method to use an approach that is a better fit for your domain. To learn more about how LSPI's default runLearningEpisode method is used, see the class's documentation . The next thing we will want to define is the state basis features LSPI will use for its linear estimator of the value function. As noted previously, we will use Fourier basis functions. Fourier basis functions are very easy to implement without having to set many parameters, which makes it a good first approach to try. Each Fourier basis function takes as input a state variable vector, where each element is a normalized scalar value. Each basis function corresponds to a state feature that LSPI will use for its linear function. The BURLAP FourierBasis class is an implementation of the FeatureDatabase interface and will automatically make multiple Fourier basis functions based on the order you choose. The larger the order, the more basis functions (which grow exponentially with the dimension of input state feature vector) and the more fine grained the representation becomes, allowing for a more precise linear value function approximation. Recall that BURLAP states are not defined with state variable vectors, but with sets of objects (adhering to the OO-MDP paradigm); however, we can convert an OO-MDP state into a vector trivially since OO-MDPs tend to provide more information than a standard variable vector definition does. The simplest way to convert an OO-MDP state into a variable vector is to simply concatenate the attributes values of each object in the state into a single large vector. To do so, we can make use of the ConcatenatedObjectFeatureVectorGenerator , which asks for which object classes to concatenate (and their concatenation order) and whether to normalize the values or not (is required by Fourier basis funcitons). Custom Vector Conversions If you need to define the vafriable vector conversion differently (perhaps, for instance, you want to use relative variables, or ignore certain attributes of the objects), you can always make your own vector conversion definition by implementing a StateToFeatureVectorGenerator , which takes as input a State object and returns a double array. In the Mountain Car domain, there is only one object class\u2014the agent\u2014which defines the car's position and velocity, so we only need to tell the ConcatenatedObjectFeatureVectorGenerator to use the \"agent\" class values and to normalize its attribute values. With a state vector conversion method in hand, lets create a set of 4th order Fourier basis functions to use as our state features for LSPI. ConcatenatedObjectFeatureVectorGenerator featureVectorGenerator = new ConcatenatedObjectFeatureVectorGenerator(true, MountainCar.CLASSAGENT);FourierBasis fb = new FourierBasis(featureVectorGenerator, 4); Note that the \"true\" parameter in the ConcatenatedObjectFeatureVectorGenerator constructor tells it that all dimensions should be normalized in the returned vector, which is what Fourier basis functions expect. Now lets instantiate LSPI on our Mountain Car domain and task with our Fourier basis functions; tell it to use a 0.99 discount factor; set its SARS dataset to the datasetwe collected; and run LSPI until the weight values of its fitted linear function change no more than 10^-6 between iterations or until 30 iterationshave passed. LSPI lspi = new LSPI(domain, 0.99, fb, dataset);Policy p = lspi.runPolicyIteration(30, 1e-6); After LSPI has run until convergence, we will want to analyze the policy is produced. To analyze the resulting policy, we could roll it out and load an EpisodeSequenceVisualizer, as we have in prior tutorials. But for fun, lets watch it in real time. To visualize the animated results, we can simply grab the existing visualizer from the domain ( MountainCarVisualizer ), create a SimulatedEnvironment in which to evaluate the policy, and add a VisualActionObserver to the to the environment. Note that we can add an EnvironmentObserver to a SimulatedEnvironment, because it implements the EnvironmentServerInterface (otherwise we could use an EnvironmentServer wrapper for Environment instances that do not implement the observer interface). Specifically, we'll let it run for five policy rollouts. Visualizer v = MountainCarVisualizer.getVisualizer(mcGen);VisualActionObserver vob = new VisualActionObserver(domain, v);vob.initGUI();SimulatedEnvironment env = new SimulatedEnvironment(domain, rf, tf,MountainCar.getCleanState(domain, mcGen.physParams));env.addObservers(vob);for(int i = 0; i < 5; i++){p.evaluateBehavior(env);env.resetEnvironment();}System.out.println(\"Finished\"); If you now run the main method, you see at the start a bunch of print outs to the terminal specifying the maximum change in weight values after each policy iteration. When the change is small enough, LSPI will end and you'll get a window animating the the mountain car task using the results of LSPI. That is, you should see something like the below image. A screen cap from the animation of the Mountain car task Although the settings we used are pretty robust to failure, it is possible (even if unlikely) that the car won't make it to the right side, which indicates that LSPI failed to find a good policy from the valley of the hill. LSPI can fail if your dataset collection happened to be unluckily bad. However, if you rerun the code (resulting in a a new random data collection), you should find that it works. Radial Basis Functions Before we leave Mountain Car and LSPI for the next example, lets consider running LSPI on Mountain Car with a different kind of state basis features; specifically, lets consider using radial basis functions. A radial basis function is defined with a \"center\" state, a distance metric, and a bandwidth parameter. Given an input query state, the basis function returns a value between 0 and 1 with a value of 1 when the query state has a distance of zero from the function's \"center\" state. As the query state gets further away, the basis function's returned value degrades to a value of zero. The sensitivity of the basis function to the distance is defined by its bandwidth parameter; as the bandwidth value increases, the less sensitive the function is to distance (that is, a large bandwidth will result in it returning a value near 1 even when the query state is far away). A set of state features defined by a set of radial basis functions distributed across the state space gives an approximation of where a given state is. You can think of the set of radial basis function outputs as compressing the state space. As a consequence, a common approach to using radial basis functions is set up a coarse multi-dimensional grid over the state space with a separate radial basis function centered at each intersection point of the grid. BURLAP provides us tools to easily accomplish such a construction of radial basis functions. Lets start by a creating a new method for running LSPI with radial basis functions. It will look almost identical to the previous Fourier Basis LSPI method we created, except instead of defining Fourier basis functions, we'll define radial basis functions. For the moment, the code below will create an instance of a radial basis function state feature database ( RBFFeatureDatabase ), but we will need to add code to actually add the set of radial basis functions it uses. Also note that we moved the initial state object instantiation to earlier in the code, because we will use it to help define the center states of the radial basis functions we will create. The differencesare highlighted with comments in the code. public static void MCLSPIRBF(){MountainCar mcGen = new MountainCar();Domain domain = mcGen.generateDomain();TerminalFunction tf = new MountainCar.ClassicMCTF();RewardFunction rf = new GoalBasedRF(tf, 100);//get a state definition earlier, we'll use it soon.State s = mcGen.getCleanState(domain);StateGenerator rStateGen = new MCRandomStateGenerator(domain);SARSCollector collector = new SARSCollector.UniformRandomSARSCollector(domain);SARSData dataset = collector.collectNInstances(rStateGen, rf, 5000, 20, tf, null);//instantiate an RBF feature database, we'll define it more in a momentRBFFeatureDatabase rbf = new RBFFeatureDatabase(true);//notice we pass LSPI our RBF features this timeLSPI lspi = new LSPI(domain, rf, tf, 0.99, rbf);lspi.setDataset(dataset);LSPI lspi = new LSPI(domain, 0.99, rbf, dataset);Policy p = lspi.runPolicyIteration(30, 1e-6);Visualizer v = MountainCarVisualizer.getVisualizer(mcGen);VisualActionObserver vob = new VisualActionObserver(domain, v);vob.initGUI();SimulatedEnvironment env = new SimulatedEnvironment(domain, rf, tf, s);env.addObservers(vob);for(int i = 0; i < 5; i++){p.evaluateBehavior(env);env.resetEnvironment();}System.out.println(\"Finished\");} You'll notice that we passed \"true\" to our RBFFeatureDatabase constructor. The true flag indicates that that the feature database should include a constant feature that is always on. This is typically a good idea because it provides a Q-value \"y intercept\" value to the linear function that will be estimated. To construct a set of radial basis functions over a grid, we will first want to generate the states that lie at the intersection of grid points on a grid. To construct the set of states, we will make use of the StateGridder class in BURLAP. StateGridder allows you to set up arbitrarily specified grids over a state space and return the set of states that lie on the intersection points of the grid. StateGridder can even do things like include constant values for some attributes or objects (that is, attribute values that remain fixed for every state in the grid). For our current purposes, we just want a fairly simple grid that spans the full state space of Mountain Car. To get the set of states that span a 5x5 grid over the car position and velocity attributes (for a total of 25 states), add the below code right below the instantiation of the RBFFeatureDatabase. If you want to know how to set up a more specific grid (e.g., an asymmetric grid like a 3x7), see the class's documentation RBFFeatureDatabase rbf = new RBFFeatureDatabase(true);StateGridder gridder = new StateGridder();gridder.gridEntireDomainSpace(domain, 5);List<State> griddedStates = gridder.gridInputState(s); Notice that the gridInputState method requires an example State object? An example state is required because it's what tells the gridder how many objects of each object class need to be gridded (and what any constant ungridded objects/values are, if any). Now that we have a bunch of states distributed over a uniform grid of the state space, we will want to create radial basis functions centered at each of those states. Since a radial basis function also needs a distance metric between states, let us use a Euclidean distance metric. BURLAP already has an Euclidean distance metric implementation, but it requires that a state first be converted to a variable vector, which we can again do using the ConcatenatedObjectFeatureVectorGenerator (and we will again normalize the attribute values). To instantiate the distance metric, add the below code. DistanceMetric metric = new EuclideanDistance( new ConcatenatedObjectFeatureVectorGenerator(true, MountainCar.CLASSAGENT)); Now we will add a radial basis function to our RBFFeatureDatabase for each state on the grid using the Euclidean distance metric and setting the bandwidth parameter to 0.2. In particular, we will use Gaussian radial basis functions . for(State g : griddedStates){rbf.addRBF(new GaussianRBF(g, metric, .2));} Our final Mountain Car LSPI radial basis function method should now look like the below. public static void MCLSPIRBF(){MountainCar mcGen = new MountainCar();Domain domain = mcGen.generateDomain();TerminalFunction tf = new MountainCar.ClassicMCTF();RewardFunction rf = new GoalBasedRF(tf, 100);State s = MountainCar.getCleanState(domain, mcGen.physParams);StateGenerator rStateGen = new MCRandomStateGenerator(domain);SARSCollector collector = new SARSCollector.UniformRandomSARSCollector(domain);SARSData dataset = collector.collectNInstances(rStateGen, rf, 5000, 20, tf, null);RBFFeatureDatabase rbf = new RBFFeatureDatabase(true);StateGridder gridder = new StateGridder();gridder.gridEntireDomainSpace(domain, 5);List griddedStates = gridder.gridInputState(s);DistanceMetric metric = new EuclideanDistance(new ConcatenatedObjectFeatureVectorGenerator(true, MountainCar.CLASSAGENT));for(State g : griddedStates){rbf.addRBF(new GaussianRBF(g, metric, .2));}LSPI lspi = new LSPI(domain, 0.99, rbf, dataset);Policy p = lspi.runPolicyIteration(30, 1e-6);Visualizer v = MountainCarVisualizer.getVisualizer(mcGen);VisualActionObserver vob = new VisualActionObserver(domain, v);vob.initGUI();SimulatedEnvironment env = new SimulatedEnvironment(domain, rf, tf, s);env.addObservers(vob);for(int i = 0; i < 5; i++){p.evaluateBehavior(env);env.resetEnvironment();}System.out.println(\"Finished\");} If you now point your main method to call the MCLSPIRBF method, you should see similar results as before, only this time we've used radial basis functions! Now that we've demonstrated how to use LSPI on the mountain car domain with Fourier basis functions and radial basis functions, we'll move on to a different algorithm (Sparse Sampling) and a different domain (the Inverted Pendulum). Next Part", "http://burlap.cs.brown.edu/tutorials_v2/scd/p2.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Solving Continuous Domains Tutorials > Solving Continuous Domains > Part 2 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA(\u03bb) Conclusions Final Code Previous Part | Next Part Solving the Inverted Pendulum with Sparse Sampling In this part of the tutorial we will be solving the Inverted Pendulum problem. There are actually a number of different versions of this problem (for other variants, see the CartPoleDomain and its parameters), but in this example we'll be using one of the more simple forms. The problem is as follows; a cart exists on an infinite track on which force can be applied to move the cart left or right on the track. On top of the cart is a pole (the inverted pendulum) and the goal is to keep the pole balanced and pointing up by using left, right, or no force actions. If the angle between the pole and the vertical axis is larger than some threshold, the task is considered to have been failed. The state is defined by a single object which is defined by the pole angle and its angular velocity. An illustration of the problem, as visualized in BURLAP, is shown below. The BURLAP visualization of the Inverted Pendulum problem We are going to solve this problem using Sparse Sampling (more on that in a moment). Let us start by making a method (IPSS) for solving this problem and filling it in with code to instantiate the InvertedPendulum domain and task. public static void IPSS(){InvertedPendulum ip = new InvertedPendulum();ip.physParams.actionNoise = 0.;Domain domain = ip.generateDomain();RewardFunction rf = new InvertedPendulum.InvertedPendulumRewardFunction(Math.PI/8.);TerminalFunction tf = new InvertedPendulum.InvertedPendulumTerminalFunction(Math.PI/8.);State initialState = InvertedPendulum.getInitialState(domain);} The line \"ip.physParams.actionNoise = 0.;\" sets our domain to have no noise in the actions. ( physParams is a data member containing all physics parameters that you can modify.) The created reward function and terminal function specify task failure conditions to be when the angle between the pole and vertical axis is greater than \u03c0/8 radians. Specifically, the agent will receive zero reward everywhere except when the pole's angle is greater than \u03c0/8, at which point it will receive -1 reward. The initial state we retrieved from the InvertedPendulum class will return a state in which the pole is balanced with no initial angular velocity. The algorithm we're going to use to solve this problem is Sparse Sampling. Instead of trying to approximate the value function for all states, Sparse Sampling will estimate Q-values for only one state a time, with the exception that the Q-values estimated are for a finite horizon , which means it only considers the possible reward received up to a specific number of steps from the current state and then ignores everything that might happen after that point. The approach is called Sparse Sampling, because if the set of possible transition dynamics are very large or infinite, it will only use a small sample from the transition dynamics when computing the Q-values. A disadvantage of Sparse Sampling is that for every new state encountered in the real world, planning needs to happen all over again (unless the agent happens to arrive in the same exact state, which is often uncommon in continuous state spaces). Furthermore, the computational complexity grows exponentially with the size of the horizon used, so if a large horizon is necessary to achieve a reasonable policy, Sparse Sampling may be prohibitively expensive. However, for our Inverted Pendulum domain, failing the task is only a few easy mistakes away, which means we can use a tractably small horizon to solve the problem. Lets now instantiate SparseSampling and set up a GreedyQ policy to follow from it. SparseSampling ss = new SparseSampling(domain, rf, tf, 1, new SimpleHashableStateFactory(), 10 ,1);ss.setForgetPreviousPlanResults(true);ss.toggleDebugPrinting(false);Policy p = new GreedyQPolicy(ss); Note that we're using a discount factor of 1 because we are computing the Q-values for a finite horizon (rather than computing an infinite horizon) and a discount factor of 1 with a finite horizon will always result in finite Q-values. The method call setForgetPreviousPlanResults(true) tells Sparse Sampling to forget the previous planning tree it created every time planning for a new state is begun. Since we don't expect to see the same state twice, this is useful to clean up memory that we don't expect to use again. The last parameters of the SparseSampling constructor are the horizon size and the number of transition samples. We set the horizon to 10 and the number of transition samples to 1. Using only 1 transition sampling might be problematic in general, but since we simplified by the problem by removing action noise, everything is deterministic and so we only need one sample anyway! (Later, feel free to add back noise and increase the number samples, though you will find that a fair bit more computation time is needed). The final thing you'll notice in the code is that we never make an explicit call to planning from a state. There is a lack of an explicit planning call because whenever the GreedyQPolicy queries for the Q-values of a state, SparseSampling will automatically plan from that state first (unless we had let it remember past planning results and it was the same state as a state for which it's planned before). At this point, we're basically done!. All we need to do now is evaluate the policy that we created. We could have an animated visualization, like we did for the Mountain Car domain with LSPI, but since Sparse Sampling requires a bit more computation per step, lets let it cache an episode (with a maximum of 500 steps) to a file, and then visualize the episode using an EpisodeSequnceVisualizer like we've used in previous tutorials. Add the following code to evaluate the policy for at most 500 steps from the initial state, create a visualizer, and load up a EpisodeSequenceVisualizer to review the results. EpisodeAnalysis ea = p.evaluateBehavior(initialState, rf, tf, 500);System.out.println(\"Num steps: \" + ea.maxTimeStep());Visualizer v = InvertedPendulumVisualizer.getInvertedPendulumVisualizer();new EpisodeSequenceVisualizer(v, domain, Arrays.asList(ea)); If you now point the main method to IPSS and run it, you should first see printed to the console the number of Bellman backups that were performed in the planning for each step of the episode. After 500 steps, it will launch the EpisodeSequenceVisualizer that you can use to review the steps it took. You should have found that it successfully balanced the pole for all 500 steps and the interface should look something like the below. The EpisodeSequenceVisualizer GUI after solving the Inverted Pendulum with Sparse Sampling. We're now finished with the Sparse Sampling example! If you're looking for an additional exercise, consider trying to solve this problem with LSPI using what you learned from the previous part of the tutorial. If you do so, we recommend using 5th order Fourier basis functions and collecting 5000 SARS instances by performing random trajectories from the initial balanced state. (To create a StateGenerator that always returns the same initial state for use with the SARS collector, see the ConstantStateGenerator class.) In the final part of this tutorial, we will show how to solve the Lunar Lander domain with gradient descent SARSA lambda. Next Part", "http://burlap.cs.brown.edu/tutorials_v2/scd/p3.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Solving Continuous Domains Tutorials > Solving Continuous Domains > Part 3 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA(\u03bb) Conclusions Final Code Previous Part | Next Part Solving Lunar Lander with SARSA(\u03bb) In our final example of this tutorial we will solve a simplified Lunar Lander domain using gradient descent Sarsa Lambda and CMAC/Tiling coding basis functions. The Lunar Lander domain is a simplified version of the classic 1979 Atari arcade game by the same name. In this domain the agent pilots a ship that must take off from the ground and land on a landing pad. The agent can either use a strong rocket thruster to push the ship in the direction the ship is facing, use a weak rocket thruster that is equal magnitude to the force of gravity, rotate clockwise or counterclockwise, or coast. The agent will receive a large reward for landing on the landing pad, a large negative reward for colliding with the ground or an obstacle, and a small negative reward for all other transitions. As with the previous examples, let us begin by making a method for this example (LLSARSA) and instantiating a Lunar Lander domain , task, and initial state. public static void LLSARSA(){LunarLanderDomain lld = new LunarLanderDomain();Domain domain = lld.generateDomain();RewardFunction rf = new LunarLanderRF(domain);TerminalFunction tf = new LunarLanderTF(domain);State s = LunarLanderDomain.getCleanState(domain, 0);LunarLanderDomain.setAgent(s, 0., 5.0, 0.0);LunarLanderDomain.setPad(s, 75., 95., 0., 10.);} Most of this code should be fairly self explanatory. Using a default construct for LunarLanderDomain and not setting anything else with it will use default parameters for the domain (but you can change various properties such as the force of gravity, thrust, etc.). The default reward function returns +1000 for landing, -100 for collisions, and -1 for regular transitions (though these values can be changed with a different constructor ). The terminal function sets all states in which the ship has landed on the landing pad as terminal states. The getCleanState method, with the parameter 0 creates a state with an agent object (the ship) a landing pad object, and 0 obstacle objects. The setAgent method parameters specify the angle of the ship from the vertical axis in radians, the x position of the ship (5), and the y position of the ship (0, on the ground), respectively. The setPad method parameters define the landing pad dimensions in terms of the rectangular left, right, bottom, top boundaries, respectively. This will create an initial state that looks like the below (as visualized in BURLAP). The initial stated used in Lunar Lander. The red box is the ship, the blue box the landing pad. We're going to solve this problem with gradient descent SARSA(\u03bb) , which is a learning algorithm that behaves much like conventional tabular SARSA(\u03bb) (discussed in previous tutorials), except it learns an approximation of the value function, much like LSPI. Unlike LSPI, gradient descent SARSA(\u03bb) does not need to use a linear approximator; however, in practice it is usually a good idea to use a linear approximator because there are much stronger learning convergence guarantees with linear approximators. When using a linear approximator, it is a good idea then to use some kind of basis functions. Like in the LSPI example, we could use the same Fourier basis or radial basis functions for gradient descent SARSA(\u03bb). However, this time we'll use a different basis function: CMACs, also know in reinforcement learning literature as Tile Coding. CMACs create a set of features by generating multiple tilings over the state space. Each tile represents a features and that feature is \"on\" if the state falls within that tile. CMACs in detail CMACs address learning in continuous domains in a only slightly more complex way than merely discretizing the state space, yet also diminish the aliasing effects that discretization can incur. To describe how they work, lets start by thinking about how a state discretization can be used to create a set of binary basis functions. First imagine a discretization of the state space as a process that creates large bins, or tiles , across the entire state space. We'll let each tile represent a different binary basis function. For a given input continuous state, all basis functions return a value of 0, except the function for the tile in which the continuous state is contained, which will return a value of 1. By then estimating a linear function over these features, we generalize the observed rewards and transitions for one state to all states that are contained in the same tile; the larger the tiles we use, the larger the generalization. A disadvantage of using such a simple discretization is that it produces aliasing effects. That is, two states may be very similar but reside on opposite sides of the edge of a tile, which results in none of their experience being shared, despite the fact that they are similar and do share experiences with other states that are more distant but happen to be in the same tile. CMACs diminish this aliasing effect by instead creating multiple offset tilings over the state space and creating a basis function for each tile in each of the tilings. If there are n tilings, then any given input state will have n basis functions with a value 1 (one for the tile in which the query state is contained for each tiling). Because the tilings are offset from each other, two states may be contained in the same tile of one tiling, but in different tiles for a different tiling. As a consequence, experience generalization still occurs between states in the same tiling, but the differences between different tilings regains specificity and removes aliasing effects. For more information on CMACs with some good illustrations, we recommend the Generalization and Function Approximation chapter in the book Reinforcement Learning: An Introduction , by Sutton and Barto. An online version of the chapter can be found here . An advantage of using CMACs is that you only need to store weight values in the fitted linear function for tiles that are associated with states that the agent has experienced thus far (the basis function for all other tiles would return a value of zero and therefore contribute nothing to the value function approximation). Another advantage specific to OO-MDPs is that because each tile represents a discretized state, we can maintain object identifier independence, which is otherwise not always possible to do with a number of value function approximation methods. If you don't need object identifier independence, there is another implementation of CMACs in BURLAP called FVCMACFeatureDatabase that is slightly more CPU efficient and operates on state feature vectors (which as before are produced with StateToFeatureVectorGenerator objects). For this tutorial, however, we will use the version that provides object identifier independence, which is called CMACFeatureDatabase . Lets continue our code implementation by instantiating a CMACFeatureDatabase object and defining the tiling of our state space. To implement CMAC basis functions, we will need to decide on the number of tilings that we use and the width of each tile along each attribute. In this case, we will use 5 tilings with a width for each attribute that produces 10 tiles along each attribute range. We will limit this tiling to the Lunar Lander ship attribute values and ignore attributes for the landing pad. Since the agent's ship is defined by 5 attributes (x position, y position, x velocity, y velocity, and rotation angle from the vertical axis), this will produce 5 tilings that each define at most 10^5 tiles (again though, we don't necessarily have to store weights for all tiles if the agent never visits them!) To do so, add the below code. int nTilings = 5;CMACFeatureDatabase cmac = new CMACFeatureDatabase(nTilings, CMACFeatureDatabase.TilingArrangement.RANDOMJITTER);double resolution = 10.;double angleWidth = 2 * lld.getAngmax() / resolution;double xWidth = (lld.getXmax() - lld.getXmin()) / resolution;double yWidth = (lld.getYmax() - lld.getYmin()) / resolution;double velocityWidth = 2 * lld.getVmax() / resolution;cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS, domain.getAttribute(LunarLanderDomain.AATTNAME), angleWidth);cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS, domain.getAttribute(LunarLanderDomain.XATTNAME), xWidth);cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS, domain.getAttribute(LunarLanderDomain.YATTNAME), yWidth);cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS, domain.getAttribute(LunarLanderDomain.VXATTNAME), velocityWidth);cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS, domain.getAttribute(LunarLanderDomain.VYATTNAME), velocityWidth); In the first line, we instantiate the CMACFeatureDatabase with 5 tilings, each offset by a random amount. Then we compute tile widths along each attribute such that it would produce at most 10 tile margins along each attribute. The methods lld.getXMin() simply return the minimum x-value for our LunarLander instance (and the other methods return their respective attribute's value ranges). Finally, we inform the CMACFeatureDatabase of the width for each attribute that will be included in the tiling for each object class. In this case, we will only produce tilings over the agent class for its rotation angle; x, y position; and x, y velocity attributes and ignore the attributes for other object classes like the landing pad. Now that we have the CMACFeatureDatabase set up, we can create a linear value function approximator for it and pass it along to gradient descent SARSA(\u03bb). double defaultQ = 0.5;DifferentiableStateActionValue vfa = cmac.generateVFA(defaultQ/nTilings);GradientDescentSarsaLam agent = new GradientDescentSarsaLam(domain, 0.99, vfa, 0.02, 0.5); Note that to set the initial default Q-values to be predicted to 0.5, we set the value of each feature weight to 0.5 divided by the number of tilings. We divide the desired initial Q-value (0.5) by the number of tilings (5), because for any given state there will only be n features with a value of 1 and the rest 0, where n is the number of tilings. Therefore, if the initial weight value for all those features is 0.5/5, the linear estimate will predict our desired initial Q-value: 0.5. We also set the learning rate for gradient descent SARSA(\u03bb) to 0.02 (in general, you should decrease the learning rate as the number of features increases), and set \u03bb to 0.5. With gradient descent SARSA(\u03bb) instantiated, we can run learning episodes wtih an Environment just like we do for typical SARSA(\u03bb). Lets create a SimulatedEnvironment, run learning for 5000 episodes, and then visualize the results with an EpisodeSequenceVisualizer. SimulatedEnvironment env = new SimulatedEnvironment(domain, rf, tf, s);List episodes = new ArrayList ();for(int i = 0; i < 5000; i++){EpisodeAnalysis ea = agent.runLearningEpisode(env);episodes.add(ea);System.out.println(i + \": \" + ea.maxTimeStep());env.resetEnvironment();}Visualizer v = LLVisualizer.getVisualizer(lld.getPhysParams());new EpisodeSequenceVisualizer(v, domain, episodes); If you now point your main method to LLSARSA() and run it, you should initially see a bunch of text after each episode stating how long the learning episode lasted followed by the EpisodeSequenceVisualizerGUI, which should look something like the below. The EpisodeSequenceVisualizer GUI showing the learning results on Lunar Lander You should find that as more learning episodes are performed, the agent becomes progressively better at piloting to the landing pad. That concludes all of our examples for this tutorial! Closing remarks and the full code we created can be found on the next page. Next Part", "http://burlap.cs.brown.edu/tutorials_v2/scd/p4.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc Tutorial: Solving Continuous Domains Tutorials > Solving Continuous Domains > Part 4 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA(\u03bb) Conclusions Final Code Previous Part Conclusions In this tutorial we showed you how to solve continuous state problems with three different algorithms implemented in BURLAP: LSPI, Sparse Sampling, and gradient descent SARSA(\u03bb). We also demonstrated how to use these algorithms on three different continuous state domains: Mountain Car, Inverted Pendulum, and Lunar Lander. And finally, we also explained how to use three different basis functions (which can be used with LSPI and gradient descent SARSA(\u03bb)): Fourier basis functions, radial basis functions and CMACs/Tile coding. Hopefully these examples have made clear the kinds of tools you need to use solve any other continuous state problems. As usual, you can find all of the code developed in this tutorial below. Final Code import burlap.behavior.policy.GreedyQPolicy;import burlap.behavior.policy.Policy;import burlap.behavior.singleagent.EpisodeAnalysis;import burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizer;import burlap.behavior.singleagent.auxiliary.StateGridder;import burlap.behavior.singleagent.learning.lspi.LSPI;import burlap.behavior.singleagent.learning.lspi.SARSCollector;import burlap.behavior.singleagent.learning.lspi.SARSData;import burlap.behavior.singleagent.learning.tdmethods.vfa.GradientDescentSarsaLam;import burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSampling;import burlap.behavior.singleagent.vfa.DifferentiableStateActionValue;import burlap.behavior.singleagent.vfa.cmac.CMACFeatureDatabase;import burlap.behavior.singleagent.vfa.common.ConcatenatedObjectFeatureVectorGenerator;import burlap.behavior.singleagent.vfa.fourier.FourierBasis;import burlap.behavior.singleagent.vfa.rbf.DistanceMetric;import burlap.behavior.singleagent.vfa.rbf.RBFFeatureDatabase;import burlap.behavior.singleagent.vfa.rbf.functions.GaussianRBF;import burlap.behavior.singleagent.vfa.rbf.metrics.EuclideanDistance;import burlap.domain.singleagent.cartpole.InvertedPendulum;import burlap.domain.singleagent.cartpole.InvertedPendulumVisualizer;import burlap.domain.singleagent.lunarlander.LLVisualizer;import burlap.domain.singleagent.lunarlander.LunarLanderDomain;import burlap.domain.singleagent.lunarlander.LunarLanderRF;import burlap.domain.singleagent.lunarlander.LunarLanderTF;import burlap.domain.singleagent.mountaincar.MCRandomStateGenerator;import burlap.domain.singleagent.mountaincar.MountainCar;import burlap.domain.singleagent.mountaincar.MountainCarVisualizer;import burlap.oomdp.auxiliary.StateGenerator;import burlap.oomdp.core.Domain;import burlap.oomdp.core.TerminalFunction;import burlap.oomdp.core.states.State;import burlap.oomdp.singleagent.RewardFunction;import burlap.oomdp.singleagent.common.GoalBasedRF;import burlap.oomdp.singleagent.common.VisualActionObserver;import burlap.oomdp.singleagent.environment.SimulatedEnvironment;import burlap.oomdp.statehashing.SimpleHashableStateFactory;import burlap.oomdp.visualizer.Visualizer;import java.util.ArrayList;import java.util.Arrays;import java.util.List;public class ContinuousDomainTutorial {public static void MCLSPIFB(){MountainCar mcGen = new MountainCar();Domain domain = mcGen.generateDomain();TerminalFunction tf = new MountainCar.ClassicMCTF();RewardFunction rf = new GoalBasedRF(tf, 100);StateGenerator rStateGen = new MCRandomStateGenerator(domain);SARSCollector collector = new SARSCollector.UniformRandomSARSCollector(domain);SARSData dataset = collector.collectNInstances(rStateGen, rf, 5000, 20, tf, null);ConcatenatedObjectFeatureVectorGenerator featureVectorGenerator = newConcatenatedObjectFeatureVectorGenerator(true, MountainCar.CLASSAGENT);FourierBasis fb = new FourierBasis(featureVectorGenerator, 4);LSPI lspi = new LSPI(domain, 0.99, fb, dataset);Policy p = lspi.runPolicyIteration(30, 1e-6);Visualizer v = MountainCarVisualizer.getVisualizer(mcGen);VisualActionObserver vob = new VisualActionObserver(domain, v);vob.initGUI();SimulatedEnvironment env = new SimulatedEnvironment(domain, rf, tf, s);env.addObservers(vob);for(int i = 0; i < 5; i++){p.evaluateBehavior(env);env.resetEnvironment();}System.out.println(\"Finished\");}public static void MCLSPIRBF(){MountainCar mcGen = new MountainCar();Domain domain = mcGen.generateDomain();TerminalFunction tf = new MountainCar.ClassicMCTF();RewardFunction rf = new GoalBasedRF(tf, 100);State s = MountainCar.getCleanState(domain, mcGen.physParams);StateGenerator rStateGen = new MCRandomStateGenerator(domain);SARSCollector collector = new SARSCollector.UniformRandomSARSCollector(domain);SARSData dataset = collector.collectNInstances(rStateGen, rf, 5000, 20, tf, null);RBFFeatureDatabase rbf = new RBFFeatureDatabase(true);StateGridder gridder = new StateGridder();gridder.gridEntireDomainSpace(domain, 5);List<State> griddedStates = gridder.gridInputState(s);DistanceMetric metric = new EuclideanDistance(new ConcatenatedObjectFeatureVectorGenerator(true, MountainCar.CLASSAGENT));for(State g : griddedStates){rbf.addRBF(new GaussianRBF(g, metric, .2));}LSPI lspi = new LSPI(domain, 0.99, rbf, dataset);Policy p = lspi.runPolicyIteration(30, 1e-6);Visualizer v = MountainCarVisualizer.getVisualizer(mcGen);VisualActionObserver vob = new VisualActionObserver(domain, v);vob.initGUI();SimulatedEnvironment env = new SimulatedEnvironment(domain, rf, tf, s);env.addObservers(vob);for(int i = 0; i < 5; i++){p.evaluateBehavior(env);env.resetEnvironment();}System.out.println(\"Finished\");}public static void IPSS(){InvertedPendulum ip = new InvertedPendulum();ip.physParams.actionNoise = 0.;Domain domain = ip.generateDomain();RewardFunction rf = new InvertedPendulum.InvertedPendulumRewardFunction(Math.PI/8.);TerminalFunction tf = new InvertedPendulum.InvertedPendulumTerminalFunction(Math.PI/8.);State initialState = InvertedPendulum.getInitialState(domain);SparseSampling ss = new SparseSampling(domain, rf, tf, 1, new SimpleHashableStateFactory(), 10 ,1);ss.setForgetPreviousPlanResults(true);ss.toggleDebugPrinting(false);Policy p = new GreedyQPolicy(ss);EpisodeAnalysis ea = p.evaluateBehavior(initialState, rf, tf, 500);System.out.println(\"Num steps: \" + ea.maxTimeStep());Visualizer v = InvertedPendulumVisualizer.getInvertedPendulumVisualizer();new EpisodeSequenceVisualizer(v, domain, Arrays.asList(ea));}public static void LLSARSA(){LunarLanderDomain lld = new LunarLanderDomain();Domain domain = lld.generateDomain();RewardFunction rf = new LunarLanderRF(domain);TerminalFunction tf = new LunarLanderTF(domain);State s = LunarLanderDomain.getCleanState(domain, 0);LunarLanderDomain.setAgent(s, 0., 5., 0.);LunarLanderDomain.setPad(s, 75., 95., 0., 10.);int nTilings = 5;CMACFeatureDatabase cmac = new CMACFeatureDatabase(nTilings,CMACFeatureDatabase.TilingArrangement.RANDOMJITTER);double resolution = 10.;double angleWidth = 2 * lld.getAngmax() / resolution;double xWidth = (lld.getXmax() - lld.getXmin()) / resolution;double yWidth = (lld.getYmax() - lld.getYmin()) / resolution;double velocityWidth = 2 * lld.getVmax() / resolution;cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS,domain.getAttribute(LunarLanderDomain.AATTNAME),angleWidth);cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS,domain.getAttribute(LunarLanderDomain.XATTNAME),xWidth);cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS,domain.getAttribute(LunarLanderDomain.YATTNAME),yWidth);cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS,domain.getAttribute(LunarLanderDomain.VXATTNAME),velocityWidth);cmac.addSpecificationForAllTilings(LunarLanderDomain.AGENTCLASS,domain.getAttribute(LunarLanderDomain.VYATTNAME),velocityWidth);double defaultQ = 0.5;DifferentiableStateActionValue vfa = cmac.generateVFA(defaultQ/nTilings);GradientDescentSarsaLam agent = new GradientDescentSarsaLam(domain, 0.99, vfa, 0.02, 0.5);SimulatedEnvironment env = new SimulatedEnvironment(domain, rf, tf, s);List<EpisodeAnalysis> episodes = new ArrayList<EpisodeAnalysis>();for(int i = 0; i < 5000; i++){EpisodeAnalysis ea = agent.runLearningEpisode(env);episodes.add(ea);System.out.println(i + \": \" + ea.maxTimeStep());env.resetEnvironment();}Visualizer v = LLVisualizer.getVisualizer(lld.getPhysParams());new EpisodeSequenceVisualizer(v, domain, episodes);}public static void main(String[] args) {//MCLSPIFB();//MCLSPIRBF();//IPSS();LLSARSA();}} End.", "http://burlap.cs.brown.edu/updates.html": "BURLAP Home | Updates | Information | F.A.Q. | Tutorials | Java Doc June 17, 2016 BURLAP 3 is Here! If you've been following git or the google groups page, you may be aware of or were even following the development of BURALP 3, which is now finally ready for a more full release, replacing the master branch of the github repo! BURLAP 3 changes can be summarized as follows. a more simple and flexible State interface; a more simple and flexible action interface and model definition; stochastic games agent indexing by ints; shorter method names and/or classes in some cases abstract classes converted to interfaces; abstract methods/interfaces restructured to be more functional; slight package reorganizations; and a license change to Apache 2.0. A good way to acquaint yourself with the changes in BURLAP 3 is to review the tutorials which have all been updated for BURALP 3 or to scan the code in the examples repository . In particular, you may want to review the updated Building a Domain tutorial which will cover the most significant changes to how BURLAP works. State interface Previously in BURALP 2 and 1, all states in BURLAP were OO-MDP states, and although State was an interface in BURLAP 2 that allowed you to ignore OO-MDP related methods, there were a very large number of methods for which you'd have to throw unsupported operation exceptions if you didn't want your state to be an OO-MDP state, making what was expected rather unclear. Furthermore, all variable values were pushed through nested class wrappers and you had to specify these types and various information about them very explicitly in the domain construction. In BURLAP 3, OO-MDPs are no longer a requirement. State is now a simple interface that you implement for your problem, making the state definition equivalent to defining a Java class. The State interface only requires you to implement three methods: variableKeys(), get(Object key), and copy(). variableKeys requires you to return a list of Java type Object that are keys that can be used to refer to variables in your state. Because the list is of type Object, your keys can be any kind of structure that is most convenient for you; be it an int, a String, or something else entirely. The get method takes in a variable key and returns the variable value for that key. The value is also of type Object, meaning your state variables can be any data type you want! Because the key is an Object, you can also handle support for multiple key data representations (e.g., maybe strings and ints). Finally, the copy method simply creates a copy of your State and returns it. If you want to provide more standard functionality with your state, you can also implement MutableState , which adds a set(Object key, Object value) method to State. Doing so will let things like standard BURALP shell commands change the value of states, or create an set of states centered on grid intersection points. And if you do want to use OO-MDP representations, there are special interfaces for that too, but it's optional. If you want to use OO-MDPs, you should look at the new tutorial specifically about that: Building and OO-MDP Domain . One of the auxiliary advantages of this new state interface compared to the old methods is that it makes serialization very trivial. As long as your State implementations are JavaBeans (has a default constructor and getter and setters for all relevant non-public data fields), you can use the Yaml package to save and load data that includes states. For example: String strRep = new Yaml().dump(stateObject); Where stateObject is the State instance you want to serialize. (Naturally, this also works for serializing more complex data structures that contain State objects). And to parse a yaml string of a State, you'd do: State s = (State)new Yaml().load(stateStr); Action interfaces In BURLAP 2 and 1, there were a number of action interfaces and abstract classes and it was often unclear to new users what piece was responsible for what. In BURLAP 3, the Action interface defines a decision (and is most similar to a GroundedAction in BURALP 2 and 1); it does not request code for transition dynamics or preconditions. Implementing an Action requires implementing only two methods: actionName() and copy(). Anything else you need to distinguish an action is entirely up to you. Although Action is quite simple now, that doesn't mean BURLAP no longer has a means to handle preconditions or parameterized actions. Along with Action is the interface ActionType . ActionType serves as a generator for Actions and requires three methods: typeName(), associatedAction(String), and allApplicableActions(State). The associatedAction method takes a string representation of the action and generates the corresponding Action object. allApplicableActions is the main method of interest, which takes as input a State and returns all applicable actions of that ActionType. This method would handle determining which possible parameterizations there were and checking any preconditions you want to define. Although you can implement your own Action and ActionType classes, when you have an unparameterized action set that you can execute anywhere (as is most common in MDPs), you can define the action set using the UniversalActionType , where you create a new UniversalActionType with a different name for each of your actions. (Alternatively, you can manually give a UniversalActionType your own Action instance that it will always generate). For example, for a grid world, defining the action set would look something like this in code: domain.addActionTypes(new UniversalActionType(\"north\"),new UniversalActionType(\"south\"),new UniversalActionType(\"east\"),new UniversalActionType(\"west\")); In the previous version of BURLAP an MDP's state transition dynamics model was stored in one of the Actions. Since the Action interfaces are much simpler now, the model is now its own interface, with SampleModel , and FullModel (the former if you can only generate samples from the transition dynamics, and the latter if you can enumerate the probability distribution). The nice thing about this factoring is that for real RL problems you don't have to provide a model at all, and can just specify the action set. Additionally, it makes working with model-based RL algorithms easier, and enables you to easily change the model you're using with an algorithm, independent of even those provided with an existing simulated domain. Finally, this change to a more simple interface also provides trivial serialization in the same way states do. Since Actions are simple objects, you can serialize data that includes them with standard Yaml serialization methods. Stochastic games agent indexing by int Previously, agents in a stochastic game were identified by a name. This formulation led to more book keeping because you may have needed to ensure that your state representation was compatible with the names of the agents selecting actions. It also required duplication of existing data structures. For example, there needed to be special agent-wise action interfaces that kept track of their name and state generators that were dependent on the names of the agents being used. In BURLAP 3, agents are primarily identified by their int index in the set of agents in the game (with an agent name only providing descriptive information). That means that joint actions now consist of a list of regular Action objects, and you select an agent's action by the index of the agent in that list. Similarly, a joint reward return is a double array with each entry being the reward for each agent in the game. License change to Apache 2.0 Previously, BURALP was licensed under LGPL 3, but we have changed licenses to the more permissive Apache 2.0 license. In short, this change allows you to create modified versions of BURLAP and license your changes under a different license. February 26, 2016 Changes to BURLAP Master BURLAP master and the pre-compiled jar files have been updated with some changes, one of which may require some very minor changes to your code. The primary changes of note consist of (1) a new set of interfaces for general function approximation; and (2) a new experiment \"shell\" for interactively controlling experiments at runtime. If you need to get the prior version of BURLAP, you can get it from the v2 branch on github. Function approximation BURLAP has always supported function approximation for various algorithms. However, for standard value function approximation, there was often a notational an implementation slant toward linear function approximation, even though it could in principle support non-linear function approximation. This slant also made it less clear how to implement your own non-linear function approximators. At a high-level there is an interface named ParametricFunction that is used to provide general interfaces for getting and setting parameter values of the function. Common interface extensions include interfaces for parametric state and state-action value functions ( ParametricStateFunction and ParametricStateActionFunction ).Furthermore, inverse reinforcement learning parameterized reward functions also extend ParametricFunction to unify how you work these two kinds of objects. There, there are also interface extensions for parametric functions that are differentiable ( DifferentiableStateValue , DifferentiableStateActionValue , DifferentiableRF , etc.). These interfaces include a method that allows the gradient, with respect to the function parameters, to be returned. Gradients are provided via the interface FunctionGradient . This interface allows the retrieval and storing of partial derivatives for each parameter and also allows a list of the non-zero partial derivatives to be returned. Currently there is one concrete implementation of FunctionGradient: SparseGradient which only stores the gradient for parameters with non-zero partial derivatives with a Java hash map. This sparse data structure is especially for convenient for function approximation like tile coding. However, in principle you can implement your own FunctionGradient data structures for your own differentiable ParametricFunctions if there is a data structure that is more efficient for your needs. With these more simple interfaces, hopefully it is more clear how to implement your own custom forms of function approximation. All the previous function approximation methods in BURLAP have been converted to this new interface. Because of that conversion, in previous client code you may have developed, there shouldn't be much changes other the names of the data types. That is, Whereas before you may have had a ValueFunctionApproximtion object, it is now probably DifferentiableStateActionValue. Correspondingly, the tutorial code has been updated to reflect these changes. Shell The next change is more of an additional tool to BURLAP: a framework for setting up an interactive shell that you can use to control your experiments at runtime. Note that this shell does not provide arbitrary java code execution. Instead it's more similar to a light weight \"bash\" for BURLAP. At a high-level there is a class called BurlapShell that takes as input an input stream and output stream on which the shell will operate. The shell is then started with the method start (which runs the shell in a separate thread), which begins an input output sequence. The shell has some basic universal commands that allow you to do things like set aliases for commands. There are two primary subclasses for this shell, EnvironmentShell and SGWorldShell . The former is a shell that contains a reference to an Environment instance so that you can perform various controls with an environment and comes with a number of standard commands for interacting with an environment (such as executing actions, recording episodes, visualizing episodes, etc.). Analogously, the SGWorldShell contains a reference to a stochastic games World and has various similar commands for interacting with it. Although the EnvironmentShell and SGWorld Shell come with many convenient commands you can use for these cases, any BurlapShell can be extended by giving it your own implementations of the interface ShellCommand . Being able to extend the commands allows you to create your own experiment specific controllers. Most of the existing commands make use of the JOptSimple library so that they handle standard formats for command line arguments, and you may want to make use of it as well for your own custom commands. Its is also worth noting that the TerminalExplorer class is now just a wrapper for an EnvironmentShell that is initialized on the the standard input and output streams. Similarly for SGTerminalExplorer. The console that is accessible from a VisualExplorer or SGVisualExplorer now also makes use of the corresponding EnvironmentShell or SGWorldShell using a output and input stream from GUI elements. This inclusion allows you to have a lot of control over an experiment while it's being visualized. Currently the shell framework does not support conditionals or looping mechanisms, but we may add these capabilities in a future version. September 19, 2015 BURLAP version 2 is live! In the last update, we mentioned that BURLAP would be getting some more significant changes that turned the State class into an interface so that it opened the door for custom implementations for domains that needed more specific memory management. Since then we also began to implement a number of other changes that taken together are sufficient enough to be a new version since they may require some code changes by users. These changes make BURLAP in many cases easier to use, more flexible, and in some cases faster. BURLAP version 1 is still available for download, both the pre-compiled JAR and the source code in the github (which is on branch v1), but from now on, master will point to version 2. All tutorials have also been updated to reflect the changes in BURLAP 2 (and also received some other tuning), but the version 1 tutorials are also still available. In the remainder of this update we will review some of the main highlights of the changes in BURLAP 2. Most Significant Changes State interface As discussed in the previous update, the State class has now become an interface. Most of the domains in BURLAP will make use of the MutableState implementation, which is the same kind of implementation BURLAP version 1 used. However, by making State an interface, it opens the door for domain-specific memory optimization in which you can implement your own State class specific for your domain and even provide methods that are useful for quickly retrieving information. Environment interface Although an Environment class was included in the previous version of BURLAP, it was auxiliary for very specific purposes and did not strongly integrate with the rest of the BURLAP tools. Environment is now a central interface in BURLAP and used by many classes. The Environment interface provides methods for getting observations and rewards from some environment and receiving actions from an agent. There is also a standard SimulatedEnvironment class for using BURLAP domains to simulate the environment. The Environment interface is now integrated into other BURLAP tools in a variety of ways. First, learning algorithms that implement the LearningAgent interface now all learn by interacting with the Environment. This change removes the burden of current state book keep from the learning algorithm; moreover, it provides state safety in that the learning algorithms cannot accidentally change what the state or outcome of the Environment is and are forced to take it as it comes. This is particularly useful for model-based RL algorithms in which a separate modeled domain is learned in which planning is performed. When the agent executes an action selected from the learned model policy in an environment, there is no confusion over whether it's executed the model of the action or actually executing the action in the world, because it will be executing the action through the Environment interface when it need to apply it in the world. Second, Policy objects can now be trivially rolled out in an Environment. This paradigm is useful for using BURLAP with robotics or other external systems, since you can build a model in BURLAP, produce a policy with that model, and then roll that policy out in the external world/system by rolling it out in an Environment that interfaces with the external world/system. For example, the burlap_rosbrige extension provides an Environment implementation that interfaces with ROS so that you can have a BURLAP policy control a ROS robot by rolling out the policy in the Environment. Third, the VisualExplorer and TerminalExplorer now operate on Environment implementations, which means you can use them to manually control external systems that are interfaced with an Environment. Action organization The Action, GroundedAction, and the stochastic games equivalents have been a refactored. In the previous version of BURLAP, many of the critical methods of the Action class took as a method argument a String array that was used for specifying parameters. By default, these parameters were considered to be STRIPs-like OO-MDP object references, and although other kinds of parameters could be used, it was a hacky implementation. In the new version of BURLAP, Action methods now take a GroundedAction as an argument, instead of a String array. The motivation is that if you have a special of kind of action parameterization you would like to use, you can subclass GroundedAction to contain whatever kind of data structures you want to specify any kind of parameters that you want. (For example, it would now be trivial to implement continuous valued parameterized actions.) Along with that, two of the methods that you must implement for the Action class are used to generate your instances of GroundedAction. This way, planning and learning algorithms never need to know about your parameterization types; they simply ask your Action definition to generate the permissible parameterizations and hand them back to your appropriate methods when they want to execute them or query the transition dynamics. Along with these changes, all Action methods that are used to define an Action are all now abstract so it's entirely clear what would be expected of you to define an Action. However, if you simply want to define parameter-less actions without any preconditions, you can always just subclass the SimpleAction class which will implement those details for you. Similar changes were made for the stochastic games classes. POMDP support added BURLAP now has support for POMDP problem definitions. Currently the space of implemented solvers is limited; there is a Belief MDP conversion tool so that you use standard MDP algorithms to solve the POMDP; an exact finite horizon solver, by using the Belief MDP conversion with Sparse Sampling; and QMDP. However, other algorithms are currently being implemented, including POMCP and PBVI, which will hopefully be available soon. Less Significant Changes StateHashFactory/StateHashTuple -> HashableStateFactory/HashableState and revised For the most part there has merely been a renaming of the StateHashFactory/StateHashTuple to HashableStateFactory/HashableState; however, the code for these classes have been significantly streamlined with better support. When in doubt, you can simply use the SimpleHashableStateFactory implementation, which has much better support and which other implementations for state abstraction or value discretization extend. StateParser deprecated for Java bean serialization The StateParser in version 1 was used for serializing State objects by allowing them to be turned to and from String representations. Although the code is still there, it is now in a legacy package and should not be used going forward. Instead, it is recommended that you use the SerializableState and SerializableStateFactory classes (if at all). A SerializableState is a Java Bean class representation of a state that can be trivially serialized using any number of standard Java serialization methods (as well as providing a method for turning it back into a standard State), such as JSON or YAML. There is a standard serialization class called SimpleSerializableState that in general you can always use. In fact, now when you write an EpisodeAnalysis file to disk, it saves it in a YAML format and by default uses the SimpleSerializableState so that you never have to think about it. However, you can also always pass it a more compact SerializableState representations through the SerializableStateFactory if you're looking to keep your files compressed. Domains that previously had their own StateParser implementations now have corresponding SerializableStateFactory classes that you can use instead; though in general, you don't really need to think about state serialization anymore. Package and class name refactoring, as well as class hierarchy refactoring The class names and organization for a number of classes has changed. For example, OOMDPPlanner is now simply MDPSolver, which inherits from an MDPSolverInterface interface. The new Planner interface extends MDPSolverInterface, giving it the planFromState method, which now also returns a policy so that you don't have to think about what Policy to wrap around your planning algorithm. Similarly, the QComputablePlanner interface is now simply QFunction and it extends a ValueFunction interface. Other minor reorganization changes also exist. If you are migrating your code, many of the changes may simply require using different imports and changing the name of some elements. However, it may be worthwhile to rescan the updated tutorials to see how things have changed. Additionally, all tutorial code on the website has been included in the main distribution under the package burlap.tutorials. May 29, 2015 The latest version of BURLAP has had various changes. Most changes will be transparent or are feature additions. For example, domains for BlockDude and Frostbite have been added, and terminal explorers now accept console commandsfor directly modifying states, similar to what you will find in the VisualExplorerconsole. However, there is one change that may require some small changes to yourcode. Specifically, all domain's DomainGenerators can have their physics/model parameters modified to generate a new domain, without affecting the behavior of previously generated domains from the same DomainGenerator instance. For many domains, like MountainCar, InvertedPendulum, LunarLander, etc., this change wasimplemented by storing all physics parameters in a data member called physParams.physParams has public data members for each physics parameter that was normally part ofits corresponding DomainGenerator, so if you have code that changes a physics parameter, you will now need to reference it from the physParams data member. Note that physParams gets fully copied whenever generateDomain is called so that future changes will not affect previously generated domains. Along with embedding physics/model parameters inside a single object that is copied, the MountainCar ClassicMCTF class is now a static class. To see how these changes affect code, see the Solving a Continuous Domain Tutorial which has had its code updated to reflect the changes. Also be sure to examine the Java doc for each DomainGenerator you are using. Finally, we are planning a fairly significant change to BURLAP's statedefinitions. Currently, State is a mutable class for defining OO-MDP states with alist of ObjectInstance objects (that are also hash-indexed by their name). Although this works fine for many domains, we have found that more complex domains we are investigating would benefit from different state memory management and indexing methods. Therefore, we are planning on changing Stateto become an interface with the current State being a standard implementation that is available. This will enable users freedom to optimize their state definitions for the needs of their domain, providing increased CPU performance and reduced memory usage. If you would like to track the progress of this work, see the state_interface branch on git. Once that branch is fully developed, we willbranch the current version of master to something else so it's always there and then pull state_interface into master. If you have comments about this new direction, please share them on the BURLAP google group .", "http://caps.cs.brown.edu": "CAPS @ Brown Cryptography Anonymity Privacy Security CAPS hljs.initHighlightingOnLoad();", "https://blog.cs.brown.edu/2019/04/05/tech-social-good-spotlight-ben-spector-17/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Tech For Social Good Spotlight: Ben Spector '17 Posted by Jesse Polhemus on April 5, 2019 in Socially Responsible Computing by Adi Melamed Click the link that follows for other stories in the Tech for Social Good Spotlight series and more news items about our Socially Responsible Computing program and our innovative and pioneering alums. The Tech For Social Good Spotlight is a series focused on recent Brown Computer Science graduates working at the intersection of computer science and social good. The goal of these interviews is to explore what it means to work in the technology for social good space, what technology for social good might even mean in the first place, and most importantly, share advice for Brown students considering this path. The spotlight is organized by Impact Labs , a student-run organization creating awareness and access to opportunities in the tech for social good space. Ben Spector (Class of \u201817) has a BA in Computer Science and Music. He works as a Lead High School Instructor for Operation Spark , a nonprofit coding bootcamp focused on providing training opportunities for low-opportunity individuals to ease the process of getting software jobs. The following conversation has been edited for length and clarity. What were your past experiences in the CS for Social Good space? My sophomore summer I did an internship at a popular travel website doing software engineering, which was my first experience doing actual software engineering. I really liked the company, and really liked the people I was working with, but I didn\u2019t love the job I was doing. That also came after the year where I was taking CS 32 and CS 33, as well as CS 22... Yeah, so it was just a really intense, full year, followed by the internship and I just felt really burnt out. The next summer I got an internship at one of the big tech companies doing software engineering. I was hoping I would feel a little different about software engineering in general, but pretty much from the moment I got there I realized I didn\u2019t want to be doing software engineering\u2026.I didn\u2019t like the people, I didn\u2019t like working for the company, I didn\u2019t like what I was doing. So during my senior year I was really trying to figure out what exactly I was trying to do. I started taking some more education courses, and I started volunteering with BEAM (Brown Elementary Afterschool Program)...I had worked with kids before, and I always thought that teaching is something that I\u2019d be interested in. ...Then, I don\u2019t remember how I found Venture for America , but it is a fellowship program aimed at getting recent college grads jobs at startups in cities with smaller startup ecosystems. After graduation, I knew I wanted to work at a startup after working at two big companies and I also wanted to work at a company that had some social impact to it. So I got into Venture for America, and then the job hunt phase started: There are over 400 startups you can join, and I was connected to Operation Stark through them\u2026 Operation Spark is really the reason I joined Venture for America\u2026 it checked all the boxes, it was CS and education, and allowed me to teach in a non-traditional teaching environment. What do you enjoy most about working in a social good tech startup? I see education as a way to take my skills and apply them for good. The thing that really turned me off about my internships at the travel site and larger tech company was the fact that I wondered, well definitely at the former, why am I building this website for people to find vacations? I think it\u2019s great, and it\u2019s a great website, and the company itself is amazing, but I felt totally disconnected from what I was doing. At the large tech company it was even worse. I was building this ad search engine, it just felt very disconnected from what I am interested in\u2026 Education is definitely something I want to continue being a part of. Working with kids is really fulfilling. Schools here [in New Orleans] don\u2019t have computer science programs. It\u2019s really cool to provide opportunities for these kids, and seeing them get excited about it is really cool. Being able to build relationships with them is really rewarding. What is your advice for students at Brown interested in pursuing a career in the tech for social good space? My advice would be to take time to look for what\u2019s out there because there are tons of opportunities for people. Part of what everyone knows from going into computer science is that it is a highly sought after, highly marketable skill. Yes, you can make a huge amount of money going to one of these enormous companies, but there are also tons of companies out there that are trying to to use software to make a social impact. You just have to find them. You probably won\u2019t end up making six figures in your initial job, but 99% of people aren\u2019t going to be doing that anyway. I think there\u2019s a little bit of adjusting your expectations that needs to happen... I think if you are really driven to make social change there are a lot of opportunities, and yes you have to look for them, and you may have to make certain sacrifices, but it\u2019s not really a sacrifice if you don\u2019t view it as a sacrifice. You just have to change your perspective on what is expected, particularly at Brown, which is a very elite place. People here have high expectations, people are driven by prestige\u2026 and I think it kind of corrupts what you view as normal. Brown is a place where \u201cnormal\u201d is working at a top 5 bank, consulting firm or tech company, and I think that\u2019s great, but I also think you need to understand that that is not normal. The views and opinions expressed above are those of an individual, and do not necessarily state or reflect those of Brown University or Brown University's Department of Computer Science, nor does their publication here constitute an endorsement of them. For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://cc2007.cs.brown.edu/": "CC 2007 16th International Conference on C ompiler C onstruction A member conference of ETAPS 2007 March 26-30, 2007 Braga, Portugal Program CC is on March 26-27 . People Invited Speakers The CC invited speaker is Don Batory .Additionally, there are two ETAPS invited speakers:Rance Cleaveland and Bertrand Meyer. Program Chairs Shriram Krishnamurthi , Brown University Martin Odersky , Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne Program Committee Eric Allen , Sun Microsystems, Inc. Emery Berger , University of Massachusetts Amherst Rastislav Bodik , University of California, Berkeley William Cook , University of Texas at Austin Chen Ding , University of Rochester Sabine Glesner , Technical University of Berlin Dan Grossman , University of Washington Rajiv Gupta , University of Arizona Andrew Kennedy , Microsoft Research Cambridge Christian Lengauer , University of Passau Cristina Videira Lopes , University of California, Irvine Todd Millstein , University of California, Los Angeles G. Ramalingam , Microsoft Research India Vijay Saraswat , IBM TJ Watson Research Center Zhong Shao , Yale University Yannis Smaragdakis ,University of Oregon Gregor Snelting , University of Passau Joost Visser , Universidade do Minho Reinhard Wilhelm , Saarland University Archival Information Call for Papers CC is interested in work on processing programs in the most generalsense: analyzing, transforming or executing input that describes how asystem operates, including traditional compiler construction as aspecial case. Topics of interest include, but are not limited to: compilation and interpretation techniques , includingprogram representation and analysis, code generation and codeoptimization run-time techniques , including memory management anddynamic and just-in-time compilation programming tools , from refactoring editors tocheckers to compilers to virtual machines to debuggers techniques for specific domains , such as secure,parallel, distributed, embedded or mobile environments design of novel language constructs and theirimplementation The proceedings are published in the Springer LNCS series.Please follow their instructions for manuscript preparation. If you have questions about the suitability of a submission, pleasedon't hesitate to contact the program chairs! Submission Types CC accepts both research papers and tool demonstration papers. Research papers cover one or more of the topicsabove, including reports on tool development and case studies thatfocus on scientific contributions. All such papers should clearlystate the problem under study, propose a solution, and evaluate thesolution. Tool demonstration papers focus on noveland useful tools. Both types of contributions will appear in theproceedings and have oral presentations during the conference. Bothwill be evaluated by the CC Program Committee. All papers must be in English present original work that is unpublished and has not submittedelsewhere (conferences or journals), including other ETAPSvenues be prepared using the Springer-Verlag LNCS style come in PDF format viewable and printable by Acrobat Reader be submitted in full by the date given below Research papers can use a maximum of 15 (fifteen)pages, including figures, bibliography, and appendices. Tool Demonstration papers must consist of two parts: The first part, at most 4 (four) pages, should describe thetool. Please include the URL of the tool (if available) and provideinformation that illustrates the maturity and robustness of the tool.(This part will be included in the proceedings.) The second part, at most 6 (six) pages, should explain how thedemonstration will be carried out and what it will show, includingscreen dumps and examples. (This part will be not be included in theproceedings, but will be evaluated for acceptance.) Submissions that deviate from these parameters will be rejectedwithout review. Dates Submissions due: October 13 , 2006 Acceptance notification: December 8, 2006 Camera-ready papers due: January 5, 2007 CC conference: TBD (between March 26 and 30, 2007) The submission deadline is strict . We will notgrant any extensions.", "https://blog.cs.brown.edu/2020/10/20/read-more-brown-cs-alums-follow-diverse-career-paths/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Read More: Brown CS Alums Follow Diverse Career Paths Posted by Jesse Polhemus on Oct. 20, 2020 From creating a computer camp for girls in Rwanda to founding a company that uses machine learning to produce 3D models based on satellite photos, maps, and laser scans, Brown CS alums are known for career paths that often take them far beyond Silicon Valley, with a particular focus on CS education and socially responsible computing. Click any of the headlines below to read a full story in CS News or CS Blog: Diverse Career Paths: Jonah Kagan Discusses Meaningful Impact Through CS Diverse Career Paths: How Brown CS Alum Edwina Rissland Has Melded Math, CS, And Law Diverse Career Paths: Brown CS Alum Eleanor Tursman's Fellowship Integrates Tech Into Policy Diverse Career Paths: Brown CS Alum Jemma Issroff Works On Ruby And Strives For Ethical Impact Diverse Career Paths: Brown CS Alum Sky Adams Aims To Increase Diversity In K-12 CS Diverse Career Paths: Brown CS Alum Sharon Lo Ponders How Products Can Harm Society Alum Entrepreneurs: Genevi\u00e8ve Patterson Brings AI-Powered Video Editing To Millions Diverse Career Paths: Brown CS Alum Karen Smith Catlin Helps Build Better Allies Brown CS Alum Morgan McGuire Makes An Impact In Academia And Industry Brown CS Alum Thomas Dickerson Helps Replicate Brown In Minecraft For Virtual Visitors Brown Executive Master In Cybersecurity Alum Ernesto Zaldivar Is A Finalist For The Bracken Bower Prize Brown CS Alum Evan Wallace Has Been Named An INC 2019 Rising Star Brown CS Alum Victoria Ch\u00e1vez \u201818 Makes An Impact On The Rhode Island Community Alum Aimee Lucido Publishes A Novel About Her Two Loves, Coding And Writing BAM Asks Two Alums About A Startup Dedicated To Ethical CS Brown CS Alum danah boyd Wins An Electronic Frontier Foundation Pioneer Award Look Where Our 2019 Graduates Are Headed! Tech For Social Good Spotlight: Ruby Goldberg '17 Tech For Social Good Spotlight: Priya Patel '16 Tech For Social Good Spotlight: Ben Spector '17 Alums In Academia: Brown CS Alum Michael Horn Makes An Impact On The Learning Sciences Field Alum Adventures: Brown CS Alums David Simons, Daniel Wilk, And Michael Natkin Have Won An Academy Award For Work On Adobe After Effects danah boyd Has Been Named Among Forbes Top 50 Women In Tech Mentor Alum: Deb Mills-Scofield Inspires And Empowers Brown Students Tellex's Outreach Inspires A High School Student To Study CS, Then Teach Alum Adventures: Harry Li Helps The Chan Zuckerberg Initiative Improve K-12 Education A Member Of The First EMCS Cohort Wins Brown's Master's Award For Professional Excellence Artemis Project Alum Nirva LaFortune Advocates For Her Community On The Providence City Council Alum Tushar Bhargava Wins A 2017 Undergraduate Award For Work With Tim Edgar Brown CS Alum James Hendler Has Been Honored By The Association Of Moving Image Archivists Geopipe, Co-Founded By Thomas Dickerson, Wins $100K At The NYU $300K Entrepreneurs Challenge Brown CS Alum Hoon Ik Chang Has Been Named A 2017 Schwarzman Scholar The Atlantic Features Brown CS Alum Lyla Fujiwara's Use Of CS In The Peace Corps Brown Alumni Magazine Features CS Alum Scott Anderson TechCrunch Features Former Student Dylan Field's Design Collaboration Tool, Figma Brown CS Alum Masi Oka '97 Returns To \"Hiro\" Role In Upcoming Series Alum Update: Sunil Mallya '11 Brown CS Alum Michael Horn '97 Wins An NSF Grant To Bring Programming To Museums And Homes Artemis Alum Keeps Looking For Opportunities To Code", "https://ccmb.brown.edu/": "Skip to Main Content Brown University Data Science Insitute Center for Computational Molecular Biology Search Menu Site Navigation Home Academics Graduate Program Undergraduate Program Courses People Contact & Administration Core Members Affiliate Members Postdocs Graduate Students Ph.D. Alumni Becoming an Affiliate NIH Graduate Training Program T32 Trainees T32 Faculty Trainers Gallery News & Events Software CCMB's 20th Anniversary SorinFest Search Data Science Insitute Center for Computational Molecular Biology CCMB Celebrating 20 years of promoting the development, implementation, and application of analytical and computational methods to foundational questions in the biological and medical sciences CCMB Celebrating 20 years of promoting the development, implementation, and application of analytical and computational methods to foundational questions in the biological and medical sciences The prime intellectual mission is to promote the development, implementation, and application of analytical and computational methods to foundational questions in the biological and medical sciences. The research programs of the Core Faculty in CCMB lie fundamentally at the intersection of computer science, evolutionary biology, mathematics, and molecular and cellular biology. Biological questions Biological questions that currently unite the CCMB Core and Associate Faculty are: How do genotypes and genes interact to produce phenotypes, and how does this happen from womb to tomb? What drives the formation, maintenance and evolutionary transformations of communities of organisms over time? Quantitative questions that currently unite the CCMB faculty are: how can we design powerful algorithms to make sense of the sea of data produced in the genomic era? What principles are required for a theoretical framework to completely model cellular systems? Research challenges The research challenges at the heart of CCMB are a rich source of mathematical problems motivated by the complex nature of genomes, disease processes and evolutionary relationships. These challenges are both multi-scale (with units of interest ranging from molecules to communities of organisms) and large-scale (data-intensive, due to advances in sequencing technologies). Explore CCMB Undergraduate Program Visit Page Open details for Undergraduate Program Graduate The Center for Computational Molecular Biology (CCMB) offers Ph.D. degrees in Computational Biology to train the next generation of scientists to perform cutting-edge research in the multidisciplinary field of Computational Biology. Visit Page Open details for Graduate Contact & Administration Contact information, mailing address and directions. Visit Page Open details for Contact &amp; Administration NIH Graduate Training Program The Predoctoral Training Program (T32) in Biological Data Science is funded by the National Institutes of Health/NIGMS award T32GM128596 Visit Page Open details for NIH Graduate Training Program Partnering CCMB rounds out the broader landscape of research in methodological development at Brown University by partnering with and complementing: Data Science Institute Brown Center for Biomedical Informatics COBRE Center for the Computational Biology of Human Disease https://www.youtube.com/embed/p3zBdW-ENtU Ph.D. program in Computational Biology Stay Connected X/Twitter Brown University Providence RI 02912 401-863-1000 Quick Navigation Visit Brown Campus Map A to Z Contact Us Footer Navigation News Events Campus Safety Accessibility Careers at Brown The campaign for building on distinction Give To Brown \u00a9 Brown University Brown University For You Search Menu Mobile Site Navigation Mobile Site Navigation Home Academics Graduate Program Undergraduate Program Courses People Contact & Administration Core Members Affiliate Members Postdocs Graduate Students Ph.D. Alumni Becoming an Affiliate NIH Graduate Training Program T32 Trainees T32 Faculty Trainers Gallery News & Events Software CCMB's 20th Anniversary SorinFest This Site Only All of Brown.edu People Search Search people Advanced Search Search Close Search CCMB Open details for CCMB Bookmark this Page var WWW_ROOT = \"/\"; var STATIC_ROOT = \"/themes/custom/brown/static/\";", "https://blog.cs.brown.edu/2020/12/11/diverse-career-paths-brown-cs-alum-karen-smith-catlin-helps-build-better-allies/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Diverse Career Paths: Brown CS Alum Karen Smith Catlin Helps Build Better Allies Posted by Jesse Polhemus on Dec. 11, 2020 in Diversity Click the links that follow for more news about Karen Smith Catlin , recent accomplishments by Brown CS alums , and their diverse career paths . \u201cSomething about Brown CS influenced me,\u201d says alum Karen Smith Catlin, whose distinctive career path has taken her from working at Brown\u2019s Institute for Research in Information and Scholarship (IRIS) to Vice-President of Engineering at Adobe to a new phase as acclaimed author and speaker on inclusive workspaces. \u201cIt\u2019s a fearlessness and an idealism that says, \u2018If not us, then who? Let\u2019s get this done.\u2019 When you graduate with a CS degree from Brown , nobody can take that credibility away from you. That opened a lot of doors for me.\u201d So much of Karen\u2019s career has focused on mentorship and positive connection between people that her advice to students looking for a more unusual career may come as no surprise: \u201cReach out to the people you might want to talk to! Get their insight and think about different product spaces, different applications of technology. Be curious. Learn about possibilities.\u201d Brown was the only institution that Karen, a self-described crafter and maker who was good at math and loved puzzles, applied to after high school. She took on a CS concentration with no prior computing experience whatsoever. \u201cMy father had been hearing a lot about computer science and thought I\u2019d enjoy it,\u201d she remembers. \u201cIt seemed like fun and I thought it\u2019d allow me to support myself. I came from modest means, so that was important.\u201d Starting out with what was Professor Andy van Dam\u2019s CS 11 at the time (now CSCI 0150 ), Karen hadn\u2019t expected to be enthralled: \u201cThe community was amazing. It was hard, and I struggled, but I loved it.\u201d When Andy began devoting more of his time to educational computing, Karen became one of the first developers for the Brown ALgorithm Simulator and Animator (BALSA), a cutting-edge electronic classroom, running software that demonstrated introductory concepts. Educational software became a passion, and she used a group independent study program with Elisabeth Waymire and Janine Roeth to create a new seminar class. \u201cIt was the first of its kind,\u201d Karen says, \u201can entire curriculum around educational software with readings, guest speakers, and design projects. What thrilled me was that other students continued the Educational Software Seminar for more than a decade after we graduated \u2013 just a great leveling-up of collective knowledge.\u201d In her last summer before graduating, Karen continued her interest in applied research with a job at IRIS, a new group at Brown that focused on hypertext and combining object-oriented programming with modern user interface technology. \u201cThis was long before today\u2019s browsers,\u201d she says, \u201cand it makes me happy that our work had an influence on HTML and the Internet that followed.\u201d Happy to be coding for a living, she signed on full-time with IRIS after graduating and stayed with the organization for a half-decade. Was all of this something that she\u2019d anticipated? \u201cI never had a five-year plan,\u201d Karen says. \u201cThe landscape changes so frequently \u2013 five, ten, and let alone 35 years ago, many of us couldn\u2019t have predicted the careers we have now. My best advice is to make sure your work aligns with your values. Stay agile while following your interests.\u201d Eventually, an economic downturn caused a funding shortage for IRIS, and Karen and her husband moved to England, where he\u2019d grown up. But it felt like a move to the service sector after years of doing cutting-edge research, and Karen put California in her sights. It was 1991, and Silicon Valley was the absolute center of the technology world. She found a job at GO Corporation, a pen-based computing pioneer whose OS predated even Apple\u2019s early Newton tablet by two years. \u201cAt that point,\u201d Karen admits, \u201cI was intimidated by the myth of Silicon Valley engineers. Even with my strong background in advanced object-oriented programming from Brown, I had impostor syndrome.\u201d Instead of creating apps, she took a job writing documentation on how to create them, writing sample code. A few years later, a startup called Macromedia beckoned, and Karen began working in their localization department. It was project management at its finest, she says, and she built a reputation for being someone who partners well with different project teams, eventually founding their usability testing and product security groups. When Macromedia was bought by Adobe, she continued to move up the ranks, ending up as Vice-President of Engineering. It was during her Adobe days that Karen first attended the Grace Hopper Celebration of Women in Computing. \u201cIt was still small then,\u201d she remembers, \u201cbut I wish I\u2019d been involved years before.\u201d She returned to work with new energy, quickly founding a women\u2019s employee resource group at Adobe, where she helped equip women for career success. Mentorship quickly became a new love. It\u2019s what truly made her happy, Karen says, more than her ascent to the top echelons of the company. And so she did a career pivot and started a business as a leadership coach. \u201cI left tech,\u201d she says, \u201cbut not innovation, not that mindset. Instead of building software myself, I wanted to help women who are doing it. I still feel that way today.\u201d But she soon realized that there was a problem: companies that thought of themselves as meritocracies really weren\u2019t, and her role as coach didn\u2019t feel like enough. Reform was needed to bring about real inclusivity, and as Karen contemplated her next step, she settled on the word allies to reflect a new trend of men taking action in support of diversity. Her initial focus was on male allies, but when she found that a hoped-for Twitter handle had already been taken, she realized that @BetterAllies was a superior choice, and the Better Allies Initiative was born: \u201cIt\u2019s not just something that men can do \u2013 anyone with privilege and power can use it on behalf of others. For example, as a white woman I can help Black women, and as a straight woman I can advocate for LGBTQ-friendly policies.\u201d The initial premise of the Better Allies Initiative was to share everyday actions that anyone could take to be a better ally for someone in a historically underrepresented group (HUG). It proved popular, and public speaking requests began flowing in. \u201cAnd almost every time I spoke,\u201d Karen says, \u201csomeone in the audience would ask if I had a book, because they wanted more.\u201d She published Better Allies: Everyday Actions to Create Inclusive, Engaging Workplaces in 2019 (a second edition is due out in January) and a companion volume, The Better Allies Approach to Hiring , followed a year later. Two years later, the work continues. Asked for her latest thoughts on how our field can improve gender diversity, Karen cites the importance of expectations. \u201cWhen parents buy toys or send kids to summer camp,\u201d she says, \u201cthey\u2019re making decisions on their child\u2019s behalf, and \u2018I don\u2019t think my daughter would like to code\u2019 might be one of them. As parents, we can do more: we can tell our young women to try tech on for size. There are also societal expectations about what girls should be good at. In Turkey, female computer scientists outnumber the men. Why can\u2019t that be us?\u201d But given the events of 2020, is she still hopeful for societal change? \u201cThere\u2019s a shift toward equity and social justice that I\u2019m optimistic about,\u201d Karen says. \u201cWhatever the area, I\u2019m seeing an appetite for individuals wanting to take action in a way that wasn\u2019t there years ago. In tech, some of this is because men are finally listening to all the stories of discrimination that have been shared. Anti-racism books are at the top of the bestseller lists, and people are voting in record numbers. But they\u2019re saying that diversity and inclusion statements aren\u2019t enough. We\u2019re all demanding to see results, the impact.\u201d As we start to wrap up, Karen lights upon an unexpected topic that ties together multiple threads of her work and life. \u201cI firmly believe,\u201d she says, \u201cthat public speaking is a multivitamin for any career. My first exposure to it was as a UTA, getting up in front of a class. I started my career writing code, and on my way to becoming a VP, I got the stage fright that most people get. Later, I was told that the best way to start a coaching business was to go out and talk from your own experience, so I started doing a lot of public speaking, even though I hated it.\u201d \u201cBut when you get comfortable talking to others,\u201d says Karen, \u201cyou get visibility for what you do that could otherwise get missed. One of the reasons I wrote my book Present! A Techie\u2019s Guide to Public Speaking was to help everyone improve their public speaking skills and to make sure that women and people from HUGs are getting the information that I got. I want them to be onstage, getting the visibility they deserve, so we can keep disrupting the stereotypes about who belongs in our industry.\u201d For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://blog.cs.brown.edu/2024/02/01/brown-daily-herald-meets-csci-0150s-new-ai-powered-chatbot-teaching-assistant/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) The Brown Daily Herald Meets CSCI 0150's New AI-Powered Chatbot Teaching Assistant Posted by Jesse Polhemus on Feb. 1, 2024 Click the links that follow for more news about CSCI 0150 , Andy van Dam , our Undergraduate Teaching Assistants (UTAs), and other recent accomplishments by our faculty and students . \u201cIf you don't know the fundamentals,\" says Andy van Dam , Thomas J. Watson, Jr. University Professor of Technology and Education and Professor of Computer Science at Brown University , \"you can't debug what the (generative AI) produces.\" In a new article by Leah Koritz, The Brown Daily Herald interviews Andy and CSCI 0150 Introduction to Object-Oriented Programming and Computer Science UTA Brandon Diaz about their decision to create GPTA, a chatbot teaching assistant for the course. The full story is available here . For more information, click the following link to contact Brown CS Communications Manager Jesse C. Polhemus .", "http://conifer2.cs.brown.edu:8180/S6Search/s6search.html": "", "https://blog.cs.brown.edu/search/?q=tellex": "(function() { var cx = '31714722c428aaf23'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://ccmb.brown.edu/software": "Skip to Main Content Brown University Data Science Insitute Center for Computational Molecular Biology Search Menu Site Navigation Home Academics Graduate Program Undergraduate Program Courses People Contact & Administration Core Members Affiliate Members Postdocs Graduate Students Ph.D. Alumni Becoming an Affiliate NIH Graduate Training Program T32 Trainees T32 Faculty Trainers Gallery News & Events Software CCMB's 20th Anniversary SorinFest Search Data Science Insitute Center for Computational Molecular Biology Software Software CCMB Research is interdisciplinary involving interactions between faculty, students, and postdoctoral researchers in multiple participating departments. Several of the research groups develop software for biomedical researchers. Themes Algorithms, Statistics, & Computation RNA Biology & Epigenetics Evolutionary & Ecological Genomics Genomics of Human Disease Labs Crawford Lab - Marginal Epistasis Test Fairbrother Lab - Spliceman Istrail Lab Lawrence Lab Raphael Lab Brown University Providence RI 02912 401-863-1000 Quick Navigation Visit Brown Campus Map A to Z Contact Us Footer Navigation News Events Campus Safety Accessibility Careers at Brown The campaign for building on distinction Give To Brown \u00a9 Brown University Brown University For You Search Menu Mobile Site Navigation Mobile Site Navigation Home Academics Graduate Program Undergraduate Program Courses People Contact & Administration Core Members Affiliate Members Postdocs Graduate Students Ph.D. Alumni Becoming an Affiliate NIH Graduate Training Program T32 Trainees T32 Faculty Trainers Gallery News & Events Software CCMB's 20th Anniversary SorinFest This Site Only All of Brown.edu People Search Search people Advanced Search Search Close Search Software Open details for Software Bookmark this Page var WWW_ROOT = \"/\"; var STATIC_ROOT = \"/themes/custom/brown/static/\";", "https://blog.cs.brown.edu/2024/02/02/more-100-brown-cs-utas-start-semester-dodgeball-tournament/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) Brown CS UTAs Start The Semester With A Dodgeball Tournament Posted by Jesse Polhemus on Feb. 2, 2024 At Brown CS , the undergraduate teaching assistant (UTA) program is unlike any other. It employs more than 400 undergraduates each semester, and each of these students is given the chance to effect change, working closely with the professor, other UTAs, and other students. Last month, when this semester's UTAs returned to campus for TA Camp, which helps prepare them for their work ahead, the Meta TAs who supervise the program held a dodgeball tournament. More than 100 UTAs took part. \"It was a really fun way to give the UTAs an opportunity to get some energy out while working hard during camp!\" says Meta TA Tyler Gurth, \"I think the competition demonstratres a lot of the energy, positivity, and fun in the UTA program.\" At the end of the tournament, the staff of CSCI 0220 Discrete Structures and Probability was declared the winners. For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "https://cs.brown.edu/": "Brown CS Students Earn CRA Outstanding Undergraduate Researcher Honors The Telepresence Of Furniture In Extended Reality CHM's 40th Anniversary Celebration For The Macintosh Includes A Brown CS Shoutout Nora Ayanian Will Present Swarming Drones At SXSW 2024 Brown CS PhD Student Eric Ewing Helps Multi-Robot Research Lift Off At Brown And Beyond Introductory Courses Customized for students of all interests Undergraduate Program Numerous opportunities to contribute to research and teaching Master's Programs Computer Science and Cybersecurity degrees PhD Program Strong research with low student-faculty ratios Brown CS Blog Brown CS PhD Candidate Ji Won Chung Implements A Sleep Regularity Index In A Popular Sleep Tracker The Telepresence Of Furniture In Extended Reality The Computer History Museum\u2019s 40th Anniversary Celebration Of The Macintosh Includes A Shoutout To Brown CS Awards Four Brown CS Students Receive CRA Outstanding Undergraduate Researcher Honors John Hughes Ranks In The Top 0.21% Of Stack Exchange\u2019s Math Users Brown CS Student Mattie Ji Is A Runner-Up For The Schafer Prize For Excellence In Mathematics By An Undergraduate Woman Events Rachit Nigam: Modular Abstractions for Hardware Design Tue, 3/12 12PM, 368, CIT Konstantinos Kallas: Programmable Software Systems for Correct High-performance Applications Wed, 3/13 12PM, 368, CIT Computational Infrastructures for Consolidating our Knowledge Regarding the Human Genome Wed, 3/13 4PM, Rm 302, None Brown CS News Brown CS PhD Candidate Ji Won Chung Implements A Sleep Regularity Index In A Popular Sleep Tracker Nora Ayanian Will Present Swarming Drones At SXSW 2024 Brown CS PhD Student Eric Ewing Helps Multi-Robot Research Lift Off At Brown And Beyond", "https://blog.cs.brown.edu/2024/02/27/the-computer-history-museums-40th-anniversary-celebration-of-the-macintosh-includes-a-shoutout-to-brown-cs/": "Brown CS Blog Categories Awards ( 23 articles ) Diversity ( 71 articles ) Socially Responsible Computing ( 15 articles ) The Computer History Museum\u2019s 40th Anniversary Celebration Of The Macintosh Includes A Shoutout To Brown CS Posted by Jesse Polhemus on Feb. 27, 2024 by Norm Meyrowitz \u201881 On January 24 of 2024, I attended the Computer History Museum (CHM)\u2019s huge celebration in Silicon Valley for the 40th anniversary of the launch of the Apple Macintosh, where Brown CS got a shoutout during the two-hour program. Why would that be? I thought it would be interesting to those who weren\u2019t around to learn about how universities \u2013 Brown in particular \u2013 were instrumental to the success of the computer that many now take for granted. Today, virtually all of Brown's current undergraduates and a good number of current faculty and staff don't think twice about the introduction of personal computers, especially Macintoshes, any more than they think about the invention of televisions or microwave ovens \u2013 they just have always been around. Contrast that to faculty, staff, and alums who were at Brown more than 40 years ago, who inhabited a world where Macintoshes did not yet exist and a campus where most computing was done through \u201cdumb terminals\u201d dialed into the campus mainframe. On January 24, 1984, that changed. Apple introduced the first mass-market personal computer with a graphical user interface. For most of the world, it was astonishing. It had a mouse, which virtually no one had seen or even heard of. Most other personal computers of the time had screens that only printed characters in a matrix of 24 lines of 80 characters each, while the Macintosh allowed one to draw graphics at a resolution of 512 x 342. Apple did not have the ironclad security \u201cwe don\u2019t tell anyone anything before launch\u201d policy they have today; they often gave sneak peeks of future products in advance of launch. Dan\u2019l Lewin, the Sales and Market Development Manager for the Macintosh and Mike Murray, its Vice-President of Marketing, explained to the audience at the CHM celebration that they first sneaked to the Mac to New York City business executives in a formal focus group. How did it work? First, the execs used their familiar IBM PCs and then were given a pre-launch Mac to try. The hardened business people started giggling at how much fun they were having. To wrap up, a focus group leader asked them: which was easier to use? Mac. Which was more productive? Mac? Which was more effective? Mac! What will you recommend your purchasing department buy? IBM PCs. Dan\u2019l and his colleagues realized that the product was going to fail if they relied on big corporations to be early adopters. They had noticed when they tested the Mac on friends and family that those who were creative and artistic were captivated by what they could do with it. So where did Dan\u2019l and colleagues go to find a concentration of those types of folks? Universities! So in the fall of 1983, Andy van Dam, the late Bill Shipp (Associate Provost of Computing), Tom Doeppner, Provost Maurice Glicksman, and I (and a few others that can\u2019t be recalled) were some of the lucky few who got to take an early look at the Mac \u2013 in all of its original 128 K (yes, K!) of RAM splendor. This didn't involve flying out to Cupertino. This involved three folks from Apple: Andy Hertzfeld \u201875 (referred to as AndyH henceforth), one of the key members of the Mac development team and former student of Andy\u2019s), Dan\u2019l, and none other than Steve Jobs himself . Why was this visit important enough for Steve Jobs to visit? Brown was one of the three schools that were widely known as leaders in putting computers and networks across the campus \u2013 the other two were Carnegie Mellon University and Massachusetts Institute of Technology. Andy had a reputation for his work in graphics, so Steve thought it would be a trip worth taking (Brown was the only school he visited). Brown CS had a lab full of Apollo workstations with bitmap screens and a much less polished interface than the Mac and cost $35,000 ($110,000 today). The Brown folks who saw the sneak peek of the Macintosh that day were uniformly blown away by the price ($2,495 - $7,000 in today\u2019s dollars) and functionality even though they had seen Xerox PARC Alto workstations and their successors, so they knew what state-of-the-art WIMP (windows, icons, mouse, pointer) interfaces looked like. And Universities would get a discount off the Mac list price! In true Andy style, after singing the praises of the Mac, he told Steve that the machine wouldn\u2019t be useful without a hard disk or network. (The original Mac had just a single drive for a 400 KB (yup, that\u2019s K again!) removable diskette. Part of the system software and some apps were on the diskette, so if you wanted to use an app or store documents on another disk, the current disk would be ejected so you could put the other one in. When the operating system needed more code to continue running, that disk was ejected so you could put the system disk back. This sometimes led to absurd situations similar to thrashing in virtual memory \u2013 you would pop one disk in and it would be used for 5 seconds, then ejected so you could put the other disk in for 5 seconds, and then that was ejected, ad infinitum. Andy called this \u201cmilking\u201d, since it appeared that one was treating the Mac like a cow, albeit one lying on its side. As one might expect, Steve preferred praise to criticism. He and Andy went back and forth, with Steve saying something to the effect of \u201cpeople don\u2019t need a network, they\u2019ll just pass diskettes back and forth \u2013 SneakerNet is just fine\u201d. Lo and behold, Apple soon came out with a hard disk and a network. AndyH told me that the network hardware had already been completed before Andy and Steve had their tete-a-tete, but the software wasn\u2019t ready at launch, so Steve pooh-poohed the entire notion of networks. Steve had a habit of dismissing anything Apple didn\u2019t yet have as stupid or useless. After my time at Brown, in a meeting Macromedia had with Steve when the touch-screen iPod came out but before touch-based phones, I said to him, \u201cYou should make this into a phone.\u201d Steve replied that Apple would never, ever, ever make a phone, that the carriers were just too hard to deal with. The iPhone launched soon after, so either he changed his mind and had the fastest hardware and software development in history or it was already in process. After the meeting, the Provost took Andy aside and said he had never seen two people go at it as vehemently as Andy and Steve. Andy told him not to worry, that they were both enjoying it. Soon, Dan\u2019l and his crew formally created the Apple University Consortium, a group of 24 schools that would be the key to the Mac\u2019s initial success, with Brown amongst the first. Those schools all pledged that they would buy $2M worth of Macs over three years. Andy, Bill, and I went about getting approval from Howard Swearer, Brown\u2019s President at the time, to start an effort that would put computers across campus \u2013 Macs and IBM workstations \u2013 and raising $15M to make it happen. President Swearer signed off on the $2M deal with Dan\u2019l. Both Swearer and Dan\u2019l were Princeton grads, and Swearer said that since he was a Princeton man with Brown furniture, then Dan\u2019l should have the same, and the President sent Dan\u2019l a Brown-crested spindle chair that he still has. Today, it seems incomprehensible that there was a point in time when nobody had a Mac, but without the help of Brown and other universities, the Macintosh might not still exist. Brown CS\u2019s pre-introduction support of the Macintosh was important and memorable enough that it was called out in particular during a two-hour 40th anniversary celebration that included most of the original Mac team and hundreds of other industry and press luminaries. So, the next time you\u2019re using your MacBook Pro or iMac, remember that you\u2019re part of the lineage that helped move the Macintosh from obscurity to ubiquity.", "https://cs.brown.edu/~mlittman/": "Forwarding...", "https://blog.cs.brown.edu/search/?q=bootstrap": "(function() { var cx = '31714722c428aaf23'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://cs.brown.edu/~mph/": "Maurice Herlihy An Wang Professor of Computer Science mph@cs.brown.edu CIT 341 Bio Maurice Herlihy has an A.B. in Mathematics from Harvard University, and aPh.D. in Computer Science from M.I.T. He has served on the faculty of CarnegieMellon University and the staff of DEC Cambridge Research Lab. He is therecipient of the 2003 Dijkstra Prize in Distributed Computing, the 2004 G\u00f6delPrize in theoretical computer science, the 2008 ISCA influential paper award,the 2012 Edsger W. Dijkstra Prize, and the 2013Wallace McDowell award. He received a 2012 Fulbright Distinguished Chair in theNatural Sciences and Engineering Lecturing Fellowship, and he is fellow of the ACM, a fellow of the National Academy ofInventors, the National Academy of Engineering, and the National Academy ofArts and Sciences. In 2022, he won his third Dijkstra Prize. CV ACM author profile Google Scholar Profile Selected Talks PODC 2017 Keynote: Blockchains and the Future of DistributedComputing . Undergraduate course on Blockchains and Cryptocurrencies CS176: MultiprocessorSynchronization 2011course on Combinatorial Topology and Distributed Computing (YouTube) 2011 FulbrightDistinguished Chair lecture (YouTube) 2004G\u00f6del Prize lecture (slides) Books TheArt of Multiprocessor Programming ( Courseslides ) DistributedComputing Through Combinatorial Topology ( Courseslides )", "https://cs.brown.edu/~rfonseca/": "Rodrigo Fonseca Top News Teaching Research Students Publications Service Personal email office 329, CIT Building. Office hours by appointment. mail Box 1910, Brown University 115 Waterman St Providence , RI 02912 phone 401-863-6533 (voice) 401-863-7657 (fax) DBLP \u2022 Google Scholar \u2022 MSFT Academic Search About I am an associate professor at Brown University 's Computer Science Department . My work revolves around distributed systems, networking, and operating systems. Broadly, I am interested in understanding the behavior of systems with many components for enabling new functionality, and making sure they work as they should. In particular, I'm interested in how to build, operate, and diagnose large scale Internet systems; and in networking and power management in embedded distributed systems such as sensor networks. I'm updating this page. Take a look at my CV for the authoritative information. News Feb-2020 I'm starting as a Principal Researcher at Microsoft Research Nov-2019 I'm the General Chair for SoCC'2020! Stay tuned. Nov-2019 Was PC co-chair for HotNets 2019 , with Sylvia Ratnasamy. The workshop was a big success! May-2019 Congratulations to Dr. Da Yu, PhD #5! Going to Microsoft, to work on Azure Networking. May-2019 Congratulations to Dr. Jeff Rasley, PhD #4! Going to Microsoft, to work on AI Infrastructure at Bing. Jan-2019 Going for an 8-month visit to Microsoft Research in Redmond, WA! Oct-2018 New NSF grant: Network-centric IoT Security, with Theo Benson May-2018 Congratulations to Dr. Jonathan Mace , PhD #3! He is starting as a tenure track faculty at MPI-SWS! Oct-2017 Keynote at The 17th International Conference on Runtime Verification, RV\u201917. Seattle, WA Jul-2017 Now Associate Professor with Tenure! Jun-2017 Busy summer: I'll be spending the summer in Palo Alto, with Flowtune . Jeff will be at MSR in Seattle, Da at Alibaba, Seattle, and Jon at Facebook in Cambridge Apr-2017 Congratulations to Dr. Marcelo Martins, PhD #2! Mar-2017 NSDI Test of Time Award for X-Trace! With George Porter, Ion Stoica, Scott Shenker, and Randy Katz! Nov-2016 Switches are Monitors Too! presented at HotNets Oct-2016 Raja presented our paper 'Principled Workflow-centric Tracing of Distributed Systems' at SoCC. Aug-2016 Went to Floripa, Brasil for Sigcomm. We had a paper at the main conference, a paper in the Workshop on QoE, and I gave an invited talk at NetPL. May-2016 cDVD, on fair bandwidth allocation for competing DASH video streams, accepted at Internet-QoE 2016! Apr-2016 2DFQ accepted to Sigcomm 2016, which will be in Brazi! Apr-2016 Teaching Networking in the Fall! Apr-2016 NetEx [pdf] , our architecture for a network marketplace inside of a datacenter, accepted for HotCloud ! Feb-2016 Teaching Distributed Systems with Tom Doeppner Jan-2016 Yak, joint work with my student Jeff Rasley and Microsoft, accepted into Eurosys 2016! Oct-2015 Pivot Tracing gets best paper award at SOSP! Oct-2015 Presented \"We are Tracing like it's 1973\" [ pptx ] at the Open Zipkin workshop in San Francisco Sep-2015 Presented ' We are Losing Tack: a Case for Causal Metadata in Distributed Systems ' at the 16th Asilomar HPTS May-2015 Good Summer looking ahead: Jeff and Jonathan will have internships at Microsoft Research, Da will go to HP Labs May-2015 Jonathan will be presenting our work \"Retro: Targeted Resource Management in Multi-tenant Distributed Systems\" at NSDI 2015 ! This is join work with Peter Bodik and Madan Musuvathi from Microsoft Research. Apr-2015 Our paper \"Simon: Scriptable Interactive Monitoring for SDNs\", accepted at SOSR'15 ! Joint work with Da Yu , Yiming Li, Tim Nelson , and Shriram Krishnamurthi . Apr-2015 Our paper \"Exodus: Toward Automatic Migration of Enterprise Network Configurations to SDNs\" accepted at SOSR'15 ! Joint work with Tim Nelson , Andrew Ferguson, and Shriram Krishnamurthi . Apr-2015 Marcelo 's paper \"Selectively Taming Background Android Apps to Improve Battery Lifetime\" accepted at USENIX ATC, joint work with Justin Cappos . Mar-2015 Won an NSF CAREER Award on \"Understanding the Performance of Distributed Systems Through Causal Tracing\" Feb-2015 Teaching CS-138 Distributed Systems with Tom Doeppner. Oct-2014 Co-organizing the first New England Networking and Systems Day , Oct 24th, at the Hariri Institute at BU. We will gather more than 90 participants with many talks, posters, and much discussion time. Sep-2014 I recently documented (in Portuguese) an attack to a bank website in Brazil that got some media attention Sep-2014 The Brown-Brazil Initiative is hosting my former advisor Prof. Virgilio Almeida for the innaugural talk of the Fall Lecture Series. Sep-2014 Our paper \" Towards General-Purpose Resource Management in Shared Cloud Services \" (with my PhD student Jon Mace , Peter Bodik , and Madan Musuvathi ) was accepted for publication at HotDep'14, the 10th Workshop on Hot Topics in System Dependability! Sep-2014 Teaching Computer Networks this fall! Aug-2014 Jeff Rasley successfully presented \"Planck: Millisecond-scale Monitoring and Control for Commodity Networks\" at Sigcomm 2014. Apr-2014 Our paper \"Planck: Millisecond-scale Monitoring and Control for Commodity Networks\" was accepted for publication at Sigcomm 2014. See you in Chicago! Apr-2014 Very proud of my first minted PhD student, Andrew Ferguson . Congrats, Andrew! Mar-2014 Jeff Rasley will be interning at VMWare, and Marcelo at Intel. Feb-2014 Teaching Advanced Networking as a special topics class, focusing on Datacenter Networking and SDNs. Jan-2014 I'll be part of the Program Committees for Sigcomm 2014 and IMC 2014! Dec-2013 I'm part of the Program Committee for HotMobile 2014! July-2013 NSF NeTS Grant on Participatory Networking, to advance SDNs northbound APIs! July-2013 Our paper \"Growth Analysis of a Large ISP\" was accepted at IMC ! May-2013 Highly successful internship season for students! Andrew is going to the SDN group at Google (with Amin Vahdat), Jeff is going to IBM Research in Austin (with Collin Dixon), Jonathan is going to MSR Redmond (with Peter Bodik)! Apr-2013 We are going to Sigcomm 2013 to present our paper on Participatory Networking ! Congrats to Andrew Ferguson, Arjun Guha, Chen Liang, and Shriram Krishnamurthi! Apr-2013 Chen Liang accepted as a PhD student at Duke University! Congrats, Chen! Jan-2013 Teaching Advanced Networking as a special topics class, focusing on Datacenter Networking and SDNs. Dec-2012 Our paper \"Application Modes\" accepted for publication at HotMobile 2013 ! Sep-2012 Big welcome to Jeff Rasley (new PhD student), Jonathan Mace (new advisee), and Matheus Caldas (visiting PhD student from UFMG, Brazil)! Sep-2012 Teaching CS168, Computer Networks this spring. Jul-2012 Spending the summer at MSR Redmond, with Victor Balh's group Jul-2012 Our paper PARMA: A Parallel Randomized Algorithm for Approximate Association Rule Mining in MapReduce accepted at CIKM 2012! Jun-2012 Program Committee Member for NSDI'13! May-2012 Our paper Hierarchical Policies for Software Defined Networks accepted for publication at the HotSDN 2012 workshop, co-held with Sigcomm 2012! Apr-2012 Nathan's paper C-MR: Continuously Executing MapReduce Workflows on Multi-Core Processors accepted for publication at the MAPREDUCE 2012 workshop! Apr-2012 Andrew presented Jockey: Guaranteed Job Latency in Data Parallel Clusters at Eurosys 2012 . Work with Srikanth Kandula and Peter Bod\u00edk from Microsoft Research. Mar-2012 Our paper Participatory Networking accepted for publication at HotICE'12 , co-held with NSDI'12. Mar-2012 External Review Committee Member for OSDI 2012! Feb-2012 Google funds research on distributed tracing! Sep-2011 Teaching CSCI2950-U in Fall 2011, focusing on Large-scale data intensive computing Jul-2011 I will be co-chairing HotClouds'12 with Dave Maltz, from MSR! May-2011 Solomon Award from Brown University to work on energy managdtent in Wireless Sensor Networks! Sep-2010 NSF funds research on security in Cloud Computing . Jun-2010 Program committee for NSDI'11 ! Jun-2010 Intel funds research on 'Whole-platform Energy Usage of Software Activities' Jun-2010 Andrew's poster on block placdtent in Hadoop accepted at the USENIX ATC May-2010 Teaching CSCI1680 'Computer Networks' in Spring 2011 May-2010 Teaching CSCI2950-U 'Special Topics on Networking and Distributed Systdts' in Fall 2010 Apr-2010 Experiences with X-Trace paper presented on INM/WREN 2010 More... Teaching Fall 2019 CSCI1680 Computer Networks . Previous: F'16 , F'16 , F'16 , F'14 , F'12 , S'12 , S'11 Spring 2018 CSCI1380 Distributed Systems . Previous: S'17 S'15 Spring 2017 Advanced Networking . Previous: S'14 - CSCI2950-U Advanced Networking: SDNs and Datacenter Networking , S'13 , F'11 , F'10 , F'09 Research Projects Participatory Networking The PANE project aims to allow end-user applications to help in the configuration of a network. PANE is both a paradigm and a prototype SDN controller that solves the problem of privilege delegation and conflict resolution when unprivileged users are given read and write access to network services, configuration, and state. Read more... Mobile Device Energy We are interested in improving the battery life of mobile devices. Today's mobile devices' need for energy far surpasses their battery capacity to allow for unrestricted use and long battery life. Users must prioritize their usage to avoid running out of battery. However, for a user to do this efficiently is almost impossible: it requires knowledge of the energy and power characteristics of the applications and of the hardware components of the particular phone. This leads to a poor experience and to frustration. We propose an OS abstraction, Application Modes, that allow applications and the OS to collaborate in exposing to the user only what she cares about and understands: the tradeoff between battery lifetime and functionality. Read our HotMobile paper for an introduction to our approach. Tracing Distributed Systems Distributed systems are growing ever more complex, spanning many layers of abstraction, machines, and administrative domains, and integrating code written, deployed, and operated by different people. In these scenarios it becomes increasingly difficult to understand how a system behaves, and, especially, how and why it fails. Causal tracing is a technique that captures the causality of events across all of these components, layers, and machines, and eases the task of understanding complex distributed systems. There are a multitude of causal tracing systems and frameworks, including many research and industry projects. Examples include our own X-Trace project [ GitHub ], as well as systems such as Google's Dapper, Twitter's Zipkin, and Cloudera's HTrace. We are interested in how to extract information from both complex individual traces and across traces, to identify root causes of problems, detect unexpected anomalies, and make tracing more efficient, by biasing trace sampling and detail capture to maximize trace information on a fixed performance budget. Older Projects Quanto Fine-grained tracking of energy usage in wireless sensor networks, Quanto determines which applications used how much energy on each hardware component, even for applications that span multiple network nodes. Collection Tree Protocol Robust all-to-few routing in wireless sensor networks, CTP is de-facto routing protocol for TinyOS 2.x, and formed the basis for IETF's RPL (Routing over Low Power and lossy networks) - RFC 6550 . Beacon Vector Routing BVR is an anchor-based pseudo-geographical any-to-any routing protocol for wireless sensor networks. Students I am really very fortunate to work with an amazing set of students! Graduate Students Michael Markovitch (PhD) Alumni Linnan Wang PhD 2021. Now at NVidia Nicholas DeMarinis PhD 2021. Now at Brown! Jeff Rasley - PhD 2019. Now at Microsoft. Da Yu - PhD 2019. Now at ByteDance Jonathan Mace - PhD 2018. Now at MPI-SWS Marcelo Martins - PhD 2017 Sofware Analysis and Development for Energy Effciency in Mobile Devices\u201d . Now at Apple. Andrew D. Ferguson - PhD 2014 Policy Delegation and Migration for Software-Defined Networks . Now at Google. Junyang Chen - ScM 2016 George Hongkai Sun - ScM 2016 Wilson Cusack - AB 2016 - Honors Rui Zhou - ScM 2014 Datacenter Network Large Flow Detection and Scheduling from the Edge . Now at Google. Jonathan Leavitt - ScB 2014. Honors Thesis: End-to-End Tracing Models: Analysis and Unification. Now at Google. Matheus Caldas (Visiting PhD from UFMG ) Chen Liang - ScM 2013, now a PhD student at Duke. ScM Project: Software Defined Network Support for Real Distributed Systems Basil Crow - ScM 2012, now at Delphix. Thesis: Time and Energy Profiling in Production Sensor Networks with Quanto Sunil Mallya - ScM 2011, co-founder at Neon Labs , now at Amazon. Thesis: Entracker: Energy Tracker for Homes Jake Eakle (ScM 2011), now at Teespring. Sandy Ryza - ScB 2012, now at Cloudera. Honors Thesis: Solving Hard Problems with Lots of Computers Walter Blaurock - ScB 2011, now at Next Big Sound. Project: Automatic Scaling of Cloud-Based Web Applications Selected Publications All Publications . . , ( ) , pp. , In , pp. , , (Eds.), , , . ISBN: . [ BibTex ] [ pdf ] [ talk ] [ video ] [ doi ] Professional Activities Conference Organization 2015 Co-Organizer, 2nd New England Networking and Systems Day 2014 Co-Organizer, 1st New England Networking and Systems Day Doctoral Symposium, IC2E 2014 2012 Program Co-Chair: HotCloud'12 Technical Program Committee 2016 Eurosys'16, USENIX ATC'16, NSDI'16, SBRC'16 2015 SBRC'15, DCOSS'15, NSDI'15, HotCloud'15, DSN'15 2014 SIGCOMM'14 PC, IMC'14 PC, HotMobile 2014, Eurosys'14 Ext. Review Committee 2013 NSDI'13 PC, TRIOS, SOCC'13 2012 OSDI'12 Ext. Review Committee, Middleware'12, HotDep'12, MAD'12, IGCC'12, DSN'12 2011 NSDI'11, DSN'11, CoNEXT'11, HotPower'11, HotCloud'11, NetDB'11 2010 ... Personal You can find some of my photography as @319studio on Instagram, or at 500px . I almost never tweet as @rodrigo_fonseca . My wife Paula runs an amazing party design business, Festiva Party Design , check it out! Back to top Template and css from Twitter bootstrap. Publications list automatically generated from BibTeX using Exhibit . //create a virtual path for Google Analytics //trackOutgoing is a function that takes a url as a parameter var trackOutgoing = _trackOutgoing('from-index/'); //attach bibtex expansion to the BibTeX links var pubnodes = document.getElementsByClassName(\"publication\"); for (var i = 0; i < pubnodes.length; i++) { attachToggleBehavior(pubnodes[i]); } $(document).ready(function() { $('#older-news').on('show', function () { $('#news-button').button('less') }) $('#older-news').on('hidden', function() { $('#news-button').button('reset') }) });", "https://cs.brown.edu/about/conduit/": "Conduit Conduit is the Brown CS annual magazine, distributed to our extended family of faculty, staff, students, alums, and industry partners. Click any link below to download any issue in Adobe Acrobat format. Current Issue Conduit Volume 33 (2023) Back Issues Conduit Volume 32 (2022) Conduit Volume 31 (2021) Conduit Volume 30 (2020) Conduit Volume 29 (2019) Conduit Volume 28 (2018) Conduit Volume 27 (Winter, 2017) Conduit Volume 26 (Spring, 2017) Conduit Volume 25 (2016) Conduit Volume 24 (Spring, 2015) Conduit Volume 23, Number 1 (Spring/Summer, 2014) Conduit Volume 22, Number 1 (Spring/Summer, 2013) Conduit Volume 21 Number 2, Fall/Winter 2013 Conduit Volume 21 Number 1, Spring/Summer 2012 Conduit Volume 20 Number 2, Fall/Winter 2012 Conduit Volume 20 Number 1, Spring/Summer 2011 Conduit Volume 19 Number 2, Fall 2010 Conduit Volume 19 Number 1, Spring/Summer 2010 Conduit Volume 18 Number 2, Fall/Winter 2009 Conduit Volume 18 Number 1, Spring/Summer 2009 Conduit Volume 17 Number 2, Fall/Winter 2008 Conduit Volume 17 Number 1, Spring/Summer 2008 Conduit Volume 16 Number 2, Fall/Winter 2007 Conduit Volume 16 Number 1, Spring/Summer 2007 Conduit Volume 15 Number 2, Fall/Winter 2006 Conduit Volume 15 Number 1, Spring 2006 Conduit Volume 14 Number 2, Fall/Winter 2005 Conduit Volume 14 Number 1, Spring 2005 Conduit Volume 13 Number 1, Summer 2004 Conduit Volume 12 Number 2, Fall 2003 Conduit Volume 12 Number 1, Spring 2003 Conduit Volume 11 Number 2, Fall 2002 Conduit Volume 11 Number 1, Spring 2002 Conduit Volume 10 Number 2, Fall 2001 Conduit Volume 10 Number 1, Spring 2001 Conduit Volume 9 Number 2, Fall 2000 Conduit Volume 9 Number 1, Spring 2000 Conduit Volume 8 Number 2, Fall 1999 Conduit Volume 8 Number 1, Spring 1999 Conduit Volume 7 Number 2, Fall 1998 Conduit Volume 7 Number 1, Spring 1998 Conduit Volume 6 Number 2, Fall 1997 Conduit Volume 6 Number 1, Spring 1997 Conduit Volume 5 Number 2, Fall 1996 Conduit Volume 5 Number 1, Spring 1996 Conduit Volume 4 Number 2, Fall 1995 Conduit Volume 4 Number 1, Spring 1995 Conduit Volume 3 Number 2, Fall 1994 Conduit Volume 3 Number 1, Spring 1994 Conduit Volume 2 Number 2, Fall 1993 Conduit Volume 2 Number 1, Spring 1993 Conduit Volume 1 Number 2, September 1992 Conduit Volume 1 Number 1, March 1992", "https://cs.brown.edu/about/directions/boston/": "Getting To Brown CS From Boston From Boston, there are three ways to travel to Brown CS: Car (be sure to read the Parking and Road Construction and Traffic Alerts sections before you depart) Train Bus", "https://cs.brown.edu/about/directions/": "Directions To Brown CS Brown is located in Providence, Rhode Island, in the northeast of the USA. Providence is just an hour south of Boston and three hours north of New York City, with good connectivity by rail in addition to car and air. You can also visit Providence virtually . We're located on the Brown University campus in the Thomas J. Watson Sr. Center for Information Technology (the CIT). Our address is 115 Waterman Street, Providence, RI 02912. You can enter through a door or loading dock at this address, but if they're locked, the main entrance is located in the quadrangle off Brook Street. Our reception desk is on the fourth floor. If you're traveling by car, be sure to read the Parking and Road Construction And Traffic Alerts sections of the Car page. If you're going to have some leisure time during your stay, be sure to check out this helpful guide : the College Hill, Thayer Street, Wayland Square, and Downtown neighborhoods are all nearby. Directions Electric Scooters/Bikes | Car | Cab | Train | Bus | Plane | Public Transit | From Boston", "https://cs.brown.edu/about/diversity/health-wellness-student-advocates/": "Diversity and Inclusion As a department, we have made it our mission to create and sustain a diverse and inclusive environment in which all students, faculty, and staff can thrive. The Broadening Participation in Computing BPC 2022-2024 Department Plan has been verified by BPCnet.org. The CS Diversity & Inclusion Action Plan (DIAP) Phase II Draft is now available! Diversity Home | Who We Are | Resources | Action Plan & Initiatives | Diversity Advocates | Wellness Advocates | Data & Demographics | Student Groups | Mosaic+ Transition Program Health & Wellness Student Advocates Our Mission is improve the mental and physical health, accessibility and disability rights with the CS department on an individual and systemic level, as well as increase the sense of departmental community. We connect students with campus resources that are relevant to the issues or pressures they may be facing. Additionally, we collaborate with department to develop better policies and function as a facilitator between students and faculty. If you would like to talk to one of us, we hold office hours upon request and can be reached at wellness.advocates@lists.cs.brown.edu Check out the Brown CS Health & Wellness Advocates website to learn more! The Advocates Cristian Loor '23 Anna Ohrt '23 Kiran Rodrigues '24 Shravya Sompalli '25 2022-2023 Projects Cristian Loor : My project is to revamp the UTA Diversity, Inclusion, and Accessibility training modules, according to the CS DDIAP Phase II Section 8.4.A TA Training Enhanced Actions and Goals and Priorities. I began partial revisions in the fall of 2022 with a full synchronous training session redesign according to the themes of \u201csetting boundaries and preventing burnout.\u201d. Additionally, I helped redesign the New TA Training module 3: accessibility & universal design on Canvas by incorporating a self-reflection prompt, giving it parity with the other two. Preliminary feedback assessments suggested that these revisions were effective. Next steps for the project will be to collate and analyze survey responses from different iterations of the training to produce a succinct report. In combination with any departmental climate data, this report will inform precise changes to ALL and NEW TA training occurring in fall 2023 and later. I will also revise module 3 quiz for spring 2023 New TA training by replacing inaccessible materials, editing quiz questions, and updating the UDL presentation. By the end of spring 2023, the Health and Wellness portion of the ALL TA training should have at least two swappable versions addressing distinct themes derived from previous iterations' content. I will enlist Professor Christina Smith's help in designing these versions. Revisions to the Health and Wellness HTA training are also in the pipeline. Kiran Rodrigues : My project goal would be to assist in the creation of course material that can be used for a Race Power, and Privilege (RPP) designated CS course. With the release of the DIAP II Plan in the coming months, the department is in a unique position to critically evaluate existing practices and devise ways in which the department can build upon its practices. Brown University\u2019s Seminar for Transformation Around Anti-Racist Teaching (START) provides an opportunity to improve upon the existing Socially Responsible Computing content by laying the groundwork for the creation of a RPP course to acknowledge the social and political impacts of computer science. What perspectives and voices have been historically excluded from computer science? How has it participated in and enabled systems of oppression? How can we think holistically about the legacies of technology? In a theoretical course we would recognize that computer science is not an innocent endeavor. Shravya Sompalli: My project is to create a zine that acts as a central base for navigating the computer science department at Brown, particularly through a wellness lens. Students often rely upon word of mouth and connections to upperclassmen in order to obtain information needed to navigate department resources. This zine will centralize essential information about the department that students may need to thrive here Furthermore, this zine could serve as another form of communicating important information on the department\u2019s progress on D&I goals and receiving feedback from the community, as noted in section 9.4 E of DIAP II. 2021-2022 Projects Cristian Loor : [project continuing in 2022-23 academic year] My task is to revamp the UTA Diversity, Inclusion, and Accessibility (DIA) training modules, by assessing the modules' effectiveness. This will include reviewing feedback surveys and holding TA focus groups to identify attitudes toward the trainingprogram. I hope the resulting data will help me design interventions for Spring 2023's course iteration. I would then assess their effectiveness by correlating them with departmental climate data changes. Before I graduate, I hope to establish data collection and evaluation standards my successors will find robust and easy to implement as they assess the ongoing impacts of UTA DIA training in the CS department. Anna Ohrt : I propose working with Kathi Fisher to ensure that their new intro course- CS200, is UDL centered. Because course planning has already taken place, this involves providing feedback on assignments and lecture materials. At the same time, researching what CS UDL guidelines already exist through sources like AccessComputing and leveraging other universities\u2019 best practices. From there, this effort would serve as a pilot for integrating health & wellness consultation support into CS accessible course design. David Moon: The goal of this project is to investigate mental health policy and best practices in two ways: (a) Intra-university investigation: connect with other departments at Brown to learn about how they approach mental health and what we could take away from them, send out survey to assess current state of mental health in CS department; (b) Inter-university investigation: connect with other universities\u2019 CS departments to learn about how they approach mental health and what we could take away from them. The data collected will inform a mental health best practices document. Interviews of best practices can be found here .", "https://cs.brown.edu/about/diversity/": "Diversity and Inclusion As a department, we have made it our mission to create and sustain a diverse and inclusive environment in which all students, faculty, and staff can thrive. The Broadening Participation in Computing BPC 2022-2024 Department Plan has been verified by BPCnet.org. The CS Diversity & Inclusion Action Plan (DIAP) Phase II Draft is now available! Diversity Home | Who We Are | Resources | Action Plan & Initiatives | Diversity Advocates | Wellness Advocates | Data & Demographics | Student Groups | Mosaic+ Transition Program How To Get Involved CS Diversity Committee Diversity & Inclusion Action Plan Phase II Draft is now available for member of the Brown CS community to review. Please click this link to read the DIAP Phase II Draft . Please click this link to share anonymous feedback about the draft. CS Diversity Committee Monthly Meeting Summaries are now available for Brown University community members on the Action Plan & Initiatives page. CS DIAP Phase II Town Hall : Our semesterly Town Hall was held on Tuesday October 25 at 4P-5P in CIT 368 / 3rd Floor Atrium 2023-2024 Student Advocates for Diversity & Inclusion, and Health & Wellness: Applications for 2023-2024 Student Advocates positions are now open. To apply complete the Health & Wellness form or the Diversity & Inclusion form.. CS Diversity Conferences: The CS Department offers student scholarships to attend the Grace Hopper and Richard Tapia conferences. Student scholarship applications for fall 2023 conference attendance will open in spring 2023. Please check back fot the application form. If you would like to request funding to attend a different diveristy, equity and inclusion related CS conference, please email laura_dobler@brown.edu Socially Responsible Computing: The SRC program strives to reimagine CS education to not only familiarize future engineers with the ethical, and political challenges and social impacts of modern digital technology, but to provide them with the tools to reason critically about those challenges. Students can apply to become Socially Resoponsible TAs (STAs) and/or join the ARG reading group. You can learn more about this program here . Visiting Undergraduate Research: We offer two immersive research opportunities for visiting udnergraduate sudenfts interested in artificial intelligence reseach: exploreCSR (spring 2023) and REU Site (summer 2023). exploreCSR 2023 Socially Responsible AI for Computational Creativity: January 2023 - May 2023 (~ 5 hours per week), virtual program, compensation $300 + travel stipend to attend the Undergraduate Research Symposium in May. REU Site 2023 AI for Computational Creativity: June 2023 - August 2023 (7 weeks, 40 hours per week), in-person, compensation ~$6,000 + housing and travel stipend. If You Need Help Our Email: Diversity & Inclusion Student Advocates : diversity.advocates@lists.cs.brown.edu Health & Wellness Student Advocates : wellness.advocates@lists.cs.brown.edu Diversity Committee : diversity@lists.cs.brown.edu Have questions/concerns about mental/physical health, accessibility, disability rights, and/or diversity, equity & inclusion within the department? Open/Office Hours provide students with 1:1 peer mentorship, problem-solving, advocacy, and guidance on student resources and centers available to them on campus. Undergraduate Health & Wellness Student Advocate Office Hours : Fall 2022, in-person hours are available throughout the week, please feel free to just stop by. Link to Google Calendar hours schedule. Undergraduate Diversity Student Advocates Office Hours : Fall 2022, hours are by appointment; please email diversity.advocates@lists.cs.brown.edu or complete the contact form below to schedule. Loading... Diversity Events Thursday October 25, 4P-5P: CS DIAP II Town Hall . CIT 368 and Zoom. For a list of Brown Computer Science Department events visit the CS Events Calendar . For a full list of Women in Computer Science (WiCS) events visit the WiCS Calendar . For a full list of Mosaic+ events visit the Mosaic+ Calendar . Past Events No events Diversity News No entries found", "https://cs.brown.edu/about/diversity/resources/": "Diversity and Inclusion As a department, we have made it our mission to create and sustain a diverse and inclusive environment in which all students, faculty, and staff can thrive. The Broadening Participation in Computing BPC 2022-2024 Department Plan has been verified by BPCnet.org. The CS Diversity & Inclusion Action Plan (DIAP) Phase II Draft is now available! Diversity Home | Who We Are | Resources | Action Plan & Initiatives | Diversity Advocates | Wellness Advocates | Data & Demographics | Student Groups | Mosaic+ Transition Program Resources If You Need Help If you have an emergency that needs immediate attention contact the Department of Public Safety at 401-863-4111 . For any other incidents that you would like addressed reach out to the Diversity Committee diversity@lists.cs.brown.edu , the Student Advocates for Diversity & Inclusion diversity.advocates@lists.cs.brown.edu , the Student Advocates for Health & Wellness, wellness.advocates@lists.cs.brown.edu or the Diversity Committee staff member, Laura Dobler laura_dobler@brown.edu (401) 863 7611 The Office of Instutional Equity and Diversity ( OIED ) also has an online Bias Incident Report Form that can be completed by members of the community who wish to report incidents or issues of discrimination and/or harassment. Submissions are always confidential and can also be anonymous should the submitter choose. Emergency Contacts Emergency Medical Services (EMS) (401) 863 4111 - Physical evaluations, hospital transports, medical emergencies Student Support Deans | Dean of the Day (DOD) (401) 863-3145 - Addresses academic and personal emergencies during business hours Administrator on Call (AOC) (401) 863-3322 - 24/7/365 support for students in need of immediate assistance Sexual Assault Response Line (401) 863-6000 - Immediate support in conjunction with DPS, EMS and CAPS (confidential) Helping a Student in Distress - For a full list of student support resources Academic Support and Tutoring Dean of the College (DOC) - Addresses academic concerns including open curriculum, grading, independent concentrations, gap years, leave-taking, among others Curricular Resource Center (CRC) - Part of the Dean of the College, Peer Advising supports students navigating independent concentrations, gap years, leave-taking, DUGs, fellowships, internships and research Sheridan Center - Provides resources for teaching and learning Advising Sidekick - a common on-line space for students and advisors that includes advising materials, information about the Writing Requirement, email announcements, and the Concentration declaration process. Math Resource Center - Provides tutoring for math courses during the year Student Conduct and Community Standards - Addresses student conduct and policy concerns SAS (Student Accessibility Services) - Provides students (including graduate students and postdoctoral trainees), faculty or staff members who may need accommodations or services due to a disability or medical condition Student Centers Undocumented, First-Generation College and Low-Income Student Center (U-FLi Center) The U-FLi Center , founded in the fall of 2016, is a communal, learning, and advocacy center for members of the Brown community who identify with the undocumented, first-generation college and/or low-income student experience (U-FLi). The U-FLi Center aims to contribute to the endurance of U-FLi students by providing them with a dedicated space and programming that values their lived experiences as they navigate an elite, historically white institution and acknowledges the impact of the current socio-political climate on their academic well-being. Brown Center for Students of Color (BCSC) The BCSC , established in 1976, serves as a gathering place for communities of color. Students are encouraged to build meaningful relationships across difference, develop racial and ethnic consciousness, and enact change at Brown and beyond. The BCSC advances the University\u2019s mission of educating and preparing students to discharge the offices of life with usefulness and reputation by empowering students of color, cultivating leadership, facilitating critical reflection, fostering informed action, and promoting social justice. The LGBTQ Center The LGBTQ Center established at Brown in 2004, provides a comprehensive range of education/training, cultural, social and educational programming, support services and advocacy services to the entire Brown Community. The Center works to create and maintain an open, safe, and inclusive environment for lesbian, gay, bisexual, transgender, queer and questioning students, faculty, and staff, their families and friends, and the campus community at large. Sarah Doyle Center for Women and Gender (SDC) The SDC , established at Brown in 1974, seeks to provide a comfortable yet challenging place for students, faculty, and staff to examine the multitude of issues around gender. The Sarah Doyle Center offers programs and services for all members of the Brown community, and is a site for research into and exploration of gender issues that extend into and beyond the classroom. Brown Muslim Student Association (BMSA) and Student Center (BMSC) BMSA was founded in the early 1990s. They are a student-led group at Brown University working to meet the needs of our Muslim community while maintaining an open and inviting space. They host a range of events from spiritual to social to interfaith and work closely with the Office of Chaplains and Religious Life. Student Activities Office (SAO) As part of the Division of Campus Life, the Student Activities Office leads campus efforts to support 400+ student groups. For a full list of student groups: BearSync: Student Group List . Student Support Student Accessibility Services (SAS) SAS coordinates and facilitates services for students (including graduate students and postdoctoral trainees), faculty, staff and visitors with physical, psychological, and learning disabilities. Students (including graduate students and postdoctoral trainees), faculty or staff members who may need accommodations or services due to a disability or medical condition should contact Student and Employee Accessibility Services to discuss their needs and begin the registration process. Disability related requests for accommodations and services are evaluated individually, based on documentation and completion of the registration process. Counseling and Psychological Services (CAPS) CAPS provides a range of mental health services to the Brown community, including individual counseling, medication management, skills workshops, referral services, mental health assessment, trainings and consultation for faculty and staff, crisis stabilization, after hours assessment and urgent care, outreach programming, and groups. If you have any questions that are not answered on this page, please contact us so we can help. For those looking to help students: the B.E.A.R. Project is a training run by CAPS to help members of our community identify and support students in distress. Projet LETS: Peer Mental Health Advocates (PMHA) Project LETS is a national 501(c)(3) grassroots organization led by and for folks with lived experience of mental illness, disability, trauma, & neurodivergence. We establish peer-led communities of advocacy & support; produce resources and educational materials; and aim to protect the civil and human rights of mentally ill folks through policy change \u2014 especially those who experience multiple forms of oppression and therefore are rendered especially vulnerable. Disability Justice at Brown DJAB advocates for disability justice at Brown by holding space for a broad coalition of voices in the disabled community. We seek to foster connections between disabled people across all identities and experiences, provide resources and education for each other and the broader Brown community, and serve as a seat of power to amplify our individual voices into a collective force. By creating a space for organizing and solidarity, we aim to address the pressing issues facing all disabled students at Brown and cement disability as an important part of the campus discussion on diversity and inclusion. Health Services Health Services and its affiliated departments aim to provide primary care that is patient-centered, high-quality, confidential, easily accessible and responsive to students' needs. Health Services recognizes that physical and emotional health and well-being are necessary for the student to devote meaningful efforts to the stated goals of education and self-discovery. Partnering with students, we provide holistic care that is respectful of students' personal, cultural and social identities; thus becoming a space for education, self-discovery and intellectual growth. BWell Health Promotion BWell is dedicated to facilitating interactive workshops that provide accurate health information in a non-judgmental, inclusive style. Learn about the programs we offer and request a program for your group. Sexual Harassment & Assault Resources & Education (SHARE) Advocates The SHARE Advocates in BWell Health Promotion are confidential resources on campus that can provide support to any student from any part of the University (undergraduate, graduate, and medical students) affected by issues or experiences related to: Sexual Assault; Sexual and/or Gender-based Harassment; Domestic/Dating; Violence; Relational Abuse; Stalking Title IX & Gender Equity Brown University Title IX is committed to providing an adequate, impartial, and reliable response to Complaints pursuant to the University Sexual and Gender-Based Harassment, Sexual Violence, Relationship and Interpersonal Violence and Stalking Policy. The University\u2019s process for addressing Prohibited Conduct are grounded in fairness and support for all parties, include procedural protections that ensure notice and meaningful opportunities to participate, and recognize the dynamics involved in Prohibited Conduct. Office of the Chaplains and Religious Life The Office of the Chaplains and Reglious Life's mission is to ensure that a diversity of beliefs have voice and vitality throughout the University community. This website will introduce you to our work, programs and religious life colleagues, as well as resources available to undergraduate, graduate, medical students, staff, faculty, and alumni/ae. The Office of Residential Life The Office of Residential Life is responsible for maintaining student residences which support the educational mission of Brown University and are designed to provide a variety of learning opportunities that promote students' academic endeavors, and which encourage their growth and development. The Office of Residential Life at Brown recognizes that learning is not solely academic in nature. A large part of learning inevitably takes place outside the classroom. We are committed to supporting that learning through the residential experiences we provide. Office of International Student and Scholar Services (OISSS) The mission of the Office of International Student and Scholar Services (OISSS) is to support the University\u2019s internationalization and to facilitate the integration of international students and scholars into the Brown community. In that, OISSS serves as a resource to admitted international students, faculty and researchers and their families as well as academic departments, and other administrative offices on and off campus. OISSS provides advising services with respect to immigration and visa matters, work permission, orientation, cultural adjustment and personal concerns. OISSS provides consulting services to hiring academic departments, and handles the immigration related aspects of the hiring process for nonimmigrant faculty, researchers, and staff. OISSS is organized under the Office of Global Engagement (OGE) . Office of Military-Affiliated Students (OAMS) OAMS supports all students -- undergraduate, graduate, and medical -- and also is available as a resource to faculty, staff, alumni/ae, and families of students. While initiated by Brown's response to a review of ROTC, the Office is a campus resource for not just ROTC but for all United States military officer commissioning programs. Additionally, the Office serves student veterans, whether of the United States military or military service in other countries. The Office of Institutional Equity & Diversity (OIED) OIED serves as a critical leader, resource, and support in sponsoring programs and events related to diversity and inclusion at Brown University. OIED helps lead inclusion efforts across campus through: Accountability; Compliance; Fostering Academic Diversity; Promoting Diversity and Inclusion. Community members can report bias incident reports using the new form on OIED's website. Brown University Ombuds Office The Ombuds Office provides an independent, confidential, neutral and informal resource for faculty, staff, postdoctoral fellows and associates, graduate students and medical students who have concerns arising from or affecting their work and studies at Brown. Technical & Financial Support Computing & Information Services: Loaner Laptops CIS Help Desk : Need a loaner? The following equipment can be signed out at the IT Service Center. For current models and availability, please get in touch. [Windows laptops, Mac laptops, Webcams, Video cameras, Audio Recorders, Projectors]. Stop by the IT Service Center in the Page-Robinson 510 (69 Brown Street) during business hours [M-F 8:30A-9P, Sa closed, Sun 4P-9P] Financial Services Financial Aid : Financial aid at Brown is a partnership that draws on the combined resources of the student, his or her family, federal and state governments, and the University itself. Loan Office : As part of Financial Services, the Loan Office assists students in meeting the cost of education and managing the repayment of educational loans. We help students make informed borrowing decisions, complete loan requirements, and understand the loan process. UFunds : UFunds coordinates applications for funding from offices at Brown. You will find opportunities here for members of the Brown community, including undergraduate students, graduate students and faculty. Short-Term Loans : The Brown University Short-Term Loan Program is a zero interest loan made available to students to assist in emergencies. Computer & Information Systems: Services CIS Services : Accounts & Passwords, Computer & Printer Repair, Computer Installation & Set Up, Computer Training Consultation Sessions, Computer Training Workshops, Data Recovery, IT Knowledgebase, IT Service Center, Lynda.com Online Training, Mobile Device Repaid, On-Site Support, Undergraduate Computer Training Classes (PASS), Women and Technology Group Graduate Student Resources Graduate School Student Services : Academics, Health & Wellness, Student Experience, directory of support services for graduate students oSTEM : Out in Science, Technology, Engineering, and Mathematics ( oSTEM ) at Brown is a chapter of the national non-profit professional society ( oSTEM Incorporated ) with more than 75 chapters across the United States. Our overarching mission is to empower LGBTQIA+ folks at Brown University studying or working in STEM fields to succeed personally, academically, and professionally. GSOC : Graduate Students of Color community: Our mission aims to build a communuty of graduate students of color in STEM, increase interaction between faculty and students of color in STEM, and encourage a pipeline for underrepresented groups in STEM to increase their representation in STEM fields. SACNAS : Brown University's Chapeter of the Society of Advancement of Chicanos/Hispanics and Native Americans in Science work to foster an includive community and resilient network of scientists from underrepresented identities in STEM at Brown University and behyond.", "https://cs.brown.edu/about/diversity/student-advocates-diversity-and-inclusion/": "Diversity and Inclusion As a department, we have made it our mission to create and sustain a diverse and inclusive environment in which all students, faculty, and staff can thrive. The Broadening Participation in Computing BPC 2022-2024 Department Plan has been verified by BPCnet.org. The CS Diversity & Inclusion Action Plan (DIAP) Phase II Draft is now available! Diversity Home | Who We Are | Resources | Action Plan & Initiatives | Diversity Advocates | Wellness Advocates | Data & Demographics | Student Groups | Mosaic+ Transition Program Diversity & Inclusion Student Advocates Our Mission Our primary mission as Student Advocates for Diversity and Inclusion is to improve how our department handles academic and social diversity issues. We hope to increase the retention number of HUGs (historically underrepresented groups) in upper level computer science classes, as well as increase the number of students concentrating in computer science. We also hope to raise awareness of the issues that are ongoing in our department such as the lack of diversity among our TA program, which is the main source of instruction for our introductory classes. We hope that our initiative creates a more inclusive environment that allows students to thrive academically while also creating a diverse social atmosphere that is welcoming to all. Confidentiality When students are in their roles as student advocates they are not required to share any information disclosed. They will not answer questions about people with whom they may have spoken, or disclose an individual's name or specific issue unless during the course of the discussion, the student advocate is given explicit permission by the individual to do so. The only exception to this is if the student advocate determines that there is an imminent risk of serious harm. Student advocates will, however, keep statistical information for analyzing and reporting trends of issues, and provide recommendations to the diversity committee. Student advocates are not Title IX mandatory reporters. The Student Advocates Afia Akosah-Bempah '23.5 Valerie Aguilar Dellisanti '23 Fernanda Chavez Zapata '25 Arman Deendar '25 Contact: Email: diversity.advocates@lists.cs.brown.edu OR Contact Form 2022-2023 Projects Afia Akosah-Bempah & Arman Deendar: In line with section 7.4 E K-12 Outreach: New or Enhanced Action of Phase II of the Diversity and Inclusion Action Plan (DIAP), this project aims to expand and consolidate the community outreach initiatives already taken by the department. Given the scale and access to resources of Brown\u2019s Computer Science Department, the department has a great opportunity to serve and become accountable to local communities. We wish to implement a program that centers community needs for continued engagement and dedication of resources in Providence, Central Falls, and Pawtucket. In the short-term this involves beginning conversations with local community leaders, organizations, and educational centers, Brown CS stakeholders (faculty, graduate students, undergraduate students, and existing outreach groups, ie IgniteCS) and adjacent Brown community-oriented departments (Annenberg Institute, Swearer Center, Bonner Fellows, BRYTE). Then using information gleaned from these conversations to inform outreach initiative and policy proposals submitted to Brown CS Valerie Aguilar-Dellisanti & Fernanda Chavez Zapata: The goal of this project is to create a resource for underrepresented communities in the CS department to connect with Brown CS alumni, create impactful relationships, and gain valuable knowledge. Building a database of underrepresented CS alumni is now possible given the increased number of diverse student that have graduated and will graduate from Brown University with a CS Degree. Mosaic+ is one of the largest reasons for attracting interest and retention in the department, as well as the creation of the Diversity and Inclusion student advocates. We aspire to use these programs to create a database of alumni in order to create a program like the Women\u2019s Launch Pad or Women in Business External & Internal Mentorship Initiative. We would develop an alum mentor-student mentee program with guides, coffee chats and alum meet-ups during commencement. 2021-2022 Projects Valerie Aguilar Dellisanti: Across campuses, students and their Computer Science departments have different approaches to improving diversity and support for their members. This project evaluates different policies, clubs and initiatives in different universities, both in Rhode Island and at other schools with top CS departments. Additionally, an emphasis is given to universities with high diversity and hiring rates, especially for HUGs. There are two main purposes of this study. The first one is to analyze how initiatives already taken at Brown are implemented somewhere else, identify key differences and similarities. The second goal is to identify good practices that could be replicated here on campus. Both of these goals will help improve and strengthen the impact of current initiatives. The analysis was presented at a Diversity Committee meeting in spring 2022, and best practices were integrated into the DIAP II Draft. The presentation can be viewed here . Evan Dong: This project focused on the creation of an LGBTQIA+ umbrella affinity group, Spectrum. Growing from a queer mentorship program started last year, activities expanded to include partnerships with recruiters for career development opportunities, community-building events, and facilitated spaces for transgender students. With an eye toward sustainability, this year's activities focused on building capacity and leadership for future generations of LGBTQIA+ students in Brown CS. Amal Dualeh: This project documents high level practices for supporting first generation/low income/undocu+ students (UFLi) who experience unique challenges coming into CS as an academic field and as a department here at Brown. The goal is to create programming recommendations focused on providing UFLi students in CS with spaces of community and support with other students of shared lived experiences. Elements of the report, which can be viewed here , were integrated into the DIAP Phase II Draft. Charlotte Lee: My observation is that the student culture among the CS concentrators cohort is relatively homogenous in terms of background, academic interests, and career path considerations. In order to improve recruitment and retention of CS concentrators, I believe that we need to offer more interdisciplinary educational approaches or opportunities that cater to students who are not interested in working at big tech companies (Facebook, Amazon, Apple, Netflix, Google). The goal of my project is to increase the number of opportunities for students who are interested in CS for social good. I believe that increasing the number of these opportunities will shift the student culture in a healthier, more inclusive direction by attracting a more diverse group of students, and allowing these students to pursue / integrate their other passions in the study of Computer Science. The plan is for this work to continue in 2022-2023 with the development of a \"Socially Responsible Computing\" opportunities/careers database, as Charlotte assumes a new role of IPP Ambassador.", "https://cs.brown.edu/people/jsavage/": "John Savage Send me email at: john_savage@brown.edu Biographical Sketch MIT By the early 1970s his research interests changed from coding andcommunication theory to theoretical computer science. He has done research incomputational complexity, circuit complexity, space-time tradeoffs, VLSIsynthesis and theory, parallel algorithms and theory, scientific computation,reliable computation with unreliable components, computational nanotechnology,efficient cache management on multicore chips, and I/O complexity. Hiscurrent research interests are in cybersecurity technology and policy. He haspublished more than 100 research articles and given more than 185 invited technicalpresentations worldwide. He is a Fellow of AAAS and ACM, a Life Fellow of IEEE, and aGuggenheim Fellow. He is a recipient of a Fulbright-Hays ResearchAward. He served as a Jefferson Science Fellow in the U.S. State Department during the 2009-2010academic year and as a member of the RhodeIsland Cybersecurity Commission in 2015. He served as a ProfessorialFellow of the EastWest Institute from 2014 to 2020 when it was dissolved. His professional service has included service on the editorial boardof the Journal of Computer and Systems Sciences and as a memberof the MIT CorporationVisiting Committee for the Department of Electrical Engineering andComputer Science from 1991-2002. He gave testimony before the Subcommitteeon Crime and Terrorism of the Senate Judiciary Committee on April 12, 2011. A more comprehensive , but incomplete, biographical statement can be found here . A complete vitae can be found here . Books Security in the Cyber Age: An Introduction to Policy and Technology (with Derek S. Reveron), Cambridge University Press, 2023 (to appear). Models of Computation: Exploring the Power of Computing Addison-Wesley, 1998. ( Freely available electronically! ) The Mystical Machine (with S. Magidson and A. Stein), Addison-Wesley, 1986. The Complexity of Computing , John Wiley and Sons, 1976; Robert E. KreigerPublishing Company, 1987; Russian Translation. by Factorial Publishing, 1998 Recently Taught Courses CSCI 0510, Models of Computation CSCI 1951-E, Computer Systems Security: Principles and Practice CSCI 1800,Cybersecurity and International Relations Faculty Bulletin Articles TheGrowth of Brown University Since 1955 , October 1996 The Role of Tenure in Higher Education , May 1998 Representative Brown Service Activities Secretary of the Faculty (2015), Secretary of the Faculty Forum (2014-2016) Vice Chair (2000-2001), Chair (2001-2002), and Past Chair (2002-2003) of the Faculty and the Faculty Executive Committee Chair (2002-2003) of the Task Force on Faculty Governance President (1999-2002) of the Board of Managers of the Brown Faculty Club Distance Learning Web Pages prepared for The Committee on Electronically Mediated Instruction Source Material on Topics of Current Interest Cybersecurity and International Relations Encryption and the FBI/Apple Dispute Blockchain Technologies and Cryptocurrencies Deterrence in Cyberspace Talks, Interviews, Congressional Testimony b Blockchain Governance: Lessons learned from Internet Governance ,A summary of a talk given at ETH Zurich, March 8, 2018 Silver Bullet Interview of John Savage by Gary McGraw, a podcast posted January 24, 2011. The transcript appears in IEEE Security & Privacy magazine, July/August 2011. > Cyberspace - Taming the Wild West , Jefferson Science Fellow Distinguished Lecture, US State Department,March 23, 2010 Hearing of the U.S. Senate Committee on the Judiciary, Subcommittee on Crime andTerrorism on \"Cyber Security: Responding to the Threat of Cyber Crime andTerrorism,\" April 12, 2011. John Savage is on thesecond panel which begins at 1:41 minutes. Cyberspace Policy and Technology , The Sarah and John Graves Distinguished Cybersecurity Lecture, University of Tulsa, Tulsa, OK, October 14, 2016 Technology and the Future of Work Part 1 , White House Chronicle , February 2, 2018 Guests: Thomas Kochan, MIT Sloan School of Management; John Savage, Brown University Technology and the Future of Work Part 2 , White House Chronicle , February 9, 2018 Guests: Thomas Kochan, MIT Sloan School of Management; John Savage, Brown University Humanizing the internet of things , White House Chronicle , October 5, 2018 Guest: John Savage, Brown University Cyber Security \u2013 A Societal Grand Challenge , John Savage's retirement lecture, Department of Computer Science, Brown University, December 13, 2018 Technology and the Future of Work Part 2 , White House Chronicle , February 9, 2018 John Savage document.getElementById(\"demo\").innerHTML = document.lastModified;", "https://cs.brown.edu/about/partners/": "Industry Partners Program Advantages \u2022 About Brown CS \u2022 Become a Partner \u2022 Current Partners \u2022 Symposia \u2022 Tech Fair \u2022 Membership Levels The Department of Computer Science at Brown University runs an industry partners program that offers corporations and non-profit organizations opportunities to collaborate with faculty, learn about Brown's research, and meet Brown students who are looking for employment. The Department seeks partners whose activities are aligned with Brown\u2019s mission of education and research. Brown CS celebrates diversity and is committed to creating an inclusive environment for all our constituents. Membership in the IPP is by invitation. We welcome organizations whose business practices align with our expectation for equal opportunity and fair employment, as well as the responsible, transparent, and accessible use of technology, which precludes racial profiling, mass surveilllance and other forms of discrimination and violation of civil rights. If you have questions, we are happy to discuss this with you. Industry Partners are introduced to the Department's research and development efforts and to our students. We seek to develop relationships with a limited number of Partners who share an interest in supporting faculty and students. The full scope of the Department's research interests are listed here . Member institutions are encouraged to recruit our students, participate in the selection of topics for our IPP symposia, and advise on the employment and research needs of corporations. The IPP Director and the Program Manager stay in regular contact with participating companies, arrange campus visits, identify faculty to serve as consultants, and respond to specific requests. We encourage our students to thoughtfully consider their career interests and goals, and decide for themselves which companies they should engage with. Please contact us if you have any input regarding our program. Students: If you want to receive notifications of IPP events please click this link to be added to the mailing list: http://bit.ly/brownipp Click here for upcoming IPP events Recruiting policies 2021-2022 (113.5 KB) . Recruiting Events No events Job Listing No entries found", "https://cs.brown.edu/about/partners/symposia/": "Industry Partners Program Advantages \u2022 About Brown CS \u2022 Become a Partner \u2022 Current Partners \u2022 Symposia \u2022 Tech Fair \u2022 Membership Levels IPP Symposia 1989 - Present DATE TOPIC SPEAKER ORGANIZATIONS BROWN ORGANIZERS 4/24/14 Social Computing danah boyd, Ed Chi, Mike Develin, Connor Gramazio, Hak Rim Kim, Merrie Ringel Morris, Alexandra Papoutsaki, Genevieve Patterson, Hannah Quay-de la Vallee, Michael Stoppelman, Sizhao Yang Prof. Jeff Huang 4/25/13 Putting Big Data to Work Tim Kraska, Nadathur Satish, Daniela Florescu, Fabio Vandin, Andrew Ferguson, Matteo Riondato, Mike Hughes, Dae Il Kim, Piero P. Bonissone, Amr Awadallah, Ionnis Tollis, Casey Dunn, Meenakshi Narain, Thomas Trikalinos, Derek Aguiar, Andy Pavlo Profs. Tim Kraska & Ugur Cetintemel 2/23/12 Security & Privacy in the Cloud Ben Livshits, Michael Coates, Tao Stein, Kevin DeLange, Denis Pilipchuk, Roberto Tamassia, Arjun Guha, Joe Gibbs Politz, Feng-Hao Liu Prof. Anna Lysyanskaya 4/28/11 Visual Computing Andy Gallagher, Sanjiv Kumar, Iain Matthews, Caroline Pantofaru, Sylvain Paris, Xiaofeng Ren, Bryan Russell, Larry Zitnick Profs. James Hays & Erik Sudderth 5/13/10 Cloud Computing Jeff Hammerbacher, Joseph L. Hellerstein, Srikanth Kandula, Orran Krieger, Harry Li, Adam Silberstein Prof. Rodrigo Fonseca 4/30/09 Standardizing Transactional Memory Ali-Reza Adl-Tabatabai, David Christie, Yossi Lev, Maged Michael, Mark Moir, Vijay Saraswat, Srinivas Sridharan, Ben L. Titzer Industry Partners Program 9/22/08 Technology Showcase Stan Zdonik, John Jannotti, Pascal Van Hentenryck Industry Partners Program 5/8/08 Web Programming Technologies David Ellis, Arjun Guha, Erik Meijer, Mark S. Miller Prof. Shriram Krishnamurthi 11/15/07 Security & Privacy Seth Proctor, David Croston, Steve Weis, Moti Yung, and Blair Semple Prof. Roberto Tamassia 5/3/07 Operating Systems Technology and Brown Alumni Bryan Cantrill, Michael Shapiro, Adam Leventhal, Jeffrey Korn, Jason Lango, Matthew Ahrens, and Eric Schrock Prof. Tom Doeppner 12/06/06 to 12/08/06 The Genome and the Computational Sciences: The Next Paradigms Leon Cooper, David Barker, Craig Venter, Stephen Hoffman, Jeffrey Skolnick, Jonathan King, David Shaw, Eric Kronstadt, Pavel Pevzner, Jonathan Yewdell, Jeremy Smith, Christopher Johnson, David Altshuler, Prof. Sorin Istrail 5/01/06 Do We Need a Next-Generation Internet IBM, Microsoft Mazu Networks, CMU, Akamai Prof. John Jannotti 12/06/05 Managing the Fire Hose GTECH, HBK, IBM, MIT Prof. Stan Zdonik 5/04/05 Combinatorial Optimization - State of the Art and Future Trends ILOG, IBM, SAP,Carmen Systems, Georgia Tech, Universit\u00e9 de Montr\u00e9al Prof. Meinolf Sellmann 10/29/04 Natural Language Processing Google, ISI, Microsoft, IBM Prof. Eugene Charniak 3/25/04 Trusted Computing Group: Goals, Achievements, and Controversies Hewlett Packard Labs, IBM, Intel, Microsoft Prof. Anna Lysyanskaya 5/6/03 Mobile and Pervasive Computing: Middleware and Technologies Fidelity Investments, Hewlett Packard, IBM Watson, Intel, Invensys/Foxboro, Sun Microsystems Prof. Ugur Cetintemel 11/14/02 Symposium on Information & Knowledge Management Hewlett-Packard, Fidelity Investments, Microsoft Research, IBM, MERL, Sun Microsystems Prof. Thomas Hofmann 4/25/02 Symposium on Computer and Network Security Hewlett-Packard, BBN, EMC, GTECH, Sun Microsystems Prof. Tom Doeppner 11/1/01 Component Software & Technologies Northeastern University, IBM, University of Utah, GTECH, Sun Microsystems Prof. Shriram Krishnamurthi 5/3/01 Vision-Based Interfaces Microsoft Research, Compaq, MERL, IBM, Intel Corporation, Prof. Michael Black 11/2/00 Web Technologies Akamai Technologies, Alta Vista Company, InterTrust Technologies, Latitude Communications, Verity, Inc., Sun Microsystems Prof. Eli Upfal 4/6/00 E-Commerce American Mgt. Systems, Andersen Consulting, Ariba, Compaq, GTECH, IBM, Microsoft Research Profs. Greenwald & Savage 11/11/99 Computing in a Wireless World Microsoft, Compaq, GTE Labs, Foxboro, GTECH, IBM/Lotus Prof. Doeppner 4/29/99 Web-Based Natural Language Technology:Search, Translation and Analysis IBM Almaden, IBM Watsun, Sun, Brown Prof. Charniak 11/12/98 Realizing the Potential of Java AT&T Research, Brown, Compaq, Lotus, Sun, WorldStreet Prof. Herlihy 5/7/98 Design Patterns DIGITAL, IBM, AT&T Labs, Sun, Brown, Independent Consultant Prof. Van Hentenryck 11/20/97 Web Technology: Usability, Security, Reliability & Commerce DIGITAL, INSO Corp. Dynamic, Diagrams, IBM, Freelance Journalist Prof. Hughes 4/3/97 NT vs. UNIX: Whither the Future? AT&T Labs, Bell Labs, DIGITAL, Linux Intern'l, Microsoft, Sun Profs. Reiss & Doeppner 10/24/96 Machine Learning & Data Mining Silicon Graphics, Microsoft Research, AT&T Research, NYNEX Sci & Tech, Honeywell Prof. Kaelbling 5/3/96 A Technical Retrospective on Paris Kanellakis Stanford, MIT, Brandeis, INRIA, Rocquencourt Profs. Van Hentenryck & Zdonik 10/26/95 Parallel Architectures for Today's Marketplace Sun Microsystems, Motorola, IBM, DEC, Microsoft Prof. Herlihy 4/13/95 Architectures for Interoperating Software Components OMG, DEC, IBM, GTE, Brown, EASEL Prof. Wegner 11/10/94 Nexal Computing Bellcore, DEC, IBM, Sun Microsystems, Corp. for Nat'l Research Initiatives Prof. Savage 4/26/94 Ubiquitous Computing DEC, Xerox PARC, Brown CS, IBM Watson, Locus Computing Corp. Prof. Doeppner 10/15/93 Frontiers in Visualization Brown CS, Xerox PARC, Columbia U., Bellcore Prof. Hughes 4/27/93 Object-Oriented Database Systems Brown CS, DEC, GTE Labs., Bellcore, Object Design, Inc. Prof. Zdonik 10/1/92 Progress in Distributed Object- Oriented Computing Brown CS, IBM Yorktown, Sun Microsystems, DEC Professor Wegner 3/19/92 Software Development and CASE Cadre, IBM, Brown CS, Siemens Prof. Reiss 11/7/91 Privacy & Security IBM, Citibank. DEC, Sun, Brown Philosophy Prof. Doeppner 7/18/91 Programming Techniques for Constraint Problems & Combinatorial Optimization IBM, Siemens, Bellcore, Motorola, Brown CS Profs. Kanellakis, Van Hentenryck 3/14/91 Parallel & Distributed Systems DEC, Citibank, IBM, HP, Motorola, Transarc Prof. Savage 10/17/90 OSF and UI Operating Systems Brown Tutorial, OSF, Sun, Bellcore, DEC, IBM, Unix International, GTech Prof. Doeppner 7/12/90 Robotic Systems Design Denning Robotics, Transitions Research, Design Lab, Brown Linguistics, Engineering & CS Prof. Dean 5/3/90 Experiences with the Object Paradigm Texas Instruments, Siemens, Bellcore, Codex, Brown CS Messrs. Lejter, Kirman Shewchuk (Grad Students) 2/21/90 Scientific Visualization Stardent, Sun, HP, Bellcore, Brown CS, Brown Applied Math Prof. van Dam Prof. Hughes 7/13/89 Prototyping Environments Object Design, Inc., Siemens, Brown IRIS, Brown CS Prof. Reiss Prof. Zdonik", "https://cs.brown.edu/about/praise/praise-brown-cs/": "Praise For Brown CS Brown University 's Department of Computer Science is known for inspiring innovation, fostering a tight-knit community, and engaging its students. Click the links below to learn more about why we're one of the best places to study CS. College Facutal Ranks Brown Fifth For Best CS Schools Brown CS Wins Brown\u2019s Diversity And Inclusion Action Plan (DIAP) Community Award GradReports Ranks Brown CS First In Colleges For Computer Science SR Education Group Ranks Brown CS Third Nationwide For Graduate CS Education Brown CS Has Been Rated The Fifth Most Advanced CS Department In America Humanities Magazine Features Brown's Revolutionary 1976 Use Of Hypertext In Education BDH Names Google And Microsoft The Top Two Employers Of Brown Graduates Brown Ranks #8 For Graduating Female Founders Of VC-Funded Companies Digital Den Cites Brown CS As A \"Well Recognized\" VR Leader LinkedIn Rates Brown CS #1 For Launching Graduates Into Successful Software Development Careers Brown Rated #3 In USA For Software Developers At Startups", "https://cs.brown.edu/about/pvd/": "Praise For Providence Providence is a city known for its great quality of life, cultural attractions, and (you guessed our favorite) food. Click the links below to learn more about why we love calling it home. If you're coming for a visit, be sure to check out this helpful guide : the College Hill, Thayer Street, Wayland Square, and Downtown neighborhoods are all nearby. You're also welcome to visit Providence virtually . The New York Times Recommends Rhode Island In The Fall Gondolas: A Great Way To Enjoy And Tour Providence Cond\u00e9 Nast Traveler Calls Providence New England\u2019s \u201cNew Cultural Hub\u201d Providence Is America's 8th Best City To Go Carless Providence Has Two Restaurants In Yelp's Top 100 Providence Has One Of America's Top 50 \"Best New Restaurants\" Smart, Urbane, Wonderfully Weird: The Washington Post Shares Some Must-See Providence Attractions More Raves For Providence As A \"Foodie Mecca\" CNN Names Providence \"The USA's Most Artsy City\" Bostonians Find Providence \"Divine\" And Offer A Day Trip Guide Money Magazine Names T.F. Green America's Sixth Best Airport Providence Will Be Shiru Cafe's First US Location Providence Has Been Named America's Fourth Quirkiest City PureWow Offers A Guide To Providence As \"Your Next Weekend Escape\" Considering A Visit (Or A Move) To RI? Boston.com Gives 100 Reasons Travel And Leisure And Conde Nast Rank T.F. Green Airport One Of The Nation's Best Providence Is Home To One Of Bon Appetit's Ten Best Restaurants Parade Names Providence The Best Kept Secret On The East Coast Travel And Leisure Names Providence The Third Most Charming City In America Providence's RISD Museum Tops Architectural Digest's List Of America's Best University Art Museums Travel And Leisure Calls Providence America's Third Favorite City And Second Best For Food Brown CS Is Within An Hour's Drive Of One Of The USA's Best Beaches NYT Ranks Providence With Global Peers As A \"Place To Go In 2016\" Providence Declared Best City To Raise Kids In America DataFox Lists Providence As One Of 2015\u2019s Best Cities To Found A Startup Outside Of Silicon Valley And New York GQ Raves About Providence: \"The Coolest City\" Providence Ranked America's Eighth Best College Town For People Who Aren't In College", "https://cs.brown.edu/about/rooms/368/": "CIT 368 Equipped with: HDMI and VGA connection at the podium Projector and two 70\" display with independent inputs Overhead audio Microphones (ceiling, handheld and lavalier) Crestron Touch Panel with matrix style input-to-output mapping Extron recording from one or two video sources and all microphones, concurrently (Excluding HDCP protected content) Live Streaming Zoom Rooms control panel for Zoom video conferencing Apple TV Multiple Whiteboards Removable back wall for larger events needing to overflow into the atrium Schedule Please do not invite yourself to events on this calendar or create reservations for yourself. Reservation requests must be made through the reception ( reception@cs.brown.edu ) and all others will be deleted.", "https://cs.brown.edu/about/rooms/": "Rooms This page lists the rooms that we use to hold classes, TA hours, labs, and many other scheduled events. A few Brown CS-operated classrooms and labs have their own web pages with information for the people who use them. CIT 101 A meeting room that features audio-visual capability with Zoom. Schedule (Contact reception at cs.brown.edu to reserve) Capacity: 25 CIT 102 A meeting room that features audio-visual capability with Zoom. Schedule (Contact reception at cs.brown.edu to reserve) Capacity: 10 CIT 143, The Sunlab A lab consisting of 73 Maxbuilt PCs running Linux and two running Windows 7, the Sunlab is the primary computing resource for computer science undergraduates. The lab is available days and evenings (and sometimes around the clock). Schedule (Contact problem at cs.brown.edu to reserve) Capacity: 135 CIT 165, Motorola A lecture hall with rows of seats. Often used for lectures, recitations, and review sessions. This room is managed by CIS, so please contact Media Services (3-3600) for any audio-visual or Zoom problems. Capacity: 73 CIT 167, The MLab A classroom and cluster of Maxbuilt PCs running Mac and Linux. The MLab is a common location for large labs and for courses which use MacOS. Schedule (Contact problem at cs.brown.edu to reserve) Capacity: 22 CIT 201, Undergrad Computing Lab A large room with Linux Machines and also desks with monitors, keyboards, and mice that students can hook their laptops up to. This room follows the Sunlab hours. CIT 203 TA-Lab A computer lab used for hours and course development by TAs. CIT 205 TA-Lab A computer lab used for hours and course development by TAs. CIT 207 TA Room A room used by TAs for course development and hours. There are no computers in this room. CIT 209 This is a small lab used by UTAs. UTAs are allowed to reserve this room through the MTAs. CIT 210 A meeting/conference room. It doesn't have full Zoom room capabilities, but occupants can still use Zoom with their laptops and take advantage of the Owl, which can be thought of as a webcam. If you run into any problems with the Owl, contact Anthony Silva or Media Services. You can connect a laptop or use airmedia to the display only. This room also has a white board and large 70-inch monitor. Unfortunately, the monitor isn't fully viewable at the far end of the table. Before booking a meeting, we suggest visiting the room in person to make sure it's suitable. Brown card swipe access is required: please contact dawn_reed@brown.edu or call at 863-7612 for more information. Schedule (Contact reception at cs.brown.edu to reserve) Capacity: 18 CIT 219 A classroom with rolling whiteboards, small tables, projector, and audio-visual capability. Sometimes used for TA hours. This room is managed by CIS, so please contact Media Services (3-3600) for any audio-visual or Zoom problems. Capacity: 48 CIT 227, Moonlab A small classroom which is used by classes and for TA hours. This room is managed by CIS, so please contact Media Services (3-3600) for any audio-visual or Zoom problems. Capacity: 85 CIT 241, Swig Board Room A classroom/conference room that features audio-visual capability with Zoom. It's set up with tables and chairs. Brown card swipe access is required: please contact dawn_reed@brown.edu or call 863-7612 for more information. Schedule (Contact reception at cs.brown.edu to reserve) Capacity: 45 CIT 271, Fishbowl This room contains a cluster of Linux machines used by Mosaic+ members. CIT 316 A meeting room and classroom that features audio-visual capability with Zoom. Capacity: 25 Schedule (Contact reception at cs.brown.edu to reserve) CIT 348, TA-Lab A computer lab used for course development by the undergraduate TA program. CIT 367, J-Lab A computer lab used by the undergraduate TA program for course development and interactive grading sessions. CIT 368 A classroom and conference room that features audio-visual capability with Zoom. Schedule (Contact reception at cs.brown.edu to reserve. CIT 368 cannot be booked during the spring semester. This room is being reserved for our faculty search talks and for thesis defenses.) Capacity: 56 CIT 410, The Library Meeting room and conference room and no longer a Zoom room with all its capabilities. Occupants can still use Zoom with their laptops and take advantage of the Owl, which can be thought of as a sophisticated webcam. If anyone runs into any problems with the Owl, they can contact Anthony Silva or Media Services. Schedule (Contact reception at cs.brown.edu to reserve) Capacity: 25 CIT 477, Lubrano Conference Room A classroom and conference room that features audio-visual capability with Zoom. Schedule (Contact reception at cs.brown.edu to reserve) Capacity: 65 CIT 506 A classroom and conference room that features audio-visual capability with Zoom. Smaller and less formal than Lubrano. Schedule (Contact reception at cs.brown.edu to reserve) Capacity: 30 CIT 508 A conference room that can be reserved by students for one-on-one meetings, private calls, or Zooms, but NOT for recurring meetings. Please note that they have no technological capabilities and feature only a table, four chairs, and a whiteboard. Schedule (Contact reception at cs.brown.edu to reserve) Capacity: 4 CIT 510 A conference room that can be reserved by students for one-on-one meetings, private calls, or Zooms, but NOT for recurring meetings. Please note that they have no technological capabilities and feature only a table, four chairs, and a whiteboard. Schedule (Contact reception at cs.brown.edu to reserve) Capacity: 4 CIT 512 A conference room that can be reserved by students for one-on-one meetings, private calls, or Zooms, but NOT for recurring meetings. Please note that they have no technological capabilities and feature only a table, four chairs, and a whiteboard. Schedule (Contact reception at cs.brown.edu to reserve) Capacity: 4 CIT Atrium3 Open area on the 3rd floor, sometimes used for overflow from Room 368. Schedule (Contact reception at cs.brown.edu to reserve) CIT Atrium4 Open area on the 4th floor. Schedule (Contact reception at cs.brown.edu to reserve) SciLi 804 Conference room on the 8th floor of the SciLi. Brown card swipe access is required for all those attending a meeting or engaging in research on the Sciences Library 8th floor. Please send a list of meeting participant names and their Brown ID numbers at least 3 days in advance of your reservation date to Suzanne_Alden@brown.edu or Dawn_Reed@brown.edu to ensure their access to the space. Schedule (Contact reception at cs.brown.edu to reserve) Capacity: 20", "https://cs.brown.edu/about/rooms/sunlab/": "The Sunlab CIT 143 The Sunlab is the primary facility for undergraduate computer science. It is the latest incarnation of a facility that first appeared in 1982. The machines in the Sunlab are equivalent to those used by graduate students, staff, and faculty, and are an integral part of the Computer Science Department network. For questions about using/accessing the department computers, see the Sun Lab Consultant FAQ Schedule Work From Home Guides Windows Mac OS X Platform agnostic (including Linux, *nix, etc.) Android Links for Working from Home FastX PuTTYgen and PuTTY XQuartz MobaXTerm WinSCP People Sunlab Consultants Head Consultants Other Information House Rules Computer System Policies", "https://cs.brown.edu/about/rooms/sunlab/hours/": "Sunlab Hours Sunlab Hours Opening Closing Mon-Thurs 9am midnight Fri 9am 10pm Sat noon 10pm Sun noon midnight", "https://cs.brown.edu/about/system/accounts/email/": "Email Your Brown email is your CS email. The CS Department offers a mail forwarding service for addresses of the form shortID @cs.brown.edu Where shortID is your Brown short ID (aka logname or username). By default, this address forwards to your regular Brown email address. You can change that forwarding address to anything you like. Note that we do not provide alternate CS addresses to CS users - your address must be your University-issued short ID. Your CS address does not expire, ever. Change your email forwarding address At https://cs.brown.edu/account/ you will have the opportunity to change your preferred email address as well as a few other personal items. You should login to that page using your ldap password. If you are already logged into the website, look for the profile icon in the lower right hand corner of the website (upper right on the home page). Mailing Lists The Department runs its own email discussion lists . Beware of Phishing Phishing emails are bogus emails that try to trick you into giving away your personal info. Read the Phishing Primer provided by CIS IT service center.", "https://cs.brown.edu/about/system/accounts/passwords/": "Passwords With one exception, CS systems authenticate against the University's Active Directory, which means that your username and passsword are the same as for Banner, wifi, Workday, etc. If you need to reset your University password, go to https://myaccount.brown.edu . Here are three methods (stolen from a Yale web page) for creating passwords that are hard to guess yet easy to remember: 1. Randomly pick alternating vowels and consonants. Throw in a digit or two (or change a letter or two to a digit) and punctuate. Mix up the case (randomly capitalize for best effect). This will create passwords that have no meaning in the real world but which can still be sounded out (e.g., Me1&BopA). 2. Combine three and four character words with a punctuation character or digit between them, modify the case of some of the letter and change some of the others to digits or punctuation -- or add digits/punctuation to the beginning or end of the password (e.g. '0Yum|fUn'). 3. Randomly pick a book, poem or song. Select a phrase from the work and use the first character of each word in the phrase as your password. Capitalize some of the letters and add in at least one punctuation character and digit (or change some of the existing letters to punctuation and/or digits). For example, the phrase 'Four score and seven years ago our forefathers...' might become '4s&7YaOf'.", "https://cs.brown.edu/about/system/connecting/fastx/": "FastX FastX is a remote desktop service developed by StarNet Communications, which allows you to connect from your personal machine to our systems using a normal graphical interface as if you were sitting at a department machine. FastX also has far less network lag than using X forwarding over regular SSH. Detailed Instructions Follow the steps for setting up an ssh keypair. If you are running Windows, you will also need to install and run Pageant (described under the Windows ssh instructions ). Download and install the FastX 3 desktop client from https://www.brown.edu/information-technology/software/catalog/fastx-0 - CIS has a license for all of Brown, so the download links should appear after logging in. IMPORTANT: We are now running FastX version 3 . Do not use the FastX version 2 client - the versions are incompatible. OSX users - Drag the \u201cFastX\u201d icon into your /Applications directory to make it easier to find and run later. 32-bit Linux users - the \u201cGet FastX for Linux\u201d link will download a 64-bit binary. Contact problem@cs.brown.edu for a copy of the 32-bit binary. Run FastX. Click the plus sign at the top right to add a new connection configuration. You\u2019ll be presented with two options, \u201cssh\u201d and \u201cweb\u201d. Select \u201cssh\u201d. Fill out the form with the following information: Name = [whatever you want] Host = fastx-cluster.cs.brown.edu Port = 22 [should be the default] User = [your CS username] Path = fastx-protocol [should be the default] Forward Agent Connections = check this if you are on Windows and running Pageant, otherwise leave unchecked Click \u201cSave\u201d after entering the above information. You might be presented with a warning that \u201cThis host is not recognized by the system. Are you sure you want to continue?\u201d Click Continue. This should create a new entry in the list. Double click on that - it should try to connect. Enter your key passphrase when prompted. (If you have not previously logged into FastX, ssh, or any lab machine, or if you have recently changed your University password, you will also be prompted for your University password and Duo 2-factor auth.) This should open a new window. You are now connected to FastX but have not created a session yet. The new window should present you with a few different session options: \u201cGNOME\u201d, \u201cXFCE\u201d, or \u201cXTerm\u201d. If you don\u2019t know what these are, or don't have a preference between desktop environments, pick \u201cXFCE\u201d. Make sure Window mode is \u201cSingle\u201d, then click \u201cOK\u201d. This should start a session on one of the virtual desktop machines in the FastX cluster, and open a window that looks like a normal desktop session. You might have to resize the window a bit. Other Issues If you have any issues not covered here, contact someone on the technical staff for help .", "https://cs.brown.edu/about/system/connecting/openvpn/": "OpenVPN A VPN (Virtual Private Network) provides a mechanism whereby a machine outside of the CS department's trusted network can securely access the department's resources. Typically, users connect to the VPN when they have access to a high speed internet connection, i.e. a cable modem or another university intranet, and require access to departmental resources which are not typically provided outside the firewall. Departmental VPN servers The department provides an OpenVPN server. This server has two configuration types available for download: Browncs and Browncs-gateall. Browncs routes only traffic destined for a brown CS department IP through our VPN, leaving your computer to route other traffic as it sees fit. Browncs-gateall passes all traffic through the CS department. While browncs-gateall is not optimal for continual use, it does have some benefits over browncs - for example, if you wish to access Brown University Library services or other university-based web services. Setup Overview To use the Brown CS VPN, you will need to use your Brown account username and password (this is the same account you use to log into CS Deparment Linux systems). After installing an appropriate OpenVPN client (see OS specific instructions below) download the Brown CS OpenVPN client certificate and config files . Configuration Files Use <username>_browncs.ovpn when all you want to do is access Brown campus resources. Use <username>_browncs_gateall.ovpn when you want all network traffic to appear as though it originates from the CS department. This can be useful when accessing internet resources only available to Brown campus machines. ***The client certificates in these packages are specific to each user.*** Detailed Setup and Configuration Windows Instructions Mac OS X Instructions Linux Instructions Problems If you've followed the directions here and still can't connect to the department's VPN, then contact our technical staff for help.", "https://cs.brown.edu/about/system/connecting/": "Connecting Remotely Internet access to the Brown Computer Science Department network is restricted by a firewall. The firewall protects our computers from outside attackers, but it also limits the ways legitimate users can access the department. This page describes how to get at department computing resources from outside the department. What does remote access let me do? You can: Work in a shell ( SSH or Mosh ) Connect through OpenVPN Read your email Display X client applications Run a remote desktop session using FastX Copy files to or from your CS account Mount department filesystems via Windows (CIFS) Access your home directory using VS Code (requires an active VPN connection) You cannot: Mount department filesystems via NFS See the Remote Access page for information about connecting to the CS Department. See Connecting in the CIT page for information about access from within the CIT building. How to connect to the department and your home directory using VS Code : Have an active VPN connection. Open VS Code and select the \" Remote Explorer \" icon in the left sidebar. Note that you need Microsoft's \"Remote - SSH\" extension installed to see this Hover your cursor over \"SSH TARGETS\" (or whatever text is below \"Remote\") and select the + icon. Type: <your_brown_username>@fastx-cluster.cs.brown.edu Note that we expect you to have setup SSH through the department already as using VSCode requires you to have SSH key authentication. If this doesn't automatically start a SSH session, you need to then specify a remote window. If you click on the bottom left-hand corner, it should say \"start remote window\" and you can then choose if you want to create a new one or use the current window. If VSCode is saying \"Connection failed\" when it looks like you are connecting normall inside the terminal, you need to add \"ConnectTimeout 30\" into your ssh config under the fastx host. Awesome, you should be connected now! (congrats) Now, let's access your home folder as your default directory. Select the \"Explorer\" icon in the left sidebar. Select the blue button \"Open Folder.\" Select your home folder from the modal windo w VSCode for Windows Users If you are using Windows, you may need to do some extra steps to get this working. Please see the general VSCode extension guide for a further reference. You will need the OpenSSH client installed for Windows, which you can install using these instructions . Further, if you've used PuTTY you will need to convert your PuTTY key into an OpenSSH compatible key which you can do following these instructions .", "https://cs.brown.edu/about/rooms/mslab/": "The MLab Schedule", "https://cs.brown.edu/about/system/connecting/ssh/": "SSH Ssh (Secure Shell) is a program used for logging onto a remote machine or for executing commands on a remote machine. It provides secure encrypted communications between two hosts over an unsecured network. X11 connections and arbitrary TCP/IP ports can also be forwarded over the secure channel. Keypair Authentication You will need to upload public keys for each device you wish to use to connect to the CS department. You can upload keys to your CS website profile page . The first time you log in to ssh, after entering the passphrase associated with your ssh key, you will need to enter your University password and do Duo 2-factor authentication. On subsequent logins, you will only need to enter the key passphrase (until you change your University password). Detailed Step-by-Step Guides Windows instructions Mac OS X/Linux instructions Android instructions Problems If you've followed the directions here, looked at the detailed instructions, and still can't get in, contact someone on the technical staff for help .", "https://cs.brown.edu/about/system/ergo/": "Ergonomics This page contains information on Repetitive Strain Injury (RSI), ergonomic advice, and resources available in the Brown community. The advice here should not be used in lieu of contacting a medical professional. Additional resources are available in the Department of Computer Science through the \"ergo merc\": we have a pool of keyboards and mice that you can use to evaluate before buying and lots of practical advice on RSI prevention, treatment, insurance difficulties, etc. Please email the ergo merc (currently Ben Abbatematteo if you have any questions or need assistance. Useful links What is RSI? What you should do if you feel pain Prevention Treatment and recovery A special note on laptops List of ergonomic equipment in the pool Books, links, and other resources Brown Resources Brown University Safety Specialist, Stephanie Santucci: (401) 863-1522 Brown Health Services : (401) 863-3953 Student and Employee Accessibility Services : (401) 863-9588 Brown Psychological Services : (401) 863-3476 Office of Insurance and Purchasing Services : (401) 863-9481 Environmental Health and Safety (EHS) : (401) 863-3353 Brown University EHS staff are available upon request to assess workstation ergonomic needs for Brown faculty, staff and students. They are also available to meet with departments proactively to provide Office Ergonomics Training. EHS offers a guide to Sit Stand Adjustable Workstation Guidance. Quick Healthy Working Tips Modifying your behavior to practice healthy work habits (along with regular work breaks, described here ) will vastly help you prevent and recover from typing injury. Take the time to look down at your hands occasionally to make sure your forearms are in neutral, prone positions (straight lines, as depicted below) and not twisted or bent. It can take weeks or months to re-train yourself, but this process is essential to preventing pain and injury.", "https://cs.brown.edu/about/system/services/printing/printers/": "Printers The department maintains several printers located in the CIT. Department etiquette dictates that large printouts be queued early in the morning or late at night, unless it's an urgent need Please read the Printer Use Policy to ensure you are making appropriate use of the department printers. See the printing page for information how to print from Linux, Windows, and Mac NOTE: Printing and printer installs over Wi-Fi must be done while connected to our . For instructions on setting up vpn access, please see our . The CS print server, printhost.cs.brown.edu, has the following printer queue names: Printer Queue Name Printer Model Room Number Capability BW1 HP LaserJet 600 M603 143 - Sunlab Double-sided B&W: Paper BW2 HP LaserJet P3015 271 - TA room Double-sided B&W: Paper, Letterhead BW2-205 HP LaserJet M604 205 Double-sided B&W: Paper BW3 HP LaserJet M604 350 - hallway Double-sided B&W: Paper BW4 HP LaserJet Enterprise M608 480 - copy room Double-sided B&W: Paper BW5 HP LaserJet P4015 548 Double-sided B&W: Paper, Letterhead C3 HP Color LaserJet CP4025 350 - hallway Double-sided Color: Paper C4 HP Color LaserJet CP4025 480 - copy room Double-sided Color: Paper C4HQ HP Color LaserJet 4700 470 Double-sided Color: Paper CLF4HQ HP Color DesignJet Z5200 480 Single-sided Color: Coated Paper Roll C5 HP Color LaserJet CP4025 548 Double-sided Color: Paper CCMB-C2-243 HP Color LaserJet MFP M476dn 243 Double-sided Color: Paper CCMB-C2-247 HP Color LaserJet MFP M476dw 247 Double-sided Color: Paper SciLi-BW HP LaserJet 600 - M601 SciLi 802 Double-sided B&W: Paper More details The B&W Laserjets are 24 page-per-minute high quality printers. They are also duplex' printers, providing two-sided printing. The names in the first column are valid names for use with the -P option to the printer commands lpr(1), lpq(1), and lprm(1). Wi-Fi printing should be done over vpn . For instructions on setting up vpn check out this page. Restrictions The clf4hq print queue is a restricted print queue for faculty and graduate students only. The clf4hq printer is a large format printer capable of printing 42\" width image.", "https://cs.brown.edu/about/system/help/": "Help Problem Sometimes, things break. When they do, it's nice to have someone to call. Tstaff maintains a problem resolution system. Each day, a member of the technical staff responds to all system problems. That person is responsible for resolving each problem, or forwarding it to someone who can. To contact the designated problem person, send email to problem@cs.brown.edu . Submitting a Problem Ticket When sending an email to problem, please include the following information. This will greatly aid us in fixing your problem quickly and completely. (If it's an urgent situation, please call the tstaff cell phone which is available during University business hours - 401-316-2334 ) The name of the machine The OS of the machine which has the problem (e.g. Windows 10,Linux) The software packages being used (e.g. Chrome, Office, OpenVPN) Is the problem transient or repeatable? If possible, specific steps to reproduce the problem Software Problems Some software is supported by tstaff, and some isn't. See software support page for details. Supported Software Users with software problems should first try to resolve their problems with the man pages provided with the operating system or specific software package, or with the hardcopy documentation. If the problem cannot be resolved by this approach, send mail to problem . Unsupported Software For help with unsupported software (see section Unsupported Software ) ask the owner of the program. Hardware Problems Some hardware is supported by tstaff, and some isn't. The few remaining Suns, all tstaff-built PCs (MaxBuilt) running Windows or Linux, all networking (see the \"self-managed\" network ), and the printers (see printers ) are supported by tstaff. Supported Hardware If the problem is a hardware problem (ie. frozen workstation, jammed printer, etc.) send mail to problem@cs.brown.edu . Users are not to attempt hardware repairs themselves. Unsupported Hardware For help with unsupported hardware, contact the machine's owner/administrator. forum.cs.brown.edu (under service) Tstaff is developing an instance of discourse that will be accessible to anyone with a brown login. Some features and resources available through forum: FAQs run by tstaff and sunlab consultants for common issues faced. Announcements and updates from tstaff People can post about any questions they have or issues they encounter Members of the community can post and respond to each other to share information Forum exists as a space for the cs community to connect online. For more information on how to use the site and what the different categories/terms mean, the discourse staff put together an extensive guide on getting used to the site. Additional questions can also be directed to tstaff via emailing problem or posting on discourse.", "https://cs.brown.edu/about/system/managed/latex/": "The LaTeX Page For the impatient: Packages alphabetically Local FAQ General TeX FAQ Welcome to the (La)TeX page! Here you will find information about the TeX setup at the Computer Science Department at Brown University, available commands and how to use them, (La)TeX primers and package documentation, and pointers to other useful TeX-related sites on the Web. Warning: These pages contain no (La)TeX source or distribution packages, only documentation. If you are running (La)TeX on non-departmental machines note that some of the information may not be applicable to your installation. Our TeX Setup The currently installed version of TeX is 3.14159 as provided by the Web2C-7.4.5 distribution. The supported version of LaTeX is the 2001 version of LaTeX2e (LaTeX2e is the recommended version of LaTeX, and the older version LaTeX 2.09 is obsolete). Public files are organized in a tree structure that obeys the TDS standard . Our TDS tree is rooted at /usr/share/texmf . If you have LaTeX input files of your own, you should define the TEXINPUTS environment variable in your startups. This variable contains a colon-separated list of directories with inputs for latex2e . You do not need to include the system directories on this list, just your own directories (the initial colon provides that the system directories are included). In csh you would need something like this: setenv TEXINPUTS :.:<your latex2e directory 1>:<your latex2e directory 2>... Collaborative LaTex Editing The department is working with the library to pilot a test of ShareLaTex ( https://www.sharelatex.com/ ), an online, collaborative LaTex editor. If you are interested in having access to the system, please email problem@cs.brown.edu and provide your @ brown.edu email address. TeX-related Commands tex - plain TeX latex - Same as latex2e, see below xdvi - DVI previewer for X ( The online documentation for xdvi only available as a unix \"man\" page and is not provided in the teTEX documentation. Use man xdvi to read it. ) dvips - convert a DVI file to Postscript makeindex - a general purpose, formatter-independent index processor bibtex - make a bibliography for LaTeX (see also bibtex ) texinfo - a macro package for TeX used by the GNU system for producing printed manuals tib -another way to create bibliographies for (La)TeX ( available on our Solaris machines, please see the \"man\" page for documentation ) mf - the metafont program for generating fonts mp - the metapost program for generating Postscript figures latex2html - convert LaTeX files to HTML xfig - X11 drawing program; can generate LaTeX figures in a variety of formats lgrind - produce nice program listings using LaTeX Local FAQ Questions that we find ourselves answering often are here . Primers The canonical documentation for (La)TeX may be found in these books: The TeXbook , by Donald Knuth The original book describing the guts of the system, written by the guy who wrote TeX in the first place. LaTeX: A Document Preparation System , by Leslie Lamport , Addison-Wesley, 2nd ed, 1994. Leslie Lamport originally wrote LaTeX; this book is the book to buy to learn LaTeX. The second edition documents LaTeX2e. The LaTeX Companion , by Goossens, Mittelbach and Samarin, Addison-Wesley, 1994. Written by members of the LaTeX3 project, it describes further how to use LaTeX2e and documents additional classes/packages. A Guide to LaTeX , by Kopka and Daly, Addison-Wesley, 1999. This book is a more recent one and offers considerably more information than the earlier books. Useful on-line primers include: The Not So Short Introduction to LaTeX2e A longer (87 pages) more in-depth introduction to LaTeX2e. Also a good starting point. LaTeX Command Reference Manual Describes all LaTeX2e commands. Don't expect to learn LaTeX from this. Symbols in LaTeX A six page list of available mathematical symbols. A LaTeX Surivical Guide for Unix Systems This document describes how to run LaTeX and utilities on a Unix system. Including Graphics in LaTeX2e Documents Everything you ever wanted to know about using Postscript graphics in LaTeX documents. Packages in the graphics bundle This provides a documentation on the recommended LaTeX2e graphics package, which includes information on how to use colours in the output. HTML documentation of many LaTeX topics at NASA. Documentation LaTeX2e User's Guide , class and package author's guide and font guide . LaTeX2e packages AMSLaTeX and the AMS fonts Babel Packages in the graphics bundle The PSfrag system (PSfrag system allows you to import PostScript figures from any other package, but use LaTeX's power for all of the mathematical and textual annotations. (Note that xfig allows you to do this anyway).) Creating graphics with MetaPost Creating graphics with PSTricks part1 , part2 , part3 , part4 XY-pic user guide and reference manual Using BibTeX and writing BibTeX styles Creating custom BibTeX styles with makebst Creating indices with makeindex Pretty-printing with lgrind Brown PhD thesis class file Brown Honors thesis class file Brown letterhead ( class file , logo , example letter ) Brown PhD and Honors thesis class files are available on the CS Dept intranet only Other TeX-related Resources on the Web (La)TeX Navigator A Collection of Computer Science Bibliographies (BibTeX) TeX, LaTeX, etc. FAQ Credit where it's due: These pages were originally created and maintained by Dimitris Michailidis and Manos Renieris.", "https://cs.brown.edu/about/system/services/cshe/": "CS Home Edition The CS Department runs on Linux . Brown CS has used a common platform for teaching and research (almost) as long as it has existed. Department desktops, servers, and hosted systems all share a standard operating system and configuration. CS Home Edition builds on this tradition by making it easy to recreate that platform on your own computer. How to Download and Install CS Home Edition Features What CS Home Edition adds to Linux: Simplified installation with sensible defaults Perfect version match with CS Department OS and software Nightly updates to keep you in sync with the department Preconfigured access to department services Automated Brown user identity Requirements CS Home Edition can be run on any intel-based computer and as a virtual machine. A target system. This can be VirtualBox (recommended for most) Parallels (recommended for M1 Mac) VMWare Fusion Windows Hyper-V Your own hardware (i.e., a bootable USB drive) At least 32G of disk space Internet service Getting Help Send mail to problem CS Home Edition is a new idea to help support remote learning and research environments. It is under active development by the CS Technical Staff.", "https://cs.brown.edu/about/system/services/printing/policy/": "Printing Policy bw1 All printing from undergraduate accounts as well as any course related listings should be directed to the Sunlab's HP laserjet printer (bw1). Printing should be picked up immediately. Undergraduate Printing Policy You must be in the Sunlab or MSlab when printing. You must be standing in front of the printer when your job is printing. You may print only CS course-related work. You must keep the length of your printouts under 20 pages. Any printout that does not meet these requirements should be printed to a CIS printer. This policy will be enforced by the Sunlab consultants, and repeat violators will lose printing access. Other printers The department's other laserprinters (both B&W and color), may only be used by the following people: Faculty, staff and graduate students in support of the department's research and administrative efforts. Course TAs producing course-related materials. You can find a list of printers here. See the wiki for instructions on printing.", "https://cs.brown.edu/about/system/services/printing/mac-os-x/": "Mac OS X Instruction Printing and printer installs over Wi-Fi must be done while connected to our vpn . For instructions on setting up vpn access, please see our vpn setup page . Mapping a Printer from the CS Print Server Mac OS users should install the HP Driver pack from Apple before attempting to use one or our shared printers. For Mac OS Mavericks and newer, the driver pack can be found here: https://support.apple.com/kb/dl1888 For the advance Mac users, here is the basic the printer connection info you need: Protocol: IPP Address: print.cs.brown.edu:631 Queue: /printers/<queue name> (where <queue name> is the queue on the print server i.e. bw4) Name: <printer name> i.e. BW4 Detailed Instructions 1. Log on to Mac OS with an account with admin/root privilege (try current login if unsure). 2. Click on the \"Apple\" icon on the upper left corner of the screen. 3. Select the \" System Preferences\" from the menu list. 4. Click on the \"Printers and Scanners\" icon. 5. If you have old CS printers mapped that are no longer working click the minus symbol to remove them before proceeding. On the \"Printers and Scanners\" dialog box, click on the plus sign near the bottom left hand corner of the dialog box to add a printer. 6. On the \"Add\" dialog box, click on the \"IP\" icon. 7. In the \"Address:\" section, enter the \"print.cs.brown.edu:631\" without the quotes. 8. The \"Protocol:\" section should be set to \"Internet Printing Protocol - IPP\". 9. In the \"Queue:\" section, enter \"/printers/<queue name>\" where <queue name> is the print queue on the print server i.e. /printers/bw4 for the bw4 printer. 10. In the \"Name:\" section, enter a name for the printer connection i.e. BW4 for the bw4 printer. 11. In the \"Use:\" section, choose \"Select Software\" to pick the correct printer driver for the printer connection. See the printers page for the exact printer model. Pick the driver closest to the printer model i.e HP LaserJet P4010 for BW4 or BW5, going with the \"Series\" driver when the exact model # is not available. 12. Click on the Add button to continue with the printer connection wizard. The printer setup will ask you to select some settings. The \u201cduplex unit\u201d or \u201cduplexing\u201d option should be selected to enable two sided print jobs. (All CS printers, except CLF4HQ, have duplexing units). The other default options are sufficient. 13. Click \"OK\" to finish adding the printer. *If you get a warning message stating something similar to \"Unable to verify the printer on your network\" click on the \"continue\" button to proceed.", "https://cs.brown.edu/about/system/services/printing/": "Printing Departmental printers can be accessed via our print server print.cs.brown.edu . You can access this print server from any departmental network, or wirelessly when connected through the CS VPN . It h osts a variety of print queues for all the department network printers . See the printing policy for usage limitations. Bonjour/DNS Available Printers Most Apple products will detect printers that are shared to the network using mDNS packets that adhere to the Bonjour standard. Those network packets provide details about the devices available on the network, for easy installation or access. In accordance with this feature we offer the following printers, which show up automatically when a host is wired to our network or connected to our VPN. BW1 C4 BW2 C4HQ BW2-205 C5 BW3 CCMB-C2-243 BW4 CCMB-C2-247 BW5 CLF4HQ C3 SciLi-BW *For WIndows users, the names above should be used with \"_windows\" add. i.e. c4_windows When adding an auto-discovered printer it is important to note that capitalization and the name itself must be identical to the list above. If you do not see a printer that is listed above or the name is in any way different form that list, please visit the printer page on our cups server to get the official list of printers being offered by our server. (https://print.cs.brown.edu:631/printers/) Printing in the Sunlab See the Printing in the Sunlab page for more information. Tstaff Managed Systems All managed department machines are configured to use the internal print server. No user configuration is required. Linux As with many things in Linux, there are quite a few printing commands . Some of the most important are: ' lpstat -a ': show the list of printers available on the print server ' lpr ': send a file in text, postscript or pdf format to the printer Viewing the current jobs in a Linux print queue You can view the current jobs in a Linux print queue by running: lpq -P<print queue>, where <print queue> is the name of the queue (e.g. bw4). The command will return something similar to: bw4 is ready and printing Rank Owner Job File(s) Total Size active esatoh 373926 smbprn.00001934 https://library 76622848 bytes 1st esatoh 373927 smbprn.00001935 https://library 21590016 bytes Windows In Windows, most programs let you print from the File-Print menu of that application. To see the list of printers, go to the Start Menu, select Control Panels, and then Devices & Printers. All printers are available except for the clf4hq printer. Self Managed Systems Printer Mapping Instruction for Self Managed System or over Wireless network Windows *Please only use printer names ending in \"_windows\". i.e. c4_windows Mac OS X *HP driver pack for Mac OS Mavericks and newer can be found here: https://support.apple.com/kb/dl1888 Linux Other Printing Issues If you encounter a physical problem with a printer (jammed, out of toner or ink, etc) and have not been ``trained'' in how to fix the problem, please do not try to guess your way through. Use the problem facility to report the trouble, or ask a Tstaff member or one of those friendly veteran grad students. They'll show you how to fix it for the next time. Be especially hesitant to mess with the color printers. If your printout is on the wrong type of paper Occasionally, if you specify a certain type of paper and that tray is empty, the printer will automatically default to a different paper tray. If your printout ends up printed on a different type of paper than you expected, you might want to check the paper trays and make sure none of them are empty. How to print an A4 sized PostScript file Our printers print only on US Letter sized paper. Most European countries print on A4 sized paper, which is taller and narrower. Electronic documents formatted for A4 often will not print properly, or at all, on our printers. When printing an A4 document from a browser or application on any platform, it will be helpful to preview it and, if necessary, to scale it down before sending the job to the printer. The easiest way around this is to transform the A4-size document into a Letter-size document before printing it. How you do this depends on the format the document is in. If, for example, the document is a Framemaker document, you may find it easiest to reformat the document in Framemaker. The same goes for Microsoft Word, or Acrobat or many other document formats. How to print an A4 sized PostScript file in Linux In Linux, you can reformat any A4 postscript document using the following simple command. Most desktop publishing applications let you save a document as PostScript, usually from the Print menu. If the document is already in PostScript format, or if you cannot reformat it in some other way, try this. Let's say our A4 document is called euro.ps: % mpage -1o euro.ps> amer.ps % lpr amer.ps The resulting file, amer.ps, is in US Letter format.", "https://cs.brown.edu/about/system/services/printing/windows-instruction/": "Windows Instruction Mapping a printer on the Authenticated Printing Server IMPORTANT: Windows users can only use the printers with names ending in \"_windows\". i.e. c4_windows Follows these step to map a printer located on the authenticated print server. 1. Log on to the Windows system with local admin credential. 2. Click on the \"Start\" menu and choose \"Devices and Printers\". 3. Click on the \"Add a printer\" button at the top menu item. 4. Click on the \"Add a network, wireless or Bluetooth printer\" menu item. 5. Click on \"The printer that I want isn't listed\" menu item. 6. Choose \"Select a shared printer by name\" and enter the printer mapping using IPP. Here is an example for bw5_windows: https://printhost.cs.brown.edu:631/printers/bw5_windows For Windows, only the printers with names ending in \"_windows\" can be used for a list of printers browse to https://printhost.cs.brown.edu:631/printers 7. Click on the \"Next\" button. 8. Enter LDAP credential when prompted. Click on the \"Ok\" button to continue. 9. Choose the correct printer driver for the printer. 10. Click on the \"Next\" button to accept printer name. 11. Uncheck the \"Set as the default printer\" box. 12. Click on the \"Finish\" button.", "https://cs.brown.edu/about/system/services/hpc/": "Hydra Compute Cluster Hydra is a mythical multi-headed monster Hydra is the CS Department compute cluster for use by our faculty, staff, and students. Jobs are submitted to our cluster using the Slurm workload manager . We provide a slurm quick-start guide . Community There is an active group of researchers within the department working on computationally intensive research. The department continually tries to meet the needs of all researchers, by periodically adding new dedicated compute hardware. We encourage anyone involved in research requiring high performance computing to join the compute mailing list . Doing so will help you stay abreast of the latest compute-related changes within the department, and allow you to collaborate and exchange ideas with other cluster users. Policy and Appropriate Use The cluster is a general department resource and is available to all members of the CS community. Cluster users should only run jobs associated with legitimate research or educational activities. The cluster is a specialized tool, and should not be used to simply off-load normal desktop computing activities. If you are unsure if a proposed use of the cluster is appropriate, send mail to problem@cs.brown.edu and tstaff will render an opinion. CCV Cluster Resources The Center for Computation & Visualization has a large linux compute cluster which they make available to researchers across campus.", "https://cs.brown.edu/about/system/services/printing/linux-tips/": "Linux Tips Self Managed Systems On a self managed linux system, the easiest to connect to the printhost server is to use cups client. Depending on your flavor of linux and architecture, you use either aptitude or yum to install the cups-client packages as follows: Run as root: `aptitude install cups-client` or Run as root: `yum install cup.x86_64` Once the cup client is installed. Modify the /etc/cups/printers.conf file as follows: ServerName printhost.cs.brown.edu You will need to authenticate with your LDAP credential every time you print if your local username and password is different than what the printhost server is expecting. Command Line Printing The command lpr(1) sends a file to a printer. The CUPS version of lpr understands a variety of formats including, text, PostScript, and PDF. Many GUI programs, such as Mozilla and Acrobat, will print by passing arguments through LPR. Usually you can see the command the program will use after selecting Print from the File menu. Your default printer is specified by your shell's PRINTER environment variable. For new users, this is set to bw1 in the .environment file in your home directory. To change your default printer, modify your PRINTER environment variable in the appropriate location. Setting Print Options on the Command Line For the common tasks of printing single-sided, on letterhead, and on transparency, we have modified the command-line lpr program to accept -s, -l, and -t, respectively. The full feature command set for CUPS are listed below and is available from man lpr. Some common printer options: Printing non text/postscript documents from the command line lpr acrobatdoc.pdf Printing to a certain printer (i.e. bw4) lpr -Pbw4 mydocument Setting the Custom paper size to 42.1 x 42.1 inches lpr -o media=Custom.42.1x42.1in mydocument Setting Duplex Printing (two-sided-long-edge is default) lpr -o sides=one-sided mydocument lpr -o sides=two-sided-long-edge mydocument lpr -o sides=two-sided-short-edge mydocument Setting the media type (duplex is on by default, so turn it off) lpr -o media=Transparency -o sides=one-sided mydocument lpr -o media=Letterhead -o sides=one-sided mydocument Print on Letterhead for first page, Plain for remaining pages lpr -o sides=one-sided -o 1:media=Letterhead -o media=Plain mydocument Print multiple document pages on a printed page (N-Up) lpr -o number-up=2 mydocument lpr -o number-up=4 mydocument Print only odd or even pages lpr -o page-set=odd mydocument lpr -o page-set=even mydocument Print page ranges lpr -o page-ranges=5 mydocument lpr -o page-ranges=2-5 mydocument lpr -o page-ranges=2-5,7-9 mydocument Rotate page lpr -o landscape mydocument Set the percentage brightness lpr -o brightness=120 mydocument Set the Gamma correction ( 1000 is default) lpr -o gamma=1700 mydocument Print multiple copies lpr -n num copies -o collate=True mydocument Text Printing Options lpr -o prettyprint mydocument.txt lpr -o cpi=10 mydocument.txt lpr -o lpi=8 mydocument.txt lpr -o columns=2 mydocument.txt Setting Page Margins (in 1/72's of an Inch) lpr -o page-left=72 -o page-right=72 -o page-top=72 -o page-bottom=72 mydocument.txt Image Printing Options lpr -o position=center myimage {center,top,left,right,top-left,top-right, bottom,bottom-left,bottom-right} lpr -o scaling=100 myimage (1-800%) lpr -o ppi=300 myimage (dots per inch) lpr -o hue=-10 myimage (-360 to 360) lpr -o saturation=110 myimage (0-200%) Setting Default Options The printing options above can also be used to set default options for future print jobs. Use the lpoptions command with the same arguments above. The options will be saved in the .lpoptions file in your home directory. The following example will set 1/2\" margins and make text smaller: lpoptions -o page-left=36 -o page-right=36 -o page-top=36 -o page-bottom=36 lpoptions -o cpi=12 lpoptions -o lpi=7 To get all available options for a specific printer: lpoptions -p <printer name> Cancelling Jobs To cancel a job, use lprm and enter your LDAP password. Note that you have to cancel the job on the same printer you sent it to, specified with the -P option (example: lprm -P bw5). Each time you run lprm it deletes one job unless you give \"-\" as the last argument, in which case it deletes all your jobs. Graphically Setting Print Options To set printer options graphically, you may use the gtklp(1) command instead of lpr in exactly the same manner. After you click Print in your application, a tabbed window will pop up where you can set options such as letterhead and single-sided printing in a point-and-click manner. Most of the useful options are on the General tab. By default, changes to the options presented in gtklp apply only to the current print job and not to subsequent print jobs. If you have a set of options that you wish to be able to reuse easily in the future, you can click on \"Templates\" at the bottom. To permanently change your default options for this printer, simply click \"Save\". To save a set of options for this printer that you only want to use occasionally, type a name for this set in the box labeled \"Instance\", and then click \"New\". You can modify or remove these named sets of options later by clicking \"Templates\" later.", "https://cs.brown.edu/courses/cs016/static/files/docs/LatexHandout.tex": "%==============================================================================% Homework Template%==============================================================================%Fill out this line with the homework number\\newcommand{\\course}{CS 16}\\newcommand{\\hw}{Homework \\#}%==============================================================================% Formatting parameters%==============================================================================\\documentclass[11pt]{article}% 11pt article\\makeatletter% Make '@' accessible.\\pagestyle{myheadings}% We do our own page headers.\\def\\@oddhead{\\bf \\course: \\hw \\hfill} \\oddsidemargin=0in% Left margin minus 1 inch.\\evensidemargin=0in% Same for even-numbered pages.\\textwidth=6.5in% Text width (8.5in - margins).\\topmargin=0in% Top margin minus 1 inch.\\headsep=0.2in% Distance from header to body.\\textheight=8in% Body height (incl. footnotes)\\skip\\footins=4ex% Space above first footnote.\\hbadness=10000% No \"underfull hbox\" messages.\\makeatother% Make '@' special again.%==============================================================================% Packages used%==============================================================================\\usepackage{amsmath}% want AMS fonts\\usepackage[pdftex]{graphicx}% for including images\\usepackage{hyperref}% for links\\usepackage{enumerate}\\usepackage{/course/cs016/latex/cs0160}%==============================================================================% Macros%==============================================================================\\newcommand{\\hooray}[1]{#1}%==============================================================================% Title%==============================================================================\\begin{document}\\centerline{\\bf \\LARGE\\hw}\\section{What is LaTeX?}\\begin{itemize}\\item LaTeX is a document markup language\\item You prepare a (.tex) document, and compile it into a PDF\\item LaTeX helps make your homework pretty (just like this document!) and makes us happy when you use it!\\item Make sure to open the provided \\verb|.tex| file to see how we coded all of these examples\\end{itemize}\\section{Editing LaTeX files}\\begin{itemize}\\item You'll want to use some LaTeX editor to edit and compile your \\verb|.tex| files\\item Try using Kile for now by typing \\verb|kile| into your terminal, or open an existing \\verb|.tex| file by typing \\verb|kile filename.tex|\\item It may be useful to open Kile and Okular (a PDF viewer) side by side\\begin{itemize} \\item Then when you make a PDF from Kile (by clicking the blue gear with a PDF symbol), your product will refresh in Okular automatically\\item The PDF will be created in the same folder as your \\verb|.tex| file\\end{itemize}\\end{itemize}\\section{Code}Here is an example of putting code in your homework:\\begin{verbatim}def bubbleSort(A): swapped = True while swapped: swapped = False for i in range(len(A)-1): if A[i] > A[i+1]: A[i], A[i+1] = A[i+1], A[i] swapped = True\\end{verbatim}\\section{Lists}\\begin{enumerate} \\item Enumerate automatically makes appropriate \\item numbers or letters at the start of your \\item list items.\\begin{itemize}\\item[a.] Itemize uses bullets unless you make labels.\\item This has no label.\\item[i.] This has a label. \\begin{enumerate} \\item Nested lists\\item of the same kind\\item look different \\end{enumerate} \\end{itemize}\\end{enumerate}You can format any text as code, if you'd like, by declaring it as $\\backslash$\\verb|verb|$\\mid$\\verb|code here|$\\mid$.\\section{Tables}Perhaps you would like to put a table in your homework---here is how. Note that 'lll' means three left-justified columns, whereas 'lcr' would be a left-justified column, a center-justified column, and a right-justified column. Also, in a table (and in general) double backslash creates a \\\\new \\\\line.\\begin{center}% use packages: array\\begin{tabular}{lll}Name & Street Number & Other random number \\\\ Anastasia & 1441 & 13577893 \\\\ Bob & 6461 & 9085653233\\end{tabular}\\end{center}If you want lines on your table, just put them there with vertical bars and \\verb|\\hline|.\\begin{center}% use packages: array\\begin{tabular}{|l|c||r|}\\hlineName & Street Number & Other random number \\\\ \\hlineAnastasia & 1441 & 13577893 \\\\ \\hlineBob & 6461 & 9085653233\\\\\\hline\\end{tabular}\\end{center}\\section{Math}To make math things look like math, write them between dollar signs. If you use double dollar signs, then your math goes on its own line with nice spacing. You can write a lot of useful things this way.\\\\\\subsection{Sums}This is a plain old sum: $\\sum a_i = 10$\\\\This is a sum with upper and lower bounds: $\\sum_{i = 1}^{5} 1^i = 5$\\\\That's ugly, so here's a prettier version, also with double dollar signs: $$\\displaystyle \\sum_{i = 1}^{23} a^i = 5$$\\\\If we just want one character, we don't need braces: $\\displaystyle \\sum_1^8 x_i = 5$\\\\\\subsection{Fractions (and other math, like logs, exponents, and roots)}We can do a similar thing with fractions: $\\frac{1}{5}$\\\\Here's another version: $\\dfrac{1}{5}$\\\\Sometimes we get really complicated fractions: $(\\dfrac{\\sqrt{2} - \\log_2 (\\beta \\bmod x)}{\\log 5^{x + 1} \\times \\dfrac{2}{3}} \\times 5) + \\delta \\leq 12$\\\\Note: you should use $\\log$ and $\\mod$ instead of just typing 'log' and 'mod'. To do bases, you typically use an underscore. For example, $\\log_{2} n^2$.\\subsection{Prettier Equations and alignment}Align can be used to make your equations line up in nice ways. Note that the syntax is similar to the syntax for tables. It puts your equations in the center of the page and right-justifies them.\\begin{align*} x + 3 = 5 \\\\ 2x + 30 = 5000\\end{align*}You can use double ampersands to separate multiple equations on one line.\\begin{align} x + 3 = 5 && y < 1 && x = y \\\\ x + 3 = 5 && z \\ge 2\\end{align}In general, putting a * means that your equations won't get numbered.\\subsection{Big-O Notation}Big-O notation is just written with a big $O$, as in $O(n\\log n)$.\\subsection{Other random stuff that will be helpful}\\begin{itemize}\\item Floors and ceilings: $\\lfloor x \\rfloor$ and $\\lceil x \\rceil$\\item Comparison: $\\{\\leq, \\geq, >, <, =, \\neq\\}$\\item Macros: \\begin{itemize} \\item This is in \\verb|inline verbatim|. \\item I write $n \\log n$ a lot.\\end{itemize}\\item Special characters:\\begin{itemize} \\item $\\backslash$ (backslash) - escapes, begins macros \\item \\~ ~%this tilde is necessary to keep the tilde to the left from going over (tilde) - same with the tilde below(tilde) - an unbreakable space \\item \\_ (underscore) - subscripts in math mode (they cause errors outside of math mode) \\item \\^ ~(superscript) - superscripts in math mode (they cause errors outside of math mode) \\item \\{ , \\} (curly brackets) - group commands\\end{itemize}\\end{itemize}\\section{Images}You can also include images, such as this one:\\\\\\includegraphics[width=3in]{rabbit.jpg}\\section{Pseudocode}\\begin{pseudo}Surround your pseudocode with this environment, which will both respect your tabs and line breaks and allow $M \\alpha \\dagger h$ formatting to work. This environment comes with the package /course/cs0160/latex/cs0160.sty which is included at the top of this file.\\end{pseudo}\\section{If you're super fancy}\\begin{description} \\item[Firstly,]you can define macros by putting something like \\hooray{this} at the top of your homework:\\begin{center} \\verb|\\newcommand{\\command}[# args]{whatever you want using #arg1 #arg2 #argEtc}|\\\\ \\end{center} \\item[Secondly,]you can reflect, rotate, and scale text, and anything else:\\\\\\reflectbox{\\rotatebox{-5}{\\scalebox{2}{like this!}\\includegraphics[width=1in]{rabbit.jpg}}}\\\\ \\item[Thirdly,]you can include packages by putting this at the top of your homework:\\begin{center} \\verb|\\usepackage{package name}|\\\\ \\end{center}\\end{description}\\end{document}", "https://cs.brown.edu/courses/cs016/static/files/docs/PseudocodeStandards.tex": "%==============================================================================% Formatting parameters%==============================================================================\\documentclass[11pt]{article}% 11pt article\\makeatletter% Make '@' accessible.\\pagestyle{empty}% We do our own page headers.\\oddsidemargin=0in% Left margin minus 1 inch.\\evensidemargin=0in% Same for even-numbered pages.\\textwidth=6.5in% Text width (8.5in - margins).\\topmargin=0in% Top margin minus 1 inch.\\headsep=0in% Distance from header to body.\\textheight=9in% Body height (incl. footnotes)\\skip\\footins=4ex% Space above first footnote.\\hbadness=10000% No \"underfull hbox\" messages.\\makeatother% Make '@' special again.%==============================================================================% Packages used%==============================================================================\\usepackage{amsmath}% want AMS fonts\\usepackage{/course/cs0160/latex/psfig}% want to include EPS files\\usepackage[pdftex]{graphicx}% for including images%\\usepackage{algorithmic}% may want algo package\\\\usepackage{hyperref}% for links\\usepackage{/course/cs0160/latex/cs0160}% if you want all the nice CS 16 macros, use this package%==============================================================================% Title%==============================================================================\\begin{document}\\begin{center}\\begin{LARGE}\\textbf{CS 16 Pseudocode standards}\\end{LARGE}\\end{center}\\section*{Example: Java to pseudocode conversion}This example is NOT from Dasgupta, but may help those of you who are used to Java learn to write pseudocode.\\subsection*{Java Version}\\begin{pseudo}public int arrayMax(int[] intArray, int n) \\{int maximum = intArray[0];for (int i = 1; i < n; i ++) \\{if (maximum < intArray[i]) \\{maximum = intArray[i];\\}\\}return maximum;\\}\\end{pseudo}\\subsection*{PseudoCode Version}\\begin{pseudo}\\underline{procedure arrayMax} $(A, n)$Input: An array $A$ storing $n \\geq 1$ integersOutput: The maximum element in $A$$maximum = A[0]$for $i = 1$ to $n-1$:if $maximum < A[i]$: $maximum = A[i]$return $maximum$\\end{pseudo}For more resources on this, consult the \\href{http://cs.brown.edu/courses/cs016/static/files/lectures/slides/10_improvingPseudocode.pdf}{Improving Pseudocode Lecture}!\\end{document}", "https://cs.brown.edu/archive/submit/": "Submit Asset input { /* width: 100%; */ height: 1.5em; font-size: 1em; min-width: 33%; } input.bcsdr-submit { height: 100%; padding: 1em; background: #006992; color: #fff; font-size: 1em; border-radius: .5em; cursor: pointer; } Brown CS Digital Archive (BCSDA) Welcome to the submission form for the Brown CS Digital Archive (BCSDA), an extension of the Brown Digital Repository. Put simply, it allows anyone on the planet to submit a piece of Brown CS history for permanent preservation online, accessible to all. The BCSDA accepts more than a dozen different formats: Photos and other graphic files PDFs, audio, video, etc... Papers, abstracts, and posters Even code! (please submit a PDF containing descriptive text and a link to the source code) All assets go through a virus check and are verified for accuracy. Authors/creators retain all copyright. We would like items with real historical interest, so please do not send us your lecture notes, but you can visit www.cs.brown.edu/archive to see the wide variety of things that we are looking for. After verification from an appropriate staff or faculty member, your asset will enter the BCSDA and be available in perpetuity to anyone with an Internet connection. (Please be patient if we're getting a lot of submissions all at once.) Thanks for sharing your piece of Brown CS history! Submit New Asset Required * Name submitted by * (limit 250 chars) Email submitted by * (limit 250 chars) Asset Title * (limit 250 chars) Year * (4-digits) Description * (limit 750 chars) Asset file * Faculty (choose multiple Computer Science Faculty) Adam Blumenthal Alan Usas Alessandro Epasto Alexander Galakatos Alexander Steinmaurer Alper Ahmetoglu Amy Greenwald Andrew Crotty Andries van Dam Ankit Shah Anna Lysyanskaya Barbara Meier Benedetto Buratti Benjamin Greenman Benjamin Lerner Benjamin Raphael Bernardo Palazzi Bertrand Cambou Bruce Campbell Caroline Klivans Caroline Ziemkiewicz Carsten Eickhoff Carsten Binnig Chad Jenkins Chen Avin Chen Sun Christopher Crick Claire Mathieu Cristina Menghini Cyrus Cousins Daniel Ritchie Daniel Keefe Daniel Potter David Paulius David Laidlaw David Beazley Deborah Hurley Dina Goldin Donald Stanford Dora Erdos Doug Woos Elaheh Raisi Eliezer Upfal Ellie Pavlick Ellis Hershkowitz Erik Sudderth Erika Sudderth Ernesto Zaldivar Eugene Charniak Evangelos Atlidakis Fabio Vandin Franco Preparata Frank Pfenning Fumei Lam Gabriel Taubin Gayathri Garimella George Konidaris Gianluca Brero Gopal Pandurangan Grigory Yaroslavtsev Gunnar Klau Harini Suresh Ian Gonsher Iman Hajirasouliha Jake Russin James Hays James MacGlashan James Tompkin Jeff Huang Jian Chen John Savage John Jannotti John Clements John Hughes Jose James Joseph Laviola Julia Netter Karianne Bergen Kathi Fisler Konstantinos Stylianou Lawson Wong Liang Zhang Linn Freedman Lionel Reveret Lorenzo De Stefani Malte Schwarzkopf Mark Johnson Mark Nadel Martha Lewis Matteo Riondato Matthew Reyna Maurice Herlihy Megumi Ando Meinolf Sellmann Michael Littman Michael Black Michael Turchin Milda Zizyte Mohammed El-Kebir Musik Kwon Nancy Pfenning Nicholas DeMarinis Nikos Vasilakis Nikos Triandopoulos Nora Ayanian Norm Meyrowitz Omer Gottesman Pascal Hentenryck Paul Valiant Pedro Felzenszwalb Peihan Miao Peter Wegner Peter Wegner Philip Klein R Bahar Ravindra Pendse Ritambhara Singh Robert Lewis Roberto Tamassia Rodrigo Fonseca Roger Blumberg Ronald Parr Sarah Chasins Sarah Osentoski Seny Kamara Serdar Kadioglu Shahrzad Haddadan Sherief Reda Shriram Krishnamurthi Sohini Ramachandran Sorin Istrail Srinath Sridhar Stanley Zdonik Stefanie Tellex Stephen Bach Steven Reiss Subarna Shakya Suresh Venkatasubramanian Tarik Moataz Tharpe Stephen Strickland Theophilus Benson Thomas Sgouros Thomas Dean Thomas Serre Thomas Hofmann Thomas Doeppner Tim Nelson Tim Kraska Timothy Edgar Trevor Jay Tristan Dyer Ugur Cetintemel Vanessa Cho Vasilis Kemerlis Vincent Cohen-Addad Waleed Khamies Will Crichton Yoonseon Oh Yu Cheng Research areas (choose multiple) Algorithms and Theory Artificial Intelligence Computational Biology Computer Systems Database Systems Distributed Systems Graphics and Visualization Human-Computer Interaction Machine Learning Networking Programming Languages Robotics Security and Cryptography Software Engineering Communities (choose multiple) Faculty Undergraduate Students Master's Students PhD Students Staff Alums Buildings (choose multiple) 180 George Street Barus and Holley 151 Thayer Street The CIT 182 George Street", "https://cs.brown.edu/courses/cs016/static/files/docs/TexTemplate.tex": "\\documentclass[12pt,letterpaper]{article}\\usepackage{cs0160}\\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}\\usepackage{fullpage}\\usepackage{lastpage}\\usepackage{enumerate}\\usepackage{fancyhdr}\\usepackage{mathrsfs}\\usepackage[margin=3cm]{geometry}\\setlength{\\parindent}{0.0in}\\setlength{\\parskip}{0.05in}% Edit these as appropriate\\newcommand\\course{CS 16}\\newcommand\\hwnum{1} % <-- homework number\\newenvironment{answer}[1]{ \\subsubsection*{Problem \\hwnum.#1}}{\\newpage}\\pagestyle{fancyplain}\\headheight 35pt\\lhead{\\course\\ --- \\ ---}\\chead{\\textbf{\\Large Homework \\hwnum}}\\rhead{\\today}\\headsep 10pt\\begin{document}\\begin{answer}{1}1. True.2. False.3. True.\\end{answer}\\begin{answer}{2}Answer to problem 2 goes here, etc.\\end{answer}\\end{document}", "https://cs.brown.edu/courses/cs015/javadocs/cs15/fnl/sketchySupport/FileIO.html": "<!-- try { if (location.href.indexOf('is-external=true') == -1) { parent.document.title=\"FileIO\"; } } catch(err) { }//-->var methods = {\"i0\":10,\"i1\":10,\"i2\":9,\"i3\":10,\"i4\":10,\"i5\":10,\"i6\":10,\"i7\":10,\"i8\":10,\"i9\":10,\"i10\":10,\"i11\":10};var tabs = {65535:[\"t0\",\"All Methods\"],1:[\"t1\",\"Static Methods\"],2:[\"t2\",\"Instance Methods\"],8:[\"t4\",\"Concrete Methods\"]};var altColor = \"altColor\";var rowColor = \"rowColor\";var tableTab = \"tableTab\";var activeTableTab = \"activeTableTab\"; JavaScript is disabled on your browser. Skip navigation links Overview Package Class Tree Index Help Prev Class Next Class Frames No Frames All Classes <!-- allClassesLink = document.getElementById(\"allclasses_navbar_top\"); if(window==top) { allClassesLink.style.display = \"block\"; } else { allClassesLink.style.display = \"none\"; } //--> Summary: Nested | Field | Constr | Method Detail: Field | Constr | Method cs15.fnl.sketchySupport Class FileIO java.lang.Object cs15.fnl.sketchySupport.FileIO public class FileIO extends java.lang.Object A SUPPORT class that provides easy file input and output operations. The read methods provide word by word and number by number access to any file. The write methods, however, should only be used to create new files and not to modify existing files. The FileIO class uses sequential file access. This means that it views the file as a sequence of entries or tokens. Each string, int, or double that is written using the write methods of this class makes up its own entry. Each time one of the write methods is called, a new entry is added to the end of the sequence of entries in the file which is currently open for writing. Each time one of the read methods is called, it returns the next entry in the sequence of entries in the file which is currently open for reading. Constructor Summary Constructors Constructor and Description FileIO () Method Summary All Methods Static Methods Instance Methods Concrete Methods Modifier and Type Method and Description void closeRead () A SUPPORT method that closes the current file which is open for READING. void closeWrite () A SUPPORT method that closes the current file which is open for READING. static java.lang.String getFileName (boolean save, javafx.stage.Window stage) A SUPPORT method that opens a FileChooser (pop-up window that allows you to navigate your computer to choose a file to load or save to. boolean hasMoreData () A SUPPORT method that returns whether there is more data to be read from the file that is currently open for reading. void openRead (java.lang.String filename) A SUPPORT method that opens the file specified by 'filename' for reading. void openWrite (java.lang.String filename) A SUPPORT method that opens the file specified by 'filename' for writing. double readDouble () A SUPPORT method that reads the next entry in the file and returns it as a double. int readInt () A SUPPORT method that reads the next entry in the file and returns it as an integer. java.lang.String readString () A SUPPORT method that reads the next entry in the file and returns it as a string. void writeDouble (double num) A SUPPORT method that adds an entry to the end of the current file open for writing. void writeInt (int num) A SUPPORT method that adds an entry to the end of the current file open for writing. void writeString (java.lang.String message) A SUPPORT method that adds an entry to the end of the current file open for writing. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail FileIO public FileIO() Method Detail closeRead public void closeRead() A SUPPORT method that closes the current file which is open for READING. This method should be called as soon as a program is done reading from the current file. Calling this method when there is no file currently open for reading will result in an error message and termination of the program. closeWrite public void closeWrite() A SUPPORT method that closes the current file which is open for READING. This method should be called as soon as a program is done reading from the current file. Calling this method when there is no file currently open for reading will result in an error message and termination of the program. getFileName public static java.lang.String getFileName(boolean save, javafx.stage.Window stage) A SUPPORT method that opens a FileChooser (pop-up window that allows you to navigate your computer to choose a file to load or save to. This method will return the absolute path of the file or null. Parameters: save - a boolean value - pass TRUE if you're saving, FALSE if loading stage - your program's Stage Returns: the name of the file to open, null if invalid file hasMoreData public boolean hasMoreData() A SUPPORT method that returns whether there is more data to be read from the file that is currently open for reading. Returns: A boolean that is TRUE if there is more data, FALSE otherwise openRead public void openRead(java.lang.String filename) A SUPPORT method that opens the file specified by 'filename' for reading. This method must be called before any of the read methods can be called. Calling one of the three 'read' methods or closeRead() before calling openRead() will result in a Null Pointer Exception. Once a file has been opened for reading, every subsequent call to one of the three read methods will read from the file specified by 'filename.' This method can be called multiple times, but once a file has been opened for reading, it must be closed for reading before another file can be opened for reading. Parameters: filename - The pathname of the file to be opened for reading. openWrite public void openWrite(java.lang.String filename) A SUPPORT method that opens the file specified by 'filename' for writing. This method must be called before any of the write methods can be called. Calling one of the three 'write' methods or closeWrite() before calling openWrite() will result in a Null Pointer Exception. Once a file has been opened for writing, every subsequent call to one of the three write methods will write to the file specified by 'filename.' This method can be called multiple times, but once a file has been opened for writing, it must be closed for writing before another file can be opened for writing. Calling this method an existing file will delete the contents of the original and replace them with whatever new information is written. For this reason, openWrite() should only be used to create new files or to replace the information in an existing file. Parameters: filename - The pathname of the file to be opened for writing. readDouble public double readDouble() A SUPPORT method that reads the next entry in the file and returns it as a double. You must only use this method if you are certain that the entry being read will be a double. The program will terminate with an error message if this method is called but there are no more entries in the file to be read. There must be a file open for reading when this method is called or an error message will be produced and the program will terminate. Returns: A double value that stores the value that was just read readInt public int readInt() A SUPPORT method that reads the next entry in the file and returns it as an integer. You must only use this method if you are certain that the entry being read will be a integer. The program will terminate with an error message if this method is called but there are no more entries in the file to be read. There must be a file open for reading when this method is called or an error message will be produced and the program will terminate. Returns: An integer value that stores the value that was just read readString public java.lang.String readString() A SUPPORT method that reads the next entry in the file and returns it as a string. You must only use this method if you are certain that the entry being read will be a double. The program will terminate with an error message if this method is called but there are no more entries in the file to be read. There must be a file open for reading when this method is called or an error message will be produced and the program will terminate. Returns: A string that stores the value that was just read writeDouble public void writeDouble(double num) A SUPPORT method that adds an entry to the end of the current file open for writing. This entry is encoded as a double and will have the value of the passed in parameter. There must be a file open for writing when this method is called or An error message will be produced if this method is called and a file is not open for writing and the program will terminate. Parameters: num - The double to write to the file writeInt public void writeInt(int num) A SUPPORT method that adds an entry to the end of the current file open for writing. This entry is encoded as an integer and will have the value of the passed in parameter. There must be a file open for writing when this method is called or An error message will be produced if this method is called and a file is not open for writing and the program will terminate. Parameters: num - The integer to write to the file writeString public void writeString(java.lang.String message) A SUPPORT method that adds an entry to the end of the current file open for writing. This entry is encoded as a string and will have the value of the passed in parameter. There must be a file open for writing when this method is called or An error message will be produced if this method is called and a file is not open for writing and the program will terminate. Parameters: message - The string to write to the file Skip navigation links Overview Package Class Tree Index Help Prev Class Next Class Frames No Frames All Classes <!-- allClassesLink = document.getElementById(\"allclasses_navbar_bottom\"); if(window==top) { allClassesLink.style.display = \"block\"; } else { allClassesLink.style.display = \"none\"; } //--> Summary: Nested | Field | Constr | Method Detail: Field | Constr | Method", "https://cs.brown.edu/courses/cs016/static/files/docs/cs0160.sty": "%%%% This is file `fancyvrb.sty',%% generated with the docstrip utility.%%%% The original source files were:%%%% fancyvrb.dtx (with options: `fancyvrb')%% %% IMPORTANT NOTICE:%% %% For the copyright see the source file.%% %% Any modified versions of this file must be renamed%% with new filenames distinct from fancyvrb.sty.%% %% For distribution of the original source see the terms%% for copying and modification in the file fancyvrb.dtx.%% %% This generated file may be distributed as long as the%% original source files, as listed above, are part of the%% same distribution. (The sources need not necessarily be%% in the same archive or directory.)%%%% Package `fancyvrb'%%%% COPYING:%% The files of this package \"fancyvrb\" are released under the Artistic%% License Version 2. A copy of that license is included in the file%% artistic2.txt. The package consists of the following files:%% README artistic2.txt fancyvrb.cb fancyvrb.dtx fancyvrb.ins%%%% Timothy Van Zandt %% July 17, 1998%%%% COPYRIGHT 1992-1999, by Timothy Van Zandt %%%% This package may be distributed under the terms of the LaTeX Project Public%% License, as described in lppl.txt in the base LaTeX distribution.%% Either version 1.0 or, at your option, any later version.%%%% DESCRIPTION:%% fancyvrb.sty is a LaTeX style option, containing flexible%% verbatim environments and commands and extensive documentation.%%%% This is a companion to the `fancybox' package.%%\\NeedsTeXFormat{LaTeX2e}\\def\\fileversion{2.7a, with DG/SPQR fixes, and firstline=lastline fix}\\def\\filedate{2008/02/07}\\ProvidesPackage{fancyvrb}[\\filedate]\\message{Style option: `fancyvrb' v\\fileversion \\space <\\filedate> (tvz)}\\csname fancyvrb@loaded\\endcsname\\let\\fancyvrb@loaded\\endinput\\def\\FV@Error#1#2{% \\edef\\@tempc{#2}\\expandafter\\errhelp\\expandafter{\\@tempc}% \\errmessage{FancyVerb Error:^^J\\space\\space #1^^J}}\\def\\FV@eha{Your command was ignored. Type to continue.}%% DG/SR modification begin - Jan. 21, 1998%% Suggested by Bernard Gaulle to solve a compatibility problem with `french'%% (it introduce the restriction to put \\VerbatimFootnotes AFTER the preambule)%%\\def\\VerbatimFootnotes{\\let\\@footnotetext\\V@footnotetext}\\let\\V@footnote\\footnote\\def\\VerbatimFootnotes{%\\let\\@footnotetext\\V@footnotetext%\\let\\footnote\\V@footnote}%% DG/SR modification end\\long\\def\\V@footnotetext{% \\afterassignment\\V@@footnotetext \\let\\@tempa}\\def\\V@@footnotetext{% \\insert\\footins\\bgroup \\csname reset@font\\endcsname \\footnotesize \\interlinepenalty\\interfootnotelinepenalty \\splittopskip\\footnotesep \\splitmaxdepth\\dp\\strutbox \\floatingpenalty \\@MM \\hsize\\columnwidth \\@parboxrestore \\edef\\@currentlabel{\\csname p@footnote\\endcsname\\@thefnmark}% \\@makefntext{}% \\rule{\\z@}{\\footnotesep}% \\bgroup \\aftergroup\\V@@@footnotetext \\ignorespaces}\\def\\V@@@footnotetext{\\strut\\egroup}\\RequirePackage{keyval}\\def\\define@booleankey#1#2#3#4{% \\@namedef{KV@#1@#2@default}{#3}% \\@namedef{KV@#1@#2@false}{#4}% \\@namedef{KV@#1@#2}##1{\\KV@booleankey{##1}{#1}{#2}}}\\def\\KV@booleankey#1#2#3{% \\edef\\@tempa{#1}\\expandafter\\KV@@booleankey\\@tempa\\relax\\@nil{#2}{#3}}\\def\\KV@@booleankey#1#2\\@nil#3#4{% \\@nameuse{KV@#3@#4@\\if t#1default\\else\\if T#1default\\else false\\fi\\fi}}\\def\\FV@None{none}\\def\\FV@Auto{auto}\\def\\fvset#1{\\setkeys{FV}{#1}}\\def\\FV@Command#1#2{% \\@ifstar {\\def\\FV@KeyValues{#1,showspaces}\\FV@@Command{#2}}% {\\def\\FV@KeyValues{#1}\\FV@@Command{#2}}}\\def\\FV@@Command#1{% \\@ifnextchar[% {\\FV@GetKeyValues{\\@nameuse{FVC@#1}}}% {\\@nameuse{FVC@#1}}}\\def\\FV@GetKeyValues#1[#2]{% \\expandafter\\def\\expandafter\\FV@KeyValues\\expandafter{\\FV@KeyValues,#2}#1}\\def\\@CustomVerbatimCommand#1#2#3#4{% \\begingroup\\fvset{#4}\\endgroup % If there are errors, it easier to locate.%% DG/SR modification begin - Jan. 13, 1998%% \\def\\@tempa##1##2\\@nil{\\def\\@tempa{##2}}%%% \\expandafter\\@tempa\\string#3\\@empty\\@nil%% \\@ifundefined{FVC@\\@tempa}% \\@ifundefined{FVC@#3}%%% DG/SR modification end {\\FV@Error{Command `\\string#3' is not a FancyVerb command.}\\@eha}% {#1{#2}{\\FV@Command{#4}{#3}}}}\\def\\CustomVerbatimCommand{\\@CustomVerbatimCommand\\newcommand}\\def\\RecustomVerbatimCommand{\\@CustomVerbatimCommand\\renewcommand}\\def\\FV@Environment#1#2{% \\def\\FV@KeyValues{#1}% \\catcode`\\^^M=\\active \\@ifnextchar[% {\\catcode`\\^^M=5 \\FV@GetKeyValues{\\@nameuse{FVB@#2}}}% {\\catcode`\\^^M=5 \\@nameuse{FVB@#2}}}\\def\\CustomVerbatimEnvironment{\\@CustomVerbatimEnvironment\\newenvironment}\\def\\RecustomVerbatimEnvironment{\\@CustomVerbatimEnvironment\\renewenvironment}\\def\\@CustomVerbatimEnvironment#1#2#3#4{% \\begingroup\\fvset{#4}\\endgroup % If there are errors, it easier to locate. \\@ifundefined{FVB@#3}% {\\FV@Error{`#3' is not a FancyVerb environment.}\\@eha}% {#1{#2}{\\FV@Environment{#4}{#3}}{\\@nameuse{FVE@#3}}% #1{#2*}{\\FV@Environment{#4,showspaces}{#3}}{\\@nameuse{FVE@#3}}}}\\def\\DefineVerbatimEnvironment#1#2#3{% \\@namedef{#1}{\\FV@Environment{#3}{#2}}% \\@namedef{end#1}{\\@nameuse{FVE@#2}}% \\@namedef{#1*}{\\FV@Environment{#3,showspaces}{#2}}% \\@namedef{end#1*}{\\@nameuse{FVE@#2}}}\\def\\FV@UseKeyValues{% \\ifx\\FV@KeyValues\\@empty\\else \\def\\KV@prefix{KV@FV@}% \\expandafter\\KV@do\\FV@KeyValues,\\relax,% \\def\\FV@KeyValues{}% \\fi}\\def\\FV@CatCodes{% \\let\\do\\@makeother\\dospecials % The usual stuff. \\FV@ActiveWhiteSpace % See below. \\FV@FontScanPrep % See below. \\FV@CatCodesHook % A style hook. \\FancyVerbCodes} % A user-defined hook.\\def\\FV@ActiveWhiteSpace{% \\catcode`\\^^M=\\active % End of line \\catcode`\\ =\\active % Space \\catcode`\\^^I=\\active} % Tab\\def\\FV@CatCodesHook{}\\def\\FV@AddToHook#1#2{% \\expandafter\\def\\expandafter#1\\expandafter{#1#2\\relax}}\\define@key{FV}{codes}[]{\\def\\FancyVerbCodes{#1\\relax}}\\define@key{FV}{codes*}{% \\expandafter\\def\\expandafter\\FancyVerbCodes\\expandafter{% \\FancyVerbCodes#1\\relax}}\\fvset{codes}\\define@key{FV}{commandchars}[\\\\\\{\\}]% {\\def\\@tempa{#1}% \\ifx\\@tempa\\FV@None \\let\\FV@CommandChars\\relax \\else \\FV@DefineCommandChars#1\\relax\\relax\\relax \\fi}\\def\\FV@DefineCommandChars#1#2#3{% \\def\\FV@CommandChars{% \\catcode`#1=0\\relax\\catcode`#2=1\\relax\\catcode`#3=2\\relax}}\\FV@AddToHook\\FV@CatCodesHook\\FV@CommandChars\\define@key{FV}{commentchar}[\\%]{% \\def\\@tempa{#1}% \\ifx\\@tempa\\FV@None \\let\\FV@CommentChar\\relax \\else \\def\\FV@CommentChar{\\catcode`#1=14}% \\fi}\\FV@AddToHook\\FV@CatCodesHook\\FV@CommentChar\\fvset{commandchars=none,commentchar=none}\\define@key{FV}{firstline}{% \\afterassignment\\FV@ParseStart\\@tempcnta=0#1\\relax\\@nil{#1}}\\def\\FV@ParseStart#1\\relax\\@nil#2{% \\ifx\\@nil#1\\@nil \\edef\\FancyVerbStartNum{\\the\\@tempcnta}% \\let\\FancyVerbStartString\\relax \\else \\edef\\FancyVerbStartString{#2}% \\fi}\\def\\KV@FV@firstline@default{% \\let\\FancyVerbStartNum\\z@ \\let\\FancyVerbStartString\\relax}\\define@key{FV}{lastline}{% \\afterassignment\\FV@ParseStop\\@tempcnta=0#1\\relax\\@nil{#1}}\\def\\FV@ParseStop#1\\relax\\@nil#2{% \\ifx\\@nil#1\\@nil \\edef\\FancyVerbStopNum{\\the\\@tempcnta}% \\let\\FancyVerbStopString\\relax \\else \\edef\\FancyVerbStopString{#2}% \\fi}\\def\\KV@FV@lastline@default{% \\let\\FancyVerbStopNum\\z@ \\let\\FancyVerbStopString\\relax}\\fvset{firstline,lastline}\\newcount\\FV@CodeLineNo\\def\\FV@PreProcessLine{% \\global\\advance\\FV@CodeLineNo\\@ne \\FV@FindStartStop}\\def\\FV@@PreProcessLine{% \\FV@StepLineNo \\FV@Gobble \\expandafter\\FV@ProcessLine\\expandafter{\\FV@Line}}\\def\\FV@FindStartStop{\\FV@DefineFindStart\\FV@FindStartStop}%% \\def\\FV@DefinePreProcessLine{%%% \\setcounter{FancyVerbLine}{0}%%% \\FV@DefineFindStart}\\def\\FV@DefineFindStart{% \\ifx\\FancyVerbStartString\\relax \\ifnum\\FancyVerbStartNum<\\tw@ \\FV@DefineFindStop \\else \\let\\FV@FindStartStop\\FV@FindStartNum \\fi \\else \\let\\FV@FindStartStop\\FV@FindStartString \\fi}\\def\\FV@FindStartNum{% \\ifnum\\FancyVerbStartNum>\\FV@CodeLineNo\\else \\FV@DefineFindStop \\expandafter\\FV@@PreProcessLine \\fi}%% SR modification begin - 1996\\def\\FV@FindStartString{% \\expandafter\\FV@@FindStartString{\\meaning\\FV@Line}%{\\meaning\\FancyVerbStartString}%}\\def\\FV@@FindStartString#1#2{%\\edef\\@fooA{#1}\\edef\\@fooB{#2}% \\ifx\\@fooA\\@fooB \\FV@DefineFindStop \\fi}%% SR modification end\\def\\FV@DefineFindStop{% \\ifx\\FancyVerbStopString\\relax \\ifnum\\FancyVerbStopNum<\\@ne \\let\\FV@FindStartStop\\FV@@PreProcessLine \\else \\let\\FV@FindStartStop\\FV@FindStopNum \\fi \\else \\let\\FV@FindStartStop\\FV@FindStopString \\fi}\\def\\FV@FindStopNum{% \\ifnum\\FancyVerbStopNum>\\FV@CodeLineNo \\else \\let\\FV@FindStartStop\\relax \\ifeof\\FV@InFile\\else \\immediate\\closein\\FV@InFile \\fi \\fi \\ifnum\\FancyVerbStopNum<\\FV@CodeLineNo \\else \\FV@@PreProcessLine \\fi}%% SR modification begin - 1996\\def\\FV@FindStopString{% \\expandafter\\FV@@FindStopString{\\meaning\\FV@Line}%{\\meaning\\FancyVerbStopString}%}\\def\\FV@@FindStopString#1#2{%\\edef\\@fooA{#1}\\edef\\@fooB{#2}% \\ifx\\@fooA\\@fooB \\let\\FV@FindStartStop\\relax \\ifeof\\FV@InFile\\else \\immediate\\closein\\FV@InFile \\fi \\else \\expandafter\\FV@@PreProcessLine \\fi}%% SR modification end\\def\\FV@@Gobble{% \\expandafter\\expandafter\\expandafter\\FV@@@Gobble \\expandafter\\FV@@@@Gobble\\FV@Line \\@nil\\@nil\\@nil\\@nil\\@nil\\@nil\\@nil\\@nil\\@nil\\@nil\\@@nil}\\def\\FV@@@Gobble#1\\@nil#2\\@@nil{\\def\\FV@Line{#1}}\\define@key{FV}{gobble}{% \\@tempcnta=#1\\relax \\ifnum\\@tempcnta<\\@ne \\let\\FV@Gobble\\relax \\else \\ifnum\\@tempcnta>9 \\FV@Error{gobble parameter must be less than 10}\\FV@eha \\else \\renewcommand{\\FV@@@@Gobble}[\\@tempcnta]{}% \\let\\FV@Gobble\\FV@@Gobble \\fi \\fi}\\def\\FV@@@@Gobble{}\\def\\KV@FV@gobble@default{\\let\\FV@Gobble\\relax}\\fvset{gobble}\\def\\FV@Scan{% \\FV@CatCodes \\VerbatimEnvironment \\FV@DefineCheckEnd \\FV@BeginScanning}\\def\\VerbatimEnvironment{% \\ifx\\FV@EnvironName\\relax\\xdef\\FV@EnvironName{\\@currenvir}\\fi}\\let\\FV@EnvironName\\relax\\begingroup\\catcode`\\!=0\\catcode`\\[=1\\catcode`\\]=2!gdef!FV@CheckEnd@i#1[!FV@@CheckEnd#1\\end{}!@nil]!gdef!FV@@CheckEnd@i#1\\end#2#3!@nil[!def!@tempa[#2]!def!@tempb[#3]]!gdef!FV@@@CheckEnd@i[\\end{}]\\catcode`!\\=12!gdef!FV@CheckEnd@ii#1[!FV@@CheckEnd#1\\end{}!@nil]!gdef!FV@@CheckEnd@ii#1\\end#2#3!@nil[!def!@tempa[#2]!def!@tempb[#3]]!gdef!FV@@@CheckEnd@ii[\\end{}]!catcode`!{=12!catcode`!}=12!gdef!FV@CheckEnd@iii#1[!FV@@CheckEnd#1\\end{}!@nil]!gdef!FV@@CheckEnd@iii#1\\end{#2}#3!@nil[!def!@tempa[#2]!def!@tempb[#3]]!gdef!FV@@@CheckEnd@iii[\\end{}]!catcode`!\\=0!gdef!FV@CheckEnd@iv#1[!FV@@CheckEnd#1\\end{}!@nil]!gdef!FV@@CheckEnd@iv#1\\end{#2}#3!@nil[!def!@tempa[#2]!def!@tempb[#3]]!gdef!FV@@@CheckEnd@iv[\\end{}]\\endgroup\\def\\FV@BadCodes#1{% \\FV@Error {\\string\\catcode\\space of \\expandafter\\@gobble\\string#1 is wrong: \\the\\catcode`#1}% {Only the following catcode values are allowed: ^^J\\@spaces \\expandafter\\@gobble\\string\\\\ \\space\\space --> 0 or 12. ^^J\\@spaces \\string{ \\string} --> 1 and 2, resp., or both 12. ^^JTo get this error, either you are a hacker or you got bad advice.}% \\def\\FV@CheckEnd##1{\\iftrue}}\\def\\FV@DefineCheckEnd{% \\ifnum\\catcode`\\\\=\\z@ \\ifnum\\catcode`\\{=\\@ne \\let\\FV@CheckEnd\\FV@CheckEnd@i \\let\\FV@@CheckEnd\\FV@@CheckEnd@i \\let\\FV@@@CheckEnd\\FV@@@CheckEnd@i \\else \\ifnum\\catcode`\\{=12 \\let\\FV@CheckEnd\\FV@CheckEnd@iv \\let\\FV@@CheckEnd\\FV@@CheckEnd@iv \\let\\FV@@@CheckEnd\\FV@@@CheckEnd@iv \\else \\FV@BadCodes\\{% \\fi \\fi \\else \\ifnum\\catcode`\\\\=12 \\ifnum\\catcode`\\{=\\@ne \\let\\FV@CheckEnd\\FV@CheckEnd@ii \\let\\FV@@CheckEnd\\FV@@CheckEnd@ii \\let\\FV@@@CheckEnd\\FV@@@CheckEnd@ii \\else \\ifnum\\catcode`\\{=12 \\let\\FV@CheckEnd\\FV@CheckEnd@iii \\let\\FV@@CheckEnd\\FV@@CheckEnd@iii \\let\\FV@@@CheckEnd\\FV@@@CheckEnd@iii \\else \\FV@BadCodes\\{% \\fi \\fi \\else \\FV@BadCodes\\\\% \\fi \\fi}\\begingroup\\catcode`\\^^M=\\active \\gdef\\FV@BeginScanning#1^^M{% \\def\\@tempa{#1}\\ifx\\@tempa\\@empty\\else\\FV@BadBeginError\\fi% \\FV@GetLine}%\\endgroup\\def\\FV@BadBeginError#1{% \\expandafter\\@temptokena\\expandafter{\\@tempa}% \\FV@Error {Extraneous input `\\the\\@temptokena' between \\string\\begin{\\FV@EnvironName}[ ] and line end}% {This input will be discarded. Hit to continue.}}%% DG/SR modification begin - May. 18, 1998 (added code to turn off ligatures)%% \\def\\FV@GetLine{\\expandafter\\FV@CheckScan\\FancyVerbGetLine}\\def\\FV@GetLine{\\@noligs\\expandafter\\FV@CheckScan\\FancyVerbGetLine}%% DG/SR modification end\\begingroup\\catcode`\\^^M=\\active\\gdef\\FancyVerbGetLine#1^^M{% \\@nil \\FV@CheckEnd{#1}% \\ifx\\@tempa\\FV@EnvironName% % True if end is found \\ifx\\@tempb\\FV@@@CheckEnd\\else\\FV@BadEndError\\fi% \\let\\next\\FV@EndScanning% \\else% \\def\\FV@Line{#1}% \\def\\next{\\FV@PreProcessLine\\FV@GetLine}% \\fi% \\next}%\\endgroup\\def\\FV@BadEndError{% \\expandafter\\@temptokena\\expandafter{\\@tempb}% \\FV@Error {Extraneous input `\\the\\@temptokena' between \\string\\end{\\FV@EnvironName} and line end}% {This input will be discarded. Type to continue.}}\\def\\FV@EndScanning{% \\edef\\next{\\noexpand\\end{\\FV@EnvironName}}% \\global\\let\\FV@EnvironName\\relax \\next}\\@ifundefined{@currenvline}{\\let\\@currenvline\\@empty}{}\\def\\FV@CheckScan#1{\\@ifnextchar\\@nil{\\@gobble}{\\FV@EOF}}\\def\\FV@CheckScan#1{\\ifx\\@nil#1\\@empty\\else\\expandafter\\FV@EOF\\fi}\\def\\FV@EOF{% \\FV@Error{Couldn't find `\\string\\end{\\FV@EnvironName}' to end a verbatim environment\\@currenvline.}% {Probably you mistyped the environment name or included an extraneous ^^Jspace, or are using an improperly defined verbatim environment. ^^JHit return and I will try to terminate this job.}% \\FV@EndScanning \\end{document}} % \\subsection{Input}\\newread\\FV@InFile\\def\\FV@Input#1{% \\immediate\\openin\\FV@InFile #1\\relax \\ifeof\\FV@InFile \\FV@Error{No verbatim file #1}\\FV@eha \\immediate\\closein\\FV@InFile \\else \\FV@CatCodes \\expandafter\\FV@@Input \\fi}\\def\\FV@@Input{% \\def\\FV@Line{}% \\FV@ReadLine \\ifeof\\FV@InFile \\ifx\\FV@Line\\@empty\\else \\FV@PreProcessLine \\fi \\immediate\\closein\\FV@InFile \\else \\FV@PreProcessLine \\expandafter\\FV@@Input \\fi}\\begingroup\\catcode`\\^^M=\\active\\gdef\\FV@ReadLine{% \\ifeof\\FV@InFile\\else \\immediate\\read\\FV@InFile to\\@tempa% \\expandafter\\FV@@ReadLine\\@tempa^^M\\relax^^M\\@nil% \\fi}\\gdef\\FV@@ReadLine#1^^M#2^^M#3\\@nil{% \\expandafter\\def\\expandafter\\FV@Line\\expandafter{% \\FV@Line#1}% \\ifx\\relax#2\\@empty\\expandafter\\FV@ReadLine\\fi}%\\endgroup\\def\\FV@FormattingPrep{% \\global\\FV@CodeLineNo\\z@ \\frenchspacing % Cancels special punctuation spacing. \\FV@SetupFont % See below. \\FV@DefineWhiteSpace % See below. \\FancyVerbDefineActive \\FancyVerbFormatCom} % A user-defined hook (formatcom parameter).\\expandafter\\ifx\\csname selectfont\\endcsname\\relax\\def\\FV@SetupFont{% \\FV@BaseLineStretch \\ifx\\@currsize\\small\\normalsize\\else\\small\\fi\\@currsize \\FV@FontSize \\FV@FontFamily}\\else\\def\\FV@SetupFont{% \\FV@BaseLineStretch \\FV@FontSize \\FV@FontFamily \\FV@FontSeries \\FV@FontShape \\selectfont%% DG/SR modification begin - May. 18, 1998 (added code to turn off ligatures) \\@noligs}%% DG/SR modification end\\fi\\define@key{FV}{fontsize}{% \\def\\@tempa{#1}% \\ifx\\@tempa\\FV@Auto \\let\\FV@FontSize\\relax \\else \\def\\FV@FontSize{#1}% \\fi}\\def\\KV@FV@fontsize@default{\\let\\FV@FontSize\\relax}\\define@key{FV}{baselinestretch}[auto]{% \\def\\@tempa{#1}% \\ifx\\@tempa\\FV@Auto \\let\\FV@BaseLineStretch\\relax \\else \\def\\FV@BaseLineStretch{\\def\\baselinestretch{#1}}% \\fi}\\def\\KV@FV@baselinestretch@default{\\let\\FV@BaseLineStretch\\relax}\\define@key{FV}{fontfamily}{% \\@ifundefined{FV@fontfamily@#1}% {\\def\\FV@FontScanPrep{}\\def\\FV@FontFamily{\\fontfamily{#1}}} {\\csname FV@fontfamily@#1\\endcsname}}\\define@key{FV}{fontseries}{% \\def\\@tempa{#1}% \\ifx\\@tempa\\FV@Auto \\let\\FV@FontSeries\\relax \\else \\def\\FV@FontSeries{\\fontseries{#1}}% \\fi}\\define@key{FV}{fontshape}{% \\def\\@tempa{#1}% \\ifx\\@tempa\\FV@Auto \\let\\FV@FontShape\\relax \\else \\def\\FV@FontShape{\\fontshape{#1}}% \\fi}\\def\\FV@MakeActive#1{% \\catcode`#1=\\active \\def\\next##1{\\expandafter\\def\\expandafter\\FV@MakeUnActive\\expandafter{% \\FV@MakeUnActive\\def##1{\\string##1}}}% \\begingroup\\lccode`~=`#1\\relax\\expandafter\\next\\expandafter~\\endgroup}\\def\\FV@MakeUnActive{}\\begingroup\\catcode`\\`=\\active\\gdef\\FV@fontfamily@tt{% \\def\\FV@FontScanPrep{\\FV@MakeActive\\`}%%% SR modification begin - 1995%% \\def\\FV@FontFamily{\\tt`{{\\string`}}}} \\def\\FV@FontFamily{\\ttfamily\\edef`{{\\string`}}}}%% SR modification end\\gdef\\FV@fontfamily@cmtt{% \\def\\FV@FontScanPrep{\\FV@MakeActive\\`}% \\def\\FV@FontFamily{\\edef`{{\\string`}}\\fontfamily{cmtt}}}\\endgroup\\@namedef{FV@fontfamily@cmtt-spanish}{% \\def\\FV@FontScanPrep{}% \\def\\FV@FontFamily{\\fontfamily{cmtt}}}\\@namedef{FV@fontfamily@courier}{% \\def\\FV@FontScanPrep{}%%% SR modification begin - 1995%% \\def\\FV@FontFamily{\\fontfamily{rpcr}}} \\def\\FV@FontFamily{\\fontfamily{pcr}}}%% SR modification end\\@namedef{FV@fontfamily@helvetica}{% \\def\\FV@FontScanPrep{}%%% SR modification begin - 1995%% \\def\\FV@FontFamily{\\fontfamily{rphv}}} \\def\\FV@FontFamily{\\fontfamily{phv}}}%% SR modification end\\fvset{fontfamily=tt,fontsize=auto,fontshape=auto,fontseries=auto, baselinestretch=auto}\\begingroup\\catcode`\\ =\\active\\catcode`\\^^I=\\active\\gdef\\FV@DefineWhiteSpace{\\def {\\FV@Space}\\def^^I{\\FV@Tab}}%\\endgroup\\define@key{FV}{defineactive}[]{\\def\\FancyVerbDefineActive{#1\\relax}}\\define@key{FV}{defineactive*}{% \\expandafter\\def\\expandafter\\FancyVerbDefineActive\\expandafter{% \\FancyVerbDefineActive#1\\relax}}\\fvset{defineactive}\\define@booleankey{FV}{showspaces}% {\\def\\FV@Space{{\\FancyVerbSpace}}}% {\\def\\FV@Space{\\ }}{\\catcode`\\ =12 \\gdef\\FancyVerbSpace{\\tt }}\\fvset{showspaces=false}\\def\\FV@Tab{\\hbox to\\FancyVerbTabSize\\fontdimen2\\font{\\hss\\FV@TabChar}}\\define@key{FV}{tabsize}{% \\@tempcnta=#1\\relax \\ifnum\\@tempcnta>100 \\FV@Error{Tab size too large: `\\the\\@tempcnta'. (Max size = 100)}\\FV@eha \\else \\edef\\FancyVerbTabSize{\\the\\@tempcnta}% \\fi}\\define@booleankey{FV}{showtabs}% {\\def\\FV@TabChar{\\FancyVerbTab}}% {\\let\\FV@TabChar\\relax}\\fvset{tabsize=8,showtabs=false}\\def\\FancyVerbTab{% \\valign{% \\vfil##\\vfil\\cr \\hbox{$\\scriptscriptstyle-$}\\cr \\hbox to 0pt{\\hss$\\scriptscriptstyle\\rangle\\mskip -.8mu$}\\cr \\hbox{$\\scriptstyle\\mskip -3mu\\mid\\mskip -1.4mu$}\\cr}}\\newbox\\FV@TabBox\\def\\FV@@ObeyTabsInit{% \\@tempdimb=\\FancyVerbTabSize\\fontdimen\\tw@\\font \\edef\\FV@ObeyTabSize{\\number\\@tempdimb}% \\advance\\@tempdimb\\fontdimen\\tw@\\font \\advance\\@tempdimb-\\FancyVerbTabSize sp % Allow for rounding errors. \\edef\\FV@@ObeyTabSize{\\number\\@tempdimb}% \\let\\FV@ObeyTabs\\FV@@ObeyTabs \\let\\FV@Tab\\FV@TrueTab}\\def\\FV@@ObeyTabs#1{\\setbox\\FV@TabBox=\\hbox{#1}\\box\\FV@TabBox}\\let\\FV@ObeyTabs\\relax\\def\\FV@TrueTab{% \\egroup \\@tempdima=\\FV@ObeyTabSize sp\\relax \\@tempcnta=\\wd\\FV@TabBox \\advance\\@tempcnta\\FV@@ObeyTabSize\\relax \\divide\\@tempcnta\\@tempdima \\multiply\\@tempdima\\@tempcnta \\advance\\@tempdima-\\wd\\FV@TabBox \\setbox\\FV@TabBox=\\hbox\\bgroup \\unhbox\\FV@TabBox\\kern\\@tempdima\\hbox to\\z@{\\hss\\FV@TabChar}}\\define@booleankey{FV}{obeytabs}% {\\let\\FV@ObeyTabsInit\\FV@@ObeyTabsInit}% {\\let\\FV@ObeyTabsInit\\relax}\\fvset{obeytabs=false}\\define@key{FV}{formatcom}[]{\\def\\FancyVerbFormatCom{#1\\relax}}\\define@key{FV}{formatcom*}{% \\expandafter\\def\\expandafter\\FancyVerbFormatCom\\expandafter{% \\FancyVerbFormatCom#1\\relax}}\\fvset{formatcom}\\def\\FancyVerbFormatLine#1{\\FV@ObeyTabs{#1}}\\define@key{FV}{xleftmargin}{\\def\\FV@XLeftMargin{#1}}\\let\\FV@XLeftMargin\\z@\\define@key{FV}{xrightmargin}{\\def\\FV@XRightMargin{#1}}\\let\\FV@XRightMargin\\z@\\define@booleankey{FV}{resetmargins}% {\\let\\if@FV@ResetMargins\\iftrue} {\\let\\if@FV@ResetMargins\\iffalse}\\fvset{resetmargins=false}\\define@key{FV}{listparameters}{\\def\\FV@ListParameterHook{#1}}\\def\\FV@ListParameterHook{}\\define@key{FV}{hfuzz}{% \\@tempdima=#1\\relax \\edef\\FancyVerbHFuzz{\\number\\@tempdima sp}}\\fvset{hfuzz=2pt}\\define@booleankey{FV}{samepage}% {\\def\\FV@InterLinePenalty{\\interlinepenalty\\@M}}% {\\let\\FV@InterLinePenalty\\relax}\\fvset{samepage=false}\\def\\FV@List#1{% \\begingroup \\FV@UseKeyValues \\FV@LeaveVMode \\if@inlabel\\else\\setbox\\@labels=\\box\\voidb@x\\fi \\FV@ListNesting{#1}% \\FV@ListParameterHook \\FV@ListVSpace \\FV@SetLineWidth \\FV@InterLinePenalty \\let\\FV@ProcessLine\\FV@ListProcessLine@i \\FV@CatCodes \\FV@FormattingPrep \\FV@ObeyTabsInit \\FV@BeginListFrame}\\def\\FV@LeaveVMode{% \\if@noskipsec \\leavevmode \\else \\if@FV@ResetMargins\\if@inlabel\\leavevmode\\fi\\fi \\fi \\ifvmode\\@noparlisttrue\\else\\@noparlistfalse\\unskip\\par\\fi}\\def\\FV@ListNesting#1{% \\if@FV@ResetMargins \\@listdepth=\\z@ \\else \\ifnum\\@listdepth>5\\relax \\@toodeep \\else \\advance\\@listdepth\\@ne \\fi \\fi \\rightmargin\\z@ \\csname @list\\romannumeral\\the\\@listdepth\\endcsname \\ifnum#1=\\z@ \\rightmargin\\z@ \\leftmargin\\z@ \\fi}\\def\\FV@ListVSpace{% \\@topsepadd\\topsep \\if@noparlist\\advance\\@topsepadd\\partopsep\\fi \\if@inlabel \\vskip\\parskip \\else \\if@nobreak \\vskip\\parskip \\clubpenalty\\@M \\else \\addpenalty\\@beginparpenalty \\@topsep\\@topsepadd \\advance\\@topsep\\parskip \\addvspace\\@topsep \\fi \\fi \\global\\@nobreakfalse \\global\\@inlabelfalse \\global\\@minipagefalse \\global\\@newlistfalse}\\def\\FV@SetLineWidth{% \\if@FV@ResetMargins\\else \\advance\\leftmargin\\@totalleftmargin \\fi \\advance\\leftmargin\\FV@XLeftMargin\\relax \\advance\\rightmargin\\FV@XRightMargin\\relax \\linewidth\\hsize \\advance\\linewidth-\\leftmargin \\advance\\linewidth-\\rightmargin \\hfuzz\\FancyVerbHFuzz\\relax}\\def\\FV@ListProcessLine#1{% \\hbox to \\hsize{% \\kern\\leftmargin \\hbox to \\linewidth{% \\FV@LeftListNumber \\FV@LeftListFrame \\FancyVerbFormatLine{#1}\\hss%% DG/SR modification begin - Jan. 28, 1998 (for numbers=right add-on)%% \\FV@RightListFrame}% \\FV@RightListFrame \\FV@RightListNumber}%%% DG/SR modification end \\hss}}\\def\\FV@ListProcessLine@i#1{% \\hbox{% \\ifvoid\\@labels\\else \\hbox to \\z@{\\kern\\@totalleftmargin\\box\\@labels\\hss}% \\fi \\FV@ListProcessLine{#1}}% \\let\\FV@ProcessLine\\FV@ListProcessLine@ii}\\def\\FV@ListProcessLine@ii#1{% \\setbox\\@tempboxa=\\FV@ListProcessLine{#1}% \\let\\FV@ProcessLine\\FV@ListProcessLine@iii}\\def\\FV@ListProcessLine@iii#1{% {\\advance\\interlinepenalty\\clubpenalty\\penalty\\interlinepenalty}% \\box\\@tempboxa \\setbox\\@tempboxa=\\FV@ListProcessLine{#1}% \\let\\FV@ProcessLine\\FV@ListProcessLine@iv}\\def\\FV@ListProcessLine@iv#1{% \\penalty\\interlinepenalty \\box\\@tempboxa \\setbox\\@tempboxa=\\FV@ListProcessLine{#1}}%\\def\\FV@EndList{% \\FV@ListProcessLastLine \\FV@EndListFrame \\@endparenv \\endgroup \\@endpetrue}\\def\\FV@ListProcessLastLine{% \\ifx\\FV@ProcessLine\\FV@ListProcessLine@iv {\\advance\\interlinepenalty\\widowpenalty\\penalty\\interlinepenalty}% \\box\\@tempboxa \\else \\ifx\\FV@ProcessLine\\FV@ListProcessLine@iii {\\advance\\interlinepenalty\\widowpenalty \\advance\\interlinepenalty\\clubpenalty \\penalty\\interlinepenalty}% \\box\\@tempboxa \\else \\ifx\\FV@ProcessLine\\FV@ListProcessLine@i \\FV@Error{Empty verbatim environment}{}% \\FV@ProcessLine{}% \\fi \\fi \\fi}\\def\\FV@VerbatimBegin{\\FV@List\\z@}\\def\\FV@VerbatimEnd{\\FV@EndList}\\def\\FVB@Verbatim{\\FV@VerbatimBegin\\FV@Scan}\\def\\FVE@Verbatim{\\FV@VerbatimEnd}\\DefineVerbatimEnvironment{Verbatim}{Verbatim}{}\\def\\FV@UseVerbatim#1{% \\FV@VerbatimBegin#1\\FV@VerbatimEnd \\@doendpe\\global\\@ignorefalse\\ignorespaces}\\def\\VerbatimInput{\\FV@Command{}{VerbatimInput}}\\def\\FVC@VerbatimInput#1{\\FV@UseVerbatim{\\FV@Input{#1}}}\\def\\FV@LVerbatimBegin{\\FV@List\\@ne}\\def\\FV@LVerbatimEnd{\\FV@EndList}\\def\\FVB@LVerbatim{\\FV@LVerbatimBegin\\FV@Scan}\\def\\FVE@LVerbatim{\\FV@LVerbatimEnd}\\DefineVerbatimEnvironment{LVerbatim}{LVerbatim}{}\\def\\FV@LUseVerbatim#1{% \\FV@LVerbatimBegin#1\\FV@LVerbatimEnd \\@doendpe\\global\\@ignorefalse\\ignorespaces}\\def\\LVerbatimInput{\\FV@Command{}{LVerbatimInput}}\\def\\FVC@LVerbatimInput#1{\\FV@LUseVerbatim{\\FV@Input{#1}}}\\def\\FV@Frame@none{% \\let\\FV@BeginListFrame\\relax \\let\\FV@LeftListFrame\\relax \\let\\FV@RightListFrame\\relax \\let\\FV@EndListFrame\\relax}\\def\\FV@Frame@single{% \\let\\FV@BeginListFrame\\FV@BeginListFrame@Single \\let\\FV@LeftListFrame\\FV@LeftListFrame@Single \\let\\FV@RightListFrame\\FV@RightListFrame@Single \\let\\FV@EndListFrame\\FV@EndListFrame@Single}\\def\\FV@Frame@lines{% \\let\\FV@BeginListFrame\\FV@BeginListFrame@Lines \\let\\FV@LeftListFrame\\relax \\let\\FV@RightListFrame\\relax \\let\\FV@EndListFrame\\FV@EndListFrame@Lines}\\def\\FV@Frame@topline{% \\let\\FV@BeginListFrame\\FV@BeginListFrame@Lines \\let\\FV@LeftListFrame\\relax \\let\\FV@RightListFrame\\relax \\let\\FV@EndListFrame\\relax}\\def\\FV@Frame@bottomline{% \\let\\FV@BeginListFrame\\relax \\let\\FV@LeftListFrame\\relax \\let\\FV@RightListFrame\\relax \\let\\FV@EndListFrame\\FV@EndListFrame@Lines}%% To define a frame with only a left line\\def\\FV@Frame@leftline{% % To define the \\FV@FrameFillLine macro (from \\FV@BeginListFrame) \\ifx\\FancyVerbFillColor\\relax \\let\\FV@FrameFillLine\\relax \\else \\@tempdima\\FV@FrameRule\\relax \\multiply\\@tempdima-\\tw@ \\edef\\FV@FrameFillLine{% {\\noexpand\\FancyVerbFillColor{\\vrule\\@width\\number\\@tempdima sp}% \\kern-\\number\\@tempdima sp}}% \\fi \\let\\FV@BeginListFrame\\relax \\let\\FV@LeftListFrame\\FV@LeftListFrame@Single \\let\\FV@RightListFrame\\relax \\let\\FV@EndListFrame\\relax}\\def\\FV@BeginListFrame@Single{% \\lineskip\\z@ \\baselineskip\\z@ \\ifx\\FancyVerbFillColor\\relax \\let\\FV@FrameFillLine\\relax \\else \\@tempdima\\FV@FrameRule\\relax \\multiply\\@tempdima-\\tw@ \\edef\\FV@FrameFillLine{% {\\noexpand\\FancyVerbFillColor{\\vrule\\@width\\number\\@tempdima sp}% \\kern-\\number\\@tempdima sp}}% \\fi%% DG/SR modification begin - May. 19, 1998%% \\FV@SingleFrameLine \\FV@SingleFrameLine{\\z@}%%% DG/SR modification end \\penalty\\@M \\FV@SingleFrameSep \\penalty\\@M}%% DG/SR modification begin - May. 19, 1998\\define@key{FV}{label}{% \\def\\@tempa{#1}% \\ifx\\@tempa\\FV@None \\let\\FV@LabelBegin\\relax \\let\\FV@LabelEnd\\relax \\else \\FV@Label@i#1\\@nil% \\fi}\\def\\FV@Label@i{\\@ifnextchar[{\\FV@Label@ii}{\\FV@Label@ii[]}}\\def\\FV@Label@ii[#1]#2\\@nil{% \\def\\@tempa{#1}% \\ifx\\@tempa\\empty \\def\\FV@LabelBegin{#2}% \\else \\def\\FV@LabelBegin{#1}% \\def\\FV@LabelPositionBottomLine{\\@ne}% \\fi \\def\\FV@LabelEnd{#2}}\\fvset{label=none}\\define@key{FV}{labelposition}[none]{% \\@ifundefined{FV@LabelPosition@#1}% {\\FV@Error{Label position `#1' not defined.}\\FV@eha}% {\\@nameuse{FV@LabelPosition@#1}}}\\def\\FV@LabelPosition@none{% \\let\\FV@LabelPositionTopLine\\relax% \\let\\FV@LabelPositionBottomLine\\relax}\\def\\FV@LabelPosition@topline{% \\def\\FV@LabelPositionTopLine{\\@ne}% \\let\\FV@LabelPositionBottomLine\\relax}\\def\\FV@LabelPosition@bottomline{% \\let\\FV@LabelPositionTopLine\\relax% \\def\\FV@LabelPositionBottomLine{\\@ne}}\\def\\FV@LabelPosition@all{% \\def\\FV@LabelPositionTopLine{\\@ne}% \\def\\FV@LabelPositionBottomLine{\\@ne}}\\fvset{labelposition=topline}%% DG/SR modification end%% DG/SR modification begin - May. 19, 1998%% \\def\\FV@SingleFrameLine{%\\def\\FV@SingleFrameLine#1{%%% DG/SR modification end \\hbox to\\z@{% \\kern\\leftmargin%% DG/SR modification begin - Jun. 22, 1998 \\ifnum#1=\\z@ \\let\\FV@Label\\FV@LabelBegin \\else \\let\\FV@Label\\FV@LabelEnd \\fi \\ifx\\FV@Label\\relax%% DG/SR modification end \\FancyVerbRuleColor{\\vrule \\@width\\linewidth \\@height\\FV@FrameRule}%%% DG/SR modification begin - Jun. 22, 1998 \\else \\ifnum#1=\\z@ \\setbox\\z@\\hbox{\\strut\\enspace\\FV@LabelBegin\\enspace\\strut}% \\else \\setbox\\z@\\hbox{\\strut\\enspace\\FV@LabelEnd\\enspace\\strut}% \\fi \\@tempdimb=\\dp\\z@ \\advance\\@tempdimb -.5\\ht\\z@ \\@tempdimc=\\linewidth \\advance\\@tempdimc -\\wd\\z@ \\divide\\@tempdimc\\tw@ \\ifnum#1=\\z@ % Top line \\ifx\\FV@LabelPositionTopLine\\relax \\FancyVerbRuleColor{\\vrule \\@width\\linewidth \\@height\\FV@FrameRule}% \\else \\FV@FrameLineWithLabel \\fi \\else % Bottom line \\ifx\\FV@LabelPositionBottomLine\\relax \\FancyVerbRuleColor{\\vrule \\@width\\linewidth \\@height\\FV@FrameRule}% \\else \\FV@FrameLineWithLabel \\fi \\fi \\fi%% DG/SR modification end \\hss}}%% DG/SR modification begin - May. 19, 1998\\def\\FV@FrameLineWithLabel{% \\ht\\z@\\@tempdimb\\dp\\z@\\@tempdimb% \\FancyVerbRuleColor{% \\vrule \\@width\\@tempdimc \\@height\\FV@FrameRule \\raise\\@tempdimb\\box\\z@ \\vrule \\@width\\@tempdimc \\@height\\FV@FrameRule}}%% DG/SR modification end\\def\\FV@BeginListFrame@Lines{% \\begingroup \\lineskip\\z@skip%% DG modification begin - June 18, 1997 (effect of \\baselineskip too earlier)%% \\baselineskip\\z@skip%% \\FV@SingleFrameLine%% DG/SR modification begin - May. 19, 1998%% \\FV@SingleFrameLine \\FV@SingleFrameLine{\\z@}%%% DG/SR modification end \\kern-0.5\\baselineskip\\relax \\baselineskip\\z@skip%% DG modification end \\kern\\FV@FrameSep\\relax \\endgroup}%\\def\\FV@EndListFrame@Lines{% \\begingroup \\baselineskip\\z@skip \\kern\\FV@FrameSep\\relax%% DG/SR modification begin - May. 19, 1998%% \\FV@SingleFrameLine \\FV@SingleFrameLine{\\@ne}%%% DG/SR modification end \\endgroup}\\def\\FV@SingleFrameSep{% \\hbox to \\z@{% \\kern\\leftmargin \\hbox to\\linewidth{% \\FancyVerbRuleColor{%%% DG modification begin - June 18, 1997 (\\FV@FrameSep missing) \\ifx\\FancyVerbFillColor\\relax \\vrule\\@width 0pt\\@height\\FV@FrameSep\\relax \\fi%% DG modification end \\vrule\\@width\\FV@FrameRule\\relax \\ifx\\FancyVerbFillColor\\relax \\hfil \\else {\\FancyVerbFillColor\\leaders\\hrule\\@height\\FV@FrameSep\\hfil}% \\fi%% DG modification begin - June 18, 1997 (\\FV@FrameSep missing) \\ifx\\FancyVerbFillColor\\relax \\vrule\\@width 0pt\\@height\\FV@FrameSep\\relax \\fi%% DG modification end \\vrule\\@width\\FV@FrameRule\\relax}}% \\hss}}\\def\\FV@LeftListFrame@Single{% \\strut {\\FancyVerbRuleColor{\\vrule \\@width\\FV@FrameRule}}% \\FV@FrameFillLine%% DG modification begin - June 18, 1997 (to fill color on left side)%% \\kern\\FV@FrameSep} \\ifx\\FancyVerbFillColor\\relax \\kern\\FV@FrameSep \\else {\\noexpand\\leavevmode\\FancyVerbFillColor{\\vrule\\@width\\FV@FrameSep}}% \\fi}%% DG modification end\\def\\FV@RightListFrame@Single{%%% DG modification begin - June 18, 1997 (to fill color on right side)%% \\kern\\FV@FrameSep \\ifx\\FancyVerbFillColor\\relax \\kern\\FV@FrameSep \\else {\\noexpand\\leavevmode\\FancyVerbFillColor{\\vrule\\@width\\FV@FrameSep}}% \\fi {\\noexpand\\leavevmode\\FancyVerbRuleColor{\\vrule\\@width\\FV@FrameRule}}}%% DG modification end\\def\\FV@EndListFrame@Single{% \\penalty\\@M \\FV@SingleFrameSep \\penalty\\@M%% DG/SR modification begin - May. 19, 1998%% \\FV@SingleFrameLine} \\FV@SingleFrameLine{\\@ne}}%% DG/SR modification end\\define@key{FV}{framerule}{% \\@tempdima=#1\\relax \\edef\\FV@FrameRule{\\number\\@tempdima sp\\relax}}\\def\\KV@FV@framerule@default{\\let\\FV@FrameRule\\fboxrule}\\define@key{FV}{framesep}{% \\@tempdima=#1\\relax \\edef\\FV@FrameSep{\\number\\@tempdima sp\\relax}}\\def\\KV@FV@framesep@default{\\let\\FV@FrameSep\\fboxsep}\\fvset{framerule,framesep}\\define@key{FV}{rulecolor}{% \\def\\@tempa{#1}% \\ifx\\@tempa\\FV@None \\let\\FancyVerbRuleColor\\relax \\else \\let\\FancyVerbRuleColor\\@tempa \\fi}\\define@key{FV}{fillcolor}{% \\def\\@tempa{#1}% \\ifx\\@tempa\\FV@None \\let\\FancyVerbFillColor\\relax \\else \\let\\FancyVerbFillColor\\@tempa \\fi}\\fvset{rulecolor=none,fillcolor=none}\\def\\FV@Frame@double{% \\let\\FV@FrameBegin\\FV@FrameBegin@double \\let\\FV@FrameLine\\FV@FrameLine@double \\let\\FV@FrameEnd\\FV@FrameEnd@double}\\define@key{FV}{frame}[none]{% \\@ifundefined{FV@Frame@#1}% {\\FV@Error{Frame style `#1' not defined.}\\FV@eha}% {\\@nameuse{FV@Frame@#1}}}\\fvset{frame=none}\\newcounter{FancyVerbLine}\\define@key{FV}{firstnumber}[auto]{% \\def\\@tempa{#1}\\def\\@tempb{auto}% \\ifx\\@tempa\\@tempb \\def\\FV@SetLineNo{% \\c@FancyVerbLine\\FV@CodeLineNo \\advance\\c@FancyVerbLine\\m@ne}% \\else \\def\\@tempb{last}% \\ifx\\@tempa\\@tempb \\let\\FV@SetLineNo\\relax \\else%% DG/SR modification begin - Jan. 19, 1998%% \\def\\FV@SetLineNo{\\c@FancyVerbLine#1}% \\def\\FV@SetLineNo{% \\c@FancyVerbLine#1 \\advance\\c@FancyVerbLine\\m@ne}%%% DG/SR modification end \\fi \\fi}\\define@booleankey{FV}{numberblanklines}% {\\let\\if@FV@NumberBlankLines\\iftrue} {\\let\\if@FV@NumberBlankLines\\iffalse}\\fvset{numberblanklines=true}%% DG/SR modification begin - May. 20, 1998%%\\def\\refstepcounter#1{% Adapted from latex.ltx\\def\\FV@refstepcounter#1{%%% DG/SR modification end \\stepcounter{#1}% \\protected@edef\\@currentlabel {\\csname p@#1\\endcsname\\arabic{FancyVerbLine}}}\\def\\FV@StepLineNo{% \\FV@SetLineNo%% DG/SR modification begin - Apr. 28, 1998 and May 20, 1998%% \\def\\FV@StepLineNo{\\refstepcounter{FancyVerbLine}}% \\def\\FV@StepLineNo{% \\if@FV@NumberBlankLines \\FV@refstepcounter{FancyVerbLine} \\else \\ifx\\FV@Line\\empty \\else \\FV@refstepcounter{FancyVerbLine} \\fi \\fi}%%% DG/SR modification end \\FV@StepLineNo}%% DG/SR modification begin - 1995%%\\def\\theFancyVerbLine{\\rm\\tiny\\arabic{FancyVerbLine}}\\def\\theFancyVerbLine{\\rmfamily\\tiny\\arabic{FancyVerbLine}}%% DG/SR modification end\\define@key{FV}{numbers}[none]{% \\@ifundefined{FV@Numbers@#1}% {\\FV@Error{Numbers style `#1' not defined.}\\FV@eha}% {\\@nameuse{FV@Numbers@#1}}}%% DG modification begin - Dec. 20, 1995 and Jan. 28, 1998%%\\def\\FV@Numbers@none{\\let\\FV@LeftListNumber\\relax}\\def\\FV@Numbers@none{%\\let\\FV@LeftListNumber\\relax\\let\\FV@RightListNumber\\relax}\\newcount\\FV@StepNumber\\define@key{FV}{stepnumber}{\\FV@StepNumber#1}\\def\\KV@FV@stepnumber@default{\\FV@StepNumber\\@ne}\\fvset{stepnumber}%% DG modification begin - Dec. 20, 1995%%\\def\\FV@Numbers@left{%%% \\def\\FV@LeftListNumber{\\hbox to\\z@{%%% \\hss\\theFancyVerbLine\\kern\\FV@NumberSep}}}\\def\\FV@Numbers@left{%%% DG/SR modification begin - Apr. 28, 1998 \\let\\FV@RightListNumber\\relax%% DG/SR modification end \\def\\FV@LeftListNumber{% \\@tempcnta=\\FV@CodeLineNo \\@tempcntb=\\FV@CodeLineNo \\divide\\@tempcntb\\FV@StepNumber \\multiply\\@tempcntb\\FV@StepNumber \\ifnum\\@tempcnta=\\@tempcntb%% DG/SR modification begin - Apr. 28, 1998%% \\hbox to\\z@{\\hss\\theFancyVerbLine\\kern\\FV@NumberSep}% \\if@FV@NumberBlankLines \\hbox to\\z@{\\hss\\theFancyVerbLine\\kern\\FV@NumberSep}% \\else \\ifx\\FV@Line\\empty \\else \\hbox to\\z@{\\hss\\theFancyVerbLine\\kern\\FV@NumberSep}% \\fi \\fi%% DG/SR modification end \\fi}}\\def\\FV@Numbers@right{%%% DG/SR modification begin - Apr. 28, 1998 \\let\\FV@LeftListNumber\\relax%% DG/SR modification end \\def\\FV@RightListNumber{% \\@tempcnta=\\FV@CodeLineNo \\@tempcntb=\\FV@CodeLineNo \\divide\\@tempcntb\\FV@StepNumber \\multiply\\@tempcntb\\FV@StepNumber \\ifnum\\@tempcnta=\\@tempcntb%% DG/SR modification begin - Apr. 28, 1998%% \\hbox to \\z@{\\kern\\FV@NumberSep\\theFancyVerbLine\\hss}% \\if@FV@NumberBlankLines \\hbox to\\z@{\\kern\\FV@NumberSep\\theFancyVerbLine\\hss}% \\else \\ifx\\FV@Line\\empty \\else \\hbox to\\z@{\\kern\\FV@NumberSep\\theFancyVerbLine\\hss}% \\fi \\fi%% DG/SR modification end \\fi}}%% DG modification end\\define@key{FV}{numbersep}{% \\@tempdima=#1\\relax \\edef\\FV@NumberSep{\\number\\@tempdima sp\\relax}}\\fvset{numbers=none,numbersep=12pt,firstnumber=auto}\\def\\FV@BVerbatimBegin{% \\begingroup \\FV@UseKeyValues \\FV@BeginVBox \\let\\FV@ProcessLine\\FV@BProcessLine \\FV@FormattingPrep \\FV@ObeyTabsInit}%\\def\\FV@BVerbatimEnd{\\FV@EndVBox\\endgroup}\\def\\FV@BeginVBox{% \\leavevmode \\hbox\\ifx\\FV@boxwidth\\relax\\else to\\FV@boxwidth\\fi\\bgroup \\ifcase\\FV@baseline\\vbox\\or\\vtop\\or$\\vcenter\\fi\\bgroup}\\def\\FV@EndVBox{\\egroup\\ifmmode$\\fi\\hfil\\egroup}\\define@key{FV}{boxwidth}{% \\def\\@tempa{#1}\\def\\@tempb{auto}% \\ifx\\@tempa\\@tempb \\let\\FV@boxwidth\\relax \\else \\@tempdima=#1\\relax \\edef\\FV@boxwidth{\\number\\@tempdima sp}% \\fi}\\def\\KV@FV@boxwidth@default{\\let\\FV@boxwidth\\relax}\\define@key{FV}{baseline}{% \\if t#1\\@empty\\let\\FV@baseline\\@ne\\else \\if c#1\\@empty\\let\\FV@baseline\\tw@\\else\\let\\FV@baseline\\z@\\fi \\fi}\\fvset{baseline=b,boxwidth}\\def\\FV@BProcessLine#1{\\hbox{\\FancyVerbFormatLine{#1}}}\\def\\FVB@BVerbatim{\\FV@BVerbatimBegin\\FV@Scan}\\def\\FVE@BVerbatim{\\FV@BVerbatimEnd}\\DefineVerbatimEnvironment{BVerbatim}{BVerbatim}{}\\def\\FV@BUseVerbatim#1{\\FV@BVerbatimBegin#1\\FV@BVerbatimEnd}\\def\\BVerbatimInput{\\FV@Command{}{BVerbatimInput}}\\def\\FVC@BVerbatimInput#1{\\FV@BUseVerbatim{\\FV@Input{#1}}}\\def\\SaveVerbatim{\\FV@Environment{}{SaveVerbatim}}\\def\\FVB@SaveVerbatim#1{% \\@bsphack \\begingroup \\FV@UseKeyValues%% \\FV@BeginVBox%% \\let\\FV@ProcessLine\\FV@BProcessLine%% \\FV@FormattingPrep%% \\FV@ObeyTabsInit%%% \\def\\SaveVerbatim@Name{#1}% \\gdef\\FV@TheVerbatim{}% \\def\\FV@ProcessLine##1{% \\expandafter\\gdef\\expandafter\\FV@TheVerbatim\\expandafter{% \\FV@TheVerbatim\\FV@ProcessLine{##1}}}% \\gdef\\FV@TheVerbatim{}% \\FV@Scan}\\def\\FVE@SaveVerbatim{% \\expandafter\\global\\expandafter\\let \\csname FV@SV@\\SaveVerbatim@Name\\endcsname\\FV@TheVerbatim%% \\expandafter\\gdef%% \\csname FV@SV@\\SaveVerbatim@Name\\endcsname{\\FV@TheVerbatim}%% \\FV@EndVBox%% \\endgroup} \\endgroup\\@esphack}\\DefineVerbatimEnvironment{SaveVerbatim}{SaveVerbatim}{}\\def\\FV@CheckIfSaved#1#2{% \\@ifundefined{FV@SV@#1}% {\\FV@Error{No verbatim text has been saved under name `#1'}\\FV@eha}% {#2{\\csname FV@SV@#1\\endcsname}}}\\def\\UseVerbatim{\\FV@Command{}{UseVerbatim}}\\def\\FVC@UseVerbatim#1{\\FV@CheckIfSaved{#1}{\\FV@UseVerbatim}}\\def\\LUseVerbatim{\\FV@Command{}{LUseVerbatim}}\\def\\FVC@LUseVerbatim#1{\\FV@CheckIfSaved{#1}{\\FV@LUseVerbatim}}\\def\\BUseVerbatim{\\FV@Command{}{BUseVerbatim}}\\def\\FVC@BUseVerbatim#1{\\FV@CheckIfSaved{#1}{\\FV@BUseVerbatim}}\\newwrite\\FV@OutFile\\def\\VerbatimOut{\\FV@Environment{}{VerbatimOut}}\\def\\FVB@VerbatimOut#1{% \\@bsphack \\begingroup \\FV@UseKeyValues \\FV@DefineWhiteSpace \\def\\FV@Space{\\space}% \\FV@DefineTabOut \\def\\FV@ProcessLine{\\immediate\\write\\FV@OutFile}% \\immediate\\openout\\FV@OutFile #1\\relax \\let\\FV@FontScanPrep\\relax%% DG/SR modification begin - May. 18, 1998 (to avoid problems with ligatures) \\let\\@noligs\\relax%% DG/SR modification end \\FV@Scan}\\def\\FVE@VerbatimOut{\\immediate\\closeout\\FV@OutFile\\endgroup\\@esphack}\\DefineVerbatimEnvironment{VerbatimOut}{VerbatimOut}{}\\def\\FV@DefineTabOut{% \\def\\FV@Tab{}% \\@tempcnta=\\FancyVerbTabSize\\relax \\loop\\ifnum\\@tempcnta>\\z@ \\edef\\FV@Tab{\\FV@Tab\\space}% \\advance\\@tempcnta\\m@ne \\repeat}\\def\\SaveVerb{\\FV@Command{}{SaveVerb}}\\begingroup\\catcode`\\^^M=\\active%\\gdef\\FVC@SaveVerb#1#2{% \\@namedef{FV@SV@#1}{}% \\begingroup% \\FV@UseKeyValues% \\FV@CatCodes% \\outer\\def^^M{\\FV@EOL}% \\global\\let\\@tempg\\FancyVerbAfterSave% \\catcode`#2=12% \\def\\@tempa{\\def\\FancyVerbGetVerb####1####2}% \\expandafter\\@tempa\\string#2{\\endgroup\\@namedef{FV@SV@#1}{##2}\\@tempg}% \\FancyVerbGetVerb\\FV@EOL}%\\endgroup\\def\\FV@EOL{% \\endgroup \\FV@Error% {Could not find the end delimiter of a short verb command}% {You probably just forget the end delimiter of a \\string\\Verb\\space or \\string\\SaveVerb^^J% command, or you broke the literal text across input lines.^^J% Hit to procede.}}\\define@key{FV}{aftersave}{\\def\\FancyVerbAfterSave{#1}}\\fvset{aftersave=}\\def\\FV@UseVerb#1{\\mbox{\\FV@UseKeyValues\\FV@FormattingPrep#1}}\\def\\UseVerb{\\FV@Command{}{UseVerb}}\\def\\FVC@UseVerb#1{% \\@ifundefined{FV@SV@#1}% {\\FV@Error{Short verbatim text never saved to name `#1'}\\FV@eha}% {\\FV@UseVerb{\\@nameuse{FV@SV@#1}}}}\\def\\Verb{\\FV@Command{}{Verb}}\\begingroup\\catcode`\\^^M=\\active%\\gdef\\FVC@Verb#1{% \\begingroup% \\FV@UseKeyValues% \\FV@FormattingPrep% \\FV@CatCodes% \\outer\\def^^M{}% \\catcode`#1=12% \\def\\@tempa{\\def\\FancyVerbGetVerb####1####2}% \\expandafter\\@tempa\\string#1{\\mbox{##2}\\endgroup}% \\FancyVerbGetVerb\\FV@EOL}%\\endgroup\\def\\DefineShortVerb{\\FV@Command{}{DefineShortVerb}}\\def\\FVC@DefineShortVerb#1{% \\@ifundefined{FV@CC@\\string#1}% {\\FVC@@DefineShortVerb#1}% {\\FV@Error{`\\expandafter\\@gobble\\string#1' is already a short verb character.}\\FV@eha}}\\def\\FVC@@DefineShortVerb#1{% \\begingroup \\lccode`\\~=`#1% \\lowercase{\\gdef\\@tempg{\\edef~}\\global\\let\\@temph~}% \\endgroup \\expandafter\\let\\csname FV@AC@\\string#1\\endcsname\\@temph \\expandafter\\edef\\csname FV@CC@\\string#1\\endcsname{\\the\\catcode`#1}% \\expandafter\\let\\csname FV@KV@\\string#1\\endcsname\\FV@KeyValues \\@tempg{% \\let\\noexpand\\FV@KeyValues\\expandafter\\noexpand \\csname FV@KV@\\string#1\\endcsname \\noexpand\\FVC@Verb\\expandafter\\@gobble\\string#1}% \\expandafter\\def\\expandafter\\dospecials\\expandafter{\\dospecials\\do#1}% \\expandafter\\def\\expandafter\\@sanitize\\expandafter{\\@sanitize\\@makeother#1}% \\catcode`#1=\\active}%\\def\\UndefineShortVerb#1{% \\@ifundefined{FV@CC@\\string#1}% {\\FV@Error{`\\expandafter\\@gobble\\string#1' is not a short verb character}\\FV@eha}% {\\FV@UndefineShortVerb#1}}\\def\\FV@UndefineShortVerb#1{% \\catcode`#1=\\csname FV@CC@\\string#1\\endcsname%% DG/SR modification begin - Jun. 12, 1998 \\expandafter\\let\\csname FV@CC@\\string#1\\endcsname\\relax%% DG/SR modification end \\begingroup \\lccode`\\~=`#1% \\lowercase{\\gdef\\@tempg{\\let~}}% \\endgroup \\expandafter\\@tempg\\csname FV@AC@\\string#1\\endcsname \\def\\@tempa##1\\do#1##2\\@nil##3\\@nil##4\\@@nil{##3\\def\\dospecials{##1##2}\\fi}% \\expandafter\\@tempa\\dospecials\\@nil\\iftrue\\@nil\\do#1\\@nil\\iffalse\\@nil\\@@nil \\def\\@tempa##1\\@makeother#1##2\\@nil##3\\@nil##4\\@@nil{% ##3\\def\\@sanitize{##1##2}\\fi}% \\expandafter\\@tempa\\@sanitize\\@nil\\iftrue\\@nil\\do#1\\@nil\\iffalse\\@nil\\@@nil}\\def\\SaveMVerb{\\FV@Command{}{SaveMVerb}}\\begingroup\\catcode`\\^^M=\\active%\\gdef\\FVC@SaveMVerb#1#2{% \\@ifundefined{FV@SVM@#1}{}% {\\FV@Error{Moving verbatim name `#1' already used}% {I will overwrite the old definition. Hit to continue.}}% \\global\\@namedef{FV@SVM@#1}{}% \\begingroup% \\let\\FV@SavedKeyValues\\FV@KeyValues% \\FV@UseKeyValues% \\FV@CatCodes% \\outer\\def^^M{}% \\global\\let\\@tempg\\FancyVerbAfterSave% \\catcode`#2=12% \\def\\@tempa{\\def\\FancyVerbGetVerb####1####2}% \\expandafter\\@tempa\\string#2{% \\if@filesw \\FV@DefineWhiteSpace% \\let\\FV@Space\\space% \\let\\FV@Tab\\space% \\FV@MakeUnActive% \\let\\protect\\string \\immediate\\write\\@auxout{% \\noexpand\\SaveGVerb[\\FV@SavedKeyValues]{#1}\\string#2##2\\string#2}% \\fi \\endgroup% \\@namedef{FV@SV@#1}{##2}% \\@tempg}% \\FancyVerbGetVerb\\FV@EOL}%\\endgroup\\def\\SaveGVerb{\\FV@Command{}{SaveGVerb}}\\begingroup\\catcode`\\^^M=\\active%\\gdef\\FVC@SaveGVerb#1#2{% \\global\\@namedef{FV@SVG@#1}{}% \\begingroup% \\FV@UseKeyValues% \\FV@CatCodes% \\outer\\def^^M{}% \\catcode`#2=12% \\def\\@tempa{\\def\\FancyVerbGetVerb####1####2}% \\expandafter\\@tempa\\string#2{\\endgroup\\global\\@namedef{FV@SVG@#1}{##2}}% \\FancyVerbGetVerb\\FV@EOL}%\\endgroup\\def\\UseMVerb{\\protect\\pUseMVerb}\\def\\pUseMVerb{\\FV@Command{}{pUseMVerb}}\\def\\FVC@pUseMVerb#1{% \\expandafter\\ifx \\csname FV@SVM@#1\\endcsname\\relax \\expandafter\\ifx \\csname FV@SVG@#1\\endcsname\\relax \\@warning{Moving verbatim text not defined for name `#1'}\\FV@eha {\\bf ??}% \\else \\FV@UseVerb{\\@nameuse{FV@SVG@#1}}% \\fi \\else \\FV@UseVerb{\\@nameuse{FV@SVM@#1}}% \\fi}\\expandafter\\ifx\\csname documentclass\\endcsname\\relax \\def\\lrbox#1{% \\edef\\@tempa{% \\endgroup \\setbox#1\\hbox{% \\begingroup\\aftergroup}% \\def\\noexpand\\@currenvir{\\@currenvir}}% %\\def\\noexpand\\@currenvline{\\on@line}}% \\@tempa \\@endpefalse \\bgroup \\ignorespaces} \\def\\endlrbox{\\unskip\\egroup}\\fi%%%%%%%%%%%%%%% New for CS16\\newenvironment{pseudo}{\\Verbatim[commandchars=\\\\\\{\\},codes={\\catcode`$=3\\catcode`^=7\\catcode`_=8}]}{\\endVerbatim}\\newenvironment{verbatimcs}{\\Verbatim[commandchars=\\\\\\{\\},codes={\\catcode`$=3\\catcode`^=7\\catcode`_=8}]}{\\endVerbatim}\\newcommand{\\new}[1]{{\\em #1\\/}}% New term (set in italics).\\newcommand{\\set}[1]{\\{#1\\}}% Set (as in \\set{1,2,3})\\newcommand{\\setof}[2]{\\{\\,{#1} $\\mid$~{#2}\\,\\}}% Set (as in \\setof{x}{x > 0})\\newcommand{\\N}{\\mathord{\\Bbb N}}% Positive integers.\\newcommand{\\compl}[1]{\\overline{#1}}% Complement of ... \\newcommand{\\bigand}{\\bigwedge}\\newcommand{\\bigor}{\\bigvee}\\newcommand{\\OR}{\\vee}\\newcommand{\\AND}{\\wedge}\\newcommand{\\code}[1]{\\texttt{#1}}\\newcommand{\\tab}{\\hspace*{.3in}}\\newcommand{\\nlogn}{n \\log n}%% DG/SR modification begin - Mar 21 2000%%\\@input{fancyvrb.rc}\\InputIfFileExists{fancyvrb.cfg}{}{}%% DG/SR modification end\\endinput%%%% End of file `fancyvrb.sty'.", "https://cs.brown.edu/courses/cs016/static/files/lectures/slides/longest_capitalized_word.py": "def longest_capitalized_word(sentence): words = sentence.split(\" \") longest = \"\" length = 0 for word in words: if len(word) > 0: capitalized = word[0].isupper() if capitalized and len(word) > length: longest = word length = len(word) return longestdef test_longest_capitalized_word(): assert longest_capitalized_word(\"There are Several capitalized Words Here\") == \"Several\" assert longest_capitalized_word(\"dog\") == \"\" assert longest_capitalized_word(\"Hello World\") == \"Hello\" assert longest_capitalized_word(\"\") == \"\"tests = [test_longest_capitalized_word]if __name__ == \"__main__\": for test in tests: test() print(\"All tests passed\")", "https://cs.brown.edu/courses/cs016/static/files/lectures/slides/preceding_words.py": "def preceding_words(sentence): words = sentence.split(\" \") index = 1 preceding = {} while index < len(words): word = words[index] if len(word) > 0: previous = words[index - 1] if word in preceding: preceding[word].append(previous) else: preceding[word] = [previous] index = index + 1 return precedingdef test_preceding_words(): assert preceding_words(\"\") == {} assert preceding_words(\"Hello\") == {\"Hello\": []} assert preceding_words(\"Python is fun\") == {\"Python\": [], \"is\": [\"Python\"], \"fun\": [\"is\"]} assert preceding_words(\"a b b\") == {\"a\": [], \"b\": [\"a\", \"b\"]}tests = []if __name__ == \"__main__\": for test in tests: test() print(\"All tests passed\")", "https://cs.brown.edu/courses/cs019/2012/assignments/filesystem": "Programming with Data Structures and Algorithms Welcome README Assignments Readings Software Contact Credits Filesystem Read How to Design Programs Chapter 16 Complete exercises 16.3.2-16.3.4 and the Challenge question. Clarifications: Though we would love to see your response for the follow-up question for 16.3.2, we aren't requiring you to. There is a solution attached to 16.3.2. Though we know you may well read it, we highly suggest not to, at least until you've completed the problem. Before you start working, you should add dir.ss as a teachpack. (Language/Add Teachpack) In the second part of exercise 16.3.3, the size of a directory is the sum of the sizes of its contents, the length of its files list, and the length of its dirs list. For example, in HTDP Figure 44, the size of the TS directory is 218, and the size of the Code directory is 12. The Challenge question asks you to \"Generalize the function [find] to return a list of paths if the file name occurs more than once. Each path should lead to a different occurrence, and there should be a path for each occurrence.\"The find function you hand in should have type signature find : directory symbol -> (listof path)) where a path is a list of symbols. Note: it should return empty if the file name does not occur (rather than false as stated under the challenge instructions), and a list containing a single path if the file name occurs only once. What to turn in: A Racket file, filesystem.rkt , containing your implementations of the functions described in these exercises. Only turn in the final version of each function.", "https://cs.brown.edu/courses/cs016/averages.html": "Toggle navigation SEA-S 16 Home Documents Lectures Assignments Section TA Hours + Staff Assignment Averages Assignment Averages: Assignment averages will be released after grade reports are sent. Assignment Mean Median Out Of HW1 52.12 53 60 HW2 - Written 31.26 33 36 HW2 - Code 60.73 63.17 68.5 HW3 - Written 18.41 20 22 HW3 - Code 39.46 42 44 HW4 - Written 27.15 28.5 33 HW4 - Code 25.19 27.47 31 HW5 - Written 23.69 25 28 HW5 - Code 18.82 20.48 23 Optional HW6 - Written 16.88 20 25 Optional HW6 - Code 33.52 41.13 46 HW8 - Written 12.71 13 16 HW8 - Code 55.94 60 62.5 HW9 - Written 17.97 19 20 HW9 - Code 36.94 39 44 Seamcarve 91.48 93 100 Heap 90.75 94 100 Decision Tree Graph Midterm 71.98 74 87", "https://cs.brown.edu/courses/cs019/2012/assignments/flags": "Programming with Data Structures and Algorithms Welcome README Assignments Readings Software Contact Credits Flags Supplement The world is full of countries, each with its own unique identifier, in the form of a beautiful flag.Your job is to create the flags of the following countries by composing shapes onto a scene. Vietnam Chile Suriname Tunisia Saint Lucia Example: Japan. (place-image (circle 35 \"solid\" \"red\") 100 50 (rectangle 200 100 \"solid\" \"white\")) Note: You can use either place-image or overlay to position your images, it is up to you. The Image.ss Teachpack In order to use the functions place-image , rotate ,and other goodies that we've included, you will be wanting to add a specialimage-processing teachpack called image.ss . You can find it in the Add Teachpackmenu, (Language/Add Teachpack) in the HtDP/2e section, in the center of the screen.You will find the documentation to be useful. The CS17 teachpack will conflict with image.ss , so uninstall 17.ss while working with the images. How to turn it in: Please submit a Racket file, flags.rkt , which, when run, displays all the flags in order, along with the rest of your CS17 handin. Read the CS17 homework for details on how to submit all of your files.", "https://cs.brown.edu/courses/cs004/": "CSCI0040 Introduction to Scientific Computing and Problem Solving Piazza Hours Homework Projects Lectures Staff Welcome to CS4! ABOUT Welcome to CS4, Introduction to Scientific Computing and Problem Solving . CS4 provides an introduction to using computers to solve STEM (Science, Technology, Engineering, and Mathematics) data analysis, visualization, simulation, and numerical analysis problems. The course begins with an introduction to the basics of programming, accompanied by several applications of fundamental coding elements and concepts. As we do this we will explore some of the breadth of Computer Science as a discipline. The first part of the course (which runs until Spring Break) will be taught in Python. Following this, we will explore more specialized topics related to scientific computing and mathematics that will allow students to access and analyze a number of \"real world\" problems. The later portion of the course will be taught in MATLAB. Requirements: No prior programming experience is required to take this course (Python and MATLAB are easy and fun to use!). A calculus course (perhaps in high school) is highly recommended. SUPPORT If you have any feedback about assignments or the course in general, please fill out the Anonymous Feedback Form to let the course staff know. If you have any academic/SEAS accommodations that we should be aware of, please fill out this form so that the course staff can best support you. We understand that being a student can be stressful and that certain circumstances can affect your performance in the course. Please refer to the syllabus for more information about receiving academic support for CS0040 or email the HTAs or Prof. Gaudette for more information regarding accommodations. You can also find some resources the CS department has compiled for students here and a helpful message from your TAs here . COURSE DOCUMENTS Syllabus Course Schedule TA Section Signups First Steps Collaboration Policy \"CS For All\" Textbook Python Tutor Python Installation | Style | Testing | Terminal MATLAB Installation Quiz 2 Review QUICK LINKS OUR INSTAGRAM ACCOUNT Piazza Picobot Anonymous Feedback Form WORKING FROM HOME Working from Home (Windows) Working from Home (Mac OSX/Linux) Hours How do TA hours work? In lieu of labs, CS4 has \"TA sections\" (think of them as your assigned TA hours). Each student will be assigned to a single mandatory section. Any material that hasn't been covered in lecture but will be necessary for the assignments will be covered in section. In addition to TA sections, we have open TA hours where you can ask for help on assignments, whether that be conceptual questions or debugging help. These hours are listed on the calendar. When you show up, use SignMeUp to sign up for help. Refer to the course missive for the code of conduct during hours. Homework In general, homeworks will be released on Wednesday after class and will be due the following Wednesday at 4 PM! You have a total of 6 late days to be used on homeworks or projects. However, you can use a max of 3 late days on any given assignment. Please see the syllabus for more information! Diversity and Inclusion Goals As part of a new CS department initiative, we're listing CS4-specific goals to promote diversity and inclusion within the course: 1) Background Agnosticism - since this is an intro course, we want to ensure that no course material, including section lesson plays, lectures, and assignments, will require previous knowledge 2) Feedback Responsiveness - in order to make sure each and every student feels like their voice is valued, we aim to respond to all feedback as quickly and as effectively as possible Name Out Due Homework 0 1/23 1/30 Homework 1 1/30 2/6 Homework 2 2/6 2/13 Homework 3 2/13 2/20 Homework 4 2/20 2/27 Homework 5 2/27 3/6 Homework 6 3/6 3/13 Homework 7 3/13 3/20 Homework 8 4/3 4/10 Homework 9 4/10 4/17 Homework 10 4/17 4/24 Extra Credit 3/12 3/17 Projects Name Out Due Markstrings 2/7 2/28 Modeling 3/1 3/21 Twentyone 4/4 4/25 Projects will always be released and due on Thursdays at midnight! We give you a lot of time to work on these projects since you'll be completing them alongside the other assignments. This means you should manage your time wisely, starting as early as you can! Lectures Topics Date Section Notes Course Introduction and Computational Problem-Solving 1/23 Intro to Python (Data Types, Expressions, Strings, List, Functions) 1/28 Conditional Logic and Variable Scope 1/30 1/31 Test-Driven Design and Iterative Programming 2/4 Iterative Programming and Nested Loops 2/6 2/7 2D Lists and Mutability 2/11 2/11 Files, Dictionaries, and Markov Text 2/13 2/14 Long Weekend! 2/18 Recursion I 2/20 2/21 Recursion II 2/25 Higher Order Functions and Anonymous Functions 2/27 2/28 Modeling and OOP I 3/4 OOP II 3/6 Inheritance 3/11 Connect 4 3/13 MATLAB I: Programs and Functions 3/18 MATLAB II: Conditional Statements and Arrays 3/20 3/25 Spring Break! 3/27 MATLAB III: More Arrays and Design Recipe 4/1 Linear Algebra I 4/3 Linear Algebra II 4/8 Image Processing I 4/10 Image Processing II 4/15 Medical Imaging 4/17 HTA Lecture 4/22 HTA Lecture 4/24 MATLAB Quiz 4/29 CS4 Staff Professor Jason Gaudette (jegaudet) Team: Puppies Welcome to CS4! I am happy to be your instructor this semester. As a research engineer with loads of real-world experience in scientific computing, my goal is to teach you the art and joy of the field. Outside of my main job, I coach kids in FIRST LEGO robotics, volunteer for the IEEE, teach programming and electronics courses, sail a Hobie Cat, and run with my dog Luna.\" HTAs E-mail us at cs0040headtas@lists.brown.edu if you have administrative or private questions. Griffin Kao (gk16) Team: Babies Hi there, I\u2019m a junior from Philadelphia studying computer science and engineering. A fun fact about me is that Kobe Bryant went to my high school! Hersh Gupta (hgupta1) Team: Puppies Hey everybody! My name is Hersh and I\u2019m a junior concentrating in chemistry and computational biology. I\u2019m a big sports fan and love going on Netflix binges but never actually finishing the show. Joy Bestourous (jbestour) Team: Babies Hi hello! I'm a junior studying computer science while filling pre-med requirements (and maybe pre-law! Who knows!). I like New York pizza, iced coffee, going to the gym, dancing, and singing Disney songs. Loudly. UTAs E-mail us at cs0040tas@lists.brown.edu or post a question (privately!) on Piazza if you have any questions about the course. Annie He (ahe6) Team: Babies Hey y\u2019all! I\u2019m a junior from Dallas, TX concentrating in computational biology. If you don\u2019t see me in the scili, I\u2019m either chilling in my pjs or exploring new restaurants! I also love to rock climb, ski, bungee jump, basically anything adventurous! :) Alex Liu (aliu31) Team: Babies I am a junior concentrating in Applied Mathematics and Computer Science. I\u2019m from Eugene, Oregon and outside of class I am involved with the Socially Responsible Investment Fund, I play golf whenever I get the chance, and I try my best to keep up on practicing the Piano. I also run Brown Data Science, a club that, much like this class, brings educational opportunities related to Data Science to undergraduates of all academic backgrounds. Aryan Srivastava (asriva11) Team: Puppies I am a freshman concentrating in CS (probably). I love watching and playing basketball (1v1 me), reading and talking philosophy, and watching artisan videos on youtube! My favorite thing to eat at Brown is a warm Blue Room Chocolate Chip Muffin. Ellen Ling (eling) Team: Babies Hi, I\u2019m a junior from Shanghai studying physics and CS. I like good movies and dance and babies! Irene Rhee (irhee) Team: Puppies Sup dudes, my name is Irene and I\u2019m a junior from Corvallis, OR studying computer science! I like to drink my coffee black, am part of a dance group called Daebak (come to our spring show!!), and enjoy dim sum, boba, and tagging people in memes (go like my post on subtle asian traits). My favorite word is lit. Joseph Chen (jchen88) Team: Babies Hey everyone! I\u2019m a junior from California concentrating in Neuroscience and CS, and I\u2019m a big fan of all things related to swimming, playing basketball, Game of Thrones, and stand-up comedy. Jarrett Huddleston (jhuddle1) Team: Puppies Hey! I\u2019m a sophomore from Eastern Massachusetts concentrating in computer science. Outside of classes I enjoy camping and music, and I\u2019m always looking for a good book! Milla Shin (mshin7) Team: Puppies I\u2019m a junior from Tokyo studying computer science. I like going to the beach. I like food and cooking! I like snowboarding and scuba diving! I love sweet potatoes, avocado, and matcha! Yummy. I like puppies but I like babies too. Pedro de Freitas (pfreitas) Team: Babies Senior from Portland, Maine studying cognitive neuroscience. I\u2019m a lyra performer/instructor who also enjoys painting. Solomon Rueschemeyer-Bailey (sruesche) Team: Puppies I am a junior trying not to let school get in the way of college. Come to my hours or my section if you want to learn about: The Bucket Theorem, whether or not true Love exists, and the future of teleportation. Tiffany Ding (tding5) Team: Puppies Hi! I\u2019m a sophomore from upstate NY studying applied math, economics, and computer science. When I\u2019m not in the CIT, you can find me going for a run or taking photos for the Brown Daily Herald. I also love puns, penguins, and podcasts!", "https://cs.brown.edu/courses/cs019/2012/assignments/rocket": "Programming with Data Structures and Algorithms Welcome README Assignments Readings Software Contact Credits RacketRocket In this assignment you will use universe to create a simple game. In this game you must pilot a rocket around invading aliens to reach \"space\" (the top of the screen). Here is an example of how the game should look: Winning: Reaching the End Losing: Crashing into a UFO The Problem When you are finished, your game should contain the following: A rocket that moves continuously towards the top of the screen from the bottom. The user can control the left-right motion of the rocket with the arrow keys. If the rocket gets to the side of the screen, it should hit a wall (and not be able to fly off the side of the screen). Three UFOs moving left and right across the screen. All three should have different random starting X positions, different random starting Y positions, and different speeds. The position should be \"random\" but constrained so as to make sense. The UFOs should detect collisions with the edge of the screen and move the other way after colliding. If the rocket hits any of the UFOs the rocket should burst into flames (turn into fire-small.png) and the game should end. If the rocket reaches the top of the screen (outer space) the game should end and a victory message should be displayed. To make the assignment easier, you may want to break it up into simpler stages such as: Draw a rocket on the screen and have it move from the bottom to the top. Add UFOs drawn standing still at different starting x and y positions. Make the Rocket horizontally controllable by keyboard Make the UFOs move from left to right across the screen. Add collisions between the UFOs and the walls. Add collision detection between the UFOs and the rocket and add the flame-burst final scene Testing Your test cases will be a major part of your grade on this assignment.Remember, many of your functions have graphical output, which makesthem difficult to test. This puts an even greater burden on how wellyou test your non-graphical functions. We expect to see you sustainthis burden. Hints You will want the following clipart images: rocket-small-up.png ufo.png fire-small.png Remember, you can insert an image into your Racket code by selecting \"Insert Image...\" from the \"Insert\" menu, or by copying and pasting an image into your code. Your definition of an image to use for drawing would look like: (define MY-IMAGE ) You may also find the Racket documentation on big-bang to be useful. You'll want a big-bang that reacts to key-presses, knows when to stop, can draw itself and continually moves the rocket. You'll need to figure out which of the big-bang clauses will allow you to do this. Remember to think about what you want in your world - and how you'll need tochange your world before starting to program, and use the design recipe. You will also find the Racket documentation on drawing your own images to be useful - especially on how to overlay one image above another in a givenposition. For generating random numbers, look at the documentation on random here . You shouldn't have to copy-paste any code. If you find yourself duplicating code, you make wish to rethink the structure of your world. Finally, you may want to look through the fully worked-out example ofa universe program (Flight Lander) in How to Design Worlds . Note thatthe text uses an older version of big-bang , so read itfor the ideas and most, but not all, of the code. What should my Racket code look like? Your Racket should look like Racket, not Java. We expect you to follow the formatting conventions below: This means,closing parentheses go on the same line, not the line below. You wantthe following: (define (add-two num) (+ num 2)) not: (define (add-two num) (+ num 2) ) Name your variables using dashes to separate words. Don't camel case, don't useunderscores. You want my-function not MyFunction , my_function or My-Function . Try to keep the total length of your lines around 80 characters. You can bringarguments down to a new line if you have too many. Breaking up different argumentsonto separate lines allows the reader to see what expressions are arguments to what other functions. This is much easier to read: (a-very-long-function-name a-long-input-argument an-even-longer-input-argument an-even-even-longer-input-argument) than: (a-very-long-function-name a-long-input-argument an-even-longer-input-argument an-even-even-longer-input-argument) If you bring arguments down to a new line, many coders will put all of thearguments on their own line, even if multiple arguments could be fit on the sameline. However, this depends on the coder. Comments - you should have them and they should say things that the functionname doesn't already say. Constants - should be named in all caps with hyphens. E.g: (define SOME-CONSTANT 2) The Image.ss Teachpack Again, you'll want to include the image.ss teachpack to get accessto image processing function. You can find it in the Add Teachpack menu,(Language/Add Teachpack) in the HtDP/2e section, in the center of the screen. Also, since you'll be using world programming, please include Universe.ss , from the same middle column. And also remember to uninstall the 17.ss teachpack while working with image.ss . What to turn in: A Racket file, rocket.rkt , with code implementing the finished game.", "https://cs.brown.edu/courses/cs019/2012/assignments/sortacle": "Programming with Data Structures and Algorithms Welcome README Assignments Readings Software Contact Credits Supp 5: Sortacle When you are testing complex functions, or perhaps even relations (as in the case of this assignment), you will need to put time and effort into building testing oracles. In this assignment, you will develop oracles to test purported sorting algorithms. Countries by medal count, companies by income, students by GPA, the list goes on and on. The Assignment Being confident that your software is correct involves more than just writing code you think is right. However, almost no software complex enough to be useful can be proved correct by hand in a reasonable amount of time. Naturally, a computer scientist's solution to this problem is to write automated testing. Your job, in this assignment, is to build an automated testing oracle for a solution to the sorting problem. Your oracle's job is to generate and feed test inputs to this solution and test the correctness of the output. In the past, you did this by comparing the output to a precomputed correct answer. This assumes two things: that there is only one right answer, and that it is easy for you to find it. In the real world, either or bothof these can be false. Using the following struct where name is a string and age is a number , you will build an oracle for a function sorting lists of people by non-decreasing age. (define-struct person (name age)) Use the \"sort\" function in the language to make a correct version called age-sort that takes in a list of people and returns the sorted list. Our sorting functions will use the same contract. age-sort : (listof person) -> (listof person) We will be feeding your oracle a multitude of interesting functions, some that are legitimate sorting algorithms, some that are not. Your oracle should only return true for functions that pass all tests. Input-Output Specification Each purported solution will return the list of people in a new order; your oracle must determine the functions that consistently return the list sorted by age in a strictly non-decreasing order (eg. 1, 13, 25, 25, 41). Your assignment has three tasks: Write a function named generate-input that (surprise, surprise!) generates input. This function should take an integer length, and return a list of randomly aged people of that length. (You may assume an upper age limit of 150). generate-input : number -> (listof person) Write a function that determines whether the second input is a sorted version of the first. valid? : (listof person) (listof person) -> boolean Using valid? and generate-input (along with any other edge cases you think to include), write a function named oracle that tests whether an algorithm is a valid sorter. oracle : ((listof: person) -> (listof person)) -> boolean Remember, an algorithm may sometimes produce a correct solution even if it is an incorrect algorithm. Therefore, your oracle should only return true if an algorithm always sorts correctly (it is up to you to determine the magnitude of \"always\"). To do well on this assignment, you will want to spend time considering all the different ways that output could be either invalid or inconsistent with the original problem statement. Be thorough! That's the name of the game when testing. What to turn in: A Racket file, sortacle.rkt , containing your implementation.", "https://cs.brown.edu/courses/cs0112/": "Under construction", "https://cs.brown.edu/courses/cs015/": "\u2630 Assignments Lectures Sections Code-along Hours Resources SRC Staff function toggleNavbar() { var navbar = document.getElementById(\"navbar\"); if (navbar.className === \"nav-bar\") { navbar.className += \" responsive\"; } else { navbar.className = \"nav-bar\"; } } WELCOME TO CSCI 0150 CS0150 is one of the introductory Computer Science courses offered at Brown University. This course introduces students to Computer Science through object-oriented design and programming, using Java and the JavaFX graphics library. You will use these tools for building interactive programs with graphical user interfaces. CS0150 reinforces concepts with practical exercises in weekly lab sessions and with challenging and engaging programming assignments, such as Doodle Jump and Tetris! There are no prerequisites for CS0150 and the course expects no prior programming experience. This Week in CS15 (Nov 26 - Dec 2) Assignment Othello Handout Help Slides Help Session AI Handout Assignment Pacman Handout Help Slides Help Session Assignment Sketchy Handout Help Slides Help Session Javadocs Assignment Indy Handout Mini-Assignment Assignments Assignment Released Early On Time Late Javadocs Help Slides Help Session Additional Handouts Rattytouille Sept 13 N/A Sept 16 N/A - - - - AndyBot Sept 17 N/A Sept 20 N/A JavaDocs - - - Pong Sept 21 N/A Sept 25 N/A JavaDocs - - - TicTacToe Sept 26 Sept 28 Sept 30 Oct 02 JavaDocs - - - Fruit Ninja Oct 03 Oct 08 Oct 10 Oct 12 JavaDocs Help Slides - - Cartoon Oct 12 Oct 19 Oct 21 Oct 23 - Help Slides - Mini-Assignment DoodleJump Oct 24 Oct 30 Nov 01 Nov 03 - Help Slides - - Tetris Nov 04 Nov 11 Nov 13 Nov 15 - Help Slides - - Pacman Nov 17 Dec 10 Dec 12 Dec 14 - Help Slides Help Session - Sketchy Nov 17 Dec 10 Dec 12 Dec 14 Javadocs Help Slides Help Session - Othello Nov 17 Dec 10 Dec 12 Dec 14 - Help Slides Help Session AI Handout Indy Nov 17 Dec 10 Dec 12 Dec 14 - - - Mini-Assignment Lectures Lectures are held in Salomon DECI on Tuesdays and Thursdays from 2:30-3:50pm. Date Lecture PDF Printable PDF PPT Recordings Skit Code 09/07 Welcome to CS0150 + What is Programming? PDF Printable PDF PPT Recording Skit - 09/12 Calling and Defining Methods PDF Printable PDF PPT Recording - - 09/14 Introduction to Parameters and Math PDF Printable PDF PPT Recording - - 09/19 Working with Objects I PDF Printable PDF PPT Recording - - 09/21 Working with Objects II PDF Printable PDF PPT Recording - - 09/26 Interfaces and Polymorphism PDF Printable PDF PPT Recording - - 09/28 Inheritance and Polymorphism PDF Printable PDF PPT Recording - - 10/03 Math and Making Decisions PDF Printable PDF PPT Recording Skit - 10/05 Graphics I PDF Printable PDF PPT Recording - Code 10/10 Graphics II PDF Printable PDF PPT Recording - Code 10/12 Graphics III PDF Printable PDF PPT Recording - Code 10/17 Loops PDF Printable PDF \"PPT Recording - - 10/19 Arrays PDF Printable PDF PPT Recording - - 10/24 Design Principles and Patterns I PDF Printable PDF PPT Recording - Code 10/26 Design Principles and Patterns II PDF Printable PDF PPT Recording - - 10/31 Recursion PDF Printable PDF PPT Recording Skit - 11/02 Big O, Sorting and Searching PDF Printable PDF PPT Recording - - 11/07 Data Structures I (Linked Lists) PDF Printable PDF PPT Recording - - 11/09 Data Structures II (Stacks, Queues, and Trees) PDF Printable PDF PPT Recording - - 11/14 Data Structures III PDF Printable PDF PPT Recording - - 11/16 Final Project Intro PDF Printable PDF PPT Recording - - 11/28 History PDF Printable PDF PPT Recording - - 11/30 Computer Graphics PDF Printable PDF PPT Recording - - 12/05 HTA Lectures PDF Printable PDF PPT Recording - - Labs & Sections Lab/section is a time to review course content in a smaller group setting and practice applying those concepts through partnered labs. Each section will meet once a week and will be led by two TAs with around SOME NUMBER of students, so it is also a time to work closely with and get to know some of your fellow CS15-ers. A typical lab/section consists of short group check in, a fun SRC activity, and then either a presentation and some smaller group activities to review concepts or a lab. Date Lab/Section Handout Mini-Assignment Review Video SRC Slides 09/12 Lab 0: Linux & Terminal Handout Mini-Assignment - - Slides 09/19 Lab 1: Intro to Java Handout - - SRC Activity - 09/26 Section 2: Class Relationships - Mini-Assignment - SRC Activity Slides 10/03 Section 3: Polymorphism - Mini-Assignment - SRC Activity Slides 10/10 Lab 4: JavaFX Handout - Video - - 10/17 Lab 5: Debugging Handout Mini-Assignment - - - 10/24 Section 6: 1D Array, ArrayLists, and Loops Handout Mini-Assignment - SRC Activity Slides 10/31 Lab 7: 2D Arrays Handout Mini-Assignment Video SRC Activity Slides 11/07 Section 8: Algorithms - Mini-Assignment - - Slides 11/14 Lab 9: Data Structures and Recursion Handout - - SRC Activity Slides Code-Along CS15 Code-Alongs are your one stop shop for getting hands-on experience with guided coding exercises in order to better understand the concepts of OOP! We know that lectures can at times feel very abstract, and that we sometimes need examples in code in order to fully understand how these concepts work. Throughout the semester, we will host various code-alongs in order to assist you all with the skills necessary for succeeding in the course! Code-Along Related To Date #1 Date #2 Date #3 Video Stencil Java Syntax Code-along Rattytouille 09/13 at 7:00 PM MacMillan 117 09/15 at 7:00 PM MacMillan 117 09/17 at 7:00 PM MacMillan 117 Video Stencil Writing Classes Code-along Andybot, Pong, TicTacToe 09/19 at 8:00 PM Metcalf Research Auditorium 09/24 at 3:00 PM Metcalf Research Auditorium 09/27 at 9:00 PM Metcalf Research Auditorium Video Stencil Java FX & Design Code-along Cartoon 10/15 at 3:00 PM MacMillan 115 10/18 at 4:00 PM MacMillan 115 - Video Stencil GitHub and Debugging Code-along Doodle Jump 10/25 at 7:00 PM MacMillan 117 10/29 at 3:00 PM MacMillan 117 - Video Stencil Tetris Pieces Code-along Tetris 11/05 at 3:00 PM Friedman 202 11/08 at 7:00 PM Friedman 202 - Video Stencil Hours Have a Quick Question? Try out CS15's own virtual TA Chatbot, GPTA! Terms and Conditions | GPTA User Guide | Generative AI Usage Guide reminder that GPTA is experimental and is a supplement, not a replacement, for real TA help CONCEPTUAL TA HOURS Confused about an idea discussed in lecture or in a project handout? If we don't have to look at your code to answer your question, conceptual hours are a great place to meet other students and talk to a TA. Your question will get answered much faster here than at the debugging hours line. DEBUGGING HOURS Debugging Hours are a great resource to discuss 1-on-1 with a TA about your code and learn how to solve your bugs; however, please be sure to check our TA Hours policy and the Ed page before getting in line at the hours website . When waiting for hours, wait near CIT 210 and a TA will come to get you! Resources Quick Links Syllabus Ed Course Calendar Course Missive Gradescope Feedback Form Hours Emails TA Email cs0150tas@lists.brown.edu (general questions for all TAs) HTA Email cs0150headtas@lists.brown.edu (HTA-Specific Questions/Concerns) Individual TA Emails &ltcslogin&gt@cs.brown.edu (cslogins found under Staff) General Resources Required Readings Course Syllabus Course Missive Collaboration Policy TA Hours Policy Retake Policy GPTA User Guide Generative AI Usage Guide Online Help IntelliJ + Git Set-up Guide Mac IntelliJ Set-up Video Windows IntelliJ Set-up Video Github Guide Github Video Master the Terminal Guide Understanding CS0150 Support Code Java Documentation Javadocs: All built-in Java classes JavaFX-docs: All built-in JavaFx classes JavaFX Guide JavaFX Images Documentation Java Language Specification Guides & Tutorials README Guide Style Guide Variables & Constructors Runtime Errors Containment & Inheritance Diagrams Guide CS15 Vocabulary Sheet Partner Projects Logistics Guide Department Docs Undergraduate Missive Ergonomics IT Services Email Organizations Student Support Services CAPS Title IX Women in Computer Science Mosaic+ Health & Wellness Advocates Diversity & Inclusion Advocates Computer Science DUG SRC What is SRC? As awareness of technology's consequences increases, attention turns to how computer scientists are trained. In response, the CS department created the \"Socially Responsible Computing\" initiative in 2019 to integrate ethics and social impact topics broadly across its curriculum. At Brown, SRC is embedded into most major CS courses. Our goals in CS15 are to give a broad overview of today's technological landscape so that you are familiar with these concepts when you are eventually faced with ethical design decisions further down your CS journey. How does this fit into the CS15 curriculum? Mini-lectures Lab activities about lecture content Two extra credit discussion sections with details TBA How can I get involved? Groups @ Brown: SRC Reading group: ARG@Brown AIRES (AI Robotic Ethics Society@Brown) Human Centered Robotics Initiative Design for America @ Brown Alum-foudned groups & others: Better World by Design Impact Labs Coding it Forward TechCongress Classes @ Brown: CSCI1870: Cybersecurity Ethics CSCI1951I: CS for Social Change DATA0080: Data, Ethics and Privacy MCM0230: Digital Media PHIL401: Ethics of Digital Technology STS 1700T: Race, Gender, and Technology in Everyday Life Classes under the 'Science, Technology, and Society' (STS) department ...and more! Topics in Socially Responsible Computing Artificial Intelligence Lecture 1 Lectures 2-4 Lecture 5 Blockchain and Crypto Lecture 1 Lecture 2 Cybersecurity Lecture 1 Data Privacy Lecture 1 Lecture 2 Ethics in Big Tech Lecture 1 Lecture 2 Misinformation & Freedom of Expression Lecture 1 Labor Practices Lecture 1 Philosophy Lecture 1 Software Design Lecture 1 Lecture 2 AI Overview \u00d7 GPT-3 Creative Fiction Interactive: Stable Diffusion (free text-to-image generator) How DALL-E could power a creative revolution One Hundred Year Study on Artificial Intelligence (AI100) LLMs and Neural Nets \u00d7 Exclusive: OpenAI Used Kenyan Workers on Less Than $2 Per Hour to Make ChatGPT Less Toxic A Very Gentle Introduction to Large Language Models Without the Hype Lawyer Used Chat-GPT in Court and Cited Fake Cases AI for radiographic COVID-19 detection selects shortcuts over signal AI Bias and Ethics \u00d7 Who Is Making Sure the A.I. Machines Aren't Racist? A.I. Brings the Robot Wingman to Aerial Combat Automation isn't the biggest threat to US factory jobs Robots were supposed to take our jobs. Instead they're making it worse Economic possibilities for our grandchildren Privacy Violations and Regulation \u00d7 The New Rules of Data Privacy Data Protection and Privacy Laws China Social Credit System Explained CCTV Surveillance for Crime Prevention FTC Finalizes Order with Flo Health Examining the intersection of data privacy and civil rights Ring, Google and the Police: What to Know About Emergency Requests for Video Footage H.R.8152 - American Data Privacy and Protection Act Section 230 Surveillance Capitalism \u00d7 High tech is watching you What Is Surveillance Capitalism Cambridge Analytica and Facebook: The Scandal and the Fallout So Far \"You Are the Product\": Targeted by Cambridge Analytica on Facebook Corporate Surveillance in Everyday Life Antitrust \u00d7 Support for tech regulation has declined The Antitrust Laws House passes antitrust bill Regulating Big Tech \u00d7 To Regulate Network-Based Platforms, Look at Their Data Why 'Breaking Up' Big Tech Probably Won't Work Who Will Teach Silicon Valley to Be Ethical? Responsible AI tools and Practices Ethics Alone Can't Fix Big Tech Can Big Tech be Disrupted Big Tech Needs to Be Regulated. Here Are 4 Ways to Curb Disinformation and Protect Our Privacy The value and challenges of regulating big tech F.T.C.'s Court Loss Raises Fresh Questions About Its Chair's Strategy Blockchain Overview \u00d7 Blockchain Facts: What Is It, How It Works, and How It Can Be Used The Collapse of FTX: What Went Wrong With the Crypto Exchange? Blockchain Energy and Sustainability \u00d7 Cryptocurrency's energy consumption problem What is 'proof of work' or 'proof of stake'? Ethereum's Energy Revamp Is No Guarantee of Global Climate Gains Cybersecurity \u00d7 The Untold Story of Solarwinds Equifax Data Breach Settlement Chinese Malware Hits Systems on Guam. Is Taiwan the Real Target? Hunting Russian Intelligence 'Snake' Malware What You Need to Know About Autonomous Weapons Executive Order on Improving the Nation's Cybersecurity A.I Brings the Robot Wingman to Aerial Combat Philosophy \u00d7 Microsoft Says New A.I Shows Signs of Human Intelligence Philo-GPT's Surprisingly Wise Answer to What is the Meaning of Life A.I Thinking vs. Human Thinking How Close Are We to A.I That Surpasses Human Intelligence Dark & Addictive Design \u00d7 Deceptive Design How Facebook and other sites manipulate your privacy choices How financial apps get you to spend more and question less A survey of addictive software design Dopamine, smartphones and you Good User Design Practice \u00d7 Coming Soon! Misinformation & Freedom of Expression \u00d7 Coming Soon! Labor Practices \u00d7 Coming Soon! Staff Professor & Head Teaching Assistants Andy (avd) he/him I'm originally from the Netherlands. My CS specialty is Computer Graphics, especially pen- and touch-computing. I'm a foodie and love the outdoors: hiking and backpacking (especially in the Grand Canyon), mountain- and road-biking, and kayaking. THE CAPITOL Allie (amasthay) she/her Hi guys! I am a junior from Connecticut studying Computer Science, and I am super excited for this semester! When I am not in the CIT, I love going to Bajas, drinking Diet Coke, singing karaoke, or trying to catch the Sci Li rats. Feel free to reach out to me anytime about anything CS15, CS at Brown, or general questions on life. Can't wait to meet you! DISTRICT 10 - LIVESTOCK Anastasio (aortiz18) he/him Hey! My name is Anastasio, I am a Junior from Nicaragua studying APMA-CS. I like ice cream and long walks by the beach. DISTRICT 2 - MASONRY Cannon (ccaspar) he/him I am Cannon, Junior, CS and Classics Major, from Concord MA. Super excited to HTA CS15! I often do things that make me happy, which includes: adventure, fun, hope, power, meditation, and sometimes even CS. Reach out if you ever wanna talk about anything :) DISTRICT 7 - LUMBER Lexi (ehenrion) she/her Hi everyone! I switched to CS after taking CS15 as a student, and I'm now a senior studying Visual Computing. I couldn't be happier, and I'm so excited to share this AWESOME class with all of you! I'm also an artist and writer when I'm not coding, wandering around Providence, or eating waffles and reading manga at Zinneken's :) DISTRICT 6 - TRANSPORTATION Sarah (sonderdo) she/her Hi! I am a junior from New Jersey studying computer science and history. In my free time you can find me hanging out with my friends, pretending to read books, dreaming about pasta, and watching the same movies over and over again. In my not-free time you can find me in the CIT. I am so excited to meet you all, feel free to reach out and say hi! DISTRICT 11 - AGRICULTURE Joint Socially Responsible Computing/Undergraduate Teaching Assistants Adam (amroueh) he/him Hi! I am a senior from Rochester, NY studying CS-Econ. I enjoy food, reading and trying new coffee shops. I can't wait for CS15 and to meet everyone! DISTRICT 8 - TEXTILES Faizah (ffnaqvi) she/her Hi everyone! I'm a sophomore from NJ studying CS and IAPA. In my free time I like reading, baking (and then eating what I bake), and dousing my food with Tabasco sauce. Looking forward to meeting you all and having a great semester! DISTRICT 13 - NUCLEAR Katie (kli154) she/her Hi! I'm a sophomore from the Seattle area studying computer science and philosophy. I like reading, hiking, tap dancing, losing at chess, and eating Andrews yogurt bowls. DISTRICT 7 - LUMBER Undergraduate Teaching Assistants Alyssa (asun59) she/her Hi! I am a sophomore from Oregon studying CS-Econ. When I am not rotting in the CIT, I'm fencing, watching Dance Moms, or getting food with friends. Welcome to CS15, super excited to have an awesome semester with you guys! DISTRICT 5 - POWER Annabel (aroth7) she/her Hi! I'm a senior studying APMA-Econ and CS. I was born in Boston, MA, then lived in Shanghai, China for 5 years before moving to Connecticut. When I'm not working on psets in one of the CIT conference rooms, you can find me running, baking, or doing the NYT crossword or some variation of wordle. So excited for an awesome semester with everyone! DISTRICT 9 - GRAIN Ashton (agglover) he/him Hi everyone! I'm a sophomore from Lake Wylie, South Carolina studying computer science. I like the outdoors, traveling, and watching sports (especially soccer). Looking forward to meeting everyone! DISTRICT 3 - TECHNOLOGY Asia (atnguyen) she/her I'm a sophomore from Nashville, Tennessee! I'm planning on concentrating in CS and IAPA. I'm a huge swiftie, and I love to read and hang out with my friends in my free time! I'm so excited to meet you all! DISTRICT 1 - LUXURY Astrid (armoreno) she/her Hi! I'm a sophomore concentrating in Computer Science. I'm from Detroit, Michigan and I enjoy things like reading, crocheting, sewing, and cooking. So excited to guide everyone through the semester! DISTRICT 6 - TRANSPORTATION Ayman (abenjell) he/him Hi everyone! I'm Ayman, a junior from Casablanca, Morocco studying Computer Science here at Brown! When I'm not in the CIT, I like walking around campus while drinking boba, playing retro and current Nintendo games, and practicing piano! (started learning a year ago!). I also love drinking anything with caffeine in it, so any tea/coffee shop recommendations are welcome. I'm super excited for this semester, can't wait to meet y'all! DISTRICT 12 - MINING Ben (baizenbe) he/him I am a sophomore from Highland Park, Illinois, probably studying either CS or APMA. Outside of school, I play tennis, do crosswords, and watch movies -- most recently Puss in Boots: The Last Wish, one of the best movies ever made. I can't wait to be your TA! DISTRICT 12 - MINING Brandon (bdiaz2) he/him Hi! I'm a senior from Atlanta, GA studying CS and IAPA. I love spontaneous beach trips and listening to music. Can't wait to meet everyone! :) DISTRICT 10 - LIVESTOCK Chloe (cnevas) she/her Hi! I'm a sophomore from Westport, CT and I'm studying APMA-CS. In my free time I love to bake and cook, play the violin, and listen to music. I'm SO excited to be a TA for CS15 and I'm looking forward to a great semester! DISTRICT 8 - TEXTILES Channing (cpbryant) he/him Hey everyone! My name is Channing, and I'm from Massachusetts. I'm a sophomore studying Computer Science-Economics. I like listening to music, playing sports, eating, and watching movies. I'm excited to work with all of you, and feel free to reach out. DISTRICT 3 - TECHNOLOGY Caden (cschroe4) he/him Hi! I'm a sophomore from New Hampshire studying Applied Math and Computer Science. I love going to the beach, playing Spikeball, and climbing trees. Plus, I'm a big Ratty and Jo's fan so you can usually find me there. I'm super excited to meet all of you! DISTRICT 6 - TRANSPORTATION Cameron (csikich) she/her Hi everyone! I'm a junior from Toronto, Ontario concentrating in APMA-CS. I'm also on the Women's Ice Hockey team and I love to bake. Feel free to talk to me about sports, food or anything else. I look forward to meeting you all! DISTRICT 4 - FISHING Cindy (czheng27) she/her Hi, I'm a senior from Louisiana studying APMA-Biology. I love reading, gardening, and walking aimlessly. Looking forward to meeting everyone! DISTRICT 6 - TRANSPORTATION Dan (dliu58) he/him Hello there! I'm a junior concentrating in CS from Lockport, NY. My hobbies are sleeping in late, try-harding at Mario Kart and Smash, reading manga/web serials, and spending money at the CIT vending machines. DISTRICT 12 - MINING Daniel Z.(dzhu36) he/him Hey everyone! I'm a sophomore from San Ramon, California studying neuroscience and computer science. In my free time, I enjoy hiking, reading manga/books, playing games, cooking, and voice calling friends on discord. So excited to meet you all in CS15! DISTRICT 3 - TECHNOLOGY Dawood (dolaniyi) he/him Hey everybody, I'm Dawood! I'm a CS student from America's most beloved state, Iowa (real place, I swear). If I'm not coding video games in my dorm I'm probably saving my semester in the Sci-Li basement. If you ever see me hopping around campus, try to stop me for a conversation! I'd love to chat! Thank yall for contributing to my sophmore-year excitement by taking CS15, I'm beyond excited to work and learn with you all! DISTRICT 11 - AGRICULTURE Emily H. (ehinds3) she/her I'm a senior from Seattle, WA concentrating in Computer Science and French and I am so excited to meet all of the students this year! :) DISTRICT 7 - LUMBER Emily O. (eiolson) she/her Hi everyone! I'm a sophomore planning on studying a combination of computer science and physics. I'm from the Bay Area, California, but I am so happy to call Providence a home now too. I'm even more happy to get to work with you all, and I can't wait for a great semester in CS15 :) DISTRICT 11 - AGRICULTURE Emily W. (emwang) she/her Hi! I'm a sophomore from the Chicago suburbs, studying CS. I spend most of my time crocheting, watching anime, playing violin, and making silly drawings. Super excited to be your TA this semester!! :D DISTRICT 9 - GRAIN Ethan (eohayon1) he/him Hi! I am a Junior from Maryland studying CS-Econ. In my free time I enjoy playing sports, hanging at the beach, and walking my dog. I'm looking forward to working with everyone this fall! DISTRICT 6 - TRANSPORTATION Francesca (felia) she/her Hi!! I'm a sophomore double concentrating in APMA-Econ and CS. I love thrifting, iced caramel lattes, watching trashy reality TV, and beach days (which is unfortunate considering I'm from Minnesota). I'm so incredibly excited to TA this year and cannot wait to meet you all, so feel free to reach out for anything! :) DISTRICT 1 - LUXURY Gaby (cgchoi) she/her hi! i'm a sophomore from irvine, california studying cs-econ and international business! in my free time i love making coffee, drinking coffee, and spending way too much on coffee (ceremony). i'm also always at trader joes. so excited to meet everyone!! DISTRICT 10 - LIVESTOCK Gavin (gdhanda) he/him Hi! I'm a sophomore majoring in CS and Econ from Denver, Colorado. I play the guitar and piano in my free time and take lots of naps, and I'm so excited to TA CS15 this fall!!! DISTRICT 3 - TECHNOLOGY Grace (gcma) she/her Hi, and welcome to CS15!!! I'm Grace and I'm a sophomore from Montgomery County, Maryland studying music (and maybe cs??? idk). I enjoy playing random instruments, eating Chinese food, and watching animated kids shows. Super excited to meet you all! :) DISTRICT 11 - AGRICULTURE Grace (gmarshbu) she/her Hi! I'm a junior from Houston studying CS and visual arts, both for animation. I'm also interested in Russian language, musical performance, and fiction writing. When I can, I love to travel, watch animated movies, and listen to all sorts of music. I'm also very fond of Blue Room, so I'll go there as often as my flex points allow. DISTRICT 3 - TECHNOLOGY Grant (glandon) he/him Hello everyone! I'm a Junior from the North Shore of Massachusetts studying Applied Math and Computer Science. In my free time, I enjoy playing Spikeball on the main green, climbing anything and everything that looks climbable (including but not limited to rocks, walls, and trees), and playing tabletop games like Dungeons and Dragons. I can't wait to meet you all! DISTRICT 13 - NUCLEAR Julie (hchung33) she/her Hi everyone :) I'm Julie from West Hartford, CT. In my free time, I love to write music, go for nature walks, play Nintendo Switch, and attempt to skateboard. You can probably spot me in Steinert center practice rooms. I'm so excited to meet everyone, welcome to CS15!! DISTRICT 6 - TRANSPORTATION Ilan (ibrauns) he/him Hi everyone, I'm Ilan! I am a sophomore from South Orange, New Jersey studying Applied Math - Computer Science and Mathematics. In my free time I like to play sports, work out, and hang with friends. I love my dog Ruby and you can find me constantly tracking my fantasy football team. I'm so excited for the semester and feel free to reach out about CS15 or anything else! DISTRICT 7 - LUMBER Imran (ihussai3) he/him Hey! I'm a sophomore from Cambridge, MA, studying neuroscience and computer science. I love climbing, pottery, and I am a barista here at the underground cafe! So excited to meet all of you ^_^ DISTRICT 7 - LUMBER Isabelle (iashapir) she/her Hi! I'm Isabelle, and I'm a sophomore from Los Angeles studying CS. In my free time, I love cooking, baking, and trying new food. I've enjoyed eating pretty much every food I've tried except for cashews. I also love anything outdoors: hiking, rock climbing, kayaking, swimming, etc. I am so excited to be a CS15 TA this semester! DISTRICT 9 - GRAIN Jackson (jwschwar) he/him I am a sophomore from southern Connecticut. I am thinking about concentrating in Computer Science and possibly Political Science. I love sports and am involved in club Frisbee on campus. I also love the outdoors and spend most of my summers in the Adirondacks in upstate New York. I am super excited to experience CS15 again and to meet you all throughout the semester! DISTRICT 7 - LUMBER Jaclyn (jcohen45) any pronouns Hi all!! I'm a sophomore CS and Visa concentrator from South Florida. I love anything art and design, spooky full moon ceremonies, spending time in nature, ressurecting Blueno, and chasing birbs :) I'm excited to meet all of you! DISTRICT 10 - LIVESTOCK Jinho (jlee812) he/him Hey! I'm a sophomore from Cambridge, Mass studying CS and literary arts! When I'm not on tiktok, I'm in lecture watching tiktok. I love Taylor Swift, Succession, and am looking forward to meeting you all :) DISTRICT 11 - AGRICULTURE Jennifer (jzliao) she/her Hi, I'm Jennifer! I'm a sophomore from Farmington, CT planning to concentrate in CS and History. I like reading, playing piano and guitar, and rotting in bed. so excited for CS15!!!!! DISTRICT 1 - LUXURY Juan (jgarci71) he/him Hey everyone! My name is Juan, and I'm a junior from Compton, CA studying CS and Education. Outside of school, I tend to spend time playing random mobile games or watching a Gordon Ramsay show. I'm so excited to meet you all this semester :) DISTRICT 6 - TRANSPORTATION Kamryn (kwalke19) she/her Hi! I'm a sophomore from Maryland studying CS. When I'm not camping at the CIT, I'm dancing (go Fusion Dance Company!), reading, thrifting, or exploring cities. You can also find me in the Mosaic+ room pretty often. I'm so excited for this semester and I can't wait to meet you all :) DISTRICT 12 - MINING Kanayo (kduru1) he/him Hi! I'm a junior from Maryland. I like outdoor activities, cooking, and listening to music. If I'm not sleeping, you can usually find me sitting on the green enjoying the sun, unless it's winter in which case I'll disappear. I love exploring new places and food, so you might also just catch me wandering around! I'm so excited to meet all of you. Welcome to CS15 :) DISTRICT 1 - LUXURY Karim (kmouline) he/him Hi there! My name is Karim, and I am a junior studying Math-CS and English. While I'm not in the CIT working on projects or essays, you can find me in the pool with the club swim team, on the bike path with the running club, or spending an abnormal amount of flex points on Blue Room bagels and coffee. Let me know if you have questions about anything, whether it be Brown related or life in general! DISTRICT 4 - FISHING Keanu (kthuynh) he/him Hi! I'm a sophomore from LA concentrating in Computer Science and Applied Math if everything goes my way. Outside of CS15, I enjoy video games, comics, photography, and blowing all my Bear Bucks on Blue Room muffins. If it's something to brag about, I own the griddy emote in Fortnite. If it's not, I don't own the griddy emote in Fortnite. Excited to see you all this year! DISTRICT 9 - GRAIN Khalil (kodesai) he/him Hello!!!! My name is Khalil and I am a sophomore from San Diego, California planning to study Computational Biology. I love all things science and have some wet-lab experience if that is something any of y'all want to ask me about! Outside of academics, I love playing the flute, baking pies, and being generally a bit of a mess. I also listen to a ton of music (Big Thief, Radiohead, Angel Olsen, Sufjan Stevens, etc.), so come talk to me about that :) DISTRICT 11 - AGRICULTURE Logan (ldhines) he/they hey! i'm a sophomore from portland, oregon studying CS (and maybe linguistics). outside of school i'm really into thrifting, hiking, and listening to music while worrying about my spotify wrapped (please feel free to recommend anything!) :) i also love trying out random baking recipes and failing miserably. i'm super super excited to meet all of you this semester!! DISTRICT 6 - TRANSPORTATION Lana (lyangmac) she/her Hi everyone! I'm a sophomore from Ann Arbor, Michigan and I'm planning on concentrating in computer engineering. In my free time, I love to read, eat anything mango flavored, and spend time outside (especially hiking or swimming). Can't wait to meet you all! :)) DISTRICT 7 - LUMBER Morgane (mpizigo) she/her Hi! I'm a sophomore from France concentrating in Computer Science and Psychology. CS15 is the class that convinced me to pursue CS, so I hope y'all have a blast! Outside of classes, I love crocheting, cooking (badly), playing fishing mini games, and pursuing my love for hiking and martial arts. Debugging and testing are my favorite parts of CS, so don't feel bad if you bring a bug to me! DISTRICT 4 - FISHING Marissa (mshaffe3) she/they Hiya! I'm a sophomore from Philadelphia, PA, studying CS and either Science, Technology, and Society or Gender and Sexuality Studies. On campus, you can find me performing circus shows with Brown Aerial Acrobatics and a cappella music with the Higher Keys. I love contemporary & fantasy fiction, racing my mom on the NYT crossword, and sipping boba on the main green. DISTRICT 6 - TRANSPORTATION Megan (mtanuwid) she/her Hi everyone! I'm a sophomore from Jakarta, Indonesia studying Computational Biology. I love solving crosswords, eating English muffins, and binge-watching Law & Order: SVU. Can't wait to meet everyone! DISTRICT 3 - TECHNOLOGY Natalie (nking12) she/her I'm a sophomore from Houston, Texas. I'm planning on concentrating in CS and Econ and I'm so excited to TA the best class ever this year!! DISTRICT 3 - TECHNOLOGY Owen (oanders6) he/him I'm a junior studying Computer Science and Philosophy from Portland, Maine. When I'm not coding, I like watching sports, the beach, and bagels. Looking forward to the semester with you all! DISTRICT 13 - NUCLEAR Orlando (ocedeno) he/him Hey my name is Orlando! I'm currently a Senior studying computer science and I'm originally from the Bronx, NY. Currently, I'm binge watching One Piece, catching sunsets, going to the gym, or just chilling. DISTRICT 10 - LIVESTOCK Robyn (rjecroi1) Hi! I'm a sophomore. I am 87.2% likely to double concentrate in IAPA and CS. I am an avid sunset picture taker, Music lover (Spotify > Apple Music), and an unhealthily committed binger of shows (yes I've watched up to 16 seasons of Grey's Anatomy and will finish 20 seasons of One Piece). I am also excited to be your TA this semester. DISTRICT 4 - FISHING Sarah (sberhan4) she/her Hi everyone! I'm Sarah, and I am a sophomore from Cambridge, MA. I am undecided in my concentration, but I am thinking about Education and CS. In my free time, I enjoy doing the wordle, playing connections, and reading! I am super excited to get to know you all! Feel free to ask me any questions! DISTRICT 6 - TRANSPORTATION Sarah (snrichma) she/her Hi! I'm a sophomore from Danville, New Hampshire studying APMA-CS and physics. Outside of computer science, I love dancing and eating mint chocolate chip ice cream. I'm super excited to be a C15 TA this semester! DISTRICT 8 - TEXTILES Seehanah (stang52) she/her hiii i'm a junior from central jersey studying apma- cs. i'm from central jersey and enjoy eating, hiking, and traveling. really excited for a great semester with everyone! DISTRICT 9 - GRAIN Sherry (szhan235) she/her Hey! I'm a junior from Bellevue, WA studying CS with a focus on animation. I love drawing a lot and also enjoy powerlifting, swimming, and being in nature. Please do not mention anything anime/animation-related in front of me because I will literally not be able to stop talking about it. Can't wait for you to take CS15!! &lt3 DISTRICT 4 - FISHING Sophia (szlim) she/her Hi everyone! My name is Sophia and I'm a sophomore from Auckland, New Zealand. I intend on concentrating in Computer Science (and maybe Cognitive Science) but I enjoy exploring different classes in Brown's Open Curriculum. I love traveling, baking, and wasting my time watching tv shows and movies. Can't wait to get to know you all this semester :) DISTRICT 1 - LUXURY Will (wvandewa) he/him Junior from Cleveland, Ohio studying APMA-CS. Crochet enjoyer and casual runner. It's gonna be a crazy year. DISTRICT 7 - LUMBER Xiaoyue (xhou8) she/her I'm a junior concentrating in CS and Econ, and I'm from Beijing, China. I love traveling, hiking, learning languages, and watching & stage managing musicals. Really excited to meet you all! DISTRICT 3 - TECHNOLOGY", "https://cs.brown.edu/login/?next=/account/": "Sign In Brown CS users , please use your Brown Account to sign in. Brown Login Friends and alumni , non-Brown logins are disabled for now.", "https://cs.brown.edu/courses/cs016/static/files/docs/nds4/index.html": "JavaScript is disabled on your browser. Frame Alert This document is designed to be viewed using the frames feature. If you see this message, you are using a non-frame-capable web client. Link to Non-frame version .", "https://cs.brown.edu/courses/cs019/2016/professionalism.html": "\u25bc Fall 2016: Accelerated Introduction to Computer Science 1 Anticipated Frequent Questions 2 README 3 Learning Goals, Assessments, and Time Allocation 4 Syllabus and Course Policies 5 Diversity and Professionalism 6 Assignments 7 Textbook 8 Software 9 Staff and Contact 10 Peer Review 11 How to Ask Questions (and Report Bugs) 12 Pyret Style Guide 13 Credits \u25ba 5 Diversity and Professionalism 5.1 Be An Adult 5.2 About Course Staff 5.3 Disclosure On this page: 5.1 Be An Adult 5.2 About Course Staff 5.3 Disclosure \u2190 prev up next \u2192 5 Diversity and Professionalism 5.1 Be An Adult 5.2 About Course Staff 5.3 Disclosure The lack of sufficient diversity is an important problem in computerscience. In this course, we want to help improve the situation, notmake it worse. Some of the responsibility for that lies with us, thecourse staff, but a lot of it ultimately rests with you, the students. 5.1 Be An Adult College is a great time, and for many of you might offer a sense ofnew-found liberation. (I sure remember how liberating college felt forme!) It\u2019s a space for exploration and experimentation of various kinds(legal, no doubt). However, it also provides opportunities to crossvarious lines, and unfortunately some people do so in awful ways. Every now and then I hear disturbing statements from students abouthow they have been made to feel uncomfortable in class or in thedepartment. I don\u2019t mean intellectual discomfort\u2014 e.g., the kind youmight get from having a heated debate about a technical subject with afellow student\u2014 but the personal kind. These range from inappropriatecomments to invitations to even touching and other physicalcontact. The subjects are almost overwhelmingly (but not exclusively)female students or from races underrepresented in computer science. There\u2019s a term for some of the behaviors I hear about. It\u2019s called harassment . And let there be absolutely no doubt about this:harassment is against the law and it is completely against thenorms by which we want to run this course and thisdepartment. (See Brown\u2019s Title IX Web site .)We\u2014 the university, the department, and this course\u2019sstaff\u2014 have absolutely zero tolerance for it. Your reaction might be to laugh it off, or to make (or think) snideremarks about political correctness or jokes about consent or whathave you. You might think people just need to grow a thicker skin orlearn to take a joke. However, the subject of your harassment (and that\u2019s what your remarksand actions are, harassment , even if you decide you wouldclassify them as jokes) is forced, by the nature of classes and campuslife, to be around you. That can make them uncomfortable to the pointof wanting to stay away, or focusing more on you than on what they arehere to learn. That hurts their education. That is not okay at all:you have no right to steal their hard-won education away fromthem. And often the harm goes much deeper: it hurts thempsychologically in subtle and long-standing ways. And that\u2019s why theseare not laughing matters. In light of recent reports about such issues on campus, Brown istaking additional steps to reduce this form of harm. Therefore, if Icannot appeal to your decency, intelligence, and collegiality, let meat least appeal to your self-interest. Do not mess around on thismatter. It will not go well for you. However, I prefer that you think of this in positive terms. Yourclassmates are your colleagues. Someday you may be each others\u2019start-up partners or co-employees; one of you may even be the other\u2019sinterviewer or boss. So start treating one another like professionals,and I mean that in the best possible interpretation of that phrase. In short: Be safe, be happy, and have fun without taking away anyoneelse\u2019s. 5.2 About Course Staff Professionalism and respect for diversity are not just matters betweenstudents; they also apply to how the course staff treat the students.The staff of this course pledge to treat you in a way that respectsour differences. However, despite our best efforts, we might slip up,hopefully inadvertently. When we do, please feel free to talk to usabout it. Sometimes, you may not be comfortable bringing this up directly tous. If so, you are welcome to talk to Laura Dobler or to the department chair . As a department, we will take all complaints about unprofessional ordiscriminatory behavior seriously. 5.3 Disclosure In principle, I would like to say that you are always open to cometalk to me if you are facing any such issues. Unfortunately, I have towarn you that on account of being the director of our PhD program, I\u2019mwhat Title IX law calls a Responsible Employee . That means, ifyou report an incident to me, I am required to report it to theTitle IX coordinator at Brown. This will likely launch aninvestigation. Usually, an investigation is a good idea. However, I realize this mayput you in an uncomfortable position, and that\u2019s certainly not what Iwant. Therefore, I need to tell you that if you want to do thingsconfidentially, you should talk to one of the many resources listed here . If you would like to learn more about Brown\u2019s policies and resources,please see the university\u2019s Title IX site . \u2190 prev up next \u2192", "https://cs.brown.edu/courses/cs125/index.html": "CS125 Menu Home FAQs Course Missive Syllabus Lectures Assignments Resources Gallery CS125 Intro to 3D Computer Animation Brown University Learn More Welcome to CSCI 1250 In this course you will be introduced to the process of making a short computer animated film from beginning to end. It's super fun and usually a lot of work. To learn more about the course, click on Course Missive . Also check out the CS125 FAQs . First Class Meeting CSCI 1250 will not be offered Fall 2023. I will be teaching my advanced course CS1950T instead. The course is capped at 20 students and requires an application which is open here . You must also attend the first class in order to have your application considered. Make sure to put this course in your shopping cart to get email updates about the course. Selection criteria include class seniority, previous related experience, and enthusiasm. We aim to create a diverse class so there is no one thing that assures acceptance. Prerequisites There are no fixed prerequisites for the class, but we like to see demonstrated in-depth background in computer science, computer graphics, a related area like filmmaking, or in some aspect of visual art. Your background does not have to be from a formal course, but you will have to explain or demonstrate it. If you have an online portfolio or website, you can provide a link in your application. This is not necessary, but can give us a better picture of you. In the mean time, you can read about the course in the missive and syllabus. HTML5 UP", "https://cs.brown.edu/courses/": "Computer Science Courses The following is a comprehensive list of Computer Science course offerings. Or view CS courses at Courses@Brown . Semester charts are available for Fall '23 (119.3 KB) and Spring '24 (228.1 KB) . The undergraduate TA program is a great way for students to get to know their professors, sharpen their knowledge of a subject, and get paid! See the UTA-designed slides promoting next semester's courses . What CS Course Should I Take? .active-course-row { display: inherit; opacity: 1; transition: display 1s, opacity 3s linear; } .inactive-course-row { display: none; opacity: 0; transition: display 1s, opacity 3s linear; } .hide-row { display: none; } .main.current { font-weight: 600; } .pulldown { padding: .5em; margin: .5em .5em 1em 0; } .details { font-weight: normal; font-size: .9em; } .details > span { padding: 0 .5em; } Showing all 2024-2025 courses Showing summer 2024-2025 courses Showing fall 2024-2025 courses Showing spring 2024-2025 courses Showing all current and past courses Hiding course details Showing course details CSCI0020 The Digital World Fall \u2022 2024 \u2022 H-Tue Thu 0900am-1020am \u2022 TBD \u2022 Donald L Stanford CSCI0030 Introduction to Computation for the Humanities and Social Sciences CSCI0040 Introduction to Scientific Computing and Problem Solving CSCI0050 A Data-Centric Introduction to Programming CSCI0060 Practical Systems Skills CSCI0080 A First Byte of Computer Science CSCI0081 TA Apprenticeship: Full Credit Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Thomas W Doeppner Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Thomas W Doeppner CSCI0082 TA Apprenticeship: Half Credit Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Thomas W Doeppner Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Thomas W Doeppner CSCI0100 Data Fluency for All CSCI0111 Computing Foundations: Data Fall \u2022 2024 \u2022 C-Mon Wed Fri 1000am-1050am \u2022 Metcalf Research Building AUD \u2022 Milda Zizyte Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Milda Zizyte CSCI0112 Computing Foundations: Program Organization Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Tim Nelson CSCI0130 User Interfaces and User Experience CSCI0150 Introduction to Object-Oriented Programming and Computer Science Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Andries van Dam CSCI0160 Introduction to Algorithms and Data Structures CSCI0170 CS: An Integrated Introduction Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 John F Hughes CSCI0180 CS: An Integrated Introduction CSCI0190 Accelerated Introduction to Computer Science Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Shriram Krishnamurthi CSCI0200 Program Design with Data Structures and Algorithms Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Nicholas A DeMarinis Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Kathi Fisler CSCI0220 Introduction to Discrete Structures and Probability Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Robert Y. Lewis CSCI0300 Fundamentals of Computer Systems Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Nicholas A DeMarinis , Malte Schwarzkopf CSCI0310 Introduction to Computer Systems CSCI0320 Introduction to Software Engineering Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Tim Nelson Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Tim Nelson CSCI0330 Introduction to Computer Systems Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Thomas W Doeppner CSCI0360 Introduction to Systems Programming CSCI0450 Introduction to Probability and Computing CSCI0500 Data Structures, Algorithms, and Intractability: An Introduction Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Philip Klein CSCI0510 Models of Computation CSCI0530 Coding the Matrix: an Introduction to Linear Algebra for Computer Science CSCI0920 Educational Software Seminar CSCI0931 Introduction to Computation for the Humanities and Social Sciences CSCI1010 Theory of Computation Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Lorenzo De Stefani CSCI1040 The Basics of Cryptographic Systems Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Anna A Lysyanskaya CSCI1230 Computer Graphics Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Daniel C Ritchie CSCI1234 Computer Graphics Lab Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Daniel C Ritchie CSCI1250 Introduction to Computer Animation Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Barbara J. Meier CSCI1260 Compilers and Program Analysis Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Robert Y. Lewis CSCI1270 Database Management Systems Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Ugur Cetintemel CSCI1280 Intermediate 3D Computer Animation CSCI1290 Computational Photography Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 James H Tompkin CSCI1300 User Interfaces and User Experience Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 TBD CSCI1301 Livestreaming Reimagined CSCI1310 Fundamentals of Computer Systems Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Nicholas A DeMarinis , Malte Schwarzkopf CSCI1320 Creating Modern & Mobile Web Applications CSCI1330 Computer Systems (Master's students only) Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Thomas W Doeppner CSCI1340 Introduction to Software Engineering Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Tim Nelson Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Tim Nelson CSCI1360 Human Factors in Cybersecurity Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Ernesto Zaldivar CSCI1370 Virtual Reality Design for Science CSCI1380 Distributed Computer Systems Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Nikos Vasilakis CSCI1410 Artificial Intelligence Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 TBD CSCI1420 Machine Learning Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Stephen Bach CSCI1430 Computer Vision Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Srinath Sridhar Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Srinath Sridhar CSCI1440 Algorithmic Game Theory Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Amy R Greenwald CSCI1450 Advanced Introduction to Probability for Computing and Data Science CSCI1460 Computational Linguistics Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Ellie Pavlick CSCI1470 Deep Learning Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Ritambhara Singh CSCI1480 Building Intelligent Robots CSCI1490 Introduction to Combinatorial Optimization CSCI1510 Introduction to Cryptography and Computer Security Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Peihan Miao CSCI1515 Applied Cryptography Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Peihan Miao CSCI1550 Probabilistic Methods in Computer Science Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Eli Upfal CSCI1570 Design and Analysis of Algorithms Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Lorenzo De Stefani CSCI1575 Algorithms: In Depth CSCI1580 Information Retrieval and Web Search CSCI1590 Introduction to Computational Complexity CSCI1600 Real-time and Embedded Software Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Milda Zizyte CSCI1610 Building High-Performance Servers CSCI1620 Computer Systems Security Lab Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Nicholas A DeMarinis CSCI1650 Software Security and Exploitation Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Vasileios Kemerlis CSCI1660 Computer Systems Security Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Bernardo Palazzi , Nicholas A DeMarinis CSCI1670 Operating Systems Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Thomas W Doeppner CSCI1680 Computer Networks Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Nicholas A DeMarinis CSCI1690 Operating Systems Laboratory Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Thomas W Doeppner CSCI1695 Operating System Design and Implementation CSCI1710 Logic for Systems Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Tim Nelson CSCI1729 Programming Languages Lab CSCI1730 Design and Implementation of Programming Languages Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Shriram Krishnamurthi CSCI1760 Multiprocessor Synchronization Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Maurice P Herlihy CSCI1780 Parallel and Distributed Programming CSCI1800 Cybersecurity and International Relations Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Ernesto Zaldivar CSCI1805 Computers, Freedom and Privacy: Current Topics in Law and Policy Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Timothy H Edgar CSCI1810 Computational Molecular Biology Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Sorin Istrail CSCI1820 Algorithmic Foundations of Computational Biology Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Sorin Istrail CSCI1850 Deep Learning in Genomics CSCI1860 Cybersecurity Law and Policy Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Timothy H Edgar CSCI1870 Cybersecurity Ethics Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Deborah Hurley CSCI1880 Introduction to Computer Security Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Bernardo Palazzi CSCI1900 csciStartup CSCI1950-E Human-Robot Interaction Seminar CSCI1950-H Computational Topology CSCI1950-I Designing, Developing and Evaluating User Interfaces CSCI1950-N 2D Game Engines Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 James H Tompkin CSCI1950-Q Programming for the Humanities and Social Sciences CSCI1950-R Compiler Practice CSCI1950-S Fundamentals of Computer Systems CSCI1950-T Advanced Animation Production CSCI1950-U Topics in 3D Game Engine Development Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Daniel C Ritchie CSCI1950-V Advanced GPU Programming CSCI1950-W Topics in Data Science CSCI1950-X Software Foundations CSCI1950-Y Logic for Systems CSCI1950-Z Computational Methods for Biology CSCI1951-A Data Science Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Lorenzo De Stefani CSCI1951-B Virtual Citizens or Subjects? The Global Battle Over Governing Your Internet CSCI1951-C Designing Humanity Centered Robots CSCI1951-D Projective Geometry via Interactive Proof Assistants CSCI1951-E Computer Systems Security: Principles and Practice CSCI1951-G Optimization Methods in Finance CSCI1951-H Software Security and Exploitation CSCI1951-I CS for Social Change CSCI1951-J Interdisciplinary Scientific Visualization CSCI1951-L Blockchains & Cryptocurrencies Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Maurice P Herlihy CSCI1951-M Great Ideas in Computer Science CSCI1951-N VR+X, the Potential of Virtual Reality to Transform Nearly Everything CSCI1951-O Design of Robotic Systems CSCI1951-R Introduction to Robotics CSCI1951-S Virtual Reality Software Review CSCI1951-T Surveying VR Data Visualization Software for Research CSCI1951-U Software Engineering of Large Systems CSCI1951-V Hypertext/Hypermedia: The Web Was Not the Beginning and the Web Is Not the End CSCI1951-W Sublinear Algorithms for Big Data CSCI1951-X Formal Proof and Verification CSCI1951-Y The Robots are Coming! The Robots are Coming! CSCI1951-Z Fairness in Automated Decision Making Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Suresh Venkatasubramanian CSCI1952-B Responsible Computer Science in Practice Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Julia Netter CSCI1952-C Frontiers of Graph Algorithms Seminar CSCI1952-I Language Processing in Humans and Machines CSCI1952-L Robotics and Choreography CSCI1952-Q Robust Algorithms for Machine Learning Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Yu Cheng CSCI1952-V Algorithms for the People CSCI1952-X Contemporary Digital Policy and Politics Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Timothy H Edgar CSCI1952-Y Computer Architecture Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Milda Zizyte CSCI1952-Z Robots as a Medium: Creating art with teams of robots Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Nora Ayanian CSCI1970 Individual Independent Study CSCI1971 Independent Study in 2D Game Engines CSCI1972 Topics in 3D Game Engine Development CSCI2000 Computer Science Research Methods CSCI2002 Privacy and Personal Data Protection Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Deborah Hurley CSCI2230 Computer Graphics Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Daniel C Ritchie CSCI2240 Interactive Computer Graphics Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Daniel C Ritchie CSCI2270 Topics in Database Management Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Stanley B Zdonik , Ugur Cetintemel CSCI2300 Human-Computer Interaction Seminar CSCI2310 Human Factors and User Interface Design CSCI2330 Programming Environments CSCI2340 Software Engineering Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Steven P Reiss Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Steven P Reiss CSCI2370 Interdisciplinary Scientific Visualization Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 David H. Laidlaw CSCI2390 Privacy-Conscious Computer Systems CSCI2410 Statistical Models in Natural-Language Understanding CSCI2420 Probabilistic Graphical Models CSCI2440 Advanced Algorithmic Game Theory Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Amy R Greenwald CSCI2470 Deep Learning Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Ritambhara Singh CSCI2500-A Advanced Algorithms CSCI2500-B Optimization Algorithms for Planar Graphs Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Philip Klein CSCI2500-C Graph Theory and Algorithms CSCI2510 Approximation Algorithms CSCI2520 Computational Geometry CSCI2531 Internet and Web Algorithms CSCI2540 Advanced Probabilistic Methods in Computer Science Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 TBD CSCI2550 Parallel Computation: Models, Algorithms, Limits CSCI2560 Advanced Complexity CSCI2570 Introduction to Nanocomputing CSCI2580 Solving Hard Problems in Combinatorial Optimization: Theory and Systems CSCI2590 Advanced Topics in Cryptography CSCI2660 Computer Systems Security Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Bernardo Palazzi , Nicholas A DeMarinis CSCI2670 Operating Systems Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Thomas W Doeppner CSCI2730 Programming Language Theory CSCI2750 Topics in Parallel & Distributed Computing CSCI2810 Advanced Computational Molecular Biology Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Sorin Istrail CSCI2820 Algorithmic Foundations in Computational Biology Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Sorin Istrail CSCI2840 Advanced Algorithms in Computational Biology and Medical Bioinformatics CSCI2950-C Algorithms for Cancer Genomics CSCI2950-E Stochastic Optimization CSCI2950-G Large-Scale Networked Systems CSCI2950-J Cognition, Human-Computer Interaction and Visual Analysis CSCI2950-K Special Topics in Computational Linguistics CSCI2950-L Medical Bioinformatics: Disease Associations, Protein Folding and Immunogenomics CSCI2950-O Topics in Brain-Computer Interfaces CSCI2950-P Special Topics in Machine Learning CSCI2950-Q Topics in Computer Vision CSCI2950-R Special Topics in Advanced Algorithms CSCI2950-T Topics in Distributed Databases & Systems CSCI2950-U Special Topics on Networking and Distributed Systems CSCI2950-V Topics in Applied Cryptography CSCI2950-W Online Algorithms CSCI2950-X Topics in Programming Languages & Systems CSCI2950-Z Robot Learning and Autonomy CSCI2951-A Robots for Education CSCI2951-B Data-Driven Vision and Graphics CSCI2951-C Autonomous Agents and Computational Market Design CSCI2951-D Topics in Information Retrieval and Web Search CSCI2951-E Topics in Computer System Security Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Roberto Tamassia CSCI2951-F Learning and Sequential Decision Making Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Ronald Parr CSCI2951-G Computational Protein Folding CSCI2951-H Algorithms for Big Data CSCI2951-I Computer Vision for Graphics and Interaction Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 James H Tompkin CSCI2951-J Topics in Advanced Algorithmics: Algorithmic Game Theory, 3D Computational Geometry, Quantum Computing CSCI2951-K Topics in Collaborative Robotics CSCI2951-L Human-Computer Interaction Seminar CSCI2951-M Advanced Algorithms Seminar CSCI2951-N Advanced Algorithms in Computational Biology CSCI2951-O Foundations of Prescriptive Analytics Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Serdar Kadioglu CSCI2951-P Human-Robot Interaction Seminar CSCI2951-Q Topics in Advanced Algorithms CSCI2951-R Personal Informatics Seminar CSCI2951-S Distributed Computing through Combinatorial Topology CSCI2951-T Data-Drive Computer Vision CSCI2951-U Topics in Software Security Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Vasileios Kemerlis CSCI2951-V Systems for Interactive Data Exploration CSCI2951-W Creative Artificial Intelligence for Computer Graphics CSCI2951-X Reintegrating AI Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 George D Konidaris CSCI2951-Y Special Topics in Formal Semantics and Notional Machines CSCI2951-Z Advanced Algorithmic Game Theory CSCI2952-A Blockchains and Cryptocurrencies CSCI2952-B Topics in Computer Science Education Research CSCI2952-C Learning with Limited Labeled Data CSCI2952-D Computational Semantics CSCI2952-E Topics in Network Management: Data-driven and Programmable Networks CSCI2952-F Distributed Systems at Scale: Microservices Management CSCI2952-G Deep Learning in Genomics CSCI2952-H Recent Progress in Reinforcement Learning CSCI2952-I Language Processing in Humans and Machines CSCI2952-J Computing with Emerging Technology CSCI2952-K Topics in 3D Computer Vision and Deep Learning CSCI2952-L Special Topics in Secure Computation CSCI2952-M The Works that Made and Changed Machine Learning CSCI2952-N Advanced Topics in Deep Learning Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Chen Sun CSCI2952-O A Practical Introduction to Advanced 3D Robot Perception Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Srinath Sridhar CSCI2952-P Coordinated Mobile Robotics CSCI2952-Q Robust Algorithms for Machine Learning Fall \u2022 2024 \u2022 TBD \u2022 TBD \u2022 Yu Cheng CSCI2952-R Systems Transforming Systems CSCI2952-S Topics in Cyber and Digital Policy Spring \u2022 2025 \u2022 TBD \u2022 TBD \u2022 Timothy H Edgar CSCI2952-V Algorithms for the People CSCI2955 The Design and Analysis of Trading Agents CSCI2956-F Machine Learning Reading Group CSCI2980 Reading and Research DATA0080 Data, Ethics and Society DATA0200 Data Science Fluency DATA1030 Hands-on Data Science DATA1050 Data Engineering DATA2040 Deep Learning DATA2050 Data Science Practicum DATA2080 Data and Society ENGN2502 3D Photography ENGN2520 Pattern Recognition and Machine Learning XLIST_BIOL_1430 Computational Theory of Molecular Evolution XLIST_ENGN2911-I 3D Photography and Geometry Processing const coursesShowingDropdown = document.getElementById('courses_showing'); coursesShowingDropdown.addEventListener('change', (event) => { updateShowing(); }); const detailsShowingDropdown = document.getElementById('details_showing'); detailsShowingDropdown.addEventListener('change', (event) => { updateShowing(); }); function updateShowing() { const coursesToShow = coursesShowingDropdown.value; const detailsToShow = detailsShowingDropdown.value; Object.values(coursesTable.rows).forEach( row => { action = 'hide'; if (coursesToShow == 'all') action = 'show'; else if (row.classList.contains('current')) if (coursesToShow == 'year' || row.classList.contains(coursesToShow)) action = 'show'; if (action == 'show' && row.classList.contains('details')) action = detailsToShow if (action == 'show') { if (row.classList.contains('hide-row')) row.classList.remove('hide-row'); } else { if (!row.classList.contains('hide-row')) row.classList.add('hide-row'); } } ) } const showClass = 'active-course-row'; const hideClass = 'inactive-course-row'; const coursesTable = document.getElementById('courses_table'); //coursesShowingDropdown.value = 'year' //detailsShowingDropdown.value = 'hide' updateShowing();", "https://cs.brown.edu/courses/cs051/": "CS051 Models of Computation The Next Generation rip 51 About Models of Computation This was a core undergraduateComputer Science course on the foundations of computing. Thequestions it aimed to answer were: (1) What is computation? (2) What iscomputable? (3) What is computable given our limited resources? The course has now been renamed CS1010, Theory of Computation. Come visit CS1010!", "https://cs.brown.edu/courses/cs137/2006/images.html": "VirtualReality Design for Science IMAGE GALLERIES 2002 ClassCreations July 2004Visit to Bat-Cave... sort of 2004 ClassDemo Day 2006 classfaces... home classdescription calendar images links previous years: 2002 2004 Brown Brown CS RISD RISD Illustration BrownCS Visualization", "https://cs.brown.edu/courses/cs0931/": "This course has been renumbered and is using the URL: cs.brown.edu/courses/csci0030 , so head there instead.", "https://cs17-fall2022.github.io": "cs17-fall2022.github.io I think you\u2019re on the wrong page! If you were looking for the current version of CS17, you can find the website at https://cs17-fall2023.github.io/cs17fall2023.github.io/ anchors.add();", "https://cs.brown.edu/courses/cs0931/2012/": "I'm Ruth Simmons and I endorse this interdisciplinary course. Home ~ Assignments ~ Staff ~ Resources ~ Projects CS 0931 { Introduction to Computation for the Humanities & Social Sciences Welcome to CS0931, Spring 2012! Before you continue , read About CS0931 for information about the waitlist, prerequisites, and work load. Whether you know a little bit about programming and are eager tolearn more or you've never programmed before, don't worry, we're hereto help. CS0931 is an introductory computer science course specifically developed for concentrators in the humanities andsocial sciences. Because of this, we'll be focusing on real worldapplications rather than computer science theory. There are noprerequisites , though some experience with Excel will help.Students from all fields are welcome. The course will be very hands-on and cover a variety oftopics that will ultimately allow you to: Practice solving real world problems by learning to use new tools and applying familiar ones - like Excel - in new ways Gather data from the web Learn about and create algorithms that analyze large amounts of data Create web-based interfaces Become proficient in a scripting language CS0931 meets Tuesdays and Thursdays from 2:30-3:50 PM in room 265 ofthe CIT ( map ). Check out the staff page to meet theinstructor, faculty, and TAs. For more information, read the Course Missive . All studentsmust read and sign the Collaboration Policy . Past editions of the course can be found on the offerings page .", "https://cs.brown.edu/courses/cs132/": "Skip to main content Home Description Tracks Lectures Assignments Final Project Labs Hours Docs Staff CSCI1320 Modern Web & Mobile Applications CSCI1320 takes a holistic look at the process of developing web and mobile applications and aims to bring the students to a point of mastery of many of the most used technologies and development practices. Zoom link for the lecture: link Course Description CSCI 1320, Creating Modern Web and Mobile Applications, is a spring semester course within the Brown CS department. The course has two tracks, one intended for CS concentrators, and one intended for non-concentrators with previous design experience. It takes a holistic look at the process of developing web and mobile applications and aims to bring the students to a point of mastery of many of the most used technologies and development practices. The course includes a semester long group final project in which the students will be working with external companies, non-profits, and other organizations. Tracks Concentrator The Concentrator track will teach students everything they need to know to program a practical and workable web or mobile application. It starts with HTML, covers JavaScript in the front end, various back end technologies, databases, as well as security, scaling and testing issues. Students in this track can expect to do a significant amount of programming (mostly in JavaScript) on their assignments and in their final project. CSCI 1320's Concentrator track is high encouraged for Computer Science concentrators (or potential concentrators) and is appropriate for any student who has completed an intro level CS course (CS15, CS17, CS19) or has equivalent programming experience. Students should be comfortable with basic programming concepts. CS33 (Introduction to Computer Systems) and CS32 (Introduction to Software Engineering) are listed on CAB as recommended courses. Having taken either of these courses will certainly make the material easier, as students who have taken these courses will have had experience working on large-scale, open-ended projects similar to this course\u2019s final project. However, such experience is by no means necessary for students to succeed in CS132\u2019s concentrator track. Students should still bear in mind that the concentrator track of CS132 may be an intense experience, especially for students without previous web background. Expect assignments to take upwards of 5-10 hours to complete. Designer The Designer track is for students with a design background that would like to apply that background to creating web and mobile applications. Students in this track are expected to be familiar with various design tools and have some background in HTML or web design. Designers will be expected to take the lead role in the user interface design for their final project. The Designer track does involve some programming, but to a much smaller degree than the concentrator track. Assignments in this track will let students show off their design expertise rather than their programming skills. The Designer track is most appropriate for non-concentrators with design experience, as well as most RISD students. Capstone Students taking CS132 for capstone credit must take the concentrator track. In addition, they are expected either to propose and guide a final project or to act as the leader of their project team (or both). Lectures Topic Date Slides Lecture Capture Course Introduction 1/20/21 PDF / PPTX Capture The Browser and HTML 1/22/21 PDF / PPTX Capture Accessibility 1/25/21 PDF / PPTX Capture Lab 2: HTML 1/27/21 PDF / PPTX JavaScript 1/29/21 PDF / PPTX Capture DOM 2/1/21 PDF / PPTX Capture DOM 2/3/21 PDF / PPTX Capture Requirements and Specifications 2/5/21 PDF / PPTX Capture Lab 3: DOM 2/8/21 PDF / PPTX Capture Frameworks/VUE 2/10/21 PDF / PPTX Capture Lab 4: VUE 2/12/21 PDF / PPTX Capture NO CLASS 2/15/21 --- Capture --- Capture Web Server 2/17/21 PDF / PPTX Capture Node.js 2/19/21 PDF / PPTX Capture Web Architectures 2/22/21 PDF / PPTX Capture Web Architectures II 2/24/21 PDF / PPTX Capture Lab 5: Node.js 2/26/21 PDF / PPTX Capture Project Elevator Pitches 3/1/21 PDF / PPTX Capture Databases Part I 3/3/21 PDF / PPTX Capture Databases Part II 3/5/21 PDF / PPTX Capture Lab 6: Databases 3/8/21 PDF / PPTX Capture Mobile Applications 3/10/21 PDF / PPTX Capture NativeScript 3/12/21 PDF / PPTX Capture Lab 7: Mobile Lab 3/15/21 PDF / PPTX Capture HCI I 3/17/21 PDF / PPTX Capture Lab 8: AWS 3/19/21 PDF / PPTX Capture HCI II 3/22/21 PDF / PPTX Capture HCI III 3/24/21 PDF / PPTX Capture Security I 3/26/21 PDF / PPTX Capture Security II 3/29/21 PDF / PPTX Capture Security III 3/31/21 PDF / PPTX Capture Privacy 4/2/21 PDF / PPTX Capture Testing Part I 4/5/21 PDF / PPTX Capture Testing Part II 4/7/21 PDF / PPTX Capture NO CLASS 4/9/21 --- Capture --- Capture Project Presentations 4/12/21 --- --- Project Presentations 4/14/21 --- --- Project Presentations 4/16/21 --- --- Assignments # Concentrator Out Due 0 Logistics & Setup 1/20/21 1/26/21 1 HTML & CSS 1/27/21 2/7/21 2 Javascript 2/8/21 2/19/21 3 Vue 2/17/21 2/26/21 4 Backend 3/1/21 3/12/21 5 Mobile 3/15/21 3/26/21 6 Final Exam 4/15/21 4/20/21 # Designer Out Due 0 Logistics & Setup 1/20/21 1/26/21 1 HTML & CSS 1/27/21 2/7/21 2 Javascript 2/8/21 2/19/21 3 Vue 2/17/21 2/26/21 4 Wireframes & Mockups 3/1/21 3/12/21 5 Prototype 3/15/21 3/26/21 6 Final Exam 4/15/21 4/20/21 Labs Please complete pre-labs before each lab. # Topic Pre-Lab Out Pre-Lab Due Lab Out Lab Due 1 Accessibility --- --- 1/22/21 1/27/21 2 HTML ( Pre-Lab ) 1/22/21 1/27/21 1/27/21 (During class) 1/27/21 (During class) 3 DOM ( Pre-Lab ) 2/3/21 2/8/21 2/8/21 (During class) 2/8/21 (During class) 4 Vue.js ( Pre-Lab ) 2/10/21 2/12/21 2/12/21 (During class) 2/12/21 (During class) 5 Node.js ( Pre-Lab ) 2/19/21 2/26/21 2/26/21 (During class) 2/26/21 (During class) 6 Databases ( Pre-Lab ) 3/3/21 3/8/21 3/8/21 (During class) 3/8/21 (During class) 7 Mobile ( Pre-Lab ) 3/12/21 3/15/21 3/15/21 (During class) 3/15/21 (During class) 8 AWS ( Pre-Lab ) 3/15/21 3/19/21 3/19/21 (During class) 3/19/21 (During class) Hours Please check the calendar for the latest times and the most updated schedule. Join the queue using SignMeUp when signing up for hours. Docs The syllabus can be found here . Note that the dates in the syllabus are tentative and that the actual deadlines will be on this website and on the course calendar for each Lab/Pre-Lab/Assignment/Final Project checkpoint. Professor Steve Reiss ( spr ) HTAs Jen Kaplan ( jckaplan ) Pragadeesh ( pchandir ) UTAs Colby Anderson ( cander23 ) Enmin Zhou ( ezhou24 ) Griffin Kupsaw ( gkupsaw ) Hans Bala ( hbala ) Kalli Feinberg ( kfeinbe1 ) Ragna Agerup ( ragerup ) Delmy Garcia ( dgarci14 ) CSCI1320 Spring 2021 | Professor Steve Reiss cs1320tas@lists.brown.edu cs1320headtas@lists.brown.edu", "https://cs0320.github.io/": "You need to enable JavaScript to run this app.", "https://cs.brown.edu/courses/cs137/2008/": "Virtual Reality Design for Science, Fall 2008 Home Calendar Class Description Images Links Previous years: 1999 2000 2002 2003 2004 2005 2006 2007 Brown CS Visualization RISD Illustration This course explores the visual and human-computer interaction design process for scientific applications in immersive virtual reality. It is cross listed at Brown (as CSCI1370) and RISD (as ILLUS5303) and is co-taught by David Laidlaw from Brown Computer Science, Fritz Drury from RISD Illustration, and Sharon Swartz from Ecology and Evolutionary Biology. Jadrian Miles is the TA. Computer science students learn how to work effectively with each other as well as with artists and designers in creating applications targeting Brown's Cave. A Cave is an 8'x8'x8' cube whose floor and walls are covered with displays, which we will use to create interactive 3D virtual environments. Artists and designers learn to interact with scientists in designing and realizing applications in this new medium. We study the process of design from several perspectives; learn about some specific scientific problems; study existing applications of scientific visualization and virtual reality; explore the medium of the Cave; create designs for the scientific applications; critique, evaluate, realize, and iterate the designs; and culminate with a demonstration of final projects.", "https://cs.brown.edu/courses/cs137/": "Virtual Reality Design for Science, Fall 2019 Home Calendar Class Description Images Links Previous years: 1999 2000 2002 2003 2004 2005 2006 2007 2008 2013 2015 2017 Brown CS Visualization RISD Illustration ** For those considering the Fall 2019 class, consider the following: I suggest reviewing the course website from 2017, especially the calendar page, to see exactly what the class involves. That has all the assignments. The course description in CAB is short, so reviewing this info will make sure that know exactly what you would be doing in taking the course. ** We will provide overrides after the first assignment is handed in. In the past, we have almost always been able to accommodate everyone what was interested, who made it to the classes, and who completed the first assignment. I can't guarantee that will be the case this year, but it has been for the last 10 years. ** For registration, please request an override in CAB and also make sure that the class is in your primary cart. Those steps will keep you on the waiting list and also ensure that you get course emails. This course explores the visual and human-computer interaction design processfor scientific applications in immersive virtual reality. It is cross listedat Brown (as CSCI1370) and RISD (as ILLUS3340) and is co-taught by David Laidlaw from Brown Computer Science, Fritz Drury from RISD Illustration, as well as Stephen Gatesy from Ecology and Evolutionary Biology. Brandon Li is the TA. Computer science students learn how to work effectively with each other aswell as with artists and designers in creating applications targeting Brown'sCaves. A Cave is an immersive virtual reality space whose floor and walls arecovered with displays, which we will use to create interactive 3D virtualenvironments. There are currently two Caves on campus that are managed by the Brown Center for Computation and Visualization (CCV) : the YURT, a curved display system with 360-degree field of view located at 180 George St., and it's predecessor an 8'x8'x8' cube display system located at Studio4 of the Granoff Center. Artists and designers learn to interact with scientists in designing andrealizing applications in this new medium. We study the process of design fromseveral perspectives; learn about some specific scientific problems; studyexisting applications of scientific visualization and virtual reality; explorethe medium of the YURT; create designs for the scientific applications;critique, evaluate, realize, and iterate the designs; and culminate with ademonstration of final projects. The first class meets Thursday, September 5th at 10am in 180 George St. room 102B. 2019 shoppers, check out the \"calendar\" page for many details about what the course will involve.", "https://cs.brown.edu/courses/cs137/2015/gallery/": "VR Design for Science : Gallery Home Calendar Class Description Images Links Previous years: 1999 2000 2002 2003 2004 2005 2006 2007 2008 2013 Brown CS Visualization RISD Illustration Week 2B Week 3A Week 3B Week 4A Week 4B Week 5A Week 5B Week 6A Week 6B Week 7A Week 7B Week 8A Week 8B Week 9A Week 9B Week 10A Week 10B Week 11A Week 11B Week 13A Week 13B Week 14A Week 14B Week 15A Week 15B var initPhotoSwipeFromDOM = function(gallerySelector) { // parse slide data (url, title, size ...) from DOM elements // (children of gallerySelector) var parseThumbnailElements = function(el) { var thumbElements = el.childNodes, numNodes = thumbElements.length, items = [], figureEl, linkEl, size, item; for(var i = 0; i < numNodes; i++) { figureEl = thumbElements[i]; // <figure> element // include only element nodes if(figureEl.nodeType !== 1) { continue; } linkEl = figureEl.children[0]; // <a> element size = linkEl.getAttribute('data-size').split('x'); // create slide object item = { src: linkEl.getAttribute('href'), w: parseInt(size[0], 10), h: parseInt(size[1], 10) }; if(figureEl.children.length > 1) { // <figcaption> content item.title = figureEl.children[1].innerHTML; } if(linkEl.children.length > 0) { // <img> thumbnail element, retrieving thumbnail url item.msrc = linkEl.children[0].getAttribute('src'); } item.el = figureEl; // save link to element for getThumbBoundsFn items.push(item); } return items; }; // find nearest parent element var closest = function closest(el, fn) { return el && ( fn(el) ? el : closest(el.parentNode, fn) ); }; // triggers when user clicks on thumbnail var onThumbnailsClick = function(e) { e = e || window.event; e.preventDefault ? e.preventDefault() : e.returnValue = false; var eTarget = e.target || e.srcElement; // find root element of slide var clickedListItem = closest(eTarget, function(el) { return (el.tagName && el.tagName.toUpperCase() === 'FIGURE'); }); if(!clickedListItem) { return; } // find index of clicked item by looping through all child nodes // alternatively, you may define index via data- attribute var clickedGallery = clickedListItem.parentNode, childNodes = clickedListItem.parentNode.childNodes, numChildNodes = childNodes.length, nodeIndex = 0, index; for (var i = 0; i < numChildNodes; i++) { if(childNodes[i].nodeType !== 1) { continue; } if(childNodes[i] === clickedListItem) { index = nodeIndex; break; } nodeIndex++; } if(index >= 0) { // open PhotoSwipe if valid index found openPhotoSwipe( index, clickedGallery ); } return false; }; // parse picture index and gallery index from URL (#&pid=1&gid=2) var photoswipeParseHash = function() { var hash = window.location.hash.substring(1), params = {}; if(hash.length < 5) { return params; } var vars = hash.split('&'); for (var i = 0; i < vars.length; i++) { if(!vars[i]) { continue; } var pair = vars[i].split('='); if(pair.length < 2) { continue; } params[pair[0]] = pair[1]; } if(params.gid) { params.gid = parseInt(params.gid, 10); } return params; }; var openPhotoSwipe = function(index, galleryElement, disableAnimation, fromURL) { var pswpElement = document.querySelectorAll('.pswp')[0], gallery, options, items; items = parseThumbnailElements(galleryElement); // define options (if needed) options = { // define gallery index (for URL) galleryUID: galleryElement.getAttribute('data-pswp-uid'), getThumbBoundsFn: function(index) { // See Options -> getThumbBoundsFn section of documentation for more info var thumbnail = items[index].el.getElementsByTagName('img')[0], // find thumbnail pageYScroll = window.pageYOffset || document.documentElement.scrollTop, rect = thumbnail.getBoundingClientRect(); return {x:rect.left, y:rect.top + pageYScroll, w:rect.width}; } }; // PhotoSwipe opened from URL if(fromURL) { if(options.galleryPIDs) { // parse real index when custom PIDs are used // http://photoswipe.com/documentation/faq.html#custom-pid-in-url for(var j = 0; j < items.length; j++) { if(items[j].pid == index) { options.index = j; break; } } } else { // in URL indexes start from 1 options.index = parseInt(index, 10) - 1; } } else { options.index = parseInt(index, 10); } // exit if index not found if( isNaN(options.index) ) { return; } if(disableAnimation) { options.showAnimationDuration = 0; } // Pass data to PhotoSwipe and initialize it gallery = new PhotoSwipe( pswpElement, PhotoSwipeUI_Default, items, options); gallery.init(); }; // loop through all gallery elements and bind events var galleryElements = document.querySelectorAll( gallerySelector ); for(var i = 0, l = galleryElements.length; i < l; i++) { galleryElements[i].setAttribute('data-pswp-uid', i+1); galleryElements[i].onclick = onThumbnailsClick; } // Parse URL and open gallery if it contains #&pid=3&gid=1 var hashData = photoswipeParseHash(); if(hashData.pid && hashData.gid) { openPhotoSwipe( hashData.pid , galleryElements[ hashData.gid - 1 ], true, true ); }};// execute above functioninitPhotoSwipeFromDOM('.my-gallery');", "https://cs.brown.edu/courses/cs137/2017/gallery/": "VR Design for Science : Gallery Home Calendar Class Description Images Links Previous years: 1999 2000 2002 2003 2004 2005 2006 2007 2008 2013 2015 Brown CS Visualization RISD Illustration Week 2A Week 2B Week 3A Week 3B Week 4A Week 4B Week 5A Week 6A Week 6B Week 7A Week 7B Week 8A Week 8B Week 9A Week 9B Week 10A Week 10B Week 11A Week 11B Week 13A Week 13B Week 14A Week 14B Week 15A var initPhotoSwipeFromDOM = function(gallerySelector) { // parse slide data (url, title, size ...) from DOM elements // (children of gallerySelector) var parseThumbnailElements = function(el) { var thumbElements = el.childNodes, numNodes = thumbElements.length, items = [], figureEl, linkEl, size, item; for(var i = 0; i < numNodes; i++) { figureEl = thumbElements[i]; // <figure> element // include only element nodes if(figureEl.nodeType !== 1) { continue; } linkEl = figureEl.children[0]; // <a> element size = linkEl.getAttribute('data-size').split('x'); // create slide object item = { src: linkEl.getAttribute('href'), w: parseInt(size[0], 10), h: parseInt(size[1], 10) }; if(figureEl.children.length > 1) { // <figcaption> content item.title = figureEl.children[1].innerHTML; } if(linkEl.children.length > 0) { // <img> thumbnail element, retrieving thumbnail url item.msrc = linkEl.children[0].getAttribute('src'); } item.el = figureEl; // save link to element for getThumbBoundsFn items.push(item); } return items; }; // find nearest parent element var closest = function closest(el, fn) { return el && ( fn(el) ? el : closest(el.parentNode, fn) ); }; // triggers when user clicks on thumbnail var onThumbnailsClick = function(e) { e = e || window.event; e.preventDefault ? e.preventDefault() : e.returnValue = false; var eTarget = e.target || e.srcElement; // find root element of slide var clickedListItem = closest(eTarget, function(el) { return (el.tagName && el.tagName.toUpperCase() === 'FIGURE'); }); if(!clickedListItem) { return; } // find index of clicked item by looping through all child nodes // alternatively, you may define index via data- attribute var clickedGallery = clickedListItem.parentNode, childNodes = clickedListItem.parentNode.childNodes, numChildNodes = childNodes.length, nodeIndex = 0, index; for (var i = 0; i < numChildNodes; i++) { if(childNodes[i].nodeType !== 1) { continue; } if(childNodes[i] === clickedListItem) { index = nodeIndex; break; } nodeIndex++; } if(index >= 0) { // open PhotoSwipe if valid index found openPhotoSwipe( index, clickedGallery ); } return false; }; // parse picture index and gallery index from URL (#&pid=1&gid=2) var photoswipeParseHash = function() { var hash = window.location.hash.substring(1), params = {}; if(hash.length < 5) { return params; } var vars = hash.split('&'); for (var i = 0; i < vars.length; i++) { if(!vars[i]) { continue; } var pair = vars[i].split('='); if(pair.length < 2) { continue; } params[pair[0]] = pair[1]; } if(params.gid) { params.gid = parseInt(params.gid, 10); } return params; }; var openPhotoSwipe = function(index, galleryElement, disableAnimation, fromURL) { var pswpElement = document.querySelectorAll('.pswp')[0], gallery, options, items; items = parseThumbnailElements(galleryElement); // define options (if needed) options = { // define gallery index (for URL) galleryUID: galleryElement.getAttribute('data-pswp-uid'), getThumbBoundsFn: function(index) { // See Options -> getThumbBoundsFn section of documentation for more info var thumbnail = items[index].el.getElementsByTagName('img')[0], // find thumbnail pageYScroll = window.pageYOffset || document.documentElement.scrollTop, rect = thumbnail.getBoundingClientRect(); return {x:rect.left, y:rect.top + pageYScroll, w:rect.width}; } }; // PhotoSwipe opened from URL if(fromURL) { if(options.galleryPIDs) { // parse real index when custom PIDs are used // http://photoswipe.com/documentation/faq.html#custom-pid-in-url for(var j = 0; j < items.length; j++) { if(items[j].pid == index) { options.index = j; break; } } } else { // in URL indexes start from 1 options.index = parseInt(index, 10) - 1; } } else { options.index = parseInt(index, 10); } // exit if index not found if( isNaN(options.index) ) { return; } if(disableAnimation) { options.showAnimationDuration = 0; } // Pass data to PhotoSwipe and initialize it gallery = new PhotoSwipe( pswpElement, PhotoSwipeUI_Default, items, options); gallery.init(); }; // loop through all gallery elements and bind events var galleryElements = document.querySelectorAll( gallerySelector ); for(var i = 0, l = galleryElements.length; i < l; i++) { galleryElements[i].setAttribute('data-pswp-uid', i+1); galleryElements[i].onclick = onThumbnailsClick; } // Parse URL and open gallery if it contains #&pid=3&gid=1 var hashData = photoswipeParseHash(); if(hashData.pid && hashData.gid) { openPhotoSwipe( hashData.pid , galleryElements[ hashData.gid - 1 ], true, true ); }};// execute above functioninitPhotoSwipeFromDOM('.my-gallery');", "https://cs.brown.edu/courses/cs137/2013/gallery/": "CS137 2013 Gallery This page shows student work from CS137 . Week 2 - 5 temporarily removed due to ongoing class assignments Tuesday, Week 6 Tuesday, Week 8 Tuesday, Week 10 Thursday, Week 10 Thursday, Week 11", "https://cs.brown.edu/courses/cs137/gallery/": "VR Design for Science : Gallery Home Calendar Class Description Images Links Previous years: 1999 2000 2002 2003 2004 2005 2006 2007 2008 2013 2015 Brown CS Visualization RISD Illustration Week 2A Week 2B Week 3A Week 3B Week 4A Week 4B Week 5A Week 5B Week 6A Week 6B Week 7A Week 7B Week 8A Week 8B Week 9A Week 9B Week 10A Week 10B Week 11 Week 12 Week 13 Week 14 var initPhotoSwipeFromDOM = function(gallerySelector) { // parse slide data (url, title, size ...) from DOM elements // (children of gallerySelector) var parseThumbnailElements = function(el) { var thumbElements = el.childNodes, numNodes = thumbElements.length, items = [], figureEl, linkEl, size, item; for(var i = 0; i < numNodes; i++) { figureEl = thumbElements[i]; // <figure> element // include only element nodes if(figureEl.nodeType !== 1) { continue; } linkEl = figureEl.children[0]; // <a> element size = linkEl.getAttribute('data-size').split('x'); // create slide object item = { src: linkEl.getAttribute('href'), w: parseInt(size[0], 10), h: parseInt(size[1], 10) }; if(figureEl.children.length > 1) { // <figcaption> content item.title = figureEl.children[1].innerHTML; } if(linkEl.children.length > 0) { // <img> thumbnail element, retrieving thumbnail url item.msrc = linkEl.children[0].getAttribute('src'); } item.el = figureEl; // save link to element for getThumbBoundsFn items.push(item); } return items; }; // find nearest parent element var closest = function closest(el, fn) { return el && ( fn(el) ? el : closest(el.parentNode, fn) ); }; // triggers when user clicks on thumbnail var onThumbnailsClick = function(e) { e = e || window.event; e.preventDefault ? e.preventDefault() : e.returnValue = false; var eTarget = e.target || e.srcElement; // find root element of slide var clickedListItem = closest(eTarget, function(el) { return (el.tagName && el.tagName.toUpperCase() === 'FIGURE'); }); if(!clickedListItem) { return; } // find index of clicked item by looping through all child nodes // alternatively, you may define index via data- attribute var clickedGallery = clickedListItem.parentNode, childNodes = clickedListItem.parentNode.childNodes, numChildNodes = childNodes.length, nodeIndex = 0, index; for (var i = 0; i < numChildNodes; i++) { if(childNodes[i].nodeType !== 1) { continue; } if(childNodes[i] === clickedListItem) { index = nodeIndex; break; } nodeIndex++; } if(index >= 0) { // open PhotoSwipe if valid index found openPhotoSwipe( index, clickedGallery ); } return false; }; // parse picture index and gallery index from URL (#&pid=1&gid=2) var photoswipeParseHash = function() { var hash = window.location.hash.substring(1), params = {}; if(hash.length < 5) { return params; } var vars = hash.split('&'); for (var i = 0; i < vars.length; i++) { if(!vars[i]) { continue; } var pair = vars[i].split('='); if(pair.length < 2) { continue; } params[pair[0]] = pair[1]; } if(params.gid) { params.gid = parseInt(params.gid, 10); } return params; }; var openPhotoSwipe = function(index, galleryElement, disableAnimation, fromURL) { var pswpElement = document.querySelectorAll('.pswp')[0], gallery, options, items; items = parseThumbnailElements(galleryElement); // define options (if needed) options = { // define gallery index (for URL) galleryUID: galleryElement.getAttribute('data-pswp-uid'), getThumbBoundsFn: function(index) { // See Options -> getThumbBoundsFn section of documentation for more info var thumbnail = items[index].el.getElementsByTagName('img')[0], // find thumbnail pageYScroll = window.pageYOffset || document.documentElement.scrollTop, rect = thumbnail.getBoundingClientRect(); return {x:rect.left, y:rect.top + pageYScroll, w:rect.width}; } }; // PhotoSwipe opened from URL if(fromURL) { if(options.galleryPIDs) { // parse real index when custom PIDs are used // http://photoswipe.com/documentation/faq.html#custom-pid-in-url for(var j = 0; j < items.length; j++) { if(items[j].pid == index) { options.index = j; break; } } } else { // in URL indexes start from 1 options.index = parseInt(index, 10) - 1; } } else { options.index = parseInt(index, 10); } // exit if index not found if( isNaN(options.index) ) { return; } if(disableAnimation) { options.showAnimationDuration = 0; } // Pass data to PhotoSwipe and initialize it gallery = new PhotoSwipe( pswpElement, PhotoSwipeUI_Default, items, options); gallery.init(); }; // loop through all gallery elements and bind events var galleryElements = document.querySelectorAll( gallerySelector ); for(var i = 0, l = galleryElements.length; i < l; i++) { galleryElements[i].setAttribute('data-pswp-uid', i+1); galleryElements[i].onclick = onThumbnailsClick; } // Parse URL and open gallery if it contains #&pid=3&gid=1 var hashData = photoswipeParseHash(); if(hashData.pid && hashData.gid) { openPhotoSwipe( hashData.pid , galleryElements[ hashData.gid - 1 ], true, true ); }};// execute above functioninitPhotoSwipeFromDOM('.my-gallery');", "https://cs.brown.edu/courses/cs138/s16/lectures/screencasts/05comm1/": ".smart-player-embed-container-iframe{width:1280px;height:720px}.smart-player-full-frame-mode{position:absolute;top:0;left:0;z-index:10;width:100%;height:100%;padding:0;margin:0}", "https://cs.brown.edu/courses/cs138/s18/": "CSCI-1380 :: Distributed Computer Systems :: Spring 2018 CS 138: Home CS 138 Home Syllabus Calendar Assignments Exams Announcements Latest Announcements 04/12: Puddlestore released! Due 05/07, via handin script. 04/05: Homework 3 released! Due 04/19, please submit on Gradescope. See all announcements Overview CSCI 1380 is an undergraduate course in distributed computer systems. Wewill explore the fundamental principles and practice underlying networkedinformation systems. First we will cover basic distributed computingmechanisms (e.g., naming, replication, security, etc.) and enabling middlewaretechnologies. We then discuss how these mechanisms and technologies fittogether to realize distributed databases and file systems, web-based andmobile information systems. Prerequisites: CSCI 0320, CSCI 0330, or consent of the instructor. Lecture time: Tu/Th 10:30-11:50 Location: Metcalf Research AUD If you are not registered for the class and would like to be put on the waitlist, thenplease fill out this form. Course Staff We'll be using Piazza for almost all course-related communication. You can mark questions as privateor public. Private messages are seen by all course staff, see the collaboration policy for guidelinesof how to choose. You can also use cs1380tas@lists.brown.edu to e-mail thecourse staff regarding administrative issues. For sensitive issues that you wouldnot like to discuss with the entire course staff, you may email the instructorsand head TAs at cs1380headtas@lists.brown.edu . Instructor Name Email Office Hours Theo Benson tab@cs.brown.edu CIT 327 Tuesdays 4-5 p.m., Wednesdays 11-12 p.m. Teaching Assistants Name Email Office Office Hours HTA: Sidd Karamcheti skaramch@cs.brown.edu CIT 205 Thursday 1-3 p.m. TA: Amedeo Alberio aalberio@cs.brown.edu CIT 205 Friday 4-6 p.m. TA: Abdulla Aldilaijan aaldilai@cs.brown.edu CIT 205 Monday 6-8 p.m. TA: Sandy Harvie charvie@cs.brown.edu CIT 205 Sunday 6-8 p.m. TA: Ben Shteinfeld bshteinf@cs.brown.edu CIT 205 Wednesday 10 a.m.-12 p.m. TA: Jared Siskin jsiskin1@cs.brown.edu CIT 205 Tuesday 6-8 p.m. Course Policies Collaboration Policy The collaboration policy document is available online. You must read it,and then sign the collaboration policy form so that youcan receive credit for the assignments. Incomplete Policy Incompletes are granted only under exceptional circumstances (e.g. severe illness, death in the family, kidnapping, etc.; too heavy of a course load is not sufficient reason for an incomplete). Getting a dean to certify your reason for requesting an incomplete helps, but is not sufficient. Late Policy Students will be allowed a total of four late days to be used on homework and project assignments free of charge, but no more than three late days may be applied to any one assignment. Students will be penalized by a letter grade on the assignment for each day it is late. CSCI-1380 :: Spring 2018 :: Theo Benson All materials in this site are licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 3.0 United States License . Last modified: 2018-01-10 13:27:47 -0400. Page design adapted from the glued ideas subtle wp theme. var gaJsHost = ((\"https:\" == document.location.protocol) ? \"https://ssl.\" : \"http://www.\"); document.write(unescape(\"%3Cscript src='\" + gaJsHost + \"google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E\")); try { var pageTracker = _gat._getTracker(\"UA-371922-7\"); pageTracker._trackPageview(); } catch(err) {}", "https://cs.brown.edu/courses/cs138/s17/": "CSCI-1380 :: Distributed Computer Systems :: Spring 2017 CS 138: Home CS 138 Home Syllabus Calendar Assignments Exams Announcements Attention: This is an old version of the CS 138 website. Please click here for the current offering. Latest Announcements 03/16: Raft released! Due 04/11 via handin script. 02/16: Tapestry released! Due 03/02 via handin script. 02/12: Homework 1 released Due 02/22, please submit on Gradescope. See all announcements RSS 2.0 feed Overview CSCI 1380 is an undergraduate course in distributed computer systems. Wewill explore the fundamental principles and practice underlying networkedinformation systems. First we will cover basic distributed computingmechanisms (e.g., naming, replication, security, etc.) and enabling middlewaretechnologies. We then discuss how these mechanisms and technologies fittogether to realize distributed databases and file systems, web-based andmobile information systems. Prerequisites: CSCI 0320, CSCI 0330, or consent of the instructor. Lecture time: Tu/Th 10:30-11:50 Location: BioMed 202 If you are not registered for the class and would like to be put on the waitlist, thenplease fill out this form. Course Staff We'll be using Piazza for almost all course-related communication. You can mark questions as privateor public. Private messages are seen by all course staff, see the collaboration policy for guidelinesof how to choose. You can also use cs1380tas@lists.brown.edu to e-mail thecourse staff regarding administrative issues. For sensitive issues that you wouldnot like to discuss with the entire course staff, you may email the instructorsand head TAs at cs1380headtas@lists.brown.edu . Instructor Name Email Office Hours Tom Doeppner twd@cs.brown.edu CIT 405 Mondays and Wednesdays 3-4 p.m., Fridays 4-5 p.m. Rodrigo Fonseca rfonseca@cs.brown.edu CIT 329 TBD Teaching Assistants Name Email Office Office Hours HTA: Louisa Conwill lconwill@cs.brown.edu CIT 205 Monday 7-9 p.m. HTA: Atty Eleti aeleti@cs.brown.edu CIT 271 (Fishbowl) Thursday 7-9 p.m. TA: Carlos Rotger crotger@cs.brown.edu CIT 205 Sunday 7-9 p.m. TA: Scott Zellers szellers@cs.brown.edu CIT 205 Thursday 4-6 p.m. TA: Max Luzuriaga mluzuria@cs.brown.edu CIT 205 Wednesday 7-9 p.m. TA: Haris Choudhary hchoudha@cs.brown.edu CIT 205 Friday 4-6 p.m. TA: Ishan Bansal ibansal@cs.brown.edu CIT 205 Tuesday 7-9 p.m. TA: Rohil Bhansali rb32@cs.brown.edu CIT 205 Tuesday 4-6 p.m. Course Policies Collaboration Policy The collaboration policy is available as a handout. You must print, read,and sign the collaboration policy before returning it to a TA so that youcan receive credit for the assignments. Incomplete Policy Incompletes are granted only under exceptional circumstances (e.g. severe illness, death in the family, kidnapping, etc.; too heavy of a course load is not sufficient reason for an incomplete). Getting a dean to certify your reason for requesting an incomplete helps, but is not sufficient. Late Policy Students will be allowed a total of four late days to be used on homework and project assignments free of charge, but no more than three late days may be applied to any one assignment. Students will be penalized by a letter grade on the assignment for each day it is late. CSCI-1380 :: Spring 2017 :: Tom Doeppner, Rodrigo Fonseca All materials in this site are licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 3.0 United States License . Last modified: 2017-04-13 13:27:47 -0400. Page design adapted from the glued ideas subtle wp theme. var gaJsHost = ((\"https:\" == document.location.protocol) ? \"https://ssl.\" : \"http://www.\"); document.write(unescape(\"%3Cscript src='\" + gaJsHost + \"google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E\")); try { var pageTracker = _gat._getTracker(\"UA-371922-7\"); pageTracker._trackPageview(); } catch(err) {}", "https://cs.brown.edu/courses/cs173/2018/AFQ.html": "\u25bc Fall 2018: Programming Languages 1 Anticipated Frequent Questions 2 Learning Goals, Assessments, and Time Allocation 3 Syllabus and Course Policies 4 Late Policy 5 Laptop Policy 6 Diversity and Professionalism 7 Assignments 8 (Early) Testing for Programming 9 Textbook 10 Software 11 Staff and Contact 12 How to Ask Questions (and Report Bugs) 13 Pyret Style Guide 14 Credits \u2190 prev up next \u2192 1 Anticipated Frequent Questions This AFQ (Anticipated Frequent Questions) should cover most of your questions. Q: How do I keep on top of things, and where can I ask questionswhile the assignments are in progress? Please use the Piazza board .You should use your Brown emailaddress to access the board. Be sure to not post hints or solutions publicly! Be aware of the Honesty and Sharing policy before you sign up. Q: Are there any exams in this course? No. I don\u2019t believe exams are a useful way of measuring learningexcept inasmuch as they can be proctored to detect cheating (for whichwe have other mechanisms). In return, they are too dependent ontest-taking ability, time preferences, not being ill on a particularday, personal constraints, etc. Therefore, this course has no exams,only Assignments . Q: Why do you want anonymous submissions? To the extent possible, we want to eliminate biases whengrading. These may include biases both in favor or against peoplebased on attributes such as race, gender, or even how they presentthemselves in person. To make clear we are serious, we will impose asmall penalty if you do include personal identifying information(unless asked to). I know this runs counter to what you have probably been told bycountless prior instructors, and maybe even those in your otherclasses. If you\u2019re turning in pieces of paper, it is important tolabel them clearly. Since your submissions here are electronic, that\u2019snot a problem. In case you\u2019re wondering: yes, your identity is recorded when yousubmit. However, we run an anonymization script before distributingwork for grading. Therefore, the graders only see an anonymous token(e.g., \u201c103\u201d) in place of your identity. You may then wonder what happens when you go in for help after you getgraded material back. Would that deanonymize you for the future, i.e.,will that TA henceforth know who person 103 is? No, because the scriptrandomly assigns different tokens on each use. Therefore,there\u2019s no reason to believe person 103 from the previous assignmentis the same as 103 on this one (in fact, there\u2019s a very highlikelihood it\u2019s a different person). Q: What is the course format? In your day-to-day work, you are going to confront numerousprogramming languages: new ones are created almost daily, and younever know which new language will become really important in yourwork. You therefore need the ability to rapidly dive into newlanguages and understand them. However, you haven\u2019t really been exposed to a useful mental landscapethat lets you quickly understand a new language. This usually comesthrough practice and experience, combined with a knowledge of variouspoints in the space of language design. The original style of cs173\u2014 used 2000 through 2015\u2014 was (webelieve) good at helping you understand a few points in the designspace really well. But it didn\u2019t cover enough of the space, nor did itgive you practice with rapidly exploring a large space of designs. In2016 we came up with a radically new way of running the course that wefound addressed this problem. However, we also felt something was lostin the original style, and this was echoed in student evaluations. We had suspected this, but weren\u2019t sure how much time the new style ofassignments would take, and didn\u2019t want to accidentally overburdenstudents. Fortunately, the evaluations confirmed that the assignmentstook less time than we expected. Therefore, we have the time to mergethe two styles (making some time for it by dropping or changingassignments). Q: What did you do before 2016? Until 2016, the emphasis was on implementing languages throughso-called \u201cdefinitional interpreters\u201d: working implementations thatcreated the core of a language. We still do this, but far less of it. Q: What did you change in 2016? The most important thing is to make you understand that approaching a new language requires a security mindset ,and that\u2019s what we want the course to inculcate. It won\u2019t be aboutcomputer security per se, but it will be the mindset that comeswith it: of probing, asking questions, looking for ways in whichthings might not fit together, etc. We will achieve this through a series of what we call mysterylanguage (ML) assignments. In an ML assignment, you are given a newlanguage feature\u2019s syntax and a very loose description of it. Theassignment will contain (say) three different languages thatcontain that new feature, each presented in terms of a black-boximplementation of that language. Each language will contain this newfeature but will define it to behave in a somewhat different way. Youwill need to use the implementations to explore how the feature variesacross the languages and try to pin down the differences precisely. For instance, suppose the new feature is array dereference, and you\u2019regiven a notation for it such as a[i] where a evaluatesto an array and i is an expression computing the arrayindex. When i is within the bounds of the array, all threelanguages might behave identically. But when i isout-of-bounds, one language might signal an error (like Java does),another might return a special undefined value (like JavaScriptdoes), and the third might return the content of some other array(like C sometimes does). These differences have all been chosen because they have significantconsequences, and the class after the homework comes due, we willdiscuss them. Note that in the above example, to find thesedifferences, you needed to \u201cthink like an attacker\u201d: ask what thearrays do not when you use them as intended but rather when you usethem erroneously. Of course, many ML assignments have nothing to dowith errors, but it is wise to remember that those are also worthchecking. In general, in ML assignments, your task is to: Write a small suite of (one or more) programs, which we call a classifier , that tell the languages apart. That is, eachprogram in the suite produces different outputs on at least two of theimplementations, and across the suite, you can tell all three apart. Since these small programs are meant to be illustrative, it helps tomake them relatively small. At the same time, you will not be rewardedby trying to cleverly wire them all together into a single program:that can sometimes be really hard to understand. If you spot two orthree conceptual differences, try to express them in differentprograms. Imagine you\u2019re trying to explain your findings toanother human being, not just impress them with your cleverness. Write a small textual description, the theory , of what you think is thedifference between the languages, focusing on the new feature and itsinteraction with the existing features. This should not just be atextual rewriting of the classifier, but rather an attempt tosynthesize what you\u2019ve learned and describe the difference inhigh-level terms. What we\u2019re getting at is essentially the heart of the ScientificMethod. You perform some observations; using these, you formulate aninitial theory; you use the theory to suggest additional experiments.If an experiment fails, then you have to revise your theory and tryagain. As more experiments succeed, you gain greater and greaterfaith in your theory. At some point you conclude you\u2019re sufficientlysatisfied with your theory, you clean up your work, and you turn it in. Q: Were there other issues you were trying to address in 2016? Yes, there are a few things that also needed fixing: The course was a little too helpful to cs017 students (and to alesser extent, cs019 students), and disadvantaged cs015students. Though we\u2019ve tried various mitigations over the years, theyhave worked only somewhat. The use of mystery languages greatlyreduces that advantage. The course was a little too much focused on implementation,whereas that\u2019s really the domain of a course on compilers. We wantedto reduce the emphasis on implementation of languages and increase theemphasis on understanding them. Q: So the new style is a merger of the two approaches? That\u2019s correct. There will be a whole bunch of mystery languages. Nowthat we have a good understanding of how much time they take, we havealso been able to put back in several implementation tasks. We willalso implement some other tools to help you understand some patternsin programming language tools as well as in language expressive power. Q: How much time will things take? For the mystery languages, specifically:we ask that if you spend more than five hours on a homework,stop ; talk to the course staff; make sure you\u2019re on the righttrack. We may tell you you\u2019re on the right track and to continue; wemay tell you you\u2019re on the wrong path and help set you right; or wemay tell you you\u2019ve gotten the point of the assignment and shouldstop. For the other (implementation) assignments, your usual internal cueson programming apply. Q: What are \u201cCore\u201d, \u201cAdvanced\u201d, and \u201cPrank\u201d? In the mystery language assignments, you may see the differentlanguages labeled differently. Every assignment has (usually three)Core languages. These reflect the most common or important variationsin these features. The array dereference example described abovepresents three such variations. Sometimes, there are variations that have made it into real languagesbut are less important or harder to find. We label these Advanced. Forinstance, in array dereferencing, a negative index, instead of beingan error, could mean \u201cthat many indices from the end of thearray\u201d. We would consider this an Advanced (but a somewhatstraightforward one for people familiar with certain languages thathave this behavior). Before you tackle any Advanceds, make sure you\u2019venailed down the differences between the Cores! Also, be aware that theAdvanceds may take a little or a lot more time than a core. On very rare instances, an assignment might also have Pranklanguages. This is usually us re-implementing for you especiallybizarre behaviors found in some language. You should only try toclassify these languages if you\u2019re really bored or really want to showoff your language hacking skills. (Under no circumstances will weexpect you to get any of them to get an A in the course.) As anexample, there was once a bug in a well-known browser wheredereferencing the index -6 would return the value of eval , adangerous primitive that many Web sandboxes do their best to hide. Ifwe were to provide an implementation of this, we\u2019d certainly classifyit as a Prank. Q: I have a question not answered above! Where do I send it? A: Address it to the professor . \u2190 prev up next \u2192", "https://cs.brown.edu/courses/cs173/2018/web/mysteries/conditionals.xml": "", "https://cs.brown.edu/courses/cs173/2012/book/Desugaring_as_a_Language_Feature.html": "\u25bc Programming Languages: Application and Interpretation 1 Introduction 2 Everything (We Will Say) About Parsing 3 A First Look at Interpretation 4 A First Taste of Desugaring 5 Adding Functions to the Language 6 From Substitution to Environments 7 Functions Anywhere 8 Mutation: Structures and Variables 9 Recursion and Cycles: Procedures and Data 10 Objects 11 Memory Management 12 Representation Decisions 13 Desugaring as a Language Feature 14 Control Operations 15 Checking Program Invariants Statically: Types 16 Checking Program Invariants Dynamically: Contracts 17 Alternate Application Semantics \u25ba 13 Desugaring as a Language Feature 13.1 A First Example 13.2 Syntax Transformers as Functions 13.3 Guards 13.4 Or: A Simple Macro with Many Features 13.5 Identifier Capture 13.6 Influence on Compiler Design 13.7 Desugaring in Other Languages On this page: 13.1 A First Example 13.2 Syntax Transformers as Functions <sc-macro-eg> <sc-macro-eg-body> <sc-macro-eg-rule> 13.3 Guards <sc-macro-eg-guarded-rule> 13.4 Or: A Simple Macro with Many Features 13.4.1 A First Attempt 13.4.2 Guarding Evaluation 13.4.3 Hygiene 13.5 Identifier Capture 13.6 Influence on Compiler Design 13.7 Desugaring in Other Languages \u2190 prev up next \u2192 13 Desugaring as a Language Feature We have thus far extensively discussed and relied upon desugaring, butour current desugaring mechanism have been weak. We have actuallyused desugaring in two different ways. One, we have used it to shrink the language: to take a large language and distill itdown to its core [REF]. But we have also used it to grow thelanguage: to take an existing language and add new features to it[REF]. This just shows that desugaring is a tremendously usefulfeature to have. Indeed, it is so useful that we might ask twoquestions: Because we create languages to simplify the creation of commontasks, what would a language designed to support desugaring looklike? Note that by \u201clook\u201d we don\u2019t mean only syntax but also itskey behavioral properties. Given that general-purpose languages are often used as atarget for desugaring, why don\u2019t they offer desugaring capabilities in the language itself ? For instance, this might meanextending a base language with the additional language that is theresponse to the previous question. We are going to explore the answer to both questions simultaneously,by studying the facilities provided for this by Racket. 13.1 A First Example DrRacket has a very useful toolcalled the Macro Stepper, which shows the step-by-step expansion ofprograms. You should try all the examples in this chapter using theMacro Stepper. For now, however, you should run them in #lang plai rather than #lang plai-typed . Remember that in [REF] we added let as syntactic sugar over lambda . The pattern we followed was this: ( let ( var val ) body ) is transformed into ( ( lambda ( var ) body ) val ) Do Now! If this doesn\u2019t sound familiar, now would be a good time to refreshyour memory of why this works. The simplest way of describing this transformation would be to stateit directly: to write, somehow, ( let ( var val ) body ) -> ( ( lambda ( var ) body ) val ) In fact, this is almost precisely what Racket enables you to do. We\u2019ll use the name my-let instead of let Because the latter is already defined in Racket. ( define-syntax my-let-1 ( syntax-rules ( ) [ ( my-let-1 ( var val ) body ) ( ( lambda ( var ) body ) val ) ] ) ) syntax-rules tells Racket that whenever it sees an expressionwith my-let-1 immediately after the opening parenthesis, itshould check that it follows the pattern (my-let-1 (var val)body) .The var , val and body are syntactic variables : they are variables that stand for bodies ofcode. In particular, they match whatever s-expression is in thatposition. If the expression matches the pattern, then the syntacticvariables are bound to the corresponding parts of the expression, andbecome available for use in the right-hand side. You mayhave noticed some additional syntax, such as () . We\u2019ll explainthis later. The right-hand side\u2014 in this case, ((lambda (var) body) val) \u2014 is the output generated. Each ofthe syntactic variables are replaced with the corresponding parts ofthe input using our old friend, substitution. This substitution isutterly simplistic: it makes no attempt to. Thus, if we were to tryusing it with ( my-let-1 ( 3 4 ) 5 ) Racket would not initially complain that 3 is provided in anidentifier position; rather, it would let the identifier percolatethrough, desugaring this into ( ( lambda ( 3 ) 5 ) 4 ) which in turn produces an error: lambda: expected either <id> or `[<id> : <type>]' for function argument in: 3 This immediately tells us that the desugaring process isstraightforward in its function: it doesn\u2019t attempt to guess or beclever, but instead simply rewrites while substituting. The output isan expression that is again subject to desugaring. As a matter of terminology, this simple form of expression-rewritingis often called a macro , as we mentioned earlier in [REF].Traditionally this form of desugaring is called macro expansion ,though this term is misleading because the output of desugaring can besmaller than the input (though it is usually larger). Of course, in Racket, a let can bind multiple identifiers, notjust one. If we were to write this informally, say on a board, wemight write something like (let ([var val] ...) body)->((lambda (var ...) body) val ...) with the ... meaning \u201czero or more\u201d, and the intent beingthat the var ... in the output should correspond to thesequence of var s in the input. Again, this is almost preciselyRacket syntax: ( define-syntax my-let-2 ( syntax-rules ( ) [ ( my-let-2 ( [ var val ] ... ) body ) ( ( lambda ( var ... ) body ) val ... ) ] ) ) Observe the power of the ... notation: the sequence of\u201cpairs\u201d in the input is turned into a pair of sequences in theoutput; put differently, Racket \u201cunzips\u201d the input sequence.Conversely, this same notation can be used to zip together sequences. 13.2 Syntax Transformers as Functions Earlier we saw that my-let-1 does not even attempt to ensurethat the syntax in the identifier position is truly (i.e.,syntactically) an identifier. We cannot remedy that with the syntax-rules mechanism, but we can with a much more powerfulmechanism called syntax-case . Because syntax-case exhibits many other useful features as well, we\u2019ll introduce it andthen grow it gradually. The first thing to understand is that a macro is actually a function . It is not, however, a function from regular run-timevalues to other run-time values, but rather a function from syntax to syntax . These functions execute in a worldwhose purpose is to create the program to execute .Observe that we\u2019re talking about the program to execute: theactual execution of the program may only occur much later (or never atall). This point is actually extremely clear when we examinedesugaring, which is very explicitly a function from (one kind of)syntax to (another kind of) syntax. This is perhaps obscured above intwo ways: The notation of syntax-rules , with no explicitparameter name or other \u201cfunction header\u201d, may not make clear thatit is a functional transformation (though the rewriting rule formatdoes allude to this fact). In desugaring, we specify one atomic function for the entireprocess. Here, we are actually writing several little functions,one for each kind of new syntactic construct (such as my-let-1 ), and these pieces are woven together by aninvisible function that controls the overall rewriting process. (Asa concrete example, it is not inherently clear that the output of amacro is expanded further\u2014 though a simple example immediatelydemonstrates that this is indeed the case.) Exercise Write one or more macros to confirm that the output of a macro isexpanded further. There is one more subtlety. Because the form of a macro looks ratherlike Racket code, it is not immediately clear that it \u201clives inanother world\u201d. In the abstract, it may be helpful to imagine thatthe macro definitions are actually written in an entirely differentlanguage that processes only syntax. This simplicity is, however,misleading. In practice, program transformers\u2014 also called compilers \u2014 are full-blown programs, too, and need all the powerof ordinary programs. This would have necessitated the creation of aparallel language purely for processing programs. This would bewasteful and pointless; therefore, Racket instead endowssyntax-transforming programs with the full power of Racket itself. With that prelude, let\u2019s now introduce syntax-case . We\u2019llbegin by simply rewriting my-let-1 (under the name my-let-3 ) using this new notation. First, we have to write aheader for the definition; notice already the explicit parameter: <sc-macro-eg> ::= ( define-syntax ( my-let-3 x ) <sc-macro-eg-body> ) This binds x to the entire (my-let-3 ...) expression. As you might imagine, define-syntax simply tells Racket you\u2019reabout to define a new macro. It does not pick precisely how you wantto implement it, leaving you free to use any mechanism that\u2019sconvenient. Earlier we used syntax-rules ; now we\u2019re going touse syntax-case . In particular, syntax-case needs toexplicitly be given access to the expression to pattern-match: <sc-macro-eg-body> ::= ( syntax-case x ( ) <sc-macro-eg-rule> ) Now we\u2019re ready to express the rewrite we wanted. Previously arewriting rule had two parts: the structure of the input and thecorresponding output. The same holds here. The first (matching theinput) is the same as before, but the second (the output) is a littledifferent: <sc-macro-eg-rule> ::= [ ( my-let-3 ( var val ) body ) #' ( ( lambda ( var ) body ) val ) ] Observe the crucial extra characters: # \u2019 . Let\u2019s examine whatthat means. In syntax-rules , the entire output part simply specifies thestructure of the output. In contrast, because syntax-case islaying bare the functional nature of transformation, the output partis in fact an arbitrary expression that may perform any computationsit wishes. It must simply evaluate to a piece of syntax. Syntax is actually a distinct datatype. As with any distinct dataype,it has its own rules for construction. Concretely, we constructsyntax values by writing # \u2019 ; the following s-expression istreated as a syntax value. (In case you were wondering, the x bound in the macro definition above is also of this datatype.) The syntax constructor, # \u2019 , enjoys a special property. Insidethe output part of the macro, all syntax variables in the input areautomatically bound, and replaced on occurrence. As a result, whenthe expander encounters var in the output, say, it replaces var with the corresponding part of the input expression. Do Now! Remove the # \u2019 and try using the above macro definition. Whathappens? So far, syntax-case merely appears to be a more complicatedform of syntax-rules : perhaps slightly better in that it morecleanly delineates the functional nature of expansion, and the type ofoutput, but otherwise simply more unwieldy. As we will see, however,it also offers significant power. Exercise syntax-rules can actually be expressed as a macro over syntax-case . Define it. 13.3 Guards Now we can return to the problem that originally motivated theintroduction of syntax-case : ensuring that the bindingposition of a my-let-3 is syntactically an identifier. Forthis, you need to know one new feature of syntax-case : eachrewriting rule can have two parts (as above), or three. If there arethree present, the middle one is treated as a guard : apredicate that must evaluate to true for expansion to proceed ratherthan signal a syntax error. Especially useful in this context is thepredicate identifier? , which determines whether a syntax objectis syntactically an identifier (or variable). Do Now! Write the guard and rewrite the rule to incorporate it. Hopefully you stumbled on a subtlety: the argument to identifier? is of type syntax . It needs to refer to theactual fragment of syntax bound to var . Recall that var is bound in the syntax space, and # \u2019 substitutes identifiersbound there. Therefore, the correct way to write the guard is: ( identifier? #' var ) With this information, we can now write the entire rule: <sc-macro-eg-guarded-rule> ::= [ ( my-let-3 ( var val ) body ) ( identifier? #' var ) #' ( ( lambda ( var ) body ) val ) ] Do Now! Now that you have a guarded rule definition, try to use the macro witha non-identifier in the binding position and see what happens. 13.4 Or: A Simple Macro with Many Features Consider or , which implements disjunction. It is natural, withprefix syntax, to allow or to have an arbitrary number ofsub-terms. We expand or into nested conditionals thatdetermine the truth of the expression. 13.4.1 A First Attempt Let\u2019s try a first version of or : ( define-syntax ( my-or-1 x ) ( syntax-case x ( ) [ ( my-or-1 e0 e1 ... ) #' ( if e0 e0 ( my-or-1 e1 ... ) ) ] ) ) It says that we can provide any number of sub-terms (more on this in amoment). Expansion rewrites this into a conditional that tests thefirst sub-term; if this is a true value it returns that value (more on this in a moment!), otherwise it is the disjunction of theremaining terms. Let\u2019s try this on a simple example. We would expect this to evaluateto true , but instead: > (my-or-1 #f #t) my-or-1: bad syntax in: (my-or-1) What happened? This expression turned into ( if #f #f ( my-or-1 #t ) ) which in turn expanded into ( if #f #f ( if #t #t ( my-or-1 ) ) ) for which there is no definition. That\u2019s because the pattern e0 e1 ... means one or more sub-terms, but we ignored thecase when there are zero. What should happen when there are no sub-terms?The identity for disjunction is falsehood. Exercise Why is #f the right default? By filling it in below, we illustrate a macro that has more than onerule. Macro rules are matched sequentially, so we should be sure toput the most specific rules first, lest they get overridden by moregeneral ones (though in this particular case, the two rules arenon-overlapping). This yields our improved macro: ( define-syntax ( my-or-2 x ) ( syntax-case x ( ) [ ( my-or-2 ) #' #f ] [ ( my-or-2 e0 e1 ... ) #' ( if e0 e0 ( my-or-2 e1 ... ) ) ] ) ) which now expands as we expect. Though it isn\u2019t necessary, we willadd a rule for the case when there is only a single sub-term: ( define-syntax ( my-or-3 x ) ( syntax-case x ( ) [ ( my-or-3 ) #' #f ] [ ( my-or-3 e ) #' e ] [ ( my-or-3 e0 e1 ... ) #' ( if e0 e0 ( my-or-3 e1 ... ) ) ] ) ) This keeps the output of expansion more concise, which we will finduseful below. Observe that in this version of the macro, thepatterns are not disjoint: the third (one-or-more sub-terms)subsumes the second (one sub-term). Therefore, it is essential thatthe second rule not swap with the third. 13.4.2 Guarding Evaluation We said above that this expands as we expect.Or does it? Let\u2019s try the following example: ( let ( [ init #f ] ) ( my-or-3 ( begin ( set! init ( not init ) ) init ) #f ) ) Observe that or returns the actual value of the first\u201ctruthy\u201d value, so the developer can use it in furthercomputations. Therefore, this returns the value of init . Whatdo we expect it to be? Naturally, because we\u2019ve negated the value of init once, we expect it to be #t . But evaluating itproduces #f ! This problem is not an artifact of set! . Ifinstead of internal mutation we had, say, printed output, the printingwould have occurred twice. To understand why, we have to examine the expanded code. It is this: ( let ( [ init #f ] ) ( if ( begin ( set! init ( not init ) ) init ) ( begin ( set! init ( not init ) ) init ) #f ) ) Aha! Because we\u2019ve written the output pattern as #' ( if e0 e0 ... ) This looked entirely benign when we first wrote it, but it illustratesa very important principle when writing macros (or indeed any otherprogram transformation systems): do not copy code ! In oursetting, a syntactic variable should never be repeated; if you need torepeat it in a way that might cause multiple execution of that code,make sure you have considered the consequences of this.Alternatively, if you meant to work with the value of theexpression, bind it once and use the bound identifier\u2019s namesubsequently. This is easy to demonstrate: ( define-syntax ( my-or-4 x ) ( syntax-case x ( ) [ ( my-or-4 ) #' #f ] [ ( my-or-4 e ) #' e ] [ ( my-or-4 e0 e1 ... ) #' ( let ( [ v e0 ] ) ( if v v ( my-or-4 e1 ... ) ) ) ] ) ) This pattern of introducing a binding creates a new potential problem:you may end up evaluating expressions that weren\u2019t necessary. Infact, it creates a second, even more subtle one: even if it going tobe evaluated, you may evaluate it in the wrong context!Therefore, you have to reason carefully about whether anexpression will be evaluated, and if so, evaluate it once in just theright place, then store that value for subsequent use. When we repeat our previous example, that contained the set! ,with my-or-4 , we see that the result is #t , as we wouldhave hoped. 13.4.3 Hygiene Hopefully now you\u2019re nervous about something else. Do Now! What? Consider the macro (let ([v #t]) (my-or-4 #f v)) . What wouldwe expect this to compute? Naturally, #t : the first branch is #f but the second is v , which is bound to #t .But let\u2019s look at the expansion: ( let ( [ v #t ] ) ( let ( [ v #f ] ) ( if v v v ) ) ) This expression, when run directly, evaluates to #f . However, (let ([v #t]) (my-or-4 #f v)) evaluates to #t . In otherwords, the macro seems to magically produce the right value: the namesof identifiers chosen in the macro seem to be independent of thoseintroduced by the macro! This is unsurprising when it happens in a function ; the macro expander enjoys a property called hygiene that gives it the same property. One way to think about hygiene is that it effectively automaticallyrenames all bound identifiers. That is, it\u2019s as if the programexpands as follows: ( let ( [ v #t ] ) ( or #f v ) ) turns into ( let ( [ v1 #t ] ) ( or #f v1 ) ) (notice the consistent renaming of v to v1 ),which turns into ( let ( [ v1 #t ] ) ( let ( [ v #f ] ) v v1 ) ) which, after renaming, becomes ( let ( [ v1 #t ] ) ( let ( [ v2 #f ] ) v2 v1 ) ) when expansion terminates. Observe that each of the programs above,if run directly, will produce the correct answer. 13.5 Identifier Capture Hygienic macros address a routine and important pain that creators ofsyntactic sugar confront. On rare instances, however, a developerwants to intentionally break hygiene. Returning to objects, considerthis input program: ( define os-1 ( object/self-1 [ first ( x ) ( msg self ' second ( + x 1 ) ) ] [ second ( x ) ( + x 1 ) ] ) ) What does the macro look like? Here\u2019s an obvious candidate: ( define-syntax object/self-1 ( syntax-rules ( ) [ ( object [ mtd-name ( var ) val ] ... ) ( let ( [ self ( lambda ( msg-name ) ( lambda ( v ) ( error ' object \"nothing here\" ) ) ) ] ) ( begin ( set! self ( lambda ( msg ) ( case msg [ ( mtd-name ) ( lambda ( var ) val ) ] ... ) ) ) self ) ) ] ) ) Unfortunately, this macro produces the following error: self: unbound identifier in module in: self which is referring to the self in the body of the method boundto first . Exercise Work through the hygienic expansion process to understand why error isthe expected outcome. Before we solve this directly, let\u2019s consider a variant of theinput term that makes the binding explicit: ( define os-2 ( object/self-2 self [ first ( x ) ( msg self ' second ( + x 1 ) ) ] [ second ( x ) ( + x 1 ) ] ) ) The corresponding macro is a small variation on what we had before: ( define-syntax object/self-2 ( syntax-rules ( ) [ ( object self [ mtd-name ( var ) val ] ... ) ( let ( [ self ( lambda ( msg-name ) ( lambda ( v ) ( error ' object \"nothing here\" ) ) ) ] ) ( begin ( set! self ( lambda ( msg ) ( case msg [ ( mtd-name ) ( lambda ( var ) val ) ] ... ) ) ) self ) ) ] ) ) This macro expands without difficulty. Exercise Work through the expansion of this version and see what\u2019s different. This offers a critical insight: had the identifier that goes inthe binding position been writtenby the macro user , there would have been no problem. Therefore, wewant to be able to pretend that the introduced identifier waswritten by the user. The function datum->syntax convertsthe s-expression in its second argument; its first argument is whichsyntax to pretend it was a part of (in our case, the original macrouse, which is bound to x ). To introduce the result into theenvironment used for expansion, we use with-syntax to bind itin that environment: ( define-syntax ( object/self-3 x ) ( syntax-case x ( ) [ ( object [ mtd-name ( var ) val ] ... ) ( with-syntax ( [ self ( datum->syntax x ' self ) ] ) #' ( let ( [ self ( lambda ( msg-name ) ( lambda ( v ) ( error ' object \"nothing here\" ) ) ) ] ) ( begin ( set! self ( lambda ( msg-name ) ( case msg-name [ ( mtd-name ) ( lambda ( var ) val ) ] ... ) ) ) self ) ) ) ] ) ) With this, we can go back to having self be implicit: ( define os-3 ( object/self-3 [ first ( x ) ( msg self ' second ( + x 1 ) ) ] [ second ( x ) ( + x 1 ) ] ) ) 13.6 Influence on Compiler Design The use of macros in a language\u2019s definition has an impact on alltools, especially compilers. As a working example, consider let . let has the virtue that it can be compiledefficiently, by just extending the current environment. In contrast,the expansion of let into function application results in amuch more expensive operation: the creation of a closure and itsapplication to the argument, achieving effectively the same result butat the cost of more time (and often space). This would seem to be an argument against using the macro. However, asmart compiler recognizes that this pattern occurs often, and insteadinternally effectively converts left-left-lambda [REF] back into theequivalent of let . This has two advantages. First, it meansthe language designer can freely use macros to obtain a smaller corelanguage, rather than having to trade that off against the executioncost. It has a second, much subtler, advantage. Because the compilerrecognizes this pattern, other macros can also exploit it andobtain the same optimization; they don\u2019t need to contort their outputto insert let terms if the left-left-lambda pattern occursnaturally, as they would have to do otherwise. For instance, theleft-left-lambda pattern occurs naturally when writing certain kindsof pattern-matchers, but it would take an extra step to convert thisinto a let in the expansion\u2014 which is no longer necessary. 13.7 Desugaring in Other Languages Many modern languages define operations via desugaring, not onlyRacket. In Python, for instance, iterating using for is simplya syntactic pattern. A developer who writes for x in o is introducing a new identifier (call it i \u2014 but be sureto not capture any other i the programmer has alreadydefined, i.e., bind i hygienically!), binding it to an iterator obtained from o , and creating a (potentially) infinite while loop thatrepeatedly invokes the .next method of i until theiterator raises the StopIteration exception. There are many such patterns in modern programming languages. \u2190 prev up next \u2192", "https://browncsci1430.github.io/index.html": "This website requires JavaScript to function. const searchParams = new URLSearchParams(window.location.search); const isDevMode = searchParams.has(\"dev\"); // Set this to true to 'fake' pages vs. one big page // i.e., each section of content will appear in a // smaller div and the rest will be removed. // paginate = true was preferred by Prof. Srinath // paginate = false was preferred by Prof. Tompkin for easier CTRL-F // // Spring 2023: James turned this from content being split across real HTML pages to be making <div>s visible/invisible. This let us dynamically paginate without rearranging the actual files to stop from having to swap around the filesystem each time. // const paginate = true; const options = { contentContainer: \"main\", includeCss: false, show: !paginate, // Only show other pages if we aren't paginating }; const optionsHome = { contentContainer: \"main\", includeToc: false, includeCss: false, show: true, }; const contents = [ { path : \"./content/home.md\", divID : \"home-content\", name : \"Home\", options : optionsHome, }, { path : \"./content/schedule.md\", divID : \"schedule-content\", name : \"Schedule\", options : options, }, { path : \"./content/officehours.md\", divID : \"officehours-content\", name : \"Office Hours\", options : options, }, { path : \"./content/assignments.md\", divID : \"assignments-content\", name : \"Assignments\", options : options, }, { path : \"./content/policies.md\", divID : \"policies-content\", name : \"Policies\", options : options, }, { path : \"./content/team.md\", divID : \"team-content\", name : \"Team\", options : options, } ] function setThemeBannerImages() { var db = document.getElementById(\"desktop-banner\") db.src = theme.bannerImageDesktop db.alt = theme.bannerImageAlt var mb = document.getElementById(\"mobile-banner\") mb.src = theme.bannerImageMobile mb.alt = theme.bannerImageAlt } function showItem( contentsItem ) { // On click, hide all the other content divs except the one selected to show. contents.forEach( function(item) { document.getElementById( item.divID ).style.display = 'none'; }) document.getElementById( contentsItem.divID ).style.display = 'block'; } promises = []; contents.forEach( function(item, index) { listItemLink = document.createElement('a') listItemLink.classList.add(\"nav-link\") listItemLink.href = \"#\" + item.divID // // Future TAs: James would prefer you didn't, but if you would like actual HTML pages, // then make some new HTML pages to contain each .md file and link them here. e.g., //listItemLink.href = \"./policies/index.html\" listItemLink.textContent = item.name listItem = document.createElement('li') listItem.classList.add(\"nav-item\") listItem.appendChild( listItemLink ) listItemLink.addEventListener( 'click', function(event) { showItem( item ); }) document.getElementById(\"navbar-ul\").appendChild( listItem ) }) // Add markdown content promises.push( markdown2html( contents ) ); Promise.all(promises).then((responses) => { for (const response of responses) { // Do something with each one as needed } setThemeBannerImages() renderStaffCards() // Turn pages on/off if hashcode exists, e.g., #home-content hashString = document.location.hash.substring(1) hashItem = contents.filter(x => x.divID == hashString ) if( hashItem[0] != undefined ) { showItem( hashItem[0] ) } }) // Enable section highlighting in navbar as user scrolls on page $(\"body\").scrollspy({ target: \"#navbar\", offset: 60 });", "https://cs.brown.edu/courses/cs173/2018/web/mysteries/evaluation-order.xml": "", "https://cs.brown.edu/courses/cs145/": "Home Lectures Assignments Calendar Staff Resources CS1450, Fall 2023, taught by Professor Eli Upfal and Alessio Mazzetto Probability and statistics have become indispensable tools in computer science. Probabilistic methods and statistical reasoning play major roles in machine learning, cryptography, network security, communication protocols, web search engines, robotics, program verification, and more. This course introduces the basic concepts of probability and statistics, focusing on topics that are most useful in computer science applications. Topics include: modeling and solution in sample space, random variables, simple random processes and their probability distributions, Markov processes, limit theorems, and basic elements of statistical inference. This course emphasizes both mathematical rigor and computing applications. For more details, please refer to the course syllabus . We use Ed Stem in this course. You can join it by clicking the \"Ed Discussion\" tab on the canvas page for this course. Please let us know if you can't access Ed Stem. Fall 2023: Lectures will be held in CIT 368.", "https://cs.brown.edu/courses/cs173/2018/web/mysteries/fields.xml": "", "https://cs.brown.edu/courses/cs173/2012/book/": "\u25bc Programming Languages: Application and Interpretation 1 Introduction 2 Everything (We Will Say) About Parsing 3 A First Look at Interpretation 4 A First Taste of Desugaring 5 Adding Functions to the Language 6 From Substitution to Environments 7 Functions Anywhere 8 Mutation: Structures and Variables 9 Recursion and Cycles: Procedures and Data 10 Objects 11 Memory Management 12 Representation Decisions 13 Desugaring as a Language Feature 14 Control Operations 15 Checking Program Invariants Statically: Types 16 Checking Program Invariants Dynamically: Contracts 17 Alternate Application Semantics On this page: Programming Languages: Application and Interpretation Second Edition \u2190 prev up next \u2192 Programming Languages: Application and Interpretation Shriram Krishnamurthi 1 Introduction 1.1 Our Philosophy 1.2 The Structure of This Book 1.3 The Language of This Book 2 Everything (We Will Say) About Parsing 2.1 A Lightweight, Built-In First Half of a Parser 2.2 A Convenient Shortcut 2.3 Types for Parsing 2.4 Completing the Parser 2.5 Coda 3 A First Look at Interpretation 3.1 Representing Arithmetic 3.2 Writing an Interpreter 3.3 Did You Notice? 3.4 Growing the Language 4 A First Taste of Desugaring 4.1 Extension: Binary Subtraction 4.2 Extension: Unary Negation 5 Adding Functions to the Language 5.1 Defining Data Representations 5.2 Growing the Interpreter 5.3 Substitution 5.4 The Interpreter, Resumed 5.5 Oh Wait, There\u2019s More! 6 From Substitution to Environments 6.1 Introducing the Environment 6.2 Interpreting with Environments 6.3 Deferring Correctly 6.4 Scope 6.4.1 How Bad Is It? 6.4.2 The Top-Level Scope 6.5 Exposing the Environment 7 Functions Anywhere 7.1 Functions as Expressions and Values 7.2 Nested What? 7.3 Implementing Closures 7.4 Substitution, Again 7.5 Sugaring Over Anonymity 8 Mutation: Structures and Variables 8.1 Mutable Structures 8.1.1 A Simple Model of Mutable Structures 8.1.2 Scaffolding 8.1.3 Interaction with Closures 8.1.4 Understanding the Interpretation of Boxes 8.1.5 Can the Environment Help? 8.1.6 Introducing the Store 8.1.7 Interpreting Boxes 8.1.8 The Bigger Picture 8.2 Variables 8.2.1 Terminology 8.2.2 Syntax 8.2.3 Interpreting Variables 8.3 The Design of Stateful Language Operations 8.4 Parameter Passing 9 Recursion and Cycles: Procedures and Data 9.1 Recursive and Cyclic Data 9.2 Recursive Functions 9.3 Premature Observation 9.4 Without Explicit State 10 Objects 10.1 Objects Without Inheritance 10.1.1 Objects in the Core 10.1.2 Objects by Desugaring 10.1.3 Objects as Named Collections 10.1.4 Constructors 10.1.5 State 10.1.6 Private Members 10.1.7 Static Members 10.1.8 Objects with Self-Reference 10.1.8.1 Self-Reference Using Mutation 10.1.8.2 Self-Reference Without Mutation 10.1.9 Dynamic Dispatch 10.2 Member Access Design Space 10.3 What (Goes In) Else? 10.3.1 Classes 10.3.2 Prototypes 10.3.3 Multiple Inheritance 10.3.4 Super-Duper! 10.3.5 Mixins and Traits 11 Memory Management 11.1 Garbage 11.2 What is \u201cCorrect\u201d Garbage Recovery? 11.3 Manual Reclamation 11.3.1 The Cost of Fully-Manual Reclamation 11.3.2 Reference Counting 11.4 Automated Reclamation, or GarbageCollection 11.4.1 Overview 11.4.2 Truth and Provability 11.4.3 Central Assumptions 11.5 Convervative Garbage Collection 11.6 Precise Garbage Collection 12 Representation Decisions 12.1 Changing Representations 12.2 Errors 12.3 Changing Meaning 12.4 One More Example 13 Desugaring as a Language Feature 13.1 A First Example 13.2 Syntax Transformers as Functions 13.3 Guards 13.4 Or: A Simple Macro with Many Features 13.4.1 A First Attempt 13.4.2 Guarding Evaluation 13.4.3 Hygiene 13.5 Identifier Capture 13.6 Influence on Compiler Design 13.7 Desugaring in Other Languages 14 Control Operations 14.1 Control on the Web 14.1.1 Program Decomposition into Now and Later 14.1.2 A Partial Solution 14.1.3 Achieving Statelessness 14.1.4 Interaction with State 14.2 Continuation-Passing Style 14.2.1 Implementation by Desugaring 14.2.2 Converting the Example 14.2.3 Implementation in the Core 14.3 Generators 14.3.1 Design Variations 14.3.2 Implementing Generators 14.4 Continuations and Stacks 14.5 Tail Calls 14.6 Continuations as a Language Feature 14.6.1 Presentation in the Language 14.6.2 Defining Generators 14.6.3 Defining Threads 14.6.4 Better Primitives for Web Programming 15 Checking Program Invariants Statically: Types 15.1 Types as Static Disciplines 15.2 A Classical View of Types 15.2.1 A Simple Type Checker 15.2.2 Type-Checking Conditionals 15.2.3 Recursion in Code 15.2.3.1 A First Attempt at Typing Recursion 15.2.3.2 Program Termination 15.2.3.3 Typing Recursion 15.2.4 Recursion in Data 15.2.4.1 Recursive Datatype Definitions 15.2.4.2 Introduced Types 15.2.4.3 Pattern-Matching and Desugaring 15.2.5 Types, Time, and Space 15.2.6 Types and Mutation 15.2.7 The Central Theorem: Type Soundness 15.3 Extensions to the Core 15.3.1 Explicit Parametric Polymorphism 15.3.1.1 Parameterized Types 15.3.1.2 Making Parameters Explicit 15.3.1.3 Rank-1 Polymorphism 15.3.1.4 Interpreting Rank-1 Polymorphism as Desugaring 15.3.1.5 Alternate Implementations 15.3.1.6 Relational Parametricity 15.3.2 Type Inference 15.3.2.1 Constraint Generation 15.3.2.2 Constraint Solving Using Unification 15.3.2.3 Let-Polymorphism 15.3.3 Union Types 15.3.3.1 Structures as Types 15.3.3.2 Untagged Unions 15.3.3.3 Discriminating Untagged Unions 15.3.3.4 Retrofitting Types 15.3.3.5 Design Choices 15.3.4 Nominal Versus Structural Systems 15.3.5 Intersection Types 15.3.6 Recursive Types 15.3.7 Subtyping 15.3.7.1 Unions 15.3.7.2 Intersections 15.3.7.3 Functions 15.3.7.4 Implementing Subtyping 15.3.8 Object Types 16 Checking Program Invariants Dynamically: Contracts 16.1 Contracts as Predicates 16.2 Tags, Types, and Observations on Values 16.3 Higher-Order Contracts 16.4 Syntactic Convenience 16.5 Extending to Compound Data Structures 16.6 More on Contracts and Observations 16.7 Contracts and Mutation 16.8 Combining Contracts 16.9 Blame 17 Alternate Application Semantics 17.1 Lazy Application 17.1.1 A Lazy Application Example 17.1.2 What Are Values? 17.1.3 What Causes Evaluation? 17.1.4 An Interpreter 17.1.5 Laziness and Mutation 17.1.6 Caching Computation 17.2 Reactive Application 17.2.1 Motivating Example: A Timer 17.2.2 Callback Types are Four-Letter Words 17.2.3 The Alternative: Reactive Languages 17.2.4 Implementing Transparent Reactivity 17.2.4.1 Dataflow Graph Construction 17.2.4.2 Dataflow Graph Update 17.2.4.3 Evaluation Order 17.3 Backtracking Application 17.3.1 Searching for Satisfaction \u2190 prev up next \u2192", "https://cs.brown.edu/courses/cs173/2018/web/mysteries/function-calls.xml": "", "https://cs.brown.edu/courses/cs173/2018/web/mysteries/mutable-structures.xml": "", "https://cs.brown.edu/courses/cs173/2018/web/mysteries/mutable-variables.xml": "", "https://cs1420.vercel.app/": "astro-island,astro-slot,astro-static-slot{display:contents} (()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).load=e;window.dispatchEvent(new Event(\"astro:load\"));})();;(()=>{var b=Object.defineProperty;var f=(c,o,i)=>o in c?b(c,o,{enumerable:!0,configurable:!0,writable:!0,value:i}):c[o]=i;var l=(c,o,i)=>(f(c,typeof o!=\"symbol\"?o+\"\":o,i),i);var p;{let c={0:t=>m(t),1:t=>i(t),2:t=>new RegExp(t),3:t=>new Date(t),4:t=>new Map(i(t)),5:t=>new Set(i(t)),6:t=>BigInt(t),7:t=>new URL(t),8:t=>new Uint8Array(t),9:t=>new Uint16Array(t),10:t=>new Uint32Array(t)},o=t=>{let[e,r]=t;return e in c?c[e](r):void 0},i=t=>t.map(o),m=t=>typeof t!=\"object\"||t===null?t:Object.fromEntries(Object.entries(t).map(([e,r])=>[e,o(r)]));customElements.get(\"astro-island\")||customElements.define(\"astro-island\",(p=class extends HTMLElement{constructor(){super(...arguments);l(this,\"Component\");l(this,\"hydrator\");l(this,\"hydrate\",async()=>{var d;if(!this.hydrator||!this.isConnected)return;let e=(d=this.parentElement)==null?void 0:d.closest(\"astro-island[ssr]\");if(e){e.addEventListener(\"astro:hydrate\",this.hydrate,{once:!0});return}let r=this.querySelectorAll(\"astro-slot\"),a={},h=this.querySelectorAll(\"template[data-astro-template]\");for(let n of h){let s=n.closest(this.tagName);s!=null&&s.isSameNode(this)&&(a[n.getAttribute(\"data-astro-template\")||\"default\"]=n.innerHTML,n.remove())}for(let n of r){let s=n.closest(this.tagName);s!=null&&s.isSameNode(this)&&(a[n.getAttribute(\"name\")||\"default\"]=n.innerHTML)}let u;try{u=this.hasAttribute(\"props\")?m(JSON.parse(this.getAttribute(\"props\"))):{}}catch(n){let s=this.getAttribute(\"component-url\")||\"<unknown>\",y=this.getAttribute(\"component-export\");throw y&&(s+=` (export ${y})`),console.error(`[hydrate] Error parsing props for component ${s}`,this.getAttribute(\"props\"),n),n}await this.hydrator(this)(this.Component,u,a,{client:this.getAttribute(\"client\")}),this.removeAttribute(\"ssr\"),this.dispatchEvent(new CustomEvent(\"astro:hydrate\"))});l(this,\"unmount\",()=>{this.isConnected||this.dispatchEvent(new CustomEvent(\"astro:unmount\"))})}disconnectedCallback(){document.removeEventListener(\"astro:after-swap\",this.unmount),document.addEventListener(\"astro:after-swap\",this.unmount,{once:!0})}connectedCallback(){if(!this.hasAttribute(\"await-children\")||document.readyState===\"interactive\"||document.readyState===\"complete\")this.childrenConnectedCallback();else{let e=()=>{document.removeEventListener(\"DOMContentLoaded\",e),r.disconnect(),this.childrenConnectedCallback()},r=new MutationObserver(()=>{var a;((a=this.lastChild)==null?void 0:a.nodeType)===Node.COMMENT_NODE&&this.lastChild.nodeValue===\"astro:end\"&&(this.lastChild.remove(),e())});r.observe(this,{childList:!0}),document.addEventListener(\"DOMContentLoaded\",e)}}async childrenConnectedCallback(){let e=this.getAttribute(\"before-hydration-url\");e&&await import(e),this.start()}start(){let e=JSON.parse(this.getAttribute(\"opts\")),r=this.getAttribute(\"client\");if(Astro[r]===void 0){window.addEventListener(`astro:${r}`,()=>this.start(),{once:!0});return}Astro[r](async()=>{let a=this.getAttribute(\"renderer-url\"),[h,{default:u}]=await Promise.all([import(this.getAttribute(\"component-url\")),a?import(a):()=>()=>{}]),d=this.getAttribute(\"component-export\")||\"default\";if(!d.includes(\".\"))this.Component=h[d];else{this.Component=h;for(let n of d.split(\".\"))this.Component=this.Component[n]}return this.hydrator=u,this.hydrate},e,this)}attributeChangedCallback(){this.hydrate()}},l(p,\"observedAttributes\",[\"props\"]),p))}})(); CS 1420 Home Lectures Assignments Calendar Staff Resources Welcome to CS1420 - Machine Learning! How can artificial systems learn from examples, and discover information buried in massive datasets? We explore the theory and practice of statistical machine learning, focusing on computational methods for supervised and unsupervised data analysis. Specific topics include empirical risk minimization, probably approximately correct learning, maximum likelihood parameter estimation, kernel methods, neural networks, the expectation maximization algorithm, and principal component analysis. Time: 2:30 - 3:50pm, Tue & Thu Location: Metcalf Research Building AUD Announcement Due to a large number of requests, we're asking anyone who is unable to register through C@B to join the waitlist here , in order to allocate any available spots as fairly as we can. There is also a waitlist FAQ available here . Useful Links Waitlist Waitlist FAQ Canvas Page Missive Gradescope TopHat Edstem TA Hours Steve's Hours Anonymous Feedback Steve's Research Group Lectures Time and Location: Tuesday & Thursday, 2:30pm to 3:50pm ET Lecture Recordings: Lecture recordings are available through Canvas Media Library. Schedule Date Topics Book Chapters Notes Thursday, Jan 25 Intro, ERM framework 1, 2.0, 2.1, 2.2 Tuesday, Jan 30 Halfspaces and Perceptron 9.0, 9.1.0, 9.1.2 Thursday, Feb 1 Linear and Polynomial Regression 9.2 Tuesday, Feb 6 Logistic Regression 9.3, 12.1.1, 14.0, 14.1.0 Thursday, Feb 8 SGD, Data Prep, and other Practicalities 14.3.0, 14.5.1 Tuesday, Feb 13 PAC Learning 2.3, 3 Thursday, Feb 15 The Bias-Complexity Tradeoff 5 Tuesday, Feb 20 LONG WEEKEND, NO CLASS Thursday, Feb 22 Model Selection, Validation, and Regularization 11.0, 11.2, 11.3, 13.1, 13.4 Tuesday, Feb 27 Boosting 10 Thursday, Feb 29 Decision Trees 18 Tuesday, Mar 5 Learning via Uniform Convergence 4 Thursday, Mar 7 VC Dimension 6, 9.1.3 Tuesday, Mar 12 Naive Bayes 24.0, 24.1, 24.2 Thursday, Mar 14 K-Nearest Neighbors / Fairness in Machine Learning 19 Tuesday, Mar 19 Support Vector Machines 15 Thursday, Mar 21 Kernel Methods 16 Tuesday, Mar 26 NO CLASS (SPRING BREAK) Thursday, Mar 28 NO CLASS (SPRING BREAK) Tuesday, Apr 2 Neural Networks 20.0, 20.1, 20.2, 20.3 Thursday, Apr 4 Backpropagation 20.6 Tuesday, Apr 9 Deep Learning Thursday, Apr 11 K-Means 22.0, 22.2, 22.5 Tuesday, Apr 16 Expectation Maximization 24.4 Thursday, Apr 18 Principal Component Analysis 23.0, 23.1 Tuesday, Apr 23 Ethics in Machine Learning Thursday, Apr 25 Cutting Edge Machine Learning Homework Policy All assignments are due at 12:00pm noon . Written and programming assignments are to be submitted to Gradescope. See the missive for more information on late days and extensions. Assignments Description Release Due Latex Code Solutions #1. Review, Python Jan 25 Feb 1 Latex Code Solutions #2. Halfspaces, Linear and Polynomial Regression Feb 1 Feb 8 Latex Code Solutions #3. Logistic Regression Feb 8 Feb 15 Latex Code Solutions #4. PAC Learning and the Bias-Complexity Tradeoff Feb 15 Feb 22 Latex #5. Model Selection, Validation, and Regularization Feb 22 Feb 29 Latex Code #6. Boosting and Decision Trees Feb 29 Mar 7 Latex Code #7. Uniform Convergence and VC Dimension Mar 7 Mar 14 Latex #8. Naive Bayes and Fairness Mar 14 Mar 21 #9. SVM and Kernels Mar 21 Apr 4 #10. Neural Networks Apr 4 Apr 11 #11. Deep Learning Apr 11 Apr 18 #12. Clustering Apr 18 Apr 25 #13. Dimensionality Reduction Apr 25 May 2 Final Exam May 16, 12pm noon May 17, 11:59pm Calendar Refer to the calendar below for the most up-to-date lecture and office hour schedule. Meet Our Staff Stephen Bach he/him | Professor \ud83c\udfe0 Providence, RI | \ud83d\udc96 Providence, RI Assistant professor with an awesome team of students. Check out our research group! (link under 'Useful Links') Emily Ye she/her | HTA \ud83c\udfe0 Nothern Virginia | \ud83d\udc96 Shanghai Hi, I'm a senior studying CS + economics! Ask me about Providence cafes, book recs, and the NYT mini :) Kevin Lu he/him | HTA \ud83c\udfe0 New Orleans, LA | \ud83d\udc96 Singapore :) Matthew Meeker HTA \ud83c\udfe0 Milton, GA | \ud83d\udc96 Stockholm, Sweden I'm a senior studying mostly APMA. My interests are in probability, numerics and analysis, and (of course) ML. I play a lot of guitar, own too many hhkb's, and almost studied art history. Aditya Agashe he/him | UTA \ud83c\udfe0 Edison, NJ | \ud83d\udc96 Edison, NJ Hi, I'm Aditya. I'm a junior studying APMA-CS. Alex Liang UTA \ud83c\udfe0 Shanghai, China | \ud83d\udc96 Shanghai, China Hi, I'm a junior studying APMA-CS. I enjoy playing and watching basketball, binging Criminal Minds, and eating any microwave foods. Alex Lin UTA \ud83c\udfe0 Boston, MA | \ud83d\udc96 Seoul, South Korea Hey all, I'm a Junior studying CS. I spend my free time cooking, playing tennis, and learning different languages and eating food from around the world. Andrew Yang he/him | UTA \ud83c\udfe0 Cincinnati, OH | \ud83d\udc96 Cincinnati, OH I am a junior studying applied math and computer science. I am originally from Cincinnati, OH. Jaideep Naik UTA \ud83c\udfe0 South Windsor, CT | \ud83d\udc96 NYC Hey! I'm a sophomore from Connecticut studying APMA + CS. I love playing soccer, hiking, and working out. Johnny Elias he/him | UTA \ud83c\udfe0 Dallas, TX | \ud83d\udc96 Seoul Hey guys! My name is Johnny and I'm a sophomore studying Math and CS. In my free time, I really enjoy photography and studying languages/linguistics! Keitaro Nishijima he/him | UTA \ud83c\udfe0 Tokyo, Japan | \ud83d\udc96 Barcelona, Spain frosted caramel nut espresso! Krishi Saripalli he/him | UTA \ud83c\udfe0 San Jose, CA | \ud83d\udc96 San Francisco, CA I'm a senior studying CS and love tropical fruits Luke Choi he/him | UTA \ud83c\udfe0 Avon, CT | \ud83d\udc96 Seoul, South Korea Hi! I'm a junior studying computer science and math. In my free time, I like to follow football and play Tetris :) Marco Ayala he/him | UTA \ud83c\udfe0 Manila, Philippines | \ud83d\udc96 Manila, Philippines International student from the Philippines! I love tennis and basketball Mason Lee he/him | UTA \ud83c\udfe0 San Diego, CA | \ud83d\udc96 Provy, RI Hi, I'm a junior studying APMA-CS. I like to play soccer and try new foods. Nitin Sreekumar he/him | UTA \ud83c\udfe0 Thiruvananthapuram, India | \ud83d\udc96 Los Angeles, CA Hello! I am a junior studying Biology and Computer Science. I enjoy hiking through the wild and people watching in cities. I hope y'all enjoy the class! Noah Foster he/him | UTA \ud83c\udfe0 San Leandro, CA | \ud83d\udc96 Melbourne, Australia I'm a senior double concentrating in MATH-CS and APMA. My research with Ellie Pavlick and Chen Sun focuses on interpretability in large vision and language models and the implications for multimodal models. Talk to me about 1420 or any vaguely statistical course at Brown! Reggie Zheng he/any | UTA \ud83c\udfe0 Greenville, Mississippi | \ud83d\udc96 Fuzhou, China howdy :D i'm a senior studying cs-apma and a lover of coffee, lowercase letters, and video essays on obscure topics. excited to meet y'all! Sarah Peters she/her | UTA \ud83c\udfe0 Chennai, India | \ud83d\udc96 Rome Always happy to talk about dancing, dogs and all things ML (: Spencer Dellenbaugh he/him | UTA \ud83c\udfe0 Portsmouth, RI | \ud83d\udc96 Auckland, NZ I am a senior studying computer science in the AI/ML and theory tracks. Outside of the classroom I enjoy sailing on Brown's club team, playing games with friends, and building robots. Taishi Nishizawa he/him | UTA \ud83c\udfe0 Tokyo, Japan | \ud83d\udc96 Tokyo, Japan Hi guys, I'm a Senior studying APMA-CS. Outside of CS, I'm into soccer, cars, aquatic animals, and traveling. Excited to meet everyone! Thomas Chang he/him | UTA \ud83c\udfe0 Pittsburgh, PA | \ud83d\udc96 Seoul Hi! I'm a junior studying applied math and computer science. When I'm not in the Sci Li, I love reading or playing the viola. Looking forward to a great semester with everyone! Youjung Koo UTA \ud83c\udfe0 Seoul | \ud83d\udc96 Gyeongju Hey everyone! I'm a data science student with a background in electronic engineering. I enjoy swimming, yoga, and trying out different cuisines. This year, I plan to attend more workshops at the Brown Design Workshop! Zeeshan Bhalwani he/him | UTA \ud83c\udfe0 Canton, MI | \ud83d\udc96 Mumbai Hey everyone! I'm a junior studying CS and also have a passion for finance. In my free time, I enjoy playing basketball, practicing archery, and watching cricket and F1. Emma Huang she/her | STA \ud83c\udfe0 Short Hills, NJ | \ud83d\udc96 San Francisco, CA Hi! I'm Emma, and I'm a junior studying CS and IAPA. I enjoy skiing, anything disco ball themed, olive oil on ice cream, and house music (unironically) :) Julie Qian she/her | STA \ud83c\udfe0 Bay Area, CA | \ud83d\udc96 Marin Headlands, CA butter-toasted multigrain bread + thick layer of goat cheese + roughly chopped blackberries + healthy drizzle of honey = key to my daily happiness Resources Course Documents LaTeX \u00a9 2024 CS1420 TA Staff | Computer Science Department | Brown University Original art by Cindy Zhu", "https://cs.brown.edu/courses/cs173/2018/web/mysteries/numbers.xml": "", "https://cs.brown.edu/courses/cs173/2018/web/mysteries/mystery-setup.xml": "To install the mystery languages, open DrRacket ( Version 7 required!), click on the \"File\" tab in the upper left hand corner, and scroll down to \"Install Package\". In the \"Package Source\" text box, type https://github.com/samwaxman/MysteryLanguages7.git . Below the package source box, click \"Show Details.\" Change the Dependencies Mode to \"Auto + Update: update dependencies whenever possible,\" and then click install. This will install the mystery languages for all of the assignments in this class, so you only need to do this once. Once these are installed, you can run them as language in DrRacket. To do so, create a new file and write #lang <LANG> at the top of the file, where <LANG> is the language to run. For any given assignment, the name of the language will be the name of the assignment in UpperCamelCase/PascalCase. So for assignment \"foo bar,\" you would type #lang FooBar at the top of your program. In addition, if you only wish to work with one language in a language set instead of all of them, you can append an 1-indexed number to the end of the language name. So for Numbers, if you only would like to look at core 1, you can type #lang Numbers1 at the top of your program.", "https://brown-csci1660.github.io": "CS1660: Computer Systems Security About Assignments Lectures Calendar/Hours Staff Resources FAQ About Assignments Lectures Calendar/Hours Staff Resources FAQ window.onscroll = function() {stickyNav()}; var navbar = document.getElementById(\"sticky-nav\"); var navbar2 = document.getElementById(\"sticky-nav-2\"); var offset = navbar.offsetTop + navbar.offsetHeight/2; function stickyNav() { if (window.pageYOffset >= offset) { navbar.style.visibility = \"hidden\"; navbar2.classList.remove(\"hidden\"); } else { navbar.style.visibility = \"visible\"; navbar2.classList.add(\"hidden\"); } } Quick links Zoom : Join lectures here! EdStem : Used for announcements, online questions, etc Gradescope : Submit work here, and receive grades for all assignments Panopto : View lecture recordings here. Hours : Used to manage queuing and links for all one-on-one and remote office hours Administrative Information What's this course about? CS1660 (formerly called CS166) is a course on computer systems security through a balanced mixture of theory and practice. We\u2019ll start out with building the foundations of security through an exploration of cryptography . From there, we\u2019ll move to more complex, multi-faceted systems such as web applications , operating systems , and networks . Along the way, we\u2019ll explore complementary topics such as authentication, physical security, social engineering, privacy, anonymity, usability, and the security of emergent systems such as blockchains and machine learning. By learning about security through these multiple domains, you\u2019ll concretely learn how various classes of attacks appear in a vast variety of scenarios and how they work in practice. You\u2019ll also learn how to evaluate systems adversarially, from writing precise security analyses about subtle issues in protocols to discovering and exploiting vulnerabilities in concrete technical systems for yourself. Through all of these activities, you\u2019ll ultimately work to develop a specific kind of intuition\u2014a \u201csecurity mindset\u201d \u2014that will give you the knowledge, vocabulary, and confidence to critically analyze and effectively defend the software and systems you approach as a computer scientist even after the course. CS1620/CS2660: The Lab We encourage you to take additional half-credit \u201clab\u201d, called CS1620 (for undergraduates) or CS2660 (for master\u2019s graduate students, or concurrent master\u2019s students). Senior undergraduates may use the lab portion to count for their capstone requirement. Students taking the lab have the opportunity to work on advanced challenges that will provide you with a greater appreciation of systems security and the \u201csecurity mindset\u201d as a whole: CS1620/CS2660 provides students with a deeper understanding of the material by doing advanced versions of the CS1660\u2019s projects and advanced questions on the written assignments. These advanced versions focus on real-world skills: performing attacks that are more difficult and rely on less serious vulnerabilities, performing attacks against systems with more real-world constraints, and creating attacks that achieve a higher standard of quality than a mere proof of concept. CS1620 vs. CS2660 : Due to credit-counting logistics, the lab portion of the course has two different course numbers: CS1620 and CS2660. Undergraduate students wishing to do the half-credit lab should sign up for CS1620 in addition to CS1660. CS2660 combines both CS1660 and CS1620 in one, 2000-level course. If you are a graduate student (or an ScB student who has applied for the concurrent CS master's program), and wish to earn 2000-level credit for this course, you should sign up for CS2660 only . What\u2019s the difference? Both CS1620 and CS2660 share the same extra course content, but only CS2660 counts for 2000-level credit. In course materials, we will refer to the lab portion simply as CS1620\u2013this includes both CS1620 and CS2660 students. How much work is the lab? : In previous years, students taking the lab report spending approximately 8\u201320 extra hours on each project throughout the semester, though they also note that the additional components are more front-loaded so the second half of the semester is much more flexible. (We anticipate that this will be the same this year.) You do not need any additional experience beyond the base prerequsites of the course to succeed with the lab-\u2014anyone who feels comfortable taking CS1660 should also feel comfortable taking CS1620/CS2660, so long as you are comfortable with the extra time requirement. Note that students taking CS2660 are committed to completing the requirements for both the lab and main portion of the course\u2013after the add/drop period ends, it is not possible for a CS2660 student to drop the lab portion and still get credit for CS1660 in the same semester. How do I sign up? : If you are interested in the lab portion, undergraduates should register for CS1660 and CS1620 on CAB. Senior undergraduates are eligible to capstone with CS1620\u2014-email the HTA list if you intend to have the lab count for your capstone credit. If you intend to take CS2660, please fill out this form and request an override code on CAB. Registration and Waitlist Interested in taking the course? That\u2019s great! Since our course has multiple sections , all students require an override so that we can make sure everyone is in the correct section. See the following steps for instructions on how to request an override and (if the course is full) join the waitlist. If you are interested in registering, please do the following: Request to register by filling out this form . If the course is full, this will also add you to the waitlist. If you have any particular reasons you want to take the course, please let us know on the form. Please avoid sending us email about this (it will take longer!)\u2013the form is designed to help us process your requests efficiently. You MUST fill out the form to be considered\u2013 we will not consider requests on CAB without an accompanying form response . Add the course to your shopping cart. This will grant you access to EdStem and Gradescope, when they become available at the start of the semester. If possible, attend (in person or via Zoom) the first lecture on Thursday, January 25 or watch the recording as soon as is feasible. How does the waitlist work? Once the course fills up, we will give priority to students who are unable to take the course at another time\u2013otherwise, we admit students on a first-come, first-serve basis. If you have any strict program requirements or other constraints that limit when you can take the course, please indicate this in your form response. If you already responded and need to edit your response, you can do so by clicking on the form link again. What are my chances? We hope to admit around 90-100 students across all sections of CS1660 and CS2660. While we cannot officially guarantee that all students on the waitlist will be able to take the course, we have typically been able to accommodate all students by the end of shopping period. Prerequisites You should have an intro-sequence\u2019s worth of programming experience ( 0160 , 0180 , or 0190 ) and have a good understanding of systems programming ( 0300 , 0330 , 1310 , or 1330 ). This concretely means that: You should be comfortable writing programs and scripts in a language of your choice (such as Python, Ruby, Bash, Go, C++, etc.), be somewhat comfortable in a Unix command-line environment (running binaries, filesystem navigation, etc.) and have a basic understanding of systems programming concepts such as memory management and networking. You also should have heard of the terms \u201crace condition\u201d, \u201cpacket\u201d, \u201cTCP\u201d, \u201cUDP\u201d, \u201cbuffer overflows\u201d, and \u201cDNS\u201d. (If you forget what these are, don\u2019t worry\u2014we\u2019ll describe them again when they come up in the latter half of the course.) You should also be willing to learn how to read code in languages that you\u2019ve never used before. We will gain practice with this throughout the course as we learn about securing systems in many areas. If you don\u2019t meet the official prerequisites but still want to take the course, please consult the instructors during shopping period . We are happy to discuss your individual situation to determine if the course is right for you! Your willingness to challenge yourself is perhaps the most important prerequsite for the course. Security can be frustrating at times, but the rewards are great. In exchange for engaging with some difficult intellectual challenges, you\u2019ll have the opportunity to gain concrete insights about systems and security and become a better computer scientist along the way! Lecture Policy We will have live lecture on Tuesdays and Thursdays @ 2:30pm - 3:50pm ET in person at CIT 368 and on Zoom via this link . All lectures will be recorded and will be posted on Panopto within 24 hours of the lecture. Attendance : Students are encouraged to attend lecture in-person or synchronously via Zoom, though this is not required. Attendance does not impact your course grade. Lecture may use TopHat questions to poll students during class\u2013these are optional and are only used to gauge your understanding during class. TopHat responses have no impact on your course grade. Asking Questions : We encourage students to ask questions in class, either by raising your hand (either in person, or as a reaction or chat message in Zoom). If you are participating remotely, we will ask you to unmute and ask your question. Recordings: : All lectures will be recorded. Recordings and any notes/slides from lecture will be made available within 24 hours of the lecture date in Panopto . During shopping period , students who are interested in CS1660 must have the course in their primary cart in order to have access to Panopto. Office Hours We are happy to work with you in office hours to help with understanding any course concept or homework/project work. We are happy to help with planning how to approach problems, working with tools, figuring out how to debug your work, or reviewing concepts from lectures/homework assignments. In order to make office hours accessible to as many students as possible, we are holding hours in two formats: Collaborative hours (in-person or hybrid): Most hours will be collaborative hours. In this format, simply come to the designated room and members of the course staff will circulate and take questions. Some collaborative sections can support remote students in a hybrid format, as indicated on the calendar . Remote students may join via Zoom using the (available on the Hours platform )\u2013a dedicated staff member will talk with everyone on Zoom in parallel with in-person discussion. In collaborative hours, you are welcome to stay and work and ask questions as they come up\u2013this is meant to create a space where you can meet and collaborate with your peers, while course staff is available to help you get \u201cunstuck\u201d, or explain a concept to a group if you encounter a problem. We can provide all forms of help during this time, including debugging or help with concepts. Some projects (notably Flag and Handin) may have certain restrictions on what can be discussed during collaborative hours\u2013more information will be provided when these assignments are released. Individual, queue-managed (remote): This is the standard format at Brown. When the hour begins, a queue will appear on the Hours platform designated for our course. Whether you are in-person or remote, simply join the queue! When your turn comes up, you will receive a Zoom link to talk with a member of the course staff. Course staff may limit the amount of time one person may spend with a TA (i.e. ~10-15 minutes), especially during peak times. As the semester progresses, we may make adjustments to the balance of remote/in-person/hybrid hours or the mechanics of the different formats based on student and TA feedback. If you have thoughts on your experience in hours, please fill out our Anonymous Feedback Form ! Collaboration The Collaboration Policy is available as a separate document. Please read this policy, as it may differ significantly from other courses you have taken. By submitting any assignment, you agree to abide by the collaboration policy. If you have any questions, please ask on Edstem . Late Policy Students are have five (5) late passes to use on homeworks and projects, though no more than two (2) late passes may be applied to any deadline. Each late pass extends the deadline by one day. Weekends and University holidays (long weekend, spring break, etc.) do not count towards lateness or use of late passes\u2013in other words, a late submission for an assignment due on Friday at 11:59pm and submitted before Monday at 11:59pm is considered one day late. Accordingly, the last day the assignment could be submitted would be Tuesday at 11:59pm (which would be days late). If you have no more late passes, each day a project or homework is submitted late will subtract 20% from that assignment\u2019s grade. Project 4 is a partner project that contains multiple deadlines. Late passes may not be applied to the intermediate deadlines of Project 4. On the final deadline, your group will be allowed to use the minimum of you and your partner\u2019s remaining late days (up to a maximum of two, as for all assignments). Late passes and penalties are automatically applied at the end of the semester in an optimal fashion; that is, we will apply late passes in such a way that gives you the highest grade. CS1620 and CS2660 students receive two additional late passes (seven total). However, students who drop CS1620 lose the additional passes and receive late penalties under the default CS1660 policy. Extenuating circumstances : If there are extenuating circumstances preventing you from completing an assignment on time (e.g., illness), you may use to request an extension (without using late days), most preferably before the assignment is due. In these situations, please contact the instructors as soon as it is feasible for you to do so using this form . This form is not meant to be impersonal\u2013we simply want to make sure we can keep track of any requests! Please note that only the instructors are authorized to grant extensions for the course. The Head TAs and UTAs cannot approve, or comment on the likelihood of, extension requests. All assignments have a due time of 11:59 PM ET. See this section for information on the course late policy. Homeworks Out In Resources Homework 0 Jan 25 Jan 30 Homework 1 Feb 9 Feb 23 Burp suite lab Homework 2 Mar 4 Mar 14 Homework 3 TBA TBA Homework 4 TBA TBA Projects Out In Resources Project 0: Setup Jan 27 Feb 5 Project 1: Cryptography Feb 2 Feb 16 Gearup notes Gearup recording Project 2: Flag Feb 22 Mar 7 Setup guide Flag Wiki Lecture demos Gearup notes Gearup recording Project 3: Handin Mar 8 Mar 22 Setup guide Handin Wiki Autograder source code OS Lecture demos Project 4: Dropbox Apr 2 May 1 Logistics: Lectures take place on Tuesdays and Thursdays at 2:30pm ET in person at CIT 368 and on Zoom . Lecture recordings are available on Panopto within a few hours of the lecture time. Please note that this schedule is subject to change. Jan 25 Lec 1. Course Intro: Logistics, Security Principles Lecture notes Textbook chapters: 1.1, 1.3.1, 1.3.3, 1.3.4, 1.4 w/ Nick Jan 30 Lec 2. Cryptography I: Confidentiality (Intro) Lecture notes Textbook chapters: 8.1.1, 8.1.2, 8.1.3, 8.1.4, 8.1.6, 8.1.7, 8.3 Birthday survey In-class demo: OTP - Imperfect Randomness In-class demo: OTP - Key Reuse Reading: \u201cThe two-time-pad\u201d Reading: \u201cWhy is 2^256 secure?\u201d w/ Bernardo Feb 1 Lec 3. Crypto II: Confidentiality (in practice) Lecture notes Textbook chapters: 1.3.2, 1.3.5, 8.2.1, 8.2.2, 8.4 (except 8.4.2), 7.1.2 In-class demo: ECB vs CBC Reading: A GIF which displays its own MD5 hash Reading: \u201cA Stick Figure Guide to AES\u201d Reading: Sections 3\u20135 of \u201cMove Fast and Roll Your Own Crypto: Zoom\u201d, which describes Zoom\u2019s use of ECB mode for video and audio w/ Bernardo Feb 6 Lec 4. Crypto III: Integrity, Authentication I Lecture notes Textbook chapters: 1.4.2 Reading: Sections 1\u20132 and 4\u20137 of \u201cDefective Sign & Encrypt\u201d w/ Bernardo Feb 8 Lec 5. Crypto IV: Human authentication, Passwords Lecture notes Textbook chapters: 7.1, 7.2.3 w/ Bernardo Feb 13 Lec 6. Crypto V: Password mechanics and password cracking w/ Bernardo Feb 15 Lec 7. Web Security I: Intro to the web: Resources and Origins Lecture notes Textbook chapters: 7.1, 7.2.3-7 In-class demo: Client-Side Checks on WebGoat (w/ Bernardo) Reading: Same-origin policy w/ Bernardo Feb 22 Lec 8. Web II: Securing requests: Cross-Site Request Forgery, CORS, CSP Lecture notes Textbook chapters: 7.2.6, 7.3.3 In-class demo: CSRF example Reading: \u201cCross Site Request Forgery (CSRF)\u201d on OWASP Reading: \u201cA new default Referrer-Policy for Chrome\u201d Reading: \u201cCSRF\u201d from the CS166 Flag Wiki Reading: \u201cContent Security Policy\u201d w/ Nick Feb 20 No class, Long weekend Feb 27 Lec 9. Web III: Code as data: SQLI, XSS Lecture notes Textbook chapter: 3.3.2 In-class demo: XSS example Reading: \u201cCross-Site Scripting (XSS)\u201d from the CS166 Flag Wiki w/ Nick Feb 29 Lec 10. Web IV: More code injection and defenses Lecture notes In-class demo: SQLI example Reading: \u201cSQL Injection\u201d from the CS166 Flag Wiki Reading: \u201cPassword max length limits are dumb (but we need them)\u201d w/ Nick Mar 5 Lec 11. Web V: Modern Web Frameworks, Disclosure w/ Nick Mar 7 Lec 12. Operating Systems: Intro, Privileges Lecture notes Textbook chapter: 3 Reading: CS166 Handin Wiki w/ Nick Mar 12 Lec 13. OS II: Scripting and Privilege Escalation w/ Nick Mar 14 Lec 14. OS III: Isolation and Sandboxing w/ Nick Mar 19 Lec 15. OS IV: Supply chain and boot security w/ Nick Mar 21 Lec 16. OS V: Mobile OS Security Textbook chapter: 6.1 w/ Nick Mar 26 No class (Spring break) Mar 28 No class (Spring break) Apr 2 Lec 17. Storage Encryption, Cloud platform security Cloud security notes Textbook chapters: 7.1.2, 8.2.4 w/ Bernardo & Nick Apr 4 Lec 18. Networks I: Intro, Scanning w/ Bernardo Apr 9 Lec 19. Networks II: Low-level attacks w/ Bernardo Apr 11 Lec 20. Networks III: DNS, DDoS, Botnets w/ Bernardo & Nick Apr 16 Lec 21. Networks IV: TLS, Certificates w/ Bernardo & Nick Apr 18 Lec 22. Networks V: Tor, Firewalls, Intrusion detection Preview: notes on Tor \u201cIn-class demo: Scanning, Tor\u201d w/ Bernardo & Nick Apr 23 Lec 23. AI / ML security w/ TBA Apr 25 Lec 24. Physical Security and Lockpicking \u201cIn-class demo: Lockpicking, USB Rubber Ducky\u201d w/ Bernardo For information about office hours formats and policies, see here . Calendar not loading? Make sure that you are signed into your Brown University Google account in this browser, then do a hard refresh Otherwise, click here to view the calendar in another page. All emails below have a @cs.brown.edu suffix, though please do not write to individual course staff unless they have asked you to do so. For sensitive matters, please contact the instructors cs1660-profs@lists.brown.edu . Requests for extensions should be directed to the instructors---HTAs or UTAs cannot grant extensions. Bernardo Palazzi bernardo@cs - Instructor - he/him If you look hard enough around the spaceship, you might just find a clue... Nick DeMarinis ndemarin@cs - Instructor - he/him Hello! I\u2019m a lecturer in CS, and not so long ago I was a TA and PhD student at Brown. When I\u2019m not teaching, I like to think about how to make systems and networks more secure. Outside of work, I enjoy climbing, baking, and board games. Rhea rgoyal6@cs - HTA - she/her Hi! I'm a senior studying CS, and I like baking, basketball, and video games. Siming Feng sfeng22@cs - HTA - he/him I'm into gaming, photography, and cooking :P Chen Wei cwei24@cs - UTA - she/her Hey! I'm a second-year master's student from Nanjing, China, studying CS. Outside of class, I love rock climbing, debating, trying different foods, and taking random city walks~ There's a chance we might meet on the street or in the rock climbing gym :). Min Kang mkang30@cs - UTA - he/him Hi, I am a senior studying CS. Outside of class, I love spending time watching NBA or EPL. I am a huge Chelsea fan, so let me know if you are one of the Blues. Oren okohavi@cs - UTA - he/him Hi, I'm Oren! I'm a senior from California studying focusing on systems & security. I'm usually playing board games, watching shows, or stealing cookies \ud83d\ude08 Rosalie Li cli248@cs - UTA - she/her Hi, I study CS in system track. I am a lover for movies, ice cream, and snow boarding. Excited to meet you all! Sedong Hwang shwang31@cs - UTA - he/him Hello! Let's accomplish some cool things in this life. Yuntian Yang yyang324@cs - UTA - he/him Hello! I'm a second-year master student in Computer Science, diving into systems. Outside of coding, I like video games and outdoor adventures. Lately, I've been capturing these moments with my camera and drone. Resources Course Documents All students are responsible for the contents of the following documents and registering for the following external services used in the course: Syllabus and Collaboration Policy : All students are required to read the Syllabus and Collaboration Policy . By working on any assignment in this course, you agree to the contents of both documents. Textbook : The textbook for the course is Introduction to Computer Security by Michael T. Goodrich and Roberto Tamassia, 1st Edition . The lecture schedule includes supplementary readings from the textbook, which is available in the Brown University Library . Students are not required to purchase this textbook to participate in the course. Gradescope : We use Gradescope for collecting certain assignments and grade distribution. We add students to our Gradescope page manually based course registration\u2014if you\u2019re trying to hand in but aren\u2019t able to access the page, please email the HTA list. Edstem : Join our Edstem board to ask questions about course content (see the Collaboration Policy for question guidelines). The course staff will also post announcements and assignment clarifications to this board. All Edstem questions must be posted privately by default, though the course staff will make posts public when necessary. Forms Extension Requests : If there are extenuating circumstances preventing you from completing an assignment on time (e.g., illness), you may use this form to request an extension (without using late days), most preferably before the assignment is due. Anonymous Feedback : If you have feedback that you\u2019d wish to share anonymously, you can use this form . Emails are tracked on this form, but these email addresses cannot be viewed by the course staff (including the professor) and are only viewable by Thomas Doeppner (Director of Undergraduate Studies). Technical resources Resources for Go Some of projects have stencils provided in Go, which is a systems programming language that students report is relatively easy to pick up in a class setting. Learning Go is not required for this class, but, if you\u2019re interested, this may be a good opportunity to pick it up! Here are our favorite resources about Go: A Tour of Go is an interactive, concise introduction to the Go programming language. We highly recommend it for new (and inexperienced) learners of Go; it provides an overview of all of its major language features, including the unique concurrency model. Go By Example is a hands-on introduction to Go with annotated example programs, with nice snippets of idiomatic Go code implementing various different programming constructs, from file I/O to channel synchronization. The Go blog provides more in-depth articles on specific features within Go. We recommend it if you want to learn certain aspects of Go more in-depth; for example, we found the blogs on slices , errors , and project organization quite helpful. This repository provides some examples of a \u201cstandard\u201d package layout (note that many people, including the Go tech lead , object to this structure; we provide it here simply for inspiration). Another package layout resource is this blog post . Department Resources Diversity and Inclusion : In addition to the following resources, you can email the Student Advocates for Diversity & Inclusion at diversity.advocates@lists.cs.brown.edu : Diversity and Inclusion at Brown CS Responsible CS Program Health and Wellness : In addition to the following resources, you can email the Student Advocates for Health & Wellness at wellness.advocates@lists.cs.brown.edu : Health and Wellness at Brown CS Ergonomic Equipment Rental Student Groups : The department sponsors or is affiliated with several student groups: CS for Social Change : Focuses on the intersection of computer science and social impact. CS DUG (Department Undergraduate Group) : Seeks to increase undergraduate participation in the department and continue the Brown legacy of involved undergraduates. Mosaic+ : Student-led diversity initiative to create an inclusive space for racially and ethnically underrepresented minority (URM) students. oStem@Brown : Student group that aims to empower LGBTQ people studying or working in STEM fields to succeed personally, academically, and professionally. WiCS (Women in Computer Science) : Student group that aims to support and increase the participation of women in the field of Computer Science. Full Stack @ Brown : A Brown University club committed to promoting the education of full stack software engineering by working on applications for the Brown community and beyond. University Resources Writing Center : The Writing Center offers free consultations for students who would like to improve the quality of their writing; this is relevant in CS1660 since the written components of the course involve communicating complex technical ideas clearly, concisely, and precisely. Appointments can be scheduled on the Writing Center website or by emailing writing_center@brown.edu . CAPS (Counseling and Psychological Services) : If you feel yourself falling behind, needing to talk to someone about personal problems, or, in general, want a supportive ear, you may find CAPS helpful\u2014they provide a range of mental health services to the Brown community. The office can be reached at 401-863-3476 or counseling@health.brown.edu . SAS (Student Accessibility Services) : Brown University is committed to full inclusion of all students. Students who, by nature of a documented disability, require academic accommodations should contact the professor. The staff of the SAS office can be reached at 401-863-9588 or seas@brown.edu to discuss the process for requesting accomodations. Ombudsperson Office : The Ombuds Office provides a safe, informal, and confidential service independent from the University administration for students involved in a University-related problem (academic or administrative), acting as a neutral complaint resolver and not as an advocate for any of the parties involved in a dispute. The Ombudsperson can provide information on policies and procedures affecting students, facilitate students\u2019 contact with services able to assist in resolving the problem, and assist students navitgate conflicts concerning improper application of University policies or procedures. All matters referred to this office are held in strict confidence (with the exception of cases where there appears to be imminent threat of serious harm). Student Support Services : Student Support Services assists students with a wide-range of issues and concerns that might arise during their time at Brown. The Student Support Services Deans provide 24-hour crisis services for undergraduate, graduate, and medical students with personal or family emergencies, and are available by appointment to consult with individual students about their personal questions/concerns, thus allowing students to succeed and thrive in their academic pursuits. Administrator on Call : The Student Support Services office manages Brown\u2019s Administrator On Call (AOC) system which provides a mechanism for Brown students to seek assistance in emergency situations after business hours. An AOC is able to respond to students, connect them with resources and referrals, consult with colleagues as needed, and gather information for additional follow-up during business hours. To reach the AOC, call 401-863-3322 and ask to speak to the Administrator-On-Call. FAQs What\u2019s the difference between 1660 and {1510, 1650, 1800, 2390}? Each of these courses cover relatively disjoint material, and you\u2019ll learn completely different things in all of them. (If you haven\u2019t taken any of them\u2014great! CS1660 is a great introduction to the field, and you\u2019ll learn a lot through this course. If you have taken a subset of these courses\u2014also great! A lot of CS1660\u2019s material will still be new to you, and all of these courses are useful in terms of honing your security mindset for the long-term.) 1510 focuses on cryptography from a theoretical and more formal perspective by building on the concepts learned in 1010 and involves proving that cryptosystems are secure under defined, precise notions of security. In comparison, 1660 looks at a small slice of applied cryptography, and we generally assume the cryptographic tools that we\u2019re using are \u201csecure\u201d. We instead focus on the practical applications of conventional cryptography as it applies to computer systems. 1650 is a deep-dive into software security , which focuses on low-level memory vulnerabilities (i.e. on the stack), and coursework primarily focuses on developing attacks. In comparison, 1660 looks at higher-level abstractions (cryptography, browser and web applications, networks, etc.) and principles of systems security. Our coursework also focuses on a mix of discovering attacks and designing defenses. (We don\u2019t really look at software security / stack-based code execution vulnerabilities at all.) 1800 looks at cybersecurity from a more historical and policy-driven perspective. In comparison, 1660 motivates much of its content with historical examples (but is primarily about technical details). 2390 is about privacy engineering\u2014making sure that the data is either not collected in the first place or, if collected, not misused. In comparison, 1660 focuses on the whole of the \u201cCIA\u201d mnemonic of \u201cconfidentiality\u201d, \u201cintegrity\u201d, and \u201cavailability\u201d; some of the techniques used in privacy engineering overlap with 1660 content, but our usage and analysis of those techniques differs. Can I use this course as a ugrad capstone? If you\u2019re a 7th semester (or greater) undergraduate, then you can use CS1660 as a capstone by completing the lab . To do this, you must register for CS1620 or CS2660, and you need to email the HTA list to indicate that you want to use this course for your capstone requirement. Can I use this course for 2000-level credit? If you\u2019re a graduate student, or an ScB student who has applied for the concurrent master\u2019s program in CS, you can obtain 2000-level credit by completing the lab . To do this, you must register for CS2660 : CS1620 does not count for 2000-level credit. One caveat: note that if you are taking CS2660, you must complete both the lab and main portion of the course in order to receive a grade\u2013after the add/drop period ends, it is not possible for a CS2660 student to drop the lab portion and still get credit for CS1660. Do I have to attend lectures synchronously? See Lectures . If you have a time conflict with the lectures, you may enroll by registering for the remote section (S02). If you need to do this, please indicate it on your registration form . Can I audit the course? Students wishing to officially audit the course (ie, to receive a grade of \u201cAudit\u201d on their transcript) must achieve an overall passing grade, which usually requires completing a minimum version of all projects. Due to the time required to complete the projects (see the syllabus for a breakdown), students rarely choose to audit the course officially. If you simply want to follow along with the material, any student at Brown may do so without officially registering: all lecture materials, notes, and recordings are always available to any student with a Brown University account, even after the course ends. If you are considering auditing, or if you have trouble accessing any course resources, please contact the instructors. Brown University Department of Computer Science (Spring 2024) This website was designed by zespirit . It\u2019s built on top of Jekyll , a static site generator. The text scanning effect at the top of the page uses TypewriterJS . The elevator feature uses Elevator.js . Fonts used are Jost , Alegreya , Iosevka Term , and In your face, joffrey! . Syntax highlighting provided by Rouge . When you stand on the shoulders of giants, you can see really far. Special thanks to the staff members from the fifteen previous offerings of the course: Aaron Gokoslan ( agokosla ), Aaron Myers ( atm ), Abigail Siegel ( as130 ), Adam Horowitz ( ahorowi2 ), Ahmad Mahmoody ( ahmad ), Alex Light ( allight ), Alexander Heitzmann ( aheitzma ), Ali Ozler ( aozler ), Andrej Simeski ( asimeski ), Andy Donzelli ( adonzell ), Anne Rothen ( arothen ), Aurojit Panda ( apanda ), Babi Papamanthou ( bpapaman ), Bernardo Palazzi ( bernardo ), Chanel Johnson ( cjohns18 ), Charles Somerville ( csomerv1 ), Charlotte Whatley ( cwhatley ), DJ Hoffman ( dj ), Dan Haugh ( dhaugh ), Dan Kuebrich ( dkuebric ), Danfeng Yao ( dyao ), David Kilian ( dkilian ), Douglas McErlean ( dmcerlea ), Erica Li ( eli32 ), Evgenios Kornaropoulos ( evgenios ), Foteini Baldimtsi ( foteini ), Gal Peleg ( gpeleg ), Giselle Lillie ( glillie ), Gregory Thompson ( gnthomps ), Hannah Baackmann-Friedlaender ( hbaackma ), Hannah Chow ( hchow ), Harjasleen Malvai ( hmalvai ), Harrison Xu ( hxu6 ), Isaac Semaya ( isemaya ), Jacob Baskin ( jbaskin ), Jake Ellis ( jte ), James Kelley ( jakelley ), Jason Fedor ( jfedor ), Jearson Alfajardo ( ja43 ), Jeffrey Pfau ( jpfau ), Jennie Rogers ( jennie ), Jeremy Tong ( jwtong ), Jian Cong Loh ( jloh4 ), Jimmy Kaplowitz ( jk ), Jingyiping Zhang ( jzhang12 ), Joel Weinberger ( jweinber ), John Boreiko ( jboreiko ), Jonah Stanley ( jms11 ), Jonathan Natkins ( jnatkins ), Jonathan Sailor ( jon ), Josh Brown ( jwsbrown ), Joshua Liebow-Feeser ( jliebowf ), Julia Kim ( jjk8 ), Justin Bisignano ( jtbisign ), Justin Brower ( jbrower ), Kento Nambara ( knambara ), Kimberly Le ( kle2 ), Leo Meyerovich ( lmeyerov ), Lilika Markatou ( emarkato ), Linda Park ( lpark ), Marcus Mitchell ( mmitch15 ), Mariya Gedrich ( mgedrich ), Matthew Milano ( matthew ), Memo Beltran ( gbeltran ), Mike Shim ( ssh ), Milla Shin ( mshin7 ), Natalie Roe ( nroe ), Nathan Partlan ( npartlan ), Neal Poole ( neal ), Nick Ratchev ( nratchev ), Nina Polshakova ( npolshak ), Nisha Khater ( nkhater ), Olin Gay ( ogay ), Olivia Langley ( olangley ), Oussama ben Abdelbaki ( obenabde ), Pablo Meier ( pmeier ), Priya Lotun ( dlotun ), Rathanak Chhay ( rchhay ), Roberto Tamassia ( rt ), Samuel Boger ( sboger ), Saurya Velagapudi ( svelagap ), Scott Kidd ( shkidd ), Sean Murray ( sem1 ), Shawna Huang ( shuang19 ), Sierra Rowley ( srowley2 ), Willem Speckmann ( wspeckma ), William Schor ( wschor ), Yaou Wei ( yawei ), Zach Dixon ( zdixon ), Zachary Espiritu ( zespirit ), Zachary Kirschenbaum ( zkirsche ), Zachary Zagorski ( zzagorsk ), Zoe Stoll ( zstoll )", "https://cs.brown.edu/courses/cs173/2020/policy.html": "\u25bc Fall 2020: Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Credits \u25ba Syllabus and Course Policies 1 Basic Course Information 2 Course Goals and Learning Objectives 3 Keeping Current and Contacting Us 4 Class Meeting Times 5 Assignments and Exams 6 Anonymous Submissions 7 Time Allocation 8 Grades 9 Grading Personnel 10 Books and Materials 11 Technologies and Sites 12 Hybrid Meetings / Accessibility / Class Recording 13 Timeliness 14 Due Dates 15 Academic Integrity 16 Capstone 17 Unusual Assignments 18 Legal and Ethical Issues 19 In- Class Electronics Use 20 Diversity and Professionalism 21 Semi- Anonymous Feedback 22 Counseling On this page: 1 Basic Course Information 2 Course Goals and Learning Objectives 3 Keeping Current and Contacting Us 4 Class Meeting Times 5 Assignments and Exams 6 Anonymous Submissions 7 Time Allocation 8 Grades 9 Grading Personnel 10 Books and Materials 11 Technologies and Sites 12 Hybrid Meetings / Accessibility / Class Recording 13 Timeliness 14 Due Dates 15 Academic Integrity 16 Capstone 17 Unusual Assignments 18 Legal and Ethical Issues 19 In- Class Electronics Use 20 Diversity and Professionalism 21 Semi- Anonymous Feedback 22 Counseling \u2190 prev up next \u2192 Syllabus and Course Policies 1 Basic Course Information 2 Course Goals and Learning Objectives 3 Keeping Current and Contacting Us 4 Class Meeting Times 5 Assignments and Exams 6 Anonymous Submissions 7 Time Allocation 8 Grades 9 Grading Personnel 10 Books and Materials 11 Technologies and Sites 12 Hybrid Meetings / Accessibility / Class Recording 13 Timeliness 14 Due Dates 15 Academic Integrity 16 Capstone 17 Unusual Assignments 18 Legal and Ethical Issues 19 In-Class Electronics Use 20 Diversity and Professionalism 21 Semi-Anonymous Feedback 22 Counseling 1 Basic Course Information Please follow these links for relevant information: Course Instructor ClassTimetable : note that the lecture schedule is highly tentative andsubject to change, especially as the class adopts to virtual and hybridformats; however, we are committed to the assignment dates 2 Course Goals and Learning Objectives Artists, engineers, poets: all create things. Creators often develop anintimate understanding of the materials and media they work with; this helpsthem better understand the creations of others and better able to create newartifacts themselves. For us who write programs, our primary medium is the programming language. Somelanguages help us write certain kinds of (good) programs better; otherlanguages prevent us from writing certain kinds of (bad) programs at all. Somelanguages focus on unfettered freedom; others try to find strong compromisesbetween expression and constraint. Understanding these trade-offs helps usbetter understand computation itself, and makes us better programmers. This course provides you with a framework to gain this understanding. I hope itwill help you to: learn about the basic building blocks of modern programminglanguages; use these building blocks to compare and contrast the languages youencounter (and also to prepare you for the languages you will build!); andreflect on the relationship between languages and programming (and, in somecases, programmers). 3 Keeping Current and Contacting Us You must subscribe to and follow the course\u2019s Piazza board . You are welcome to post questions to the board. When you do, unless you have aparticularly good reason for doing so, please make your question privateto the course staff . If we feel the question is of general interest, we maychoose to make it public. Please contact us solely through Piazza unless you have a very good reason notto. You are, of course, welcome to write course staff directly if you want todiscuss a private matter. However, please do not write to staffindividually for help with coursework: those requests should all go throughPiazza. 4 Class Meeting Times This class is listed as hybrid . That means we will try to havein-person meetings as much as possible. The class currently has seven sections listed on CAB. The seventh isvirtual. The other six will meet in rotation. In one week, A will come on Monday, B onWednesday, and C on Friday; the next week, D on Monday, E on Wednesday, and Fon Friday; then we cycle back to A. That way, you will get an in-person classat least every two weeks. This allocation is tentative. The course\u2019s in-person enrollment may bemuch lower than the amount of capacity this creates. If so, we\u2019ll merge thesections. For instance, if we only fill three sections, then each section cancome to class once a week. If we only fill one section, then you can come toclass every day! Of course, virtual students will also be supported. Whether you are virtualbecause you are physically remote or don\u2019t wish to attend, that\u2019s your choice andyou don\u2019t owe us any explanation. 5 Assignments and Exams The Assignments are divided into four threads: Quizius Mystery Languages Implementation Reflection Each thread has a different set of tools and techniques. To avoid making thisdocument overwhelmingly long, each of them will be explained along the way inthe assignments. The course has no exams. 6 Anonymous Submissions We expect you to submit all your work anonymously . This is to eliminatebiases (both positive and negative) when grading, based on attributes such asrace, gender, or even how you present yourselves in person. To make clear we are serious, we will impose a small penalty if you do includepersonal identifying information (unless asked to). The penalty will escalateif you keep repeating this mistake. Turning in work without your name on it may run contrary to what you\u2019ve beentold by countless prior instructors. However, because you\u2019re turning in workelectronically, not on paper, there is no danger we will \u201close track\u201d ofwhose work it is. 7 Time Allocation The work load in the course is quite uniformly distributed across thesemester. Students can expect to spend about 10 hours each week onassignments. Combined with the 2.5 hours spent per week in class, thistranslates to approximately 180 hours over the course of the semester. 8 Grades I hope you are, or will become, as passionate about programming languages as Iam. Still, I recognize that students have different goals and constraints, andnot everyone can afford to immerse themselves fully in this course. You stilldeserve a quality course in return for a reasonable amount of effort. Therefore, the assignments in this course are broken down into two categories,depending on what kind of grade you are aiming for. If you want a lettergrade , you must do all the assignments. If you are taking the class S/NC , then you can skip those assignments that are explicitly taggedas being for letter grades. I really mean you can skip them entirely. If you aim for the S/NC level, then you have to do very well on all theassignments at that level to pass the course. If you go for a letter grade,then you will be given a letter commensurate with the quality of yoursubmissions. Each assignment type [ Assignments ] explains what we arelooking for in that kind of assignment. That said, there are two kinds of leniency: The early part of the semester can be rough as you\u2019re getting used to allthese different kinds of assignments. Therefore, assignments due beforeSep 30will essentially be ignored in your final grade. By that date you will haveexperienced each of the tracks and gotten over initial learning hurdles. Ofcourse, it would be unwise to not take these assignments seriously, as the restof the semester will still build on them! I will excuse up to two poor performances after this date when computingfinal grades. However, for students trying to earn an A, the standards will behigher: doing poorly on a small assignment will be excused much more than doingpoorly on one of the significant, later assignments. In short, you get a breathing period early on, and you can screw up a littlebit later, well, you\u2019re human. Your overall course grade is a certificate of how you did: An A means you didExcellent work, B means you did Good work, and C means you did Fair work. Iview it as a one-letter recommendation letter (a recommendation letter \u2014 ha, ha). I envision a person trying to hire a student with theskills that this class teaches. An A effectively says, \u201cThis person knows orcan figure out how to do well most or all the tasks that might come up!\u201d Agrade of B effectively says, \u201cThis person can do several things, but may needsome guidance or help.\u201d A grade of C means, \u201cThis person has basic competencein the area\u201d. It should then be obvious that your performance cannot affect that of yourclassmates, or vice versa. I therefore do not \u201cgrade on a curve\u201d, because Iconsider the notion meaningless. By the same token, there is also no\u201cdefault\u201d grade in this course. At least in principle, everyone can do well. For some assignments, you will get two or more grades: usually one willrepresent the correctness of your solution, while others its codequality, efficiency, thoroughness of testing, and so on. We give highest priority tocorrectness for a simple reason: it\u2019s very easy to write a clean orefficient or other solution to a different problem. Once weconfirm you\u2019ve actually solved the problem we asked you to, then wecare about all these other characteristics as well. In general,assuming you have correct solutions, consistently poor code qualitywill hurt your grade while, if you\u2019re at a grade boundary, especiallygood code can improve it. If you\u2019re given an algorithmic problem, thenefficiency will be almost as important as correctness, but you shouldstill make sure you get the solution correct first : it\u2019s betterto have a less-efficient correct solution than a very efficientincorrect one. There is only one way in which I look at the performance of the class. If alarge portion of the class did poorly on an assignment, I assume there may havebeen a problem in the assignment itself, and I will check for that. If I findthat we did indeed screw up in some way, I will lower my expectations for theassignment (i.e., lower standards for Excellent, Good, and Fair). 9 Grading Personnel In this course, you will encounter undergraduate TAs(UTAs). UTAs are an important part of the educational mission of thisdepartment. We believe that students learn best by approachingmaterial multiple times; we also know from personal experience that welearn best by teaching others. Therefore, UTAs undertake valuablepersonal learning by revisiting material some time after they firstlearned it, and by trying to explain it to others. In the same way,you may also encounter graduate TAs (GTAs). These TAs also help with grading materials in the course. Their work isregularly reviewed by me. Grading is ultimately a collaboration in terms ofsetting standards, checking rubrics, reviewing work, etc. However, TAs are not involved in any way in the creation of coursegrades. The course grade is entirely determined by me and nobody else,and is kept confidential from all TA staff. I have ultimateresponsibility for the course. 10 Books and Materials We will rely, wherever possible, on material that is available free-of-cost. Wewill use free software tools, and the textbook and other materials for thecourse are also provided for free. We will link to some third-party sites thatare also available at no cost. The primary course textbook is PLAI , both thefirst and second edition, and some new material that may be created as thesemester progresses. The primary course software is DrRacket .Make sure you\u2019ve installed version 7.8 . If you have an olderversion, you must upgrade. 11 Technologies and Sites Please see thisdepartmental list . If you have difficulty accessing some of these, please get in touch with thecourse staff. We think most issues can be addressed so long as you can (a)download Racket and (b) ssh into the department\u2019s computers. 12 Hybrid Meetings / Accessibility / Class Recording Since the text for these is common across courses, to keep this document frombecoming excessively long, I am linking to the theSheridan Center site .The text on those pages should be considered included here. Please do not assume that just because I have linked to that page instead ofcopying it\u2019s text that I don\u2019t take this content seriously. I am committed toworking with students with accessibility needs. If you have such needs, pleaseget in touch with me as early as possible and we will do everything we can toaccommodate them. Please be sure to note the copyright policy listed on the Sheridansite. 13 Timeliness This course has deadlines for two reasons: Many assignments in this course are accumulative : they aredesigned so that the learning in one assignment improves your learning in thenext assignment, and so on. Therefore, turning in one late can force you toturn in the next one late, and so on, potentially leading to a difficultsituation as the semester ends. As a team, the course staff need predictability in their gradingschedules. There is also benefit to locality : by grading all thesubmissions for an assignment at the same time, (a) the staff don\u2019t have to\u201cpage in\u201d the assignment\u2019s content, and (b) they can handle all thesubmissions uniformly and thus fairly. For these reasons, we really prefer that you turn things in on time. However,we recognize that many things can interfere with our calendars, and we have setout accommodations for each of them. You can submit an assignment late underthe following circumstances: You have five late days that you can use at (almost: see below)any time during the semester. You do not have to give us any reasons; you don\u2019teven tell us you\u2019re using them. Just use them in the approved ways. Note : There are a few rules and exceptions: You may not take more than two late days on any assignment. Wewill start grading your assignment two days after it comes due. This way, we donot have to re-grade any work, while still providing feedback in a timelymanner. You may take only one late day on a Mystery Languagesassignment. This is because we will be posting solutions after a day. You cannot take any late days on the Quizius assignments. This is because they require you to author and respond to otherstudents\u2019 work, which has to happen roughly synchronously. You cannot take any late days on the last assignment of thesemester. This is so that course staff can finish grading on a reasonable datewhile attending to their own other needs. For HW0, you do not have to use any late days . We understand youmay have joined the course late; since this is only a procedural assignment,you won\u2019t be penalized for being late on it. If you are taking a late day, you can submit after the deadline even if youhave submitted something before the deadline. You don\u2019t need to notify us ifyou do this. Just submit and we\u2019ll automatically count your late day(s). Excused absences are when you have a reason that is justifiable bya note from a Dean or Health Services. (If you are home, you can submit aletter from a local doctor.) Excused absences do not count against your late days. Note : When this happens, it\u2019s usually because you are facing someadverse situation, sometimes an emergency. Follow the principle of\u201cforgiveness, not permission\u201d. That is, if you are in a crisis, focuson your needs . (If you have a moment to drop us a note telling us you will bedelayed, that\u2019s helpful, but in an emergency, don\u2019t worry.) You can submit yournote later. But you do need to submit official documentation for this delay tonot count; otherwise it will be counted against your late days. Per the university\u2019s ReligiousObservance policy , if a religious event overlaps with half or more of theduration of an assignment being out, you can have as many days as you missedextra to complete the assignment. You are responsible for giving the staff afull list of the expected religious absences that require extensions beforeSep 23. 14 Due Dates These are in the course calendar, linked above and also from Assignments . 15 Academic Integrity Brown University has an AcademicCode that governs all our transactions. This Code includes asection on Respect for the Integrity of the Academic Process, which establishesits policy on cheating. We expect that you, as students and scholars, will abide by this faithfully and fully . You should be extremely careful when using Internet resources for assistanceother than those specifically linked from the course website or specified inthe assignment. You are welcome to use reference material, e.g., programminglanguage documentation or an encyclopaedia. Be aware that performing a genericWeb search may get you to much more, such as solutions. (The one exception iswhen an assignment explicitly tells you to search for information on the Web.)If you accidentally find a solution and choose to use it, document that you aredoing so. You will lose some credit for the assignment, but at least you won\u2019tbe in violation of the Code. You shouldn\u2019t post looking for solutions onmailing lists or Web sites, either. Unless stated otherwise, assignments must be done alone. You are welcome todiscuss any parts of the assignments with course staff. With yourfriends, you may talk about the assignment: e.g., how far along you are,how long you anticipate needing, etc. You may not, however, discusssolutions. If in doubt about whether you can discuss something, ask us. You are responsible for keeping your files private by setting the appropriateprotections. If you fail and someone copies your work, you too will be heldresponsible. The same holds for other kinds of \u201csharing\u201d, such as leavingyour work visible in public places (whether computer screens orwhiteboards). Another important kind of file-sharing is posting solutions on apublicly-visible version control repository site. If you host your work on sucha site, make sure it\u2019s in a private repository. Regret Clause : Exceptions are possible only if you admityour violation to the professor (not a TA) within 24 hours of theassignment due time. This gives you an option if you cheated indesperation the night an assignment was due, or allowed someone tocheat from you, or something else\u2014 and then felt guilty about it soonafter. Violations may still be sent through the normal Universityprocess even if you admit to them under this clause, under mydiscretion, though perhaps with mitigating recommendationsso the penalty may be less harsh than if you were caught by us. 16 Capstone The course will have a capstone option. It is designed for students who havehad a logic course such as Logic for Systems, or a formal logic course inphilosophy. In the capstone option, you will learn to and use a tool for formally modelingprogramming languages called PLT Redex and use it to create and model a handful of systems. Even if you do not have abackground in logic, if you can figure out Redex and complete this work, that\u2019sfine! Details will be published on October 1. If you are interested in pursuing thecapstone option and we haven\u2019t yet published information on this, please pingus on Piazza. 17 Unusual Assignments Unlike most other courses you take, this one may have some unusualassignments. For instance, you may be asked to do something impossible, or youmay be given a task that sounds significant but is actually trivial. In thesecases, you should focus on providing a justification for your reasoning ratherthan a solution itself. The purpose in having such assignments is to more accurately mimic the realworld in which you will be asked to solve tasks: there are no \u201canswers in theback\u201d; some problems are trivial while others, which look similar, areimpossible, and a priori you can\u2019t tell which is which. How will you know which assignments these are? You won\u2019t. After you\u2019ve wrestledwith a problem for a while and built a hunch that this is one of them, ask thecourse staff to confirm your hunch. They will ask you to justify yourreasoning. If you do and are on the right track, they\u2019ll tell you that you\u2019veunderstood the real point of the problem and inform you about how to write upyour (non-)solution. 18 Legal and Ethical Issues This text is based, withthanks, on text from CSCI 1660. Some of the material covered in this course may be usable to create attacks oncomputer systems or on people. It may be unethical and/or illegal to use orapply it in contexts beyond the course itself. Breaking into, misusing, orharming computer systems, networks, or people can be illegal and punishable bylaw. You may also run afoul of Brown\u2019s computeruse policy , which can have disciplinary consequences. 19 In-Class Electronics Use Please see the separate page on it[ Electronics Policy ]. 20 Diversity and Professionalism Please see the separate page on it[ Diversity and Professionalism ]. 21 Semi-Anonymous Feedback If you run into any issues that you wish to report to the course\u2019s head course staff, you can report them usingthis form .We will be discreet in how we use this information. In particular, we willdiscuss our plans with you before we contact anyone named in the form. 22 Counseling If you feel yourself falling behind, needing to talk to someone aboutpersonal problems, or in general want a supportive ear, the universityhas extensive Counselingand Psychological Services . Please don\u2019t hesitate to usethese: everyone finds them helpful at some time or the other, andthey\u2019re part of what you\u2019re paying for to attend Brown. Make the mostof them. \u2190 prev up next \u2192", "https://cs.brown.edu/courses/cs173/2018/web/mysteries/scope.xml": "", "https://csci1710.github.io/2024/": "You need to enable JavaScript to run this app.", "https://cs.brown.edu/courses/cs173/2021/testing-guidelines-section.html": "\u25ba Fall 2021: Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Capstone Credits \u25ba Assignments SMo L Mystery Languages Implementation Analysis \u25bc Implementation 1 Stacks 1 2 Stacks 2 3 Interpreter 4 Stacks 3 5 Macros 6 OMac 7 SMo LTalk 8 Type Checker 9 Type Inference 10 ACI 11 Lazy 12 Generators 13 From Assertions to Security 14 Testing Guidelines \u25ba 14 Testing Guidelines 14.1 Testing Guidelines On this page: 14.1 Testing Guidelines 14.1.1 Provided Library 14.1.2 Error- Handling 14.1.3 Check Your Understanding \u2190 prev up next \u2192 14 Testing Guidelines 14.1 Testing Guidelines 14.1.1 Provided Library 14.1.2 Error-Handling 14.1.3 Check Your Understanding 14.1 Testing Guidelines In addition to the quality and correctness of your code, you will be evaluated on the quality and correctness of your tests. We grade your tests by running them against correct and incorrect solutions (called wheat and chaff respectively) that we have written to see whether your tests can tell the difference. In every Implementation assignment where we collect test cases, we will provide two additional files: A test-support.rkt file. The test-support.rkt file provides specific testing forms that you should use when writing tests for the wheats and chaffs. You should not use any external testing library other than those specifically provided; otherwise, we will not be able to grade your test suite. Please make sure to use the test-support.rkt file specifically provided with each assignment\u2014some assignments will have assignment-specific testing forms to help you when testing. A starter file in which you should write your test suite. This test suite will contain a (define/provide-test-suite test-suite-name ...) statement, where test-suite-name is some identifier. You should make sure to write all of your test expressions within this statement; otherwise, we will not be able to grade your test suite. The testing stencils provide examples of how to do this. While you should never include implementation-specific test cases within your testing file, you are welcome to (and encouraged to) write implementation-specific test cases within your implementation file. For example, you may find it helpful to write test cases against your helper functions. However, your implementation file does not have access to the forms defined in test-support.rkt , so you\u2019ll need to use either Racket\u2019s or Plait\u2019s built-in testing utilities. 14.1.1 Provided Library You will always have access to the following forms: (test-equal? name actual expected) (test-not-equal? name actual expected) Tests that actual and expected evaluate to the same value (in the case of test-not-equal? , different values). (test-true name expr) (test-false name expr) Tests that expr evaluates to #t (in the case of test-false , #f ). (test-pred name pred expr) Tests that expr returns a value that satisfies the given pred predicate. (test-raises-error-with-substring? name expr substr) Tests if the given expr raises an error that contains the substring substr . Some assignments will have specific testing forms; see the assignment specs for more information. 14.1.2 Error-Handling When we run your tests, they can result in an error (either due to an intentionally raised error or a bug in a chaff). It is important that invocations of your functions in your tests are caught by a testing statement from our provided testing library, each of which will handle the error automatically. Without a testing statement to handle an error, the test running could terminate due to the error, and you will receive no credit. Thus, you should write this: (test-equal? \"Works with Num primitive\" (eval `{+ 2 2}) (v-num 4)) However, don\u2019t write this: (define result (eval `{+ 2 2})) ; this is not caught by `test-equal?`! (test-equal? result (v-num 4)) That said, if you need to define intermediary variables in a test case, you can use a begin or let statement: (test-equal? \"Multi-statement test case\" (let ([result (eval `{+ 2 2})]) result) (v-num 4)) 14.1.3 Check Your Understanding Implementation assignments that ask for test cases will have a \u201cTests\u201d upload on Gradescope for you to submit your test cases. Prior to the assignment deadline, you are welcome (and encouraged) to upload your testing file to the Gradescope drop early . When you do this, Gradescope will automatically run all of the wheats and a subset of the chaffs against your test suite. Once it\u2019s done running, it will immediately give you feedback on: Whether your test suite passed all of the wheats Which of the starter chaffs your test suite caught We provide you this functionality to help you check your understanding of the problem and to encourage you to explore the more interesting edge cases in the specification. Specifically, the starter subset of chaffs on Gradescope are designed to help catch any misunderstandings of the problem statement you may have. However, when we evaluate the comprehensiveness of your final test suite, we\u2019re going to run it against many more chaffs, which will mainly focus on errors that might occur during implementation. In other words, make sure you keep developing your test cases while you\u2019re implementing your functions, even if you caught all of the chaffs, since catching all of the initial Gradescope chaffs may not be sufficient to getting the highest possible evaluations on testing. \u2190 prev up next \u2192", "https://cs.brown.edu/courses/cs195-5/spring2012/calendar.html": "Introduction to Machine Learning News Calendar Assignments Resources Lectures & Readings Most course readings are taken from Machine Learning: A Probabilistic Perspective ( MLaPP ), a draft textbook in preparation by Prof. Kevin Murphy . The first chapter is freely available online. Later chapters will be distributed via a pair of readers available from the Metcalf Copy Center . The specific schedule of topics and readings below is tentative, and will change as the course progresses. Date Topic Primary Readings Materials 1/26 Course Overview MLaPP: 1.1-1.3 slides 1/31 Probability: Discrete random variables Dimensionality & model validation MLaPP: 2.1-2.3 MLaPP: 1.4.1-1.4.4, 8.3.8 slides 2/02 Maximum likelihood & Bayesian learning Naive Bayes classifiers MLaPP: 3.1-3.2 MLaPP: 5.1-5.2 slides 2/07 Probability: Continuous random variables Smoothing: Beta & Dirichlet priors MLaPP: 2.4, 2.5.4 MLaPP: 3.3-3.5 slides 2/09 Bayesian decision theory & ROCs Gaussian ML estimation MLaPP: 8.1-8.2, 8.3.4 MLaPP: 1.4.5-1.4.6 slides 2/14 Decision theory & continuous estimation Bayesian model selection Directed graphical models MLaPP: 8.2, 10.2 MLaPP: 1.4.7-1.4.9, 10.3 MLaPP: 9.1-9.2 slides 2/16 Multivariate Gaussian Distributions Gaussian Classification MLaPP: 2.5, 4.1-4.4.2 MLaPP: 5.3-5.3.1 slides 2/21 Brown Holiday: No Lecture 2/23 Linear Regression & Least Squares Bayesian Linear Regression MLaPP: 1.4.5-1.4.7 MLaPP: 6.2-6.3 slides 2/28 Gaussian Discriminant Analysis Logistic Regression, Probit Regression MLaPP: 5.3 MLaPP: 6.4, 7.4 slides 3/01 Logistic Regression Gradient Descent, Newton's Method MLaPP: 6.4 MLaPP: 6.4 slides 3/06 Logistic Regression: ML & MAP Laplace Approximations MLaPP: 6.4 MLaPP: 6.5 slides 3/08 Exponential Families MLaPP: 7.1-7.2 slides 3/13 Midterm Exam: In Class 3/15 Generalized Linear Models Robust Linear Regression Binary Feature Selection & Search MLaPP: 7.3 MLaPP: 6.2.3 MLaPP: 13.2 slides 3/20 L1 Regularization & Sparsity MLaPP: 13.3-13.4 slides 3/22 Online Learning & Perceptrons Kernel Methods MLaPP: 6.6 MLaPP: 14.2, 14.4 slides 3/27 Spring Break: No Lecture 3/29 Spring Break: No Lecture 4/03 Gaussian Process Regression Gaussian Process Classification, GLMs MLaPP: 15.1, 15.2 MLaPP: 15.3 slides 4/05 Margins & Support Vector Machines MLaPP: 14.5 slides 4/10 Clustering & K-Means Algorithm Probabilistic Mixture Models MLaPP: 1.3, 11.2 MLaPP: 11.2, 11.3 slides 4/12 Graphical Models EM for Mixture Models MLaPP: 9.1, 9.2, 9.4 MLaPP: 11.2-11.4 slides 4/17 Expectation Maximization Algorithm MLaPP: 11.4 slides 4/19 Principal Components Analysis Factor Analysis & Probabilistic PCA MLaPP: 12.1-12.3 slides 4/24 EM Algorithm for Factor Analysis & PPCA MLaPP: 12.1-12.3 slides 4/26 Hidden Markov Models Inference & Learning for HMMs MLaPP: 17.1-17.3 MLaPP: 17.4-17.5 slides 5/01 Topic Models Monte Carlo Methods MLaPP: 27.3 MLaPP: 23.2, 23.4 slides 5/03 MCMC & Gibbs Samplers Continuous State Space Models MLaPP: 24.2 MLaPP: 18.1-18.3, 23.5 slides 5/08 Final Exam Review Session slides 1 slides 2 5/10 Graduate Project Presentations Recitations Date Topic Readings Materials 2/02 Matlab Tutorial YAGTOM Matlab 2/09 Continuous Bayesian Estimation MLaPP: 2.4, 3.3 demo notes 2/16 Linear Algebra Tutorial Stanford CS229 notes 2/23 Multivariate Gaussians, Linear Regression MLaPP: 4, 6.2-6.3 demo notes 3/01 Continuous Optimization MLaPP: 6.4 demo notes 3/08 Midterm Review Session MLaPP: 1-6, 8, 10 slides 1 slides 2 3/15 No Recitation 3/22 Lagrange Multipliers Klein tutorial notes 3/29 No Recitation 4/05 Kernels MLaPP: 14 notes 4/12 EM Algorithm MLaPP: 11.4 notes 4/19 Markov Chains MLaPP: 17.2 Matlab notes 4/26 Dynamic Programming, HMMs MLaPP: 17.4 notes 5/03 No Recitation", "https://cs.brown.edu/courses/cs190/2017/": "csciStartup More than a class In csciStartup, you will incorporate and run a startup. You must apply as a team to be a part of a class to remove the mystery from starting a company, and to focus entirely on a product you're passionate about. Apply as a team You should apply if you have a team in place and a product in mind. Teams of two to four are probably best, and a great team might not be all CS students. We will focus on products that a small team can implement in months \u2014 web sites and mobile apps will be the norm. If you nearly have a team in place, and want to meet other students who are looking for a team (or vice versa), you might check out this Facebook group . Applications are closed for 2017. Product Focused We will learn by doing. Each team will incorporate, build a product for real customers, advertise their product, and improve it week after week. We'll spend at least half of our class meetings with individual attention to each group's progress and how to improve your offerings. Assignments will be designed to apply to any company, with enough flexibility to ensure you're always working on things that make sense for your business. Lectures / Talks We meet twice a week, Tuesday and Thursday from 6:40pm-8pm. Usually one meeting is \"normal\" class, and the other is a guest lecture. Last, year guests included: Evan Stites-Clayton, Teespring's start Ted Howell, Legal questions Nick Kishfy, Mojotech, Addressing risks first Jon Mellon, TripAdvisor, SEO Ben Simon, Down Dog, Mobile app engagement Melissa Withers, Betaspring Adam Leventhal, Delphix, After the MVP Chris Erway, Appneta, Hiring / Funding Eliot Horowitz, MongoDB Louis Forward-Henry, moo.com, Sales Many will return, and we'll look for more speakers that fit with team needs this year. Syllabus \u00bb John Jannotti window.jQuery || document.write('<scr'+'ipt src=\"js/vendor/jquery-1.11.2.min.js\"></scr'+'ipt>')", "https://cs.brown.edu/courses/cs195-5/spring2012/": "Introduction to Machine Learning News Calendar Assignments Resources CSCI 1950-F: Introduction to Machine Learning, Spring 2012 Brown University Department of Computer Science Course Information See the syllabus , and the calendar for details on readings, lectures, and recitations. Textbook The primary course textbook is Machine Learning: A Probabilistic Perspective , in preparation by Prof. Kevin Murphy . Printed copies are available as a pair of readers from the Metcalf Copy Center . Lectures Tuesdays and Thursdays from 1:00-2:20pm, CIT room 227 . Recitations Thursdays from 5:00-6:00pm, CIT room 227 . Led by the graduate teaching assistants. Instructor Professor Erik Sudderth , office hours Mondays from 11:00am-12:00pm, Tuesdays from 2:30-3:30pm, CIT room 509 . Graduate Teaching Assistants Dae Il Kim , office hours Wednesdays from 10:00am-12:00pm, CIT room 409 . Ben Swanson , office hours Tuesdays from 12:00-1:00pm and 3:00-4:00pm, CIT room 411 . Undergraduate Teaching Assistants William Allen, Head UTA, office hours Sundays from 7:00-9:00pm, CIT room 219 . Paul Kernfeld, office hours Mondays from 7:00-9:00pm, CIT room 219 . Zachary Kahn, office hours Tuesdays from 8:00-10:00pm, CIT room 219 . Soravit Changpinyo, office hours Wednesdays from 7:00-9:00pm, CIT room 219 . Vazheh Moussavi, office hours Wednesdays from 9:00-11:00pm, CIT room 219 . Mailing Lists The course staff can be reached at cs195fheadtas-at-cs. The primary mailing list for course announcements is cs195f.2011-12.s@lists.cs.brown.edu . Registered students have been automatically added. If desired, you can forward your CS e-mail to another account. Previous Courses Spring 2011 : CSCI 1950-F: Introduction to Machine Learning, Erik Sudderth. Fall 2009 : CSCI 1950-F: Introduction to Machine Learning, Mark Johnson and Erik Sudderth. Fall 2006 : CS 195-5: Introduction to Machine Learning, Greg Shakhnarovich. Announcements May 8, 2012 Graduate projects will be presented on Thursday, May 10 at 1:00pm in Lubrano (CIT fourth floor). Food will be served! May 1, 2012 Homework 10 is an optional, extra credit assignment. If you submit it, you can replace a low score on a previous homework with the points earned on homework 10. April 11, 2012 The deadlines for homeworks 8-10 have been extended, to better fit the schedule of lecture material. March 5, 2012 The deadline for homework 5 has been extended until 12:00 noon on Monday, March 12. Remember that the midterm exam will be given in class on Tuesday, March 13. February 16, 2012 Due to the holiday weekend, Prof. Sudderth's normal office hours are canceled on Monday and Tuesday, Feb. 20-21. He will hold extra office hours on Wednesday, Feb. 22 from 4-5pm. February 10, 2012 The problems with the electronic handin script have now been fixed, and you should be able to successfully submit homework 1. If you sent your solutions via email, please resubmit them using the handin script. We will extend the deadline for homework 1 until noon on Monday, February 13. February 3, 2012 The course mailing list, cs195f.2011-12.s@lists.cs.brown.edu , is now in use. Please ensure that you are receiving course emails, including information about homework 1. January 25, 2012 The first lecture will be held on Thursday, January 26 in CIT 227. A reader containing the course textbook is available for purchase from the Metcalf Copy Center .", "https://cs.brown.edu/courses/cs237/2018/brown-cs237-fall18-website/ideas.html": "CSCI2370: Interdisciplinary Scientific Visualization (fall 2018) Project Ideas Home Syllabus Calendar People Gallery Links Project Ideas Ideas Compiled for Students Note: Brown-internal or password protected links are styled like this , as opposed to public links . You can also find the list of ideas proposed in previous years: 2000 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 . Proposals and Projects from Previous Years Click on the year numbers to review some of the individual project proposals students made in 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 . The resulting final projects , completed in groups, can be reviewed here for 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 .", "https://cs.brown.edu/courses/cs1951i/": "CS1951I Course Info Assignments Staff Course Information CS1951I is taught by Lachlan Kermode and the HTAs. Class is held on Tuesday and Thursday mornings from 9:00 to 10:20 am. Lachlan's office hours are on Thursday afternoons , or by appointment. To take this course, you should have taken CS 32, CS 33 or CS 132. The course is limited to a certain number of students, and so it is also required to submit an application by January 20th. In Spring '23 students will work with one of the following four organizations: The Peace Lab Student Clinic For Immigrant Justice Center For Health and Justice Transformation iCareForYou \"Students will work in a studio environment to iteratively design, build, and test technical projects in partnership with different social change organizations. Students will be placed in small teams to collaboratively work on projects that will range from, for example, developing a chatbot to aid community engagement to conducting geospatial data analytics. Through the course, we will also reflect on our positionality and ethics in engaging in social impact work and what it practically means to leverage technology to create social change on an everyday basis.\" \u2013 Course Announcement Guides & Documents Check out the following useful documents for questions you have about course organization, tools we use, and other helpful resources. Syllabus Student Support and Resources Guide to Github (PDF) Guide to Github (HTML) Assignments Milestones Students are responsible for setting milestones with their partnering organizations. See the syllabus for more information. Readings All reading responses are due Wednesday night at 11:59 pm. Links to the forms where you should submit your response are listed weekly in the table below. Week Unit Readings Response Form Due Week 0 1/25 - 1/28 Introduction Syllabus Week 0 Response 1/30, 11:59pm EST Week 1 1/29 - 2/4 Structural thinking \" Demystifying Big Tech with Meredith Whittaker \" [audio] - Meredith Whittaker and Astra Taylor Week 1 Response 2/1, 11:59pm EST Week 2 2/5 - 2/11 Structural thinking \" When Did the Fire Start? \" in Your Computer is on Fire - Mar Hicks \" The Internet We Could Have Had \" - Chris Kelty Week 2 Response 2/8, 11:59pm EST Week 3 2/12 - 2/18 Capital \" David Harvey on Capital \" [audio] - David Harvey and Daniel Denver Week 3 Response 2/15, 11:59pm EST Week 4 2/19 - 2/25 Capital \" The Making of the Tech Worker Movement \" - Ben Tarnoff Internet for the People: The Fight for our Digital Future (only the Introduction is required) - Ben Tarnoff Week 4 Response 2/22, 11:59pm EST Week 5 2/26 - 3/4 Labor \" Coding is Not Empowerment \" in Your Computer is on Fire - Janet Abbate [optional] Breaking Things at Work [audio] - Gavin Mueller Week 5 Response 3/1, 11:59pm EST Week 6 3/5 - 3/11 Neoliberalism \" The Big Picture: Defending Society \" - Wendy Brown \" Platforms are Infrastructures on Fire \" in Your Computer is on Fire - Paul N. Edwards Week 6 Response 3/8, 11:59pm EST Week 7 3/12 - 3/18 Neoliberalism \" Counterculture to Cyberculture with Fred Turner \" - Fred Turner and Daniel Denver Hegemony Now: How Big Tech and Wall Street Won the World (And How We Win It Back) (excerpt) - Jeremy Gilbert and Alex Williams Week 7 Response 3/15, 11:59pm EST Week 8 3/19 - 3/24 Gender \" Sexism is a Feature, Not a Bug \" in Your Computer is on Fire - Mar Hicks \" When Computers Were Women \" - Jennifer S. Light Week 8 Response 3/22, 11:59pm EST Week 9 SPRING BREAK Week 10 4/3 - 4/8 Partner 1: The Peace Lab Hemmatian GS: No amount of weapons can end the Ukraine war, but a peace mindset might Tech Workers versus the Pentagon 3 Years After the Project Maven Uproar, Google Cozies to the Pentagon Militarising Big Tech: The Rise of Silicon Valley's Digital Defense Industry Week 11 4/9 - 4/15 Partner 2: Student Clinic for Immigrant Justice The Fetishization of Data The Cruel New Era of Data-Driven Deportation Marc Benioff defends Salesforce\u2019s contract with Customs and Border Protection At US border, tech issues plague new migrant applications Biden's new CBP One app panned for trapping asylum seekers in 'daily lottery system' Week 12 4/16 - 4/22 Partner 3: Center for Health and Justice Transformation My Turn: Sarah Martino: Post-COVID justice system should be smaller, smarter Giving Serious Offenders a Second Chance Podcast An Algorithm that Grants Freedom or Takes it Away Deloitte Criminal Justice Tech Report (page 6 onwards) Week 13 4/23 - 4/29 Partner 4: iCareForYou Ableism, Technoableism, and Future AI Disability Visibility Project Ep. 3: Assistive Technology (podcast with transcript) (first 12 minutes) Ten Principles of Disability Justice Week 14 4/30 - 5/6 Reading Period Week 15 5/7 - 5/13 Final Project Submissions Final Project Submission 5/13, 11:59pm EST Inclusive Course Goals & Actions CS1951I is committed to the full inclusion of students. Our course goals and actions for the semester are the following: Goal: Ensure that students of different religious backgrounds feel supported by the staff. Action: A Google form for students to request extensions or excused absences for a religious holiday that Brown does not officially observe. Goal: Allow students to voice their opinions about the course. Action: An anonymous feedback form for students to submit any concerns or questions they have about the course. Diversity & Accessibility Statements The CSCI1951i course staff is committed to increasing the retention of historically underrepresented groups in upper level computer science classes. We believe that an inclusive environment allows students to thrive academically while also creating a diverse social atmosphere that is welcoming to all. We value all feedback about the environment that we are creating, so here is a link to our feedback form. You also can reach out to the Diversity and Inclusion Advocates here. Accommodations: If you feel you have physical, psychological, or learning disabilities that could affect your performance in the course, we urge you to contact SEAS . We will do whatever we can to support accommodations recommended by SEAS. Mental Health: The CSCI1951i staff cares deeply about student mental health. If there are any mental health issues that keep you from performing well at Brown, we encourage you to contact CAPS . They provide confidential, free counseling. Project LETS at Brown University also can provide access to Peer Mental Health Advocates. You can find more info on Project LETS here . Staff Instructor Lachlan Kermode He/Him Ciao! I'm a PhD student in the department of Modern Culture and Media at Brown, and a Research Fellow at the research agency Forensic Architecture. My current work is concerned with the history of computer science and software. HTAs ( cs1951Iheadtas@lists.brown.edu) Ahmad Jamal Alkhatib He/Him Hello! I am a senior studying computer science and I call Jordan and Palestine home. I am part of the best a cappella group on campus -> Harmonic Motion <- Valerie Aguilar Dellisanti She/Her Hi! I\u2019m a senior from Peru majoring in CS-Econ & IAPA. In my free time, I love dancing and playing polo. I love desserts and I\u2019m very excited about HTAing this class for my last semester at Brown. UTAs ( cs1951Itas@lists.brown.edu ) Trevor Ing He/Him Hey! I\u2019m a senior studying CS from Seattle, WA. I\u2019m a club baseball captain and love solving and creating crosswords, watching sports, and using Notion! Blake Shao He/Him Hi! I am a junior from Jinan, China studying CS and MCM. I like powerlifting, making videos/animations, and looking at cool artworks:) \u00a9 2022 CS1951I TA Staff | Computer Science Department | Brown University", "https://cs.brown.edu/courses/cs195y/2018/": "Home Assignments Staff/Hours Resources Notes Policies Labs Piazza What is Logic for Systems? Logic plays a central role in describing systems. In addition, logic offers the foundation for a rich set of tools for reasoning about systems, namely, determining whether they have been described correctly relative to our expectations. Unfortunately, this fascinating set of activities can come across to some as rather drab and pedantic. In turn, logic often fails to take hold of computer science imaginations because it seems to be a collection of statements about the state of Socrates and rain, not about the state of buffers and caches and the other difficulties that everyday practicing computer scientists wrestle with. This course attempts to address this problem by re-focusing logic on computer systems. We will use logic to describe systems and then analyze our descriptions of them. We will use modern tools that ease the description and automate the analysis. In the process we will try to re-imagine the way we think about not only describing but even designing complex modern computer systems. Class Time and Location Class will be held on Mondays, Wednesdays, and Fridays from 10:00am to 11:00am in 85 Waterman 130. Useful Links Syllabus Piazza Signup Do you have any feedback for us? Course Calendar", "https://cs.brown.edu/courses/cs195y/2020/": "Course Info Assignments Staff/Hours Lectures Piazza What is Logic for Systems? Mathematical logic provides the foundation for a rich set of tools for reasoning about systems and discovering whether their behavior meets our expectations. These tools allow us to model (e.g.) the state of buffers and caches, prove whether our protocols obey desirable properties, explore the consequences of memory-management strategies, and much more. As a Computer Science student, you\u2019ve often been asked to write code with the intent of creating a system. This class is different. Here, we\u2019ll ask you to create models of systems and interact with them in numerous ways. You will learn to use modern, logic-based tools to describe and analyze program designs, algorithms, data-structures, and other artifacts\u2014we\u2019ll learn the logical frameworks we need as we go along. In the end, you\u2019ll develop a better understanding of how to use logic-based tools to analyze whatever systems you encounter after Brown. Class Time and Location Class will be held on Mondays, Wednesdays, and Fridays from 10:00am to 10:50am in Barus & Holley 168. Course Calendar Resources Emails HTA email cs1950yheadtas@lists.brown.edu (HTAs and Tim) TA email cs1950ytas@lists.brown.edu (All TAs) Course Documents Syllabus Collaboration Policy Inclusion and Professionalism Policy Anonymous Feedback Form SSH Guide Other resources We recognize that being a student is not easy, and hope to provide support in any way we can. Beyond our staff, here is a list of other resources available to you here at Brown: Counseling and Psycological Services (CAPS) Student and Employee Accessibility Services (SEAS) Student Advocates for Diversity and Inclusion ( email ) CS Health and Wellness Resources ( email )", "https://cs.brown.edu/courses/cs2951x/2018.html": "CSCI 2951X: Reintegrating AI (Spring 2018) Overview Schedule Assignments Grading Resources Overview The primary goal of Artificial Intelligence has always been to build complete intelligent agents. However, the field has also always been fragmented into a collection of problem-specific areas of study. This seminar course will survey efforts made, over several decades, to produce \"big picture\" theories and architectures for reintegrating the various component technologies into complete, generally-capable, intelligent agents. The class will read and discuss two papers per week. Grading will be based on two written essays, and a substantial open-ended final project. Instructor George Konidaris Office: CIT 447 Email: gdk at cs dot brown dot edu [Back to top] Schedule The first class is on Thursday January 25th . The class meets on aTuesday-Thursday schedule, from 1:00pm to 2:20pm in CIT 506 . Note that the schedule below is tentative , and may be revisedas we go along. Date Assigned Reading January 25th Elephants Don't Play Chess, R.A. Brooks. January 30th Class cancelled February 1st Computer science as empirical inquiry: symbols and search. A. Newell and H.A. Simon, CACM 1976. Also read:Report on a general problem solver. A. Newell, J.C. Shaw, and H.A. Simon. Technical report, Carnegie Institute of Technology, 1959. February 6th CYC: Using Common Sense Knowledge to Overcome Brittleness and Knowledge Acquisition Bottlenecks. Lenat, Prakash, Shepherd. AI Magazine, 1985. February 8th Extending the Soar Cognitive Architecture. Laird, GAIC 2008. February 13th From Micro-Worlds to Knowledge Representation: AI at an Impasse. H.L. Dreyfus. In Mind Design II , Haugeland. February 15th Shakey the Robot. N. Nilsson, ed. Technical Note 323, SRI International, April 1985. February 20th Long weekend February 22nd The Architecture of Mind: A Connectionist Approach,D.E. Rumelhart. In Mind Design II, chapter 8. February 27th Connectionism andcognitive architecture: a critical analysis. J.A. Fodor and Z.W. Pylyshyn. In Mind Design II, chapter 12. March 1st The Presence of a Symbol, A. Clark. In Mind Design II, chapter 14. March 6th Quantifying Uncertainty , Chapter 13, Russell and Norvig. March 8th On Chomsky and the Two Cultures of Statistical Learning, by Peter Norvig. March 13th Snow day March 15th How to Grow a Mind: Statistics, Structure, and Abstraction, Tenenbaum et al., Science, 2011. March 20th No class March 22nd Building Machines That Learn and Think Like People, Lake et al., 2017. March 27th Spring break March 29th Spring break April 3rd Behaviour: perception, action and intelligence - the view from situated robotics, J.C.T. Hallam and C.A. Malcolm, Philosophical Transactionsof the Royal Society A. April 5th The Animat Path to AI, S.W. Wilson Autonomous Mental Development by Robots and Animals, Weng et al. April 10th Class discussion: embodiment, the modern AI method, and MDPs/POMDPs April 12th No class April 17th Hierarchically organized behavior and its neural foundations:A reinforcement learning perspective, Botvinick, Niv, and Barto, Cognition 2008. April 19th Building Portable Options: Skill Transfer in Reinforcement Learning, Konidaris and Barto 2007, and Autonomous Skill Acquisition on a Mobile Manipulator, Konidaris et al., 2011. April 24th From Skills to Symbols: Learning Symbolic Representations for Abstract High-Level Planning, Konidaris, Kaelbling,and Lozano-Perez, JAIR 2018. April 26th Discussion [Back to top] Assignments Assignment 1 GOFAI and connectionism are generally conceived of as direct competitors. However, their relationship is not quite that simple, since they are usually not applicable to the same sorts of problems. I'd like you to think about a specific type of problem - two player, zero-sum games, like chess and Go - where both approaches have been tried. Your aim is to discuss the relative merits, successes, and failures of both GOFAI-like (which we'll take to include all search, knowledge-based, and explicit reasoning systems) and connectionist (which we'll take to include the direct prediction of best move or value using a neural net, of whatever type) systems. Where both types of methods have been combined in a single system, I'd like you to explain why, and to analyze what specific advantages the combination brings to the game. Your goal is to try and characterize what specific aspects of a two-player game GOFAI-style and connectionist approaches are best suited to, or to demonstrate that one approach has decisively \"won\". I expect you to do substantial reading outside of the course materials, and to write a properly referenced report. You should cover as many individual games as you feel is necessary to cover the \"space\" of solutions. (I would be surprised if that is less than three.) The assignment is due in class, in hardcopy, on March 15th . It may not be more than 8 pages in 11 point font (not including references). Please do NOT feel the need to necessarily use all of those pages; I am grading on insight, analysis, and coverage, NOT length. Assignment 2 Your second assignment is to compare connectionist and Bayesian approaches to Natural Language Processing. Here I'd like you to pick a component problem in NLP (e.g., parsing), and find and summarize the state-of-the-art approaches that use deep nets and that use explicit probabilistic models. I'd like you to discuss both the actual performance achieved, and the specific things that each approach makes possible in principle (e.g., semantically meaningful uncertainty) for the specific task you've chosen. If the leading approaches are hybrid, that's OK, and even interesting! Explain what advantages are imported from each paradigm. I expect a properly referenced hardcopy report handed in during class on April 17th . It may not be more than 5 pages in 11 point font (not including references). Please do NOT feel the need to necessarily use all of those pages; as usual I am grading on insight, and analysis, NOT length. Final Project Your major project will be a substantial creative and original piece of work, in one of the following two categories: 1) A computational research study, in which I expect you to design and implement theory and experiments studying some algorithm or model that is aligned with the course content. I expect it to have approximately the length, form, and content of a conference paper at a good AI conference (though it need not be publishable). It does not necessarily have to be an original contribution, although that would be nice. If it is not, then I expect at least an original evaluation that is relevant to our topic (e.g., an existing algorithm is tried in a new domain that speaks to what we have discussed). For example, one might design a new method that combines connectionism and probabilistic reasoning, or one might find such a method and then evaluate it in a domain designed to test one of the critiques of such methods that we have discussed. The study will be graded on insight, completeness, and clarity. These studies can be completed singly or in pairs. I expect the submitted document to be more substantial for a pair than a similar single-author assignment that earns a similar grade. 2) A philosophical study, in which you propose and defend a proposition about the nature of intelligence. Here I am looking for the sort of argument and analysis that we have been seeing in the papers we've read so far. I expect a well-referenced, thoughtful piece that advanced a coherent and interesting argument and interrogates its implications. For example, one might propose that (following today's discussion) a text corpus, no matter how large, does not contain the information necessary to discover the meaning of any sentence in natural language. A good essay will describe the proposition, argue for its truth, point to (or argue the irrelevance of) results in the CS literature, and perhaps consider and argue against possible objections. Again this does not have to be a particularly new idea, but I'd like you you to argue it without relying on the arguments of others. You should cite computational research studies and foundational philosophical studies (e.g., Chomsky), but do not find another essay on a similar topic and use its arguments. This type of study will be graded on the coherence of the idea, how well it is argued and analyzed, and on writing style. I expect it to be about as long as it needs to be to be complete; 10-20 pages as a ballpark. The project accounts for 60% of your grade and is due at the end of the reading period (May 8th). [Back to top] Grading Graded components will tentatively include two written homework assignments (20% each),and a substantial final project (60%). [Back to top] Resources Our readings are in large part drawn from the following books,all of which are highly recommended for more in-depth reading intothis topic: Mind Design II, J. Haugeland, ed. Computers & Thought, E.A. Feigenbaum and J. Feldman, eds. Mindware, 2nd edition, Andy Clark, ed. Being There, Andy Clark. Cambrian Intelligence, R.A. Brooks. Also worth reading, but much more about philosophy than CS, is: Mind and Cognition, 2nd ed, W.G. Lycan, ed. These books and readings will be of interest to students who want to understandthe probabilistic foundation of AI more deeply: Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, by Judea Pearl. Probability Theory: The Logic of Science, by E.T. Jaynes. Probabilistic Logic, by Nils Nilsson. In Artificial Intelligence 28 (1986), 71-85. [Back to top]", "https://cs.brown.edu/courses/cs1951r/": "CS1951R Introduction to Robotics Fall 2023 Home Syllabus Schedule Hours FAQ Staff Safety EDStem Forum Welcome! We\u2019re excited to build and fly drones with you. Each student willlearn to program a small quad-rotor helicopter. We will provide eachstudent with their own robot for the duration of the course. Thecourse will cover PID controllers for stable flight, localization witha camera, mapping, and autonomous planning. At the end of the course,the aim is for students to understand the basic concepts of a mobilerobot and aerial vehicle. The class is taught by ProfessorStefanie Tellex and the rest of the course staff . Enrollment is limited due to limited amounts of drone kits, lab space, and staff support for the class. You can apply for an override to join the class here . Lectures Our lectures online can be found on edX Edge. Use this link to make an account and access the lecture material. Notwithstanding online lectures, attendance is required in person on Tuesday and Thursday 10:30am-11:50am in the Science Library 8th floor lab space. Professor Tellex will be running extended office hours during this time. The first lecture was delivered live over Zoom and covered mostly class logistics. You can find the slides here . Textbook The class textbook can be found online at DuckieskyLearning Materials . Each assignment or project is a link to aspecific chapter in this textbook and has corresponding lectures inthe edX Edge course. Schedule The class schedule contains videolectures, assignments, and projects organized based on due dates.This is the main page for what happens when with the class. Hardware For those taking the class at Brown, as well as our high schoolcollaborators, we will provide a drone kit using funds donated byAmazon Robotics. Anyone can buy the drone kit online here . Anonymous Feedback Form Please use this anonymousfeedback form to tell us how we\u2019re doing. Copyright \u00a9 CS1951R Course Staff | Computer Science Department | Brown University", "https://cs.brown.edu/courses/cs2951x/2021_fall.html": "CSCI 2951X: Reintegrating AI (Fall 2021) Overview Schedule Project Reading Further Reading Overview The goal of AI has been to build complete intelligent agents, yet the field has been fragmented into a collection of problem-specific areas of study. We will first spend a few weeks in lecture covering a new approach to integrating existing AI subfields into a single agent architecture, and remainder of the semester on self-directed, semester-long research projects. Grading will be based on a mid-semester project proposal, and a substantial open-ended final project. The projects will be multi-disciplinary in nature but students will have the opportunity to work in small groups, so they need not necessarily have expertise in the relevant areas. All students need special permission to enroll; advanced undergraduate students welcome. The 2018 incarnation of this course was a reading seminar; the old website and reading lists are here . Instructor George Konidaris Office: CIT 447 Email: gdk at cs dot brown dot edu [Back to top] Schedule The first class is on Wednesday September 8th , meeting weekly on a Wednesday from 3-5:30pm in CIT 241 (Swig). The first few sessions will be lectures (which will be recorded and uploaded to Pantopo, and so can be watched asynchronously), after which we will break into project groups, and weekly meetings will be progress check-ins and discussions with each group. [Back to top] Project Your project will be a substantial creative and original piece of work.I expect you to design and implement theory and experiments studying some algorithm or model that is aligned with the course content - i.e., a model that integrates at least two aspects of AI research in an interesting way. I expect it to have approximately the length, form, and content of a conference paper at a good AI conference (though it need not be publishable). That means careful, clear, and precise writing, a well-formalized and thoughtfully evaluated point, and thorough referencing throughout. It does not necessarily have to be an original contribution, although that would be nice. If it is not, then I expect at least an original evaluation that is relevant to our topic (e.g., an existing algorithm is tried in a new domain or addresses a setting that speaks to what we have discussed). The study will be graded on insight, completeness, and clarity. These studies can be completed in groups of between 1 and 4 people. Undergraduates taking the course should work in groups of at least 3. The project accounts for 100% of your grade and is due at the end of the reading period (December 12th). There is an intermediate deadline: a 2-page project proposal due by approximately early October,which identifies the topic, names the group, and sketches out what you hope to accomplish in the study. I will use these to discuss the project with each group to make sure they're on an appropriate path. [Back to top] Reading General background for embodiment and general AI (all quite dated): Elephants Don't Play Chess , R.A. Brooks. Shakey the Robot. N. Nilsson, ed. Technical Note 323, SRIInternational , April 1985. Video The Animat Path to AI , S.W. Wilson 1991. Behaviour: perception, action and intelligence - the view fromsituated robotics , J.C.T. Hallam and C.A. Malcolm, PhilosophicalTransactions of the Royal Society A (1994). (You'll need to login via Brown.) Structuralism: Kaelbling, Leslie Pack. The Foundation of Efficient Robot Learning . Science 369(6506), pages 915-916, August 2020. MDPs and RL: Kaelbling, Leslie Pack, Michael L. Littman, and Andrew W. Moore. Reinforcement learning: A survey. Journal of artificial intelligence research 4 (1996): 237-285. Object-Oriented MDPs: Diuk, Carlos, Andre Cohen, and Michael L. Littman. An object-oriented representation for efficient reinforcement learning. Proceedings of the 25th international conference on Machine learning. 2008. Abstraction in RL: Sutton, Richard S., Doina Precup, and Satinder Singh. Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning. Artificial intelligence 112.1-2 (1999): 181-211. Li, Lihong, Thomas J. Walsh, and Michael L. Littman. Towards a Unified Theory of State Abstraction for MDPs. ISAIM. 2006. David Abel, D Ellis Hershkowitz, Michael L. Littman. Near Optimal Behavior via Approximate State Abstraction. , ICML 2016. Problem-Specific Abstractions: Konidaris, George. On the necessity of abstraction. Current opinion in behavioral sciences 29 (2019): 1-7. POMDPs: Spaan, Matthijs TJ. Partially observable Markov decision processes. In Reinforcement Learning: The State of the Art. Springer, Berlin, Heidelberg, 2012. 387-414. Natural Language for MDPs: Jelena Luketina, Nantas Nardelli, Gregory Farquhar, Jakob Foerster, Jacob Andreas, Edward Grefenstette, Shimon Whiteson, Tim Rocktaschel. A Survey of Reinforcement Learning Informed by Natural Language , Proceedings of the Twenty-Eighth International Joint Conference on Artificial IntelligenceSurvey track. Pages 6309-6317. R. Rodriguez-Sanchez, R. Patel, and G.D. Konidaris. On the Relationship Between Structure in Natural Language and Models of Sequential Decision Processes . In The First Workshop on Language in Reinforcement Learning at ICML 2020, July 2020. Further Reading Readings from the following booksare recommended for more in-depth engagement with the topic, thoughnote that all of these are now dated: Mind Design II, J. Haugeland, ed. Computers & Thought, E.A. Feigenbaum and J. Feldman, eds. Mindware, 2nd edition, Andy Clark, ed. Being There, Andy Clark. Cambrian Intelligence, R.A. Brooks. Dreyfus, Herbert and Dreyfus, Stuart, Making a Mind versus Modeling the Brain: Artificial Intelligence Back at a Branchpoint . Daedalus 117(1), pages 15-43, 1988. Also worth reading, but much more about philosophy than CS, is: Mind and Cognition, 2nd ed, W.G. Lycan, ed. These books and readings will be of interest to students who want to understandthe probabilistic foundation of AI more deeply: Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, by Judea Pearl. Probability Theory: The Logic of Science, by E.T. Jaynes. Probabilistic Logic, by Nils Nilsson. In Artificial Intelligence 28 (1986), 71-85. [Back to top]", "https://cs.brown.edu/courses/cs2951x/2020.html": "CSCI 2951X: Reintegrating AI (Spring 2020) Overview Schedule Project Reading Further Reading Overview The goal of AI has been to build complete intelligent agents, yet the field has been fragmented into a collection of problem-specific areas of study. We will first spend a few weeks in lecture covering a new approach to integrating existing AI subfields into a single agent architecture, and remainder of the semester on self-directed, semester-long research projects. Grading will be based on a mid-semester project proposal, and a substantial open-ended final project. The projects will be multi-disciplinary in nature but students will have the opportunity to work in small groups, so they need not necessarily have expertise in the relevant areas. Graduate students welcome; undergraduates need instructor permission to enroll. The previous incarnation of this course was a reading seminar; the old website and reading lists are here . Instructor George Konidaris Office: CIT 447 Email: gdk at cs dot brown dot edu [Back to top] Schedule The first class is on Tuesday January 23rd . The class meets on aTuesday-Thursday schedule, from 1:00pm to 2:20pm in CIT 316 . [Back to top] Project Your project will be a substantial creative and original piece of work.I expect you to design and implement theory and experiments studying some algorithm or model that is aligned with the course content - i.e., a model that integrates at least two aspects of AI research in an interesting way. I expect it to have approximately the length, form, and content of a conference paper at a good AI conference (though it need not be publishable). That means careful, clear, and precise writing, a well-formalized and thoughtfully evaluated point, and thorough referencing throughout. It does not necessarily have to be an original contribution, although that would be nice. If it is not, then I expect at least an original evaluation that is relevant to our topic (e.g., an existing algorithm is tried in a new domain or addresses a setting that speaks to what we have discussed). The study will be graded on insight, completeness, and clarity. These studies can be completed in groups of between 1 and 4 people. Graduate students should work in groups of at most 2. Undergraduates taking the course should work in groups of at least 2. Mixed groups have more flexibility but should talk to me. :) The project accounts for 100% of your grade and is due at the end of the reading period (May 5th). There is an intermediate deadline: a 2-page project proposal due by approximately the end of February,which identifies the topic, names the group, and sketches out what you hope to accomplish in the study. I will use these to discuss the project with each group to make sure they're on an appropriate path. [Back to top] Reading General background for embodiment and general AI (all quite dated): Elephants Don't Play Chess , R.A. Brooks. Shakey the Robot. N. Nilsson, ed. Technical Note 323, SRIInternational , April 1985. Video The Animat Path to AI , S.W. Wilson 1991. Behaviour: perception, action and intelligence - the view fromsituated robotics , J.C.T. Hallam and C.A. Malcolm, PhilosophicalTransactions of the Royal Society A (1994). (You'll need to login via Brown.) MDPs and RL: Kaelbling, Leslie Pack, Michael L. Littman, and Andrew W. Moore. Reinforcement learning: A survey. Journal of artificial intelligence research 4 (1996): 237-285. Object-Oriented MDPs: Diuk, Carlos, Andre Cohen, and Michael L. Littman. An object-oriented representation for efficient reinforcement learning. Proceedings of the 25th international conference on Machine learning. 2008. Abstraction in RL: Sutton, Richard S., Doina Precup, and Satinder Singh. Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning. Artificial intelligence 112.1-2 (1999): 181-211. Li, Lihong, Thomas J. Walsh, and Michael L. Littman. Towards a Unified Theory of State Abstraction for MDPs. ISAIM. 2006. David Abel, D Ellis Hershkowitz, Michael L. Littman. Near Optimal Behavior via Approximate State Abstraction. , ICML 2016. Problem-Specific Abstractions: Konidaris, George. On the necessity of abstraction. Current opinion in behavioral sciences 29 (2019): 1-7. POMDPs: Spaan, Matthijs TJ. Partially observable Markov decision processes. In Reinforcement Learning: The State of the Art. Springer, Berlin, Heidelberg, 2012. 387-414. Natural Language for MDPs: Jelena Luketina, Nantas Nardelli, Gregory Farquhar, Jakob Foerster, Jacob Andreas, Edward Grefenstette, Shimon Whiteson, Tim Rocktaschel. A Survey of Reinforcement Learning Informed by Natural Language , Proceedings of the Twenty-Eighth International Joint Conference on Artificial IntelligenceSurvey track. Pages 6309-6317. Further Reading Readings from the following booksare recommended for more in-depth engagement with the topic, thoughnote that all of these are now dated: Mind Design II, J. Haugeland, ed. Computers & Thought, E.A. Feigenbaum and J. Feldman, eds. Mindware, 2nd edition, Andy Clark, ed. Being There, Andy Clark. Cambrian Intelligence, R.A. Brooks. Also worth reading, but much more about philosophy than CS, is: Mind and Cognition, 2nd ed, W.G. Lycan, ed. These books and readings will be of interest to students who want to understandthe probabilistic foundation of AI more deeply: Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, by Judea Pearl. Probability Theory: The Logic of Science, by E.T. Jaynes. Probabilistic Logic, by Nils Nilsson. In Artificial Intelligence 28 (1986), 71-85. [Back to top]", "https://cs.brown.edu/courses/cs242/": "Brown CS 242 Probabilistic Graphical Models, Fall 2016. News Lectures Assignments Projects Resources Syllabus Probabilistic graphical models provide a flexible framework for describing large, complex, heterogeneous collections of random variables. This course surveys state-of-the-art methods for statistical learning and inference in graphical models, as motivated by applications in image and video analysis, text and language processing, sensor networks, autonomous robotics, biological structure prediction, social networks, and more. We will study efficient inference algorithms based on optimization-based variational methods, and simulation-based Monte Carlo methods. Several approaches to learning from data will be covered, including conditional models for discriminative learning, and Bayesian methods for controlling model complexity. Motivating applications will be explored via homework assignments and a final project. See the Fall 2016 syllabus for further details. News Have Questions? September 7, 2016 All students should sign up for the CS242 Piazza discussion site . Please watch Piazza for course announcements, and use it to post questions about homeworks and projects. Please Register! September 7, 2016 All students need to complete the CS242 registration survey . Without this, you won't be able to handin assignments or have them graded! Welcome! September 6, 2016 The first lecture is on Thursday, September 8 at 2:30pm in CIT 368 . To learn more about course prerequisites, see the webpage for CS 142: Introduction to Machine Learning . Brown University Computer Science CSCI 2420 , Fall 2016 Lectures on Probabilistic Graphical Models Tuesdays and Thursdays from 2:30-3:50pm, CIT 368 . Professor Erik Sudderth E-mail: lastname@cs.brown.edu Office Hours: Wednesdays from 11:00-12:00pm, CIT 555 Graduate TA Zhile Ren E-mail: lastname@cs.brown.edu Office Hours: Tuesdays & Wednesdays from 4:00-5:00pm, CIT 545 \u00a9 2016 Erik Sudderth , adapted from a design by styleshout . Go To Top window.jQuery || document.write('<script src=\"js/jquery-1.10.2.min.js\"><\\/script>')", "https://cs.brown.edu/courses/cs242/fall2014/": "Brown CS 242 Probabilistic Graphical Models, Fall 2014. News Lectures Assignments Projects Resources Syllabus Probabilistic graphical models provide a flexible framework for describing large, complex, heterogeneous collections of random variables. This course surveys state-of-the-art methods for statistical learning and inference in graphical models, as motivated by applications in image and video analysis, text and language processing, sensor networks, autonomous robotics, biological structure prediction, social networks, and more. We will study efficient inference algorithms based on optimization-based variational methods, and simulation-based Monte Carlo methods. Several approaches to learning from data will be covered, including conditional models for discriminative learning, and Bayesian methods for controlling model complexity. Motivating applications will be explored via homework assignments and a final project. See the Fall 2014 syllabus for further details. News Office Hours December 5, 2014 Regular office hours end on Friday, December 5. Additional office hours during reading period will be announced to the course mailing list. Thanksgiving Week November 24-28, 2014 During Thanksgiving week, the instructor and TA will be available for questions from 4:00-5:00pm on Tuesday, November 25. All other office hours are cancelled. Project Proposals November 3, 2014 The deadline for project proposals has been extended until Tuesday, November 11, 2014. See the detailed instructions . Discussion Group October 14, 2014 The Google group brown.course.csci.2420.2014-fall.s01 may be used to discuss assignments and projects. All registered students are members. Fall Weekend October 13, 2014 Normal office hours on Monday, October 13 are cancelled due to the Fall Weekend Holiday. Prof. Sudderth will instead hold office hours on Wednesday, October 15 from 4:00-5:00pm. Mailing List September 15, 2014 All registered students have been added to the primary course mailing list . Please confirm that you received the welcome message sent this afternoon, and that you regularly check e-mail sent to your CS account . Welcome! September 2, 2014 The first lecture is on Thursday, September 4 at 2:30pm in CIT 368 . After lecture, Prof. Sudderth will be available to answer questions about the course prerequisite, CS 142: Introduction to Machine Learning . Brown University Computer Science CSCI 2420 , Fall 2014 Lectures on Probabilistic Graphical Models Tuesdays and Thursdays from 2:30-3:50pm, CIT 368 . Final lecture on December 9, 2014. Professor Erik Sudderth E-mail: lastname@cs.brown.edu Office Hours: Mondays from 3:30-5:00pm, CIT 509 Graduate TA Jeroen Chua E-mail: firstname_lastname@brown.edu Office Hours: Tuesdays and Thursdays from 4:00-5:00pm, CIT 423 \u00a9 2014 Erik Sudderth , adapted from a design by styleshout . Go To Top window.jQuery || document.write('<script src=\"js/jquery-1.10.2.min.js\"><\\/script>')", "https://cs.brown.edu/courses/csci0050/2019/Lectures/Code/weather.csv": "Date,Place,Type,Data1/6/16,Houston,ozone,11/7/16,Houston,ozone,0.071/8/16,Houston,ozone,0.51/9/16,Houston,ozone,0.231/10/16,Houston,ozone,0.61/11/16,Houston,ozone,0.421/12/16,Houston,ozone,0.31/15/16,Houston,ozone,0.321/16/16,Houston,ozone,0.351/17/16,Houston,ozone,0.21/18/16,Houston,ozone,0.081/19/16,Houston,ozone,0.092/1/16,Houston,ozone,0.42/3/16,Houston,ozone,0.422/4/16,Houston,ozone,0.432/5/16,Houston,ozone,0.53", "https://cs.brown.edu/courses/cs250/": "CS 2500b: Optimization Algorithms for Planar Graphs Monday, Wednesday, Friday, 11:00-12:00 Instructor: <!--// <![CDATA[var zzuser = \"klein\";var zzhost = \"brown.edu\";var zzlink = \"Philip Klein\";document.write(\"<a href=\" + \"mai\" + \"lto:\" + zzuser + \"@\" + zzhost +\">\" + zzlink + \"</a>\");// ]]>//-- Location: CIT 477 Planargraphs arise in applications such as road map navigation and logistics, graph drawing, and image processing. In this course, we study algorithmic techniques that exploit planarity in addressing classical problems, e.g. Traveling Salesperson , Shortest Paths , and Maximum Flow . Prerequisite: CS 157 or equivalent (introductory algorithms) Focus The focus is on algorithms for addressing logistics and planning problems in road maps. Textbook Draft textbook chapters available at http://planarity.org (to be updated as the class proceeds). Work Homeworks will be assigned once every week or two for the first three-fourths of the semester. During the last one-fourth of the semester, students will work on projects. In addition, there will likely be a midterm to ensure students have mastered the basics. Class participation will also affect students' grades. Topics will be chosen from among the following Separators in trees Elementary graph theory Embedded graphs and duality Planar graphs and planar duality Maintaining a bounded-outdegree orientation Separators in planar graphs Primal-dual method for approximation Approximation algorithms for vertex-weighted Steiner trees and feedback vertex set Carvingwidth and branchwidth Optimization algorithms for graphs with bounded branchwidth Brenda Baker's method for approximation schemes Metric version of Baker's method, and approximation for {\\em $k$-center}/{\\em $r$-domination} Linear-time approximation scheme for traveling salesperson problem Brick decomposition and approximation scheme for Steiner traveling salesperson problem Approximation scheme for Steiner tree Prize-collecting clustering Approximation scheme for Steiner forest Bicriteria approximation scheme for bisection Maximum flow in directed $st$-planar graphs Shortest paths with nonnegative edge-lengths Dynamic-tree data structure Maximum flow in directed planar graphs Multiple-source shortest paths Maximum flow and multiple-source shortest paths in graphs with small weights Fast construction of brick decomposition Shortest paths in directed graphs with positive and negative edge-lengths Approximate distance oracle Fakcharoenphol-Rao priority queue Exact distance oracle Multiple-source multiple-sink maximum flow", "https://cs.brown.edu/courses/cs2951x/2021_spring.html": "CSCI 2951X: Reintegrating AI (Spring 2021) Overview Schedule Project Reading Further Reading Overview The goal of AI has been to build complete intelligent agents, yet the field has been fragmented into a collection of problem-specific areas of study. We will first spend a few weeks in lecture covering a new approach to integrating existing AI subfields into a single agent architecture, and remainder of the semester on self-directed, semester-long research projects. Grading will be based on a mid-semester project proposal, and a substantial open-ended final project. The projects will be multi-disciplinary in nature but students will have the opportunity to work in small groups, so they need not necessarily have expertise in the relevant areas. All students need special permission to enroll; advanced undergraduate students welcome. The 2018 incarnation of this course was a reading seminar; the old website and reading lists are here . Instructor George Konidaris Office: CIT 447 Email: gdk at cs dot brown dot edu [Back to top] Schedule The first class is on Thursday January 21st ,and the class is on a Tuesday-Thursday schedule, from 1:00pm to 2:20pm. The class is asynchronous: lectures will be deliveredvia Zoom ( at this link ) at the scheduled date and time, andyou are welcome to attend live, but recordings will be posted. After the first few lectures, you will break into project groups,and we will arrange asynchronous check-ins. [Back to top] Project Your project will be a substantial creative and original piece of work.I expect you to design and implement theory and experiments studying some algorithm or model that is aligned with the course content - i.e., a model that integrates at least two aspects of AI research in an interesting way. I expect it to have approximately the length, form, and content of a conference paper at a good AI conference (though it need not be publishable). That means careful, clear, and precise writing, a well-formalized and thoughtfully evaluated point, and thorough referencing throughout. It does not necessarily have to be an original contribution, although that would be nice. If it is not, then I expect at least an original evaluation that is relevant to our topic (e.g., an existing algorithm is tried in a new domain or addresses a setting that speaks to what we have discussed). The study will be graded on insight, completeness, and clarity. These studies can be completed in groups of between 1 and 4 people. Undergraduates taking the course should work in groups of at least 3. The project accounts for 100% of your grade and is due at the end of the reading period (April 19th). There is an intermediate deadline: a 2-page project proposal due by approximately mid-February,which identifies the topic, names the group, and sketches out what you hope to accomplish in the study. I will use these to discuss the project with each group to make sure they're on an appropriate path. [Back to top] Reading General background for embodiment and general AI (all quite dated): Elephants Don't Play Chess , R.A. Brooks. Shakey the Robot. N. Nilsson, ed. Technical Note 323, SRIInternational , April 1985. Video The Animat Path to AI , S.W. Wilson 1991. Behaviour: perception, action and intelligence - the view fromsituated robotics , J.C.T. Hallam and C.A. Malcolm, PhilosophicalTransactions of the Royal Society A (1994). (You'll need to login via Brown.) Structuralism: Kaelbling, Leslie Pack. The Foundation of Efficient Robot Learning . Science 369(6506), pages 915-916, August 2020. MDPs and RL: Kaelbling, Leslie Pack, Michael L. Littman, and Andrew W. Moore. Reinforcement learning: A survey. Journal of artificial intelligence research 4 (1996): 237-285. Object-Oriented MDPs: Diuk, Carlos, Andre Cohen, and Michael L. Littman. An object-oriented representation for efficient reinforcement learning. Proceedings of the 25th international conference on Machine learning. 2008. Abstraction in RL: Sutton, Richard S., Doina Precup, and Satinder Singh. Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning. Artificial intelligence 112.1-2 (1999): 181-211. Li, Lihong, Thomas J. Walsh, and Michael L. Littman. Towards a Unified Theory of State Abstraction for MDPs. ISAIM. 2006. David Abel, D Ellis Hershkowitz, Michael L. Littman. Near Optimal Behavior via Approximate State Abstraction. , ICML 2016. Problem-Specific Abstractions: Konidaris, George. On the necessity of abstraction. Current opinion in behavioral sciences 29 (2019): 1-7. POMDPs: Spaan, Matthijs TJ. Partially observable Markov decision processes. In Reinforcement Learning: The State of the Art. Springer, Berlin, Heidelberg, 2012. 387-414. Natural Language for MDPs: Jelena Luketina, Nantas Nardelli, Gregory Farquhar, Jakob Foerster, Jacob Andreas, Edward Grefenstette, Shimon Whiteson, Tim Rocktaschel. A Survey of Reinforcement Learning Informed by Natural Language , Proceedings of the Twenty-Eighth International Joint Conference on Artificial IntelligenceSurvey track. Pages 6309-6317. Further Reading Readings from the following booksare recommended for more in-depth engagement with the topic, thoughnote that all of these are now dated: Mind Design II, J. Haugeland, ed. Computers & Thought, E.A. Feigenbaum and J. Feldman, eds. Mindware, 2nd edition, Andy Clark, ed. Being There, Andy Clark. Cambrian Intelligence, R.A. Brooks. Dreyfus, Herbert and Dreyfus, Stuart, Making a Mind versus Modeling the Brain: Artificial Intelligence Back at a Branchpoint . Daedalus 117(1), pages 15-43, 1988. Also worth reading, but much more about philosophy than CS, is: Mind and Cognition, 2nd ed, W.G. Lycan, ed. These books and readings will be of interest to students who want to understandthe probabilistic foundation of AI more deeply: Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, by Judea Pearl. Probability Theory: The Logic of Science, by E.T. Jaynes. Probabilistic Logic, by Nils Nilsson. In Artificial Intelligence 28 (1986), 71-85. [Back to top]", "https://cs.brown.edu/courses/cs2951x/": "CSCI 2951X: Reintegrating AI (Spring 2024) Overview Schedule Project Reading Further Reading Overview The goal of AI has been to build complete intelligent agents, yet the field has been fragmented into a collection of problem-specific areas of study. We will first spend a few weeks in lecture covering a new approach to integrating existing AI subfields into a single agent architecture, and remainder of the semester on self-directed, semester-long research projects. Grading will be based on a mid-semester project proposal, and a substantial open-ended final project. The projects will be multi-disciplinary in nature but students will have the opportunity to work in small groups, so they need not necessarily have expertise in the relevant areas. All students need special permission to enroll; advanced undergraduate students welcome. The 2018 incarnation of this course was a reading seminar; the old website and reading lists are here . Instructor George Konidaris Office: CIT 447 Email: gdk at brown dot edu [Back to top] Schedule The first class is on Tuesday January 30th (there will be no class on January 25th ), meeting weekly on Tuesday and Thursday from 1-2:20pm in CIT 477 (Lubrano) .The first few sessions will be lectures, after which we will break into project groups, and weekly meetings will be progress check-ins and discussions with each group. [Back to top] b Project Your project will be a substantial creative and original piece of work.I expect you to design and implement theory and experiments studying some algorithm or model that is aligned with the course content - i.e., a model that integrates at least two aspects of AI research in an interesting way. I expect it to have approximately the length, form, and content of a conference paper at a good AI conference (though it need not be publishable). That means careful, clear, and precise writing, a well-formalized and thoughtfully evaluated point, and thorough referencing throughout. It does not necessarily have to be an original contribution, although that would be nice. If it is not, then I expect at least an original evaluation that is relevant to our topic (e.g., an existing algorithm is tried in a new domain or addresses a setting that speaks to what we have discussed). The study will be graded on insight, completeness, and clarity. These studies can be completed in groups of ~5 people. This year your project proposal will have to include a half-page statementexplaining which model of a general intelligence you are using, and how your project fits into realizing that model. The project accounts for 100% of your grade and is due at the end of the reading period (May 8th). There is an intermediate deadline: a 2-page project proposal due by approximately mid-March,which identifies the topic, names the group, and sketches out what you hope to accomplish in the study. I will use these to discuss the project with each group to make sure they're on an appropriate path. [Back to top] Reading General background for embodiment and general AI (all quite dated): Elephants Don't Play Chess , R.A. Brooks. Shakey the Robot. N. Nilsson, ed. Technical Note 323, SRIInternational , April 1985. Video The Animat Path to AI , S.W. Wilson 1991. Behaviour: perception, action and intelligence - the view fromsituated robotics , J.C.T. Hallam and C.A. Malcolm, PhilosophicalTransactions of the Royal Society A (1994). (You'll need to login via Brown.) Structuralism: Kaelbling, Leslie Pack. The Foundation of Efficient Robot Learning . Science 369(6506), pages 915-916, August 2020. The data-driven approach: Y. LeCun. A Path Towards Autonomous Machine Intelligence . 2022. Blaise Ag\u00fcera y Arcas and Peter Norvig. Artificial General Intelligence is Already Here . Noema Magazine, October 2023. More cognitive approaches: A. Laird, A. Newell, and P.S. Rosenbloom. Soar: An architecture for general intelligence , Artificial Intelligence 33(1), 1987. B.M. Lake, T.D. Ullman, J.B. Tenenbaum, and S.J. Gershman. Building machines that learn and think like people , Behavioral and Brain Sciences 40, 2017. MDPs and RL: D. Silver, S. Singh, D. Precup, and R.S. Sutton. Reward is Enough . Artificial Intelligence 299, October 2021. Kaelbling, Leslie Pack, Michael L. Littman, and Andrew W. Moore. Reinforcement learning: A survey. Journal of artificial intelligence research 4 (1996): 237-285. Object-Oriented MDPs: Diuk, Carlos, Andre Cohen, and Michael L. Littman. An object-oriented representation for efficient reinforcement learning. Proceedings of the 25th international conference on Machine learning. 2008. Abstraction in RL: Sutton, Richard S., Doina Precup, and Satinder Singh. Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning. Artificial intelligence 112.1-2 (1999): 181-211. Li, Lihong, Thomas J. Walsh, and Michael L. Littman. Towards a Unified Theory of State Abstraction for MDPs. ISAIM. 2006. David Abel, D Ellis Hershkowitz, Michael L. Littman. Near Optimal Behavior via Approximate State Abstraction. , ICML 2016. Problem-Specific Abstractions: Konidaris, George. On the necessity of abstraction. Current opinion in behavioral sciences 29 (2019): 1-7. POMDPs: Spaan, Matthijs TJ. Partially observable Markov decision processes. In Reinforcement Learning: The State of the Art. Springer, Berlin, Heidelberg, 2012. 387-414. Natural Language for MDPs: Jelena Luketina, Nantas Nardelli, Gregory Farquhar, Jakob Foerster, Jacob Andreas, Edward Grefenstette, Shimon Whiteson, Tim Rocktaschel. A Survey of Reinforcement Learning Informed by Natural Language , Proceedings of the Twenty-Eighth International Joint Conference on Artificial IntelligenceSurvey track. Pages 6309-6317. R. Rodriguez-Sanchez, R. Patel, and G.D. Konidaris. On the Relationship Between Structure in Natural Language and Models of Sequential Decision Processes . In The First Workshop on Language in Reinforcement Learning at ICML 2020, July 2020. Further Reading Readings from the following booksare recommended for more in-depth engagement with the topic, thoughnote that all of these are now dated: Mind Design II, J. Haugeland, ed. Computers & Thought, E.A. Feigenbaum and J. Feldman, eds. Mindware, 2nd edition, Andy Clark, ed. Being There, Andy Clark. Cambrian Intelligence, R.A. Brooks. Dreyfus, Herbert and Dreyfus, Stuart, Making a Mind versus Modeling the Brain: Artificial Intelligence Back at a Branchpoint . Daedalus 117(1), pages 15-43, 1988. Also worth reading, but much more about philosophy than CS, is: Mind and Cognition, 2nd ed, W.G. Lycan, ed. These books and readings will be of interest to students who want to understandthe probabilistic foundation of AI more deeply: Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, by Judea Pearl. Probability Theory: The Logic of Science, by E.T. Jaynes. Probabilistic Logic, by Nils Nilsson. In Artificial Intelligence 28 (1986), 71-85. [Back to top]", "https://cs.brown.edu/courses/cs2951x/2023_spring.html": "CSCI 2951X: Reintegrating AI (Spring 2023) b Overview Schedule Project Reading Further Reading Overview The goal of AI has been to build complete intelligent agents, yet the field has been fragmented into a collection of problem-specific areas of study. We will first spend a few weeks in lecture covering a new approach to integrating existing AI subfields into a single agent architecture, and remainder of the semester on self-directed, semester-long research projects. Grading will be based on a mid-semester project proposal, and a substantial open-ended final project. The projects will be multi-disciplinary in nature but students will have the opportunity to work in small groups, so they need not necessarily have expertise in the relevant areas. All students need special permission to enroll; advanced undergraduate students welcome. The 2018 incarnation of this course was a reading seminar; the old website and reading lists are here . Instructor George Konidaris Office: CIT 447 Email: gdk at cs dot brown dot edu [Back to top] Schedule The first class is on Thursday January 26th , meeting weekly on Tuesdays and Thursdays from 1-2:20pm in CIT 477 (Lubrano). The first few sessions will be lectures (which will be recorded and uploaded to Pantopo, and so can be watched asynchronously), after which we will break into project groups, and weekly meetings will be progress check-ins and discussions with each group. [Back to top] b Project Your project will be a substantial creative and original piece of work.I expect you to design and implement theory and experiments studying some algorithm or model that is aligned with the course content - i.e., a model that integrates at least two aspects of AI research in an interesting way. I expect it to have approximately the length, form, and content of a conference paper at a good AI conference (though it need not be publishable). That means careful, clear, and precise writing, a well-formalized and thoughtfully evaluated point, and thorough referencing throughout. It does not necessarily have to be an original contribution, although that would be nice. If it is not, then I expect at least an original evaluation that is relevant to our topic (e.g., an existing algorithm is tried in a new domain or addresses a setting that speaks to what we have discussed). The study will be graded on insight, completeness, and clarity. These studies can be completed in groups of between 1 and 4 people. Undergraduates taking the course should work in groups of at least 3. The project accounts for 100% of your grade and is due at the end of the reading period (May 10th). There is an intermediate deadline: a 2-page project proposal due by approximately mid-March,which identifies the topic, names the group, and sketches out what you hope to accomplish in the study. I will use these to discuss the project with each group to make sure they're on an appropriate path. [Back to top] Reading General background for embodiment and general AI (all quite dated): Elephants Don't Play Chess , R.A. Brooks. Shakey the Robot. N. Nilsson, ed. Technical Note 323, SRIInternational , April 1985. Video The Animat Path to AI , S.W. Wilson 1991. Behaviour: perception, action and intelligence - the view fromsituated robotics , J.C.T. Hallam and C.A. Malcolm, PhilosophicalTransactions of the Royal Society A (1994). (You'll need to login via Brown.) Structuralism: Kaelbling, Leslie Pack. The Foundation of Efficient Robot Learning . Science 369(6506), pages 915-916, August 2020. MDPs and RL: Kaelbling, Leslie Pack, Michael L. Littman, and Andrew W. Moore. Reinforcement learning: A survey. Journal of artificial intelligence research 4 (1996): 237-285. Object-Oriented MDPs: Diuk, Carlos, Andre Cohen, and Michael L. Littman. An object-oriented representation for efficient reinforcement learning. Proceedings of the 25th international conference on Machine learning. 2008. Abstraction in RL: Sutton, Richard S., Doina Precup, and Satinder Singh. Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning. Artificial intelligence 112.1-2 (1999): 181-211. Li, Lihong, Thomas J. Walsh, and Michael L. Littman. Towards a Unified Theory of State Abstraction for MDPs. ISAIM. 2006. David Abel, D Ellis Hershkowitz, Michael L. Littman. Near Optimal Behavior via Approximate State Abstraction. , ICML 2016. Problem-Specific Abstractions: Konidaris, George. On the necessity of abstraction. Current opinion in behavioral sciences 29 (2019): 1-7. POMDPs: Spaan, Matthijs TJ. Partially observable Markov decision processes. In Reinforcement Learning: The State of the Art. Springer, Berlin, Heidelberg, 2012. 387-414. Natural Language for MDPs: Jelena Luketina, Nantas Nardelli, Gregory Farquhar, Jakob Foerster, Jacob Andreas, Edward Grefenstette, Shimon Whiteson, Tim Rocktaschel. A Survey of Reinforcement Learning Informed by Natural Language , Proceedings of the Twenty-Eighth International Joint Conference on Artificial IntelligenceSurvey track. Pages 6309-6317. R. Rodriguez-Sanchez, R. Patel, and G.D. Konidaris. On the Relationship Between Structure in Natural Language and Models of Sequential Decision Processes . In The First Workshop on Language in Reinforcement Learning at ICML 2020, July 2020. Further Reading Readings from the following booksare recommended for more in-depth engagement with the topic, thoughnote that all of these are now dated: Mind Design II, J. Haugeland, ed. Computers & Thought, E.A. Feigenbaum and J. Feldman, eds. Mindware, 2nd edition, Andy Clark, ed. Being There, Andy Clark. Cambrian Intelligence, R.A. Brooks. Dreyfus, Herbert and Dreyfus, Stuart, Making a Mind versus Modeling the Brain: Artificial Intelligence Back at a Branchpoint . Daedalus 117(1), pages 15-43, 1988. Also worth reading, but much more about philosophy than CS, is: Mind and Cognition, 2nd ed, W.G. Lycan, ed. These books and readings will be of interest to students who want to understandthe probabilistic foundation of AI more deeply: Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, by Judea Pearl. Probability Theory: The Logic of Science, by E.T. Jaynes. Probabilistic Logic, by Nils Nilsson. In Artificial Intelligence 28 (1986), 71-85. [Back to top]", "https://browncs1951x.github.io": "CS 1951x : Formal Proof and Verification Fall 2023 Assignments Lectures Calendar Resources Staff Project \u2630 CS 1951x Assignments Lectures Calendar Resources Staff Project \u2630 Course Description Proof assistants are tools that are used to check the correctness of programs. Unlike tools like model checkers and SAT solvers, proof assistants are highly interactive. Machine-checked formal proofs lead to trustworthy programs and fully specified reliable mathematics. This course introduces students to the theory and use of proof assistants, using the system Lean. We will use Lean to verify properties of functional programs and theorems from pure mathematics. We will learn the theory of deductive reasoning and the logic that these tools are based on. Syllabus: syllabus.pdf Lecture: MW 3:00\u20134:20 p.m., CIT 368 Lab: Th 4:30\u20136:00 p.m., CIT 210 Course Content We plan to cover most of the Hitchhiker\u2019s Guide to Logical Verification . We'll cover chapters roughly according to the schedule below, but topics may shift slightly as the semester progresses. Basics 1. Types and Terms 2. Programs and Theorems 3. Backward Proofs 4. Forward Proofs Functional-Logic Programming 5. Functional Programming 6. Inductive Predicates Program Semantics 9. Operational Semantics Mathematics 12. Logical Foundations 13. Basic Mathematical Structures 14. Rational and Real Numbers Meta-Reasoning 7. Monads 8. Metaprogramming Assignments Homework Homework will be submitted via Gradescope . Please ensure that you have familiarized yourself with the grading and collaboration policies in the syllabus . Homework Material Covered Released Due HW 1 Ch. 1, 2 9/11/23 9/20/23 HW 2 Ch. 3 9/18/23 9/27/23 HW 3 Ch. 4 9/25/23 10/4/23 HW 4 Ch. 5 10/2/23 10/11/23 10/13/23 HW 5 Ch. 6 10/16/23 10/25/23 HW 6 Ch. 9 10/23/23 11/1/23 HW 7 Ch. 13 10/30/23 11/8/23 HW 8 Ch. 12 11/6/23 11/15/23 HW 9 Ch. 14 11/15/23 11/29/23 HW 10 (optional) Ch. 8 11/28/23 12/6/23 Final Project 12/17/23 Labs Labs are optional, TA-guided sessions that provide an opportunity to practice and reinforce the content covered in lecture. Labs are held every Thursday, 4:30\u20136:00 p.m. in CIT 210 . Lab Date Lab 1 (Lean Basics) 9/14/23 Lab 2 (Backward Proofs) 9/21/23 Lab 3 (Forward Proofs) 9/28/23 Lab 4 (Functional Programming) 10/5/23 Lab 5 (Inductive Predicates) 10/12/23 Lab 6 (Operational Semantics) 10/19/23 Lab 7 (Algebraic Structures) 11/2/23 Lab 8 (Logical Foundations) 11/9/23 Lab 9 (Rationals and Reals) 11/16/23 Lab 10 (Monads and Tactics) 11/30/23 Lectures You can download lecture demo files and view lecture recordings here. We will aim to update this table shortly after each lecture. All lecture recordings can also be found on Panopto . Date Topic Downloads Summary 9/6 Introduction Ch. 0 demo file We'll talk about what Lean is and see what it can do, and also go over some organizational points about the course. Takeaways: Verified programming is fun and powerful! 9/11 The basics of Lean syntax Ch. 1-2 demo file In this lecture we'll learn the basics of the Lean programming and specification language: types and terms, type inhabitation, and writing and evaluating very simple functional programs. No proving yet! 9/13 Dependent type theory Ch. 1-2 demo file We'll finish Chapter 2 of the HHG, and get a head start on some material from Chapter 4. Today's topics: inductive types (continued), function definition and evaluation, specifications, and dependent type theory. 9/18 Backward (tactic) proofs Ch. 3 demo file We'll dive into the meat of the HHG Ch. 3: what are some of the moves available to us in the tactic proving minigame, beyond intro and apply ? How do we deal with logical connectives: And , Or , Not , and so on? 9/20 Backward (tactic) proofs, contd. Ch. 3 demo file We'll continue talking about tactic proofs. How do we deal with equality ? What about the natural numbers? We'll also talk about classical vs constructive logic. 9/25 Forward proofs Ch. 4 demo file We'll see another way to write proofs in Lean, incorporating forward reasoning . Structured (\"proof-term\") proofs are a little closer to the underlying logic. Surprise: proofs in Lean are, literally, just terms in the type theory. 9/27 Dependent types Ch. 4 demo file We talked about dependent types before; now, more. The type theory that Lean is based on, the Calculus of Inductive Constructions, is an instance of dependent type theory. In DTT, we follow the PAT principle: propositions as types, proofs as terms. (Buzzword: the Curry-Howard correspondence!) We'll look deeper today into these foundations. Time permitting, we'll look at a few important algorithms, including unification . 10/2 Functional programming: data structures Ch. 5 demo file Chapter 5 of the Hitchhiker's Guide introduces some paradigms \u2014 inductive types, structures, recursive definitions, type classes \u2014 that might be familiar from other functional programming languages. The interesting thing for us is how these paradigms interact with writing proofs. For instance, how do we mix properties into data structures ? 10/4 Functional programming: type classes, lists, trees Ch. 5 demo file Type classes are a language feature inspired by Haskell with equivalents in Scala, ML, and other languages. They allow us a kind of ad hoc polymorphism : we can define functions on types that implement certain interfaces, and can declare that certain types implement these interfaces, without bundling the interfaces into the data type itself. we'll see how this interacts with some of the data structures we like to use, as we implement and specify functions on these types. 10/11 Inductive predicates Ch. 6 demo file We'll cover ch. 6 of the Hitchhiker's Guide today, on inductive predicates. This will complete what we need to know about foundations for now: inductive predicates give us a way to introduce new propositions and prove things about them. Inductive predicates are also the source of most of the propositional symbols we've used so far \u2014 And , Or , Exists , Eq , \u2026. 10/16 Big-step operational semantics Ch. 9 demo file We're jumping ahead to Chapter 9 today! Time to start putting what we've learned into practice. We'll define the syntax of a toy programming language inside of Lean, discussing the difference between shallow and deep embeddings. Using inductive predicates, we'll define a transition system and use this to prove things about the execution of programs in this toy language. 10/18 Small-step operational semantics Ch. 9 demo file The big-step semantics we saw on Monday aren't fine-grained. We can't reason about intermediate states. An alternative is using a small-step semantics, where our program execution path is broken down much further. This comes with upsides and downsides. 10/23 A look under the hood Ch. XX demo file We'll talk theory today, about the data structures and process flow that underlie a proof assistant. Basically, we'll think about Lean as a programming language in the sense of the last two lectures. What's its syntax? What are its semantics ?? 10/25 Logical foundations Ch. 12 demo file Russellian paradox demo As this course has progressed, we've gotten some insight into the foundations of Lean and its type theory. But some features have remained mysterious. In the next few lectures we'll poke some more at this foundational theory. Today we'll be focusing in particular on the type universe Prop , what we're allowed and disallowed in this universe compared to the others. 10/30 Algebraic structures Ch. 13 demo file Complex numbers playground We'll jump ahead again to chapter 13, where we'll start talking about algebraic structures. But we'll also improvise a bit here. After we see some basic structures, we'll define some mathematical types of our own. 11/1 Numbers and sets Ch. 13 demo file Complex numbers playground We'll continue the Ch 13 material we started last time, including a little more with the complex number playground. We'll also talk about embeddings between different numerical structures, and some different kinds of \"set-like\" objects. 11/6 Logical foundations, contd. Ch. 12 demo file Ch. 13 demo file Complex numbers playground We'll continue with chapter 12 today, talking about more foundational constructs. As we discussed last class, there's a grab bag of features that we can take or leave: proof irrelevance, impredicative Prop, the axiom of choice, and others. Why should we be convinced that the collection we choose is consistent? We'll introduce the notion of a model of the type theory to answer questions like this. 11/8 Quotients, rationals, and reals Ch. 12 demo file Ch. 14 demo file The last bit of Ch. 12, on quotient types, is very relevant to what we want to do next! We'll wrap up that discussion (including talking a bit about the computability properties of quotients) and then immediately use quotient types to define some familiar things. Rational and real numbers are interesting mathematically, and for programming purposes, they can be a very convenient tool for writing specifications. Even if we don't compute with real numbers they're useful to have around. 11/13 Real numbers Ch. 14 demo file We finished last week with the rational numbers. Now we need to complete them to get the reals. This will take yet another quotient. The reals bring to light some computability issues that we've touched on briefly before: what does it mean to compute with real numbers? How do we do it in normal languages? If time permits, we'll look at mathlib's implementation of the reals and see some generalizations. 11/20 Monads and tactics Ch. 7 demo file Lean has a very powerful framework for writing custom tactics. These tactics are written in Lean itself, with a number of catches to make this possible. Today we'll see the fundamentals of this approach. We'll learn the (very) basics about monads, a technique used in some functional languages to simulate programming with side effects. (But this isn't an FP class and we're not going to dwell on monads, beyond what we need to know.) Chapter 7 of the HHG is a more detailed introduction to monads. 11/27 Monads and tactics Ch. 8 demo file More from chapters 7 and 8 of the HHG. We'll look at macros , a simple kind of metaprogram. Then we'll turn our attention to the TacticM monad, which provides an API for interacting with our context and goals. 11/29 Monads and tactics Ch. 8 demo file We'll continue our discussion of metaprogramming by implementing a few custom tactics. Along the way, we'll see some more metaprogramming techniques and a few \"imperative-like\" features of monads that make our lives easier when writing tactics. 12/4 Tactic design strategies Tactic strategies demo file The tactics we've seen so far manipulate the tactic state in stages. Today we'll consider some high level designs for automation: proof by certificate and proof by reflection. We'll also talk about the strategy and algorithm behind the tactic linarith , a great example of a \"large\" metaprogram that shows off a number of interesting design principles. 12/6 Guest lecture: Mario Carneiro Mario will tell us about (part of) his paper on Lean's type theory . In particular: what does it mean to have a model of Lean in ZFC? Calendar Resources Course Links Syllabus Course Textbook Setup Instructions Course GitHub Repository Final Project Information Hours Queue Ed Discussion Anonymous Feedback Form Extension Request Form Lean Documentation & Resources Loogle , a search tool for Mathlib The Lean Language Manual An index of Lean tactics Functional Programmming in Lean , a text focusing on Lean as a programming language instead of a theorem prover Metaprogramming in Lean 4 , a reference to programming-for-proving Official Lean/mathlib4 API documentation Theorem Proving in Lean 4 , a comprehensive introduction to the system The leanprover-community website Concrete Semantics: With Isabelle/HOL , a textbook that covers similar material in a different proof assistant The Lean Zulip Chat is a very active and very helpful discussion site. Search the history here, or post questions in the \u201cNew Members\u201d stream. (Note: please don\u2019t ask course-specific questions here. When in doubt, talk to the course staff first. This is a great resource if you want to learn beyond our course!) Staff To email the course staff, click here . To email just the HTA and Rob, click here . To email Rob directly, click here . You are also encouraged to post (and answer!) questions on Ed Discussion. Robert Y. Lewis Professor Call me Rob! I'm half computer scientist, half mathematician, and fully excited to go through some of my favorite material with you all this semester. Pronouns: he/him/his Joseph Rotella HTA I'm a senior concentrating in math-CS. When not extolling the virtues of functional programming, I can be found playing piano, cycling, or reading in the Rock stacks. Ryan Edmonds UTA I\u2019m an MSc student with interests in game theory, graph algorithms, and logic. Outside of the classroom, I enjoy strategy games, MMORPGs, and progressive metal, and will happily chat about all of the above! Pronouns: he/him/his Yizhong Hu UTA I'm a senior concentrating in APMA-CS and Physics with an interest in Complex Systems/Nonlinear Dynamics. I also enjoy talking about Anime, classical music, and Linguistics. Pronouns: he/him/his Copyright \u00a9 2023 CSCI 1951X at Brown University", "https://cs.brown.edu/courses/csci0050/2019/Lectures/envs-practice.html": "\u25ba Class summary: Practice with Known Names 1 Recap: What\u2019s in the Environment Class summary: Practice with Known Names 1 Recap: What\u2019s in the Environment 1.1 Practice Exercises Class summary: Practice with Known Names Copyright (c) 2017 Kathi Fisler We have talked about how Pyret maintains a collection of \"known names\"under the hood. Pyret uses the \"known names\" area to look up thevalues associated with names while running your program. We\u2019ve talkeda bit about this idea, but today we want to look at it in much moredetail, since managing known names is one of the essential tasks inany programming language. While we\u2019ve been using the informal term \"known names\", the actualtechnical term for this mapping from names to values is theenvironment . We\u2019ll switch to using the actual term now that youhopefully have intuition about the concept. 1 Recap: What\u2019s in the Environment So far, we\u2019ve had the following rules for populating the environment: A bunch of standard functions, like + and string-length are in the environment by default If you use include , you add several more functions (e.g.,on tables or images) to the environment If you associate a name with a value using name = some-expression then name goes into the environment, associated with the value fromcomputing some-expression . If a name gets added to the environment while Pyret isevaluating the body of a function, Pyret creates a temporaryenvironment for definitions that arise within the function. Pyretdeletes the temporary environment once the function body bfinishesevaluating. There\u2019s one more rule we haven\u2019t talked about yet. Up until now, wehave said that when you call a function, Pyret substitutes the inputsthat you provided for the variables within the function. Actually,Pyret just makes entries in the temporary environment for thevariables and associates those names with the values youprovided. This behaves the same way as substitution, but it will provea bit easier for us to work with as our programs get more complicated. Let\u2019s Try It : For the following program, what is in theenvironment at each of the marked points? month = \"July\" # point 1 fun create-date(day :: Number) -> String: # point 3 month + \" \" + day + \", 2019\" end # point 2 today = create-date(7) # point 4 Answer: We\u2019ll omit the Pyret defaults as we write these out. At point 1, the environment has month -> \"July\" At point 2, the environment has month -> \"July\" create-date -> function<...> At point 3, the environment has month -> \"July\" create-date -> function<...> ------ # we'll use lines to mark off the temporary environment day = 7 ------ At point 4, the environment has month -> \"July\" create-date -> function<...> today = \"July 7, 2019\" Notice that day goes into the temporary environment for theuse (call) of the function, then disappears once the function has finished. Question: Point 3 appears on an earlier line than Point 2 in the originalcode sample. Why did we use that numbering, instead of swapping points2 and 3? (Hint: what order does the code get evaluated in?} 1.1 Practice Exercises We worked through two handouts of sample programs to make sure you seehow the environment works in different situations ( handout 1 \u2013 handout 2 ). For each handout,you were asked to indicate what order the lines are executed in, andthe environment contents at each marked point. Hopefully these exercises have helped you strengthen yourunderstanding of how programs evaluate in Pyret. These rules arefairly standard across most programming languages. Takeaways from this segment: Two functions can use the same variable name. The two nameswon\u2019t clash due to the temporary environments. The same value can be referenced via multiple names during thecourse of a program. This allows programmers to use different names indifferent parts of the code without causing problems. If the same function is called multiple times, it gets a freshtemporary environment on each call.", "https://cs.brown.edu/courses/csci0050/2019/Lectures/handling-table-errors.html": "\u25ba Class summary: Handling Tables Errors with Programs 1 Identifying Table Errors 2 Managing Table Errors 3 Setting Up a Data Analysis file Class summary: Handling Tables Errors with Programs 1 Identifying Table Errors 2 Managing Table Errors 3 Setting Up a Data Analysis file Class summary: Handling Tables Errors with Programs Copyright (c) 2017 Kathi Fisler 1 Identifying Table Errors Last class, we talked about the importance of sanity checking databefore you begin to work with it. Let\u2019s briefly review what that meanson a concrete example, then look at how to use programs to help usmanage the sanicty-checking process. Open up this table of partial salary information for a small business. Spend a couple ofminutes looking at the table. What do you notice that warrants beingchecked or fixed about this data. Potential issues include: Names of departments aren\u2019t spelled or capitalized consistently One salary level seems much higher than the others Someone at a lower salary level is making more than someone elseat another level, even within the same department 2 Managing Table Errors How many of these errors could we check (or correct) with small Pyretprograms? Many, as it turns out, though some point to additionalprogramming constructs that would be nice to have. Here is the starter file that loads the salary table into Pyret. We wrote a series of functions to work on different issues from theoriginal table. You can see the resulting code in the final codehandout posted to the lectures page. 3 Setting Up a Data Analysis file Now that we have a slew of programs to help detect, and in some casesclean, a data file, how should we use all of this in setting up a datatable for doing some sort of deeper statistical or other analysis? Partly, this is a question of how to balance naming intermediatetables and keeping the collection of table names manageable forpeople. As a general rule, it makes sense to name the raw data tablethat you import into your program, to name the cleaned-up table, andto name any portions of the table that you want to use in multipleanalyses. For example: #| THE CLEANING CODE TEMPLATE raw-data = load-table(...) check for issues repair issues via programs sanity check values clean-data = result of all repairs ... then work only with the clean data |#", "https://cs.brown.edu/courses/csci0030/": "CS 3 CLASS MATERIALS TA HOURS RESOURCES CALENDAR PIAZZA CS 3 Introduction to Computation for the Humanities and Social Sciences Learn More Class Time Classes start the week of 09/10. They will be held during the 9:00-10:20 AM ET block on Tuesdays and Thursdays. All meetings will be recorded, and the videos will be uploaded to the class materials page. The zoom link for all classes is https://brown.zoom.us/my/aagarwal . Welcome Thanks for your interest in our course! In the past fifty years, computing has irrevocably changed subjects like engineering, physics, and biology, and it is now starting to do the same for the social sciences and humanities. You stand at the cusp of a new computing revolution. We offer a supportive environment that, combined with your hard work, will put you at the front of this wave. With the skills you get in this course, you should be able to contribute much more effectively to your chosen field, whatever it is, as computation takes a larger role over time. The course will be held synchronously. Students are encouraged to attend live lectures. However, recorded sessions will also be available. Waitlist We only have so much room in the classroom, so if you would like to take the course, please add yourself here , and we'll do our best to admit as many people as possible If we can't admit you this semester, you will be considered for next semester. In any case, to be admitted to the course, you must attend every class, and do the homework assignments. Finally, if you have special circumstances (e.g., you enrolled last semester but talked to us about taking it this semester instead), we'll take that into account. Remind us if it looks like we've forgotten. For now, don't sweat it. Background We require no prior computer science or mathematical background! As long as you are interested in learning, you have all the background we need. If you have done any prior programming, this is probably not the class for you. See here for other CS classes you can take. Workload You've probably heard legends about computer science workloads. Some of the legends are true, many are not. Either way, CS 3 is not your typical computer science course. We expect you to put in roughly 6-8 hours per week (including class time). Depending on your perspective, this can seem like a little or a lot. All the course staff are available to help you, but learning the material in this course requires a time investment. We require people to use laptops for the course. Since the classroom doesn't have any computers, you'll be required to bring a laptop to class to do the work. If you don't have a laptop, talk with the course staff \u2014 we will direct you to resources that have laptops available. Design: HTML5 UP", "https://cs.brown.edu/courses/csci0050/2018/": "\u2022 CSCI0050- Home CSCI0050- Home CSCI0050: A Data-Centric Introduction to Programming (Summer 2018) Home Schedule Staff Learning Software Policies Canvas Piazza Time : Mon/Wed/Thurs 9:00-11:40am Location : SciLi 618 CSCI-50 provides an introduction to computer programming with a focus on skills needed for data-intensive applications. Topics include core constructs for processing both tabular and structured data (including lists and trees); decomposing problems into programming tasks; data structures; algorithms; and testing programs for correct behavior. The course does not assume any prior programming background; many assignments will have (optional) advanced material for students who already have some programming background or who want to cover the topic in greater depth. This is a computer science and programming course, not a data science course. While we will cover concepts and programming constructs and software practices that are highly relevant for data science, we will not cover statistics or statistics-focused programming. The course has been designed to provide the computer science background needed for Brown\u2019s Data Science masters program (but the course is open to all who wish to enroll). CSCI-50 does not currently satisfy the introductory programming sequence requirement for CS (undergraduate) concentrators. If you are interested in options that lead into the CS concentration, talk to Professor Fisler. Class sessions will interleave lecture and hands-on exercises (both programming and conceptual). Students are expected to participate and work with others during class sessions. Page maintained by Kathi Fisler", "https://cs.brown.edu/courses/csci0050/2017/": "\u2022 CSCI0050- Home CSCI0050- Home CSCI0050: A Data-Centric Introduction to Programming Home Schedule Staff Learning Software Policies Canvas Piazza Time : Mon/Wed/Thurs 9:00-11:40am Location : CIT 227 CSCI-50 provides an introduction to computer programming with a focuson skills needed for data-intensive applications. Topics include coreconstructs for processing both tabular and structured data (includinglists and trees); decomposing problems into programming tasks; datastructures; algorithms; and testing programs for correct behavior. Thecourse does not assume any prior programming background. This is a computer science and programming course, not adata science course. While we will cover concepts and programmingconstructs that are relevant for data science, we will not coverstatistics or statistics-focused programming. The course has beendesigned to provide the computer science background needed for Brown\u2019sData Science masters program (but the course is open to all who wishto enroll). CSCI-50 does not satisfy the introductory programmingsequence requirement for CS (undergraduate) concentrators. Studentsinterested in concentrating in CS should take CSCI 0150, 0170, or 0190instead. Class sessions will interleave lecture and hands-on programmingpractice. Students are encouraged to work with others during classsessions, and outside of class on some assignments. Page maintained by Kathi Fisler", "https://cs.brown.edu/courses/csci0050/2019/": "\u2022 CSCI0050- Home CSCI0050- Home CSCI0050: A Data-Centric Introduction to Programming (Summer 2019) Home Schedule Staff Learning Software Policies Canvas Piazza Time : Mon/Wed/Thurs 9:00-11:40am Location : CIT 368 (though first two classes in CIT 477/Lubrano) CSCI-50 provides an introduction to computer programming with a focus on skills needed for data-intensive applications. Topics include core constructs for processing both tabular and structured data (including lists and trees); decomposing problems into programming tasks; data structures; algorithms; and testing programs for correct behavior. The course does not assume any prior programming background; many assignments will have (optional) advanced material for students who already have some programming background or who want to cover the topic in greater depth. This is a computer science and programming course, not a data science course. While we will cover concepts and programming constructs and software practices that are highly relevant for data science, we will not cover statistics or statistics-focused programming. The course has been designed to provide the computer science background needed for Brown\u2019s Data Science masters program (but the course is open to all who wish to enroll). CSCI-50 does not currently satisfy the introductory programming sequence requirement for CS (undergraduate) concentrators. If you are interested in options that lead into the CS concentration, talk to Professor Fisler. Class sessions will interleave lecture and hands-on exercises (both programming and conceptual). Students are expected to participate and work with others during class sessions. Page maintained by Kathi Fisler", "https://cs.brown.edu/courses/csci0111/fall2020/going-to-18.html": "Skip to main content CS111 Lectures Assignments Labs Learning Resources Software Hours Staff Campuswire Going to CS 0180 (aka CS18) CS 0111 and CS 0180 form a valid intro sequence for all CS and CS-joint concentrations. You might not yet see this listed in the Brown Bulletin (we are working on those edits), but it has been approved in all appropriate departments. All CS intro sequences (0150/0160, 0170/0180, 0111/0112/0180, 0111/0180, and 0190) prepare you for subsequent courses in the CS department. The first courses are all rather different in style and somewhat different in content (we bring them together across by the end of the sequence). In order to take CS 0180 directly after 0111, you need to be able to work on problems at the complexity level of those in CS 0170. Those problems draw on the same concepts and style of programming that we do in 0111. You just need to be able to scale your skills to more complex problems. We will therefore offer additional exercises to help you prepare for 0180, most of them attached to existing 0111 assignments. These additional exercises are NOT required for 0111, nor do they affect your grade in 0111. They are only for those who wish to take CS0180 without going through CS0112. If you finish the additional work, you can take 0180 anytime before you graduate (it doesn't have to be this year). The Assignments Sorting lists Working with trees: In lecture, we looked at using data to capture a form of real-world data with a branching structure (family relationships). Sometimes, we organize data into a tree shape to enable a particular approach to a computation. These next two assignments explore these two uses of trees. You can do them in either order. Files and Directories (this is in the spirit of the problem we discussed in lecture about trees that let us navigate from people to their offspring). Binary Search Trees (this is a different use of trees, but you might find this one easier to start with). The last problem on the run-time performance can be done either as part of this assignment or as a question on the running times assignment below -- your choice. Running times: this is the one topic that we haven't gotten to discuss in 111. There's a lecture-capture video with background in the handout. Kathi will also offer a session on this content at some point later this semester. Running Times We wrap up with two more examples of interesting uses of trees, this time for capturing documents and programs. Getting these conceptually will likely be more challenging than the (small bit of) corresponding code. Processing Documents and Languages Frequently-Asked Questions When do I have to decide about trying for CS0180? We will start 0180-related assignments about 5 weeks into the course. How do I sign up? By turning in the work once it starts. There's no need to formally tell us you want to do this. Where do I submit the extra work? There will be a separate assignment area on Gradescope for each assignment. When will the extra work be due? We strongly encourage you to try to complete the assignments as they are released, as this will help acclimate you to the workload of CS18. That said, we understand that remote learning is posing its own challenges for many students. You can therefore take up through December 21, 2020 to turn in all of the assignments. PLEASE do not leave all of the work to that point. If you only start it after finals, you are unlikely to finish in time. Will the extra work be doable for those new to programming? Yes. The extra work will not assume any more material than what we are covering in regular 0111 lecture (with the exception of one additional lecture that we will schedule in November). The extra work simply uses the 111 material in somewhat more complex ways. How much time will the extra work take? Roughly an extra 3-4 hours per assignment beyond the normal 0111 workload. This is in line with the time requirements of assignments in CS0170, which is the course that normally feeds into CS0180. If I don't want to do 0180, can I still take CS 0112? Absolutely, but we won't be offering 0112 again until next year (likely fall). We apologize for the inconvenience, but the 3-semester schedule for this year needed us to offer some courses twice, which cuts into our available teaching staff. Can I take 0180 without doing the extra work? No. Since you won't have taken 0170, you'll need an override code for CS 0180. Kathi will only give override codes (this year or in future years) to students who have done the bridge work or completed CS 0112. If I took 0111 in a previous semester, can I still take CS0180 this year? Yes. Reach out to Kathi to make arrangements. Is there a grade cutoff for getting into CS18? That's not the right way to think about it. The goal of these assignments is to make sure that you understand the concepts sufficiently well for what 18 will expect. Kathi will get a sense of that from a combination of your work on the assignments, the kinds of comments that come up in your reflections, interactions in office hours, etc. Kathi will look at the quality of your work and reflections, not at whether you were above some arbitrary cutoff. Will we get grades and feedback on the bridge work? When? You will get some feedback, but it won't necessarily be the kinds of rubric-based grades that you get on the regular 111 homeworks (since Kathi is handling these herself, without the backup of the TAs). Kathi will work on providing feedback as work comes in, starting in mid-November. Where can I get help if I'm stuck on these? Kathi has two open-access office hours per week (see the 111 calendar), and is available for appointments (contact her by email). Some of the TAs can answer 18 questions, but as a general rule, questions on the bridge work should route through Kathi (since our TA staff is primarily allocated to help with 111). Kathi will be monitoring Campuswire and can take questions there as well. Reach out to Kathi with other questions, as she will be handling this part of 0111. 2020 CSCI 0111 Staff | Brown University Computer Science Department", "https://cs.brown.edu/courses/csci0111/": "CSCI 0111 Computing Foundations: Data Welcome to CS111, the intro CS course that blends data science and computer science for both concentrators and non-concentrators alike! We've had students from a wide range of concentrations and backgrounds (mostly with no prior programming experience) succeed in the course. We strive to provide a supportive environment for all who wish to try out computing while leaving open options for subsequent courses in CS or Data Science. The broad vision for CS111 is to put data and socially responsible computing at the heart of introductory computer science. We do this through a combination of writing small programs for data analysis, looking at core data structures that help us organize data towards different computations, and looking at case studies that reveal ways in which data-facing decisions can prevent or foster social harms. For a short article on the vision for CS111, see Data-Centricity: A Challenge and Opportunity for Computing Education , by Brown CS professors Shriram Krishnamurthi and Kathi Fisler . For those exploring from outside Brown: feel free to explore our current or past editions to see our course structure, notes, and assignments. The course textbook (which also has a major section on introductory algorithms that is not used in 111) is freely available online. CSCI 0111 is planned to be offered every Fall and Spring semester, as of Fall 2021 Current Offering : Spring 2024 Past editions: Fall 2023 Spring 2023 Fall 2022 Spring 2022 Fall 2021 Fall 2020 Spring 2020 Fall 2019 Fall 2018", "https://cs.brown.edu/courses/csci0111/fall2020/": "Skip to main content CS111 Lectures Assignments Labs Learning Resources Software Calendar Staff Campuswire Welcome to CSCI 0111 - Computing Foundations: Data! Meeting time: MWF 10:00-10:50 AM EST, on Zoom CS0111 is the beginning course of a new introductory Computer Science sequence at Brown University for both concentrators and non-concentrators. We want to provide our students the chance to master the fundamentals needed for upper-level courses, in addition to reasonable stopping point after any course and real-life applications to other academic fields. In this course, you will learn foundational ideas about Computer Science through essential programming, data structures, data science applications, and social impacts of data. We use two different programming languages, Pyret and Python, to help students learn to approach concepts from different perspectives. The course expects no prior programming experience. Quick links Course Syllabus Anonymous Feedback Form Going to CS 0180 Extension Request Form Blocklist Form Lab Switch Form Late Day Form Important dates Midterm exam: Oct 28-30 Midterm Prep Guide Final exam: Dec 9 (plus a couple of days TBD) Final Prep Guide Shopping period announcements Students who are shopping should keep up with assignments, which will start being due the second week of classes. Past experience shows that many students who first join the course at the end of shopping period and are new to programming struggle to catch up. We strongly urge you to be participating in the course by the start of the second week. All students must agree to the collaboration policy at the end of the course syllabus . Course Archives Materials from previous semesters are linked to the main CS 111 page .", "https://cs.brown.edu/courses/csci0111/fall2021/": "Skip to main content CS111 Lectures Assignments Labs Learning Resources Software Calendar Staff Edstem Welcome to CSCI 0111 - Computing Foundations: Data! MWF 10:00-10:50 AM EST, Metcalf Auditorium CSCI 0111 is an introductory course for both concentrators and non-concentrators who want to understand computing through the lens of data. It covers the fundamentals needed for additional CS courses, while also being designed as a useful stopping point forstudents who want to use a bit of computing, data analysis, or programming in other disciplines. The course starts with writing small programs to process and manage table-shaped data (like CSV files). It then progresses to problems involving structured (text-based) data for which tables aren't the best organization (introducing common computer science data structures). Throughout the course, we examine practical questions about working with realistic data, as well as the (often adverse) social impacts that can arise when using data at scale. The course expects no prior programming experience. It is paced more gently than CSCI 0150 or CSCI 0170 (which also assume no prior experience), while also focusing on styles of programming that are in common practice across many disciplines. The course uses two programming languages (initially Pyret and later Python), with the first explicitly designed to transition into the second. Students from concentrations across campus have succeeded in and enjoyed CSCI 0111. Check out the Critical Review [Brown access only] (Professor Fisler last led the course in Spring 2020; she and Professor Woos co-taught in Fall 2020, with Professor Woos running lectures). Quick Links Course Syllabus Anonymous Feedback Form Going to CSCI 0200 Lab Switch Form Blocklist Form Important dates Final exam: Dec 16 (as per CAB) What Can I Take After CSCI 0111? Students who want to continue learning CS at the pace of 0111 can take CSCI0112 (offered in the fall), followed by CSCI 0200 (the new course replacing the former CSCI 0160 and CSCI 0180) Students who want to accelerate their learning of CS can do additional work in the last third of the semester to move directly to CSCI 0200 in the spring (just as students would do after CSCI 0150 and CSCI 0170) Students who are more interested in data science than computer science can take DATA 200 in the spring (which leads into the Data Fluency Certificate).", "https://cs.brown.edu/courses/csci0111/spring2020/index.html": "CS111 Lectures Assignments Labs Learning Resources Software Hours Staff Campuswire Welcome to CSCI 0111: Computing Foundations: Data! Meeting time and location: MWF 10:00-10:50 AM (can choose to be asynchronous) CS0111 is the beginning course of an introductory Computer Science sequence at Brown University for both concentrators and non-concentrators. We want to provide our students the chance to master the fundamentals needed for upper-level courses, in addition to reasonable stopping point after any course and real-life applications to other academic fields. In this course, you will learn foundational ideas about Computer Science through essential programming, data structures, data science applications, and social impacts of data, alongside other big ideas in computing. We use two different programming languages, Pyret and Python, to help students learn to approach concepts from different perspectives. The course expects no prior programming experience. Quick links Anonymous Feedback Form Course Missive Blocklist Form Shopping period announcements All students must agree to the collaboration policy at the end of the course missive . Archive The archive to the previous iterations of the course could be found here . 2019 CSCI 0111 Staff | Brown University Computer Science Department", "https://cs.brown.edu/courses/csci0111/spring2020/labs/lab10-recs1.html": "Things to Do Google error messages Check Stack Overflow for similar questions. Try to find the most popular posts/questions with a lot of upvotes. Specify the language you\u2019re using Ask specific questions Things Not to Do Copy and paste lines of code directly into Google Use long or complicated code snippets directly without attribution Copy and paste lines of code directly into your editor. This is because there are often special characters (like extra whitespace or open- and close- quotes) that will cause errors when you try to run your code, but won\u2019t be visibly different when you look at it Things to Do Things Not to Do Expand all Back to top Go to bottom Things to Do Things Not to Do Expand all Back to top Go to bottom var markdown = $(\".markdown-body\"); //smooth all hash trigger scrolling function smoothHashScroll() { var hashElements = $(\"a[href^='#']\").toArray(); for (var i = 0; i < hashElements.length; i++) { var element = hashElements[i]; var $element = $(element); var hash = element.hash; if (hash) { $element.on('click', function (e) { // store hash var hash = this.hash; if ($(hash).length <= 0) return; // prevent default anchor click behavior e.preventDefault(); // animate $('body, html').stop(true, true).animate({ scrollTop: $(hash).offset().top }, 100, \"linear\", function () { // when done, add hash to url // (default click behaviour) window.location.hash = hash; }); }); } } } smoothHashScroll(); var toc = $('.ui-toc'); var tocAffix = $('.ui-affix-toc'); var tocDropdown = $('.ui-toc-dropdown'); //toc tocDropdown.click(function (e) { e.stopPropagation(); }); var enoughForAffixToc = true; function generateScrollspy() { $(document.body).scrollspy({ target: '' }); $(document.body).scrollspy('refresh'); if (enoughForAffixToc) { toc.hide(); tocAffix.show(); } else { tocAffix.hide(); toc.show(); } $(document.body).scroll(); } function windowResize() { //toc right var paddingRight = parseFloat(markdown.css('padding-right')); var right = ($(window).width() - (markdown.offset().left + markdown.outerWidth() - paddingRight)); toc.css('right', right + 'px'); //affix toc left var newbool; var rightMargin = (markdown.parent().outerWidth() - markdown.outerWidth()) / 2; //for ipad or wider device if (rightMargin >= 133) { newbool = true; var affixLeftMargin = (tocAffix.outerWidth() - tocAffix.width()) / 2; var left = markdown.offset().left + markdown.outerWidth() - affixLeftMargin; tocAffix.css('left', left + 'px'); } else { newbool = false; } if (newbool != enoughForAffixToc) { enoughForAffixToc = newbool; generateScrollspy(); } } $(window).resize(function () { windowResize(); }); $(document).ready(function () { windowResize(); generateScrollspy(); }); //remove hash function removeHash() { window.location.hash = ''; } var backtotop = $('.back-to-top'); var gotobottom = $('.go-to-bottom'); backtotop.click(function (e) { e.preventDefault(); e.stopPropagation(); if (scrollToTop) scrollToTop(); removeHash(); }); gotobottom.click(function (e) { e.preventDefault(); e.stopPropagation(); if (scrollToBottom) scrollToBottom(); removeHash(); }); var toggle = $('.expand-toggle'); var tocExpand = false; checkExpandToggle(); toggle.click(function (e) { e.preventDefault(); e.stopPropagation(); tocExpand = !tocExpand; checkExpandToggle(); }) function checkExpandToggle () { var toc = $('.ui-toc-dropdown .toc'); var toggle = $('.expand-toggle'); if (!tocExpand) { toc.removeClass('expand'); toggle.text('Expand all'); } else { toc.addClass('expand'); toggle.text('Collapse all'); } } function scrollToTop() { $('body, html').stop(true, true).animate({ scrollTop: 0 }, 100, \"linear\"); } function scrollToBottom() { $('body, html').stop(true, true).animate({ scrollTop: $(document.body)[0].scrollHeight }, 100, \"linear\"); }", "https://cs.brown.edu/courses/csci0111/spring2020/labs/lab10-recs2.html": "Identifying Useful Links Stack Overflow is useful for answering specific coding questions (but try to find posts with lots of upvotes) Websites with tutorials such as GeeksForGeeks are more useful for explaining a particular concept or algorithm If an answer contains concepts that you haven\u2019t seen before, keep searching \u2013 there are often many ways to implement the same feature, and a different one might be more familiar If you\u2019re not sure why an answer isn\u2019t working, double check that it uses Python 3.7 or higher (and not Python 2) Identifying Useful Links Expand all Back to top Go to bottom Identifying Useful Links Expand all Back to top Go to bottom var markdown = $(\".markdown-body\"); //smooth all hash trigger scrolling function smoothHashScroll() { var hashElements = $(\"a[href^='#']\").toArray(); for (var i = 0; i < hashElements.length; i++) { var element = hashElements[i]; var $element = $(element); var hash = element.hash; if (hash) { $element.on('click', function (e) { // store hash var hash = this.hash; if ($(hash).length <= 0) return; // prevent default anchor click behavior e.preventDefault(); // animate $('body, html').stop(true, true).animate({ scrollTop: $(hash).offset().top }, 100, \"linear\", function () { // when done, add hash to url // (default click behaviour) window.location.hash = hash; }); }); } } } smoothHashScroll(); var toc = $('.ui-toc'); var tocAffix = $('.ui-affix-toc'); var tocDropdown = $('.ui-toc-dropdown'); //toc tocDropdown.click(function (e) { e.stopPropagation(); }); var enoughForAffixToc = true; function generateScrollspy() { $(document.body).scrollspy({ target: '' }); $(document.body).scrollspy('refresh'); if (enoughForAffixToc) { toc.hide(); tocAffix.show(); } else { tocAffix.hide(); toc.show(); } $(document.body).scroll(); } function windowResize() { //toc right var paddingRight = parseFloat(markdown.css('padding-right')); var right = ($(window).width() - (markdown.offset().left + markdown.outerWidth() - paddingRight)); toc.css('right', right + 'px'); //affix toc left var newbool; var rightMargin = (markdown.parent().outerWidth() - markdown.outerWidth()) / 2; //for ipad or wider device if (rightMargin >= 133) { newbool = true; var affixLeftMargin = (tocAffix.outerWidth() - tocAffix.width()) / 2; var left = markdown.offset().left + markdown.outerWidth() - affixLeftMargin; tocAffix.css('left', left + 'px'); } else { newbool = false; } if (newbool != enoughForAffixToc) { enoughForAffixToc = newbool; generateScrollspy(); } } $(window).resize(function () { windowResize(); }); $(document).ready(function () { windowResize(); generateScrollspy(); }); //remove hash function removeHash() { window.location.hash = ''; } var backtotop = $('.back-to-top'); var gotobottom = $('.go-to-bottom'); backtotop.click(function (e) { e.preventDefault(); e.stopPropagation(); if (scrollToTop) scrollToTop(); removeHash(); }); gotobottom.click(function (e) { e.preventDefault(); e.stopPropagation(); if (scrollToBottom) scrollToBottom(); removeHash(); }); var toggle = $('.expand-toggle'); var tocExpand = false; checkExpandToggle(); toggle.click(function (e) { e.preventDefault(); e.stopPropagation(); tocExpand = !tocExpand; checkExpandToggle(); }) function checkExpandToggle () { var toc = $('.ui-toc-dropdown .toc'); var toggle = $('.expand-toggle'); if (!tocExpand) { toc.removeClass('expand'); toggle.text('Expand all'); } else { toc.addClass('expand'); toggle.text('Collapse all'); } } function scrollToTop() { $('body, html').stop(true, true).animate({ scrollTop: 0 }, 100, \"linear\"); } function scrollToBottom() { $('body, html').stop(true, true).animate({ scrollTop: $(document.body)[0].scrollHeight }, 100, \"linear\"); }", "https://cs.brown.edu/courses/csci0111/spring2020/labs/lab6-help.html": "Proposed task list for days-in-range For the days-in-range function, here\u2019s a possible task list, with annotations (after ==>) on how to implement each task: determine whether a temperature is with a range of two other numbers ==> write a lam or a named function for this determine whether all temps in a list are within a range ==> write a helper such as all-in-range(lst :: List<Number>, low :: Number, high :: Number) -> Boolean find the days for which all temps are within a range ==> filter the data using all-in-range count the days from the previous step ==> Use L.length You could also choose to combine tasks 3 and 4 into something like the following: count the days for which all temps are within a range ==> recur through the days-lists, counting those for which all-in-range returns true Proposed task list for days-in-range Expand all Back to top Go to bottom Proposed task list for days-in-range Expand all Back to top Go to bottom var markdown = $(\".markdown-body\"); //smooth all hash trigger scrolling function smoothHashScroll() { var hashElements = $(\"a[href^='#']\").toArray(); for (var i = 0; i < hashElements.length; i++) { var element = hashElements[i]; var $element = $(element); var hash = element.hash; if (hash) { $element.on('click', function (e) { // store hash var hash = this.hash; if ($(hash).length <= 0) return; // prevent default anchor click behavior e.preventDefault(); // animate $('body, html').stop(true, true).animate({ scrollTop: $(hash).offset().top }, 100, \"linear\", function () { // when done, add hash to url // (default click behaviour) window.location.hash = hash; }); }); } } } smoothHashScroll(); var toc = $('.ui-toc'); var tocAffix = $('.ui-affix-toc'); var tocDropdown = $('.ui-toc-dropdown'); //toc tocDropdown.click(function (e) { e.stopPropagation(); }); var enoughForAffixToc = true; function generateScrollspy() { $(document.body).scrollspy({ target: '' }); $(document.body).scrollspy('refresh'); if (enoughForAffixToc) { toc.hide(); tocAffix.show(); } else { tocAffix.hide(); toc.show(); } $(document.body).scroll(); } function windowResize() { //toc right var paddingRight = parseFloat(markdown.css('padding-right')); var right = ($(window).width() - (markdown.offset().left + markdown.outerWidth() - paddingRight)); toc.css('right', right + 'px'); //affix toc left var newbool; var rightMargin = (markdown.parent().outerWidth() - markdown.outerWidth()) / 2; //for ipad or wider device if (rightMargin >= 133) { newbool = true; var affixLeftMargin = (tocAffix.outerWidth() - tocAffix.width()) / 2; var left = markdown.offset().left + markdown.outerWidth() - affixLeftMargin; tocAffix.css('left', left + 'px'); } else { newbool = false; } if (newbool != enoughForAffixToc) { enoughForAffixToc = newbool; generateScrollspy(); } } $(window).resize(function () { windowResize(); }); $(document).ready(function () { windowResize(); generateScrollspy(); }); //remove hash function removeHash() { window.location.hash = ''; } var backtotop = $('.back-to-top'); var gotobottom = $('.go-to-bottom'); backtotop.click(function (e) { e.preventDefault(); e.stopPropagation(); if (scrollToTop) scrollToTop(); removeHash(); }); gotobottom.click(function (e) { e.preventDefault(); e.stopPropagation(); if (scrollToBottom) scrollToBottom(); removeHash(); }); var toggle = $('.expand-toggle'); var tocExpand = false; checkExpandToggle(); toggle.click(function (e) { e.preventDefault(); e.stopPropagation(); tocExpand = !tocExpand; checkExpandToggle(); }) function checkExpandToggle () { var toc = $('.ui-toc-dropdown .toc'); var toggle = $('.expand-toggle'); if (!tocExpand) { toc.removeClass('expand'); toggle.text('Expand all'); } else { toc.addClass('expand'); toggle.text('Collapse all'); } } function scrollToTop() { $('body, html').stop(true, true).animate({ scrollTop: 0 }, 100, \"linear\"); } function scrollToBottom() { $('body, html').stop(true, true).animate({ scrollTop: $(document.body)[0].scrollHeight }, 100, \"linear\"); }", "https://cs.brown.edu/courses/csci0160/local.html": "Toggle navigation SEA-S 16 Home Documents Lectures Assignments Section TA Hours + Staff Working Locally Guide: Select your operating system and follow the guides or videos below to learn how to set yourself up to work locally! If you run into any issues, post to Ed Discussion under the logistic tag! Mac Windows 1) Local Python Setup These steps are to install/ensure the correct version of python and pytest are installed locally on your computer. In terminal, run python --version to get the python version you are running. If it says 3.7.3 you are good to go, if not: Run python3 --version . If you don't get 3.7.3 install python 3.7.3 If you get 3.7.3 you must type python3 to run anything, or setup an alias as shown below. Setting up an alias: What an alias is: a (usually short) command that the shell (terminal) translates into another (usually longer) command. For example, if instead of typing cs0160_install you wanted to type i you could set up an alias so i was interpreted as cs0160_install in your terminal We are going to make an alias so python is interpreted as python3 by default. Note: If your shell is zsh (look at top of terminal and see if it says bash or zsh), you should be modifying the .zshrc file instead of the .bash_profile . In your local terminal (not over ssh) type open -e ~/.bash_profile if a file does not exist type touch ~/.bash_profile first and then open -e ~/.bash_profile Then add the following line to the end of the document: alias python=\"python3.7\" Now run source ~/.bash_profile (essentially refreshing your terminal) and then run python --version to confirm that you've correctly set the version to python 3. It should now say: 3.7.3 Make sure pytest is installed by running python and then in the python shell run import pytest If you get no errors doing this, you are fine, If not: Type exit() to exit the python shell Run pip3.7 install -U pytest Now go back into the python shell by running python and then in the shell write import pytest once more to confirm it is installed by making sure you no longer have errors Important note: if you have python 3.7.3 , then you're good to go. If not: Follow this link to download python 3.7.3 To determine which download you want to do, go into system info and look at system type. If it is x64 you want the x86-64 executable installer If it is x86 you want the x86 installer Once that downloads open the executable. There will be a box in at the bottom that says add python 3.7 to path, make sure this box is checked. Press install now. Python 3.7.3 takes about 30 seconds to a minute to download Once the download is complete, open either powershell or cmd prompt and type python --version , you should see Python 3.7.3 Continue only if NOTHING or the WRONG version comes up: If nothing comes up, or you receive a different version, python probably hasn\u2019t been added to the path. To add it to the path manually, press the windows key and type edit the system environment variables The bottom right hand corner will have an option \u201cenvironment variables\u201d that you should click on In user variables, click \u201cpath\u201d then edit. You will be adding two new lines. Press new, then add C:\\Users\\ \\AppData\\Local\\Programs\\Python\\Python37\\Scripts\\ C:\\Users\\ \\AppData\\Local\\Programs\\Python\\Python37\\ Make sure pytest is installed by running python and then in the python shell run import pytest If you get no errors doing this, you are fine, If not: Type exit() to exit the python shell Run pip3.7 install pytest Now go back into the python shell by running python and then in the shell write import pytest once more to confirm it is installed by making sure you no longer have errors 2) Local Java Setup These steps are to make sure the correct version of java is installed on your local computer. You must do this before doing your local Eclipse setup! In terminal type, java -version and check that the number following \u201cjava version\u201d starts with 1.8 or 8, if it does, you're done! If not, read on. Visit this website, and download the program that corresponds with your computer (ie Mac, Linux, or Windows), and download the 64-bit version. If you don't have an Oracle account and don't want to make one, you can also download jdk8 here. That said, we highly recommend making an Oracle account -- you'll be able to download jdk8 directly from the source, and it may come in handy later on. In your terminal type java -version again to check if the version is now 1.8 or 8, and if it is not type the following into your terminal: cd /Library/Java/JavaVirtualMachines ls you should see at least one file that starts with \u201cjdk\u201d, look for the file whose number starts with 1.8 or 8 and copy the file name. The full copied file name should look something like jdk.1.8.0_181.jdk cd ~ open -e .bash_profile if it says no bash_profile file exists, type touch .bash_profile then open -e.bash_profile Add the below code line to the end of your .bash_profile file. However, fill in the part <fill me in> with the copied file name from the second bullet point: export JAVA_HOME=/Library/Java/JavaVirtualMachines/<fill me in>/Contents/Home Now type java -version to make sure the correct version of java is being used Type java -version to see your version of java, if it is 1.8, you\u2019re done Visit this website, and download the program that corresponds with your computer (ie Mac, Linux, or Windows). If you don't have an Oracle account and don't want to make one, you can also download jdk8 here. That said, we highly recommend making an Oracle account -- you'll be able to download jdk8 directly from the source, and it may come in handy later on. Follow the install setup provided from the download until it completes Check to make sure the path of java has been updated by running java -version in powershell or cmd prompt. If nothing or the wrong version comes up, continue following these instructions To add it to the path manually, press the windows key and type edit the system environment variables The bottom right hand corner will have an option \u201cenvironment variables\u201d that you should click on In system variables, click \u201cpath\u201d then edit. You will be adding 1 line, press new, then add: C:\\Program Files\\Java\\jdk1.8.0_231\\bin Note: To make sure this runs properly, make sure this new line added to the path goes to the top, you can do so by clicking on the newly added line and pressing \u201cmove up\u201d until it is at the top. 3) Local IntelliJ Setup Follow this guide . Follow this guide . 4) Local Atom/Sublime/VSCode/Pycharm Setup There are many different IDEs that work for writing in python (IDEs are platforms in which you can write code). You can edit your python files in whatever program you like. Some recommended ones are Atom , VS Code , Sublime , and Pycharm . Atom, VS Code, and Sublime are free whereas Pycharm can be downloaded for free by first creating a GitHub account and then registering it as a GitHub student account here . The video tutorial shows these off more. There are many different IDEs that work for writing in python (IDEs are platforms in which you can write code). You can edit your python files in whatever program you like. Some recommended ones are Atom , VS Code , Sublime , and Pycharm . Atom, VS Code, and Sublime are free whereas Pycharm can be downloaded for free by first creating a GitHub account and then registering it as a GitHub student account here . The video tutorial shows these off more. 5) Zoom Setup Zoom will be used for all interactions that used to be in person :(. This is the link to log in to your Zoom account. This is how Zoom will work for each of its implementations: Code Hours: At the beginning of an hours slot, TAs will release a link to join a Zoom video call. Sign up on signmeup as normal. You can join the call at any time. However, you will be placed in a waiting room before actually meeting with TAs until it comes to your spot in line. As a result, please constantly be monitoring the hours line and/or your Zoom account when it comes close to being your turn in line. You will then be accepted to join the meeting. After being accepted into the meeting you will have 2 minutes to initiate conversation with the TA. If you fail to do so, the TA will release you back to the waiting room, where you will have 30 minutes to email the TAs who are currently on hours to unmark you missing. If it has been more than 30 minutes, we reserve the right to delete your sign up. Once in hours, in order to debug over Zoom, you will have to rely on Zoom\u2019s screen-sharing feature. To screen share over Zoom : in the panel on the bottom of the meeting, there is a \u201cScreen Share\u201d or \u201cShare\u201d option in which you can choose which screen you\u2019d like to share. You should select your Eclipse Workspace/FastX Session/Atom File/whatever, and then click share in the bottom right hand corner. Your TA should be able to see your screen. After you\u2019re done screen sharing, at the top of your screen, select the \u201cStop Share\u201d option. Conceptual Hours/Clinic: At the beginning of the Conceptual Hours/Clinic TAs will be posting a link for you to join them for Conceptual Hours/Clinic. TAs will answer questions by demand, and split you into supervised breakout sessions if necessary. Section: Your section TAs will send out invitations to join a Zoom meeting 5 minutes before your section. Joining the meeting will earn you attendance points for that session. (All mini assignments are to be emailed to your section TAs before your section.) Zoom will be used for all interactions that used to be in person :(. This is the link to log in to your Zoom account. This is how Zoom will work for each of its implementations: Code Hours: At the beginning of an hours slot, TAs will release a link to join a Zoom video call. Sign up on signmeup as normal. You can join the call at any time. However, you will be placed in a waiting room before actually meeting with TAs until it comes to your spot in line. As a result, please constantly be monitoring the hours line and/or your Zoom account when it comes close to being your turn in line. You will then be accepted to join the meeting. After being accepted into the meeting you will have 2 minutes to initiate conversation with the TA. If you fail to do so, the TA will release you back to the waiting room, where you will have 30 minutes to email the TAs who are currently on hours to unmark you missing. If it has been more than 30 minutes, we reserve the right to delete your sign up. Once in hours, in order to debug over Zoom, you will have to rely on Zoom\u2019s screen-sharing feature. To screen share over Zoom : in the panel on the bottom of the meeting, there is a \u201cScreen Share\u201d or \u201cShare\u201d option in which you can choose which screen you\u2019d like to share. You should select your Eclipse Workspace/FastX Session/Atom File/whatever, and then click share in the bottom right hand corner. Your TA should be able to see your screen. After you\u2019re done screen sharing, at the top of your screen, select the \u201cStop Share\u201d option. Conceptual Hours/Clinic: At the beginning of the Conceptual Hours/Clinic TAs will be posting a link for you to join them for Conceptual Hours/Clinic. TAs will answer questions by demand, and split you into supervised breakout sessions if necessary. Section: Your section TAs will send out invitations to join a Zoom meeting 5 minutes before your section. Joining the meeting will earn you attendance points for that session. (All mini assignments are to be emailed to your section TAs before your section.)", "https://cs.brown.edu/courses/csci0111/spring2020/": "CS111 Lectures Assignments Labs Learning Resources Software Hours Staff Campuswire Welcome to CSCI 0111: Computing Foundations: Data! Meeting time and location: MWF 10:00-10:50 AM (can choose to be asynchronous) CS0111 is the beginning course of an introductory Computer Science sequence at Brown University for both concentrators and non-concentrators. We want to provide our students the chance to master the fundamentals needed for upper-level courses, in addition to reasonable stopping point after any course and real-life applications to other academic fields. In this course, you will learn foundational ideas about Computer Science through essential programming, data structures, data science applications, and social impacts of data, alongside other big ideas in computing. We use two different programming languages, Pyret and Python, to help students learn to approach concepts from different perspectives. The course expects no prior programming experience. Quick links Anonymous Feedback Form Course Missive Blocklist Form Shopping period announcements All students must agree to the collaboration policy at the end of the course missive . Archive The archive to the previous iterations of the course could be found here . 2019 CSCI 0111 Staff | Brown University Computer Science Department", "https://cs.brown.edu/courses/csci0300/2021/assign/labs/assets/Vagrantfile": "# -*- mode: ruby -*-# vi: set ft=ruby :# ### CS300 Development VM #### Feel free to modify this file to best work with your machine.## For documentation, please see the comments here or go to# https://docs.vagrantup.com for more information.# All Vagrant configuration is done below. The \"2\" in Vagrant.configure# configures the configuration version (we support older styles for# backwards compatibility). Please don't change it unless you know what# you're doing.Vagrant.configure(\"2\") do |config| # The most common configuration options are documented and commented below. # For a complete reference, please see the online documentation at # https://docs.vagrantup.com. # Every Vagrant development environment requires a box. You can search for # boxes at https://vagrantcloud.com/search. config.vm.box = \"ubuntu/bionic64\" # Disable automatic box update checking. If you disable this, then # boxes will only be checked for updates when the user runs # `vagrant box outdated`. This is not recommended. # config.vm.box_check_update = false # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine. In the example below, # accessing \"localhost:8080\" will access port 80 on the guest machine. # NOTE: This will enable public access to the opened port # config.vm.network \"forwarded_port\", guest: 80, host: 8080 # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine and only allow access # via 127.0.0.1 to disable public access #config.vm.network \"forwarded_port\", guest: 80, host: 8080, host_ip: \"127.0.0.1\" # Create a private network, which allows host-only access to the machine # using a specific IP. #config.vm.network \"private_network\", ip: \"192.168.55.10\" # Create a public network, which generally matched to bridged network. # Bridged networks make the machine appear as another physical device on # your network. # config.vm.network \"public_network\" config.ssh.forward_agent = true config.ssh.forward_x11 = true # Share an additional folder to the guest VM. The first argument is # the path on the host to the actual folder. The second argument is # the path on the guest to mount the folder. And the optional third # argument is a set of non-required options. # config.vm.synced_folder \"./go/src\", \"/home/vagrant/go/src\" # Manually edit synced folder mount options just in case, but this # should not be an issue for most config.vm.synced_folder '.', '/vagrant', mount_options: [\"dmode=775,fmode=777\"] # Provider-specific configuration so you can fine-tune various # backing providers for Vagrant. These expose provider-specific options. # Example for VirtualBox: # # config.vm.provider \"virtualbox\" do |vb| # Display the VirtualBox GUI when booting the machine #vb.gui = true # Customize the amount of memory on the VM: #vb.memory = \"1024\" # end # # View the documentation for the provider you are using for more # information on available options. # Enable provisioning with a shell script. Additional provisioners such as # Puppet, Chef, Ansible, Salt, and Docker are also available. Please see the # documentation for more information about their specific syntax and use. config.vm.provision \"shell\", inline: <<-SHELL rm -fv /etc/ssh/ssh_host_* dpkg-reconfigure openssh-server apt-get update SHELLend", "https://cs.brown.edu/courses/csci0160/static/files/docs/doc/decisiontree/index.html": "JavaScript is disabled on your browser. Frame Alert This document is designed to be viewed using the frames feature. If you see this message, you are using a non-frame-capable web client. Link to Non-frame version .", "https://cs.brown.edu/courses/csci0111/spring2020/data/hw10/": "Homework 10 Source Code Download The zip file below contains your data, and everything needed to run the Flask web app!Note the absence of the stencil, which is instead on Canvas. hw10.zip", "https://cs.brown.edu/courses/csci0160/static/files/docs/doc/graph/index.html": "JavaScript is disabled on your browser. Frame Alert This document is designed to be viewed using the frames feature. If you see this message, you are using a non-frame-capable web client. Link to Non-frame version .", "https://cs.brown.edu/courses/csci0190/2018/laptop-policy.html": "\u25bc Fall 2018: Accelerated Introduction to Computer Science 1 Anticipated Frequent Questions 2 README 3 Learning Goals, Assessments, and Time Allocation 4 Syllabus and Course Policies 5 Late Policy 6 Laptop Policy 7 Diversity and Professionalism 8 Assignments 9 (Early) Testing for Programming 10 Textbook 11 Software 12 Staff and Contact 13 How to Ask Questions (and Report Bugs) 14 Credits \u25ba 6 Laptop Policy 6.1 Background 6.2 The Course Policy 6.3 Popular Press 6.4 Research Literature On this page: 6.1 Background 6.2 The Course Policy 6.3 Popular Press 6.4 Research Literature \u2190 prev up next \u2192 6 Laptop Policy Thanks to Cassandra Jacobs and (alum!) Jake Eakle forfeedback that improved this document. 6.1 Background 6.2 The Course Policy 6.3 Popular Press 6.4 Research Literature Note: \u201cLaptop\u201d is used in this document as a proxy for abroad range of devices, including tablets, smartphones, etc. 6.1 Background Numerous research studies over the past several years have foundgenerally adverse learning impacts of having laptops in classrooms (alist of papers on that and related topics is in Research Literature andsummarized in Popular Press ). Some of this literature is mainly an argument about how using laptopscauses students to harm their own learning. However, not all studentsare alike, and some may feel they\u2019re excellent multitaskers or thatusing a laptop actually helps them (presumably almost everyone inthose studies felt that way...). Anyway, they may feel that theyshould be allowed to take responsibility for their own education. The research, however, also shows a much more perniciousproblem. Student learning is also negatively impacted by someone else\u2019s laptop use. This isn\u2019t surprising: screens haveflashing content, keyboards make noise, and distractors are, ingeneral, distracting. This is where an individual\u2019s exercise of rightsbecome problematic: you have the right to squander your educationalopportunities, but not to take away those of others. This phenomenon isn\u2019t confined to the research literature. Inend-of-semester surveys across multiple courses, I have foundnon-trivial percentages of students express frustration (sometimes ina colorful manner) at others\u2019 laptop use. In fact, it\u2019s seeing this onsurveys that prompted me to look up the research. At the same time, laptops are sometimes useful in coursework. Mostcommonly, you may be asked to try out a program, especially a conceptyou haven\u2019t seen before (and hence can\u2019t imagine in your head). 6.2 The Course Policy I am instituting a new policy on laptop use in class that reconcilesthese different pressures. By default, laptop use is prohibited. There are only threeexceptions: I\u2019ve explicitly given permission to use laptops for sometask. (If I haven\u2019t but you think some task is laptop-suitable, ask. Imay want you to think about it instead of blindly typing it in.) Whenthe task ends, you have to close \u201cClose\u201d means \u201cscreenno longer visible and no more typing\u201d. More broadly, the deviceshould be inert, neither producing discernible output nor being giveninput. your laptop. You have some documentable reason that requires laptop use. Ifso please discuss it with me beforehand. Also, in light of the rest ofthis document, I\u2019d appreciate your positioning yourself in class in away that your laptop\u2019s screen will not distract others. Note that thisdoes not mean you have to relegate yourself to the back; perhaps thatisn\u2019t where you would like to sit! But closer to the ends of rowswould help. Thanks. Emergencies. 6.3 Popular Press The following articles are not scientific literature but summarize theresearch in easily-accessible terms. To Remember a Lecture Better, Take Notes by Hand by Robinson Meyer, The Atlantic , 2014 Laptops Are Great. But Not During a Lecture or a Meeting. by Susan Dynarski, The New York Times , 2017 (Note that Susan Dynarski is a distinguished professor of education, not just a random person with anopinion on the Web.) 6.4 Research Literature The following are research papers you can read to learn more. The laptop and the lecture: The effects of multitasking in learning environments byHelene Hembrooke and Geri Gay, Journal of Computing in Higher Education , 2003 In-class laptop use and its effects on student learning byCarrie B. Fried, Computers & Education , 2007 Daydreaming and its correlates in an educational environment by Sophie Lindquist and John McLean, Learning and Individual Differences , 2011 Examining the impact of off-task multi-tasking with technology on real-timeclassroom learning byEileen Wood, Lucia Zivcakova, Petrice Gentile, Karin Archer, Domenica De Pasquale, Amanda Nosko, Computers & Education , 2011 The impact of laptop-free zones on student performance and attitudes in large lectures byNancy Aguilar-Roca, Adrienne Williams, and Diane O\u2019Dowd, Computers & Education , 2012 Laptop multitasking hinders classroom learning for both users and nearby peers byFaria Sana, Tina Weston, Nicholas J. Cepeda, Computers & Education , 2013 The pen is mightier than the keyboard: Advantages of longhand over laptop note taking byPam A. Mueller and Daniel M. Oppenheimer, Psychological Science , 2014 The impact of computer usage on academic performance: Evidence from a randomized trial at the United States Military Academy bySusan Payne Carter, Kyle Greenberg, Michael S. Walker, Economics of Education Review , 2017 Logged in and zoned out: How laptop internet use relates to classroom learning bySusan Ravizza, Mitchell Uitvlugt, Kimberly Fenn, Psychological Science , 2017 \u2190 prev up next \u2192", "https://cs.brown.edu/courses/csci0190/2020/assignments.html": "\u25ba Fall 2020: Accelerated Introduction to Computer Science Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Credits \u25bc Assignments Doc Diff Nile Sortacle Data Scripting Oracle Filesystem Updater Continued Fractions Twee Search Join Lists Tour Guide MST Map Reduce Fluid Images 24 \u2190 prev up next \u2192 Assignments Please make sure all submissions are anonymous . We will use Gradescope for assignment submission and grading. Follow theseinstructions to sign up for Gradescope. Please do not go to Gradescopedirectly; you really do need to read these instructions! All work will be due by 11:59pm US/Eastern of the indicated day. Title Pair? Published Due DocDiff no Wed, Sep 9 Fri, Sep 11 Nile no Sat, Sep 12 Tue, Sep 15 Sortacle no Wed, Sep 16 Mon, Sep 21 Data Scripting no Tue, Sep 22 Wed, Sep 23 Oracle no Fri, Sep 25 Tue, Sep 29 Filesystem no Wed, Sep 30 Thu, Oct 1 Updater yes Fri, Oct 2 Wed, Oct 7 Continued Fractions no Thu, Oct 8 Thu, Oct 15 TweeSearch no Sun, Oct 18 Wed, Oct 21 JoinLists yes Thu, Oct 22 Tue, Oct 27 Tour Guide no Wed, Oct 28 Thu, Nov 5 MST no Sun, Nov 8 Sat, Nov 14 MapReduce yes Sun, Nov 15 Thu, Nov 19 Fluid Images no Sun, Nov 22 Thu, Dec 3 24 no Fri, Dec 4 Sun, Dec 6 For assignments marked \u201cpair\u201d, you must work with at least onepartner. You cannotrepeat a partner across non-simultaneous \u201cpair\u201d assignments. The course homeworks will be programmed in Pyret , Please program according to the Pyret Style Guide . unless indicated otherwise.Pyret is a reasonably large language with many libraries, some ofwhich reproduce functionality (like basic data structures) that we areasking you to create in this course. This can lead to some confusionabout what you are and aren\u2019t allowed to use from the language. Eachassignment provides information about this when necessary, but ingeneral, the following rules apply: You can always use the computational core of the language: basicconstants, functions, higher-order functions, and composition. You can always construct your own new data definitions, unlessexplicitly stated otherwise. You are allowed to use builtin functions for the followingdatatypes unless explicitly stated otherwise: Numbers (functions such as num-abs , num-max ) Strings (functions such as string-to-number , string-length ) Booleans (functions such as not ) You are allowed to use the following libraries unless explicitlystated otherwise: lists sets pick tables option either You should not use any other built-in functions or librariesunless an assignment explicitly permits you to. When in doubt, ask. You may not use variables ( var ) or mutate objects( ! ) unless explicitly permitted to by an assignment. \u2190 prev up next \u2192", "https://cs.brown.edu/courses/csci0150/": "\u2630 Assignments Lectures Sections Code-along Hours Resources SRC Staff function toggleNavbar() { var navbar = document.getElementById(\"navbar\"); if (navbar.className === \"nav-bar\") { navbar.className += \" responsive\"; } else { navbar.className = \"nav-bar\"; } } WELCOME TO CSCI 0150 CS0150 is one of the introductory Computer Science courses offered at Brown University. This course introduces students to Computer Science through object-oriented design and programming, using Java and the JavaFX graphics library. You will use these tools for building interactive programs with graphical user interfaces. CS0150 reinforces concepts with practical exercises in weekly lab sessions and with challenging and engaging programming assignments, such as Doodle Jump and Tetris! There are no prerequisites for CS0150 and the course expects no prior programming experience. This Week in CS15 (Nov 26 - Dec 2) Assignment Othello Handout Help Slides Help Session AI Handout Assignment Pacman Handout Help Slides Help Session Assignment Sketchy Handout Help Slides Help Session Javadocs Assignment Indy Handout Mini-Assignment Assignments Assignment Released Early On Time Late Javadocs Help Slides Help Session Additional Handouts Rattytouille Sept 13 N/A Sept 16 N/A - - - - AndyBot Sept 17 N/A Sept 20 N/A JavaDocs - - - Pong Sept 21 N/A Sept 25 N/A JavaDocs - - - TicTacToe Sept 26 Sept 28 Sept 30 Oct 02 JavaDocs - - - Fruit Ninja Oct 03 Oct 08 Oct 10 Oct 12 JavaDocs Help Slides - - Cartoon Oct 12 Oct 19 Oct 21 Oct 23 - Help Slides - Mini-Assignment DoodleJump Oct 24 Oct 30 Nov 01 Nov 03 - Help Slides - - Tetris Nov 04 Nov 11 Nov 13 Nov 15 - Help Slides - - Pacman Nov 17 Dec 10 Dec 12 Dec 14 - Help Slides Help Session - Sketchy Nov 17 Dec 10 Dec 12 Dec 14 Javadocs Help Slides Help Session - Othello Nov 17 Dec 10 Dec 12 Dec 14 - Help Slides Help Session AI Handout Indy Nov 17 Dec 10 Dec 12 Dec 14 - - - Mini-Assignment Lectures Lectures are held in Salomon DECI on Tuesdays and Thursdays from 2:30-3:50pm. Date Lecture PDF Printable PDF PPT Recordings Skit Code 09/07 Welcome to CS0150 + What is Programming? PDF Printable PDF PPT Recording Skit - 09/12 Calling and Defining Methods PDF Printable PDF PPT Recording - - 09/14 Introduction to Parameters and Math PDF Printable PDF PPT Recording - - 09/19 Working with Objects I PDF Printable PDF PPT Recording - - 09/21 Working with Objects II PDF Printable PDF PPT Recording - - 09/26 Interfaces and Polymorphism PDF Printable PDF PPT Recording - - 09/28 Inheritance and Polymorphism PDF Printable PDF PPT Recording - - 10/03 Math and Making Decisions PDF Printable PDF PPT Recording Skit - 10/05 Graphics I PDF Printable PDF PPT Recording - Code 10/10 Graphics II PDF Printable PDF PPT Recording - Code 10/12 Graphics III PDF Printable PDF PPT Recording - Code 10/17 Loops PDF Printable PDF \"PPT Recording - - 10/19 Arrays PDF Printable PDF PPT Recording - - 10/24 Design Principles and Patterns I PDF Printable PDF PPT Recording - Code 10/26 Design Principles and Patterns II PDF Printable PDF PPT Recording - - 10/31 Recursion PDF Printable PDF PPT Recording Skit - 11/02 Big O, Sorting and Searching PDF Printable PDF PPT Recording - - 11/07 Data Structures I (Linked Lists) PDF Printable PDF PPT Recording - - 11/09 Data Structures II (Stacks, Queues, and Trees) PDF Printable PDF PPT Recording - - 11/14 Data Structures III PDF Printable PDF PPT Recording - - 11/16 Final Project Intro PDF Printable PDF PPT Recording - - 11/28 History PDF Printable PDF PPT Recording - - 11/30 Computer Graphics PDF Printable PDF PPT Recording - - 12/05 HTA Lectures PDF Printable PDF PPT Recording - - Labs & Sections Lab/section is a time to review course content in a smaller group setting and practice applying those concepts through partnered labs. Each section will meet once a week and will be led by two TAs with around SOME NUMBER of students, so it is also a time to work closely with and get to know some of your fellow CS15-ers. A typical lab/section consists of short group check in, a fun SRC activity, and then either a presentation and some smaller group activities to review concepts or a lab. Date Lab/Section Handout Mini-Assignment Review Video SRC Slides 09/12 Lab 0: Linux & Terminal Handout Mini-Assignment - - Slides 09/19 Lab 1: Intro to Java Handout - - SRC Activity - 09/26 Section 2: Class Relationships - Mini-Assignment - SRC Activity Slides 10/03 Section 3: Polymorphism - Mini-Assignment - SRC Activity Slides 10/10 Lab 4: JavaFX Handout - Video - - 10/17 Lab 5: Debugging Handout Mini-Assignment - - - 10/24 Section 6: 1D Array, ArrayLists, and Loops Handout Mini-Assignment - SRC Activity Slides 10/31 Lab 7: 2D Arrays Handout Mini-Assignment Video SRC Activity Slides 11/07 Section 8: Algorithms - Mini-Assignment - - Slides 11/14 Lab 9: Data Structures and Recursion Handout - - SRC Activity Slides Code-Along CS15 Code-Alongs are your one stop shop for getting hands-on experience with guided coding exercises in order to better understand the concepts of OOP! We know that lectures can at times feel very abstract, and that we sometimes need examples in code in order to fully understand how these concepts work. Throughout the semester, we will host various code-alongs in order to assist you all with the skills necessary for succeeding in the course! Code-Along Related To Date #1 Date #2 Date #3 Video Stencil Java Syntax Code-along Rattytouille 09/13 at 7:00 PM MacMillan 117 09/15 at 7:00 PM MacMillan 117 09/17 at 7:00 PM MacMillan 117 Video Stencil Writing Classes Code-along Andybot, Pong, TicTacToe 09/19 at 8:00 PM Metcalf Research Auditorium 09/24 at 3:00 PM Metcalf Research Auditorium 09/27 at 9:00 PM Metcalf Research Auditorium Video Stencil Java FX & Design Code-along Cartoon 10/15 at 3:00 PM MacMillan 115 10/18 at 4:00 PM MacMillan 115 - Video Stencil GitHub and Debugging Code-along Doodle Jump 10/25 at 7:00 PM MacMillan 117 10/29 at 3:00 PM MacMillan 117 - Video Stencil Tetris Pieces Code-along Tetris 11/05 at 3:00 PM Friedman 202 11/08 at 7:00 PM Friedman 202 - Video Stencil Hours Have a Quick Question? Try out CS15's own virtual TA Chatbot, GPTA! Terms and Conditions | GPTA User Guide | Generative AI Usage Guide reminder that GPTA is experimental and is a supplement, not a replacement, for real TA help CONCEPTUAL TA HOURS Confused about an idea discussed in lecture or in a project handout? If we don't have to look at your code to answer your question, conceptual hours are a great place to meet other students and talk to a TA. Your question will get answered much faster here than at the debugging hours line. DEBUGGING HOURS Debugging Hours are a great resource to discuss 1-on-1 with a TA about your code and learn how to solve your bugs; however, please be sure to check our TA Hours policy and the Ed page before getting in line at the hours website . When waiting for hours, wait near CIT 210 and a TA will come to get you! Resources Quick Links Syllabus Ed Course Calendar Course Missive Gradescope Feedback Form Hours Emails TA Email cs0150tas@lists.brown.edu (general questions for all TAs) HTA Email cs0150headtas@lists.brown.edu (HTA-Specific Questions/Concerns) Individual TA Emails &ltcslogin&gt@cs.brown.edu (cslogins found under Staff) General Resources Required Readings Course Syllabus Course Missive Collaboration Policy TA Hours Policy Retake Policy GPTA User Guide Generative AI Usage Guide Online Help IntelliJ + Git Set-up Guide Mac IntelliJ Set-up Video Windows IntelliJ Set-up Video Github Guide Github Video Master the Terminal Guide Understanding CS0150 Support Code Java Documentation Javadocs: All built-in Java classes JavaFX-docs: All built-in JavaFx classes JavaFX Guide JavaFX Images Documentation Java Language Specification Guides & Tutorials README Guide Style Guide Variables & Constructors Runtime Errors Containment & Inheritance Diagrams Guide CS15 Vocabulary Sheet Partner Projects Logistics Guide Department Docs Undergraduate Missive Ergonomics IT Services Email Organizations Student Support Services CAPS Title IX Women in Computer Science Mosaic+ Health & Wellness Advocates Diversity & Inclusion Advocates Computer Science DUG SRC What is SRC? As awareness of technology's consequences increases, attention turns to how computer scientists are trained. In response, the CS department created the \"Socially Responsible Computing\" initiative in 2019 to integrate ethics and social impact topics broadly across its curriculum. At Brown, SRC is embedded into most major CS courses. Our goals in CS15 are to give a broad overview of today's technological landscape so that you are familiar with these concepts when you are eventually faced with ethical design decisions further down your CS journey. How does this fit into the CS15 curriculum? Mini-lectures Lab activities about lecture content Two extra credit discussion sections with details TBA How can I get involved? Groups @ Brown: SRC Reading group: ARG@Brown AIRES (AI Robotic Ethics Society@Brown) Human Centered Robotics Initiative Design for America @ Brown Alum-foudned groups & others: Better World by Design Impact Labs Coding it Forward TechCongress Classes @ Brown: CSCI1870: Cybersecurity Ethics CSCI1951I: CS for Social Change DATA0080: Data, Ethics and Privacy MCM0230: Digital Media PHIL401: Ethics of Digital Technology STS 1700T: Race, Gender, and Technology in Everyday Life Classes under the 'Science, Technology, and Society' (STS) department ...and more! Topics in Socially Responsible Computing Artificial Intelligence Lecture 1 Lectures 2-4 Lecture 5 Blockchain and Crypto Lecture 1 Lecture 2 Cybersecurity Lecture 1 Data Privacy Lecture 1 Lecture 2 Ethics in Big Tech Lecture 1 Lecture 2 Misinformation & Freedom of Expression Lecture 1 Labor Practices Lecture 1 Philosophy Lecture 1 Software Design Lecture 1 Lecture 2 AI Overview \u00d7 GPT-3 Creative Fiction Interactive: Stable Diffusion (free text-to-image generator) How DALL-E could power a creative revolution One Hundred Year Study on Artificial Intelligence (AI100) LLMs and Neural Nets \u00d7 Exclusive: OpenAI Used Kenyan Workers on Less Than $2 Per Hour to Make ChatGPT Less Toxic A Very Gentle Introduction to Large Language Models Without the Hype Lawyer Used Chat-GPT in Court and Cited Fake Cases AI for radiographic COVID-19 detection selects shortcuts over signal AI Bias and Ethics \u00d7 Who Is Making Sure the A.I. Machines Aren't Racist? A.I. Brings the Robot Wingman to Aerial Combat Automation isn't the biggest threat to US factory jobs Robots were supposed to take our jobs. Instead they're making it worse Economic possibilities for our grandchildren Privacy Violations and Regulation \u00d7 The New Rules of Data Privacy Data Protection and Privacy Laws China Social Credit System Explained CCTV Surveillance for Crime Prevention FTC Finalizes Order with Flo Health Examining the intersection of data privacy and civil rights Ring, Google and the Police: What to Know About Emergency Requests for Video Footage H.R.8152 - American Data Privacy and Protection Act Section 230 Surveillance Capitalism \u00d7 High tech is watching you What Is Surveillance Capitalism Cambridge Analytica and Facebook: The Scandal and the Fallout So Far \"You Are the Product\": Targeted by Cambridge Analytica on Facebook Corporate Surveillance in Everyday Life Antitrust \u00d7 Support for tech regulation has declined The Antitrust Laws House passes antitrust bill Regulating Big Tech \u00d7 To Regulate Network-Based Platforms, Look at Their Data Why 'Breaking Up' Big Tech Probably Won't Work Who Will Teach Silicon Valley to Be Ethical? Responsible AI tools and Practices Ethics Alone Can't Fix Big Tech Can Big Tech be Disrupted Big Tech Needs to Be Regulated. Here Are 4 Ways to Curb Disinformation and Protect Our Privacy The value and challenges of regulating big tech F.T.C.'s Court Loss Raises Fresh Questions About Its Chair's Strategy Blockchain Overview \u00d7 Blockchain Facts: What Is It, How It Works, and How It Can Be Used The Collapse of FTX: What Went Wrong With the Crypto Exchange? Blockchain Energy and Sustainability \u00d7 Cryptocurrency's energy consumption problem What is 'proof of work' or 'proof of stake'? Ethereum's Energy Revamp Is No Guarantee of Global Climate Gains Cybersecurity \u00d7 The Untold Story of Solarwinds Equifax Data Breach Settlement Chinese Malware Hits Systems on Guam. Is Taiwan the Real Target? Hunting Russian Intelligence 'Snake' Malware What You Need to Know About Autonomous Weapons Executive Order on Improving the Nation's Cybersecurity A.I Brings the Robot Wingman to Aerial Combat Philosophy \u00d7 Microsoft Says New A.I Shows Signs of Human Intelligence Philo-GPT's Surprisingly Wise Answer to What is the Meaning of Life A.I Thinking vs. Human Thinking How Close Are We to A.I That Surpasses Human Intelligence Dark & Addictive Design \u00d7 Deceptive Design How Facebook and other sites manipulate your privacy choices How financial apps get you to spend more and question less A survey of addictive software design Dopamine, smartphones and you Good User Design Practice \u00d7 Coming Soon! Misinformation & Freedom of Expression \u00d7 Coming Soon! Labor Practices \u00d7 Coming Soon! Staff Professor & Head Teaching Assistants Andy (avd) he/him I'm originally from the Netherlands. My CS specialty is Computer Graphics, especially pen- and touch-computing. I'm a foodie and love the outdoors: hiking and backpacking (especially in the Grand Canyon), mountain- and road-biking, and kayaking. THE CAPITOL Allie (amasthay) she/her Hi guys! I am a junior from Connecticut studying Computer Science, and I am super excited for this semester! When I am not in the CIT, I love going to Bajas, drinking Diet Coke, singing karaoke, or trying to catch the Sci Li rats. Feel free to reach out to me anytime about anything CS15, CS at Brown, or general questions on life. Can't wait to meet you! DISTRICT 10 - LIVESTOCK Anastasio (aortiz18) he/him Hey! My name is Anastasio, I am a Junior from Nicaragua studying APMA-CS. I like ice cream and long walks by the beach. DISTRICT 2 - MASONRY Cannon (ccaspar) he/him I am Cannon, Junior, CS and Classics Major, from Concord MA. Super excited to HTA CS15! I often do things that make me happy, which includes: adventure, fun, hope, power, meditation, and sometimes even CS. Reach out if you ever wanna talk about anything :) DISTRICT 7 - LUMBER Lexi (ehenrion) she/her Hi everyone! I switched to CS after taking CS15 as a student, and I'm now a senior studying Visual Computing. I couldn't be happier, and I'm so excited to share this AWESOME class with all of you! I'm also an artist and writer when I'm not coding, wandering around Providence, or eating waffles and reading manga at Zinneken's :) DISTRICT 6 - TRANSPORTATION Sarah (sonderdo) she/her Hi! I am a junior from New Jersey studying computer science and history. In my free time you can find me hanging out with my friends, pretending to read books, dreaming about pasta, and watching the same movies over and over again. In my not-free time you can find me in the CIT. I am so excited to meet you all, feel free to reach out and say hi! DISTRICT 11 - AGRICULTURE Joint Socially Responsible Computing/Undergraduate Teaching Assistants Adam (amroueh) he/him Hi! I am a senior from Rochester, NY studying CS-Econ. I enjoy food, reading and trying new coffee shops. I can't wait for CS15 and to meet everyone! DISTRICT 8 - TEXTILES Faizah (ffnaqvi) she/her Hi everyone! I'm a sophomore from NJ studying CS and IAPA. In my free time I like reading, baking (and then eating what I bake), and dousing my food with Tabasco sauce. Looking forward to meeting you all and having a great semester! DISTRICT 13 - NUCLEAR Katie (kli154) she/her Hi! I'm a sophomore from the Seattle area studying computer science and philosophy. I like reading, hiking, tap dancing, losing at chess, and eating Andrews yogurt bowls. DISTRICT 7 - LUMBER Undergraduate Teaching Assistants Alyssa (asun59) she/her Hi! I am a sophomore from Oregon studying CS-Econ. When I am not rotting in the CIT, I'm fencing, watching Dance Moms, or getting food with friends. Welcome to CS15, super excited to have an awesome semester with you guys! DISTRICT 5 - POWER Annabel (aroth7) she/her Hi! I'm a senior studying APMA-Econ and CS. I was born in Boston, MA, then lived in Shanghai, China for 5 years before moving to Connecticut. When I'm not working on psets in one of the CIT conference rooms, you can find me running, baking, or doing the NYT crossword or some variation of wordle. So excited for an awesome semester with everyone! DISTRICT 9 - GRAIN Ashton (agglover) he/him Hi everyone! I'm a sophomore from Lake Wylie, South Carolina studying computer science. I like the outdoors, traveling, and watching sports (especially soccer). Looking forward to meeting everyone! DISTRICT 3 - TECHNOLOGY Asia (atnguyen) she/her I'm a sophomore from Nashville, Tennessee! I'm planning on concentrating in CS and IAPA. I'm a huge swiftie, and I love to read and hang out with my friends in my free time! I'm so excited to meet you all! DISTRICT 1 - LUXURY Astrid (armoreno) she/her Hi! I'm a sophomore concentrating in Computer Science. I'm from Detroit, Michigan and I enjoy things like reading, crocheting, sewing, and cooking. So excited to guide everyone through the semester! DISTRICT 6 - TRANSPORTATION Ayman (abenjell) he/him Hi everyone! I'm Ayman, a junior from Casablanca, Morocco studying Computer Science here at Brown! When I'm not in the CIT, I like walking around campus while drinking boba, playing retro and current Nintendo games, and practicing piano! (started learning a year ago!). I also love drinking anything with caffeine in it, so any tea/coffee shop recommendations are welcome. I'm super excited for this semester, can't wait to meet y'all! DISTRICT 12 - MINING Ben (baizenbe) he/him I am a sophomore from Highland Park, Illinois, probably studying either CS or APMA. Outside of school, I play tennis, do crosswords, and watch movies -- most recently Puss in Boots: The Last Wish, one of the best movies ever made. I can't wait to be your TA! DISTRICT 12 - MINING Brandon (bdiaz2) he/him Hi! I'm a senior from Atlanta, GA studying CS and IAPA. I love spontaneous beach trips and listening to music. Can't wait to meet everyone! :) DISTRICT 10 - LIVESTOCK Chloe (cnevas) she/her Hi! I'm a sophomore from Westport, CT and I'm studying APMA-CS. In my free time I love to bake and cook, play the violin, and listen to music. I'm SO excited to be a TA for CS15 and I'm looking forward to a great semester! DISTRICT 8 - TEXTILES Channing (cpbryant) he/him Hey everyone! My name is Channing, and I'm from Massachusetts. I'm a sophomore studying Computer Science-Economics. I like listening to music, playing sports, eating, and watching movies. I'm excited to work with all of you, and feel free to reach out. DISTRICT 3 - TECHNOLOGY Caden (cschroe4) he/him Hi! I'm a sophomore from New Hampshire studying Applied Math and Computer Science. I love going to the beach, playing Spikeball, and climbing trees. Plus, I'm a big Ratty and Jo's fan so you can usually find me there. I'm super excited to meet all of you! DISTRICT 6 - TRANSPORTATION Cameron (csikich) she/her Hi everyone! I'm a junior from Toronto, Ontario concentrating in APMA-CS. I'm also on the Women's Ice Hockey team and I love to bake. Feel free to talk to me about sports, food or anything else. I look forward to meeting you all! DISTRICT 4 - FISHING Cindy (czheng27) she/her Hi, I'm a senior from Louisiana studying APMA-Biology. I love reading, gardening, and walking aimlessly. Looking forward to meeting everyone! DISTRICT 6 - TRANSPORTATION Dan (dliu58) he/him Hello there! I'm a junior concentrating in CS from Lockport, NY. My hobbies are sleeping in late, try-harding at Mario Kart and Smash, reading manga/web serials, and spending money at the CIT vending machines. DISTRICT 12 - MINING Daniel Z.(dzhu36) he/him Hey everyone! I'm a sophomore from San Ramon, California studying neuroscience and computer science. In my free time, I enjoy hiking, reading manga/books, playing games, cooking, and voice calling friends on discord. So excited to meet you all in CS15! DISTRICT 3 - TECHNOLOGY Dawood (dolaniyi) he/him Hey everybody, I'm Dawood! I'm a CS student from America's most beloved state, Iowa (real place, I swear). If I'm not coding video games in my dorm I'm probably saving my semester in the Sci-Li basement. If you ever see me hopping around campus, try to stop me for a conversation! I'd love to chat! Thank yall for contributing to my sophmore-year excitement by taking CS15, I'm beyond excited to work and learn with you all! DISTRICT 11 - AGRICULTURE Emily H. (ehinds3) she/her I'm a senior from Seattle, WA concentrating in Computer Science and French and I am so excited to meet all of the students this year! :) DISTRICT 7 - LUMBER Emily O. (eiolson) she/her Hi everyone! I'm a sophomore planning on studying a combination of computer science and physics. I'm from the Bay Area, California, but I am so happy to call Providence a home now too. I'm even more happy to get to work with you all, and I can't wait for a great semester in CS15 :) DISTRICT 11 - AGRICULTURE Emily W. (emwang) she/her Hi! I'm a sophomore from the Chicago suburbs, studying CS. I spend most of my time crocheting, watching anime, playing violin, and making silly drawings. Super excited to be your TA this semester!! :D DISTRICT 9 - GRAIN Ethan (eohayon1) he/him Hi! I am a Junior from Maryland studying CS-Econ. In my free time I enjoy playing sports, hanging at the beach, and walking my dog. I'm looking forward to working with everyone this fall! DISTRICT 6 - TRANSPORTATION Francesca (felia) she/her Hi!! I'm a sophomore double concentrating in APMA-Econ and CS. I love thrifting, iced caramel lattes, watching trashy reality TV, and beach days (which is unfortunate considering I'm from Minnesota). I'm so incredibly excited to TA this year and cannot wait to meet you all, so feel free to reach out for anything! :) DISTRICT 1 - LUXURY Gaby (cgchoi) she/her hi! i'm a sophomore from irvine, california studying cs-econ and international business! in my free time i love making coffee, drinking coffee, and spending way too much on coffee (ceremony). i'm also always at trader joes. so excited to meet everyone!! DISTRICT 10 - LIVESTOCK Gavin (gdhanda) he/him Hi! I'm a sophomore majoring in CS and Econ from Denver, Colorado. I play the guitar and piano in my free time and take lots of naps, and I'm so excited to TA CS15 this fall!!! DISTRICT 3 - TECHNOLOGY Grace (gcma) she/her Hi, and welcome to CS15!!! I'm Grace and I'm a sophomore from Montgomery County, Maryland studying music (and maybe cs??? idk). I enjoy playing random instruments, eating Chinese food, and watching animated kids shows. Super excited to meet you all! :) DISTRICT 11 - AGRICULTURE Grace (gmarshbu) she/her Hi! I'm a junior from Houston studying CS and visual arts, both for animation. I'm also interested in Russian language, musical performance, and fiction writing. When I can, I love to travel, watch animated movies, and listen to all sorts of music. I'm also very fond of Blue Room, so I'll go there as often as my flex points allow. DISTRICT 3 - TECHNOLOGY Grant (glandon) he/him Hello everyone! I'm a Junior from the North Shore of Massachusetts studying Applied Math and Computer Science. In my free time, I enjoy playing Spikeball on the main green, climbing anything and everything that looks climbable (including but not limited to rocks, walls, and trees), and playing tabletop games like Dungeons and Dragons. I can't wait to meet you all! DISTRICT 13 - NUCLEAR Julie (hchung33) she/her Hi everyone :) I'm Julie from West Hartford, CT. In my free time, I love to write music, go for nature walks, play Nintendo Switch, and attempt to skateboard. You can probably spot me in Steinert center practice rooms. I'm so excited to meet everyone, welcome to CS15!! DISTRICT 6 - TRANSPORTATION Ilan (ibrauns) he/him Hi everyone, I'm Ilan! I am a sophomore from South Orange, New Jersey studying Applied Math - Computer Science and Mathematics. In my free time I like to play sports, work out, and hang with friends. I love my dog Ruby and you can find me constantly tracking my fantasy football team. I'm so excited for the semester and feel free to reach out about CS15 or anything else! DISTRICT 7 - LUMBER Imran (ihussai3) he/him Hey! I'm a sophomore from Cambridge, MA, studying neuroscience and computer science. I love climbing, pottery, and I am a barista here at the underground cafe! So excited to meet all of you ^_^ DISTRICT 7 - LUMBER Isabelle (iashapir) she/her Hi! I'm Isabelle, and I'm a sophomore from Los Angeles studying CS. In my free time, I love cooking, baking, and trying new food. I've enjoyed eating pretty much every food I've tried except for cashews. I also love anything outdoors: hiking, rock climbing, kayaking, swimming, etc. I am so excited to be a CS15 TA this semester! DISTRICT 9 - GRAIN Jackson (jwschwar) he/him I am a sophomore from southern Connecticut. I am thinking about concentrating in Computer Science and possibly Political Science. I love sports and am involved in club Frisbee on campus. I also love the outdoors and spend most of my summers in the Adirondacks in upstate New York. I am super excited to experience CS15 again and to meet you all throughout the semester! DISTRICT 7 - LUMBER Jaclyn (jcohen45) any pronouns Hi all!! I'm a sophomore CS and Visa concentrator from South Florida. I love anything art and design, spooky full moon ceremonies, spending time in nature, ressurecting Blueno, and chasing birbs :) I'm excited to meet all of you! DISTRICT 10 - LIVESTOCK Jinho (jlee812) he/him Hey! I'm a sophomore from Cambridge, Mass studying CS and literary arts! When I'm not on tiktok, I'm in lecture watching tiktok. I love Taylor Swift, Succession, and am looking forward to meeting you all :) DISTRICT 11 - AGRICULTURE Jennifer (jzliao) she/her Hi, I'm Jennifer! I'm a sophomore from Farmington, CT planning to concentrate in CS and History. I like reading, playing piano and guitar, and rotting in bed. so excited for CS15!!!!! DISTRICT 1 - LUXURY Juan (jgarci71) he/him Hey everyone! My name is Juan, and I'm a junior from Compton, CA studying CS and Education. Outside of school, I tend to spend time playing random mobile games or watching a Gordon Ramsay show. I'm so excited to meet you all this semester :) DISTRICT 6 - TRANSPORTATION Kamryn (kwalke19) she/her Hi! I'm a sophomore from Maryland studying CS. When I'm not camping at the CIT, I'm dancing (go Fusion Dance Company!), reading, thrifting, or exploring cities. You can also find me in the Mosaic+ room pretty often. I'm so excited for this semester and I can't wait to meet you all :) DISTRICT 12 - MINING Kanayo (kduru1) he/him Hi! I'm a junior from Maryland. I like outdoor activities, cooking, and listening to music. If I'm not sleeping, you can usually find me sitting on the green enjoying the sun, unless it's winter in which case I'll disappear. I love exploring new places and food, so you might also just catch me wandering around! I'm so excited to meet all of you. Welcome to CS15 :) DISTRICT 1 - LUXURY Karim (kmouline) he/him Hi there! My name is Karim, and I am a junior studying Math-CS and English. While I'm not in the CIT working on projects or essays, you can find me in the pool with the club swim team, on the bike path with the running club, or spending an abnormal amount of flex points on Blue Room bagels and coffee. Let me know if you have questions about anything, whether it be Brown related or life in general! DISTRICT 4 - FISHING Keanu (kthuynh) he/him Hi! I'm a sophomore from LA concentrating in Computer Science and Applied Math if everything goes my way. Outside of CS15, I enjoy video games, comics, photography, and blowing all my Bear Bucks on Blue Room muffins. If it's something to brag about, I own the griddy emote in Fortnite. If it's not, I don't own the griddy emote in Fortnite. Excited to see you all this year! DISTRICT 9 - GRAIN Khalil (kodesai) he/him Hello!!!! My name is Khalil and I am a sophomore from San Diego, California planning to study Computational Biology. I love all things science and have some wet-lab experience if that is something any of y'all want to ask me about! Outside of academics, I love playing the flute, baking pies, and being generally a bit of a mess. I also listen to a ton of music (Big Thief, Radiohead, Angel Olsen, Sufjan Stevens, etc.), so come talk to me about that :) DISTRICT 11 - AGRICULTURE Logan (ldhines) he/they hey! i'm a sophomore from portland, oregon studying CS (and maybe linguistics). outside of school i'm really into thrifting, hiking, and listening to music while worrying about my spotify wrapped (please feel free to recommend anything!) :) i also love trying out random baking recipes and failing miserably. i'm super super excited to meet all of you this semester!! DISTRICT 6 - TRANSPORTATION Lana (lyangmac) she/her Hi everyone! I'm a sophomore from Ann Arbor, Michigan and I'm planning on concentrating in computer engineering. In my free time, I love to read, eat anything mango flavored, and spend time outside (especially hiking or swimming). Can't wait to meet you all! :)) DISTRICT 7 - LUMBER Morgane (mpizigo) she/her Hi! I'm a sophomore from France concentrating in Computer Science and Psychology. CS15 is the class that convinced me to pursue CS, so I hope y'all have a blast! Outside of classes, I love crocheting, cooking (badly), playing fishing mini games, and pursuing my love for hiking and martial arts. Debugging and testing are my favorite parts of CS, so don't feel bad if you bring a bug to me! DISTRICT 4 - FISHING Marissa (mshaffe3) she/they Hiya! I'm a sophomore from Philadelphia, PA, studying CS and either Science, Technology, and Society or Gender and Sexuality Studies. On campus, you can find me performing circus shows with Brown Aerial Acrobatics and a cappella music with the Higher Keys. I love contemporary & fantasy fiction, racing my mom on the NYT crossword, and sipping boba on the main green. DISTRICT 6 - TRANSPORTATION Megan (mtanuwid) she/her Hi everyone! I'm a sophomore from Jakarta, Indonesia studying Computational Biology. I love solving crosswords, eating English muffins, and binge-watching Law & Order: SVU. Can't wait to meet everyone! DISTRICT 3 - TECHNOLOGY Natalie (nking12) she/her I'm a sophomore from Houston, Texas. I'm planning on concentrating in CS and Econ and I'm so excited to TA the best class ever this year!! DISTRICT 3 - TECHNOLOGY Owen (oanders6) he/him I'm a junior studying Computer Science and Philosophy from Portland, Maine. When I'm not coding, I like watching sports, the beach, and bagels. Looking forward to the semester with you all! DISTRICT 13 - NUCLEAR Orlando (ocedeno) he/him Hey my name is Orlando! I'm currently a Senior studying computer science and I'm originally from the Bronx, NY. Currently, I'm binge watching One Piece, catching sunsets, going to the gym, or just chilling. DISTRICT 10 - LIVESTOCK Robyn (rjecroi1) Hi! I'm a sophomore. I am 87.2% likely to double concentrate in IAPA and CS. I am an avid sunset picture taker, Music lover (Spotify > Apple Music), and an unhealthily committed binger of shows (yes I've watched up to 16 seasons of Grey's Anatomy and will finish 20 seasons of One Piece). I am also excited to be your TA this semester. DISTRICT 4 - FISHING Sarah (sberhan4) she/her Hi everyone! I'm Sarah, and I am a sophomore from Cambridge, MA. I am undecided in my concentration, but I am thinking about Education and CS. In my free time, I enjoy doing the wordle, playing connections, and reading! I am super excited to get to know you all! Feel free to ask me any questions! DISTRICT 6 - TRANSPORTATION Sarah (snrichma) she/her Hi! I'm a sophomore from Danville, New Hampshire studying APMA-CS and physics. Outside of computer science, I love dancing and eating mint chocolate chip ice cream. I'm super excited to be a C15 TA this semester! DISTRICT 8 - TEXTILES Seehanah (stang52) she/her hiii i'm a junior from central jersey studying apma- cs. i'm from central jersey and enjoy eating, hiking, and traveling. really excited for a great semester with everyone! DISTRICT 9 - GRAIN Sherry (szhan235) she/her Hey! I'm a junior from Bellevue, WA studying CS with a focus on animation. I love drawing a lot and also enjoy powerlifting, swimming, and being in nature. Please do not mention anything anime/animation-related in front of me because I will literally not be able to stop talking about it. Can't wait for you to take CS15!! &lt3 DISTRICT 4 - FISHING Sophia (szlim) she/her Hi everyone! My name is Sophia and I'm a sophomore from Auckland, New Zealand. I intend on concentrating in Computer Science (and maybe Cognitive Science) but I enjoy exploring different classes in Brown's Open Curriculum. I love traveling, baking, and wasting my time watching tv shows and movies. Can't wait to get to know you all this semester :) DISTRICT 1 - LUXURY Will (wvandewa) he/him Junior from Cleveland, Ohio studying APMA-CS. Crochet enjoyer and casual runner. It's gonna be a crazy year. DISTRICT 7 - LUMBER Xiaoyue (xhou8) she/her I'm a junior concentrating in CS and Econ, and I'm from Beijing, China. I love traveling, hiking, learning languages, and watching & stage managing musicals. Really excited to meet you all! DISTRICT 3 - TECHNOLOGY", "https://cs.brown.edu/courses/csci0300/2021/c-cpp-primer.html": "CSCI 0300 : Fundamentals of Computer Systems Home Schedule Assignments Project 1: Strings & Vectors Project 2: DMalloc Project 3: Caching I/O Project 4: WeensyOS Project 5: Vunmo Project 6: Distributed Store Lab 0: Getting Set Up Lab 1: C Programming, Makefiles Lab 2: Debugging Lab 3: Assembly Lab 4: Caching Lab 5: Intro to WeensyOS Lab 6: Processes Lab 7: Threads Lab 8: RPCs Homework 1 Midterm Quiz Final Quiz Resources C/C++ Primers Textbooks Syllabus Missive FAQs Exercises: Computer Systems Basics Exercises: Operating Systems Exercises: Concurrency Exercises: Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Office Hours Spring 2021 \u26a0\ufe0f This is not the current iteration of the course! Head here for the current offering. C/C++ Language Primers CS 131 teaches you the fundamentals of computer systems, using the C and C++ programming languages. C and C++ are the two most widely used systems programming languages in industry today; millions of programs including your operating system and the web browser you're using to view this page are written in C and C++. C and C++ are valuable for every software engineer to know. They are powerful, but also dangerous, tools that give you more control over your computer, and more insight into its magic, than almost any other language. C C is an old programming language \u2013 it's been around since the 1970s! But despite its simple syntax, it is very powerful and versatile. We will go over the language in lectures, but lectures will move quickly, so additional reference material can be useful. We recommend these resources: USNA Intro to C Programming . This is a brief, detailed guide to the C language syntax, as well as how you use utility functions like printf . (You can ignore the bits about C++.) USNA Pointers, Arrays, and Structures . This explains in detail how the key data structure concepts of the C language work, and how you use them. C Standard Library Refrence from cplusplus.com . Despite the domain name, this site has excellent documentation for the C standard library (other parts of the site are a good C++ reference!). The C Programming Language by Brian W. Kernighan and Dennis M. Ritchie (also known as \"K&R\"; Prentice Hall PTR, ISBN 0-13-110362-8) is the classic textbook for programming in C. Harvard CS 61's C Patterns explains some handy common tricky that will be useful for your assignments. Linux/OS X/BSD man pages ! They're very detailed, but often tell you important details about library functions. Type man 3 <library_function> to open the man page for library_function (e.g., strncpy ). C++ C++ is a popular language for low-level systems coding, and unlike C, its predecessor, it comes with an extensive data structure library and high-level abstraction facilities. Though the course uses C++, it is about systems programming , and we will not use (or teach) the complex object-oriented features in C++ and attempt to avoid its most confusing concepts. That said, getting familiar with C++'s data structures and libraries will be useful. You can get this information from free resources on the web. Some web resources are almost overwhelmingly detailed, but don't despair! It often works to scroll through reference pages for example code, which can be more concise and clear than the English-language reference material. We recommend the following resources for C++: Harvard CS 161's C++ guide succinctly explains the key differences between C and C++. It explains some of the C++ concepts you may encounter in documentation or compiler error messages (e.g., constructors, destructors, etc.). C++ tutorials from LearnCpp.com C++ tutorial from cplusplus.com C++ tutorial from w3schools.com LearnCpp.com has an extensive set of tutorials. The cplusplus.com one is a good short tutorial. C++ reference from cplusplus.com C++ reference from cppreference.com As of 2019, cplusplus.com's text is more approachable, though its layout is uglier and its technical material slightly out of date. Acknowledgment: We thank Eddie Kohler and Harvard's CS 61 course for some of the above references, which we've reproduced with permission in modified form here. This work is licensed under a Creative Commons Attribution 4.0 International License . window.jQuery || document.write('<script src=\"js/jquery-slim.min.js\"><\\/script>') (function () { jQuery.fn.extend({ geometry: function (outer) { var x; if (this[0] == window) x = {left: this.scrollLeft(), top: this.scrollTop()}; else x = this.offset(); if (x) { x.width = outer ? this.outerWidth() : this.width(); x.height = outer ? this.outerHeight() : this.height(); x.right = x.left + x.width; x.bottom = x.top + x.height; } return x; } }); function sol_toggle(hide, storage) { this.childNodes[0].classList.toggle(\"hidden\", !hide); this.childNodes[0].classList.toggle(\"shown\", hide); this.childNodes[1].classList.toggle(\"hidden\", hide); this.childNodes[1].classList.toggle(\"shown\", !hide); if (storage) { var key = location.href + \" \" + $(\".has-solution\").index(this); if (hide) sessionStorage.removeItem(key); else sessionStorage.setItem(key, true); } } $(\".solution\").each(function () { $(this).wrap('<div class=\"has-solution\"></div>'); var sol = this.parentElement; $(sol).prepend('<blockquote class=\"solution-collapsed js-solution show\"><a href=\"\" class=\"js-solution show\"></a></blockquote>'); $(this).append('<p><a href=\"\" class=\"js-solution hide\"></a></p>'); $(sol).find(\"a.js-solution.show\").text(this.getAttribute(\"data-show-text\") || \"Show solution\"); $(sol).find(\"a.js-solution.hide\").text(this.getAttribute(\"data-hide-text\") || \"Hide solution\"); var key = location.href + \" \" + $(\".has-solution\").index(sol); if (sessionStorage.getItem(key)) sol_toggle.call(sol, false, false); }); $(document).on(\"click\", \".js-solution\", function (event) { if (this.classList.contains(\"all\")) { var hide = this.classList.contains(\"hide\"); $(\".has-solution\").each(function () { sol_toggle.call(this, hide, false); }); var bq = this.tagName === \"BLOCKQUOTE\" ? this : this.parentElement; $(bq).find(\".show\").toggleClass(\"hidden\", !hide); $(bq).find(\".hide\").toggleClass(\"hidden\", hide); } else { var sol = $(this).closest(\".has-solution\")[0]; sol_toggle.call(sol, this.classList.contains(\"hide\"), true); } event.preventDefault(); event.stopPropagation(); }); })()", "https://cs.brown.edu/courses/csci0300/2021/notes/l03.html": "CSCI 0300 : Fundamentals of Computer Systems Home Schedule Assignments Project 1: Strings & Vectors Project 2: DMalloc Project 3: Caching I/O Project 4: WeensyOS Project 5: Vunmo Project 6: Distributed Store Lab 0: Getting Set Up Lab 1: C Programming, Makefiles Lab 2: Debugging Lab 3: Assembly Lab 4: Caching Lab 5: Intro to WeensyOS Lab 6: Processes Lab 7: Threads Lab 8: RPCs Homework 1 Midterm Quiz Final Quiz Resources C/C++ Primers Textbooks Syllabus Missive FAQs Exercises: Computer Systems Basics Exercises: Operating Systems Exercises: Concurrency Exercises: Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Office Hours Spring 2021 \u26a0\ufe0f This is not the current iteration of the course! Head here for the current offering. hljs.initHighlightingOnLoad(); Lecture 3: Pointers and Data Representation \u00bb Lecture code \u00bb Post-Lecture Quiz (due 6pm on Monday, February 1st). Pointers and How To Use Them We previously discussed that memory boxes can store addresses of other memory boxes, and how an address occupies8 bytes. C provides the ampersand operator ( & ) to get the address of any variable. In other words, if youhave a variable local , writing &local gives you the address of the memory boxes thatstore local . Where are you going to store the address value returned from &local ? Well, if you want to hold on to it,you'll want to store it in a variable itself. Where does that variable live? It better be in memory, too! In otherwords, the 8 bytes corresponding to the address of &local will have a memory location of their own.We refer to such memory locations that hold addresses as pointers , because you can think of them asarrows pointing to other memory boxes. In terms of C types, a type followed by an asterisk corresponds to a pointer. For example, int* is apointer to an integer. An int* itself occupies 8 bytes of memory (since it stores an address), and itpoints to the first byte of a 4-byte sequence of memory boxes that store an int . To actually get to the value that a pointer points to, you use the * (asterisk) operator on the pointer(see data1/ptr-intro.c in the lecture code): void f() { int local = 1; int* ptr = &local; // prints 1 printf(\"value of ptr: %d\\n\", *ptr); // <== here, we \"dereference\" the pointer to get to the value of local // prints the address of local, twice printf(\"address of local: %p %p\\n\", &local, ptr); // <== \"%p\" is a printf format for printing pointers!} For some people, it helps to think of the asterisk operator as \"cancelling\" out the asterisk on the type:i.e., *(int*) == int . Some C programmers like to put the asterisk next to the type ( int* ptr for int -pointer ptr ), others put it with the variable name ( int *ptr ), because that way it's clear that the dereferenced version of ptr is an int . Use whatever notation makes sense for you! To change the value behind a pointer, you must dereference it. For example, the following program changesthe value of integer local through the pointer ptr by assigning a value to the dereferencedpointer: void f() { int local = 1; int* ptr = &local; *ptr = 42;// |-------------| ^// deref'd pointer | value we assign// = int | (also a int) printf(\"value of local is now: %d\\n\", local); // <== prints 42} Pointers are how to use the are very important in this course and in C/C++ programming in general. We'll keepcoming back to these concepts. The key things to remember are: & takes the address of an object andmakes a pointer, * dereferences a pointer and follows it to the value it refers to in memory. Types withan asterisk next to them are pointer types. Exploring Data Representation In Memory We already understand how programs are just bytes in memory, but now let's look in more detail at how data is represented in memory. Why are we covering this? We're now building an understanding of where the different parts of a C/C++ program (and, in fact, programs in otherlanguages too!) are stored in memory. This will help you understand how a program obtains and manages memory,something that some programming languages (e.g., Java, OCaml, Pyret) do automatically behind your back, while others,and particularly systems programming languages like C and C++, force you as the programmer do some of this memorymanagement. This gives you a great degree of control, and allows avoiding expensive hidden memory allocation andcopying costs. For this, we will use the program mexplore.c . This program declares and defines (recall the difference!)three variables, all of type char . char is the name for a byte type in the C language; itrefers to the fact that a byte is exactly sufficient to store one character according to the ASCII standard, a wayof translating numbers into characters and vice versa. Computers can only store numbers, so all characters in acomputer are actually \"encoded\" as numbers. For example, the uppercase letter \"A\" in ASCII corresponds tothe number 65 (see man ascii for the translation table). What's ASCII, and do we still use it today? In the early days of computers, every computer had its own way of encoding letters as numbers. ASCII, theAmerican Standard Code for Information Interchange, was defined in the 1960s to find a common way of representingtext. Original ASCII uses 7 bits, and can therefore represent 128 distinct characters \u2013 enough for the alphabet,numbers, and some funky special characters (e.g., newlines ( \\n ), the NUL character ( \\0 ),and \"bell\" character that made typewriter bells go off). But even 256 characters aren't sufficient to support languages that use non-Latin alphabets, and certainly notfor advanced emoji. So, while all of today's computers still support ASCII, we've mostly moved on to a new standard, Unicode , which supports 1.1 million characters using one to four bytes per character. Fun fact: to be backwardscompatible, Unicode is defined such that the original ASCII character encodings remain valid Unicode letters. What's the difference between these three char variables? Let's take a look. The first one, global_ch is defined in what we call global scope : it's at the top level of the file, not insidea function or inside the curly braces ( { } ) that C and C++ use to delineate scopes in the program. Thisvariable can be referred to from anywhere in the entire program. The second variable, const_global_ch is also a global variable, but the const keywordindicates that it is constant and the compiler and OS should not allow modifications to it. Finally, our third variable is inside function f() . It's called local_ch and is a localvariable . It's valid only within the scope of f() and other parts of the program (such as main ) cannot refer to it. The hexdump() function that f() calls is defined in hexdump.c and imported via hexdump.h , a \"header file\". (In a future lecture, we'll talk about why header files exist.) hexdump(ADDR, N) has the effect of printing the contents of N bytes of memory at address ADDR . We're passing our character variables to it, but prefix the variable with an ampersand character, & . So: hexdump(&global_ch, 1) means \"print 1 byte from a box located at theaddress of global_ch \". This is an important concept of the C language: you can always get the memory address at which an object islocated. The term \"object\" here means something different from what it means in an object-oriented languagelike Java: rather than an instance of a class, an \"object\" according to the C standard is a set of bytes thatcontain a value. This can be code (a function) or data (a variable). In other words, local and ptr in the snippet below refer to the same object, i.e., tothe same bytes of memory : void f() { int local = 1; int* ptr = &local;} Reacll that &local means \"the address of local \", and the value stored in the memorylocation where ptr is located is the 8 bytes that make up the address of local . The type of ptr is int* , which signifies that it is the address of an integer in memory (a short* would be the address of a short , a char* the address of a char , etc.). You can invert the ampersand operator using the asterisk ( * ) operator: *ptr dereferences the pointer and turns the address back into a value. In other words, *&local is the same as plain, old local . Thee concepts are very, very important \u2013 you'll use them all the time! Back to our mexplore.c program though. Let's look at what it prints when we run it (note that thespecific addresses will be different on your computer). $ ./mexplore00601038 41 |A|004009a4 42 |B|7ffd4977e80f 43 |C| On the left, we see the addresses of our three variables, printed in hexadecimal notation. Next, just to the rightof that, we see the hexadecimal value of the data stored in the byte at each of these addresses. For example,hexadecimal 41 (often written 0x41 for clarity) is equal to ... 16*4 + 1 = 65! Not surprisingly, thisequals to the ASCII character \"A\", which we see on the right. But let me draw your attention to the addresses on the left. They vary a fair amount! The exact locations of variablesin memory are decided by the compiler and OS together, but the general region where an object lives is determined by its lifetime . Think about how long each of our variables needs to stick around before the memory can be reused: The global variables, global_ch and const_global_ch , need to be around for the entire runtime of the program, as the program could reference them anywhere in the code. This is called a static lifetime . The local variable, local_ch , needs to stick around until it goes out of scope, which happens when the execution reaches the closing curly brace of f() . After it's out of scope, no code in the program can refer to the variable, so it is fine to reuse its memory. This is called an automatic lifetime . Local variables and function arguments have automatic lifetimes. But what if a function needs to create an object whose size is not known at the start of the program (so it can't beglobal) and which also needs to survive beyond the end of the function? In this common situation, neither a staticlifetime nor an automatic lifetime are appropriate. Dynamically Allocated Objects What if you have a variable that you create inside a function, but you want to keep it around after the functionreturns? For example, what if I want to define a character inside f() in mexplore-with-dynamic.c and then print it from main() ? I could make it a global variable, butwhen writing the program, I may not know exactly how many characters I'm going to need. For this purpose, the C language allows for a third kind of object lifetime: a dynamic lifetime . For anobject with a dynamic lifetime, you as the programmer have to explicitly create and destroy the object \u2013 that is,you must set aside memory for the object and make sure it is released again when the object is no longer needed. To set aside memory, you use the malloc() standard library function ( m emory alloc ate). malloc() takes only one argument, which is the number of bytes you're asking for, and it returns theaddress of the newly allocated memory (i.e., the address where the OS has set aside memory boxes for this object).For example, char* allocated_ch = malloc(1); reserves 1 byte of memory and stores the address of that bytes memory \"box\" in the variable allocated_ch .The char* in brackets is a cast of the pointer returned to the type we expect (a pointer to a char ); this is needed because malloc() itself does not have any idea what kind of objectyou're allocating, so we need to tell the compiler. To actually set the value inside a dynamic lifetime object, we have to dereference the pointer as usual.For example, in our character example in mexplore-with-dynamic.c , we dereference the pointer we got from malloc() and put our character ( 'D' ) into it by assigning a value to the dereferenced pointer: void f() { [...] char* allocated_ch = malloc(1); *allocated_ch = 'D';// |-------------| ^// deref'd pointer | value we assign// = char | (also a char)} Similarities and differences with Java Calls to malloc() may look clunky, but they effectively do the same thing as the new keyword in Java: setting aside memory for a new object. Indeed, C++ actually provides a new keywordthat, under the hood, invokes malloc() . One big difference compared to Java, however, is that you'reresponsible for cleaning up and returning that memory. Java figures out automatically when an object with a dynamiclifetime is no longer needed, and frees the memory then (a process called \"garbage collection\"). C andC++ don't do so, but leave it to the programmer to decide when the time is right to return the memory. The big upside of dynamic-lifetime objects is that we can decide at runtime how big they need to be, and that theycan outlive the function that creates them. Consider a string that takes the characters a user typed into the program\u2013 a quantity that's hard to predict correctly, and data that we certainly want to outlive the function that readsthe input! The big downside of dynamic-lifetime objects is that it's the programmer's responsibility to free the memoryallocated. You to this by calling the free() function with the address of the allocated boxes as anargument. For example, free(allocated_ch); will free the memory we asked malloc() toset aside for allocated_ch . Incorrect use of dynamic lifetimes is an immensely common source of problems, bugs, and securityholes in C/C++ programs: serious problems like memory leaks, double free, use-after-free, etc. all arise from thislanguage feature. Memory Segments Objects with different lifetimes are grouped into different regions in memory. The program code, global variables, andconstant global variables are all stored in static segments, as these all have static lifetimes and known sizesat compile time. Other objects are come and go, and therefore the memory regions that contain them grow and shrink. For example, asfunctions call each other, they create more and more local variables with automatic lifetimes; and as the program calls malloc() to reserve memory for objects with dynamic lifetimes, more memory is needed for these objects. If we look at the addresses printed by mexplore , we see that the global variables stored in are atrelatively low memory addresses (around 0x60'0000 hexadecimal and 0x40'0000 hexadecimal), whilethe local variable is stored at a high address, close to 0x7fff'ffff'ffff (about 2 47 ), andthe dynamically allocated character is stored in between (albeit closer to the static segments). There is a reason for this placement: it allows both types of segments to grow without risk of getting in each other'sway. In particular, the automatic-lifetime segment grows downwards as more local variables come intoscope, while the dynamic-lifetime segment grows upwards . If they ever meet, your computer runs out of memory. The size of the dynamic segment changesas the program asks for memory and frees it up again. Moreover, the used memory in the dynamic segment is not necessarily contiguous . Consider a program that allocates four char s, c1 to c4 andthen frees the third one: assuming the char s start at address 0x1a00050 , the memory would appearas below. 0x1a000.. ... 50 ... 51 ... 52 ... 53 <- addresses ----+------+------+------+------+-- ... | c1 | c2 | FREE | c4 | ... <- values ----+------+------+------+------+-- The gap between c2 and c4 arises because the memory of c3 has been freed bythe program, but it has not been reused. In other words, the dynamic segment can have \"holes\" in it (this iscalled fragmentation ). Finally, these segments have names: The part of the static-lifetime segment that holds program called is called the \"text segment\" (because it holds program text; though the \"text\" is in computer language); the parts for read-only globals ( \"rodata\" ) and modifyable globals ( \"data\" and \"bss\" ) also have names. The automatic-lifetime segment is called the stack . It's named so because it grows and shrinks like a stack of paper: when you call a function, its automatic-lifetime objects are added to the left of the existing automatic ones, and when the function returns, the program gives their memory up again. The dynamic-lifetime segment is called the heap , and it generally grows upwards in terms of memory addresses. But unlike the stack, it can have \"holes\": if the programmer destroyed an object that sits in between two others in memory, there is unused memory in between. (You can think of this as \"air gaps\" in a heap of things, maybe!). The stack and heap terms are important, and you will keep seeing them! Java Similarities Note In Java, any object created with the new keyword is allocated with dynamic lifetime and lives on the heap.(Java puts only \"primitive\" types ( int , double etc.) on the stack.)Indeed, Java under the hood uses malloc() ! Yet, it seems likeJava has automatic lifetime for all objects, as you never need to destroy them explicitly! This works because your programruns inside the Java virtual machine (JVM), which \"magically\" injects code that tracks whether each object isstill reachable via an in-scope variable; if this reference count goes to zero, the JVM automatically calls free() to delete the object. But all this magic is not free in performance terms, as there is code to run tokeep track of objects' reference counts. C and C++ instead opt to do nothing and give maximum control to the programmer,for better or worse. To summarize, the table below lists the memory segments we've learned about, what data they contain, and roughlywhere they are in terms of memory addresses. (In the OS part of the course, it will turn out that these memoryaddresses are actually a lie and the OS playing clever tricks on us, but for now let's assume they are the actualmemory addresses.) Object declaration (C program text) Lifetime Segment Example address range (runtime location in x86-64 Linux, non-position-independent) Constant global Static Code (or Text) 0x40'0000 (\u22481 \u00d7 2 22 ) Global Static Data 0x60'0000 (\u22481.5 \u00d7 2 22 ) Local Automatic Stack 0x7fff'448d'0000 (\u22482 47 = 2 25 \u00d7 2 22 ) Anonymous, returned by malloc (C) / new (C++) Dynamic Heap 0x1a0'0000 (\u22488 \u00d7 2 22 ) Summary Today, we looked at the notion of pointers (values storing addresses) in C. Then, we discussed more aboutwhere program data lives in memory. We learned about dynamically-allocated memory, which ishugely important for real-world programs that need to keep objects around after the end of a function or create objectswhose size is only known at runtime. We then built an understanding of how a program's memory is split into differentsegments that contain objects with different lifetimes. You're now in a good place to work on Lab 1, butwe'll talk more about arrays and pointer arithmetic next time. This work is licensed under a Creative Commons Attribution 4.0 International License . window.jQuery || document.write('<script src=\"../js/jquery-slim.min.js\"><\\/script>') (function () { jQuery.fn.extend({ geometry: function (outer) { var x; if (this[0] == window) x = {left: this.scrollLeft(), top: this.scrollTop()}; else x = this.offset(); if (x) { x.width = outer ? this.outerWidth() : this.width(); x.height = outer ? this.outerHeight() : this.height(); x.right = x.left + x.width; x.bottom = x.top + x.height; } return x; } }); function sol_toggle(hide, storage) { this.childNodes[0].classList.toggle(\"hidden\", !hide); this.childNodes[0].classList.toggle(\"shown\", hide); this.childNodes[1].classList.toggle(\"hidden\", hide); this.childNodes[1].classList.toggle(\"shown\", !hide); if (storage) { var key = location.href + \" \" + $(\".has-solution\").index(this); if (hide) sessionStorage.removeItem(key); else sessionStorage.setItem(key, true); } } $(\".solution\").each(function () { $(this).wrap('<div class=\"has-solution\"></div>'); var sol = this.parentElement; $(sol).prepend('<blockquote class=\"solution-collapsed js-solution show\"><a href=\"\" class=\"js-solution show\"></a></blockquote>'); $(this).append('<p><a href=\"\" class=\"js-solution hide\"></a></p>'); $(sol).find(\"a.js-solution.show\").text(this.getAttribute(\"data-show-text\") || \"Show solution\"); $(sol).find(\"a.js-solution.hide\").text(this.getAttribute(\"data-hide-text\") || \"Hide solution\"); var key = location.href + \" \" + $(\".has-solution\").index(sol); if (sessionStorage.getItem(key)) sol_toggle.call(sol, false, false); }); $(document).on(\"click\", \".js-solution\", function (event) { if (this.classList.contains(\"all\")) { var hide = this.classList.contains(\"hide\"); $(\".has-solution\").each(function () { sol_toggle.call(this, hide, false); }); var bq = this.tagName === \"BLOCKQUOTE\" ? this : this.parentElement; $(bq).find(\".show\").toggleClass(\"hidden\", !hide); $(bq).find(\".hide\").toggleClass(\"hidden\", hide); } else { var sol = $(this).closest(\".has-solution\")[0]; sol_toggle.call(sol, this.classList.contains(\"hide\"), true); } event.preventDefault(); event.stopPropagation(); }); })()", "https://cs.brown.edu/courses/csci0300/2021/format.html": "CSCI 0300 : Fundamentals of Computer Systems Home Schedule Assignments Project 1: Strings & Vectors Project 2: DMalloc Project 3: Caching I/O Project 4: WeensyOS Project 5: Vunmo Project 6: Distributed Store Lab 0: Getting Set Up Lab 1: C Programming, Makefiles Lab 2: Debugging Lab 3: Assembly Lab 4: Caching Lab 5: Intro to WeensyOS Lab 6: Processes Lab 7: Threads Lab 8: RPCs Homework 1 Midterm Quiz Final Quiz Resources C/C++ Primers Textbooks Syllabus Missive FAQs Exercises: Computer Systems Basics Exercises: Operating Systems Exercises: Concurrency Exercises: Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Office Hours Spring 2021 \u26a0\ufe0f This is not the current iteration of the course! Head here for the current offering. \ud83e\udda0 CS 300 format for 2021 \ud83c\udfa5 \ud83d\ude37 Rather than conventional, synchronous lectures on Zoom, we're trying out a different model that tries to accommocate different time zones and makes the Zoom experience as interactive as possible. Here's how this will work: We will split each 80-minute lecture into several recording sessions (~30 min each), which will take place at different times of the day, convenient for different time zones. You'll pick a time that works for you and join an active listener group of ~12-15 students associated with this time. A signup form for this will be available on the first day of the course. When you are an active listener, your attendance is required . We expect you to attend the recording session, be prepared, ask questions and contribute to the discussion. This is your chance to experience CSCI 0300 as if it was a small seminar! We will organize each lecture segment around a concept or demonstration program. Since we want you to participate actively in the lecture, there will often be some (brief) preparation work that we will assign to you. When it is not your rotation's turn, you will watch the recorded video, which we'll post on the course website. You are welcome to attend anyway should you wish to, but we'll ask students who aren't active listeners to turn off their video and give the active listeners priority for particiation. Over the course of the semester, each student will be required to attend about 10 lectures as an active listener (exact number TBD). Recording times. See below for the recording times. Please ensure that you attend during your active listener rotation's timeslot. Tuesday Thursday ALR1: 9-10am ALR4: 10:30-11:30am ALR2: 1-2am ALR5: 2-3pm ALR3: 7-8pm ALR6: 8-9pm Please submit your preferred times for youractive listener rotation via this form . Asynchronous lecture watching. Those students who aren't part of a live lecture recording as active listeners are expected to watch that lecture asynchronously. Once the course enrollment has stabilized, we are hoping to form \"lecture watching teams\" of about four students each, based on a number of factors, including time zone. These teams will watch the lectures together and interact at times of their own choosing. Lecture length. Lecture length will be more driven by content than time block. We will record six lecture segments a week, each 30 minutes in duration (sometimes a little more to allow for questions and discussion). Recording slots are 1 hour in duration, but will often take less time. Topics for the recordings will be announced in advance, and will roughly follow the course schedule . Optional sections. From time to time, we will offer optional sections, led by the instructor or TAs. These sections will review material and practice key skills, as well as offering a chance for you to ask questions. If the public health situation permits, we may offer in-person sections for those in Providence, subject to Brown's rules for hybrid course meetings (i.e., no more than 19 attendees, masks and social distancing required). Details will be announce on Piazza. In the shopping period , the initial lectures recordings will take place during the normal time slots (1-2:20pm Tuesday and Thursday). These recordings will be available shortly after for those who cannot make these times. Once course attendance has stabilized and you've submitted your active listener rotation time preferences, we will start the rotating recording schedule. This work is licensed under a Creative Commons Attribution 4.0 International License . window.jQuery || document.write('<script src=\"js/jquery-slim.min.js\"><\\/script>') (function () { jQuery.fn.extend({ geometry: function (outer) { var x; if (this[0] == window) x = {left: this.scrollLeft(), top: this.scrollTop()}; else x = this.offset(); if (x) { x.width = outer ? this.outerWidth() : this.width(); x.height = outer ? this.outerHeight() : this.height(); x.right = x.left + x.width; x.bottom = x.top + x.height; } return x; } }); function sol_toggle(hide, storage) { this.childNodes[0].classList.toggle(\"hidden\", !hide); this.childNodes[0].classList.toggle(\"shown\", hide); this.childNodes[1].classList.toggle(\"hidden\", hide); this.childNodes[1].classList.toggle(\"shown\", !hide); if (storage) { var key = location.href + \" \" + $(\".has-solution\").index(this); if (hide) sessionStorage.removeItem(key); else sessionStorage.setItem(key, true); } } $(\".solution\").each(function () { $(this).wrap('<div class=\"has-solution\"></div>'); var sol = this.parentElement; $(sol).prepend('<blockquote class=\"solution-collapsed js-solution show\"><a href=\"\" class=\"js-solution show\"></a></blockquote>'); $(this).append('<p><a href=\"\" class=\"js-solution hide\"></a></p>'); $(sol).find(\"a.js-solution.show\").text(this.getAttribute(\"data-show-text\") || \"Show solution\"); $(sol).find(\"a.js-solution.hide\").text(this.getAttribute(\"data-hide-text\") || \"Hide solution\"); var key = location.href + \" \" + $(\".has-solution\").index(sol); if (sessionStorage.getItem(key)) sol_toggle.call(sol, false, false); }); $(document).on(\"click\", \".js-solution\", function (event) { if (this.classList.contains(\"all\")) { var hide = this.classList.contains(\"hide\"); $(\".has-solution\").each(function () { sol_toggle.call(this, hide, false); }); var bq = this.tagName === \"BLOCKQUOTE\" ? this : this.parentElement; $(bq).find(\".show\").toggleClass(\"hidden\", !hide); $(bq).find(\".hide\").toggleClass(\"hidden\", hide); } else { var sol = $(this).closest(\".has-solution\")[0]; sol_toggle.call(sol, this.classList.contains(\"hide\"), true); } event.preventDefault(); event.stopPropagation(); }); })()", "https://cs.brown.edu/courses/csci0190/": "Next offering : Fall 2023 . Shriram's first four 0190 HTAs, at the 2013 graduation ceremony: Ethan Ceccetti (2009) Kshitij Lauria (2010) Jonah Kagan (2011) Aimee Lucido (2012) Thanks to Ethan for suggesting and arranging this! Past editions. You can find newer reviews on the Critical Review site. Some old links may no longer work because they change their URLs. Offering Review Fall 2022 Fall 2021 Fall 2020 Fall 2019 Fall 2018 Fall 2017 review Fall 2016 review Fall 2015 Fall 2014 review Fall 2013 review Fall 2012 review Fall 2011 review Fall 2010 review Fall 2009 review", "https://cs.brown.edu/courses/csci0300/2022/c-cpp-primer.html": "CSCI 0300 : Fundamentals of Computer Systems Home Schedule Assignments Project 1: Snake Project 2: DMalloc Project 3: Caching I/O Project 4: WeensyOS Project 5: Vunmo Project 6: Distributed Store Lab 0: Getting Set Up Lab 1: C Programming, Makefiles Lab 2: Debugging Lab 3: Assembly Lab 4: Caching Lab 5: Intro to WeensyOS Lab 6: Processes Lab 7: Threads Lab 8: Safer Systems Programming Lab 9: RPCs SRC Project: Software Preservation Midterm Quiz Final Quiz Resources C/C++ Primers Textbooks Syllabus Missive FAQs Exercises: Computer Systems Basics Exercises: Operating Systems Exercises: Concurrency Exercises: Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Office Hours Spring 2022 \u26a0\ufe0f This is not the current iteration of the course! Head here for the current offering. C/C++ Language Primers CS 131 teaches you the fundamentals of computer systems, using the C and C++ programming languages. C and C++ are the two most widely used systems programming languages in industry today; millions of programs including your operating system and the web browser you're using to view this page are written in C and C++. C and C++ are valuable for every software engineer to know. They are powerful, but also dangerous, tools that give you more control over your computer, and more insight into its magic, than almost any other language. C C is an old programming language \u2013 it's been around since the 1970s! But despite its simple syntax, it is very powerful and versatile. We will go over the language in lectures, but lectures will move quickly, so additional reference material can be useful. We recommend these resources: USNA Intro to C Programming . This is a brief, detailed guide to the C language syntax, as well as how you use utility functions like printf . (You can ignore the bits about C++.) USNA Pointers, Arrays, and Structures . This explains in detail how the key data structure concepts of the C language work, and how you use them. C Standard Library Refrence from cplusplus.com . Despite the domain name, this site has excellent documentation for the C standard library (other parts of the site are a good C++ reference!). The C Programming Language by Brian W. Kernighan and Dennis M. Ritchie (also known as \"K&R\"; Prentice Hall PTR, ISBN 0-13-110362-8) is the classic textbook for programming in C. Harvard CS 61's C Patterns explains some handy common tricky that will be useful for your assignments. Linux/OS X/BSD man pages ! They're very detailed, but often tell you important details about library functions. Type man 3 <library_function> to open the man page for library_function (e.g., strncpy ). C++ C++ is a popular language for low-level systems coding, and unlike C, its predecessor, it comes with an extensive data structure library and high-level abstraction facilities. Though the course uses C++, it is about systems programming , and we will not use (or teach) the complex object-oriented features in C++ and attempt to avoid its most confusing concepts. That said, getting familiar with C++'s data structures and libraries will be useful. You can get this information from free resources on the web. Some web resources are almost overwhelmingly detailed, but don't despair! It often works to scroll through reference pages for example code, which can be more concise and clear than the English-language reference material. We recommend the following resources for C++: Harvard CS 161's C++ guide succinctly explains the key differences between C and C++. It explains some of the C++ concepts you may encounter in documentation or compiler error messages (e.g., constructors, destructors, etc.). C++ tutorials from LearnCpp.com C++ tutorial from cplusplus.com C++ tutorial from w3schools.com LearnCpp.com has an extensive set of tutorials. The cplusplus.com one is a good short tutorial. C++ reference from cplusplus.com C++ reference from cppreference.com As of 2019, cplusplus.com's text is more approachable, though its layout is uglier and its technical material slightly out of date. Acknowledgment: We thank Eddie Kohler and Harvard's CS 61 course for some of the above references, which we've reproduced with permission in modified form here. This work is licensed under a Creative Commons Attribution 4.0 International License . window.jQuery || document.write('<script src=\"js/jquery-slim.min.js\"><\\/script>') (function () { jQuery.fn.extend({ geometry: function (outer) { var x; if (this[0] == window) x = {left: this.scrollLeft(), top: this.scrollTop()}; else x = this.offset(); if (x) { x.width = outer ? this.outerWidth() : this.width(); x.height = outer ? this.outerHeight() : this.height(); x.right = x.left + x.width; x.bottom = x.top + x.height; } return x; } }); function sol_toggle(hide, storage) { this.childNodes[0].classList.toggle(\"hidden\", !hide); this.childNodes[0].classList.toggle(\"shown\", hide); this.childNodes[1].classList.toggle(\"hidden\", hide); this.childNodes[1].classList.toggle(\"shown\", !hide); if (storage) { var key = location.href + \" \" + $(\".has-solution\").index(this); if (hide) sessionStorage.removeItem(key); else sessionStorage.setItem(key, true); } } $(\".solution\").each(function () { $(this).wrap('<div class=\"has-solution\"></div>'); var sol = this.parentElement; $(sol).prepend('<blockquote class=\"solution-collapsed js-solution show\"><a href=\"\" class=\"js-solution show\"></a></blockquote>'); $(this).append('<p><a href=\"\" class=\"js-solution hide\"></a></p>'); $(sol).find(\"a.js-solution.show\").text(this.getAttribute(\"data-show-text\") || \"Show solution\"); $(sol).find(\"a.js-solution.hide\").text(this.getAttribute(\"data-hide-text\") || \"Hide solution\"); var key = location.href + \" \" + $(\".has-solution\").index(sol); if (sessionStorage.getItem(key)) sol_toggle.call(sol, false, false); }); $(document).on(\"click\", \".js-solution\", function (event) { if (this.classList.contains(\"all\")) { var hide = this.classList.contains(\"hide\"); $(\".has-solution\").each(function () { sol_toggle.call(this, hide, false); }); var bq = this.tagName === \"BLOCKQUOTE\" ? this : this.parentElement; $(bq).find(\".show\").toggleClass(\"hidden\", !hide); $(bq).find(\".hide\").toggleClass(\"hidden\", hide); } else { var sol = $(this).closest(\".has-solution\")[0]; sol_toggle.call(sol, this.classList.contains(\"hide\"), true); } event.preventDefault(); event.stopPropagation(); }); })()", "https://cs.brown.edu/courses/csci0300/2021/": "CSCI 0300 : Fundamentals of Computer Systems Home Schedule Assignments Project 1: Strings & Vectors Project 2: DMalloc Project 3: Caching I/O Project 4: WeensyOS Project 5: Vunmo Project 6: Distributed Store Lab 0: Getting Set Up Lab 1: C Programming, Makefiles Lab 2: Debugging Lab 3: Assembly Lab 4: Caching Lab 5: Intro to WeensyOS Lab 6: Processes Lab 7: Threads Lab 8: RPCs Homework 1 Midterm Quiz Final Quiz Resources C/C++ Primers Textbooks Syllabus Missive FAQs Exercises: Computer Systems Basics Exercises: Operating Systems Exercises: Concurrency Exercises: Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Office Hours Spring 2021 \u26a0\ufe0f This is not the current iteration of the course! Head here for the current offering. Do you want to understand the magic that makes our computers work? CSCI 0300 is your chance to master that magic. Lectures: Tuesday/Thurday, 1:00-2:20pm (initially) ; various times \u2013 Location: Zoom . Missive \u2013 Syllabus \u2013 Schedule \u2013 Staff \u2013 Office Hours Infrastructure \u2013 Piazza \u2013 Grading server Lecture feedback \u2013 Lecture code Announcements 2021/04/19: Final Quiz released! Due 6pm AoE on Wednesday, April 21. Best of luck! ( Solutions ) 2021/04/07: Project 6 released! 2021/04/02: Lab 8 released! 2021/03/26: Project 5 released! 2021/03/23: Lab 7 released! 2021/03/12: Lab 6 released! 2021/03/08: Midterm Quiz released! Due 6pm AoE on Thursday, March 11. Best of luck! ( Solutions ) 2021/03/05: Project 4 released! 2021/03/02: Lab 5 released! 2021/02/26: Project 3 released! 2021/02/23: Lab 4 released! 2021/02/12: Project 2 released! 2021/02/09: Lab 3 released! 2021/02/02: Lab 2 released! 2021/01/26: Lab 1 released! 2021/01/21: Lab 0 and Project 1 released! 2021/01/21: Lecture notes, code, and videos will be available from the schedule page . Here are lecture notes for lectures 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 . 2021/01/19: \ud83e\udda0 Please read the notes on the CSCI 0300 format for 2021 \ud83d\ude37 2021/01/19: Sign up for Piazza ! Course Summary The goal of CSCI 0300/CS 300 is to teach the fundamentals behind the \"magic\" of computer systems from the hardware level to the global internet. We'll cover the ideas, principles and abstractions that unify computer systems design \u2013 from how your laptop runs multiple programs at the same time, to how companies like Instagram, AirBnB, and Google operate large websites, to how easy it is to exploit security vulnerabilities on badly designed systems. This is a great class for students who are interested in learning what systems programming is, how systems work, and why these systems are so critical to modern technology. CSCI 0300 highlights Learn how a computer really works: we'll look into what happens when a program runs, from the basics to high-level concepts! Use industry-strength tools: CSCI 0300 teaches you modern C/C++ programming with the tools that professional software engineers use! Two programming languages for the price of one: learn C and C++, two widely-used systems programming languages for high-performance software! Real-world inspired projects: in CSCI 0300's projects, you'll implement the core of your own operating system, and learn to build scalable infrastructure such as a distributed data store and a multi-threaded server similar to those companies use to run web services you use every day! Testimonial and Reviews \"...the resources section, the final quiz, the lectures, labs and lecture notes, all have been immensely helpful in my preparation for interviews. Just today in an interview I got asked to explain how virtual memory works and was able to explain it correctly. I was also able to give intuition on why it is necessary. [...] Overall, this interview was one I really wanted to ace and I\u2019m really glad it went well - all thanks to CS131.\" \u2014 Spring 2020 CSCI 1310 (CS131) student. See also the Critical Review's CSCI 1310 review from Spring 2020 . Prior offerings. This course was previously offered as CSCI 1310 in Spring 2020. Enrollment. CSCI 0300/CS 300 is open to anyone who has completed the introductory sequence (i.e., CSCI 0160, 0180, or 0190). Course Email: cs0300headtas@lists.cs.brown.edu . This work is licensed under a Creative Commons Attribution 4.0 International License . window.jQuery || document.write('<script src=\"js/jquery-slim.min.js\"><\\/script>') (function () { jQuery.fn.extend({ geometry: function (outer) { var x; if (this[0] == window) x = {left: this.scrollLeft(), top: this.scrollTop()}; else x = this.offset(); if (x) { x.width = outer ? this.outerWidth() : this.width(); x.height = outer ? this.outerHeight() : this.height(); x.right = x.left + x.width; x.bottom = x.top + x.height; } return x; } }); function sol_toggle(hide, storage) { this.childNodes[0].classList.toggle(\"hidden\", !hide); this.childNodes[0].classList.toggle(\"shown\", hide); this.childNodes[1].classList.toggle(\"hidden\", hide); this.childNodes[1].classList.toggle(\"shown\", !hide); if (storage) { var key = location.href + \" \" + $(\".has-solution\").index(this); if (hide) sessionStorage.removeItem(key); else sessionStorage.setItem(key, true); } } $(\".solution\").each(function () { $(this).wrap('<div class=\"has-solution\"></div>'); var sol = this.parentElement; $(sol).prepend('<blockquote class=\"solution-collapsed js-solution show\"><a href=\"\" class=\"js-solution show\"></a></blockquote>'); $(this).append('<p><a href=\"\" class=\"js-solution hide\"></a></p>'); $(sol).find(\"a.js-solution.show\").text(this.getAttribute(\"data-show-text\") || \"Show solution\"); $(sol).find(\"a.js-solution.hide\").text(this.getAttribute(\"data-hide-text\") || \"Hide solution\"); var key = location.href + \" \" + $(\".has-solution\").index(sol); if (sessionStorage.getItem(key)) sol_toggle.call(sol, false, false); }); $(document).on(\"click\", \".js-solution\", function (event) { if (this.classList.contains(\"all\")) { var hide = this.classList.contains(\"hide\"); $(\".has-solution\").each(function () { sol_toggle.call(this, hide, false); }); var bq = this.tagName === \"BLOCKQUOTE\" ? this : this.parentElement; $(bq).find(\".show\").toggleClass(\"hidden\", !hide); $(bq).find(\".hide\").toggleClass(\"hidden\", hide); } else { var sol = $(this).closest(\".has-solution\")[0]; sol_toggle.call(sol, this.classList.contains(\"hide\"), true); } event.preventDefault(); event.stopPropagation(); }); })()", "https://cs.brown.edu/courses/csci0300/2023/c-cpp-primer.html": "CSCI 0300 : Fundamentals of Computer Systems Home Schedule Assignments Project 1: Snake Project 2: DMalloc Project 3: Caching I/O Project 4: WeensyOS Project 5: Concurrent Store Project 6: Privacy-Compliant KVStore Lab 0: Getting Set Up Lab 1: C Programming, Makefiles Lab 2: Debugging Lab 3: Assembly Lab 4: Intro to WeensyOS Lab 5: Processes Lab 6: Threads SRC Project: Time Machine Section 1: Memory Organization and Pointers Section 2: Debugging, Alignment, and Signed Integers Section 3: Assembly Is Fun Section 4: Virtual Memory and Pagetables Section 5: Pipes and Multithreading Midterm Quiz Final Quiz Resources C/C++ Primers Docker Issues Textbooks Syllabus Missive FAQs Exercises: Computer Systems Basics Exercises: Operating Systems Exercises: Concurrency Exercises: Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Office Hours Spring 2023 \u26a0\ufe0f This is not the current iteration of the course! Head here for the current offering. C/C++ Language Primers CS 300 teaches you the fundamentals of computer systems, using the C and C++ programming languages. C and C++ are the two most widely used systems programming languages in industry today; millions of programs including your operating system and the web browser you're using to view this page are written in C and C++. C and C++ are valuable for every software engineer to know. They are powerful, but also dangerous, tools that give you more control over your computer, and more insight into its magic, than almost any other language. C C is an old programming language \u2013 it's been around since the 1970s! But despite its simple syntax, it is very powerful and versatile. We will go over the language in lectures, but lectures will move quickly, so additional reference material can be useful. We recommend these resources: The CS 300 TAs' C Primer is a concise overview of C language syntax and features, as well as helpful debugging tips, and comes in three parts: Part 1 , Part 2 , and Part 3 . Make sure to check this out first, since it's tailored towards the course! C Standard Library Refrence from cplusplus.com . Despite the domain name, this site has excellent documentation for the C standard library (other parts of the site are a good C++ reference!). The C Programming Language by Brian W. Kernighan and Dennis M. Ritchie (also known as \"K&R\"; Prentice Hall PTR, ISBN 0-13-110362-8) is the classic textbook for programming in C. Harvard CS 61's C Patterns explains some handy common tricky that will be useful for your assignments. Linux/OS X/BSD man pages ! They're very detailed, but often tell you important details about library functions. Type man 3 <library_function> to open the man page for library_function (e.g., strncpy ). C++ C++ is a popular language for low-level systems coding, and unlike C, its predecessor, it comes with an extensive data structure library and high-level abstraction facilities. Though the course uses C++, it is about systems programming , and we will not use (or teach) the complex object-oriented features in C++ and attempt to avoid its most confusing concepts. That said, getting familiar with C++'s data structures and libraries will be useful. You can get this information from free resources on the web. Some web resources are almost overwhelmingly detailed, but don't despair! It often works to scroll through reference pages for example code, which can be more concise and clear than the English-language reference material. We recommend the following resources for C++: Harvard CS 161's C++ guide succinctly explains the key differences between C and C++. It explains some of the C++ concepts you may encounter in documentation or compiler error messages (e.g., constructors, destructors, etc.). C++ tutorials from LearnCpp.com C++ tutorial from cplusplus.com C++ tutorial from w3schools.com LearnCpp.com has an extensive set of tutorials. The cplusplus.com one is a good short tutorial. C++ reference from cplusplus.com C++ reference from cppreference.com As of 2019, cplusplus.com's text is more approachable, though its layout is uglier and its technical material slightly out of date. Acknowledgment: We thank Eddie Kohler and Harvard's CS 61 course for some of the above references, which we've reproduced with permission in modified form here. This work is licensed under a Creative Commons Attribution 4.0 International License . window.jQuery || document.write('<script src=\"js/jquery-slim.min.js\"><\\/script>') (function () { jQuery.fn.extend({ geometry: function (outer) { var x; if (this[0] == window) x = {left: this.scrollLeft(), top: this.scrollTop()}; else x = this.offset(); if (x) { x.width = outer ? this.outerWidth() : this.width(); x.height = outer ? this.outerHeight() : this.height(); x.right = x.left + x.width; x.bottom = x.top + x.height; } return x; } }); function sol_toggle(hide, storage) { this.childNodes[0].classList.toggle(\"hidden\", !hide); this.childNodes[0].classList.toggle(\"shown\", hide); this.childNodes[1].classList.toggle(\"hidden\", hide); this.childNodes[1].classList.toggle(\"shown\", !hide); if (storage) { var key = location.href + \" \" + $(\".has-solution\").index(this); if (hide) sessionStorage.removeItem(key); else sessionStorage.setItem(key, true); } } $(\".solution\").each(function () { $(this).wrap('<div class=\"has-solution\"></div>'); var sol = this.parentElement; $(sol).prepend('<blockquote class=\"solution-collapsed js-solution show\"><a href=\"\" class=\"js-solution show\"></a></blockquote>'); $(this).append('<p><a href=\"\" class=\"js-solution hide\"></a></p>'); $(sol).find(\"a.js-solution.show\").text(this.getAttribute(\"data-show-text\") || \"Show solution\"); $(sol).find(\"a.js-solution.hide\").text(this.getAttribute(\"data-hide-text\") || \"Hide solution\"); var key = location.href + \" \" + $(\".has-solution\").index(sol); if (sessionStorage.getItem(key)) sol_toggle.call(sol, false, false); }); $(document).on(\"click\", \".js-solution\", function (event) { if (this.classList.contains(\"all\")) { var hide = this.classList.contains(\"hide\"); $(\".has-solution\").each(function () { sol_toggle.call(this, hide, false); }); var bq = this.tagName === \"BLOCKQUOTE\" ? this : this.parentElement; $(bq).find(\".show\").toggleClass(\"hidden\", !hide); $(bq).find(\".hide\").toggleClass(\"hidden\", hide); } else { var sol = $(this).closest(\".has-solution\")[0]; sol_toggle.call(sol, this.classList.contains(\"hide\"), true); } event.preventDefault(); event.stopPropagation(); }); })()", "https://cs.brown.edu/courses/csci0300/2024/c-cpp-primer.html": "CSCI 0300 : Fundamentals of Computer Systems Home Schedule Assignments Project 1: Snake Project 2: DMalloc Project 3: Caching I/O Lab 0: Getting Set Up Lab 1: C Programming, Makefiles Lab 2: Debugging Lab 3: Assembly Section 1: Pointers and Strings Section 2: Arrays and Structs Section 4: Assembly and the Stack Section 5: File Operations Resources C/C++ Primers Docker Issues Textbooks Syllabus Missive FAQs Exercises: Computer Systems Basics Exercises: Operating Systems Exercises: Concurrency Exercises: Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Sections Office Hours Spring 2024 C/C++ Language Primers CS 300 teaches you the fundamentals of computer systems, using the C and C++ programming languages. C and C++ are the two most widely used systems programming languages in industry today; millions of programs including your operating system and the web browser you're using to view this page are written in C and C++. C and C++ are valuable for every software engineer to know. They are powerful, but also dangerous, tools that give you more control over your computer, and more insight into its magic, than almost any other language. C C is an old programming language \u2013 it's been around since the 1970s! But despite its simple syntax, it is very powerful and versatile. We will go over the language in lectures, but lectures will move quickly, so additional reference material can be useful. We recommend these resources: The CS 300 TAs' C Primer is a concise overview of C language syntax and features, as well as helpful debugging tips, and comes in three parts: Part 1 , Part 2 , and Part 3 . Make sure to check this out first, since it's tailored towards the course! C Standard Library Refrence from cplusplus.com . Despite the domain name, this site has excellent documentation for the C standard library (other parts of the site are a good C++ reference!). The C Programming Language by Brian W. Kernighan and Dennis M. Ritchie (also known as \"K&R\"; Prentice Hall PTR, ISBN 0-13-110362-8) is the classic textbook for programming in C. Harvard CS 61's C Patterns explains some handy common tricky that will be useful for your assignments. Linux/OS X/BSD man pages ! They're very detailed, but often tell you important details about library functions. Type man 3 <library_function> to open the man page for library_function (e.g., strncpy ). C++ C++ is a popular language for low-level systems coding, and unlike C, its predecessor, it comes with an extensive data structure library and high-level abstraction facilities. Though the course uses C++, it is about systems programming , and we will not use (or teach) the complex object-oriented features in C++ and attempt to avoid its most confusing concepts. That said, getting familiar with C++'s data structures and libraries will be useful. You can get this information from free resources on the web. Some web resources are almost overwhelmingly detailed, but don't despair! It often works to scroll through reference pages for example code, which can be more concise and clear than the English-language reference material. We recommend the following resources for C++: Harvard CS 161's C++ guide succinctly explains the key differences between C and C++. It explains some of the C++ concepts you may encounter in documentation or compiler error messages (e.g., constructors, destructors, etc.). C++ tutorials from LearnCpp.com C++ tutorial from cplusplus.com C++ tutorial from w3schools.com LearnCpp.com has an extensive set of tutorials. The cplusplus.com one is a good short tutorial. C++ reference from cplusplus.com C++ reference from cppreference.com As of 2019, cplusplus.com's text is more approachable, though its layout is uglier and its technical material slightly out of date. Acknowledgment: We thank Eddie Kohler and Harvard's CS 61 course for some of the above references, which we've reproduced with permission in modified form here. This work is licensed under a Creative Commons Attribution 4.0 International License . window.jQuery || document.write('<script src=\"js/jquery-slim.min.js\"><\\/script>') (function () { jQuery.fn.extend({ geometry: function (outer) { var x; if (this[0] == window) x = {left: this.scrollLeft(), top: this.scrollTop()}; else x = this.offset(); if (x) { x.width = outer ? this.outerWidth() : this.width(); x.height = outer ? this.outerHeight() : this.height(); x.right = x.left + x.width; x.bottom = x.top + x.height; } return x; } }); function sol_toggle(hide, storage) { this.childNodes[0].classList.toggle(\"hidden\", !hide); this.childNodes[0].classList.toggle(\"shown\", hide); this.childNodes[1].classList.toggle(\"hidden\", hide); this.childNodes[1].classList.toggle(\"shown\", !hide); if (storage) { var key = location.href + \" \" + $(\".has-solution\").index(this); if (hide) sessionStorage.removeItem(key); else sessionStorage.setItem(key, true); } } $(\".solution\").each(function () { $(this).wrap('<div class=\"has-solution\"></div>'); var sol = this.parentElement; $(sol).prepend('<blockquote class=\"solution-collapsed js-solution show\"><a href=\"\" class=\"js-solution show\"></a></blockquote>'); $(this).append('<p><a href=\"\" class=\"js-solution hide\"></a></p>'); $(sol).find(\"a.js-solution.show\").text(this.getAttribute(\"data-show-text\") || \"Show solution\"); $(sol).find(\"a.js-solution.hide\").text(this.getAttribute(\"data-hide-text\") || \"Hide solution\"); var key = location.href + \" \" + $(\".has-solution\").index(sol); if (sessionStorage.getItem(key)) sol_toggle.call(sol, false, false); }); $(document).on(\"click\", \".js-solution\", function (event) { if (this.classList.contains(\"all\")) { var hide = this.classList.contains(\"hide\"); $(\".has-solution\").each(function () { sol_toggle.call(this, hide, false); }); var bq = this.tagName === \"BLOCKQUOTE\" ? this : this.parentElement; $(bq).find(\".show\").toggleClass(\"hidden\", !hide); $(bq).find(\".hide\").toggleClass(\"hidden\", hide); } else { var sol = $(this).closest(\".has-solution\")[0]; sol_toggle.call(sol, this.classList.contains(\"hide\"), true); } event.preventDefault(); event.stopPropagation(); }); })()", "https://cs.brown.edu/courses/csci0300/2022/": "CSCI 0300 : Fundamentals of Computer Systems Home Schedule Assignments Project 1: Snake Project 2: DMalloc Project 3: Caching I/O Project 4: WeensyOS Project 5: Vunmo Project 6: Distributed Store Lab 0: Getting Set Up Lab 1: C Programming, Makefiles Lab 2: Debugging Lab 3: Assembly Lab 4: Caching Lab 5: Intro to WeensyOS Lab 6: Processes Lab 7: Threads Lab 8: Safer Systems Programming Lab 9: RPCs SRC Project: Software Preservation Midterm Quiz Final Quiz Resources C/C++ Primers Textbooks Syllabus Missive FAQs Exercises: Computer Systems Basics Exercises: Operating Systems Exercises: Concurrency Exercises: Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Office Hours Spring 2022 \u26a0\ufe0f This is not the current iteration of the course! Head here for the current offering. Do you want to understand the magic that makes our computers work? CSCI 0300 is your chance to master that magic. Lectures: Monday/Wednesday, 3:00-4:20pm \u2013 Location: Barus & Holley 166 . Missive \u2013 Syllabus \u2013 Schedule \u2013 Staff \u2013 Office Hours Infrastructure \u2013 EdStem \u2013 Grading server Lecture feedback \u2013 Lecture code Announcements 2022/05/20: Final Quiz solutions released! 2022/04/27: Project 6 released! 2022/04/26: Lab 9 released! 2022/04/21: Lab 8 released! 2022/04/15: Project 5 released! 2022/04/12: Lab 7 released! 2022/04/05: Lab 6 released! 2022/03/29: Midterm Quiz solutions released! 2022/03/21: SRC Project released! 2022/03/20: Project 4 released! 2022/03/16: Lab 5 released! 2022/03/08: Lab 4 released! 2022/03/05: Project 3 released! 2022/02/18: Project 2 released! 2022/02/17: Lab 3 released! 2022/02/01: Lab 2 released! 2022/01/28: Lab 1 released! 2022/01/26: Lab 0 and Project 1 released! 2022/01/23: Lecture notes, code, and videos will be available from the schedule page . Here are lecture notes for lectures 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 . 2022/01/23: 2\ufe0f\u20e32\ufe0f\u20e3 Please read the notes on the CSCI 0300 format for 2022 \ud83c\udd95 2022/01/23: Join the EdStem ! Course Summary The goal of CSCI 0300/CS 300 is to teach the fundamentals behind the \"magic\" of computer systems from the hardware level to the global internet. We'll cover the ideas, principles and abstractions that unify computer systems design \u2013 from how your laptop runs multiple programs at the same time, to how companies like Instagram, AirBnB, and Google operate large websites, to how easy it is to exploit security vulnerabilities on badly designed systems. This is a great class for students who are interested in learning what systems programming is, how systems work, and why these systems are so critical to modern technology. CSCI 0300 highlights Learn how a computer really works: we'll look into what happens when a program runs, from the basics to high-level concepts! Use industry-strength tools: CSCI 0300 teaches you modern C/C++ programming with the tools that professional software engineers use! Two programming languages for the price of one: learn C and C++, two widely-used systems programming languages for high-performance software! Real-world inspired projects: in CSCI 0300's projects, you'll implement the core of your own operating system, and learn to build scalable infrastructure such as a distributed data store and a multi-threaded server similar to those companies use to run web services you use every day! Testimonial and Reviews \"...the resources section, the final quiz, the lectures, labs and lecture notes, all have been immensely helpful in my preparation for interviews. Just today in an interview I got asked to explain how virtual memory works and was able to explain it correctly. I was also able to give intuition on why it is necessary. [...] Overall, this interview was one I really wanted to ace and I\u2019m really glad it went well - all thanks to CS131.\" \u2014 Spring 2020 CSCI 1310 (CS131) student. Critical Review: Spring 2021 , Spring 2020 (as CSCI 1310) . Prior offerings: Spring 2021 , Spring 2020 (as CSCI 1310) . Enrollment. CSCI 0300/CS 300 is open to anyone who has completed the introductory sequence (i.e., CSCI 0160, 0180, 0190, or 0200). Course Email: cs0300headtas@lists.cs.brown.edu . This work is licensed under a Creative Commons Attribution 4.0 International License . window.jQuery || document.write('<script src=\"js/jquery-slim.min.js\"><\\/script>') (function () { jQuery.fn.extend({ geometry: function (outer) { var x; if (this[0] == window) x = {left: this.scrollLeft(), top: this.scrollTop()}; else x = this.offset(); if (x) { x.width = outer ? this.outerWidth() : this.width(); x.height = outer ? this.outerHeight() : this.height(); x.right = x.left + x.width; x.bottom = x.top + x.height; } return x; } }); function sol_toggle(hide, storage) { this.childNodes[0].classList.toggle(\"hidden\", !hide); this.childNodes[0].classList.toggle(\"shown\", hide); this.childNodes[1].classList.toggle(\"hidden\", hide); this.childNodes[1].classList.toggle(\"shown\", !hide); if (storage) { var key = location.href + \" \" + $(\".has-solution\").index(this); if (hide) sessionStorage.removeItem(key); else sessionStorage.setItem(key, true); } } $(\".solution\").each(function () { $(this).wrap('<div class=\"has-solution\"></div>'); var sol = this.parentElement; $(sol).prepend('<blockquote class=\"solution-collapsed js-solution show\"><a href=\"\" class=\"js-solution show\"></a></blockquote>'); $(this).append('<p><a href=\"\" class=\"js-solution hide\"></a></p>'); $(sol).find(\"a.js-solution.show\").text(this.getAttribute(\"data-show-text\") || \"Show solution\"); $(sol).find(\"a.js-solution.hide\").text(this.getAttribute(\"data-hide-text\") || \"Hide solution\"); var key = location.href + \" \" + $(\".has-solution\").index(sol); if (sessionStorage.getItem(key)) sol_toggle.call(sol, false, false); }); $(document).on(\"click\", \".js-solution\", function (event) { if (this.classList.contains(\"all\")) { var hide = this.classList.contains(\"hide\"); $(\".has-solution\").each(function () { sol_toggle.call(this, hide, false); }); var bq = this.tagName === \"BLOCKQUOTE\" ? this : this.parentElement; $(bq).find(\".show\").toggleClass(\"hidden\", !hide); $(bq).find(\".hide\").toggleClass(\"hidden\", hide); } else { var sol = $(this).closest(\".has-solution\")[0]; sol_toggle.call(sol, this.classList.contains(\"hide\"), true); } event.preventDefault(); event.stopPropagation(); }); })()", "https://cs.brown.edu/courses/csci0300/2023/": "CSCI 0300 : Fundamentals of Computer Systems Home Schedule Assignments Project 1: Snake Project 2: DMalloc Project 3: Caching I/O Project 4: WeensyOS Project 5: Concurrent Store Project 6: Privacy-Compliant KVStore Lab 0: Getting Set Up Lab 1: C Programming, Makefiles Lab 2: Debugging Lab 3: Assembly Lab 4: Intro to WeensyOS Lab 5: Processes Lab 6: Threads SRC Project: Time Machine Section 1: Memory Organization and Pointers Section 2: Debugging, Alignment, and Signed Integers Section 3: Assembly Is Fun Section 4: Virtual Memory and Pagetables Section 5: Pipes and Multithreading Midterm Quiz Final Quiz Resources C/C++ Primers Docker Issues Textbooks Syllabus Missive FAQs Exercises: Computer Systems Basics Exercises: Operating Systems Exercises: Concurrency Exercises: Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Office Hours Spring 2023 \u26a0\ufe0f This is not the current iteration of the course! Head here for the current offering. Do you want to understand the magic that makes our computers work? CSCI 0300 is your chance to master that magic. Lectures: Tuesday/Thursday, 1:00-2:20pm \u2013 Location: MacMillan 117 . Missive \u2013 Syllabus \u2013 Schedule \u2013 Staff \u2013 Office Hours Infrastructure \u2013 EdStem \u2013 Grading server Lecture feedback \u2013 Lecture code Announcements 2023/05/30: Final Quiz solutions released! Thanks for taking the course \ud83e\udd70 2023/04/15: Project 5B (Privacy-Compliant KVStore) released! 2023/04/20: Lab 6 released! 2023/04/18: Project 5A (KVStore) released! 2023/04/12: Midterm Quiz solutions released! 2023/04/09: Lab 5 released! 2023/03/21: SRC Project (Time Machine) released! 2023/03/21: Project 4 (WeensyOS) released! 2023/03/15: Lab 4 released! 2023/03/05: Project 3 (Caching I/O) released! 2023/03/01: Lab 3 released! 2023/02/18: Project 2 (DMalloc) released! 2023/02/07: Lab 2 released! 2023/01/31: Lab 1 released! 2023/01/26: Lab 0 and Project 1 (Snake) released! 2023/01/24: Lecture notes, code, and videos will be available from the schedule page . Here are lecture notes for lectures 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 . 2023/01/03: 2\ufe0f\u20e33\ufe0f\u20e3 Please read the notes on the CSCI 0300 format for 2023 \ud83c\udd95 2023/01/03: Join the EdStem ! Course Summary The goal of CSCI 0300/CS 300 is to teach the fundamentals behind the \"magic\" of computer systems from the hardware level to the global internet. We'll cover the ideas, principles and abstractions that unify computer systems design \u2013 from how your laptop runs multiple programs at the same time, to how companies like Instagram, Airbnb, and Google operate large websites, to how easy it is to exploit security vulnerabilities on badly designed systems. This is a great class for students who are interested in learning what systems programming is, how systems work, and why these systems are so critical to modern technology. CSCI 0300 highlights Learn how a computer really works: we'll look into what happens when a program runs, from the basics to high-level concepts! Use industry-strength tools: CSCI 0300 teaches you modern C/C++ programming with the tools that professional software engineers use! Two programming languages for the price of one: learn C and C++, two widely-used systems programming languages for high-performance software! Real-world inspired projects: in CSCI 0300's projects, you'll implement the core of your own operating system, and learn to build scalable infrastructure such as a distributed data store and a multi-threaded server similar to those companies use to run web services you use every day! Testimonial and Reviews \"...the resources section, the final quiz, the lectures, labs and lecture notes, all have been immensely helpful in my preparation for interviews. Just today in an interview I got asked to explain how virtual memory works and was able to explain it correctly. I was also able to give intuition on why it is necessary. [...] Overall, this interview was one I really wanted to ace and I\u2019m really glad it went well - all thanks to CS131.\" \u2014 Spring 2020 CSCI 1310 (CS131) student. Critical Review: Spring 2022 , Spring 2021 , Spring 2020 (as CSCI 1310) . Prior offerings: Spring 2022 , Spring 2021 , Spring 2020 (as CSCI 1310) . Enrollment. CSCI 0300/CS 300 is open to anyone who has completed the introductory sequence (i.e., CSCI 0160, 0180, 0190, or 0200). Course Email: cs0300headtas@lists.cs.brown.edu . This work is licensed under a Creative Commons Attribution 4.0 International License . window.jQuery || document.write('<script src=\"js/jquery-slim.min.js\"><\\/script>') (function () { jQuery.fn.extend({ geometry: function (outer) { var x; if (this[0] == window) x = {left: this.scrollLeft(), top: this.scrollTop()}; else x = this.offset(); if (x) { x.width = outer ? this.outerWidth() : this.width(); x.height = outer ? this.outerHeight() : this.height(); x.right = x.left + x.width; x.bottom = x.top + x.height; } return x; } }); function sol_toggle(hide, storage) { this.childNodes[0].classList.toggle(\"hidden\", !hide); this.childNodes[0].classList.toggle(\"shown\", hide); this.childNodes[1].classList.toggle(\"hidden\", hide); this.childNodes[1].classList.toggle(\"shown\", !hide); if (storage) { var key = location.href + \" \" + $(\".has-solution\").index(this); if (hide) sessionStorage.removeItem(key); else sessionStorage.setItem(key, true); } } $(\".solution\").each(function () { $(this).wrap('<div class=\"has-solution\"></div>'); var sol = this.parentElement; $(sol).prepend('<blockquote class=\"solution-collapsed js-solution show\"><a href=\"\" class=\"js-solution show\"></a></blockquote>'); $(this).append('<p><a href=\"\" class=\"js-solution hide\"></a></p>'); $(sol).find(\"a.js-solution.show\").text(this.getAttribute(\"data-show-text\") || \"Show solution\"); $(sol).find(\"a.js-solution.hide\").text(this.getAttribute(\"data-hide-text\") || \"Hide solution\"); var key = location.href + \" \" + $(\".has-solution\").index(sol); if (sessionStorage.getItem(key)) sol_toggle.call(sol, false, false); }); $(document).on(\"click\", \".js-solution\", function (event) { if (this.classList.contains(\"all\")) { var hide = this.classList.contains(\"hide\"); $(\".has-solution\").each(function () { sol_toggle.call(this, hide, false); }); var bq = this.tagName === \"BLOCKQUOTE\" ? this : this.parentElement; $(bq).find(\".show\").toggleClass(\"hidden\", !hide); $(bq).find(\".hide\").toggleClass(\"hidden\", hide); } else { var sol = $(this).closest(\".has-solution\")[0]; sol_toggle.call(sol, this.classList.contains(\"hide\"), true); } event.preventDefault(); event.stopPropagation(); }); })()", "https://cs.brown.edu/courses/csci0330/": "this link", "https://cs.brown.edu/courses/csci0300/2024/": "CSCI 0300 : Fundamentals of Computer Systems Home Schedule Assignments Project 1: Snake Project 2: DMalloc Project 3: Caching I/O Lab 0: Getting Set Up Lab 1: C Programming, Makefiles Lab 2: Debugging Lab 3: Assembly Section 1: Pointers and Strings Section 2: Arrays and Structs Section 4: Assembly and the Stack Section 5: File Operations Resources C/C++ Primers Docker Issues Textbooks Syllabus Missive FAQs Exercises: Computer Systems Basics Exercises: Operating Systems Exercises: Concurrency Exercises: Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Sections Office Hours Spring 2024 Do you want to understand the magic that makes our computers work? CSCI 0300 is your chance to master that magic. Lectures: Tuesday/Thursday, 1:00-2:20pm \u2013 Location: MacMillan 117 . Missive \u2013 Syllabus \u2013 Staff \u2013 Schedule \u2013 Sections Office Hours \u2013 EdStem \u2013 Grading server Lecture feedback \u2013 Lecture code Announcements 2024/03/02: Project 3 (Caching I/O) released! 2024/02/27: Lab 3 released! 2024/02/17: Project 2 (DMalloc) released! 2024/02/12: \u2603\ufe0f\u2744\ufe0f Due to the severe weather, lecture 6 (Tuesday, February 13) will take place on Zoom ! \ud83c\udfc2\ud83c\udf28\ufe0f 2024/02/06: Lab 2 released! 2024/01/30: Lab 1 released! 2024/01/24: Lecture notes, code, and videos will be available from the schedule page . Here are lecture notes for lectures 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 . 2024/01/24: Lab 0 and Project 1 (Snake) released! 2024/01/04: 2\ufe0f\u20e34\ufe0f\u20e3 Please read the notes on the CSCI 0300 format for 2024 \ud83c\udd95 2024/01/04: Join the EdStem ! Course Summary The goal of CSCI 0300/CS 300 is to teach the fundamentals behind the \"magic\" of computer systems from the hardware level to the global internet. We'll cover the ideas, principles and abstractions that unify computer systems design \u2013 from how your laptop runs multiple programs at the same time, to how companies like Instagram, Airbnb, and Google operate large websites, to how easy it is to exploit security vulnerabilities on badly designed systems. This is a great class for students who are interested in learning what systems programming is, how systems work, and why these systems are so critical to modern technology. CSCI 0300 highlights Learn how a computer really works: we'll look into what happens when a program runs, from the basics to high-level concepts! Use industry-strength tools: CSCI 0300 teaches you modern C/C++ programming with the tools that professional software engineers use! Two programming languages for the price of one: learn C and C++, two widely-used systems programming languages for high-performance software! Real-world inspired projects: in CSCI 0300's projects, you'll implement the core of your own operating system, and learn to build scalable infrastructure such as a distributed data store and a multi-threaded server similar to those companies use to run web services you use every day! Testimonial and Reviews \"...the resources section, the final quiz, the lectures, labs and lecture notes, all have been immensely helpful in my preparation for interviews. Just today in an interview I got asked to explain how virtual memory works and was able to explain it correctly. I was also able to give intuition on why it is necessary. [...] Overall, this interview was one I really wanted to ace and I\u2019m really glad it went well - all thanks to CS131.\" \u2014 Spring 2020 CSCI 1310 (CS131) student. Critical Review (missing reviews are due to CR): Spring 2023 , Spring 2022 , Spring 2021 , Spring 2020 (as CSCI 1310) . Prior offerings: Spring 2023 , Spring 2022 , Spring 2021 , Spring 2020 (as CSCI 1310) . Enrollment. CSCI 0300/CS 300 is open to anyone who has completed the introductory sequence (i.e., CSCI 0160, 0180, 0190, or 0200). Course Email: cs0300headtas@lists.cs.brown.edu . Instructors: cs300-instructors@brown.edu . This work is licensed under a Creative Commons Attribution 4.0 International License . window.jQuery || document.write('<script src=\"js/jquery-slim.min.js\"><\\/script>') (function () { jQuery.fn.extend({ geometry: function (outer) { var x; if (this[0] == window) x = {left: this.scrollLeft(), top: this.scrollTop()}; else x = this.offset(); if (x) { x.width = outer ? this.outerWidth() : this.width(); x.height = outer ? this.outerHeight() : this.height(); x.right = x.left + x.width; x.bottom = x.top + x.height; } return x; } }); function sol_toggle(hide, storage) { this.childNodes[0].classList.toggle(\"hidden\", !hide); this.childNodes[0].classList.toggle(\"shown\", hide); this.childNodes[1].classList.toggle(\"hidden\", hide); this.childNodes[1].classList.toggle(\"shown\", !hide); if (storage) { var key = location.href + \" \" + $(\".has-solution\").index(this); if (hide) sessionStorage.removeItem(key); else sessionStorage.setItem(key, true); } } $(\".solution\").each(function () { $(this).wrap('<div class=\"has-solution\"></div>'); var sol = this.parentElement; $(sol).prepend('<blockquote class=\"solution-collapsed js-solution show\"><a href=\"\" class=\"js-solution show\"></a></blockquote>'); $(this).append('<p><a href=\"\" class=\"js-solution hide\"></a></p>'); $(sol).find(\"a.js-solution.show\").text(this.getAttribute(\"data-show-text\") || \"Show solution\"); $(sol).find(\"a.js-solution.hide\").text(this.getAttribute(\"data-hide-text\") || \"Hide solution\"); var key = location.href + \" \" + $(\".has-solution\").index(sol); if (sessionStorage.getItem(key)) sol_toggle.call(sol, false, false); }); $(document).on(\"click\", \".js-solution\", function (event) { if (this.classList.contains(\"all\")) { var hide = this.classList.contains(\"hide\"); $(\".has-solution\").each(function () { sol_toggle.call(this, hide, false); }); var bq = this.tagName === \"BLOCKQUOTE\" ? this : this.parentElement; $(bq).find(\".show\").toggleClass(\"hidden\", !hide); $(bq).find(\".hide\").toggleClass(\"hidden\", hide); } else { var sol = $(this).closest(\".has-solution\")[0]; sol_toggle.call(sol, this.classList.contains(\"hide\"), true); } event.preventDefault(); event.stopPropagation(); }); })()", "https://cs.brown.edu/courses/csci0931/2015-fall/": "function swap(img, newUrl, left) { img.src=newUrl; } window.onload=function() { var images = document.getElementsByTagName('img'); for (i = 0; i < images.length; i++) { if (images[i].onmouseout) { images[i].onmouseout(); } } } Home Class Materials About CS0931 Missive/Syllabus Staff Resources Calendar Student Projects CSCI 0931, Fall 2015 Daily News Permanent Office Hours! Woot! Sunday 8-10pm (Pran): Fishbowl Monday 6:30-8:30pm (Stewart): CIT 267 Wednesday 6-8pm (Anna): CIT 201 Wednesday 8-10pm (Raymond): CIT 201 Welcome! For prospective students interested in this course, you can read About CSCI0931 for information about prerequisites, workload, and the waitlist. For more information about the syllabus, staff and grading of the course, you can read the Course Missive . CSCI0931 meets Tuesdays and Thursdays 9:00\u201310:20 in Lubrano (Room 477) of the CIT ( map ). You'll need a laptop to take this course. If you don't have one, talk with the instructor and we'll see if we can work out some solution for you. Past editions of the course can be found on the offerings page .", "https://cs.brown.edu/courses/csci1010/": "Home Assignments Hours Lectures Documents Staff Welcome to CSCI 1010! This is a core undergraduate computer science course on the foundations of computing. The questions it aims to answer are: (1) What is computation? (2) What is computable? (3) What is computable given our limited resources? We'll answer these questions and, in the process, explore important concepts such as Turing machines, languages, reductions, and NP-completeness. Welcome to the delicious world of theoretical computer science, and we hope you'll join us in exploring it! Sincerely, the entr\u00e9e course chefs Announcements Logistics All information related to the class (e.g., assignments, grading, collaboration policy, late policy) is available in the official class syllabus . Time and Location CSCI 1010 will hold in-person lectures on Tuesdays and Thursdays from 10:30AM to 11:50AM in room 368 of the CIT. The recorded lectures will be available to everyone via Panopto. EdStem Access the course EdStem page here. Students are responsible for all clarifications and toppings posted on EdStem. Exams Both midterms will be in class exams, with details to be announced. Despite popular demand, there will be no culinary practical. Wellness Resources Check out the advice, resources, and friendly words Brown CS students have put together. Please reach out to the TAs, HTA, or professor at any time with concerns or questions about the course. We're rooting for you from the kitchen!", "https://cs.brown.edu/courses/csci1270/": "Check out the previous iteration of the course here Fall 2023(In Progress) Fall 2021 Fall 2020", "https://brown-cs500.github.io": "CS500 Home Lectures Assignments Labs Calendar Staff Welcome to CS500! This is the first-ever offering of CS500 and we are glad you can join us! This course will cover the basics of how to design and analyze data structures and algorithms. This course aims to: Develop your ability to think algorithmically. (What does this even mean? The answer will emerge gradually during the course.) Ensure that you understand some well-established techniques, algorithms, and methods of analysis. Give you some technical tools to predict for a given computational problem what kind of performance is possible. Hone your ability to reason rigorously about computational problems and algorithms and quantities such as running time. Tweets The largest known prime number . Want to do better? The randomized algorithm for testing primality, the Miller-Rabin algorithm (mentioned in class on Jan. 29) uses exponentiation modulo the number being tested. We saw an algorithm for exponentiation in class on Jan. 24; exponentiation modulo an integer can be reduced to (a) integer multiplication and (b) truncated division. We have discussed a multiplication algorithm that is faster than the grade-school algorithm (though there is a faster algorithm so take CS 1570). We are in the process of working out a reduction from truncated division to multiplication. Something to think about: how fast would these algorithms have to be for you to be able to beat the record? And what is the current computational bottleneck? Course Info astro-island,astro-slot,astro-static-slot{display:contents} (()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).only=e;window.dispatchEvent(new Event(\"astro:only\"));})();;(()=>{var b=Object.defineProperty;var f=(c,o,i)=>o in c?b(c,o,{enumerable:!0,configurable:!0,writable:!0,value:i}):c[o]=i;var l=(c,o,i)=>(f(c,typeof o!=\"symbol\"?o+\"\":o,i),i);var p;{let c={0:t=>m(t),1:t=>i(t),2:t=>new RegExp(t),3:t=>new Date(t),4:t=>new Map(i(t)),5:t=>new Set(i(t)),6:t=>BigInt(t),7:t=>new URL(t),8:t=>new Uint8Array(t),9:t=>new Uint16Array(t),10:t=>new Uint32Array(t)},o=t=>{let[e,r]=t;return e in c?c[e](r):void 0},i=t=>t.map(o),m=t=>typeof t!=\"object\"||t===null?t:Object.fromEntries(Object.entries(t).map(([e,r])=>[e,o(r)]));customElements.get(\"astro-island\")||customElements.define(\"astro-island\",(p=class extends HTMLElement{constructor(){super(...arguments);l(this,\"Component\");l(this,\"hydrator\");l(this,\"hydrate\",async()=>{var d;if(!this.hydrator||!this.isConnected)return;let e=(d=this.parentElement)==null?void 0:d.closest(\"astro-island[ssr]\");if(e){e.addEventListener(\"astro:hydrate\",this.hydrate,{once:!0});return}let r=this.querySelectorAll(\"astro-slot\"),a={},h=this.querySelectorAll(\"template[data-astro-template]\");for(let n of h){let s=n.closest(this.tagName);s!=null&&s.isSameNode(this)&&(a[n.getAttribute(\"data-astro-template\")||\"default\"]=n.innerHTML,n.remove())}for(let n of r){let s=n.closest(this.tagName);s!=null&&s.isSameNode(this)&&(a[n.getAttribute(\"name\")||\"default\"]=n.innerHTML)}let u;try{u=this.hasAttribute(\"props\")?m(JSON.parse(this.getAttribute(\"props\"))):{}}catch(n){let s=this.getAttribute(\"component-url\")||\"<unknown>\",y=this.getAttribute(\"component-export\");throw y&&(s+=` (export ${y})`),console.error(`[hydrate] Error parsing props for component ${s}`,this.getAttribute(\"props\"),n),n}await this.hydrator(this)(this.Component,u,a,{client:this.getAttribute(\"client\")}),this.removeAttribute(\"ssr\"),this.dispatchEvent(new CustomEvent(\"astro:hydrate\"))});l(this,\"unmount\",()=>{this.isConnected||this.dispatchEvent(new CustomEvent(\"astro:unmount\"))})}disconnectedCallback(){document.removeEventListener(\"astro:after-swap\",this.unmount),document.addEventListener(\"astro:after-swap\",this.unmount,{once:!0})}connectedCallback(){if(!this.hasAttribute(\"await-children\")||document.readyState===\"interactive\"||document.readyState===\"complete\")this.childrenConnectedCallback();else{let e=()=>{document.removeEventListener(\"DOMContentLoaded\",e),r.disconnect(),this.childrenConnectedCallback()},r=new MutationObserver(()=>{var a;((a=this.lastChild)==null?void 0:a.nodeType)===Node.COMMENT_NODE&&this.lastChild.nodeValue===\"astro:end\"&&(this.lastChild.remove(),e())});r.observe(this,{childList:!0}),document.addEventListener(\"DOMContentLoaded\",e)}}async childrenConnectedCallback(){let e=this.getAttribute(\"before-hydration-url\");e&&await import(e),this.start()}start(){let e=JSON.parse(this.getAttribute(\"opts\")),r=this.getAttribute(\"client\");if(Astro[r]===void 0){window.addEventListener(`astro:${r}`,()=>this.start(),{once:!0});return}Astro[r](async()=>{let a=this.getAttribute(\"renderer-url\"),[h,{default:u}]=await Promise.all([import(this.getAttribute(\"component-url\")),a?import(a):()=>()=>{}]),d=this.getAttribute(\"component-export\")||\"default\";if(!d.includes(\".\"))this.Component=h[d];else{this.Component=h;for(let n of d.split(\".\"))this.Component=this.Component[n]}return this.hydrator=u,this.hydrate},e,this)}attributeChangedCallback(){this.hydrate()}},l(p,\"observedAttributes\",[\"props\"]),p))}})(); Useful Links Syllabus EdStem Gradescope Anonymous Feedback HTA Email Pseudocode Guide Github Guide Gradescope Guide Lectures Topic Date Notes Algebraic/Arithmetic Operations I 01/24 Sorting and Selection I 01/26 Sorting and Selection II 01/29 Sorting and Selection III + Algebraic/Arithmetic Operations II 01/31 Algebraic/Arithmetic Operations III 02/02 BigFloat Modulo 02/05 Hashing I 02/07 Hashing II 02/09 Hashing III 02/12 Priority Queues/Heaps I 02/14 Heaps 02/16 Binary Search Trees I 02/21 Binary Search Trees II 02/23 Binary Search Trees III 02/26 Graph Search I: Components, Topological Sort 02/28 Graph Search II: Components, Topological Sort 03/01 Graph Search III: Shortest Paths, MSTs 03/04 Graph Search IV: Shortest Paths, MSTs 03/06 Graph Search V: Shortest Paths, MSTs 03/08 Dynamic Programming I 03/11 Dynamic Programming II 03/13 Dynamic Programming III 03/15 Dynamic Programming IV 03/18 Dynamic Programming V 03/20 Midterm II 03/22 Finite Automata I 04/01 Finite Automata II 04/03 Finite Automata III 04/05 Turing Machines I 04/08 Turing Machines II 04/10 Turing Machines III 04/12 Cook-Levin Theorem I 04/15 Cook-Levin Theorem II 04/17 Cook-Levin Theorem III 04/19 NP Reductions I 04/22 NP Reductions II 04/24 NP Reductions III 04/26 Coping with NP-Hardness I 04/29 Coping with NP-Hardness II 05/01 Assignments Assignment Out In Handout Solution Getting Started 1/26 1/29 Algebraic/Arithmetic Algorithms and Selection 2/2 2/10 Sorting, Division, and Primality Testing 2/14 2/21 Hashing and Heaps 2/28 3/6 Labs Lab Out Due Handout Sorting 1/30 2/1 BigPrime 2/6 2/9 Hashing 2/13 2/15 Heaps 2/20 2/22 BST 2/27 2/29 Treaps 3/5 3/7 Calendar Staff Philip Klein | Professor | pklein Hammad Izhar | HTA | hizhar Robert Scheidegger | UTA | rscheide Ethan Williams | UTA | ewilli51 Derek Yang | UTA | dvyang", "https://cs.brown.edu/courses/csci1270/website_2020/": "Toggle navigation CS127 Home Assignments TA Hours Lectures Documents Staff CS127 Database Management Systems Welcome to CSCI1270! The concepts you will learn in this class include aspects of database design, database languages, and database-system implementation. The course textbook is Database Systems Concepts, Sixth Edition by Silberschatz, Korth, and Sudarshan. ISBN: 0073523321. The course is every Tuesday and Thursday, 2:30-3:50 Online . The first class is on Thursday, September 10th . Please stop on by! Lectures will be held at this zoom link Announcements Waitlist If you were unable to register on Banner due to the enrollment cap but are still interested in taking the course, please fill out this form . Collaboration Policy This year we will be collecting collaboration policies electronically. Please use this link to carefully read the policy and sign to indicate your agreement to abide by the policy. You will not receive any credit for any assignments until we have your signature on file. A copy will be made available on our course page for future reference. Anonymous Feedback Find the form here . Quizzes The quizzes locations, times and dates will be announced. Piazza Access the course Piazza page here . Querying the Textbook Use a small app we built to query the textbook databases here . CSCI1270 Fall 2020 \u2022 Prof. Stan Zdonik cs1270tas@cs.brown.edu", "https://browncs1260.github.io/": "CSCI 1260 Assignments Lectures Calendar Resources Staff \u2630 CSCI 1260 Assignments Lectures Calendar Resources Staff \u2630 CSCI 1260 Compilers and Program Analysis Fall 2023 Introduction Welcome to CSCI 1260 at Brown University! Have you ever wondered why C programs seem to run faster than Python programs? Have you ever been confused by an error message and wondered why Java couldn't understand your program? In CSCI 1260, we'll learn how compilers read in code in one language and produce code in another; in particular, we'll learn how to translate high-level languages to code that your computer's processor can understand. We will get hands-on practice developing compilers for a series of increasingly complex languages. Along the way, we'll learn some general best practices for developing and testing complex software systems. Lectures take place every Monday and Wednesday from 9:30 - 10:50 AM in CIT 241 . All course lectures will be recorded and livestreamed on Panopto . Assignments Homework Out In 0. OCaml Warmup Sep. 6 Sep. 13 1. S-expressions Sep. 13 Sep. 20 2. Characters Sep. 20 Sep. 27 3. DMAOC (div, mul, and, or, case) Sep. 27 Oct. 11 4. Error handling and the heap Oct. 11 Oct. 18 5. Fun with files Oct. 18 Nov. 1 2 6. Apply, variadic functions Nov. 1 Nov. 15 7. MiniML Nov. 15 Nov. 29 8. Optimizations Nov. 28 Dec. 17 (benchmarks Dec 9) Lab Handout Github Classroom Compiler Infrastructure Handout Github Classroom Debugging Assembly Handout Github Classroom Parser Generators Handout Github Classroom Drill Out In Drill 1 ( Solutions ) Sep. 6 Sep. 10 Drill 2 ( Solutions ) Sep. 13 Sep. 17 Drill 3 ( Solutions ) Sep. 20 Sep. 24 Drill 4 ( Solutions ) Sep. 28 Oct. 1 Drill 5 ( Solutions ) Oct. 11 Oct. 15 Drill 6 ( Solutions ) Nov. 1 Nov. 5 Drill 7 ( Solutions ) Nov. 8 Nov. 12 Drill 9 ( Solutions ) Dec. 4 Dec 11 Exam Date Midterm Oct. 25 Final Dec. 13 Lectures Lectures take place every Monday and Wednesday from 9:30 - 10:50 AM in CIT 241 . The lecture notes will be updated after every class. Streams and recordings will show up in our Panopto folder and are linked here. Lecture topics for future dates are very tentative. Date Topic Recording September 06 What is a compiler? Recording ( Last year's recording with audio ) September 11 OCaml intro; S-Expressions Recording September 13 Unary operations Recording September 18 Booleans Recording September 20 More booleans, conditionals Recording September 25 Binary operations Recording September 27 Abstract syntax trees Recording October 02 Naming expression with let Recording October 04 Pairs and the heap Recording October 09 NO CLASS October 11 Handling errrors Recording October 16 Debugging assembly Recording October 18 Interacting with the environment Recording October 23 Output and functions Recording October 25 MIDTERM EXAM (in class) October 30 More on functions Recording November 01 Tail calls Recording November 06 Function pointers; first-class and anonymous functions Recording November 08 Lambda lifting and closures Recording November 13 More on parsing Recording November 15 Guest lecture: Keith Adams on HHVM Recording November 20 Optimization intro -- constant folding Recording November 22 NO CLASS November 27 Inlining, CSE Recording November 29 IRs and register allocation Recording December 04 Trust and verification Recording December 06 NO CLASS December 13 FINAL EXAM (in person) Calendar Zoom links are included in the Google Calendar event, as well as in the Hours Queue. Resources Quick Links Syllabus Software Guide Environment Setup Guide x86-64 reference Compiler from lectures EdStem Panopto Anonymous Feedback Form Extension Request Form Reference Labs Contact robert_lewis@brown.edu cs1260headtas@lists.brown.edu cs1260tas@lists.brown.edu Staff Robert Lewis \ud83e\udd99 Professor | rlewis13 Call me Rob! I'm half computer scientist, half mathematician, and fully excited to learn about compilers with you all this semester. Pronouns: he/him/his Jiahua Chen \ud83c\udf35 HTA | jchen345 Hi! I'm a senior from HK and Shanghai studying Math & CS! Talk to me about art, photography, or board games! Pronouns: he/him/his Yutong Li \ud83c\udf66 UTA | yli195 Just call me Yuu! I'm a master's student studying CS, and I used to be a ling major. I love strolling around while listening to J-pop/Vocaloid/Post-rock. Parker Simon \ud83e\udd96 UTA | psimon2 Hi everyone! I'm a senior from Massachusetts studying Geology and Computer Science. I love climbing, hiking and skiing, and a good bowl of mac and cheese. Linus Sun \ud83e\udd20 UTA | lsun23 Hi! I'm from Vancouver and I enjoy climbing, mixology, and keyboards! Pronouns: he/him/his Nora Tang \ud83d\udc28 UTA | jtang82 Hello! My name is Nora. Tizzy K's is my favorite spot in Providence. Pronouns: she/her/hers Conrad Zimmerman \ud83c\udfc3\u200d\u2640\ufe0f UTA | czimmer Hi! I study math, play Pokemon Go, and sometimes run. In no particular order, I love coffee, programming languages, cute (little) dogs, and first order logic. Pronouns: she/her/hers Etha Hua \ud83d\udc18 UTA | thua5 Hi! I am a first-year master's student. Before coming to Brown, I studied CS and philosophy at Tufts. I enjoy street photography, 20th-century films, and the mechanical interpretability of language models. Pronouns: he/him/his Xinrui Zhou \ud83d\udc30 UTA | xzhou81 Hi! I'm a master's student studying CS. I'm from Chengdu, China, the home to adorable pandas and some of the best hot pot you'll ever taste. I love reading, cooking, listening to R&B and kpop. Pronouns: she/her/hers Vipul Sharma \ud83d\udef6 UTA | vsharm44 Hello! I'm a first-year master's student from India. I love trying out new recipes, modern classical music and phonk. Pronouns: he/him/his Copyright \u00a9 2023 CSCI 1260 @ Brown", "https://cs1230.graphics": "Home Docs Lectures Labs Projects Welcome to CS 1230! Calendar Staff Welcome to CS 1230! Welcome to CS 1230, the longest-running computer graphics course in the known universe! This course offers an in-depth exploration of fundamental concepts in 2D and 3D computer graphics. It introduces 2D raster graphics techniques (image creation/manipulation/filtering), as well as 3D modeling, viewing, and rendering (using both raytracing and real-time rendering on the GPU). Along the way, you'll learn to program in C++ and the shading language GLSL, and learn to use the OpenGL library. The course culminates in an open-ended group final project in which you and your teammates use the skills you've learned throughout the semester to make some cool visual effects. Check out the course missive for more information on prerequisites, assignments, workload, etc. Calendar Tip: Use the dropdown at the top right of the Google Calendar embed to filter by event type! Google Calendar and iCalendar subscription links For Google Calendar : While logged in to your Google account, click on the links below to add them to your Google Calendar. For iCalendar : Secondary-click on the links below and select \"Copy Link Address\" to copy the link to your clipboard. Then, follow the instructions for your calendar app to add a calendar subscription using the link. Do not download and import the .ics files directly, as they will not update if the calendar changes. Name Google Calendar iCalendar Description Assignments Link Link Contains project and lab timelines. Ed Hours Link Link Contains Ed hours. Hours Link Link Contains TA hours and Daniel's office hours. Lectures Link Link Contains lectures and other events held during lecture. Mentor Meetings Link Link Contains Mentor Meeting slots. Staff CS 1230 was built by the following lovely people: Daniel Ritchie \u00ae Professor \u2022 dritchi1 \u2022 he/him Has an Erd\u0151s number of 4, a Bacon number of 3, and (debatably) an Erd\u0151s-Bacon number of 7. Dylan Hu \u00ae HTA \u2022 dhu24 \u2022 he/him Is a senior from Massachusetts. Between perms. Wants to dye his hair orange. Enjoys grapefruit. William Sun \u00ae HTA \u2022 wsun28 \u2022 he/him Is a concurrent masters student in Computer Science. Enjoys anime, memes, the Japanese language, memes, the violin, and memes. Orion Bloomfield \u00ae TA \u2022 obloomfi \u2022 he/him Enjoys Norwalk, Connecticut (but has never been). Sings in acapella. Afraid of cryptic crosswords. Jared Cambier \u00ae TA \u2022 jcambier \u2022 he/him I'm a senior from Kansas City. In my free time, I like playing bullet chess and video games (Stardew Valley recently). I also enjoy listening to jazz. Jamie Chen \u00ae TA \u2022 achen309 \u2022 he/him Is a second-yr master student in CS from Shenzhen. Loves everything glowy and volumetric \ud83e\uddca. Tomas Dougan \u00ae TA \u2022 tdougan1 \u2022 he/him Hello! I'm a junior from Athens, GA. I'm interested in compilers, graphics, math, and hardware. I also like rock climbing, drawing, and TV! My favorite programming language is C. Austin Funk \u00ae TA \u2022 afunk3 \u2022 he/him Is a junior from Charlottesville, VA (shoutout to my fellow TA, Stewart). Enjoys playing saxophone, feeding goats grass (from the ground), and reading fantasy books! Kazen Gallman \u00ae TA \u2022 kgallman \u2022 he/him Hello! I'm a senior from RI studying CS and Cog Neuro, in my free time i'm probably playing video games, reading manga, playing volleyball, or sleeping, but I also like to make really bad websites :D Helen Huang \u00ae TA \u2022 hhuang65 \u2022 she/her Is a senior from Massachusetts. Favorite uses of graphics: art and video games. Mehek Jethani \u00ae TA \u2022 mjethani \u2022 she/her Is a senior from NJ studying CS. Favorite use of graphics: movie VFX. Stewart Morris \u00ae TA \u2022 smorri21 \u2022 he/him Is a junior from Charlottesville, VA (shoutout to my fellow TA, Austin). Enjoys playing guitar, watching movies, and going for the occasional hike! Sebastian Park \u00ae TA \u2022 spark265 \u2022 he/him Hi. I\u2019m a junior from Massachusetts who likes talking and jazz and making sound with his mouth. Favorite use of graphics: The Lego Movie. Anh Truong \u00ae TA \u2022 dtruong7 \u2022 he/him Really enjoys playing the piano and seeing real, unharmed bunnies. Nick Vadasz \u00ae TA \u2022 nvadasz \u2022 he/him is a senior from Texas studying CS. Ruminates to shoegaze. Enjoyer of brutalist web design. Loves cold pasta. Fan of the color blue. Smriti Vaidyanathan \u00ae TA \u2022 svaidya4 \u2022 she/her Senior from the San Francisco Bay Area. Enjoys singing, cooking, molecular biology, and gymming. Krishi Saripalli \u00ae Dev TA \u2022 ksaripal \u2022 he/him I\u2019m a senior from the San Francisco Bay Area and a (fake) TA for this course. I like interactive graphics software, like Spline, and making things with bloom . {\"pageContext\":{\"_pageId\":\"/pages/index\"}}", "https://cs.brown.edu/courses/csci1290/asgn/final/": "Final Project Final Project Due Date: 11:59pm on Thursday, Dec 20th, 2011 Brief Handin final: cs129_handin final Required files: README, code/, html/, html/index.html Proposal Requirements This year there is no formal requirement for you to propose a final project topic. If you are uncertain about the topic and scope of your project, you are encouraged to speak with or email the TAs and professor. Final Project Requirements You are required to choose a topic and implement a project based on it. A good way to start is by looking at published graphics and vision papers. You can also look at final projects from previous years in this course and similar courses linked from the course webpage (e.g. 2011 , 2010 ). If your topic is based on a particularly complex paper, you may only want to implement portions of it or a simpler version of the algorithm. On the flipside, if you want to expand upon an assignment you already did, you'll need to make extensive improvements. Final Project Presentation You are required to make a web page for your project, as you have for the previous projects, but your write-up needs to be more extensive. You will use your web page to present your final project to the entire class during the final exam period on December 21st. Your presentation can be from 2 to 4 minutes . You will lose points if you present more than 4 minutes. Practice your talk! . During this brief presentation, you should explain to the class what your project goal is, explain the algorithm in as much detail as time permits, and show a few results. Your web page should have the visualizations, diagrams, and results you need for this brief overview. Extra Credit There's no real \"extra\" credit since you are defining the specifications of your project. So basically, do more work and you'll definitely get an A. Graduate Credit Just like extra credit, except you are expected to do more work than other students. We realize this is very open-ended, so if you're not sure if you're doing enough work for graduate credit, ask us. Handing in This is very important as you will lose points if you do not follow instructions. Every time after the first that you do not follow instructions, you will lose 5 points. The folder you hand in must contain the following: README - text file containing anything about the project that you want to tell the TAs code/ - directory containing all your code for this assignment html/ - directory containing all your html report for this assignment (including images) html/index.html - home page for your results Then run: cs129_handin final If it is not in your path, you can run it directly: /course/cs129/bin/cs129_handin final Rubric +70 pts: Final Project +20 pts: Write-up +10 pts: Presentation -5*n pts: Lose 5 points for every time (after the first) you do not follow the instructions for the hand in format Good Luck!", "https://cs.brown.edu/courses/csci1310/2020/assign/labs/assets/Vagrantfile": "# -*- mode: ruby -*-# vi: set ft=ruby :# ### CS131 Development VM #### Feel free to modify this file to best work with your machine.# # For documentation, please see the comments here or go to# https://docs.vagrantup.com for more information.# All Vagrant configuration is done below. The \"2\" in Vagrant.configure# configures the configuration version (we support older styles for# backwards compatibility). Please don't change it unless you know what# you're doing.Vagrant.configure(\"2\") do |config| # The most common configuration options are documented and commented below. # For a complete reference, please see the online documentation at # https://docs.vagrantup.com. # Every Vagrant development environment requires a box. You can search for # boxes at https://vagrantcloud.com/search. config.vm.box = \"ubuntu/bionic64\" # Disable automatic box update checking. If you disable this, then # boxes will only be checked for updates when the user runs # `vagrant box outdated`. This is not recommended. # config.vm.box_check_update = false # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine. In the example below, # accessing \"localhost:8080\" will access port 80 on the guest machine. # NOTE: This will enable public access to the opened port # config.vm.network \"forwarded_port\", guest: 80, host: 8080 # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine and only allow access # via 127.0.0.1 to disable public access #config.vm.network \"forwarded_port\", guest: 80, host: 8080, host_ip: \"127.0.0.1\" # Create a private network, which allows host-only access to the machine # using a specific IP. #config.vm.network \"private_network\", ip: \"192.168.55.10\" # Create a public network, which generally matched to bridged network. # Bridged networks make the machine appear as another physical device on # your network. # config.vm.network \"public_network\" config.ssh.forward_agent = true config.ssh.forward_x11 = true # Share an additional folder to the guest VM. The first argument is # the path on the host to the actual folder. The second argument is # the path on the guest to mount the folder. And the optional third # argument is a set of non-required options. # config.vm.synced_folder \"./go/src\", \"/home/vagrant/go/src\" # Provider-specific configuration so you can fine-tune various # backing providers for Vagrant. These expose provider-specific options. # Example for VirtualBox: # # config.vm.provider \"virtualbox\" do |vb| # Display the VirtualBox GUI when booting the machine #vb.gui = true # Customize the amount of memory on the VM: #vb.memory = \"1024\" # end # # View the documentation for the provider you are using for more # information on available options. # Enable provisioning with a shell script. Additional provisioners such as # Puppet, Chef, Ansible, Salt, and Docker are also available. Please see the # documentation for more information about their specific syntax and use. config.vm.provision \"shell\", inline: <<-SHELL rm -fv /etc/ssh/ssh_host_* dpkg-reconfigure openssh-server apt-get update SHELLend", "https://browncsci1290.github.io/webpage/": "This website requires JavaScript to function. const searchParams = new URLSearchParams(window.location.search); const isDevMode = searchParams.has(\"dev\"); // Set this to true to 'fake' pages vs. one big page // i.e., each section of content will appear in a // smaller div and the rest will be removed. // paginate = true was preferred by Prof. Srinath // paginate = false was preferred by Prof. Tompkin for easier CTRL-F // // Spring 2023: James turned this from content being split across real HTML pages to be making <div>s visible/invisible. This let us dynamically paginate without rearranging the actual files to stop from having to swap around the filesystem each time. // const paginate = false; const options = { contentContainer: \"main\", //includeToc: false, includeCss: false, show: !paginate, // Only show other pages if we aren't paginating }; const optionsHome = { contentContainer: \"main\", //includeToc: false, includeCss: false, show: true, }; const contents = [ { path : \"./content/home.md\", divID : \"home-content\", name : \"Home\", options : optionsHome, }, { path : \"./content/schedule.md\", divID : \"schedule-content\", name : \"Schedule\", options : options, }, { path : \"./content/officehours.md\", divID : \"officehours-content\", name : \"Office Hours\", options : options, }, { path : \"./content/assignments.md\", divID : \"assignments-content\", name : \"Assignments\", options : options, }, { path : \"./content/policies.md\", divID : \"policies-content\", name : \"Policies\", options : options, }, { path : \"./content/team.md\", divID : \"team-content\", name : \"Team\", options : options, } ] function setThemeBannerImages() { var db = document.getElementById(\"desktop-banner\") db.src = theme.bannerImageDesktop db.alt = theme.bannerImageAlt var mb = document.getElementById(\"mobile-banner\") mb.src = theme.bannerImageMobile mb.alt = theme.bannerImageAlt } function showItem( contentsItem ) { if( paginate ) { // On click, hide all the other content divs except the one selected to show. contents.forEach( function(item) { document.getElementById( item.divID ).style.display = 'none'; }) document.getElementById( contentsItem.divID ).style.display = 'block'; } } promises = []; contents.forEach( function(item, index) { listItemLink = document.createElement('a') listItemLink.classList.add(\"nav-link\") listItemLink.href = \"#\" + item.divID // // Future TAs: James would prefer you didn't, but if you would like actual HTML pages, // then make some new HTML pages to contain each .md file and link them here. e.g., //listItemLink.href = \"./policies/index.html\" listItemLink.textContent = item.name listItem = document.createElement('li') listItem.classList.add(\"nav-item\") listItem.appendChild( listItemLink ) listItemLink.addEventListener( 'click', function(event) { showItem( item ); }) document.getElementById(\"navbar-ul\").appendChild( listItem ) }) // Add markdown content promises.push( markdown2html( contents ) ); Promise.all(promises).then((responses) => { for (const response of responses) { // Do something with each one as needed } setThemeBannerImages() renderStaffCards() // Turn fake pagination on/off hashString = document.location.hash.substring(1) hashItem = contents.filter(x => x.divID == hashString ) if( hashItem[0] != undefined ) showItem( hashItem[0] ) }) // Enable section highlighting in navbar as user scrolls on page $(\"body\").scrollspy({ target: \"#navbar\", offset: 60 });", "https://cs.brown.edu/courses/csci1310/2020/notes/l02.html": "CS 131 : Fundamentals of Computer Systems Home Schedule Assignments Project 1: Strings & Vectors Project 2: DMalloc Project 3: WeensyOS Project 4: Vunmo Project 5: Distributed Store Lab 0: Getting Set Up Lab 1: C Programs Lab 2: Building Programs Lab 3: Assembly Lab 4: Caching Lab 5: Intro to WeensyOS Lab 6: Processes Lab 7: Threads Lab 8: RPCs Final Quiz Resources COVID-19: virtualizing CS131 C/C++ Primers Textbooks Course outline Why take CS131? FAQs Exercises: Computer Systems Basics Exercises: Operating Systems Exercises: Concurrency Exercises: Distributed Systems Anonymous feedback Staff Office Hours Spring 2020 hljs.initHighlightingOnLoad(); Lecture 2: Systems Programming \u00bb Lecture video (Brown ID required) \u00bb Lecture code \u00bb Post-Lecture Quiz (due 6pm Wednesday, January 29). Context: The CS131 Journey After the first lecture, you may have wondered why understanding the details of how your computer works is so crucial.How does this understanding affect your goals, such as becoming a software engineer in industry or an academic computerscience researcher? The answer is, beyond a natural thirst for knowledge, that this kind of understanding will make you amuch better, more versatile, and more valuable computer scientist and engineer. Some reasons why systems programming and understanding the machine matters: There are billions of lines of C and C++ code in the world. If you work as a software engineer, you will sooner or later have to deal with these languages. For example, operating systems, web browsers, machine learning toolkits like TensorFlow and PyTorch, and high-performance infrastructure used by companies like Facebook and Google are written in C++. Many companies yearn to hire engineers who know these languages! The concepts we're learning here are fundamental and ultimately impact how other languages work. Even if you're programming in Go or Java, you will understand these languages a lot better if you know the underlying infrastructure. When you work with concurrent and distributed systems (which most moderately complex applications we use today, including nearly all applications on your phone, are!), mysterious bugs and seemingly impossible behavior will make a lot more sense (and be easier to debug!) if you know how the computer actually executes these programs. So, what will you learn throughout this course? Here's an overview. You will learn the C and C++ programming languages , and you'll be able to use standard debugging tools (gdb, address sanitizers, build systems, and performance profilers) that are widely-used in industry . You will write a crucial part of your own operating system , and you'll see it safely run multiple programs side by side. You will implement the server-side backend of a high-throughput micropayment application , learning how to handle many user requests in parallel without accidentally corrupting someone's balance. The concepts you learn are the core of every database and web application we use today. Finally, you will implement a scalable distributed storage system, similar to systems used at Google and make it react to changes in incoming request load by adapting itself! Interpreting Bytes In Memory Why are we covering this? The only place where a computer can store information is memory. It's up to the systems software and the programs that thecomputer runs to decide what these bytes actually mean . They could be program code, data (integers, strings,images, etc.), or \"meta-data\" used to build more complex data structures from simple memory boxes. Understandinghow complex programs boil down to bytes will help you debug your program, and will make you appreciate why they behave theway they do. Let's recap the final example from last lecture. We used bytes from the course logo image file to add numbers, and otherbytes to print messages to the terminal. How is that possible? At the end of this section, you'll understand how. We will build this up from first principles. Start with add.c , which is a C program that serves a simplepurpose: it reads numbers from the command line and adds them. Let's disect the code, and you'll get immersed in the basicstructure of a C program, as well as seeing the crucial add() function that we'll use to explore how programsare just bytes in memory. A Simple C Program C Programming Resources We'll go through the basics of C (and later C++) in lectures, but in an \"immersive\" way: we'll come acrosslanguage features are we are trying to understand fundamental concepts of systems. Check out our C/C++ Primers if you're looking for step-by-step language tutorials or links todetailed language references. #include <stdio.h> // <== import standard I/O (fprintf, printf)#include <stdlib.h> // <== import standard libraryint main(int argc, char* argv[]) { // <== starting point of our program if (argc <= 2) { fprintf(stderr, \"Usage: add A B\\n\\ Prints A + B.\\n\"); // <== print error message if arguments are missing. \"\\n\" is a newline character! exit(1); } int a = strtol(argv[1], 0, 0); // <== covert first argument (string) to integer int b = strtol(argv[2], 0, 0); // <== same for second argument printf(\"%d + %d = %d\\n\", a, b, add(a, b)); // <== invoke add() function, print result to console} What's going on here? Every C program's execution starts with the main() function. This is one of thethings that the C language standard, a long, technical document, prescribes. Our program checks if the user providedenough arguments and prints an error if not; otherwise it converts the first two arguments from strings to integersusing strtol() (a standard library function), calls add() on them and returns the results. How do the argc and argv arguments to main() get set, and how is main() called? Your computer's operating system (OS) is responsible for starting up the program, and does some prep. The command lineprogram you're using (this is called a \"shell\") makes sure to put the argument count ( argc ) andargument values in boxes at well-known memory addresses before the OS starts your program. Let's try to compile this program. $ gcc -o add add.c There's an error, because we haven't actually provided an add() function. Let's write one. The program now works, and it adds numbers. Yay! But we can also define our add function in another file \u2013something that often happens in larger programs. Let's use the add function in addf.c instead.Since the compiler looks at each source file in isolation, we now need to tell it that there is an add functionin some other file, and what arguments it takes. Let's add a line to add.c that specifies the nameand arguments of add() , but does not provide an implementation. This is called a declaration :we're telling the compiler \"there will be a function called add() , and you'll find out about itsimplementation later\". All functions and variables in C have to be declared when you first use them, but theydo not have to be defined . We'll understand the exact difference shortly. Let's try compiling this version of add.c . A different error! Why? Because we haven't told thecompiler to also look at the addf.c file, which actually has our implementation of add() .To do that, let's pass two files to the compiler. $ gcc -o add add.c addf.c It works! Great. The compiler first compiles add.c into a file called add.o , and thencompiles addf.c into a file called addf.o . These files don't contain human-readable text,but binary bytes that the computer's CPU (central processing unit) understands to execute. Programs are just bytes! We can look at the contents of addf.o using a tool called objdump . objdump -daddf.o prints two things below the <add> line: on the left, the bytes in the file inhexadecimal notation ( 8d 04 37 c3 ), and on the right, a human-readable version of what these bytesmean in computer machine language (specifically, in a language called \"x86-64 assembly\", which is thelanguage my laptop's Intel processor understands). addf.o: file format elf64-x86-64Disassembly of section .text:0000000000000000 : 0:8d 04 37 lea (%rdi,%rsi,1),%eax 3:c3 retq ^ ^ | bytes in file | their human-readable meaning in x86-64 machine language | in hexadecimal | (not stored in the file; objdump generated this) | notation What does the machine language mean? We don't know machine language yet, and though we will touch on it briefly later in the course, you'll neverneed to memorize it. But to give you an intution, lea means to add integers, and retq tells the processor to return to the calling function. Let's focus on the bytes. When the program runs, these bytes are stored somewhere in memory. The processor,which on its own is just a dumb piece of silicon, then reads these bytes and interprets them as instructions as to what to do next. Now let's change our implementation in addf.c and just store the same bytes directly: const unsigned char add[] = { 0x8d, 0x04, 0x37, 0xc3 }; We're no longer writing a function in the C programming language, we're just defining an array of bytescalled add . Do you think our add program will still work? It turns out it does work! Why? Because we are manually storing the exact same bytes in memory thatthe compiler generates when compiling our add function into machine instructions. The processor doesn'tcare that we were storing an array of data there \u2013 if we tell it to go an execute these bytes, the dumb silicongoes and does as it's told! Now we can figure out how we could add numbers using the course logo: our crucial bytes, 8d 04 37 c3 occur inside the JPEG file of the course logo. If we just tell the processor to look in the rightplace, it can execute these bytes. To do that, I use the addin.c program, which asks the operatingsystem to load the file specified in its first argument into memory, and then tells the processor to look forbytes to execute at the offset specified as the second argument. If we put the right offset ( 10302 decimal), the processor executes 8d 04 37 c3 and adds numbers! The image decoder, meanwhile, justinterprets these bytes (which I changed manually) as data and turns them into slightly discolouredpixels. What about the party emoji code? That secret was revealed in the lecture :-) Exploring Data Representation In Memory Now that we understand how programs are just bytes in memory, let's look in more detail at how data isrepresented in memory. Why are we covering this? We're now building an understanding of where the different parts of a C/C++ program (and, in fact, programs in otherlanguages too!) are stored in memory. This will help you understand how a program obtains and manages memory,something that some programming languages (e.g., Java, OCaml, Pyret) do automatically behind your back, while others,and particularly systems programming languages like C and C++, force you as the programmer do some of this memorymanagement. This gives you a great degree of control, and allows avoiding expensive hidden memory allocation andcopying costs. For, we will use the program mexplore.c . This program declares and defines (recall the difference!)three variables, all of type char . char is the name for a byte type in the C language; itrefers to the fact that a byte is exactly sufficient to store one character according to the ASCII standard, a wayof translating numbers into characters and vice versa. Computers can only store numbers, so all characters in acomputer are actually \"encoded\" as numbers. For example, the uppercase letter \"A\" in ASCII corresponds tothe number 65 (see man ascii for the translation table). What's ASCII, and do we still use it today? In the early days of computers, every computer had its own way of encoding letters as numbers. ASCII, theAmerican Standard Code for Information Interchange, was defined in the 1960s to find a common way of representingtext. Original ASCII uses 7 bits, and can therefore represent 128 distinct characters \u2013 enough for the alphabet,numbers, and some funky special characters (e.g., newlines ( \\n ), the NUL character ( \\0 ),and \"bell\" character that made typewriter bells go off). But even 256 characters aren't sufficient to support languages that use non-Latin alphabets, and certainly notfor advanced emoji. So, while all of today's computers still support ASCII, we've mostly moved on to a new standard, Unicode , which supports 1.1 million characters using one to four bytes per character. Fun fact: to be backwardscompatible, Unicode is defined such that the original ASCII character encodings remain valid Unicode letters. What's the difference between these three char variables? Let's take a look. The first one, global_ch is defined in what we call global scope : it's at the top level of the file, not insidea function or inside the curly braces ( { } ) that C and C++ use to delineate scopes in the program. Thisvariable can be referred to from anywhere in the entire program. The second variable, const_global_ch is also a global variable, but the const keywordindicates that it is constant and the compiler and OS should not allow modifications to it. Finally, our third variable is inside function f() . It's called local_ch and is a localvariable . It's valid only within the scope of f() and other parts of the program (such as main ) cannot refer to it. The hexdump() function that f() calls is defined in hexdump.c and imported via hexdump.h , a \"header file\". (In a future lecture, we'll talk about why header files exist.) hexdump(ADDR, N) has the effect of printing the contents of N bytes of memory at address ADDR . We're passing our character variables to it, but prefix the variable with an ampersand character, & . So: hexdump(&global_ch, 1) means \"print 1 byte from a box located at theaddress of global_ch \". This is an important concept of the C language: you can always get the memory address at which an object islocated. The term \"object\" here means something different from what it means in an object-oriented languagelike Java: rather than an instance of a class, an \"object\" according to the C standard is a set of bytes thatcontain a value. This can be code (a function) or data (a variable). In other words, local and ptr in the snippet below refer to the same object, i.e., tothe same bytes of memory : void f() { int local = 1; int* ptr = &local;} &local means \"the address of local \", and the value stored in the memory locationwhere ptr is located is the 8 bytes that make up the address of local . The type of ptr is int* , which signifies that it is the address of an integer in memory (a short* wouldbe the address of a short , a char* the address of a char , etc.). You can invert the ampersand operator using the asterisk ( * ) operator: *ptr dereferences the pointer and turns the address back into a value. In other words, *&local is the same as plain, old local . Thee concepts are very, very important \u2013 you'll use them all the time! Back to our mexplore.c program though. Let's look at what it prints when we run it (note that thespecific addresses will be different on your computer). $ ./mexplore00601038 41 |A|004009a4 42 |B|7ffd4977e80f 43 |C| On the left, we see the addresses of our three variables, printed in hexadecimal notation. Next, just to the rightof that, we see the hexadecimal value of the data stored in the byte at each of these addresses. For example,hexadecimal 41 (often written 0x41 for clarity) is equal to ... 16*4 + 1 = 65! Not surprisingly, thisequals to the ASCII character \"A\", which we see on the right. But let me draw your attention to the addresses on the left. They vary a fair amount! The exact locations of variablesin memory are decided by the compiler and OS together, but the general region where an object lives is determined by its lifetime . Think about how long each of our variables needs to stick around before the memory can be reused: The global variables, global_ch and const_global_ch , need to be around for the entire runtime of the program, as the program could reference them anywhere in the code. This is called a static lifetime . The local variable, local_ch , needs to stick around until it goes out of scope, which happens when the execution reaches the closing curly brace of f() . After it's out of scope, no code in the program can refer to the variable, so it is fine to reuse its memory. This is called an automatic lifetime . Local variables and function arguments have automatic lifetimes. But what if a function needs to create an object whose size is not known at the start of the program (so it can't beglobal) and which also needs to survive beyond the end of the function? In this common situation, neither a staticlifetime nor an automatic lifetime are appropriate. Dynamically Allocated Objects We did not have much time to cover dynamic lifetimes and memory allocation in today's lecture; we'll go over itagain on Thursday. The material below is for reference, in case you want to read ahead. The C language allows for a third kind of object lifetime: a dynamic lifetime . For an object with a dynamiclifetime, you as the programmer have to explicitly create and destroy the object \u2013 that is, you must set asidememory for the object and make sure it is released again when the object is no longer needed. To set aside memory, you use the malloc() standard library function ( m emory alloc ate). malloc() takes only one argument, which is the number of bytes you're asking for, and it returns a pointerto the newly allocated memory (i.e., the address where the OS has set aside memory boxes for this object). For example, char* allocated_ch = (char*)malloc(1); reserves 1 byte of memory and stores the address of that memory in the variable allocated_ch . The char* in brackets is a cast of the pointer returned to the type we expect (a pointer to a char ); this is needed because malloc() itself does not have any idea what kind of objectyou're allocating, so we need to tell the compiler. Similarities and differences with Java Calls to malloc() may look clunky, but they effectively do the same thing as the new keyword in Java: setting aside memory for a new object. Indeed, C++ actually provides a new keywordthat, under the hood, invokes malloc() . One big difference compared to Java, however, is that you'reresponsible for cleaning up and returning that memory. Java figures out automatically when an object with a dynamiclifetime is no longer needed, and frees the memory then (a process called \"garbage collection\"). C andC++ don't do so, but leave it to the programmer to decide when the time is right to return the memory. The big upside of dynamic-lifetime objects is that we can decide at runtime how big they need to be, and that theycan outlive the function that creates them. Consider a string that takes the characters a user typed into the program\u2013 a quantity that's hard to predict correctly, and data that we certainly want to outlive the function that readsthe input! The big downside of dynamic-lifetime objects is that it's the programmer's responsibility to free the memoryallocated. You to this by calling the free() function with the address of the allocated boxes as anargument. For example, free(allocated_ch); will free the memory we asked malloc() toset aside for allocated_ch . Incorrect use of dynamic lifetimes is an immensely common source of problems, bugs, and securityholes in C/C++ programs: serious problems like memory leaks, double free, use-after-free, etc. all arise from thislanguage feature. Memory Segments Objects with different lifetimes are grouped into different regions in memory. The program code, global variables, andconstant global variables are all stored in static segments, as these all have static lifetimes and known sizesat compile time. Other objects are come and go, and therefore the memory regions that contain them grow and shrink. For example, asfunctions call each other, they create more and more local variables with automatic lifetimes; and as the program calls malloc() to reserve memory for objects with dynamic lifetimes, more memory is needed for these objects. If we look at the addresses printed by mexplore , we see that the global variables stored in are atrelatively low memory addresses (around 0x60'0000 hexadecimal and 0x40'0000 hexadecimal), whilethe local variable is stored at a high address, close to 0x7fff'ffff'ffff (about 2 47 ), andthe dynamically allocated character is stored in between (albeit closer to the static segments). There is a reason for this placement: it allows both types of segments to grow without risk of getting in each other'sway. In particular, the automatic-lifetime segment grows downwards as more local variables come intoscope, while the dynamic-lifetime segment grows upwards . If they ever meet, your computer runs out of memory. Finally, these segments have names: The part of the static-lifetime segment that holds program called is called the \"text segment\" (because it holds program text; though the \"text\" is in computer language); the parts for read-only globals ( \"rodata\" ) and modifyable globals ( \"data\" and \"bss\" ) also have names. The automatic-lifetime segment is called the stack . It's named so because it grows and shrinks like a stack of paper: when you call a function, its automatic-lifetime objects are added to the left of the existing automatic ones, and when the function returns, the program gives their memory up again. The dynamic-lifetime segment is called the heap , and it generally grows upwards in terms of memory addresses. But unlike the stack, it can have \"holes\": if the programmer destroyed an object that sits in between two others in memory, there is unused memory in between. (You can think of this as \"air gaps\" in a heap of things, maybe!). The stack and heap terms are important, and you will keep seeing them! Java Similarities Note In Java, any object created with the new keyword is allocated with dynamic lifetime and lives on the heap.(Java puts only \"primitive\" types ( int , double etc.) on the stack.)Indeed, Java under the hood uses malloc() ! Yet, it seems likeJava has automatic lifetime for all objects, as you never need to destroy them explicitly! This works because your programruns inside the Java virtual machine (JVM), which \"magically\" injects code that tracks whether each object isstill reachable via an in-scope variable; if this reference count goes to zero, the JVM automatically calls free() to delete the object. But all this magic is not free in performance terms, as there is code to run tokeep track of objects' reference counts. C and C++ instead opt to do nothing and give maximum control to the programmer,for better or worse. Summary Today, we've seen more of a computer's memory bytes can be interpreted to represent many different kinds of data. For example,the same bytes can be interpreted as program code or as an image's pixels, and a sequence of bytes can represent characters of astring or a large number. We've also seen why addresses are incredibly important: C and C++ locate data and functions in memoryby their address. We learned some basic C syntax, and built an understanding of how a program's memory is split into differentsegments that contain objects with different lifetimes.We will talk more about dynamic lifetimes, strings, and sequences of objects in memory next time! window.jQuery || document.write('<script src=\"../js/jquery-slim.min.js\"><\\/script>') (function () { jQuery.fn.extend({ geometry: function (outer) { var x; if (this[0] == window) x = {left: this.scrollLeft(), top: this.scrollTop()}; else x = this.offset(); if (x) { x.width = outer ? this.outerWidth() : this.width(); x.height = outer ? this.outerHeight() : this.height(); x.right = x.left + x.width; x.bottom = x.top + x.height; } return x; } }); function sol_toggle(hide, storage) { this.childNodes[0].classList.toggle(\"hidden\", !hide); this.childNodes[0].classList.toggle(\"shown\", hide); this.childNodes[1].classList.toggle(\"hidden\", hide); this.childNodes[1].classList.toggle(\"shown\", !hide); if (storage) { var key = location.href + \" \" + $(\".has-solution\").index(this); if (hide) sessionStorage.removeItem(key); else sessionStorage.setItem(key, true); } } $(\".solution\").each(function () { $(this).wrap('<div class=\"has-solution\"></div>'); var sol = this.parentElement; $(sol).prepend('<blockquote class=\"solution-collapsed js-solution show\"><a href=\"\" class=\"js-solution show\"></a></blockquote>'); $(this).append('<p><a href=\"\" class=\"js-solution hide\"></a></p>'); $(sol).find(\"a.js-solution.show\").text(this.getAttribute(\"data-show-text\") || \"Show solution\"); $(sol).find(\"a.js-solution.hide\").text(this.getAttribute(\"data-hide-text\") || \"Hide solution\"); var key = location.href + \" \" + $(\".has-solution\").index(sol); if (sessionStorage.getItem(key)) sol_toggle.call(sol, false, false); }); $(document).on(\"click\", \".js-solution\", function (event) { if (this.classList.contains(\"all\")) { var hide = this.classList.contains(\"hide\"); $(\".has-solution\").each(function () { sol_toggle.call(this, hide, false); }); var bq = this.tagName === \"BLOCKQUOTE\" ? this : this.parentElement; $(bq).find(\".show\").toggleClass(\"hidden\", !hide); $(bq).find(\".hide\").toggleClass(\"hidden\", hide); } else { var sol = $(this).closest(\".has-solution\")[0]; sol_toggle.call(sol, this.classList.contains(\"hide\"), true); } event.preventDefault(); event.stopPropagation(); }); })()", "https://cs.brown.edu/courses/csci1310/2020/notes/l07.html": "CS 131 : Fundamentals of Computer Systems Home Schedule Assignments Project 1: Strings & Vectors Project 2: DMalloc Project 3: WeensyOS Project 4: Vunmo Project 5: Distributed Store Lab 0: Getting Set Up Lab 1: C Programs Lab 2: Building Programs Lab 3: Assembly Lab 4: Caching Lab 5: Intro to WeensyOS Lab 6: Processes Lab 7: Threads Lab 8: RPCs Final Quiz Resources COVID-19: virtualizing CS131 C/C++ Primers Textbooks Course outline Why take CS131? FAQs Exercises: Computer Systems Basics Exercises: Operating Systems Exercises: Concurrency Exercises: Distributed Systems Anonymous feedback Staff Office Hours Spring 2020 hljs.initHighlightingOnLoad(); Lecture 7: Assembly Language \u00bb Lecture video (Brown ID required) \u00bb Lecture code \u00bb Post-Lecture Quiz (due 6pm Wednesday, February 19). Assembly Language We've now arrived at the end of our introduction to C programming. The rest of the course will mostly look athigher-level concepts built atop the understanding we have developed. But before the look at higher levels, we willbriefly pull back the covers and see what happens at the level below C to make your programs run. | Web sites, Google, Facebook, AirBnB, etc.--- |------------------------------------------- | Distributed systems <-- block 4 C |------------------------- S | Parallel programming <-- block 3 |------------------------- 1 | C++ | Operating systems <-- block 2 3 |------------------------- 1 | C programming language <-- we discussed this so far |------------------------- | Assembly language <-- we will briefly cover this--- |------------------------------------------- | Hardware (chips) Now that you understand the C language and memory representations of data, you may wonder about the \"magic\"hexadecimal bytes that the compiler outputs to make your computer's processor do things like adding numbers. How does thecompiler choose these bytes, and what bytes are valid? Each computer architecture (such as x86-64, which most modern computers use and we're considering in this course) hasan instruction set specified by the manufacturer. The instruction set, first and foremost, defines what sequencesof bytes trigger specific behavior in the processor (e.g., adding numbers, comparing them for equality, or loading datafrom memory). But hexadecimal bytes are hard for humans to read, so the instruction set also comes with a human-readable assembly language that consists of short, mnemonic instructions that correspond directly to a byte encoding (i.e.,each of these instructions corresponds to a specific, unique set of hexadecimal bytes). Why are we covering this? You will almost certainly never need to write code in assembly language yourself, but it is helpful to haveat least some intuition of how to read it. Being able to read assembly helps you debug weird problems with yourprogram, and can help you understand compiler optimizations betters. Some of the examples we look at will also illustrateto you the tricks used to make computers run our code efficiently. If you're curious to learn more details about assembly, consider taking CSCI 0330, which explains it in more detail andwith more hands-on exercises than we'll have time for! From C code to instructions Let's take a look at how your C program get turned into hexadecimal bytes that can run on your processor. The compiler , which we've discussed a lot already, turns your C program into assembly language. Lots ofcleverness and optimizations. The assembler turns assembly language into a set of bytes in an executable. This a very direct translation. Registers Assembly instructions operate on registers , small pieces of very fast memory inside the processor. To processdata stored in memory, the processor first needs to load it into registers; and once it has completed working on thedata in a register, it needs to store it back to memory. Registers are the fastest kind of memory available in the machine. x86-64 has 14 general-purpose registers and severalspecial-purpose registers. The table below lists all basic registers, with special-purpose registers highlighted inyellow. You won't understand all columns yet, but you will soon and can then use this table as a reference (we won't askyou to memorize it in detail). You'll notice different naming conventions for subsets of the same register, a side effectof the long history of the x86 architecture (the first x86 processor, the 8086 was first released in 1978). Full register name 32-bit (bits 0\u201331) 16-bit (bits 0\u201315) 8-bit low (bits 0\u20137) 8-bit high (bits 8\u201315) Use in calling convention Callee-saved? General-purpose registers: %rax %eax %ax %al %ah Return value (accumulator) No %rbx %ebx %bx %bl %bh \u2013 Yes %rcx %ecx %cx %cl %ch 4th function argument No %rdx %edx %dx %dl %dh 3rd function argument No %rsi %esi %si %sil \u2013 2nd function argument No %rdi %edi %di %dil \u2013 1st function argument No %r8 %r8d %r8w %r8b \u2013 5th function argument No %r9 %r9d %r9w %r9b \u2013 6th function argument No %r10 %r10d %r10w %r10b \u2013 \u2013 No %r11 %r11d %r11w %r11b \u2013 \u2013 No %r12 %r12d %r12w %r12b \u2013 \u2013 Yes %r13 %r13d %r13w %r13b \u2013 \u2013 Yes %r14 %r14d %r14w %r14b \u2013 \u2013 Yes %r15 %r15d %r15w %r15b \u2013 \u2013 Yes Special-purpose registers: %rsp %esp %sp %spl \u2013 Stack pointer Yes %rbp %ebp %bp %bpl \u2013 Base pointer (general-purpose in some compiler modes) Yes %rip %eip %ip \u2013 \u2013 Instruction pointer (Program counter; called $pc in GDB) * %rflags %eflags %flags \u2013 \u2013 Flags and condition codes No Note that unlike primary memory (RAM) \u2013 which is what we think of when we discuss memory in a C/C++ program\u2013 registers have no addresses! There is no address value that, if cast to a pointer and dereferenced, wouldreturn the contents of the %rax register. Registers live in a separate world from the memory, and we needspecial instructions to move data to and from registers and memory. Whenever you see %ZZZ in assembly code, this refers to a register named ZZZ . The x86-64registers have confusing names because they evolved over time; each register also has multiple names thatrefer to different subsets of its bits. For example %rax , one of the general-purpose registers that is,by convention, used to pass return values from functions, is split into the following five names: 63 31 15 7 0 +-------------------------------+-------------------------------+ | | | | | +---------------------------------------------------------------+ |---------------------%rax (64 bits/8 bytes)--------------------| |-----%eax (32 bits/4 bytes)----| |-%ax (16b/2B)--| |--%ah--|--%al--| <-- 8 bits/1 byte each Assembly instructions often have a suffix that indicates what input data size and register width they'reoperating on. For instance, a set of \"move\" instructions help load signed and unsigned 8-, 16-, and 32-bitquantities from memory into registers. movzbl , for example, moves an 8-bit quantity (a b yte) into32-bit register (a l ongword; e.g., %eax ) with zero extension; movslq moves a 32-bitquantity ( l ongword) into a 64-bit register ( q uadword; e.g., %rax ) with sign extension. What's up with long suddenly meaning 32-bits (4 bytes)? Because of wonderful history of the x86 architecture, and to confuse you, a \"long\" in x86-64 hardwareterms does not refer to the same things as a long integer type in C. Specifically, a x86-64assembly long is 4 bytes, so it corresponds to a C int . The 8-byte long (or indeed any pointer type)in C uses \"quad\" instructions in x86-64 assembly, denoted by a q suffix. Note that what looks like types (such as long , short , etc.) here merely refers to theregister width used in the instruction. All actual types are removed from the program during compilation; thereare no types in assembly (for examples, see asm06.s and asm07.s and their correspondingC source files in the lecture code). Instructions There are three basic kinds of assembly instructions: Computation: These instructions computate on values, typically values stored in registers. Most have zero or one source operands and one source/destination operand, with the source operand coming first. For example, the instruction addq %rax, %rbx performs the computation %rbx := %rbx + %rax . Data movement: These instructions move data between registers and memory \u2013 so they can move values from one register to another, from memory into a register, and from a register back to memory. Almost all move instructions have one source operand and one destination operand; the source operand comes first. For example, movq %rax, %rbx copies the contents of %rax into %rbx , so it performs the assignment %rbx = %rax . Control flow: Normally the CPU executes instructions in sequence and in the order they appear in the assembly code (and, once translated into bytes, the order in memory). Control flow instructions change the next instruction the processor executes (something called the \"instruction pointer\", and stored in special register %rip ). There are unconditional branches (the instruction pointer is set to a new value), conditional branches (the instruction pointer is set to a new value if a condition is true), and function call and return instructions. Some instructions appear to combine computation and data movement. For example, given the C code int* pi; ...++(*pi); the compiler might generate incl (%rax) rather than movl (%rax), %ebx; incl %ebx;movl %ebx, (%rax) . However, the processor actually divides these complex instructions into tiny, simpler,invisible instructions called microcode , because the simpler instructions can be made to execute faster.The complex incl instruction actually runs in three phases: data movement, then computation, then datamovement. This matters when we introduce parallelism. Different assembly syntaxes There are actually multiple ways of writing x86-64 assembly. We use the \"AT&T syntax\", which isdistinguished from the \"Intel syntax\" by several features, but especially by the use of percent signs forregisters. Sadly, and just to make things more confusing, the Intel syntax puts destination registers before sourceregisters. How to read an assembly file Assembly files (and assembly layout in GDB, layout asm ) can be confusing at first. The importanttricks to reading them are the following: Focus only on the instructions that you care about, and initially ignore anything else. Work backwards from the return statement. Here's an example assembly file (output from gcc -S testasm.c ) to consider: .file \"testasm.c\" .text .globl _Z1fiii .type _Z1fiii, @function_Z1fiii:.LFB0: cmpl %edx, %esi je .L3 movl %esi, %eax ret.L3: movl %edi, %eax ret.LFE0: .size _Z1fiii, .-_Z1fiii .ident \"GCC: (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\" .section .note.GNU-stack,\"\",@progbits There are many lines here that are effectively comments. All lines starting with a dot (e.g., .file or .ident ) are of this kind: they constitute \"directives\", rather thaninstructions. Some directives tell the assembler what to do, but they're often unimportant to your understanding.All directive lines that end in a colon, however, are important: they constitute labels , which matter forcontrol flow instructions (e.g., .L3: ). The actual instructions are on the indented lines between the labels. The processor will execute these top tobottom unless it's told to continue somewhere other than the next instruction by a control flow instruction (e.g., je ). A good way to figure out the important parts of the instructions is often to work backwards fromthe ret instructions, which is the function's return point. Why do we work backwards? Going forwardis more difficult because it requires understanding what the state of the processor's register is when we call thefunction (something not explicitly described in the file here). By working backwards from the return, we can oftenfigure out what the function does without knowing its inputs. Sometimes, we are also interested in looking at the assembly in an already-compiled object file \u2013 i.e.,binary code after the translation from human-readable assembly language to bytes. This is called\"disassembling\" from executable instructions, and happens when we look at assembly using GDB, objdump -d , or objdump -S . This output looks different from compiler-generated assembly:in disassembled instructions, there are no intermediate labels or directives. This is because the labels anddirectives disappear during the process of generating executable instructions. Here's the disassembly of our function above, coming from an object file (e.g. testasm.o ): And a disassembly of the same function, from an object file:0000000000000000 <_Z1fiii>: 0: 39 d6 cmp %edx,%esi 2: 74 03 je 7 <_Z1fiii+0x7> 4: 89 f0 mov %esi,%eax 6: c3 retq 7: 89 f8 mov %edi,%eax 9: c3 retq Everything but the instructions is removed, and the helpful .L3 label has been replaced with anactual address. The function appears to be located at address 0. This is just a placeholder; the final address isassigned by the linking process, when a final executable is created. Finally, here is some disassembly from that actual executable: 0000000000400517 <_Z1fiii>: 400517: 39 d6 cmp %edx,%esi 400519: 74 03 je 40051e <_Z1fiii+0x7> 40051b: 89 f0 mov %esi,%eax 40051d: c3 retq 40051e: 89 f8 mov %edi,%eax 400520: c3 retq The instructions are the same, but the addresses are different. (Other compiler flags would generate differentaddresses.) Summary Today, we looked at how the computer operates at the level just below C code: it executes a sequence of assemblyinstructions, which are small operations that translate into operations of the processor's circuits. Assembly is hard towrite, but it is useful to be able to read it somewhat intuitively. We saw that in assembly, there are computation, data movement, and control flow instructions, and that the compileroften produces somewhat unexpected instruction sequences to make things faster. This is part of why we use compilers:they are incredibly smart at distilling our programs down into the fastest possible sequence of instructions. Next time, we will look at how function calls work and how the assembly instructions actually manage the automaticlifetime memory in the stack segment. After that, we will leave the low-level world of assembly and start moving upthe systems stack (no pun in intended)! window.jQuery || document.write('<script src=\"../js/jquery-slim.min.js\"><\\/script>') (function () { jQuery.fn.extend({ geometry: function (outer) { var x; if (this[0] == window) x = {left: this.scrollLeft(), top: this.scrollTop()}; else x = this.offset(); if (x) { x.width = outer ? this.outerWidth() : this.width(); x.height = outer ? this.outerHeight() : this.height(); x.right = x.left + x.width; x.bottom = x.top + x.height; } return x; } }); function sol_toggle(hide, storage) { this.childNodes[0].classList.toggle(\"hidden\", !hide); this.childNodes[0].classList.toggle(\"shown\", hide); this.childNodes[1].classList.toggle(\"hidden\", hide); this.childNodes[1].classList.toggle(\"shown\", !hide); if (storage) { var key = location.href + \" \" + $(\".has-solution\").index(this); if (hide) sessionStorage.removeItem(key); else sessionStorage.setItem(key, true); } } $(\".solution\").each(function () { $(this).wrap('<div class=\"has-solution\"></div>'); var sol = this.parentElement; $(sol).prepend('<blockquote class=\"solution-collapsed js-solution show\"><a href=\"\" class=\"js-solution show\"></a></blockquote>'); $(this).append('<p><a href=\"\" class=\"js-solution hide\"></a></p>'); $(sol).find(\"a.js-solution.show\").text(this.getAttribute(\"data-show-text\") || \"Show solution\"); $(sol).find(\"a.js-solution.hide\").text(this.getAttribute(\"data-hide-text\") || \"Hide solution\"); var key = location.href + \" \" + $(\".has-solution\").index(sol); if (sessionStorage.getItem(key)) sol_toggle.call(sol, false, false); }); $(document).on(\"click\", \".js-solution\", function (event) { if (this.classList.contains(\"all\")) { var hide = this.classList.contains(\"hide\"); $(\".has-solution\").each(function () { sol_toggle.call(this, hide, false); }); var bq = this.tagName === \"BLOCKQUOTE\" ? this : this.parentElement; $(bq).find(\".show\").toggleClass(\"hidden\", !hide); $(bq).find(\".hide\").toggleClass(\"hidden\", hide); } else { var sol = $(this).closest(\".has-solution\")[0]; sol_toggle.call(sol, this.classList.contains(\"hide\"), true); } event.preventDefault(); event.stopPropagation(); }); })()", "https://cs.brown.edu/courses/csci1380/s19/board.html": "The LiteMiner Competition CSCI1380 Discussion Refresh LiteMiner | How Fast Can You Mine Be a lite miner and a polite miner. Rank Nickname Latest Score (seconds) Best Score (seconds) # of Submissions Update Time I was born one mornin' when the sun didn't shine. I picked up my shovel and I walked to the mine. Johnny Cash in Sixteen Tons CSCI1380 Distributed System | Spring 2019 Brown University | 2019-02-17 01:12:46", "https://cs.brown.edu/courses/csci1380/s20/board.html": "The LiteMiner Competition CSCI1380 Discussion History Refresh LiteMiner | How Fast Can You Mine Be a lite miner and a polite miner. Rank Nickname Latest Score (seconds) Best Score (seconds) # of Submissions Update Time I was born one mornin' when the sun didn't shine. I picked up my shovel and I walked to the mine. Johnny Cash in Sixteen Tons CSCI1380 Distributed System | Spring 2019 Brown University | 2020-02-25 07:37:06", "https://cs.brown.edu/courses/csci1380/": "\u2193 Skip to main content CS1380: Distributed Systems CS1380: Distributed Systems Resources Schedule Semester Schedule Calendar Staff Milestones Milestone 0 Milestone 1 Milestone 2 Milestone 3 Milestone 4 Past Years Spring 2023 Spring 2022 Spring 2021 Spring 2020 Spring 2019 Spring 2018 Spring 2017 Spring 2016 Spring 2015 Spring 2012 Resources Schedule Semester Schedule Calendar Staff Milestones Milestone 0 Milestone 1 Milestone 2 Milestone 3 Milestone 4 Past Years Spring 2023 Spring 2022 Spring 2021 Spring 2020 Spring 2019 Spring 2018 Spring 2017 Spring 2016 Spring 2015 Spring 2012 How are services like Google, Facebook, and Amazon built? This hands-on, project-oriented course focuses on the issues encountered in building software systems for data at massive scale. We will study how these services handle massive datasets and billions of requests per day. We will build infrastructure for big-data collection and analysis, at-scale processing and storage, and information extraction in the cloud and at the edge \u2014 including massive, heavily distributed infrastructure like the one used to run these services in production today. By the end of this course, students will be able to build their own distributed search engine \u2014 and to deploy and execute it on cloud resources. Time: 10:30 \u2013 11:50am, Tue & Thu ( gCal ) Location: CIT 368 and Zoom \u2191 \u00a9 2024 CS1380 | Brown Systems Group | Brown University mediumZoom(document.querySelectorAll(\"img:not(.nozoom)\"), { margin: 24, background: 'rgba(0,0,0,0.5)', scrollOffset: 0, })", "https://cs.brown.edu/courses/info/csci1380/": "CSCI1380 (Formerly CS138) Distributed Computer Systems Offered this year and most years Spring 2025 Explores the fundamental principles and practice underlying networked information systems, first we cover basic distributed computing mechanisms (e.g., naming, replication, security, etc.) and enabling middleware technologies. We then discuss how these mechanisms and technologies fit together to realize distributed databases and file systems, web-based and mobile information systems. Instructor(s): Nikos Vasilakis Location: TBD Meeting Time: TBD Exam Group: TBD CRN: None", "https://cs.brown.edu/courses/csci1370/": "Virtual Reality Design for Science, Fall 2019 Home Calendar Class Description Images Links Previous years: 1999 2000 2002 2003 2004 2005 2006 2007 2008 2013 2015 2017 Brown CS Visualization RISD Illustration ** For those considering the Fall 2019 class, consider the following: I suggest reviewing the course website from 2017, especially the calendar page, to see exactly what the class involves. That has all the assignments. The course description in CAB is short, so reviewing this info will make sure that know exactly what you would be doing in taking the course. ** We will provide overrides after the first assignment is handed in. In the past, we have almost always been able to accommodate everyone what was interested, who made it to the classes, and who completed the first assignment. I can't guarantee that will be the case this year, but it has been for the last 10 years. ** For registration, please request an override in CAB and also make sure that the class is in your primary cart. Those steps will keep you on the waiting list and also ensure that you get course emails. This course explores the visual and human-computer interaction design processfor scientific applications in immersive virtual reality. It is cross listedat Brown (as CSCI1370) and RISD (as ILLUS3340) and is co-taught by David Laidlaw from Brown Computer Science, Fritz Drury from RISD Illustration, as well as Stephen Gatesy from Ecology and Evolutionary Biology. Brandon Li is the TA. Computer science students learn how to work effectively with each other aswell as with artists and designers in creating applications targeting Brown'sCaves. A Cave is an immersive virtual reality space whose floor and walls arecovered with displays, which we will use to create interactive 3D virtualenvironments. There are currently two Caves on campus that are managed by the Brown Center for Computation and Visualization (CCV) : the YURT, a curved display system with 360-degree field of view located at 180 George St., and it's predecessor an 8'x8'x8' cube display system located at Studio4 of the Granoff Center. Artists and designers learn to interact with scientists in designing andrealizing applications in this new medium. We study the process of design fromseveral perspectives; learn about some specific scientific problems; studyexisting applications of scientific visualization and virtual reality; explorethe medium of the YURT; create designs for the scientific applications;critique, evaluate, realize, and iterate the designs; and culminate with ademonstration of final projects. The first class meets Thursday, September 5th at 10am in 180 George St. room 102B. 2019 shoppers, check out the \"calendar\" page for many details about what the course will involve.", "https://talie.town/cs1300_spring24/": "You need to enable JavaScript to run this app.", "https://cs.brown.edu/courses/csci1380/s19/": "CSCI-1380 :: Distributed Computer Systems :: Spring 2019 CS 138: Home CS 138 Home Syllabus Calendar Assignments Exams Announcements Latest Announcements 05/11: Final Exam at 2pm, May 11 Location 85 Waterman St, 130 01/30: Welcome to ICE CREAM SOCIAL! Jan 31 Thur, 19:30-21:00 at Lubrano (CIT 477) 01/29: LiterMiner released! See all announcements RSS 2.0 feed Overview CSCI 1380 is an undergraduate course in distributed computer systems. Wewill explore the fundamental principles and practice underlying networkedinformation systems. First we will cover basic distributed computingmechanisms (e.g., naming, replication, security, etc.) and enabling middlewaretechnologies. We then discuss how these mechanisms and technologies fittogether to realize distributed databases and file systems, web-based andmobile information systems. Prerequisites: CSCI 0320, CSCI 0330, or consent of the instructor. Lecture time: Tu/Th 10:30-11:50 Location: 85 Waterman Street 130 Course Staff We'll be using Piazza for almost all course-related communication. You can mark questions as privateor public. Private messages are seen by all course staff, see the collaboration policy for guidelinesof how to choose. You can also use cs1380tas@lists.brown.edu to e-mail thecourse staff regarding administrative issues. For sensitive issues that you wouldnot like to discuss with the entire course staff, you may email the instructorsand head TAs at cs1380headtas@lists.brown.edu . Instructor Name Email Office Hours Office Theophilus Benson tab@cs.brown.edu CIT 327 Tue: 4:00-5:00 PM, Wed:11-12 PM Teaching Assistants Name Email Office Hours Office HTA: Joshua Pattiz jpattiz@cs.brown.edu Sat 2-4 PM Moonlab (CIT 227) HTA: Martin (Ziyin) Ma zma17@cs.brown.edu Thur 8-10 PM Moonlab (CIT 227) TA: Ali Mir am209@cs.brown.edu Mon 10 PM -12 AM CIT 201 TA: Brian Oppenheim boppenhe@cs.brown.edu Wed 6-8 PM CIT 269 TA: Galadriel Brady gbrady1@cs.brown.edu Wed 10 AM - 12 PM CIT 205 TA: Kerem Gurbey kerem_gurbey@brown.edu Fri 11 AM - 1 PM CIT 205 TA: Kristen McLean kmclean1@cs.brown.edu Wed 4-6 PM CIT 201 TA: Tina Lu yuyang_lu@brown.edu Sun 4-6 PM CIT 201 TA: William Riley wriley1@cs.brown.edu Sat 1-3 PM Moonlab (CIT 227) TA: Zhedi Zhang zzhang57@cs.brown.edu Tue 8-10 PM Moonlab (CIT 227) See calendar for latest updates Course Policies Collaboration Policy The collaboration policy is available as a handout. You must sign the collaboration policy so that youcan receive credit for the assignments. Incomplete Policy Incompletes are granted only under exceptional circumstances (e.g. severe illness, death in the family, kidnapping, etc.; too heavy of a course load is not sufficient reason for an incomplete). Getting a dean to certify your reason for requesting an incomplete helps, but is not sufficient. Late Policy Students will be allowed a total of four late days to be used on homework and project assignments free of charge, but no more than three late days may be applied to any one assignment. Students will be penalized by a letter grade on the assignment for each day it is late. If you must miss an assignment deadline because of a religious holiday, you may also get an extension without using late days; please contact one of the instructors within the first three weeks of the course and fill out the form to declare such conflicts and we will plan accordingly. CSCI-1380 :: Spring 2019 :: Theophilus Benson All materials in this site are licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 3.0 United States License . Last modified: 2019-05-09 21:38:33 -0400. Page design adapted from the glued ideas subtle wp theme. var gaJsHost = ((\"https:\" == document.location.protocol) ? \"https://ssl.\" : \"http://www.\"); document.write(unescape(\"%3Cscript src='\" + gaJsHost + \"google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E\")); try { var pageTracker = _gat._getTracker(\"UA-371922-7\"); pageTracker._trackPageview(); } catch(err) {}", "https://cs.brown.edu/courses/csci1380/s15/": "CSCI-1380 :: Distributed Computer Systems :: Spring 2015 CS 138: Home CS 138 Home Syllabus Calendar Assignments Exams Announcements Attention: This is an old version of the CS 138 website. Please click here for the current offering. Latest Announcements 4/18: PuddleStore is out 3/21: Raft is out 3/6: Midterm review Monday, March 16th, 5:30PM in 368 See all announcements RSS 2.0 feed Overview CSCI 1380 is an undergraduate course in distributed computer systems. Wewill explore the fundamental principles and practice underlying networkedinformation systems. First we will cover basic distributed computingmechanisms (e.g., naming, replication, security, etc.) and enabling middlewaretechnologies. We then discuss how these mechanisms and technologies fittogether to realize distributed databases and file systems, web-based andmobile information systems. Prerequisites: CSCI 0320, CSCI 0330, or consent of the instructor. Lecture time: Tu/Th 10:30-11:50 Location: CIT 368 Course Staff We'll be using Piazza for almost all course-related communication. You can mark questions as privateor public. Private messages are seen by all course staff, see the collaboration policy for guidelinesof how to choose. You can also use cs138tas@cs.brown.edu to e-mail thecourse staff regarding administrative issues. Instructor Name Email Office Hours Tom Doeppner twd@cs.brown.edu CIT 405 Mon. 4-5PM, Wed. 3-4PM, Fri. 3-4PM Rodrigo Fonseca rfonseca@cs.brown.edu CIT 329 By Appointment Teaching Assistants Name Email Office Office Hours HTA: Cody Mello cody@cs.brown.edu Fishbowl (CIT 271) Monday, 7-9 PM Grad TA: Jeff Rasley jeffra@cs.brown.edu Fishbowl (CIT 271) Tuesday, 5-7 PM Grad TA: Jonathan Mace jcmace@cs.brown.edu Fishbowl (CIT 271) Wednesday, 10 AM-12 PM Course Policies Collaboration Policy The collaboration policy is available as a handout. You must print, read,and sign the collaboration policy before returning it to a TA so that youcan receive credit for the assignments. Incomplete Policy Incompletes are granted only under exceptional circumstances (e.g. severe illness, death in the family, kidnapping, etc.; too heavy of a course load is not sufficient reason for an incomplete). Getting a dean to certify your reason for requesting an incomplete helps, but is not sufficient. Late Policy Students will be allowed a total of three (3) late days to be used on homework and project assignments free of charge. Students will be penalized by a letter grade on the assignment for each day it is late. CSCI-1380 :: Spring 2015 :: Tom Doeppner, Rodrigo Fonseca All materials in this site are licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 3.0 United States License . Last modified: 2015-05-11 20:38:09 -0400. Page design adapted from the glued ideas subtle wp theme. var gaJsHost = ((\"https:\" == document.location.protocol) ? \"https://ssl.\" : \"http://www.\"); document.write(unescape(\"%3Cscript src='\" + gaJsHost + \"google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E\")); try { var pageTracker = _gat._getTracker(\"UA-371922-7\"); pageTracker._trackPageview(); } catch(err) {}", "https://cs.brown.edu/courses/csci1310/2020/": "CS 131 : Fundamentals of Computer Systems Home Schedule Assignments Project 1: Strings & Vectors Project 2: DMalloc Project 3: WeensyOS Project 4: Vunmo Project 5: Distributed Store Lab 0: Getting Set Up Lab 1: C Programs Lab 2: Building Programs Lab 3: Assembly Lab 4: Caching Lab 5: Intro to WeensyOS Lab 6: Processes Lab 7: Threads Lab 8: RPCs Final Quiz Resources COVID-19: virtualizing CS131 C/C++ Primers Textbooks Course outline Why take CS131? FAQs Exercises: Computer Systems Basics Exercises: Operating Systems Exercises: Concurrency Exercises: Distributed Systems Anonymous feedback Staff Office Hours Spring 2020 Do you want to understand the magic that makes our computers work? This is your chance to master that magic. Lectures: Tuesday/Thurday, 1:00-2:20pm. \u2013 Location: BARHOL 168 Zoom . Missive \u2013 Syllabus \u2013 Schedule \u2013 Staff \u2013 Office Hours Infrastructure \u2013 Piazza \u2013 Grading server Lecture feedback \u2013 Lecture code Announcements Due to the university going virtual for the rest of the semester, some CS 131 deadlines and policies have changed . See here for details . Stay safe and healthy everyone! \ud83e\udd70 2020/04/09: Final Quiz released. Best of luck! Due May 12, noon. 2020/04/25: Project 5 (Distributed Store) released! 2020/04/21: Lab 8 released! (Now due May 5.) 2020/04/14: Lab 7 released! 2020/04/10: Project 4 (Vunmo) released! 2020/04/01: Lab 6 released! 2020/03/03: Lab 5 released! 2020/02/27: Project 3 (WeensyOS) released! 2020/02/25: Lab 4 released! 2020/02/19: Lab 3 released! 2020/02/14: Project 2 (DMalloc) released! 2020/02/11: Lab 2 released! 2020/01/23: Lecture notes, code, and videos will be available from the schedule page . Here are lecture notes for lectures 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 . 2020/01/23: Lab 0 and Lab 1 , and Project 1 (Strings & Vectors) released! 2020/01/22: Sign up for Piazza ! Logistics Course Summary. The goal of CS 131/CSCI 1310 is to teach the fundamentals behind the \"magic\" of computer systems from the hardware level to the global internet. We'll cover the ideas, principles and abstractions that unify computer systems design \u2013 from how your laptop runs multiple programs at the same time, to how companies like Instagram, AirBnB, and Google operate large websites, to how easy it is to exploit security vulnerabilities on badly designed systems. This is a great class for students who are interested in learning what systems programming is, how systems work, and why these systems are so critical to modern technology. Enrollment. CS 131/CSCI 1310 is open to anyone who has completed the introductory sequence (i.e., CS 16, 18, or 19). For students who don't satisfy the registration restrictions on CAB, please request an override code on CAB and include an explanation of your course experience, and we'll review your request. What does CS 131 count for? CS 131/CSCI 1310 is a 1000-level course that can count as a related course in the systems pathway of the CS concentration and masters. In addition, CS 131 will satisfy the prerequisites for CSCI 1380 (Distributed Systems), CSCI 1270 (Databases), CSCI 1650 (Software Security and Exploitation), CSCI 1660 (Computer Systems Security), CSCI 1730 (Programming Languages), CSCI 1951-A (Data Science), CSCI 1680 (Computer Networks), and CSCI 2390 (Privacy-Conscious Computer Systems). Course Email: cs1310headtas@lists.brown.edu . window.jQuery || document.write('<script src=\"js/jquery-slim.min.js\"><\\/script>') (function () { jQuery.fn.extend({ geometry: function (outer) { var x; if (this[0] == window) x = {left: this.scrollLeft(), top: this.scrollTop()}; else x = this.offset(); if (x) { x.width = outer ? this.outerWidth() : this.width(); x.height = outer ? this.outerHeight() : this.height(); x.right = x.left + x.width; x.bottom = x.top + x.height; } return x; } }); function sol_toggle(hide, storage) { this.childNodes[0].classList.toggle(\"hidden\", !hide); this.childNodes[0].classList.toggle(\"shown\", hide); this.childNodes[1].classList.toggle(\"hidden\", hide); this.childNodes[1].classList.toggle(\"shown\", !hide); if (storage) { var key = location.href + \" \" + $(\".has-solution\").index(this); if (hide) sessionStorage.removeItem(key); else sessionStorage.setItem(key, true); } } $(\".solution\").each(function () { $(this).wrap('<div class=\"has-solution\"></div>'); var sol = this.parentElement; $(sol).prepend('<blockquote class=\"solution-collapsed js-solution show\"><a href=\"\" class=\"js-solution show\"></a></blockquote>'); $(this).append('<p><a href=\"\" class=\"js-solution hide\"></a></p>'); $(sol).find(\"a.js-solution.show\").text(this.getAttribute(\"data-show-text\") || \"Show solution\"); $(sol).find(\"a.js-solution.hide\").text(this.getAttribute(\"data-hide-text\") || \"Hide solution\"); var key = location.href + \" \" + $(\".has-solution\").index(sol); if (sessionStorage.getItem(key)) sol_toggle.call(sol, false, false); }); $(document).on(\"click\", \".js-solution\", function (event) { if (this.classList.contains(\"all\")) { var hide = this.classList.contains(\"hide\"); $(\".has-solution\").each(function () { sol_toggle.call(this, hide, false); }); var bq = this.tagName === \"BLOCKQUOTE\" ? this : this.parentElement; $(bq).find(\".show\").toggleClass(\"hidden\", !hide); $(bq).find(\".hide\").toggleClass(\"hidden\", hide); } else { var sol = $(this).closest(\".has-solution\")[0]; sol_toggle.call(sol, this.classList.contains(\"hide\"), true); } event.preventDefault(); event.stopPropagation(); }); })()", "https://csci1410-2023.vercel.app/": "You need to enable JavaScript to run this app.", "https://cs.brown.edu/courses/csci1440/leaderboard/leaderboard.html?game=LemonadeArena": "CS1440 Agent Leaderboard Game: Agent Average Score #/Games", "https://cs.brown.edu/courses/csci1440/": "Toggle navigation Home Lectures Homeworks Labs Staff Calendar Welcome to Algorithmic Game Theory Course Description and Goals This course examines topics in game theory and mechanism design through the lens of computation. Like such a course in an economics department, the focus is the design and analysis of systems utilized by self-interested agents. Students investigate how the potential for strategic agent behavior can/should influence system design, and the ramifications of conflicts of interest between system designers and participating agents. Unlike a traditional economics course, however, emphasis on computational tractability is paramount, so that simplicity may trump other design desiderata. Students will learn to analyze competing designs using the tools of theoretical computer science. They will also use artificial intelligence to build autonomous agents for computational advertising markets, wireless spectrum auctions, automated negotiation, and/or prediction markets. There are two primary learning outcomes intended for students taking this course. Students should be able to: Reason about the design of multiagent systems taking into account agents' incentives, a perspective borrowed from economists, as well as computational performance, the bread and butter of computer scientists. Design and build effective autonomous agents for market domains that again incorporate both strategic and computational considerations. Prerequisites Mathematical maturity and programming experience are necessary for success in this course. The following are specific areas in which basic expertise is assumed, along with suggested courses for acquiring said expertise. Comfort with continuous mathematics: e.g., Math 0180, Math 0350, APMA 0350, or APMA 0360. Comfort with probability and statistics: e.g., CS 1450, APMA 1650, APMA 1655, or Math 1620. Comfort writing proofs: e.g., CS 22, CS 1010, CS 1550, or any 1000-level Math class. Comfort with programming: e.g., CS 4, CS 111, CS 15, CS 17, CS 19, or equivalent. Some knowledge of Java and Python is assumed; neither language is taught. For students wishing to enroll in the graduate section of this course, CSCI 2440, knowledge of Markov decision processes and linear programming is also assumed. Topics What is game theory? What is mechanism design? What is auction theory? Simple, awesome, and EPIC auctions Bidding strategies for combinatorial auctions Empirical game-theoretic analysis and mechanism design Application domains Computational advertising markets Wireless spectrum markets Automated negotiation Prediction markets Course Format CSCI 1440/2440 lectures are held on Wednesdays from 3 PM to 5:30 in CIT 368. Lecture notes are posted on the course web page, as are weekly readings that reinforce the lecture materials. In addition to weekly lectures, there are weekly two-hour lab sessions, which offer students hands-on environments in which to practice the techniques they are taught in lecture. Labs are pair-programmed ; for their own benefit, students should make a concerted effort to work with multiple partners over the course of the semester. Students are required to register for and attend one lab per week. Penalties are incurred for failure to attend. Multiple lab sections will be offered, with accommodations offered only for students who are impacted by COVID-19. Students will be assigned weekly, written homework exercises, due on Tuesday nights at 11:59 PM. To enhance the learning process, we recommend that students collaborate on homeworks, respecting the limits of the collaboration policy. During each class, the TAs will run something akin to \"section\". During these sections, they will lead an interactive discussion of the ongoing and recently-submitted homework exercises. Participating in these discussions is a great way to gain insights into how to complete the weekly homework exercises. The TAs will also lead weekly tutorials at the start of the semester to bring students up to speed on some topics that are not strictly prerequisites, but would be helpful for students to know and love : e.g., linear programming, Markov decision processes. The course will culminate in a final project that involves writing as well as programming, and students are assessed along both of these dimensions (and others, like creativity). Consistent with all the other assignments in this course, students are invited to work in pairs. Groups will present their final projects to the class during class time during reading week (Wednesday, May 1, 3-5:30 pm). All students are required both to present and be present for their fellow students' presentations. The penalty for failing to appear is severe (e.g., failing the class). There are no exams in CSCI 1440/2440. Students are evaluated based on their participation during lecture and in labs, and their performance on weekly written homework exercises, programming assignments, and the final project. This course offers a capstone option. In past years, students who elected this option did twice as much work on the final project as students who did not choose this route. (Specifically, they did both final projects instead of choosing one.) All students should expect to spend 2.5 hours per week in lecture and 2 hours per week in lab. In addition to these instruction hours, there will be weekly homework exercises (4-8 hours in the undergraduate section, and 6-10 hours in the graduate section), and supplementary readings \u2014 available online, free-of-charge (1-2 hours). The final project is open-ended, but 40 hours, over the course of 4 weeks, should suffice to produce acceptable work. In sum, students enrolled in the undergraduate (graduate) section should plan to dedicate approximately 12 (14) hours per week to this course, for a total of 180 (210) hours over the course of a 15 week semester. Grading Grading rubrics in CSCI 1440 are developed by the professor in conjunction with undergraduate TAs. TAs then grade all assignments. Grade complaints on individual assignments should be addressed to the relevant TA within ten days of grade releases. The professor assigns all final grades and reviews individual assignment grades as necessary (e.g., in borderline cases). Course grade complaints can be addressed to the professor. The (tentative) grading breakdown is as follows: Assignment Percentage Participation 10% Labs 20% Homeworks 40% Final Project 30% Late Policy For all assignments unless stated otherwise, students will be granted three free late days, which can be applied, as needed, over the course of the semester to homework assignments, (Footnote: For homeworks due Tuesday night, late days only apply until 2:59 PM the next day (Wednesday). Homeworks turned in after 2:59 PM on Wednesday will not be accepted, so that we can freely discuss the solutions in class.) and any take-home labs, but not to the final project; *the final project deadline is a hard deadline; late final projects will not be accepted*. In the unfortunate circumstance that the three free late days are all used up, late day penalties will apply: -10% within 24 hours, and -25% within 48. No assignments will be accepted electronically more than 48 hours beyond their due date. Note, however, that any assignments due the day before, but turned in the day after, a long weekend (Presidents' Day) or spring break are only charged one late day. For assignments that are to be graded interactively (meaning students have a set time at which they will be meeting a TA), the following late penalties always apply: if the student is late by 10 minutes or less, -10%; 10 to 20 minutes, -20%; more than 20 minutes counts as a \u201cno show\u201d, for which the penalty is -50%. This same penalty schedule applies recursively to rescheduled interactive gradings following a no show. Last-minute email requests to reschedule interactive gradings must be sent to the relevant grader(s) and to the head TAs at least 2 hours prior to the scheduled meeting time to avoid any penalties. For group projects that are graded interactively, if some members show up for the grading session while others do not, the grading will proceed, and those who do not appear will receive a grade of 0 for that portion of the project, while those who appear late will be penalized according to the aforementioned penalty schedule. Extensions may be granted by the professor in extreme circumstances. If you are ill, please visit health services so you can provide a doctor\u2019s notes when requesting an extension. If you are under any other sort of duress, please seek advice from a dean. Collaboration Policy Students are encouraged to collaborate with their peers in CSCI 1440/2440. Indeed, all labs are pair programmed, and students may submit homeworks and the final project with a partner as well. When working on homeworks, students may also consult students other than their partner, for example during office hours, but each student or pair of students is always required to 1. write up their solutions to the homework on their own; and 2. list the names of all students with whom they discussed the assignment on their submitted work. Unnatural similarities among students' submissions will be forwarded to the Dean of the College's office for review, to assess whether or not there has been a violation of Brown\u2019s Academic Code . As for language models like ChatGPT, students can ask them to further explain concepts (which they may or may not do correctly), but as expected, students cannot ask language models to solve their homework problems for them. If a student chooses to engage a language model in a homework discussion, a (TA-accessible) link to the conversation history must be included with the handin. If you have any questions about this policy, please ask the course staff for clarification. Not understanding our policy is not grounds for not abiding by it. Diversity and Inclusion The computer science department is committed to diversity and inclusion, and strives to create a climate conducive to the success of women, students of color, students of any sexual orientation, and any other students who feel marginalized for any reason. If you feel you have been been mistreated by another student, or by a member of the course staff, consider reaching out to one of student advocates on the CS department\u2019s Diversity and Inclusion Committee, or to Professor Greenwald or Professor Tamassia (the CS department chair). We, the CS department, take all complaints seriously. Accommodations If you feel you have any disabilities that could affect your performance in the course, please contact SEAS , and ask them to contact the course staff. We will support accommodations recommended by SEAS. Harassment Please review Brown\u2019s Title IX and Gender Equity Policy . If you feel you might be the victim of harassment (in this course or any other), you may seek help from any of the resources listed here . $(document).ready(function() { $(\"#slick\").slick({ adaptiveHeight: true, dots: true, infinte: true, }); });", "https://cs.brown.edu/courses/csci1450/": "Home Lectures Assignments Calendar Staff Resources CS1450, Fall 2023, taught by Professor Eli Upfal and Alessio Mazzetto Probability and statistics have become indispensable tools in computer science. Probabilistic methods and statistical reasoning play major roles in machine learning, cryptography, network security, communication protocols, web search engines, robotics, program verification, and more. This course introduces the basic concepts of probability and statistics, focusing on topics that are most useful in computer science applications. Topics include: modeling and solution in sample space, random variables, simple random processes and their probability distributions, Markov processes, limit theorems, and basic elements of statistical inference. This course emphasizes both mathematical rigor and computing applications. For more details, please refer to the course syllabus . We use Ed Stem in this course. You can join it by clicking the \"Ed Discussion\" tab on the canvas page for this course. Please let us know if you can't access Ed Stem. Fall 2023: Lectures will be held in CIT 368.", "https://cs.brown.edu/courses/csci1470/dlday.html": "Home Resources Lectures Assignments Labs Calendar & Hours Staff Deep Learning Day When: Thursday, December 12 Where: Sayles Hall Come see the fantastical final projects produced by the hardworking students of CSCI 1470/2470! Deep Learning Day is a celebration of their efforts. It is also, by structure, a mini research conference. The day is divided into four Sessions, each of which features multiple projects organized around a small set of themes. Students in CSCI 1470 will present posters during these sessions, and students in CSCI 2470 (the graduate-level version of the course) will give brief oral presentations. Come to one session, to multiple, or to all---just come! We'd love to have you stop by, give feedback, and show your support for the Fall 2019 cohort of Brown deep learners. Schedule \ud83c\udfa4 = oral presentation 9:00 AM Opening Remarks 9:15 AM Session 1: Natural Language Processing \ud83c\udfa4 Identification of duplicate Quora question pairs Stella Xiao, Yaxi Lei, Qiran Gong, Wenhao Yang \ud83c\udfa4 sarc2seq: Translation of Sarcastic Sentences for Improved Sentiment Analysis Accuracy Kathryn Scholl, Yanyan Ren, Michael Coppoli \ud83c\udfa4 Second Language Acquisition Modeling with Attention Rafael Alberto Sanchez Rodriguez, Nihal Vivekanand Nayak, Juho Choi, Seungchan Kim \ud83c\udfa4 Five Pages in Five Lines: Descriptive Text Summarization with GPT-2 Rashi Dhar, Soma Arunkanti Hota, Matthew McAvoy \ud83c\udfa4 Quora Insincere Questions Classification Vipul Vinayak Gupta, Esen Erdemgil, Maulik Dang \ud83c\udfa4 Generating Sarcastic Comments with LSTMs Kat Chai, Natalie Reed, Summer Gerry, Marshall Lerner \ud83c\udfa4 RNN-based Classical Chinese Poetry Generation with Planning technique Qingyi Lu, Da Huo, Yue Sun \ud83c\udfa4 Integrating Grammar Tree Structure into the BERT Language Model Shiyi Han, Shunjia Zhu, Yiming Zhang \ud83c\udfa4 Conversation Generation with Transformer and ConceptNet Jiayang Wu, Haili Chen, Ke Ding, Houyu Zhang \ud83c\udfa4 OMG: Analyzing Sentiments of Tweets Ao Wang, Emily Reed, Yunyun Yao, Pedro Freitas \ud83c\udfa4 Presidential Tweet Frequency Prediction Harman Suri, Jake Chanan, Anatoly Brevnov, Nikolai Illarionov Predicting Political Party Affiliation of Climate Change Tweets Hannah Haas, Claudia Meyer, Madeline Griswold, Cintia Araujo \u201cFake!\u201d: Identifying fake news in tweets William Patterson, Rinad Salkham, Jaja Sothanaphan HOROSCRAPE - (HOROSCOPE GENERATOR...THE DIFFERENCES BEHIND THE SIGNS) Alexander Ogilvy, Emma Kofman, Andrew Rickert Online Post Fake News Detector Ariel Rotter-Aboyoun, Daniel Kostovetsky, Julius Sun, Raymond Cao Sentiment Analysis on Amazon Customer Reviews David Promisel, Kristen Mashikian, Daniel Adkins, Kuba Tarlowski Style Transfer of Natural Language Tiger Dingsun, Nadia Lahlaf Deep Loving: Hating on Hate Speech Alina Kim, Diana Lee, Daniela Wiepert, Niharika Jhingan Genre is a Spectrum: Synoptic Multiple Label Classification Solomon Zitter, Daniel Smits Long Short Term Memory Loss: Pun Generation using Neural Networks Shawna Huang, Evan Velasquez Generating Natural Language in the style of The Office via a Neural Machine Translation Context Ruixi Seet, Lisa Yang %$@# Comment Classification Venkata Shubhang Kandiraju, Melissa Wang, Sally Zhi, Michael Lincoln Re-implementing: Teaching Machines to Read and Comprehend Young Jie Cho, Ragna Agerup, Kento Nambara, Zhengyi Peng Rhyme Time: Learning to Generate Rhythmic Verse Ivan Zhao, Sorin Cho, Timothy Wang, Morgann Thain Learning Emotional Intelligence: Emotion-Cause Pair Extraction from Text Sophie Yang, Nazem Aldroubi, Daphne Li-Chen, Ang Li Ain\u2019t Nobody Got Time for That! (Text Summarization) Jason Fischman, Kei Nawa, Seth Wernick Sentiment Analysis of Movie Reviews Yue You, Zhen Zheng T^3 (Train, Transform, Translate) Homer Walke, Sebastien Jean-Pierre, Gabriel Marks, David Cabatingan Constructing Kinship Graphs with RNNs Benjamin Spiegel 10:40 AM Break 10:50 AM Session 2: Vision and Data Science \ud83c\udfa4 Weakly Supervised Image Classifier Ahmed Agiza, Marina Hesham Wasfy Neseem \ud83c\udfa4 Pneumonia Detection from Medical Images Amber Ogata, Huayu Ouyang, Jennifer Nino Tapia \ud83c\udfa4 Medical Image Segmentation through Pruned Deep Neural Networks Georgios Zerveas, Reza Esfandiarpoor \ud83c\udfa4 Segmentation of Tumors in Medical Images Angel Suet Yan Cheung, Kyle Cui, Elliot Kang \ud83c\udfa4 Pneumonia Prediction from Chest X-Ray Images Qian Xiang, Queena Zhang, Tiancan Yu \ud83c\udfa4 Big Time Rush: Predicting Rush Distance for Football Plays Gokul Ajith, Harrison Boyer, Benjamin Decky, Akhil Trehan \ud83c\udfa4 CNN Based Predictive Maintenance Cong Huang, Hanyan Liu, Xiaodong Zhang \ud83c\udfa4 Detecting fractures on ankles and predicting the location of fracture. Yuchen Hua, Chengzhao Tu \ud83c\udfa4 Street Sign Classification Kaiqi Jiang, Christopher Wong, Dominic Ferri \ud83c\udfa4 Ship Detection In Satellite Images with U-Net Dong Xian Zou, Peng Chen, Zhoutao Lu, Wensi You Bone Abnormality X-ray Classification Nicholas Merchant, Bowen Chen, Adam Pikelny NBA Predictions Using Feature Analysis William Schor, Jacob Begemann, Eric Dellavalle, Greyson Gerhard-Young Phishing in the Deep: Detecting Phishing URLs with Deep Learning Elizabeth Wang, Koyena Pal, Cat Nguyen Dinh, Tiffany Ding Deep Climate Nickolas Eisele, Mert Tavukcuoglu, Zhen Zhang An Exploration Into the Classification of Dog Breeds (feat. What Dog Breed Are YOU? @ TAs) Nicole Cheng, Zachary Mor, Gisele Garcia Night Sight for All: Learing to Adjust Exposure in Dark/Underexposed Images Oscar Newman, Isaac Hilton-VanOsdall, Benjamin Gershuny, John Bitar Learning the Dress Code: Fashion Style Compatibility Tomi Madarikan, Angel Rodriguez, Delmy Garcia, Hannah Chow You Only Look Once with TensorFlow 2.0 Ziwei Chen, Shixin Liu, Zeyu Ruan, Geng Yang Detecting Lung Cancer fron PET Scans Gerald Wu, Jonathan Lee Real-Time Logo Detection Geo Lee, Suhye Park A CNN to detect malignant skin lesions Jung Ho Gong, Jia-Shu Chen, Isaiah Liu, Elizabeth Dimen Automating food diary entries through images Jessy Ma, Rebecca Zuo, Karlly Feng Why so serious? Facial Expression Classification Neil Sehgal, John Paul Champa, Andrew Wei, Zhe Chang Forecasting hotel reservations with LSTM based RNNs Diane Mutako, Litian Yang, Dinithi Silva Sassaman Deep State: Can We Trust You? Predicting First Impressions with Deep Learning John Diorio, Sophie Starck, Jonathan Douglas, Noah Duncan Bounding box object detection Alex Meyerowitz, Alexander Yu, Shrishti Lulla, Jesus Contreras Solving Captchas Sebastien Lamy, Ayse Sena Demir, Andrew Peterson Microorganism Classification Kayla Scharfstein, Ajay Balaji, David Lu WTF (What The Font): Font Detection Maggie Wu, Katherine Sang, Minna Kimura-Thollander Using regularization methods to tackle adversarial images classification problems ldeng8, yzhan236, yzhao101 Stock Prediction Using Reactionary Recurrent Neural Network Rahul Dey, Mustafa Ghani 12:15 PM Lunch Break 1:15 PM Session 3: Graphics and Reinforcement Learning \ud83c\udfa4 Filling in Incomplete Images Min Jeong Kang, Daniel Nam, Jingxiao Ma \ud83c\udfa4 Wetnet: Style Transfer for Water Simulation Natalie Lindsay, Purvi Goel, James Guesman, Michael Cosgrove \ud83c\udfa4 Using Generative Adversarial Networks (GANs) to Synthesize Images Depicting Traditional Mexican Crafts Xiaotong Fu, Huakai Liu \ud83c\udfa4 A de-weathering extension for self-driving cars Dhananjay Bhaskar, Loudon Cohen, Mert Alaydin, Saman Sang \ud83c\udfa4 Practical lighting and reflectance decomposition for relighting face images Xianghao Xu, Qian Zhang \ud83c\udfa4 Mastering BBTAN with Deep Reinforcement Learning Brandon Tan, Irvin Lim, Xiangyu Li, Chong Wang \ud83c\udfa4 Deep Contra Lu Shao, Yanzhi Xin \ud83c\udfa4 Project Pickaxe: Playing Minecraft with Deep RL Nikhil Pant, Spencer Greene, Deniz Bayzit Self-Driving Mario Kart Using Deep Learning Tyler Jiang, Wenhuang Zeng, Lawrence Huang, George Lee Software Breaks Hearts: Playing the Game of Hearts with Deep RL Tucker Berkmann, Gulam Murtaza, Peter Shewmaker Comparison of Deep Q Learning and Policy Learning on Trading Jeremy Chen, Stephen Cheung Deep Reinforcement Learning on Simplified Overcooked Gene Siriviboon, Top Piriyakulkij, Panthon Imemkamon Breakout of Being Bad Zak Wegweiser, Ethan Sattler, Ravi Kandula, Louis Kilfoyle Deep Recurrent Q Networks to Solve Avalon Alexander Ivanov, Jason Crowley Coloring in the Deep: Using Deep Learning for Image Colorization Husam Salhab, Martin Chu, Rohit Jawle, Robert Maloney Zero Shades of Gray: Real-Time User-Guided Image Colorization with Learned Deep Priors Shenandoah Duraideivamani, Thomas Del Vecchio, Geoffrey Glass, Mia Santomauro Image to Image Mapping using Conditional Adversarial Networks Jason Senthil, Coleman Dowdle, Nishant Kumar, Yuan Gao A Couple of If-Statements with Path-Tracing: Denoising Monte Carlo Renderings Gabriel Rizk, Brandon Li, Dylan Tian, Andrew Canino JET Net: Generating Running Routes Trevor Houchens, Elliot Laidlaw, Julia McClellan DeepLice (Deep Learning Liar\u2019s Dice) Zhaoyong Zheng, Ilan Bigio, Jacob Leiken Towards Intelligent Upsampling of Natural Images (TIUNI) Zsozsho Biegl, Isa Milefchik, Rachel Wang, Tiffany Nguyen Colorizer Kshitij Sachan, Ben Silverman, Anoop Singh Classifying Hand-Drawn Sketch Images Nisha Khater, Lucia Reyes, Madelyn Adams, Laurie Finkelsztein Face Aging with Conditional Generative Adversarial Networks Joy Zheng, Joshua Kim, James Li, Melis Gokalp Reimplementing Image Style Transfer Kotone Tsuji, Ken Kawamura Album Cover Generation by Genre. Dybe Fredy Mwaisyange, William Kuenne, Griffin Kupsaw, Mateo Encarnacion Probabilistic Neural Networks Isaac Benghiat 2:40 PM Break 2:50 PM Session 4: Music, Audio, and Much More \ud83c\udfa4 Multi-scale Deep Tensor Factorization for Financial Data Troy Moo Penn, Zachary Laporta \ud83c\udfa4 Pulse Classification from LUX RQ Data Using Supervised Learning Austin Vaitkus, Nathaniel Swanson, Casey Rhyne \ud83c\udfa4 Pulse discrimination of cosmic muon in simple scintillators Jeanne Bang, Taeun Kwon \ud83c\udfa4 Understanding the Topology of Neural Networks Yang Xiao, He Yun \ud83c\udfa4 Physics-Informed Neural Networks for Partial Differential Equations in Mechanics Enrui Zhang, Minglang Yin, Zongren Zou, Wei Cheng \ud83c\udfa4 Transcription Binding Site Identification with Attention Model Suchen Zheng, Xiling Zhang \ud83c\udfa4 Transformer Modeling on Autoencoded Neuronal Signals to Predict Relative Joint Angle Displacement Matthew Alexander, Tyler DeFroscia \ud83c\udfa4 Using AIQNs and Imitation learning to Construct an Optimal Stochastic Policy for Primate Arm Motion Olivia Langley, Sean Nathan, Gregory Cho \ud83c\udfa4 Gene Expression Prediction using Graph Convolutional Networks Jeremy Bigness, Qing Wu, Omer Dai New Ear\u2019s Resolution: Audio Super-Resolution using Neural Nets Jackson Markey, Victoria Lin, Kevin Ouyang, Sung Hyun Mo Reducing Dimension in Single-Cell Data with Generative Networks Daniel Ben-Isvy, Jaison Jain, Benjamin Foulon ShallowVariant - Training a Child Model from DeepVariant August Guang, Mary McGrath Predicting Depression Levels Shbham Makharia, Srinjoy Srimani, Jake Sokol Predicting Primate Upper Limb Movements Via Neuron Firing Rates is No Monkey Business Jason Manuel, Cindy Li, Put Dam Predicting Monkey Hand Pose from Neural Activity Conrad Zborowski, Xavier Loinaz, Naomi Lee BrainGELU: Monkeying Around Zoe Beckman, Alexander Homer, Soryan Kumar, Viknesh Kasthuri Music Generation Katie Friis, William Jurayj Accenter Mark Lavrentyev, Arvind Yalavarti, Jeffrey Zhu BachLSTM John Lhota, Nicholas Wee Efficient Music Auto-Tagging with Convolutional Neural Networks Ekaterina Lezine, Shash Sinha, Yilmaz Sayin LSTM-Type Beat Kyle Qian, Christie Gahm, Dylan Ngo Low Transverse Momentum Tau Reconstruction Using LHC Data Jason Whang, Ye Won Byun, Eleanor Eng, Young Park Bach to the Future: Learning To Generate Bach Compositions Gabby Asuncion, Sophia Chen, Kelvin Yang, Stanley Yip Pop Predictor v1.0: Predicting Music Popularity Andrew Kopplin, Marshall Vyletel, Lynn Hlaing Arabic Spoken Digit Classification Lauren Anderson, James White Music Genre Classification Prithu Dasgupta, Daniel Park, Bill Ma Piano Genie: Music Generation Based on User Input Oh Joon Kwon, Jaehyun Jeon, Junewoo Park, Min Jean Cho From Franck to Fitzgerald: Jazz in the Style of Classical Music Anessa Petteruti, Katherine Kwan, Alexander Rothberg, Luke Cadigan Implementation of a physics-informed deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations Hanxun Jin, Zhi Li 4:15 PM Closing Remarks \u00a9 2019 CS1470/2470 TA Staff | Computer Science Department | Brown University", "https://cs.brown.edu/courses/csci1510/": "CSCI 1510 Resources Homeworks Lectures Calendar Staff \u2630 CSCI 1510 Homeworks Lectures Calendar Resources Staff \u2630 CSCI 1510 Introduction to Cryptography and Computer Security Introduction Welcome to Cryptography and Computer Security (CSCI 1510) at Brown! Cryptography is about communication and computation in the presence of an adversary. In this course, we will address questions such as: Can a secret message be sent over an unsecured channel? How can Alice send a message to Bob such that Bob will understand it but no eavesdropper will? Can we guarantee authenticity of data? How can Bob be sure that the message he received is indeed from Alice? How can he convince someone else of this fact? Can we guarantee that it is impossible to cheat in an online game? Can Alice and Bob play cards over the Internet? To answer these questions, we will first decide what security properties are desirable for the situation at hand. We will then formally define the objects that we wish to derive: encryption schemes, signature schemes, and hash functions. Finally, we will give suitable constructions and prove that they satisfy the definitions we have given. Besides these foundational cryptographic notions, we will also cover more advanced topics including identity-based encryption, post-quantum cryptography, fully homomorphic encryption, zero-knowledge proofs, secure multi-party computation, and program obfuscation. We will see what security guarantees are desirable, how to properly define these security guarantees, and how to design cryptographic algorithms and protocols that satisfy them. Lectures take place every Tuesday and Thursday from 10:30 - 11:50 AM , in CIT 101 and on Zoom . Resources Quick Links Syllabus EdStem Gradescope Class Participation Template Textbooks [KL] Introduction to Modern Cryptography by Jonathan Katz and Yehuda Lindell [BS] A Graduate Course in Applied Cryptography by Dan Boneh and Victor Shoup [R] The Joy of Cryptography by Mike Rosulek [G] Foundations of Cryptography by Goldreich ( Vol. 1 and Vol. 2 ) Lecture notes by Pass-Shelat , Bellare-Goldwasser , Bellare-Rogway , and Ostrovsky Contact peihan_miao@brown.edu leah_rosenbloom@brown.edu simon_campos_greenblatt@brown.edu Homeworks Homework Release Due Homework 0 Sep 8 Sep 15 Homework 1 Sep 15 Sep 22 Homework 2 Sep 22 Sep 29 Homework 3 Sep 29 Oct 6 Homework 4 Oct 6 Oct 13 Homework 5 Oct 13 Oct 20 Homework 6 Oct 27 Nov 3 Homework 7 Nov 3 Nov 10 Homework 8 Nov 10 Nov 17 Homework 9 Nov 17 Dec 1 Homework 10 Dec 1 Dec 8 #lecturetable .left {text-align:left;} Lectures This schedule is tentative and subject to updates throughout the semester. * indicates optional reading material. Date Topics and Readings Pre-Lec Notes Post-Lec Notes Zoom Rec Sep 7 Topics: Introduction and overview. Readings: Syllabus [KL 1.1] Cryptography and modern cryptography. *[KL 1.3] Historical ciphers and cryptanalysis. Pre01.pdf Post01.pdf Rec01 Sep 12 Topics: Syntax of symmetric-key encryption scheme. Kerckhoff's principle. Definitions of perfect security. One-time pad. Limitations of perfect security. Readings: [KL 1.2, R 1.1] Encryption syntax and Kerckhoff's principle. [KL 1.4.1] Formal definitions. [KL 2.1-2.3] Perfectly secure encryption. *[KL 2.4] Shannon's theorem. Pre02.pdf Post02.pdf Rec02 Sep 14 Topics: Computational security. Concrete vs asymptotic security. Definition of semantically secure encryption. Readings: [KL 3.1] Computational security (concrete vs asymptotic). [KL 3.2, BS 2.2.2] Semantic security. Pre03.pdf Post03.pdf Rec03 Sep 19 Topics: Definition of semantically secure encryption (continued). Definition of pseudorandom generators (PRGs). Semantically secure encryption scheme from PRG. Proof by reduction. Readings: [KL 3.2, BS 2.2.2] Semantic security. [KL 3.3.1, BS 3.1.1] Definition of PRG. [KL 3.3.2-3.3.3, BS 3.2] Encryption scheme from PRG and proof. Pre04.pdf Post04.pdf Rec04 Sep 21 Topics: Fixed-length encryption from PRG (continued). Security against chosen-plaintext attacks. Pseudorandom functions (PRFs). Readings: [KL 3.3.2-3.3.3, BS 3.2] Encryption scheme from PRG and proof. [KL 3.4.2, BS 5.3] Definition of CPA security. [KL 3.5.1, BS 4.4.1] Definition of PRF. Pre05.pdf Post05.pdf Rec05 Sep 26 Topics: Construction of PRF from PRG (GGM tree). CPA-secure encrytpion scheme from PRF. Hybrid argument. Readings: [BS 4.6] Construction of PRF from PRG. [KL 3.5.1, BS 5.4.1] CPA-secure encryption from PRF and proof. Pre06.pdf Post06.pdf Rec06 Sep 28 Topics: Message authentication codes (MACs). Fixed-length MAC. CBC-MAC. Readings: [KL 4.1-4.2, BS 6.1] Definition of MACs. [KL 4.3.1, BS 6.3] Fixed-length MAC. [KL 4.4] CBC-MAC. Pre07.pdf Post07.pdf Rec07 Oct 3 Topics: CBC-MAC (continued). Security against chosen-ciphertext attacks. Definition of authenticated encryption. Readings: [KL 5.1.2, BS 9.2.2] Definition of CCA security. [KL 5.2, BS 9.1] Definition of authenticated encryption. Pre08.pdf Post08.pdf Rec08 Oct 5 Topics: Constructions and proofs of authenticated encryption. Readings: [KL 5.3.1, BS 9.4] Generic constructions of authenticated encryption. *[KL 5.4] Secure communication sessions. Pre09.pdf Post09.pdf Rec09 Oct 10 Topics: Proof of authenticated encryption (continued). Collision resistant hash function (CRHF). Birthday attacks on CRHF. Merkle\u2013Damg\u00e5rd transform. Readings: [KL 6.1.1, BS 8.1] Definition of CRHF. [KL 6.4.1, BS 8.3] Birthday attacks on CRHF. [KL 6.2, BS 8.4] Merkle\u2013Damg\u00e5rd transform. Pre10.pdf Post10.pdf Rec10 Oct 12 Topics: Hash-and-MAC. Applications of CRHF. Practical constructions of block ciphers. Readings: [KL 6.3.1, BS 8.2] Hash-and-MAC. [KL 6.6] Applications of CRHF. *[BS 8.7, 8.9, 8.10, 8.12] Additional applications of CRHF. [KL 7.2.1] Substitution-Permutation Network (SPN). Pre11.pdf Post11.pdf Rec11 Oct 17 Topics: Substitution-permutation networks (continued). Feistel networks. Data encryption standard (DES). Block cipher modes of operation. Readings: [KL 7.2.1-7.2.5] Practical constructions of block ciphers. [KL 3.6.3, R 8.1] Block cipher modes of operation. [R 5.1, 6.2] PRG from block cipher. Pre12.pdf Post12.pdf Rec12 Oct 19 Topics: Block cipher modes of operation (continued). Practical constructions of hash functions. Midterm review. Selected questions from HW 1-4. Readings: [KL 7.3] Practical constructions of hash functions. Pre13.pdf Rec13 Oct 24 In-Class Midterm Oct 26 Topics: One-way functions. Hard-core predicates. Theoretical constructions of symmetric-key primitives. Readings: [KL 8.1.1-8.1.2] Definition and candidates of one-way functions. [KL 8.1.3, 8.3] Hard-core predicates. [KL 8.2, 8.4] Construction of PRG from OWP. *[KL 8.5] Construction of PRF from PRG (GGM tree). *[KL 8.7] Assumptions for symmetric-key cryptography. Pre14.pdf Post14.pdf Rec14 Oct 31 Topics: Basic group theory. Factoring and RSA assumptions. Discrete-Log and Diffie-Hellman assumptions. Readings: [KL 9.1.1-9.1.4, 9.3.1] Basic group theory. *[KL 9.2.1-9.2.2] Generating random primes. [KL 9.2.3-9.2.4, BS 10.3] Factoring and RSA assumptions. [KL 9.3.2, BS 10.5] Discrete-Log and Diffie-Hellman assumptions. [KL 9.4, BS 10.6] Cryptographic applications. Pre15.pdf Post15.pdf Rec15 Nov 2 Topics: Factoring/RSA and DLOG/CDH/DDH assumptions. Key exchange and Diffie-Hellman protocol. Public-key encryption definitions. El Gamal encryption. RSA-based encryption. Trapdoor permutations. Readings: [KL 11.3, BS 10.4] Key exchange and Diffie-Hellman protocol. [KL 12.2, BS 11.2-11.3] Public-key encryption definitions. [KL 12.4.1, BS 11.5] El Gamal encryption. [KL 12.5.1-12.5.3] RSA-based encryption. [KL 15.1.1, BS 10.3, Pass-Shelat 2.11] Trapdoor permutations. Pre16.pdf Post16.pdf Rec16 Nov 7 Topics: Public-key encryption from trapdoor permutations. Post-quantum PKE from learning with errors (LWE) assumption. Readings: [KL 15.1.2, BS 11.4] Public-key encryption from trapdoor permutations. *[KL 14.1-14.2] Quantum algorithms and their impact on cryptography. [KL 14.3] Learning with errors (LWE) assumption and Regev encryption. Pre17.pdf Post17.pdf Rec17 Nov 9 Topics: Homomorphic property of encryption schemes. Somewhat homomorphic encryption (SWHE) over integers. SWHE from LWE (GSW). Readings: [Halevi's tutorial Sec. 1] Introduction to FHE. [ Paper ] A conceptually simple construction of FHE over integers. [Halevi's tutorial Sec. 3] GSW protocol. Pre18.pdf Post18.pdf Rec18 Nov 14 Topics: SWHE from LWE (continued). Bootstrapping SWHE to FHE. Digital signatures. Hash-and-sign paradigm. RSA-based signatures. Random oracle model. Readings: [Halevi's tutorial Sec. 3] GSW protocol. [KL 13.1-13.2] Definition of digital signatures. [KL 13.3] Hash-and-sign paradigm. [KL 13.4] RSA-based signatures. Pre19.pdf Post19.pdf Rec19 Nov 16 Topics: Identification schemes. Fiat-Shamir transform. Schnorr's identification/signature schemes. Definition of zero-knowledge proofs (ZKPs). Readings: [KL 13.5] Signatures from DLOG. [Lindell's notes Sec. 5.3, 6.1] Definition of ZKPs. [Lindell's notes Sec. 6.2] Perfect ZKP for Diffie-Hellman tuples. Pre20.pdf Post20.pdf Rec20 Nov 21 Topics: Perfect ZKP for Diffie-Hellman tuples (continued). ZKP for all NP. Non-interactive zero-knowledge proofs (NIZKs). Readings: [Lindell's notes Sec. 6.2] Perfect ZKP for Diffie-Hellman tuples. [Lindell's notes Sec. 7] ZKP for all NP. Pre21.pdf Post21.pdf Rec21 Nov 23 NO LECTURE (Thanksgiving) Nov 28 Topics: ZKP for all NP (continued). Non-interactive zero-knowledge proofs (NIZKs). Definitions of secure multi-party computation. Readings: [Lindell's note Sec. 1-2, 5] Motivation, definition, and practical use cases of MPC. [Lindell's tutorial Sec. 4.2, 6.2] Formal definitions for semi-honest and malicious MPC. Pre22.pdf Post22.pdf Rec22 Nov 30 Topics: Definitions of MPC (continued). Private set intersection. Oblivious transfer. Readings: [ Paper by Ion et al.] DDH-based PSI-sum with cardinality. [Lindell's note Sec. 3] Feasibility results of MPC. [Chou-Orlandi's paper ] A simple OT protocol. Pre23.pdf Post23.pdf Rec23 Dec 5 Topics: Oblivious transfer (continued). Semi-honest MPC for any function (GMW protocol). Malicious MPC (GMW compiler). Readings: [Evans-Kolesnikov-Rosulek's book Ch. 3.2] GMW protocol. [Evans-Kolesnikov-Rosulek's book Ch. 6.5.1] GMW compiler. Pre24.pdf Post24.pdf Rec24 Dec 7 Topics: Program obfuscation. Final review. Readings: *[Jain-Lin-Sahai's paper ] Indistinguishability obfuscation from well-founded assumptions. Pre25.pdf Post25.pdf Rec25 Calendar Zoom links are included in the Google Calendar event, as well as in the Hours queue. Staff Peihan Miao Professor | pmiao Hello! I work on cryptography, theory, and security. I'm excited about bridging the gap between theory and practice in cryptography. Pronouns: she/her/hers Leah Namisa Rosenbloom Grad TA | lrosenb3 I am studying cryptography for grassroots organizing with Anna Lysyanskaya and Seny Kamara. My favorite cryptographic primitive is a zero-knowledge proof of knowledge. Pronouns: they/them Simon Greenblatt UTA | scamposg Hi! I'm a second year Cybersecurity Master's student and I like to climb volcanos. Pronouns: he/him/his Copyright \u00a9 2023 CSCI 1510 @ Brown", "https://cs.brown.edu/courses/csci1550/": "CSCI 1550 \u2014 Probabilistic Methods in Computer Science Also available as CSCI 2540 for 2000-Level credit Course Information LectureSlides Calendar Homework About CSCI 1550/2540, Spring 2024, taught by Professor Eli Upfal . This is a course on the mathematics that motivates, formulates, and explains many of the great successes of computing, including statistical machine learning, Monte Carlo methods, and modern cryptography. Probability, randomness, and statistics play a key role in these and almost any other modern computer science application. This course introduces the novel mathematical and computation methods that were developed at the interplay of probability and computing. The course focuses on mathematical models, theorems and proofs, and leaves implementation and experiments to other courses. For more details, please refer to the course information page. Last Updated: Jan 2024", "https://csci-1460-computational-linguistics.github.io/": "cs1460 home resources lectures assignments staff hours Natural Language Processing This course provides an introduction to the field of Natural Language Processing (NLP). We will focus on a range of NLP tasks, including machine translation, question answering, text classification, as well as the underlying linguistic problems (syntax, semantics, morphology) that make building sytems to solve these tasks so challenging. This course will cover both \"traditional\" (machine learning, information theoretic) approaches as well as \"new\" deep learning approaches. Topics include: Text Classification Word Embeddings Language Modeling Pretraining, Finetuning Prompting and In-Context Learning Machine Translation POS Tagging Syntactic and Semantic Parsing NLP and Social Responsibility Topics include: Text Classification Word Embeddings Language Modeling Pretraining, Finetuning Prompting and In-Context Learning Machine Translation POS Tagging Syntactic and Semantic Parsing NLP and Social Responsibility prerequisites The course will be taught in Python and assumes coding fluency (or a willingness to learn Python on your own time).Familiarity with machine learning, deep learning, and/or linguistics is encouraged but not strictly required. overview Instructor Ellie Pavlick Instructor Office Hours Schedule Zoom Meeting HTA Mailing List cs1460headtas@lists.brown.edu Location & Time Tuesdays & Thursdays 2:30- 3:50pm List 120 Course Materials Syllabus EdStem Forms Waitlist Anonymous Feedback Form Blocklist Form Collaboration Policy Form grading Below is the grading scheme for the course: \u00a9 2023 CS1460 Staff | Computer Science Department | Brown University Thank you to 2021 CS1951A Staff for website design! var data = [ { name: \"Assignments\", value: 60, realvalue: 60 }, { name: \"Quizzes\", value: 20, realvalue: 20 }, { name: \"Final Project\", value: 15, realvalue: 15 }, { name: \"SRC Discussion\", value: 5, realvalue: 5} ]; var text = \"\"; var colors = [\"#ff5338\", \"#ffd724\", \"#2d9feb\", \"#b87aeb\"]; // var colors = [\"#005af1\", \"#005af1\", \"#005af1\"]; var width = 200; var height = 200; var thickness = 40; var duration = 750; var padding = 10; var opacity = 0.8; var opacityHover = 1; var otherOpacityOnHover = 0.8; var tooltipMargin = 13; var radius = Math.min(width - padding, height - padding) / 2; var color = d3.scaleOrdinal(d3.schemeCategory10); var pie_svg = d3 .select(\"#pie-chart\") .append(\"svg\") .attr(\"class\", \"pie\") .attr(\"width\", width) .attr(\"height\", height); var g = pie_svg .append(\"g\") .attr(\"transform\", \"translate(\" + width / 2 + \",\" + height / 2 + \")\"); var arc = d3.arc().innerRadius(0).outerRadius(radius); var pie = d3 .pie() .value(function (d) { return d.value; }) .sort(null); var path = g .selectAll(\"path\") .data(pie(data)) .enter() .append(\"g\") .append(\"path\") .attr(\"d\", arc) .attr(\"fill\", (d, i) => colors[i]) .style(\"opacity\", opacity) .on(\"mouseover\", function (d) { d3.selectAll(\"path\").style(\"opacity\", otherOpacityOnHover); d3.select(this).style(\"opacity\", opacityHover); let g = pie_svg .style(\"cursor\", \"pointer\") .append(\"g\") .attr(\"class\", \"tooltip\") .style(\"opacity\", 0); g.append(\"text\") .attr(\"class\", \"name-text\") .text(`${d.data.name} (${d.data.realvalue}%)`) .attr(\"text-anchor\", \"middle\"); let text = g.select(\"text\"); let bbox = text.node().getBBox(); let padding = 2; g.insert(\"rect\", \"text\") .attr(\"x\", bbox.x - padding) .attr(\"y\", bbox.y - padding) .attr(\"width\", bbox.width + padding * 2) .attr(\"height\", bbox.height + padding * 2) .style(\"fill\", \"white\") .style(\"opacity\", 0.75); }) .on(\"mousemove\", function (d) { let mousePosition = d3.mouse(this); let x = mousePosition[0] + width / 2; let y = mousePosition[1] + height / 2 - tooltipMargin; let text = d3.select(\".tooltip text\"); let bbox = text.node().getBBox(); if (x - bbox.width / 2 < 0) { x = bbox.width / 2; } else if (width - x - bbox.width / 2 < 0) { x = width - bbox.width / 2; } if (y - bbox.height / 2 < 0) { y = bbox.height + tooltipMargin * 2; } else if (height - y - bbox.height / 2 < 0) { y = height - bbox.height / 2; } d3.select(\".tooltip\") .style(\"opacity\", 1) .attr(\"transform\", `translate(${x}, ${y})`); }) .on(\"mouseout\", function (d) { pie_svg.style(\"cursor\", \"none\").select(\".tooltip\").remove(); path.style(\"opacity\", opacity); }) .on(\"touchstart\", function (d) { pie_svg.style(\"cursor\", \"none\"); }) .each(function (d, i) { this._current = i; }); // MAKING A LEGEND let legend = d3 .select(\"#pie-legend\") .append(\"div\") .attr(\"class\", \"legend\") .style(\"margin-top\", \"0px\"); let keys = legend .selectAll(\".key\") .data(data) .enter() .append(\"div\") .attr(\"class\", \"key\") .style(\"display\", \"flex\") .style(\"align-items\", \"center\") .style(\"margin-right\", \"20px\"); keys .append(\"div\") .attr(\"class\", \"symbol\") .style(\"height\", \"10px\") .style(\"width\", \"10px\") .style(\"margin\", \"5px 5px\") .style(\"background-color\", (d, i) => colors[i]); keys .append(\"div\") .attr(\"class\", \"name\") .text((d) => `${d.name} (${d.realvalue}%)`); keys.exit().remove(); /*----- Factor this stuff out later ------*/ //set the dimensions and margins of the graph var colors_bar = [ \"#b87aeb\", \"#ff5338\", \"#ffa10a\", \"#ffdd1f\", \"#8feb3f\", \"#30e39b\", \"#2d9feb\", ]; var rgba_bar = [ \"rgba(184, 122, 235, 0.8)\", \"rgba(255, 83, 56, 0.8)\", \"rgba(255, 161, 10, 0.8)\", \"rgba(255, 221, 31, 0.8)\", \"rgba(143, 235, 63, 0.8)\", \"rgba(48, 227, 155, 0.8)\", \"rgba(45, 159, 235, 0.8)\", ]; var margin = { top: 20, right: 20, bottom: 120, left: 50 }, bar_width = 480 - margin.left - margin.right, bar_height = 430 - margin.top - margin.bottom; // set the ranges var bar_x = d3.scaleBand().range([0, bar_width]).padding(0.35); var bar_y = d3.scaleLinear().range([bar_height, 0]); function make_y_gridlines() { return d3.axisLeft(bar_y).ticks(8); } // append the svg object to the body of the page // append a 'group' element to 'svg' // moves the 'group' element to the top left margin var bar_svg = d3 .select(\"#barchart\") .append(\"svg\") .attr(\"width\", bar_width + margin.left + margin.right) .attr(\"height\", bar_height + margin.top + margin.bottom) .append(\"g\") .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\"); // get the data d3.csv(\"bargraph2.csv\", function (error, data) { if (error) throw error; // Scale the range of the data in the domains bar_x.domain( data.map(function (d) { return d.Topic; }) ); bar_y.domain([0, 8]); var tooltip = d3 .select(\"#barchart\") .append(\"div\") .attr(\"class\", \"toolTip\"); bar_svg .append(\"g\") .attr(\"class\", \"grid\") .call(make_y_gridlines().tickSize(-bar_width).tickFormat(\"\")); // append the rectangles for the bar chart bar_svg .selectAll(\".bar\") .data(data) .enter() .append(\"rect\") .attr(\"class\", \"bar\") .attr(\"fill\", function (d) { return colors_bar[parseInt(d.Number) % 7]; }) .attr(\"x\", function (d) { return bar_x(d.Topic); }) .attr(\"width\", bar_x.bandwidth()) .attr(\"y\", function (d) { return bar_y(d.Number); }) .attr(\"height\", function (d) { return bar_height - bar_y(d.Number); }) .on(\"mousemove\", function (d, i) { tooltip // .style(\"left\", d3.event.pageX - 100 + \"px\") // .style(\"top\", d3.event.pageY - 200 + \"px\") .style(\"left\", d3.event.pageX - 50 + \"px\") .style(\"top\", d3.event.pageY - 70 + \"px\") .style(\"display\", \"inline-block\") .style(\"background-color\", rgba_bar[(i + 1) % 7]) .style(\"color\", \"black\") .html(d.desc1 + \"<br>\" + d.desc2); }) .on(\"mouseout\", function (d) { tooltip.style(\"display\", \"none\"); }); // add the x Axis bar_svg .append(\"g\") .attr(\"class\", \"xaxis\") .attr(\"transform\", \"translate(0,\" + bar_height + \")\") .call(d3.axisBottom(bar_x)); bar_svg .selectAll(\".xaxis text\") .style(\"text-anchor\", \"end\") .attr(\"dx\", \"-.8em\") .attr(\"dy\", \".15em\") .attr(\"transform\", \"rotate(-65)\"); var labels = [ \"\", \"Red\", \"Orange\", \"Yellow\", \"Green\", \"Mint\", \"Blue\", \"Purple\", \"\", ]; // add the y Axis bar_svg .append(\"g\") .attr(\"class\", \"yaxis\") .call( d3.axisLeft(bar_y).tickFormat(function (d, i) { return labels[i]; }) ); bar_svg.selectAll(\".xaxis .tick line\").remove(); });", "https://cs.brown.edu/courses/csci1600/2021/": "Link Search Menu Expand Document CSCI 1600, Fall 2021 Information Office Hours Schedule Labs \u2605Circuit Checklist \u2605Component glossary 01 Introduction to Arduino 02 Sensors, Actuators, and I/O 03 Embedded Programming and Memory 04 Clocks, Timers, and Watchdogs 05 Embedded Design and Engineering 06 Testing and Debugging 07 Networking and communication 08 Runtime monitoring Homeworks Homework 1 Homework 2 Homework 3 Homework 4 Homework 5 Homework 6 Homework 7 Homework 8 Project Information Staff This site uses Just the Docs , a documentation theme for Jekyll. Canvas Ed Discussion Embedded and Real-Time Software Latest announcements No Lab Section on Sep 9 First Tuesday lab is September 14 and first Thursday lab is September 16. See you then! Welcome! Welcome to the Fall 2021 course page for CSCI1600! All announcements Welcome to CSCI 1600, Embedded and Real-Time Systems! This course introduces the concepts necessary to write software for embedded and real time systems, such as those found in Internet of Things devices, robots, and cars. The course emphasizes how embedded systems differ from traditional software systems and how these differences translate to challenges in the design, development, testing, and deployment of these systems. How do you design software that may be constrained by power and memory usage and timing? What about software that needs to interface with sensors and other devices in the \u201creal world,\u201d and that may have safety implications if it malfunctions? How do you model and verify devices that are interacting with the physical world? This course aims to teach you specific engineering skills and considerations so that you can address these challenges. Course policies and expectations can be found on the Information page.", "https://brown-deep-learning.github.io/dl-website-s24/": "Welcome to Deep Learning DIVE IN \u2303 Deep Learning \u2630 Lectures Assignments Labs Hours Resources Staff Welcome to Deep Learning! Over the past few years, Deep Learning has become a popular area, with deep neural network methods obtaining state-of-the-art results on applications in computer vision (Self-Driving Cars), natural language processing (Google Translate), and reinforcement learning (AlphaGo). These technologies are having transformative effects on our society, including some undesirable ones (e.g. deep fakes). This course is there to give students a practical understanding of how Deep Learning works, how to implement neural networks, and how to apply them ethically. We introduce students to the core concepts of deep neural networks and survey the techniques used to model complex processes within the contexts of computer vision and natural language processing. Throughout the course, we emphasize and require students to think critically about potential ethical pitfalls that can result from mis-application of these powerful models. The course is taught using the Tensorflow deep learning framework. Course CSCI 1470/2470 Professor Ritambhara Singh Location Salomon Center DECI Time MWF 12:00-12:50pm Syllabus Canvas Edstem Gradescope The Latest Lecture Attention Recording Adobe Acrobat Reader icon Slides Homework Conceptual Language Models Due 3/18 Programming Language Models Due 3/22 Lab Debiasing Checkoff by 3/12 Lectures Monday, Wednesday, and Friday at 12:00-12:50pm in Salomon Center DECI Course offered in-person with recordings made available for reviewing. This schedule is subject to change. Week 1-4 Deep Learning Basics 1/24 Welcome to Deep Learning Recording Adobe Acrobat Reader icon Slides 1/26 Intro to Machine Learning Recording Adobe Acrobat Reader icon Slides 1/29 Perceptron and MNIST Recording Adobe Acrobat Reader icon Slides 1/31 Perceptron (continued) and Loss Functions Recording Adobe Acrobat Reader icon Slides 2/2 Optimization and Backpropagation Recording Adobe Acrobat Reader icon Slides 2/5 Backpropagation (continued) Recording Adobe Acrobat Reader icon Slides 2/7 Autodiff Recording Adobe Acrobat Reader icon Slides 2/9 Matrix representation of NNs + GPUs + Intro to Tensorflow Recording Adobe Acrobat Reader icon Slides 2/12 Multi-layer NNs and Activation Functions Recording Adobe Acrobat Reader icon Slides 2/14 Multi-layer NNs (contd.) + Intro to CNNs Recording Adobe Acrobat Reader icon Slides Week 4-6 CNNs 2/16 CNNs Recording Adobe Acrobat Reader icon Slides 2/21 Multi-layer CNNs Recording Adobe Acrobat Reader icon Slides 2/23 Overfitting and regularization Recording Adobe Acrobat Reader icon Slides 2/26 Language Models and Word Embeddings Recording Adobe Acrobat Reader icon Slides Week 6-9 Language Models 2/28 Feedforward language models Recording Adobe Acrobat Reader icon Slides 3/1 Recurrent neural networks Recording Adobe Acrobat Reader icon Slides 3/4 LSTMs + GRUs Recording Adobe Acrobat Reader icon Slides 3/6 Machine Translation Recording Adobe Acrobat Reader icon Slides 3/8 Attention Recording Adobe Acrobat Reader icon Slides 3/11 Transformers 3/13 Transformers (continued) and scaling deep learning systems 3/15 Scaling deep learning systems 3/18 Multi-modal learning using contrastive learning (guest lecture by Michal) Week 9 Interpretation 3/20 Interpretation of Neural Networks Week 10-11 Probabilistic Models 4/1 Unsupervised learning, Autoencoders 4/3 Variational Autoencoders 4/5 VAEs contd. and Generative adversarial networks 4/8 VAE and GANs contd + Deepfakes 4/10 Diffusion (guest lecture by Calvin Luo) 4/12 Diffusion continued (guest lecture by Calvin Luo) Week 12-13 Reinforcement Learning 4/15 Introduction to reinforcement learning 4/17 Value Iteration 4/19 Deep Q learning 4/22 Policy gradient methods 4/24 Actor-critic methods Week 13 GNNs 4/26 Graph neural networks Assignments Assignments will be released at noon and due at 6:00pm U.S. Eastern Time. This schedule is subject to change. Assignment Out Due 0C Math Review Wednesday 1/24 Friday 2/2 0P Setup Wednesday 1/24 Friday 2/2 1C Beras Part 1: Conceptual Wednesday 1/31 Friday 2/9 1P Beras Part 1: Programming Wednesday 1/31 Wednesday 2/14 2C Beras Part 2: Conceptual Wednesday 2/14 Friday 2/23 2P Beras Part 2: Programming Wednesday 2/14 Wednesday 2/28 3C CNNs: Conceptual Wednesday 2/28 Monday 3/4 3P CNNs: Programming Wednesday 2/28 Friday 3/8 4C LMs: Conceptual Monday 3/11 Monday 3/18 4P LMs: Programming Monday 3/11 Friday 3/22 5C Image Captioning: Conceptual Monday 4/1 Monday 4/8 5P Image Captioning: Programming Monday 4/1 Friday 4/12 6C Variational Autoencoders: Conceptual Friday 4/12 Friday 4/19 6P Variational Autoencoders: Programming Friday 4/12 Friday 4/26 Final Project See the handout for full details Deliverable Date/Due Project Check-in 1 Week beginning 3/4 Project Proposal Friday 3/15 6:00pm ET Project Check-in 2 Week beginning 4/8 Project Check-in 3 Week beginning 4/22 Final Check-in (Optional) Week beginning 4/29 Deep Learning Day Monday 5/6 & Tuesday 5/7 Final Projects Due Friday 5/10 6:00pm ET Labs Check out this guide on opening labs and using Google Colaboratory . This schedule is subject to change. Lab From Until 0 Introduction to NumPy - No Checkoff Wednesday 1/24 Monday 1/29 1 Introduction to Machine Learning Wednesday 1/31 Tuesday 2/6 2 Optimizers Wednesday 2/7 Tuesday 2/13 3 TensorFlow Wednesday 2/14 Friday 2/16 or Tuesday 2/27* 4 CNNs Wednesday 2/21 Tuesday 2/27 5 Debiasing Wednesday 3/6 Tuesday 3/12 6 LIME Wednesday 3/20 Tuesday 4/2 7 Autoencoders Wednesday 4/3 Tuesday 4/9 8 GANs Wednesday 4/10 Tuesday 4/16 9 Reinforcement Learning Wednesday 4/17 Tuesday 4/23 *Lab 3 (Tensorflow): Those with lab sections on Wednesday, Thursday, and Friday will complete the lab during the week of 2/14. Those with lab sections on Saturday, Sunday, Monday, and Tuesday will complete the lab asynchronously and get it checked off the following week (the week of 2/25). Hours Resources Forms Collaboration Form Anonymous Feedback Form Guides and Tutorials GitHub Guide Opening Up Labs Google Colaboratory Tutorial Working Remotely FastX Setup Guide ssh Guide Department Resources Capstone Information Linux Cheat Sheet Setting Up Email IT Services IT Loaner Laptops Organizations CAPS Women in Computer Science Mosaic+ Title IX Health and Wellness Advocates Diversity and Inclusion CS DUG Staff Professor: cs_deeplearning@brown.edu Professor and HTAs: cs1470headtas@lists.brown.edu All TAs: cs1470tas@lists.brown.edu Do not email sensitive information, including Health Services & Dean's Notes, to any HTAs, UTAs, or STAs. Professor Ritambhara Singh she/her Paracanthurus hepatus Graduate TA Michal Golovanevsky she/her Octopus Mascot Jelly any Jellyfish HTAs Raymond Dai he/him Manta Ray Erica Song she/her Sea Otter Joe Dodson he/him Orca Karan Kashyap he/him Octopus Pranav Mahableshwarkar he/him Blobfish Earth Mokkamakkul he/him Manatee UTAs Julian Dai he/him Crab Calvin Eng he/him Whale Taj Gillin he/him Starfish Spandan Goel he/him Dolphin Naicheng (Arnie) He he/him Sea Turtle Amanda Hernandez Sandate she/her Walrus Woody Hulse he/him Anglerfish Kelvin Jiang he/him Penguin Bumjin Joo he/him Sea Otter Preetish Juneja he/him Dolphin Mohammed Khan he/him Octopus Philip LaDuca he/him Oyster Kyle Lam he/him Jellyfish Jennifer Li she/her Blue Whale Alyssa Loo she/her Narwhal Michael Lu he/him Sea Otter Ben Maizes he/him Narwhal Ken Ngamprasertsith he/him Elephant Seal Sophia Fang she/her Seahorse Aayush Setty he/him Whale Shark Jason Silva he/him Penguin Aryan Singh he/him Blue Whale Quinn Straus he/him Octopus Torsten Ullrich he/him Otter Mikayla Walsh she/her Squid Emily Wang she/her Beluga Whale Xilin (Rice) Wang he/him Manta Ray Xu he/him Dolphin Enyan Zhang he/him Flapjack Octopus Alex Zheng he/him Jellyfish Alex Zhou he/him Penguin STAs & UTA-STAs Naphat Permpredanun he/him \u2022 STA Orca Sameer Sinha he/him \u2022 STA Otter Kyle Yeh he/him \u2022 UTA-STA Marlin Lingze Zhang he/him \u2022 UTA-STA Dolphin", "https://cs.brown.edu/courses/csci1600/2022/": "Link Search Menu Expand Document CSCI 1600, Fall 2022 Information Office Hours Schedule Labs \u2605Circuit Checklist \u2605Component glossary \u2605Connectivity Troubleshooting \u2605Reading MCU datasheets 01 Introduction to Arduino 02 Sensors, Actuators, and I/O 03 Embedded Programming and Memory 04 Clocks, Timers, and Watchdogs 05 Embedded Design and Engineering 06 Testing and Debugging 07 Networking and communication 08 Runtime monitoring Project Information Staff This site uses Just the Docs , a documentation theme for Jekyll. Ed Discussion Gradescope Anonymous feedback form Embedded and Real-Time Software Latest announcements Welcome! Welcome to the Fall 2022 course page for CSCI1600! To be fully enrolled in the class, you should register for one of the two lab sessions. The first lab will be on Monday (September 12) and Tuesday (September 13). All waitlist requests will be handled through Homework 0 (linked from the Schedule page) All remaining course announcements will be made through the EdSTEM board . . All announcements Welcome to CSCI 1600, Embedded and Real-Time Systems! This course introduces the concepts necessary to write software for embedded and real time systems, such as those found in Internet of Things devices, robots, and cars. The course emphasizes how embedded systems differ from traditional software systems and how these differences translate to challenges in the design, development, testing, and deployment of these systems. How do you design software that may be constrained by power and memory usage and timing? What about software that needs to interface with sensors and other devices in the \u201creal world,\u201d and that may have safety implications if it malfunctions? How do you model and verify devices that are interacting with the physical world? This course aims to teach you specific engineering skills and considerations so that you can address these challenges. Course policies and expectations can be found on the Information page. Anonymous Feedback Form Previous offerings By Prof. Zizyte: 2021 By Prof. Reiss: (links to be updated soon)", "https://cs.brown.edu/courses/csci1680/f14/syllabus.html": "CSCI-1680 :: Computer Networks :: Fall 2014 CSCI-1680: Computer Networks Syllabus CS 168 Home Syllabus Calendar Assignments Exams Announcements Textbooks You can follow the content of the course using either one of two books: Computer Networks: A Systems Approach (6th edition), by Larry Peterson and Bruce Davie. Computer Networking: A Top-Down Approach (6th edition), by James F. Kurose and Keith W. Ross We will indicate besides each lecture below which sections of Peterson correspond to the lecture. Programming Help C mini-course Beej's Guide to Network Programming PThreads I and PThreads II Introduction to Asynchronous Programming Sockets Helpsession Grading Your final grade for the course will be based on the following weights: 45% Programing Projects (4) 5% Snowcast, 10% IP, 25% TCP, 5% Final Project 15% Homeworks (3) 15% Midterm Exam 25% Final Exam The three written homework assignments will all be done individually.The first program, Snowcast, will also be done individually, while the remainingprograms will be completed in groups of two (2). Schedule Date Topics Notes Readings Thu 09/04 L1 - Intro [ pdf ] [ pptx ] Snowcast out 1.1-1.3 Tue 09/09 L2 - Layering [ pdf ] [ pptx ] 1.4, 1.5 Thu 09/11 L3 - Physical Layer [ pdf ] [ pptx ] Snowcast milestone 2.1, 2.3 Tue 09/16 L4 - Link Layer [ pdf ] [ pptx ] 2.4,2.5 Thu 09/18 L5 - Switching [ pdf ] [ pptx ] Snowcast due (11:59pm); HW1 out 2.6,3.1 Tue 09/23 L6 - Link Layer Wrap-up Use the slides from lecture 05 3.1 (cont) Thu 09/25 L7 - IP Intro [ pdf ] [ pptx ] HW1 due (11:59pm); IP Assignment out 4.1.1-4.1.7, 4.3.1-4.3.2 Tue 09/30 L8 - IP Continued [ pdf ] [ pptx ] 4.2 Thu 10/02 L9 - Intra-domain routing IP Milestone. Use slides from lecture 08 4.3.3 Tue 10/07 No Class Rodrigo out for a conference Thu 10/09 L10 - Inter-domain routing 1 (Intro to BGP) [ pdf ] [ pptx ] HW2 out 4.3.3 Tue 10/14 L11 - Inter-domain routing 2 (Policy and Security) [ pdf ] [ pptx ] 4.3.3, but goes beyond book. BGP Wedgies are described in RFC 4264 Thu 10/16 L12 - Network Layer Wrap-up [ pdf ] [ pptx ] 4.1.7 (ICMP), 4.3.5 (IPv6), 4.4.1 (Multicast) Fri 10/17 HW2 due (11:59pm) Mon 10/20 TCP out Tue 10/21 Midterm Up to material covered on 10/16. Thu 10/23 L13 - Transport Layer I [ pdf ] [ pptx ] UDP and TCP intro. 5.1, 5.2.1-5.2.3 Tue 10/28 L14 - Transport Layer II [ pdf ] [ pptx ] 5.2.4-5.2.8; 6.3 Thu 10/30 L15 - Fun with Congestion Control [ pdf ] [ pptx ] HW3 Out 6.4.3. Some content not in book. Sat 11/01 TCP milestone I Tue 11/04 L16 - Transport Layer Wrapup Thu 11/06 L17 - DNS [ pdf ] [ pptx ] 9.1.3 Tue 11/11 L18 - Web [ pdf ] [ pptx ] HW3 due 9.12 Sat 11/08 TCP milesonte II Thu 11/13 L19 - CDN and P2P [ pdf ] [ pptx ] 9.4-9.4.3 Tue 11/18 L20 - Data / RPC [ pdf ] [ pptx ] How to write your own application-level protocol. 5.3 Thu 11/20 L21 - Wireless [ pdf ] [ pptx ] 2.8 (intro), 2.8.2 Tue 11/25 L22 - Security [ pdf ] [ pptx ] 8.1, 8.2, 8.4.3 Thu 11/27 No class Thanksgiving Mon 12/01 Final Project Out Tue 12/02 L23 - SDNs [ pdf ] [ pptx ] Thu 12/04 L23 - Wrap-up [ pdf ] [ pptx ] Sun 12/07 Start Reading Period Thu 12/11 Final project due Sat 12/20 Final Exam, 2 pm Everything presented in class is fair game. More emphasis on material after midterm. CSCI-1680 :: Fall 2014 :: Rodrigo Fonseca All materials in this site are licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 3.0 United States License . Last modified: 2014-12-15 17:00:36 -0500. Page design adapted from the glued ideas subtle wp theme. var gaJsHost = ((\"https:\" == document.location.protocol) ? \"https://ssl.\" : \"http://www.\"); document.write(unescape(\"%3Cscript src='\" + gaJsHost + \"google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E\")); try { var pageTracker = _gat._getTracker(\"UA-371922-7\"); pageTracker._trackPageview(); } catch(err) {}", "https://cs.brown.edu/courses/csci1650/": "Toggle navigation CSCI 1650 \u2013 Software Security and Exploitation Home Lectures Assignments CTF-1 CTF-2 CTF-3 CTF-4 Overview CSCI 1650 covers software exploitation techniques and state-of-the-practice mechanisms forhardening software. The course begins with a summary ofprevalent software defects, typically found inapplications written in memory unsafe languages,like C/C++ , and proceeds with studyingtraditional and modern exploitation techniques, rangingfrom classical code injection and code reuse up to the latest goodies ( e.g., JIT-ROP ).It also covers defenses against certain vulnerabilityclasses and the way(s) to bypass them. Students will beintroduced to advanced software exploitation techniquesand countermeasures, and study (in depth) the boundariesand effectiveness of standard hardening mechanisms,such as address space randomization and stack and heap protections . syllabus.pdf Prerequisites CSCI 1670 (Operating Systems) || CSCI 0330 (Introduction to Computer Systems) || CSCI 0300 (Fundamentals of Computer Systems) Grading 10% Participation (Ed Discussion) 90% Assignments ( CTF -like write-ups) 0% Midterm 0% Final Acknowledgments This course would not be possible without the support andassistance of the following people: Fall '22: Oren Kohavi (HTA), Floria Tsui (TA), Guangfeng Xu (TA), John Fay (TA), Kaki Su (TA), Linus Sun (TA), Vanessa Chang (TA) Fall '21: Zachary Espiritu (HTA), Andrew Boden (TA), Andrew Cooke (TA), Maura Driscoll (TA), Ben Givertz (TA), Brandon Lee (TA), Zachary Mothner (TA), Ian Rackow (TA), Daniel Ramirez (TA), Alex Reuter (TA), Marina Triebenbacher (TA) Fall '20: Brian Tracy (HTA), Zsozso Biegl (TA), Ethan Greenberg (TA), Peter Harvie (TA), Garret Kern (TA), Cat Nguyen (TA), Yue Sun (TA) Fall '19: Alexander Gaidis (HTA), Di Jin (GTA), Hannah Baackmaan-Friedlaender (TA), Changmin Teng (TA), David Liu (TA), Mneera Abdullah (TA) Fall '18: Bessie Jiang (HTA), Elisa Guerrant (TA), Yujun Qin (TA) Fall '17: Frederick Rice (HTA) Fall '16: Luke Camery (TA) Meetings MW 3PM \u2013 4:20PM (T hour) MacMillan 117 ( Zoom ) Instructor Vasileios (Vasilis) Kemerlis https://cs.brown.edu/~vpk echo @cs.brown.edu|sed 's/^/vpk/' Zoom (Mon. 6PM \u2013 7PM) Teaching Assistants Oren Kohavi (HTA) echo @cs.brown.edu|sed 's/^/okohavi/' CIT 348 + Zoom (Wed. 12PM \u2013 2PM) Austin Phan (TA) echo @cs.brown.edu|sed 's/^/aphan11/' CIT 102 + Zoom (Sun. 2PM \u2013 4PM) Hayley Kang (TA) echo @cs.brown.edu|sed 's/^/hkang39/' Zoom (Sat. 2PM \u2013 4PM) Isha Mody (TA) echo @cs.brown.edu|sed 's/^/imody/' Zoom (Mon. 6PM \u2013 8PM) Kathy Li (TA) echo @cs.brown.edu|sed 's/^/kli117/' Zoom (Fri. 9:30AM \u2013 11:30AM) Keitaro Nishijima (TA) echo k^nishiji@cs.brown.edu|tr -d ^ Zoom (Thu. 8PM \u2013 10PM) Maya Fleischer (TA) echo m^fleisc1@cs.brown.edu|tr -d ^ Zoom (Mon. 4PM \u2013 6PM) Riyao Lin (TA) echo @cs.brown.edu|sed 's/^/rlin45/' Zoom (Wed. 8:30PM \u2013 10:30PM) Stephen Rosa (TA) echo @cs.brown.edu|sed 's/^/srosa5/' CIT 348 + Zoom (Tue. 12PM \u2013 2PM) Treetased Vividhwara (TA) echo t^vividhw@cs.brown.edu|tr -d ^ CIT 348 + Zoom (Thu. 12PM \u2013 2PM) Communication cs1650tas@lists.brown.edu Ed Discussion Hours TA Hours (Google Calendar) Anonymous Feedback Form Announcements 12/06/2023 Review Day! 12/04/2023 Lecture 0x18 posted. 11/29/2023 Lecture 0x17 posted. 11/27/2023 Assignment 0x4 is due today. 11/27/2023 Lecture 0x16 posted. 11/20/2023 Lecture 0x15 posted. 11/15/2023 Assignment 0x4 is due on 11/27/2023 . 11/15/2023 Lecture 0x14 posted. 11/13/2023 Lecture 0x13 posted. 11/08/2023 Assignment 0x4 posted. 11/08/2023 Assignment 0x3 is due today. 11/08/2023 Lecture 0x12 posted. 11/06/2023 Lecture 0x11 posted. 11/01/2023 Assignment 0x3 is due on 11/08/2023 . 11/01/2023 Lecture 0x10 posted. 10/30/2023 Lecture 0xf posted. 10/25/2023 Assignment 0x3 posted. 10/25/2023 Assignment 0x2 is due today. 10/25/2023 Lecture 0xe posted. 10/23/2023 Lecture 0xd posted. 10/18/2023 Assignment 0x2 is due on 10/25/2023 . 10/18/2023 Lecture 0xc posted. 10/16/2023 Lecture 0xb posted. 10/11/2023 Assignment 0x2 posted. 10/11/2023 Assignment 0x1 is due today. 10/11/2023 Lecture 0xa posted. 10/09/2023 No class today. 10/04/2023 Assignment 0x1 is due on 10/11/2023 . 10/04/2023 Lecture 0x9 posted. 10/02/2023 Lecture 0x8 posted. 09/27/2023 Assignment 0x1 posted. 09/27/2023 Lecture 0x7 posted. 09/25/2023 Lecture 0x6 posted. 09/20/2023 Lecture 0x5 posted. 09/18/2023 Lecture 0x4 posted. 09/13/2023 Lecture 0x3 posted. 09/11/2023 Lecture 0x2 posted. 09/06/2023 Lecture 0x1 posted. 09/06/2023 Welcome to CSCI 1650! \u00a9 2023 vpk Department of Computer Science Brown University", "https://cs.brown.edu/courses/csci1515/spring-2024/": "CSCI 1515 Resources Assignments Lectures Calendar Staff \u2630 CSCI 1515 Assignments Lectures Calendar Resources Staff \u2630 CSCI 1515 Applied Cryptography [IMPORTANT] Room Change: Starting from Wednesday February 7th, lectures will take place in Smith-Buonanno 106 ! Introduction Welcome to Applied Cryptography (CSCI 1515) at Brown! This course teaches cryptography from a practical perspective and provides hands-on experience in building secure systems. We first introduce foundational cryptographic algorithms including secret-key and public-key encryption schemes, message authentication codes, digital signatures, and hash functions, from which you will build secure communication and authentication systems. More advanced topics that are covered include zero-knowledge proofs, secure multi-party computation, fully homomorphic encryption, post-quantum cryptography, and differential privacy. You will learn to use these cryptographic techniques to develop more advanced applications such as secure online anonymous voting, secure computation, and private information retrieval. Besides the high-level design of these cryptosystems, this course also provides hands-on experience implementing them using tools from the existing crypto libraries such as CryptoPP and Microsoft SEAL. All the projects are written in C++ as it is the most widely used language in crypto libraries. Lectures take place every Monday and Wednesday from 3:00 - 4:20 PM , in Smith-Buonanno 106 (Bio Med Center 202) (Friedman Hall 208) and on Zoom . Resources Quick Links Syllabus EdStem Gradescope Course Notes Textbooks [MOV] Handbook of Applied Cryptography by Alfred J. Menezes, Paul C. van Oorschot, and Scott A. Vanstone [BS] A Graduate Course in Applied Cryptography by Dan Boneh and Victor Shoup [KL] Introduction to Cryptography by Jonathan Katz and Yehuda Lindell [R] The Joy of Cryptography by Mike Rosulek Guides Development Environment Guide A Primer on Sockets A Primer on C++ Contact peihan_miao@brown.edu cs1515headtas@lists.brown.edu cs1515tas@lists.brown.edu Assignments Project Release Due Project 0&colon; Cipher Jan 24 Feb 9 Project 1&colon; Signal Feb 7 Feb 16 Project 2&colon; Auth Feb 16 Mar 1 Project 3&colon; Vote Mar 1 Mar 20 Project 4&colon; Yaos Mar 20 Apr 12 Project 5&colon; PIR Apr 12 Apr 26 Final Project Apr 12 May 10 Homework Release Due HW1 Feb 7 Feb 14 HW2 Feb 16 Feb 23 HW3 Mar 1 Mar 8 HW4 Mar 20 Apr 5 HW5 Apr 12 Apr 19 Gearups will be held on Zoom; please see the course calendar for links. Gearup Date Recording Slides Cipher/Setup Gearup Jan 29 Link Link Signal Gearup Feb 12 Link Link Auth Gearup Feb 19 Link Link Vote Gearup March 5 Link Link Yaos Gearup TBD Link Link PIR Gearup TBD Link Link #lecturetable .left {text-align:left;} Lectures * indicates optional reading material. Date Topics and Readings Pre-Lec Notes Post-Lec Notes Scribe Notes Zoom Rec Jan 24 Topics: Introduction and overview. Readings: Course Syllabus [MOV 1.1-1.2] Cryptography goals and primitives. Pre01.pdf Post01.pdf Link Rec01 Jan 29 Topics: Encryption scheme basics. One-time pad (OTP). Computational assumptions. Factoring assumption. Readings: *[KL 1.2] Kerckhoffs' Principle. [R 1.2] One-time pad. *[KL 2.4] Shannon's Theorem. *[KL 3.1] Computational security. [MOV 3.3] RSA problem. *[KL 9.2] Factoring assumption. *[BS 16.5] Quantum attacks on factoring. Pre02.pdf Post02.pdf Link Rec02 Jan 31 Topics: RSA assumption and RSA encryption. Diffie-Hellman assumptions. ElGamal encryption. Diffie-Hellman key exchange. Message integrity. RSA signature scheme. Readings: *[KL 9.2] RSA assumption. [KL 12.5.1] Plain RSA encryption. *[KL 12.5.2] Padded RSA encryption. [MOV 3.7, KL 9.3.1-9.3.2] Diffie-Hellman assumptions. *[BS 15.1-15.3] Elliptic curve groups. [MOV 8.4] ElGamal encryption. [MOV 12.6.1] Diffie-Hellman key exchange. *[BS 16.5] Quantum attacks on discrete log. Pre03.pdf Post03.pdf Link Rec03 Feb 5 Topics: Chosen-message attack (CMA) security. RSA signature scheme. Authenticated encryption. Cryptographic hash functions. Birthday attacks. Random oracle model. Readings: [KL 4.1-4.2] Definition of message authentication codes (MACs). [KL 13.1-13.2] Definition of digital signatures. [KL 13.4] RSA signature. [KL 5.1-5.3] Authenticated encryption. [R 11.1] Collision-resistant hash functions. *[KL 6.5] Random oracle model. Pre04.pdf Post04.pdf Link Rec04 Feb 7 Topics: Cryptographic hash functions (continued). Applications of hash functions. Putting it all together&colon; secure messaging. Signal Diffie-Hellman ratchet. Pseudorandom generator (PRG). Pseudorandom function (PRF). Readings: *[BS 8.6] SHA256. [BS 8.7.2, 8.10.5] HMAC and HKDF. [KL 13.3] Hash-and-Sign paradigm. Signal double ratchet algorithm. [R 6.1] Definition of PRF. Pre05.pdf Post05.pdf Link Rec05 Feb 12 Topics: Pseudorandom function/permutation (PRF/PRP). Block cipher and modes of operation. CBC-MAC. Readings: [R 6.1, 6.3, 6.5] PRF/PRP and block cipher. [R 8.1] Block cipher modes of operation. [R 5.1, 6.2] PRG from block cipher. [R 10.3] CBC-MAC. Pre06.pdf Post06.pdf Link Rec06 Feb 14 Topics: Password-based authentication. Two-factor authentication. Putting it all together&colon; secure authentication. Readings: [BS 18.3-18.4] Password-based authentication. Pre07.pdf Post07.pdf Link Rec07 Feb 19 NO LECTURE (Long Weekend) Feb 21 Topics: Certificates and public key infrastructure (PKI). Case study&colon; secure shell protocol (SSH). Case study&colon; secure messaging and group chats. Case study&colon; Single Sign-On (SSO) authentication. Readings: [BS 13.8] Certificates and PKI. *[ Paper ] Security of group chats in Signal, Whatsapp, and Threema. *[ Paper Sec. 2] Kerberos overview. Pre08.pdf Post08.pdf Link Rec08 Feb 26 Topics: Definition of zero-knowledge proofs. Proof of knowledge. Example&colon; Schnorr's identification protocol. Example&colon; Diffie-Hellman tuple. Sigma protocols. Readings: [ Lindell's notes Sec. 6] Definition of zero-knowledge proof. [BS 19.1.1] Honest verifier zero knowledge (HVZK). [BS 19.1] Schnorr's identification protocol. [BS 19.4] Sigma protocols. [BS 19.5.2] Chaum-Pedersen protocol for Diffie-Hellman tuples. Pre09.pdf Post09.pdf Link Rec09 Feb 28 Topics: Anonymous online voting&colon; an overview. Example&colon; Diffie-Hellman tuple (continued). Non-interactive zero-knowledge (NIZK) proofs. Fiat-Shamir heuristic. Homomorphism of ElGamal encryption. Readings: [BS 19.5.2] Chaum-Pedersen protocol for Diffie-Hellman tuples. [BS 20.3] Fiat-Shamir heuristic. [BS 19.2] Schnorr signature. *[BS 19.3] ECDSA signature. Pre10.pdf Post10.pdf Link Rec10 Mar 4 Topics: ElGamal threshold encryption. ZKP for AND/OR statements. Anonymous online voting. Readings: [KL 15.3.3] ElGamal threshold encryption. [BS 19.7] ZKP for AND/OR statements. Pre11.pdf Post11.pdf Link Rec11 Mar 6 Topics: ZKP for OR statements (continued). RSA blind signature scheme. Putting it all together&colon; anonymous online voting. Prime-order groups. Readings: [BS Exercise 13.15] Blind signatures. *[KL 9.3.3] Working in subgroups of Z_p^*. Pre12.pdf Post12.pdf Link Rec12 Mar 11 Topics: More examples of sigma protocols. Commitment schemes. Zero-knowledge proofs for all NP. Succinct Non-Interactive Arguments (SNARGs). Readings: [BS 19.5.1, 19.5.3] More examples of sigma protocols. [ Lindell's notes Sec. 7] Zero-knowledge proof for all NP. Pre13.pdf Mar 13 Topics: Succinct Non-Interactive Arguments (SNARGs) from PCP. SNARGs from linear PCP. Introduction to secure multi-party computation (MPC). Readings: [ Thaler's book Sec. 7] Compiling a PCP into a succinct argument. *[ Nitulescu's survey Sec. 7] SNARKs from QAP. [ Lindell's note Sec. 1-2, 5] Motivation, definition, and practical use cases of MPC. Mar 18 Topics: Feasibility results of MPC. Yao's garbled circuits and optimizations. Readings: [ Lindell's note Sec. 3] Feasibility results of MPC. [ Yakoubov's note Sec. 1] Yao's garbled circuits and optimizations. Mar 20 Topics: Oblivious transfer (OT). Putting it all together&colon; 2PC for any function. GMW&colon; MPC for any function. Readings: [ Paper Sec. 1] A simple OT protocol. *[ Paper ] OT extension. [Evans-Kolesnikov-Rosulek's book Ch. 3.2] GMW protocol. Mar 25 NO LECTURE (Spring Break) Mar 27 NO LECTURE (Spring Break) Apr 1 Topics: Malicious security&colon; GMW compiler. Cut-and-choose for garbled circuits. Private set intersection. Readings: [Evans-Kolesnikov-Rosulek's book Ch. 6.5.1] GMW compiler. *[ Paper ] Malicious 2PC via cut-and-choose for garbled circuits. [ Paper Sec. 3.1] DDH-based PSI-sum with cardinality. Apr 3 Topics: Information-theoretic MPC. Introduction to fully homomorphic encryption. Somewhat homomorphic encryption over integers. Readings: [Evans-Kolesnikov-Rosulek's book Ch. 3.3] BGW protocol. [Halevi's tutorial Sec. 1] Introduction to FHE. *[ Paper ] A conceptually simple construction of FHE over integers. Apr 8 Topics: GSW&colon; SWHE from LWE. Readings: [Halevi's tutorial Sec. 3] GSW protocol for SWHE. *[ Paper ] Security of lattice-based cryptosystems. Apr 10 Topics: BFV&colon; SWHE from RLWE. Putting it all together&colon; private information retrieval. Readings: [ Paper Sec. 3-4] BFV protocol for SWHE. *[ Paper ] PIR from SWHE (BFV). *[ Paper ] PIR from (R)GSW. Apr 15 Topics: Bootstrapping SWHE to FHE. Practical constructions of block cipher. Readings: *[ Paper ] PIR from additively homomorphic (Regev) encryption. [KL 6.2.1] Substitution-permutation network (SPN). [KL 6.2.2-6.2.3] Feistel network and DES. Apr 17 Topics: Secure hardware&colon; secure enclaves (Intel SGX); hardware security module (HSM). Readings: *[ Paper ] Intel SGX explained. Apr 22 Topics: Cryptography in blockchain. Differential privacy. Readings: *[ Paper ] Bitcoin. *[ Paper ] Vadhan's tutorial on differential privacy. *[ Paper ] Deep learning with differential privacy. Apr 24 Topics: Privacy-preserving machine learning and federated learning. Readings: *[ Paper ] Secure aggregation for federated learning. Calendar Zoom links are included in the Google Calendar event, as well as in the Hours queue. Staff Peihan Miao Professor | pmiao Hello! I work on cryptography, theory, and security. I'm excited about bridging the gap between theory and practice in cryptography. Pronouns: she/her/hers Jack Cheng \ud83d\udc23 HTA | jcheng46 Hi! I'm a senior and I enjoy exploring. Pronouns: he/him/his Colby Anderson \ud83e\udd19 UTA | cander23 I'm a senior. I'm a Product Manager, CS concentrator, and lover of all athletics. Harys Dalvi \ud83d\udc0a UTA | hdalvi Hello! I'm a junior studying computer science and physics. I enjoy cryptography, ML, thermodynamics, language learning, and long walks in nature. Sudatta Hor \ud83d\udcaa UTA | shor1 I like boxing and Shaq O'Neal. Chenxin Liu \ud83c\udf67 UTA | cliu248 I am currently a second-year master's student. Feel free to reach out for any course-related queries or to share your favorite food spots! Pronouns: she/her/hers Nishchay Parashar \ud83d\udc7e UTA | nparasha Hey! I'm Nishchay, a final-year master's student from New Delhi, India. Always excited to talk about classic rock music, an absolute need for every being to love Roger Federer and the latest YouTube rabbit hole you are into! :) Michael Youssef \ud83e\udd14 UTA | myousse2 Hey! I'm a junior and I'm a fan of cryptography. Camille Zhang \ud83d\ude43 UTA | czhan152 Hi! I'm Camille, a senior concentrating in CS from NorCal. I pretty much spend most of my time dancing, so come watch my last spring show April 5th and 6th! <- this plug was mandatory as Co-Director of DAEBAK Copyright \u00a9 2024 CSCI 1515 @ Brown", "https://cs.brown.edu/courses/csci1730/2020/interpreter.html": "\u25ba Fall 2020: Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Credits \u25ba Assignments Quizius Mystery Languages Implementation Reflection \u25bc Implementation 1 Interpreter 2 Macros 3 OMac 4 SMo LTalk 5 Type Checker 6 Type Inference 7 ACI 8 Lazy 9 Generators 10 Testing Guidelines \u25ba 1 Interpreter 1.1 Introduction 1.2 Reading 1.3 Assignment 1.4 Features to Implement 1.5 Grammar 1.6 Testing 1.7 Starter Code 1.8 What To Hand In On this page: 1.1 Introduction 1.2 Reading 1.3 Assignment 1.3.1 Errors 1.4 Features to Implement 1.4.1 Desugaring 1.4.1.1 and and or 1.4.1.2 let 1.4.2 Environment 1.4.3 Binary Operators 1.4.4 Conditionals 1.4.5 Functions 1.5 Grammar 1.5.1 Abstract Syntax 1.6 Testing 1.6.1 How We Test Tests 1.6.2 Guidelines for Testing Your Interpreter 1.6.3 Debugging 1.7 Starter Code 1.8 What To Hand In \u2190 prev up next \u2192 1 Interpreter 1.1 Introduction 1.2 Reading 1.3 Assignment 1.3.1 Errors 1.4 Features to Implement 1.4.1 Desugaring 1.4.1.1 and and or 1.4.1.2 let 1.4.2 Environment 1.4.3 Binary Operators 1.4.4 Conditionals 1.4.5 Functions 1.5 Grammar 1.5.1 Abstract Syntax 1.6 Testing 1.6.1 How We Test Tests 1.6.2 Guidelines for Testing Your Interpreter 1.6.3 Debugging 1.7 Starter Code 1.8 What To Hand In 1.1 Introduction For this assignment, you will write an interpreter for the Paret language (\u201cpared-down Pyret\u201d) described below. 1.2 Reading Please read chapters 2\u2014 7 of PLAI 2/e . 1.3 Assignment We have provided a function parse which consumes an expression in the Paret language\u2019s concrete syntax, S-Exp , and returns the abstract syntax representation of that expression (an Expr ). parse :: S-Exp -> Expr parse only accepts expressions that follow Paret\u2019s grammar . You will implement two functions: desugar and interp . desugar :: Expr -> Expr which consumes an abstract syntax tree (i.e. an Expr , as returned by parse ), replaces all instances of syntactic sugar (described below) with desugared equivalents, and returns the result. interp :: Expr -> Value which consumes a desugared abstract syntax tree (i.e. the Expr returned by desugar ) and returns a Paret Value . interp should assume that it\u2019s given an Expr from desugar . If interp is given an Expr containing a sugar-* form, its behavior is undefined. Finally, interp should evaluate programs by performing a post-order traversal of the abstract syntax tree (AST): first, evaluate all of the children of an expression from left to right, then evaluate the expression itself. This makes it unambiguous which error to raise if there are multiple errors in the AST. Why evaluate our expressions from left to right? One might say we\u2019ve chosen this as a matter of convention, but ultimately the choice is completely arbitrary. Strictly speaking, we could define our language to evaluate sub-expressions from right to left and that would be just fine. What\u2019s important is that an explicit evaluation order choice is made so the language has clearly defined semantics. Once you have implemented desugar and interp , you should use the provided eval function (which wraps around those two functions and parse ) to write test cases for your interpreter. 1.3.1 Errors We have provided a function raise-error for throwing errors, as well as a type InterpError , which contains all the error cases that your interpreter might run into: (define-type InterpError (err-if-got-non-boolean [val : Value]) (err-bad-arg-to-op [op : Operator] [val : Value]) (err-unbound-id [name : Symbol]) (err-not-a-function [val : Value])) You can throw an error by using raise-error and providing the correct InterpError . For example: (raise-error (err-bad-arg-to-op (op-plus) (v-str \"str\"))) Pay careful attention to how interp \u2019s evaluation order specification impacts which errors are thrown. For example, (str= (+ 5 \"bad\") \"hello\") (++ false (+ \"bad\" 6)) (\"not function\" (+ 7 \"bad\")) should all raise (err-bad-arg-to-op (op-plus) (v-str \"bad\")) . 1.4 Features to Implement 1.4.1 Desugaring Racket macros, which you\u2019ll write later in the course, are themselves syntactic sugar. However, we are not asking you to use Racket macros for anything in this assignment. As described previously, Paret contains several forms of syntactic sugar: and , or , and let . desugar should convert sugar-and , sugar-or , and sugar-let Expr s into functionally equivalent, non-sugar Expr s. There are multiple implementation strategies for desugar . Be sure to test it well: it\u2019s easy to miss some details when desugaring, especially in regards to evaluation order! 1.4.1.1 and and or and consumes two boolean expressions. It evaluates to true if both boolean expressions are true; otherwise, it evaluates to false . or consumes two boolean expressions. It evaluates to true if at least one boolean expression is true; otherwise, it evaluates to false . desugar should convert sugar-and and sugar-or Expr s in such a way that, when interp interprets the desugared code, and and or short-circuit . In and expressions, this means that if the first argument of and evaluates to false , the second argument to and is not evaluated and the and expression evaluates to false . (Similarly, if the first argument of or evaluates to true , the second argument to or should not be evaluated.) Thus, the second argument of a short-circuited expression should never throw an error. 1.4.1.2 let let should accept a single identifier-value pair and a body. let evaluates the value, binds it to id, and evaluates the body with the newly bound identifier in scope. For example, the following should evaluate to 3 : (let (x 1) (+ x 2)) let should disallow recursive definitions. That is, in (let (<id> <expr>) <body>) , <id> should be bound in <body> but not in <expr> . The desugaring of sugar-let may not be obvious, so here\u2019s a hint: What Expr (s) allow us to extend the identifiers bound within a given environment? And how would we make that type of Expr actually do that? 1.4.2 Environment Your interpreter should use an environment, Env , to keep track of the Value s of identifiers in scope. (define-type-alias Env (Hashof Symbol Value)) Since Env is a Hashof , you can use Plait\u2019s built-in hash table functions on your Env . For your environment, make sure you use hash , which creates immutable hash tables! What happens if you use make-hash , which creates mutable hash tables instead? Try replacing one with the other and see. If none of your tests fail, you aren\u2019t testing enough! You should have at least one failing test, if not several, when you make this switch. interp should allow identifier shadowing , meaning that if you bind an identifier that is already bound, the new binding takes precedence. When in doubt, your interpreter should behave just as SMoL would. When interp encounters an unbound identifier, interp should raise the err-unbound-id exception with the name of the identifier. 1.4.3 Binary Operators Paret includes binary addition ( + ) and number equality testing ( num= ), as well as string appending ( ++ ) and string equality testing ( str= ). In place of having separate syntactic forms for each of + , num= , ++ , and str= , parse converts these operators into a single AST datatype variant, e-op , which denotes the operation to use via an Operator variant: (define-type Operator (op-plus) (op-append) (op-str-eq) (op-num-eq)) When you implement these operators, you should use Plait\u2019s + for op-plus , string-append for op-str-eq , string=? for op-str-eq , and = for op-num-eq . Evaluation should raise a err-bad-arg-to-op error for non-numeric values passed to + and num= operations, and for non-string values passed to ++ and str= operations. The op part of the error is the Operator that was called, and val is the Value it was given that had the wrong type. Argument types to Operator s should be checked from left to right. For example, (+ true \"string\") should raise (err-bad-arg-to-op op-plus (v-bool true)) . In line with interp \u2019s evaluation order specification, err-bad-arg-to-op should only be raised after evaluating the arguments to the operator. 1.4.4 Conditionals if -expressions in Paret have three parts: cond , which should evaluate to a Boolean Value consq , which evaluates if cond evaluated to true altern , which evaluates if cond evaluated to false if statements should short-circuit (i.e. only evaluate the relevant branch). If cond evaluates to a non-Boolean Value , an err-if-got-non-boolean error should be raised with val being the offending Value . 1.4.5 Functions Functions in Paret are unary (i.e. they take exactly 1 argument). Here\u2019s two examples of functions and their applications: ((lam x (+ x 3)) 2) ((lam y 5) 1) These should both evaluate to 5. It\u2019s possible that when attempting to perform a function application, the value in the function position isn\u2019t actually a function; e.g., you might have (12) . In this case you should raise a err-not-a-function exception, where val is the value that was applied; e.g., 1 . In line with interp \u2019s evaluation order specification, err-not-a-function should only be raised after evaluating the function-position expression and its argument. 1.5 Grammar The grammar of Paret is as follows: <expr> ::= <num> | <string> | <id> | true | false | (+ <expr> <expr>) | (++ <expr> <expr>) | (num= <expr> <expr>) | (str= <expr> <expr>) | (if <expr> <expr> <expr>) | (and <expr> <expr>) | (or <expr> <expr>) | (let (<id> <expr>) <expr>) | (lam <id> <expr>) | (<expr> <expr>) where <id> is an identifier (i.e., variable), lam defines anonmyous functions, and (<expr> <expr>) is a function application. 1.5.1 Abstract Syntax Refer to Environment for the definition of Env and Binary Operators for the definition of Operator . (define-type Value (v-num [value : Number]) (v-str [value : String]) (v-bool [value : Boolean]) (v-fun [param : Symbol] [body : Expr] [env : Env])) (define-type Expr (e-num [value : Number]) (e-str [value : String]) (e-bool [value : Boolean]) (e-op [op : Operator] [left : Expr] [right : Expr]) (e-if [cond : Expr] [consq : Expr] [altern : Expr]) (e-lam [param : Symbol] [body : Expr]) (e-app [func : Expr] [arg : Expr]) (e-id [name : Symbol]) (sugar-and [left : Expr] [right : Expr]) (sugar-or [left : Expr] [right : Expr]) (sugar-let [id : Symbol] [value : Expr] [body : Expr])) 1.6 Testing We care that you test programs well. Programming langauge implementations are expected to be rock-solid (when\u2019s the last time you ran into an implementation bug?). You need to uphold this standard. This isn\u2019t a course in something like AI, where we don\u2019t even know what the right answer might be! In addition to the quality and correctness of your code, you will be evaluated on the quality and correctness of your tests. 1.6.1 How We Test Tests It\u2019s probably useful for you to understand how we test your tests. What\u2019s the job of a test suite (i.e., set of tests)? It\u2019s to find errors in a program. (Examples help you understand the problem before you start writing code, tests help you catch errors in the program as and after you write it.) In short, test suites are like sorting hats, putting programs in a \u201cgood\u201d or \u201cbad\u201d bin. If you are a mathy person, you might call a test suite a classifier . So, here\u2019s how we will test your test suites. We construct a collection of implementations for the problem. One is known to be correct (because we built it that way); we call this a wheat . The rest are known to be incorrect (because we intentionally introduce errors); we call each of these a chaff . Your test suite\u2019s job is to separate the wheat from the chaff . That is, we will run the wheat and each of the chaffs against your test suite and see what happens: | On a wheat\u2026 | On a chaff\u2026 | ------------------------------------------------ \u2026all tests passed | GREAT! | Not great\u2026 | \u2026some tests failed | Ooops! | GREAT! | All tests passing a wheat, and at least one test failing on a chaff, is exactly what we are hoping for. If all tests pass on a chaff, that\u2019s not ideal, but you may miss some chaffs, so it may be okay. But when any tests fail on a wheat, that\u2019s definitely a problem because it should never happen. It quite likely means you\u2019ve misunderstood the problem statement, or perhaps the problem statement is ambiguous, or something like that. This should get cleared up right away. The quality of your test suite is then a measure of whether you passed the wheat and how many chaffs you caught. Of course, we can make the latter arbitrarily hard. For instance, we could define a chaff that always works correctly except when the given list has, say, exactly 1729 elements. We won\u2019t do things like that, both because it\u2019s cruel and because real implementations are very rarely buggy in this way. Instead, we will make \u201creasonable\u201d mistakes (but not all of them will be easy!). In short, we will be running your test suite against our implementations. Therefore, it is very important that when you turn in your test suite (see details below), it not be accompanied by your implementation: otherwise, when we try to load ours, DrRacket will complain. 1.6.2 Guidelines for Testing Your Interpreter Please read the Testing Guidelines for guidelines on how to write tests for the Implementation assignments. For the purposes of testing, we have defined an eval function that calls parse , desugar , and interp for you. eval consumes a program in the Paret language\u2019s concrete syntax ( S-Exp ) and returns a Paret Value : eval :: S-Exp -> Value You should use eval in your testing file when writing test cases. You should not directly test desugar and interp individually in your test file (though you are welcome to and encouraged to individually test these functions in your code file). There\u2019s good reason for this: there is more than one correct desugaring, so any tests you write may be implementation-specific. (And, of course, your submitted test cases should indirectly test desugaring, because you should test that and and or let work correctly.) In addition to the testing forms documented in the Testing Guidelines , we provide the following testing form: (test-raises-interp-error? name expr interp-error) Tests that the given expr raises the given interp-error . (Example usage can be found in the testing stencil.) Finally, recall that programs can evaluate to functions. However, you may have chosen a different representation for closures than we did. Therefore, your tests in your test file should only check that such a program returned a function, and not rely on the specific function returned (because of the differences in representation). For instance, you may write: (test-pred \"My predicate test\" v-fun? (eval `{lam x 5}) #t) Reminder: In Plait, you can add a ? to the end of the name of any given type variant to create a function that returns true if the expression evaluates to that type variant. However, you may not write: (test-equal? \"Don't write this test\" (eval `{lam x 5}) (v-fun 'x (e-num 5) (hash (list )))) because our representation of closures may not match your exact representation. (You are, of course, welcome to write test cases of the latter form in your code file.) 1.6.3 Debugging You may find it useful to use Plait\u2019s trace to help understand the control flow of your interpreter. For instance, if you write (trace interp) then all subsequent calls (including\u2014and especially\u2014recursive calls) to interp will be presented with their arguments and results. Please do not include calls to trace in your final submissions. 1.7 Starter Code We\u2019ve provided starter code for your implementation at interpreter.rkt and support code at support.rkt . You are not allowed to change the signature of eval , desugar , and interp , but you are welcome to add any helper functions that you need for your implementation. We\u2019ve also provided a stencil for your eval test cases at interpreter-tests.rkt and testing support code at test-support.rkt . You should check that you can run your interpreter-tests.rkt file successfully in DrRacket before submitting\u2014if you can\u2019t, it means that a definition is missing or you\u2019re trying to test a function that you shouldn\u2019t be testing (e.g. a helper function or interp or desugar directly). Do not modify the contents of support.rkt and test-support.rkt . 1.8 What To Hand In You will submit two files for this assignment: interpreter.rkt , which should be uploaded to the \u201cCode\u201d drop on Gradescope. interpreter-tests.rkt , which should be uploaded to the \u201cTests\u201d drop on Gradescope. You can update your submissions as many times as you want before the deadline. \u2190 prev up next \u2192", "https://cs.brown.edu/courses/csci1730/2020/tcheck.html": "\u25ba Fall 2020: Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Credits \u25ba Assignments Quizius Mystery Languages Implementation Reflection \u25bc Implementation 1 Interpreter 2 Macros 3 OMac 4 SMo LTalk 5 Type Checker 6 Type Inference 7 ACI 8 Lazy 9 Generators 10 Testing Guidelines \u25ba 5 Type Checker 5.1 Introduction 5.2 Reading 5.3 Assignment 5.4 Features to Implement 5.5 Grammar 5.6 Testing Guidelines 5.7 Starter Code 5.8 What To Hand In On this page: 5.1 Introduction 5.2 Reading 5.3 Assignment 5.4 Features to Implement 5.4.1 Type Environment 5.4.2 Lists 5.4.3 Exceptions 5.5 Grammar 5.5.1 Abstract Syntax 5.6 Testing Guidelines 5.7 Starter Code 5.8 What To Hand In \u2190 prev up next \u2192 5 Type Checker 5.1 Introduction 5.2 Reading 5.3 Assignment 5.4 Features to Implement 5.4.1 Type Environment 5.4.2 Lists 5.4.3 Exceptions 5.5 Grammar 5.5.1 Abstract Syntax 5.6 Testing Guidelines 5.7 Starter Code 5.8 What To Hand In 5.1 Introduction In this assignment, you will implement a static type checker for an extension of the Paret language, Typed Paret. 5.2 Reading Chapter 15.1\u2014 15.2 of PLAI 2/e. 5.3 Assignment As in Interpreter , we have provided a function parse , which consumes an expression in Typed Paret\u2019s concrete syntax and returns the abstract syntax representation ( Expr ) of that expression. You will implement one function called type-of : type-of :: Expr -> Type that consumes a Paret program in abstract syntax form. If the program is well-typed, type-of returns the Type of that program; otherwise, it raises an exception. Once you have implemented type-of , you should use the provided type-check function (analogous to eval from Interpreter ) to write test cases for your type checker in your testing file. For simplicity, Typed Paret does not have syntactic sugar. let has been converted into a non-sugar expression (so type-of will handle let expressions directly), and and and or have been removed from the language. 5.4 Features to Implement 5.4.1 Type Environment The type language you will work with is (define-type Type (t-num) (t-bool) (t-str) (t-fun [arg-type : Type] [return-type : Type]) (t-list [elem-type : Type])) which, respectively, represent the types of numbers, Booleans, strings, (one-argument) functions, and (homogenous) lists. Just as how Interpreter had an Env for mapping identifiers to values, your interpreter should use a type environment ( TEnv ) to keep track of the types of identifiers in scope. (define-type-alias TEnv (Hashof Symbol Type)) In type-of , if the program binds an identifier that is already bound, the new binding should take precedence. This is known as identifier shadowing . The new binding shadows the existing binding. 5.4.2 Lists Paret now contains support for lists via the constant empty and the operations link , is-empty , first , and rest . Lists in Paret are homogeneous : all elements in the list must have the same type. A question to briefly consider: What is the Type of the empty list? It\u2019s polymorphic : it can be a list of any type at all! Because it has no elements, there\u2019s nothing to constrain its type. However, because our type checker is not polymorphic, we handle this with a simple expedient: we require that every empty list be annotated with a type for the elements (that will eventually be linked to it). Naturally, the elements that eventually are linked to it must be consistent with that annotated type. Thus, our typed list semantics are as follows: empty (empty : t) makes an empty list whose elements have type t . link :: t, (List t) -> (List t) (link x y) prepends the element x to the list y . first :: (List t) -> t (first x) returns the first element of x . rest :: (List t) -> (List t) (rest x) returns the list x except for the first element of x . is-empty :: (List t) -> Bool (is-empty x) returns true if x is empty ; otherwise, it returns false . Whenever these type signatures are violated, the type checker should raise a tc-err-bad-arg-to-op exception. Error-checking link should occur in the following manner: If the type of the second argument to link isn\u2019t a (List t) , the arg-type of tc-err-bad-arg-to-op should be the type of the second argument. If the second argument to link is a (List t) but the type of the first argument is not t , then the arg-type of tc-err-bad-arg-to-op should be the type of the first argument. For example, (link \"hello\" 3) (link 2 (empty : Bool)) should all raise (tc-err-bad-arg-to-op (op-link) (t-num)) . 5.4.3 Exceptions Most of the exceptions your type-checker can raise are just like the errors from Interpreter , but with a type instead of a value. There are two new kinds of exceptions, though: tc-err-bad-arg-to-fun should be raised when a function is applied to an argument of the wrong type. func-type is the type of the function being applied, and arg-type is the type of the argument it was applied to. tc-err-if-branches should be raised when an if statement has branches that have different types. then-type is the type of the \u201cthen\u201d branch, and else-type is the type of the \u201celse\u201d branch. For instance, (if true 3 \"three\") should raise (tc-err-if-branches (t-num) (t-str)) . However, tc-err-if-got-non-boolean takes precedence over tc-err-if-branches . For example, (if \"non-bool\" 5 \"five\") should raise (tc-err-if-got-non-boolean (t-str)) rather than (tc-err-if-branches (t-num) (t-str)) . Thus, the full set of exceptions is as follows: (define-type TypeCheckingError (tc-err-if-got-non-boolean [cond-type : Type]) (tc-err-bad-arg-to-op [op : Operator] [arg-type : Type]) (tc-err-bad-arg-to-un-op [op : UnaryOperator] [arg-type : Type]) (tc-err-unbound-id [name : Symbol]) (tc-err-not-a-function [func-type : Type]) (tc-err-bad-arg-to-fun [func-type : Type] [arg-type : Type]) (tc-err-if-branches [then-type : Type] [else-type : Type])) For tc-err-bad-arg-to-op , argument types to Operator s should be checked from left to right . For example, (+ true \"string\") should raise (tc-err-bad-arg-to-op (op-plus) (t-bool)) . Finally, your type-checker should type-check by performing a post-order traversal of the AST: first, traverse all of the children of an expression from left to right, then check the expression itself. This makes it unambiguous which error to raise if there are multiple errors in the AST. For example, (str= (+ 1 \"bad\") (++ 1 \"bad\")) (++ false (+ \"bad\" 2)) (\"not function\" (+ 3 \"bad\")) (if true (+ 4 \"bad\") (++ 4 \"bad\")) should all raise (tc-err-bad-arg-to-op (op-plus) (t-str)) . 5.5 Grammar The grammar of Typed Paret is as follows: <expr> ::= <num> | <string> | true | false | (+ <expr> <expr>) | (++ <expr> <expr>) | (num= <expr> <expr>) | (str= <expr> <expr>) | (if <expr> <expr> <expr>) | <id> | (<expr> <expr>) | (lam (<id> : <type>) <expr>) | (let (<id> <expr>) <expr>) | (link <expr> <expr>) | (first <expr>) | (rest <expr>) | (is-empty <expr>) | (empty : <type>) <type> ::= Num | Str | Bool | (List <type>) | (<type> -> <type>) Our parse function expects and enforces spaces around : and -> , so keep that in mind when you\u2019re writing test cases. 5.5.1 Abstract Syntax Refer to Type Environment for the definitions of TEnv and Type . (define-type Expr (e-num [x : Number]) (e-bool [x : Boolean]) (e-str [x : String]) (e-op [op : Operator] [left : Expr] [right : Expr]) (e-un-op [op : UnaryOperator] [expr : Expr]) (e-if [cond : Expr] [consq : Expr] [altern : Expr]) (e-lam [param : Symbol] [arg-type : Type] [body : Expr]) (e-app [func : Expr] [arg : Expr]) (e-id [name : Symbol]) (e-let [id : Symbol] [value : Expr] [body : Expr]) (e-empty [elem-type : Type])) (define-type Operator (op-plus) (op-append) (op-num-eq) (op-str-eq) (op-link)) (define-type UnaryOperator (op-first) (op-rest) (op-is-empty)) 5.6 Testing Guidelines For the purposes of testing, we have defined a type-check function that calls parse and type-of for you. type-check consumes an expression in Paret\u2019s concrete syntax ( S-Exp ) and returns a Paret Type : type-check :: S-Exp -> Type You should use type-check in your testing file when writing test cases. You should not directly test type-of in your testing file. In addition to the testing forms documented in the Testing Guidelines , we provide the following testing form: (test-raises-type-checker-error? name expr type-checker-error) Tests that the given expr raises the given type-checker-error . (Example usage can be found in the testing stencil.) 5.7 Starter Code We\u2019ve provided starter code for your implementation at type-checker.rkt and support code at support.rkt . You are not allowed to change the signature of type-check and type-of , but you are welcome to add any helper functions that you need for your implementation. We\u2019ve also provided a stencil for your type-check test cases at type-checker-tests.rkt and testing support code at test-support.rkt . You should check that you can run your type-checker-tests.rkt file successfully in DrRacket before submitting\u2014if you can\u2019t, it means that a definition is missing or you\u2019re trying to test a function that you shouldn\u2019t be testing. 5.8 What To Hand In You will submit two files for this assignment: type-checker.rkt , which should be uploaded to the \u201cCode\u201d drop on Gradescope. type-checker-tests.rkt , which should be uploaded to the \u201cTests\u201d drop on Gradescope. You can update your submissions as many times as you want before the deadline. \u2190 prev up next \u2192", "https://cs.brown.edu/courses/csci1730/2020/generators.html": "\u25ba Fall 2020: Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Credits \u25ba Assignments Quizius Mystery Languages Implementation Reflection \u25bc Implementation 1 Interpreter 2 Macros 3 OMac 4 SMo LTalk 5 Type Checker 6 Type Inference 7 ACI 8 Lazy 9 Generators 10 Testing Guidelines \u25ba 9 Generators 9.1 Introduction 9.2 Reading 9.3 Part 1: Language Comparison 9.4 Part 2: Implementation 9.5 What To Hand In On this page: 9.1 Introduction 9.2 Reading 9.3 Part 1: Language Comparison 9.4 Part 2: Implementation 9.4.1 Grammar 9.4.2 Yielding a Value 9.4.2.1 Example Usage 9.4.3 Implementation Hints 9.4.4 Starter Code 9.5 What To Hand In \u2190 prev up next \u2192 9 Generators 9.1 Introduction 9.2 Reading 9.3 Part 1: Language Comparison 9.4 Part 2: Implementation 9.4.1 Grammar 9.4.2 Yielding a Value 9.4.2.1 Example Usage 9.4.3 Implementation Hints 9.4.4 Starter Code 9.5 What To Hand In 9.1 Introduction In this assignment, you will implement generators. 9.2 Reading Chapter 14.3 of PLAI 2/e. Optional Reading: This article provides a very nice introduction to generators in the Icon programming language, which is no longer used but inspired most modern work on generators. Generators in Icon were central to the language, not an added-on feature, and this shows how they are integrated into the language. (Notice, in paricular, how the truthy-falsy nature of the language appears to be a win early on, but becomes problematic later on.) You can see other examples on Wikipedia . It\u2019s worth noting that Icon was created in the late 1970s! 9.3 Part 1: Language Comparison Consider the following program written in Python 3 ( run it online! ): x = 0 def a(b): global x b() x = 3 def c(): a(lambda: (yield 1)) yield x gen = c() print(next(gen)) print(next(gen)) We\u2019ve translated the above program into this seemingly equivalent Racket program ( run it online! ): (require racket/generator) (define x 0) (define (a b) (b) (set! x 3)) (define c (generator () (a (lambda () (yield 1))) (yield x))) (c) (c) First, confirm that these programs look equivalent; that is, we might expect the generators in both to yield 1 , then yield 3 . Then, run both programs. Answer the following question(s): Do they behave the same way? If not, why do they differ? You are welcome to consult the Web (within the rules set down in the syllabus) for help understanding their behaviors. 9.4 Part 2: Implementation You will now emulate Python 3 generators in Racket by adapting your aci implementation from the ACI assignment to implement the generator construct: (generator (arg-name) body) which defines an unary function. This function returns a generator with routine body , and any references to arg-name within body are bound to the function\u2019s argument. Be very careful when you\u2019re reading this spec\u2014the generator construct defines a function , not a generator . Applying the function defined by generator (the syntactic construct) produces a generator (in the semantic sense). In addition to the base constructs from the aci language (that is, everything except web-read ), the language for a generator \u2019s body should support the following new forms: (yield exp) which yields the value of exp from the generator. We need our aci implementation because of yield \u2014 aci provides the continuation needed to store the generator\u2019s current state before yielding. (yield ...) itself should evaluate to (void) . Also, programs may nest yield s, and inner yield s should yield before outer yield s. (loop exp) which infinitely runs exp . (We don\u2019t need loop to understand generators, but it makes it easier to write interesting programs [e.g., streams].) Additionally, because we are trying to mimic Python, your generator should not allow the use of yield or loop inside of lambda , just as in the example above. Any programs that attempt to do either should result in an error (a syntax error is acceptable here). The body of a generator should be able to support references to definitions defined outside of the body (for example, functions and variables previously declared in a define statement), though those outer definitions do not need to support the constructs in the generator language (such as yield and loop ). To do this, you should update your aci macro such that function applications do not pass their current continuation to the callee. Instead, the function application\u2019s result should be given to the continuation just as with atomic values. This modification to how continuations interact with function applications matches Python\u2019s semantics. Finally, you should implement the next function, which takes a generator as an argument, resumes computation of the generator from the point at which it last yield ed, and returns the next value that the generator yield s. If the generator has reached the end of its body, next should call raise-stop-iteration-error (defined in the support code) to signal that the generator has been exhausted. If the generator never reaches the end of its body and never reaches a yield , next may loop infinitely. 9.4.1 Grammar Your final generator macro implementation should handle the following grammar: <generator> ::= (generator (<id>) <gen-expr>) <gen-expr> ::= <basic-expr> | (yield <gen-expr>) | (loop <gen-expr>) <basic-expr> ::= <num> | <string> | true | false | (<gen-expr> <gen-expr>) # function application | (lambda (<id>) <basic-expr>) | (set! <id> <gen-expr>) | (begin <gen-expr> <gen-expr>) | (+ <gen-expr> <gen-expr>) | (string-append <gen-expr> <gen-expr>) 9.4.2 Yielding a Value When you need to yield a value, you should use let/ec to escape from the generator and return a value. This creates an escape continuation . Escape continuations are analogous to return statements in languages like Python\u2014 when applied to an argument, the continuation unwinds the current stack out of let/ec and returns the argument. Your program must call the escape continuation within the dynamic extent of let/ec . In other words, you must call the continuation before the continuation\u2019s let/ec (and the point where the escape continuation would unwind to) pops off the stack. Otherwise, Racket will raise an error. Pay attention to the distinction between the continuation created by let/ec (echo-charlie) and the continuations we\u2019ve seen in lecture, created by let/cc (charlie-charlie). let/cc \u2019s continuations allow you to jump back to the copy of the stack where the continuation was made, regardless of where the continuation was called. In contrast, let/ec \u2019s continuations are only allowed to escape the current stack\u2014\u2014 they don\u2019t preserve a copy of the stack to permit the program to resume the computation. 9.4.2.1 Example Usage The following use of let/ec works because the escape continuation k is invoked before the let/ec call that defined k has popped off the stack: (+ 1 (let/ec k (k 5))) ; the let/ec expression evaluates to 5 When the escape continuation k is called, the application of the continuation unwinds the stack back to the invocation of let/ec . Then, the let/ec expression evaluates to the value passed to k . Thus, the above program evaluates to 6 . We can even bind the escape continuation k to a new variable, and call the escape continuation via that variable ( hint! ): (define hold \"dummy variable\") (+ 1 (let/ec k (begin (set! hold k) (hold 5)))) However, the following example results in an error (since k is invoked after the let/ec call that defined k has popped off the stack): (define hold \"dummy variable\") (+ 1 (let/ec k (begin (set! hold k) 3))) (hold 5) ; error! \"continuation application: attempt to jump into an escape continuation\" Make sure you understand why the semantics of let/cc would allow the third program to work if we were to replace let/ec with let/cc . Because of these semantics, you\u2019ll need to carefully consider how you use let/ec to return values. Specifically, every time we call next on a generator, we\u2019d like to return the yielded value to this specific invocation of next . However, defining a continuation only saves the current stack at the time the continuation was defined. As such, you\u2019ll need to figure out a way to update the escape continuation used by yield every time you call next or you\u2019ll end up using an old escape continuation. 9.4.3 Implementation Hints We recommend that you create a struct that stands for generators; exactly what this struct looks like is up to you. You may find it helpful to nest your aci macro inside your generator macro; try implementing generator without doing this and see what you run into. You can nest a define-syntax construct within another define-syntax construct by moving the \u201cinner\u201d macro inside of a particular pattern branch of your \u201couter\u201d macro: (define-syntax outer-macro (syntax-rules () [(_ some-pattern) (let () (define-syntax inner-macro (syntax-rules () [(_ another-pattern) (+ 1 2)])) ; (+ 1 2) can be whatever you want (inner-macro \"bar\"))])) (outer-macro \"foo\") You might find it tricky to know how to catch uses of loop and yield inside of lambda . Think about how you wrote your lambda case in ACI. In ACI, it was legal for a web-read to appear in the body of a lambda , so it was necessary to use aci on the body of a lambda in order to handle possible web-read s. In this assignment, a world where yield and loop aren\u2019t allowed to appear inside of lambda s, do you need to handle your lambda case in the same way? Finally, you might find implementing loop tricky. You might start by expanding loop \u2019s body into another call to loop , but that can cause your aci macro to never terminate. Instead, try implementing it via a helper function that consumes the continuation representing loop \u2019s body and runs this continuation repeatedly (it\u2019s up to you to figure out how to do this, though). 9.4.4 Starter Code We\u2019ve provided starter code for your implementation at generators.rkt . This includes a template for your generator macro as well as the next function. We\u2019ve also provided a stencil for your test cases at generators-tests.rkt and testing support code at test-support.rkt . You should check that you can run your generators-tests.rkt file successfully in DrRacket before submitting\u2014if you can\u2019t, it means that a definition is missing or you\u2019re trying to test a function that you shouldn\u2019t be testing. 9.5 What To Hand In You will submit two files for this assignment: generators.rkt , which should be uploaded to the \u201cCode\u201d drop on Gradescope. generators-tests.rkt , which should be uploaded to the \u201cTests\u201d drop on Gradescope. Finally, submit your answer to Part 1: Language Comparison to the \u201cQuestion\u201d drop on Gradescope. You can update your submissions as many times as you want before the deadline. \u2190 prev up next \u2192", "https://cs.brown.edu/courses/csci1730/2020/testing-guidelines-section.html": "\u25ba Fall 2020: Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Credits \u25ba Assignments Quizius Mystery Languages Implementation Reflection \u25bc Implementation 1 Interpreter 2 Macros 3 OMac 4 SMo LTalk 5 Type Checker 6 Type Inference 7 ACI 8 Lazy 9 Generators 10 Testing Guidelines \u25ba 10 Testing Guidelines 10.1 Testing Guidelines On this page: 10.1 Testing Guidelines 10.1.1 Provided Library 10.1.2 Error- Handling 10.1.3 Check Your Understanding \u2190 prev up next \u2192 10 Testing Guidelines 10.1 Testing Guidelines 10.1.1 Provided Library 10.1.2 Error-Handling 10.1.3 Check Your Understanding 10.1 Testing Guidelines In addition to the quality and correctness of your code, you will be evaluated on the quality and correctness of your tests. We grade your tests by running them against correct and incorrect solutions (called wheat and chaff respectively) that we have written to see whether your tests can tell the difference. In every Implementation assignment where we collect test cases, we will provide two additional files: A test-support.rkt file. The test-support.rkt file provides specific testing forms that you should use when writing tests for the wheats and chaffs. You should not use any external testing library other than those specifically provided; otherwise, we will not be able to grade your test suite. Please make sure to use the test-support.rkt file specifically provided with each assignment\u2014some assignments will have assignment-specific testing forms to help you when testing. A starter file in which you should write your test suite. This test suite will contain a (define/provide-test-suite test-suite-name ...) statement, where test-suite-name is some identifier. You should make sure to write all of your test expressions within this statement; otherwise, we will not be able to grade your test suite. The testing stencils provide examples of how to do this. While you should never include implementation-specific test cases within your testing file, you are welcome to (and encouraged to) write implementation-specific test cases within your implementation file. For example, you may find it helpful to write test cases against your helper functions. However, your implementation file does not have access to the forms defined in test-support.rkt , so you\u2019ll need to use either Racket\u2019s or Plait\u2019s built-in testing utilities. 10.1.1 Provided Library You will always have access to the following forms: (test-equal? name actual expected) (test-not-equal? name actual expected) Tests that actual and expected evaluate to the same value (in the case of test-not-equal? , different values). (test-true name expr) (test-false name expr) Tests that expr evaluates to #t (in the case of test-false , #f ). (test-pred name pred expr) Tests that expr returns a value that satisfies the given pred predicate. (test-raises-error-with-substring? name expr substr) Tests if the given expr raises an error that contains the substring substr . Some assignments will have specific testing forms; see the assignment specs for more information. 10.1.2 Error-Handling When we run your tests, they can result in an error (either due to an intentionally raised error or a bug in a chaff). It is important that invocations of your functions in your tests are caught by a testing statement from our provided testing library, each of which will handle the error automatically. Without a testing statement to handle an error, the test running could terminate due to the error, and you will receive no credit. Thus, you should write this: (test-equal? \"Works with Num primitive\" (eval `{+ 2 2}) (v-num 4)) However, don\u2019t write this: (define result (eval `{+ 2 2})) ; this is not caught by `test-equal?`! (test-equal? result (v-num 4)) That said, if you need to define intermediary variables in a test case, you can use a begin or let statement: (test-equal? \"Multi-statement test case\" (let ([result (eval `{+ 2 2})]) result) (v-num 4)) 10.1.3 Check Your Understanding Implementation assignments that ask for test cases will have a \u201cTests\u201d upload on Gradescope for you to submit your test cases. Prior to the assignment deadline, you are welcome (and encouraged) to upload your testing file to the Gradescope drop early . When you do this, Gradescope will automatically run all of the wheats and a subset of the chaffs against your test suite. Once it\u2019s done running, it will immediately give you feedback on: Whether your test suite passed all of the wheats Which of the starter chaffs your test suite caught We provide you this functionality to help you check your understanding of the problem and to encourage you to explore the more interesting edge cases in the specification. Specifically, the starter subset of chaffs on Gradescope are designed to help catch any misunderstandings of the problem statement you may have. However, when we evaluate the comprehensiveness of your final test suite, we\u2019re going to run it against many more chaffs, which will mainly focus on errors that might occur during implementation. In other words, make sure you keep developing your test cases while you\u2019re implementing your functions, even if you caught all of the chaffs, since catching all of the initial Gradescope chaffs may not be sufficient to getting the highest possible evaluations on testing. \u2190 prev up next \u2192", "https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Fdocs.google.com%2Fforms%2Fd%2Fe%2F1FAIpQLSdDVtFFyFD9zYmpdvcjwPMSWQQqVSkL_zQXWLtCjZPLVA_Vng%2Fviewform&followup=https%3A%2F%2Fdocs.google.com%2Fforms%2Fd%2Fe%2F1FAIpQLSdDVtFFyFD9zYmpdvcjwPMSWQQqVSkL_zQXWLtCjZPLVA_Vng%2Fviewform&ifkv=ATuJsjzzKmFYRoE5cT3rwVEinpRWjgXGtbyLSwKR2Le3AQT3j9a5uL23KQGnQkhpq0wUaycAK9HeYA&ltmpl=forms&osid=1&passive=1209600&service=wise&flowName=WebLiteSignIn&flowEntry=ServiceLogin&dsh=S-636666650%3A1710141940928937": "Sign in to continue to Forms Email or phone Forgot email? //# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjogMywic291cmNlcyI6WyIiXSwic291cmNlc0NvbnRlbnQiOlsiICJdLCJuYW1lcyI6WyJjbG9zdXJlRHluYW1pY0J1dHRvbiJdLCJtYXBwaW5ncyI6IkFBQUE7QUFBQTtBQUFBO0FBQUE7QUFBQTtBQUFBO0FBQUEifQ==(function(){var C=function(R,U,M,Y,n,f,c,u,D,P,e,m,K,G,p,L,V,Z,Q,N,a,B){for(Q=92;63!=Q;)if(33==Q)Q=(R+1^9)>=R&&(R+4^18)<R?54:44;else if(82==Q)a=(c=b(24,27,6,40,Y,M,n))&&1===f.eval(c.createScript(\"1\"))?function(O){return c.createScript(O)}:function(O){return U+O},Q=90;else if(7==Q)a=(c=I[U.substring(0,3)+\"_\"])?c(U.substring(3),M,Y,n,f):w(35,43,M,U),Q=96;else{if(44==Q)return a;26==Q?Q=2==(R^78)>>3?7:96:54==Q?(a=U,Q=44):90==Q?Q=(R&78)==R?39:33:92==Q?Q=26:8==Q?(L=function(){},Z=function(O,X,x){for(x=(O=93,52);;)try{if(26==O)break;else{if(93==O)return x=96,G.contentWindow.location.href.match(/^h/)?null:!1;if(17==O)return x=52,\"\"+X}}catch(E){if(52==x)throw E;96==x&&(X=E,O=17)}},N=function(){(f.f=((u.push(60,+new Date-D),clearInterval)(m),void 0),L)(),L=void 0},V=function(O,X,x){for(x=92;88!=x;)78==x?(K=O,P=X,G=document.createElement(Y),w(35,52,!1,n,function(E,J){for(J=27;93!=J;)28==J?(E=Z(),J=57):17==J?(u.push(15,+new Date-D),p=G.contentWindow,K=0,G=null,clearInterval(m),L(),L=void 0,J=93):90==J?(u.push(29,X-D,E),B(),V(O+1),J=93):57==J?J=null===E?17:90:27==J&&(J=O===K?28:93)},G),w(35,40,!1,\"error\",function(E){for(E=9;41!=E;)31==E?(u.push(64,X-D),B(),V(O+1),E=41):9==E&&(E=O===K?31:41)},G),G.style.display=\"none\",G.src=c,e.appendChild(G),x=88):43==x?x=O>U?5:78:92==x?(X=+new Date,u.push(82,X-D,O),x=43):5==x&&(u.push(35,X-D),N(),x=88)},B=function(){K=(e.removeChild(G),G=null,0)},G=null,K=0,u=[],f.f=function(O,X,x){for(x=16;99!=x;)16==x?x=L?17:6:6==x?(O(p,u),x=99):17==x&&(X=L,L=function(){X(),setTimeout(function(){O(p,u)},0)},x=99)},D=+new Date,e=document.body||document.documentElement.lastChild,m=setInterval(function(O,X,x,E){for(E=55;3!=E;)68==E?(O=K,X=+new Date,E=66):66==E?E=2E4<X-D?23:35:55==E?E=G?68:3:23==E?(u.push(66,X-D),B(),N(),E=3):65==E?E=6E3<X-P?53:3:53==E?(u.push(87,X-D),B(),V(O+1),E=3):77==E?(u.push(M,X-D,x),B(),V(O+1),E=3):35==E&&(E=(x=Z())?77:65)},512),V(1),Q=43):39==Q?(a=T(0,8)?w(35,29,\"Chromium\"):(T(\"Chrome\",17)||T(\"CriOS\",19))&&!(T(0,34)?0:T(\"Edge\",23))||T(U,27),Q=33):43==Q?Q=2==(R+9&15)?82:90:96==Q&&(Q=(R&97)==R?8:43)}},w=function(R,U,M,Y,n,f,c,u,D,P,e){for(e=60;3!=e;)if(52==e)e=U<<2&15?10:13;else{if(10==e)return P;e==R?e=34>U+6&&23<=(U^44)?83:38:75==e?e=29<=U<<1&&1>U-6>>5?23:R:97==e?(M(function(m){m(Y)}),P=[function(){return Y},function(){}],e=52):13==e?(f.addEventListener(Y,n,M),e=10):38==e?e=(U+5^26)<U&&(U-5^29)>=U?97:52:83==e?(D=I,D[n]||C(32,M,93,f,Y,D,c),D[n](u),e=38):23==e?(P=F?z?z.brands.some(function(m,K){return(K=m.brand)&&-1!=K.indexOf(M)}):!1:!1,e=R):60==e&&(e=75)}},T=function(R,U,M,Y,n,f,c,u,D,P){for(D=87;48!=D;){if(83==D)return P;if(43==D)D=(U&126)==U?49:83;else if(49==D)P=F?!!z&&z.brands.length>R:!1,D=83;else if(31==D)D=(U-4^19)>=U&&(U-1^11)<U?19:21;else if(19==D)u=function(){},c=void 0,n=l(R,function(e,m){for(m=16;42!=m;)21==m?(M&&g(M),c=e,u(),u=void 0,m=42):16==m&&(m=u?21:42)},!!M),f=n[1],Y=n[0],P={invoke:function(e,m,K,G,p,L,V){for(L=25;23!=L;)if(45==L)V(),L=23;else if(25==L)V=function(){c(function(Z){g(function(){e(Z)})},K)},L=44;else if(44==L)L=m?77:85;else if(8==L)G=u,u=function(){g((G(),V))},L=23;else if(77==L)L=c?45:8;else if(85==L)return p=Y(K),e&&e(p),p},pe:function(e){f&&f(e)}},D=21;else if(87==D)D=31;else if(5==D){a:{if(Y=k.navigator)if(M=Y.userAgent){n=M;break a}n=\"\"}D=(P=-1!=n.indexOf(R),43)}else 21==D&&(D=(U^22)>>4?43:5)}},t,l=function(R,U,M,Y,n,f){return C.call(this,88,R,U,M,Y,n,f)},y=function(R){return C.call(this,15,R)},b=function(R,U,M,Y,n,f,c,u,D,P,e,m){for(e=R,P=31;;)try{if(37==e)break;else if(e==R)u=f,D=k.trustedTypes,e=75;else if(e==U)k.console[n](m.message),e=26;else{if(26==e)return P=31,u;if(91==e)P=Y,u=D.createPolicy(c,{createHTML:y,createScript:y,createScriptURL:y}),e=26;else if(e==M)e=k.console?U:26;else if(75==e)e=D&&D.createPolicy?91:9;else if(5==e)P=31,e=M;else if(9==e)return u}}catch(K){if(31==P)throw K;P==Y&&(m=K,e=5)}},r=function(R,U,M,Y,n,f){return T.call(this,R,9,U,M,Y,n,f)},F,k=this||self;a:{for(var W=k,S=0,d=[\"CLOSURE_FLAGS\"];S<d.length;S++)if(W=W[d[S]],null==W){t=null;break a}t=W}var h=t&&t[610401301],q=k.navigator,z;F=null!=(z=q?q.userAgentData||null:null,h)?h:!1;var I,g=k.requestIdleCallback?function(R){requestIdleCallback(function(){R()},{timeout:4})}:k.setImmediate?function(R){setImmediate(R)}:function(R){setTimeout(R,0)};(I=(!T(\"Safari\",(C(10,(!T(\"Android\",25)||C(8,\"Silk\"),\"Silk\")),19))||C(6,\"Silk\")||(T(0,36)?0:T(\"Coast\",17))||(T(0,6)?0:T(\"Opera\",31))||(T(0,32)?0:T(\"Edge\",29))||(T(0,40)?w(35,31,\"Microsoft Edge\"):T(\"Edg/\",21))||T(0,38)&&w(35,30,\"Opera\"),k.botguard)||(k.botguard={}),40<I.m)||(I.m=41,I.bg=r,I.a=l),I.PCh_=function(R,U,M,Y,n,f,c,u,D){return w(35,3,5,\"load\",\"f\",\"iframe\",(c=R.lastIndexOf(\"//\"),u=atob(R.substr(c+2)),u),function(P,e,m,K,G,p,L,V){for(V=(L=53,15);;)try{if(33==L)break;else if(78==L)G=w(35,45,U,K),f=G[1],D=G[0],L=33;else if(7==L){f=(m=P.eval(C(9,(V=29,\"\"),null,\"error\",\"bg\",P)(Array(7824*Math.random()|0).join(\"\\n\")+['//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjogMywic291cmNlcyI6WyIiXSwic291cmNlc0NvbnRlbnQiOlsiICJdLCJuYW1lcyI6WyJjbG9zdXJlRHluYW1pY0J1dHRvbiJdLCJtYXBwaW5ncyI6IkFBQUE7QUFBQTtBQUFBO0FBQUE7QUFBQTtBQUFBO0FBQUEifQ==','(function(){var UI=function(L,U,e,u,R,x,P){for(x=93;26!=x;)if(56==x)this.i=e,x=36;else if(8==x)x=U-5<<1>=U&&(U-2^14)<U?57:27;else{if(27==x)return P;36==x?x=U+8>>4?8:28:28==x?(R=e,P=function(){return R<u.length?{done:false,value:u[R++]}:{done:true}},x=8):93==x?x=L:57==x?(P=eY[e](eY.prototype,{pop:u,stack:u,call:u,console:u,length:u,parent:u,floor:u,replace:u,splice:u,propertyIsEnumerable:u,document:u,prototype:u}),x=27):x==L&&(x=1==(U-3&11)?56:36)}},V=function(L,U,e,u,R,x,P,O,E,Q,D,m){for(Q=43;9!=Q;)if(5==Q){if(R.R.length){R.mk=(R.JN=!(R.JN&&0(),0),e);try{O=R.Z(),R.VN=O,R.tN=0,R.mS=O,x=G(16,null,254,0,true,e,R),E=u?0:10,P=R.Z()-R.VN,R.jQ+=P,R.vz&&R.vz(P,R.T,R.F),R.T=false,R.F=false,P<E||0>=R.n2--||(P=Math.floor(P),R.L2.push(P<=U?P:254))}finally{R.JN=false}m=x}Q=94}else if(94==Q)Q=L+7&7?88:78;else if(20==Q)u=typeof e,m=u==U&&null!=e||\"function\"==u,Q=92;else if(88==Q)Q=5<=(L-5&7)&&1>(L<<1&16)?20:92;else if(92==Q)Q=L+9>>2<L&&(L+5&76)>=L?1:83;else if(22==Q)Q=(L|64)==L?5:94;else if(78==Q)D=function(M){return U.call(D.src,D.listener,M)},U=Lw,m=D,Q=88;else if(43==Q)Q=22;else if(1==Q)U.classList?Array.prototype.forEach.call(e,function(M){X(3,0,\"class\",\" \",\"string\",U,M)}):G(68,\"class\",U,Array.prototype.filter.call(EI(36,\"string\",U),function(M){return!b(3,0,M,e)}).join(\" \")),Q=83;else if(83==Q)return m},X=function(L,U,e,u,R,x,P,O,E){for(E=55;3!=E;){if(35==E)return O;68==E?E=L-7<<2<L&&(L+4^29)>=L?77:66:55==E?E=68:66==E?E=(L-2^4)>=L&&L+9>>2<L?65:23:65==E?(u.R.splice(U,U,e),E=23):53==E?E=35:77==E?(x.classList?x.classList.remove(P):(x.classList?x.classList.contains(P):b(32,U,P,EI(37,R,x)))&&G(12,e,x,Array.prototype.filter.call(EI(35,R,x),function(Q){return Q!=P}).join(u)),E=66):23==E&&(E=2==(L<<1&7)?53:35)}},PM=function(L,U,e,u,R,x,P){for(x=92;63!=x;)if(33==x)x=1==((U^100)&7)?54:44;else if(82==x)0===this.n?P=[0,0]:(this.o.sort(function(O,E){return O-E}),P=[this.n,this.o[this.o.length>>1]]),x=90;else if(7==x)u.SQ&&u.SQ.forEach(e,void 0),x=96;else{if(44==x)return P;26==x?x=(U^64)>>3?96:7:54==x?(P=typeof R.className==u?R.className:R.getAttribute&&R.getAttribute(e)||L,x=44):90==x?x=(U&45)==U?39:33:92==x?x=26:8==x?(P=0===this.n?0:Math.sqrt(this.Hz/this.n),x=43):39==x?(jY.call(this),e||uq||(uq=new xo),this.I=this.C=this.yN=null,this.Fp=false,this.QN=null,this.lH=false,this.SQ=null,this.v=void 0,x=33):43==x?x=1<=((U^63)&12)&&4>U>>2?82:90:96==x&&(x=(U|88)==U?8:43)}},sI=function(L,U,e,u,R,x,P,O,E){for(O=60;3!=O;)if(75==O)O=U-6<<1<U&&(U+9^6)>=U?52:35;else if(O==L)O=38;else if(60==O)O=75;else if(52==O)x=QV(33,R,e,34,1,u),(P=x>=e)&&Array.prototype.splice.call(u,x,1),E=P,O=35;else if(35==O)O=(U-7|35)>=U&&(U-3|9)<U?L:38;else if(38==O)return E},nw=function(L,U,e,u,R,x,P,O,E,Q,D){for(D=26;7!=D;)if(34==D)D=(U-6|11)<U&&(U-8^8)>=U?52:40;else if(25==D)x=this.type=e.type,P=e.changedTouches&&e.changedTouches.length?e.changedTouches[0]:null,this.target=e.target||e.srcElement,this.currentTarget=u,R=e.relatedTarget,D=46;else if(26==D)D=66;else if(23==D)P in O&&x.call(void 0,O[P],P,R),D=72;else if(77==D)D=P?43:17;else if(44==D)this.relatedTarget=R,D=77;else if(42==D)Ms.call(this,e?e.type:\"\"),this.relatedTarget=this.currentTarget=this.target=null,this.button=this.screenY=this.screenX=this.clientY=this.clientX=this.offsetY=this.offsetX=0,this.key=\"\",this.charCode=this.keyCode=0,this.metaKey=this.shiftKey=this.altKey=this.ctrlKey=false,this.state=null,this.pointerId=0,this.pointerType=\"\",this.timeStamp=0,this.s=null,D=21;else if(46==D)D=R?44:8;else if(8==D)D=\"mouseover\"==x?83:71;else if(43==D)this.clientX=void 0!==P.clientX?P.clientX:P.pageX,this.clientY=void 0!==P.clientY?P.clientY:P.pageY,this.screenX=P.screenX||0,this.screenY=P.screenY||0,D=45;else if(40==D)D=U+7>>4?56:42;else if(45==D)this.button=e.button,this.keyCode=e.keyCode||0,this.key=e.key||\"\",this.charCode=e.charCode||(\"keypress\"==x?e.keyCode:0),this.ctrlKey=e.ctrlKey,this.altKey=e.altKey,this.shiftKey=e.shiftKey,this.metaKey=e.metaKey,this.pointerId=e.pointerId||0,this.pointerType=\"string\"===typeof e.pointerType?e.pointerType:OI[e.pointerType]||\"\",this.state=e.state,this.timeStamp=e.timeStamp,this.s=e,e.defaultPrevented&&mq.m.preventDefault.call(this),D=56;else if(16==D)D=32;else{if(56==D)return Q;71==D?D=\"mouseout\"==x?12:44:17==D?(this.offsetX=e.offsetX,this.offsetY=e.offsetY,this.clientX=void 0!==e.clientX?e.clientX:e.pageX,this.clientY=void 0!==e.clientY?e.clientY:e.pageY,this.screenX=e.screenX||0,this.screenY=e.screenY||0,D=45):72==D?(P++,D=32):12==D?(R=e.toElement,D=44):66==D?D=(U|L)==U?85:34:21==D?D=e?25:56:52==D?(\"function\"===typeof e?Q=e:(e[Yo]||(e[Yo]=function(m){return e.handleEvent(m)}),Q=e[Yo]),D=40):85==D?(E=R.length,O=\"string\"===typeof R?R.split(e):R,P=u,D=16):32==D?D=P<E?23:34:83==D&&(R=e.fromElement,D=44)}},I=function(L,U,e,u,R,x,P,O){return 1==L+(1==(L+3&3)&&(U.h?O=cM(U.N,U):(e=Xr(8,2,true,U),128+(e&-129)-(e^128)&&(e^=128,u=Xr(2,2,true,U),e=(e<<2)+(u|0)),O=e)),2)>>3&&(O=(x=R[u]<<24|R[(u|e)+U]<<16,P=R[(u&2)-U-~(u|2)]<<8,-(x|e)+(P|e)+(x&P)+2*(x&~P))|R[-2*~(u&3)-4*(~u^3)+3*(u|-4)+3*(~u|3)]),O},JP=function(L,U,e,u,R,x,P,O,E,Q,D,m,M,n){for(M=26;91!=M;)if(87==M){if(E=x.V.X[String(u)]){for(E=E.concat(),D=L,m=0;m<E.length;++m)(O=E[m])&&!O.GV&&O.capture==R&&(P=O.listener,Q=O.US||O.src,O.zV&&bq(true,44,L,x.V,O),D=false!==P.call(Q,U)&&D);n=D&&!U.defaultPrevented}else n=L;M=5}else if(26==M)M=40;else if(6==M)M=1==(e>>2&3)?24:27;else if(24==M)n=U in VV?VV[U]:VV[U]=L+U,M=27;else if(40==M)M=(e+3^29)<e&&(e+8^30)>=e?87:5;else if(22==M)R=U,R^=R<<13,R=(x=R>>17,~(R&x)-1-~x-(~R|x)),R=(P=R<<5,(R|P)+~(R|P)-(~R^P)),(R&=u)||(R=1),n=-1+(L&~R)-(L|~R),M=6;else{if(27==M)return n;5==M&&(M=(e&78)==e?22:6)}},pw=function(L,U,e,u,R,x,P,O,E,Q,D,m){for(D=78;63!=D;)if(49==D)pw(35,true,28,0,R,x,P,O,E[Q]),D=47;else if(10==D)D=30;else if(29==D)D=(e&26)==e?69:90;else if(50==D)R=nw(48,30,R),O&&O[Ie]?O.V.add(String(E),R,U,V(L,\"object\",x)?!!x.capture:!!x,P):oe(40,\"object\",false,E,U,R,P,O,x),D=75;else if(31==D)D=Array.isArray(E)?77:50;else if(28==D)D=U.g?66:61;else if(33==D)U=Math.floor(Math.random()*this.n),50>U&&(this.o[U]=u),D=90;else if(84==D)D=50>this.o.length?72:33;else if(61==D)U.g=u,U.A(),D=66;else if(78==D)D=29;else if(77==D)Q=u,D=10;else if(30==D)D=Q<E.length?49:75;else if(75==D)D=1==e-8>>3?28:66;else if(72==D)this.o.push(u),D=90;else if(47==D)Q++,D=30;else if(90==D)D=1==((e^21)&7)?31:75;else if(69==D)this.n++,D=84;else if(66==D)return m},Z2=function(L,U,e,u,R,x,P,O,E,Q,D,m,M,n){for(M=16;14!=M;)if(9==M){for(R in x=(Array.prototype.forEach.call(EI(34,(u={},\"string\"),U),function(Y){u[Y]=true}),Array.prototype.forEach.call(e,function(Y){u[Y]=true}),\"\"),u)x+=0<x.length?\" \"+R:R;G(14,\"class\",U,x),M=91}else if(45==M)M=L+2>>4?91:26;else if(23==M)Z2(15,\"object\",0,u,R,x,P,O[m]),M=92;else if(71==M)this.p2=a.document||document,M=6;else if(38==M)m=e,M=86;else if(4==M)M=2==(L<<1&15)?94:90;else if(86==M)M=11;else if(26==M)M=U.classList?83:9;else if(88==M)D=V(20,U,R)?!!R.capture:!!R,P=nw(48,15,P),M=1;else if(94==M){a:{for(x in R)if(u.call(void 0,R[x],x,R)){n=U;break a}n=e}M=90}else if(11==M)M=m<O.length?23:45;else{if(6==M)return n;27==M?(x.V.remove(String(O),P,D,u),M=45):92==M?(m++,M=11):91==M?M=3==L-6>>3?71:6:10==M?(E=b(36,x),M=73):87==M?M=x?10:45:16==M?M=4:51==M?((Q=E.TV(P,O,u,D))&&oe(32,true,null,Q),M=45):90==M?M=(L-6|8)<L&&(L-4^27)>=L?98:45:73==M?M=E?51:45:83==M?(Array.prototype.forEach.call(e,function(Y,K,c){for(c=85;28!=c;)85==c?c=U.classList?16:56:56==c?c=(U.classList?U.classList.contains(Y):b(35,0,Y,EI(33,\"string\",U)))?28:62:16==c?(U.classList.add(Y),c=28):62==c&&(K=PM(\"\",29,\"class\",\"string\",U),G(64,\"class\",U,K+(0<K.length?\" \"+Y:Y)),c=28)}),M=91):1==M?M=x&&x[Ie]?27:87:98==M&&(M=Array.isArray(O)?38:88)}},G=function(L,U,e,u,R,x,P,O,E,Q,D,m,M,n,Y,K){for(M=(Y=61,60);;)try{if(1==Y)break;else if(47==Y)Q=P.j,Q(function(){V(77,e,R,R,P)}),Y=71;else if(35==Y)M=11,E=wO(U,O,P,e),Y=85;else if(61==Y)Y=29;else if(85==Y)M=60,Y=20;else if(17==Y)this.Dl=this.Dl,this.g=this.g,Y=41;else if(29==Y)Y=L+4>>4?41:17;else if(71==Y)n=E,Y=67;else if(53==Y)Y=(L&78)==L?80:51;else{if(51==Y)return n;if(74==Y){if(e.i=(E=(m=(D=(u||e.tN++,0<e.gX)&&e.JN&&e.mk&&1>=e.K2&&!e.h&&!e.j&&(!u||1<e.ar-R)&&document.hidden==U,P=4==e.tN)||D?e.Z():e.mS,Q=m-e.mS,Q>>14),e.O&&(e.O^=E*(Q<<2)),E)||e.i,e.Zl+=E,P||D)e.tN=0,e.mS=m;Y=(!D||m-e.VN<e.gX-(x?255:u?5:2)?n=U:(e.ar=R,O=l(e,u?221:400),N(e,400,e.l),e.R.push([TL,O,u?R+1:R,e.T,e.F]),e.j=Cw,n=true),84)}else 41==Y?Y=2==(L+8&7)?74:84:28==Y?Y=18:20==Y?Y=x&&P.j?47:28:27==Y?Y=18:67==Y?Y=(L|48)==L?16:53:18==Y?Y=P.R.length?34:71:21==Y?(M=60,G(49,u,K,P),Y=85):80==Y?(\"string\"==typeof e.className?e.className=u:e.setAttribute&&e.setAttribute(U,u),Y=51):16==Y?(u.Y=((u.Y?u.Y+\"~\":\"E:\")+e.message+\":\"+e.stack).slice(U,2048),Y=53):34==Y?(P.j=U,O=P.R.pop(),Y=35):84==Y&&(Y=21<=(L|7)&&32>(L|8)?27:67)}}catch(c){if(60==M)throw c;11==M&&(K=c,Y=21)}},ae=function(L,U,e,u,R,x,P,O,E,Q){for(E=32;E!=U;)if(94==E)this.n++,e=R-this.hN,this.hN+=e/this.n,this.Hz+=e*(R-this.hN),E=13;else if(13==E)E=u+7&6?0:97;else if(95==E)E=1==(u-4&7)?94:13;else{if(0==E)return Q;32==E?E=95:97==E&&(this.listener=P,this.proxy=L,this.src=O,this.type=e,this.capture=!!x,this.US=R,this.key=++BM,this.GV=this.zV=false,E=0)}},lq=function(L,U,e,u,R,x,P,O,E,Q){for(E=90;7!=E;)if(90==E)E=25;else if(25==E)E=2<=(U^29)>>3&&8>(U<<1&8)?79:L;else if(68==E)E=0<=(U+7&7)&&9>(U+4&15)?10:34;else if(79==E)u.GV=e,u.listener=null,u.proxy=null,u.src=null,u.US=null,E=L;else if(E==L)E=1<=U+1>>3&&2>(U>>2&8)?19:68;else{if(34==E)return Q;19==E?(Fr.call(this),this.V=new zL(this),this.rX=null,this.Sf=this,E=68):10==E&&(O=new g(e,P,x,u),Q=[function(D){return oe(6,false,D,O)},function(D){O.sS(D)}],E=34)}},t=function(L,U,e,u,R,x,P,O,E,Q,D){for(D=86;62!=D;)if(16==D)D=L?51:58;else if(82==D)D=(U&44)==U?66:69;else if(69==D)D=(U+5^21)<U&&(U-3^22)>=U?16:88;else if(50==D)D=\"\"===u||void 0==u?65:55;else if(45==D)D=(U|56)==U?3:53;else if(49==D)Q=R,D=69;else if(29==D)e+=String.fromCharCode.apply(null,L.slice(x,x+8192)),D=67;else{if(15==D)return Q;if(86==D)D=45;else{if(63==D)throw Error(\"Invalid decorator function \"+e);if(8==D)E={},Ns=(E.atomic=false,E.autocomplete=\"none\",E.dropeffect=\"none\",E.haspopup=false,E.live=\"off\",E.multiline=false,E.multiselectable=false,E.orientation=\"vertical\",E.readonly=false,E.relevant=\"additions text\",E.required=false,E.sort=\"none\",E.busy=false,E.disabled=false,E[e]=false,E.invalid=\"false\",E),D=41;else if(65==D)D=Ns?41:8;else if(66==D)u=window.btoa,D=90;else if(57==D)D=21;else if(93==D)x=typeof R,P=x!=u?x:R?Array.isArray(R)?\"array\":x:\"null\",Q=P==e||P==u&&typeof R.length==L,D=82;else if(21==D)D=x<L.length?29:25;else if(67==D)x+=8192,D=21;else if(55==D)x.setAttribute(O,u),D=15;else if(90==D)D=u?26:91;else if(53==D)D=6<=(U>>1&7)&&11>(U>>2&12)?93:82;else if(25==D)R=u(e).replace(/\\\\+/g,\"-\").replace(/\\\\//g,\"_\").replace(/=/g,\"\"),D=49;else if(41==D)P=Ns,R in P?x.setAttribute(O,P[R]):x.removeAttribute(O),D=15;else if(91==D)R=void 0,D=49;else if(3==D)L.ua=void 0,L.kU=function(){return L.ua?L.ua:L.ua=new L},D=53;else if(88==D)D=U-6&15?15:95;else if(51==D)D=\"function\"!==typeof e?63:88;else if(26==D)e=\"\",x=0,D=57;else{if(58==D)throw Error(\"Invalid class name \"+L);95==D&&(Array.isArray(u)&&(u=u.join(\" \")),O=L+R,D=50)}}}},y=function(L,U,e,u,R,x,P,O,E,Q,D){for(D=7;35!=D;)if(49==D)D=U<<2&7?59:54;else if(97==D)Q=function(){},Q.prototype=u.prototype,e.m=u.prototype,e.prototype=new Q,e.prototype.constructor=e,e.sk=function(m,M,n){for(var Y=37;74!=Y;)if(37==Y)var K=Array((Y=97,arguments).length-L),c=L;else if(29==Y)Y=c<arguments.length?24:63;else if(97==Y)Y=29;else{if(63==Y)return u.prototype[M].apply(m,K);24==Y?(K[c-L]=arguments[c],Y=49):49==Y&&(c++,Y=29)}},D=45;else if(7==D)D=1;else if(1==D)D=(U&47)==U?60:49;else if(60==D){for(P in O=L,u.X){for(R=u.X[P],x=L;x<R.length;x++)++O,lq(69,41,e,R[x]);delete u.X[P],u.YU--}D=49}else if(54==D)this.src=L,this.X={},this.YU=0,D=59;else{if(45==D)return E;59==D&&(D=(U-4^26)<U&&(U-9|27)>=U?97:45)}},bq=function(L,U,e,u,R,x,P,O,E,Q,D,m){for(D=84;23!=D;){if(58==D)return m;if(19==D)D=0==u.X[x].length?21:45;else if(76==D)D=U-8<<1>=U&&(U-3|84)<U?57:58;else if(66==D)x=R.type,D=10;else if(96==D)D=12<=(U>>1&23)&&1>(U^37)>>4?66:45;else if(47==D)D=1==(U+3&19)?82:96;else if(10==D)D=x in u.X&&sI(10,6,0,u.X[x],R)?30:45;else if(84==D)D=47;else if(2==D)pw(35,L,12,u,E,P,O,x,R),D=53;else if(29==D)D=Q<R.length?0:53;else if(82==D)m=Math.floor(this.Z()),D=96;else if(92==D)D=Array.isArray(R)?17:1;else if(21==D)delete u.X[x],u.YU--,D=45;else if(57==D)this.type=e,this.currentTarget=this.target=u,this.defaultPrevented=this.ia=false,D=58;else if(53==D)D=2==(U<<1&23)?27:76;else if(30==D)lq(69,43,e,R),D=19;else if(13==D)Q++,D=29;else if(0==D)bq(true,3,false,0,R[Q],x,P,O,E),D=13;else if(17==D)Q=u,D=4;else if(27==D){if((R=u.length,R)>e){for(P=(x=Array(R),e);P<R;P++)x[P]=u[P];m=x}else m=[];D=76}else 4==D?D=29:45==D?D=(U&43)==U?18:53:18==D?D=P&&P.once?2:92:1==D&&(E=nw(48,14,E),x&&x[Ie]?x.V.add(String(R),E,e,V(18,\"object\",P)?!!P.capture:!!P,O):oe(41,\"object\",false,R,e,E,O,x,P),D=53)}},gO=function(L,U,e,u,R,x){for(R=45;85!=R;)if(51==R)x=u,R=28;else if(R==L)this[this+\"\"]=this,R=76;else if(97==R)R=(e-7|21)<e&&e-4<<2>=e?L:76;else if(45==R)R=97;else{if(28==R)return x;76==R&&(R=2<=e+3&&3>(e>>2&U)?51:28)}},QV=function(L,U,e,u,R,x,P,O,E,Q){for(Q=6;95!=Q;)if(28==Q)E=P,Q=26;else{if(53==Q)return E;if(54==Q)E=!!(U.Xp&e)&&!!(U.S&e)!=x&&(!(P=U.rb,(P|0)-R*~e+R*~(P|e)+(P&~e))||U.dispatchEvent(oe(3,R,16,8,4,e,x)))&&!U.g,Q=29;else if(6==Q)Q=34;else if(45==Q){a:if(\"string\"===typeof x)E=\"string\"!==typeof U||U.length!=R?-1:x.indexOf(U,e);else{for(P=e;P<x.length;P++)if(P in x&&x[P]===U){E=P;break a}E=-1}Q=53}else 26==Q?Q=u>>1&1?29:54:59==Q?(x=new mq(e,this),U=R.listener,O=R.US||R.src,R.zV&&oe(L,true,null,R),P=U.call(O,x),Q=28):29==Q?Q=(u|32)==u?45:53:44==Q?Q=R.GV?25:59:25==Q?(P=true,Q=28):34==Q&&(Q=u+3>>4?26:44)}},oe=function(L,U,e,u,R,x,P,O,E,Q,D,m,M,n,Y){for(Y=95;48!=Y;)if(31==Y)u.NU(function(K){R=K},U,e),n=R,Y=57;else if(57==Y)Y=L>>1&13?13:79;else if(56==Y)Y=O.addListener&&O.removeListener?87:0;else if(96==Y){a:{switch(x){case 1:n=P?\"disable\":\"enable\";break a;case U:n=P?\"highlight\":\"unhighlight\";break a;case R:n=P?\"activate\":\"deactivate\";break a;case u:n=P?\"select\":\"unselect\";break a;case e:n=P?\"check\":\"uncheck\";break a;case 32:n=P?\"focus\":\"blur\";break a;case 64:n=P?\"open\":\"close\";break a}throw Error(\"Invalid component state\");}Y=60}else if(86==Y)Y=7>(L>>1&8)&&10<=((L|2)&15)?51:39;else if(39==Y)Y=1==(L>>1&15)?96:60;else if(76==Y)x=u.src,Y=6;else if(38==Y)Y=O?21:45;else if(41==Y)ko||(E=m),void 0===E&&(E=e),O.addEventListener(u.toString(),M,E),Y=43;else if(3==Y)Y=28;else if(52==Y)Y=O.addEventListener?41:70;else if(49==Y)bq(true,39,U,x.V,u),Y=13;else if(21==Y)bq(true,36,U,O,u),Y=44;else if(69==Y)Y=D.proxy?39:66;else if(79==Y)Y=\"number\"!==typeof u&&u&&!u.GV?76:13;else if(33==Y)O.src=e,x[tP]=e,Y=13;else{if(15==Y)throw Error(\"Invalid event type\");if(51==Y)Y=u?97:15;else if(44==Y)Y=0==O.YU?33:13;else if(95==Y)Y=86;else if(60==Y)Y=17<=L<<2&&36>(L^19)?31:57;else if(45==Y)lq(69,40,U,u),Y=13;else if(97==Y)m=V(34,U,E)?!!E.capture:!!E,(Q=b(6,O))||(O[tP]=Q=new zL(O)),D=Q.add(u,x,R,m,P),Y=69;else if(43==Y)WM++,Y=39;else if(72==Y)P=u.type,R=u.proxy,x.removeEventListener?x.removeEventListener(P,R,u.capture):x.detachEvent?x.detachEvent(JP(\"on\",P,7),R):x.addListener&&x.removeListener&&x.removeListener(R),WM--,O=b(8,x),Y=38;else{if(28==Y)return n;if(13==Y)Y=(L&93)==L?3:28;else if(66==Y)M=V(17),D.proxy=M,M.src=O,M.listener=D,Y=52;else if(87==Y)O.addListener(M),Y=43;else if(70==Y)Y=O.attachEvent?77:56;else if(77==Y)O.attachEvent(JP(\"on\",u.toString(),5),M),Y=43;else{if(0==Y)throw Error(\"addEventListener and attachEvent are unavailable.\");6==Y&&(Y=x&&x[Ie]?49:72)}}}},r=function(L,U,e,u,R,x,P,O,E,Q,D){for(D=85;87!=D;)if(22==D)D=L>>1&15?99:53;else if(93==D)D=1==(L>>2&11)?74:27;else if(8==D)D=52;else{if(79==D)return Q;if(99==D)D=(L|24)==L?92:93;else if(77==D)x++,D=52;else if(85==D)D=22;else if(92==D)P=x=0,D=8;else if(52==D)D=x<U.length?94:69;else if(27==D)D=3==(L>>2&7)?57:79;else if(53==D)N(U,e,u),u[$o]=2796,D=99;else if(94==D)P+=U.charCodeAt(x),P+=P<<10,P^=P>>6,D=77;else if(69==D)P+=P<<3,P=(R=P>>11,-(R|0)+(P&R)+(P&~R)+2*(~P&R)),O=P+(P<<15)>>>0,E=new Number(O&(1<<e)-1),E[0]=(O>>>e)%u,Q=E,D=93;else if(74==D){a:{for(O=U;O<R.length;++O)if(P=R[O],!P.GV&&P.listener==e&&P.capture==!!x&&P.US==u){Q=O;break a}Q=-1}D=27}else 57==D&&(D=79)}},S=function(L,U,e,u,R,x,P,O,E,Q,D,m,M){if((e&110)==e){for(x=(R=I(26,u),0);0<L;L--)x=x<<U|iq(2,u,true);N(u,R,x)}if(22<=e>>((e+1^((e+((e-4|82)>=(23<=(e^84)&&34>e+6&&(m=M=function(){for(var n=32;64!=n;)if(80==n){var Y=wO(null,c,x,254);n=41}else if(32==n)n=x.i==x?84:64;else if(93==n)n=u==L?50:0;else if(0==n)n=u==U?31:80;else if(50==n)X(18,0,c,x),Y=V(78,254,false,false,x),n=41;else{if(41==n)return Y;if(57==n)O&&E&&O.removeEventListener(E,M,SY),n=64;else if(31==n){var K=!x.R.length;n=((X(10,0,c,x),K)&&V(75,254,false,false,x),41)}else if(84==n)n=x.G?44:57;else if(44==n)var c=[dO,P,(n=93,R),void 0,O,E,arguments]}}),e)&&(e-7^11)<e&&(u=eY[U.D](U.Uk),u[U.D]=function(){return L},u.concat=function(n){L=n},m=u),5)^26)<e&&(e-5^29)>=e&&(R=[-52,4,-38,-38,-16,86,R,-39,-79,-61],O=hP,Q=P&7,E=eY[x.D](x.iH),E[x.D]=function(n){Q=((Q+=6+(D=n,7*P),Q)|0)-~(Q&7)+~Q},E.concat=function(n,Y,K,c){return c=(D=(Y=(n=u%16+U,+(O()|0)*n+Q+R[Q+L&7]*u*n+3*u*u*n- -1258*D+37*D*D-n*D)-111*u*u*D-148*u*D,void 0),R)[Y],R[(K=Q+69,(K|7)- -1+(~K^7))+(P&2)]=c,R[Q+((P|0)- -1+(~P|2))]=4,c},m=E),9))>=e&&(e+4^18)<e&&(u=iq(2,L,true),-~u-(~u^128)-(~u&128)+U*(~u|128)&&(u=u&127|iq(2,L,true)<<7),m=u),1)&&15>(e>>2&16))if(R=\"array\"===qs(\"object\",\"splice\",u)?u:[u],this.Y)U(this.Y);else try{P=!this.R.length,x=[],X(20,0,[vM,x,R],this),X(11,0,[HM,U,x],this),L&&!P||V(79,254,L,true,this)}catch(n){G(48,0,n,this),U(this.Y)}return m},b=function(L,U,e,u,R,x){for(R=80;97!=R;)if(46==R)R=(L&99)==L?15:67;else if(9==R)x=Math.floor(this.jQ+(this.Z()-this.VN)),R=46;else if(15==R)x=QV(33,e,U,35,1,u)>=U,R=67;else if(98==R)R=4==(L-6&15)?73:11;else if(67==R)R=1==(L-1&25)?22:47;else if(80==R)R=98;else if(73==R)x=U&&U.parentNode?U.parentNode.removeChild(U):null,R=11;else{if(5==R)return x;78==R?(d.call(this,U,e||AP.kU(),u),R=5):22==R?(e=U[tP],x=e instanceof zL?e:null,R=47):11==R?R=2==(L<<1&14)?9:46:47==R&&(R=3==((L^93)&23)?78:5)}},EI=function(L,U,e,u,R,x,P,O,E,Q,D){for(D=15;23!=D;)if(28==D)D=8;else if(31==D)D=R<U.length?83:29;else if(49==D)D=7<P?93:43;else if(74==D)D=8;else if(50==D)eU.call(this,u),D=59;else if(76==D)D=(L+3^13)>=L&&(L-1^21)<L?13:66;else if(13==D)R=0,x=[],P=0,D=16;else if(81==D)R=O?\"function\"===typeof O.kU?O.kU():new O:null,D=91;else if(83==D)u=u<<e|U[R],P+=e,D=99;else if(35==D)Q=Object.prototype.hasOwnProperty.call(U,Db)&&U[Db]||(U[Db]=++Rl),D=97;else if(16==D)D=31;else if(29==D)Q=x,D=66;else if(98==D)D=2==(L+3&6)?35:97;else if(15==D)D=76;else if(8==D)D=x?45:81;else if(99==D)D=49;else if(69==D)x=this.constructor,D=74;else if(26==D)Q=e.classList?e.classList:PM(\"\",21,\"class\",U,e).match(/\\\\S+/g)||[],D=2;else if(66==D)D=L+5>>4?98:50;else if(22==D)D=81;else if(91==D)this.J=R,D=98;else if(93==D)P-=8,x.push((O=u>>P,(O|0)-(O^255)+(~O&255))),D=86;else{if(2==D)return Q;47==D?(x=(P=Object.getPrototypeOf(x.prototype))&&P.constructor,D=28):59==D?D=(R=e)?91:69:43==D?(R++,D=31):45==D?(E=EI(16,x),D=73):97==D?D=(L|32)==L?26:2:73==D?D=(O=UF[E])?22:47:86==D&&(D=49)}},La=function(){return oe.call(this,80)},zL=function(L){return y.call(this,L,16)},EF=function(L,U,e,u,R,x,P,O,E,Q){U.push((e=(E=L[0]<<24,P=L[1]<<16,-(E&P)-1-2*~(E|P)+(~E^P)),u=L[2]<<8,~(e&u)-~u-~(e|u)+(e|~u))|L[3]),U.push((x=(R=L[4]<<24|L[5]<<16,O=L[6]<<8,-~O+2*(R&~O)+(~R^O)+(~R&O)),Q=L[7],2*(Q|0)- -1+~Q+(x&~Q))),U.push(L[8]<<24|L[9]<<16|L[10]<<8|L[11])},Lw=function(L,U,e,u,R,x){return QV.call(this,33,u,U,3,L,e,R,x)},jU=function(L,U,e,u,R,x,P,O,E,Q,D,m,M,n,Y){for(n=(m=(P=U.replace(/\\\\r\\\\n/g,\"\\\\n\"),[]),D=0);D<P.length;D++)R=P.charCodeAt(D),128>R?m[n++]=R:(2048>R?m[n++]=R>>6|192:(55296==(R&64512)&&D+1<P.length&&56320==(M=P.charCodeAt(D+1),-~(M&64512)+(M^64512)+(~M^64512))?(R=65536+((R|0)+(~R^1023)-(R|-1024)<<10)+(E=P.charCodeAt(++D),-~(E|1023)-(E&-1024)+(E|-1024)),m[n++]=(Y=R>>18,(Y|0)-(Y&-241)+(Y^240)),m[n++]=(u=(O=R>>12,(O|63)- -1+(~O^63)),(u|0)+(u&128)+~(u&128)-(u|-129))):m[n++]=(e=R>>12,223-(~e|224)),m[n++]=(x=R>>6,-(x|0)-2*~(x|63)-(x&-64)+2*(x|-64))|128),m[n++]=(Q=L+(R|-64),(Q|0)-1-(Q|-129)));return m},uu=function(L,U,e,u,R,x,P,O,E,Q,D,m){for(D=37;75!=D;)if(70==D)m(E),D=22;else if(33==D)E=L[Q],D=76;else if(76==D)D=!t(\"number\",28,x,e,E)||V(3,e,E)&&0<E.nodeType?70:49;else if(22==D)Q++,D=30;else if(87==D)D=30;else if(30==D)D=Q<L.length?33:75;else if(49==D){a:{if(E&&\"number\"==typeof E.length){if(V(19,e,E)){O=\"function\"==typeof E.item||typeof E.item==P;break a}if(\"function\"===typeof E){O=\"function\"==typeof E.item;break a}}O=false}D=(nw(48,48,\"\",0,O?bq(true,5,0,E):E,m),22)}else 37==D&&(m=function(M){M&&u.appendChild(\"string\"===typeof M?R.createTextNode(M):M)},Q=U,D=87)},N=function(L,U,e){if(400==U||221==U)L.G[U]?L.G[U].concat(e):L.G[U]=S(e,L,31);else{if(L.Bz&&16!=U)return;404==U||325==U||11==U||29==U||164==U||389==U||131==U?L.G[U]||(L.G[U]=S(27,1,43,U,e,L,150)):L.G[U]=S(27,1,75,U,e,L,9)}16==U&&(L.O=Xr(32,2,false,L),L.u=void 0)},Fr=function(){return G.call(this,3)},xL=function(L,U){function e(){this.o=(this.n=0,[])}return[function(u){(L.Pz(u),U).Pz(u)},(U=(e.prototype.ba=function(){return PM.call(this,\"\",3)},e.prototype.Pz=function(u,R){return pw.call(this,35,R,8,u)},L=new e,new e),function(u){return U=new (u=L.ba().concat(U.ba()),e),u})]},PR=function(L,U,e,u,R,x,P){((P=l(L,(R=(u=I(30,(e=(x=2*(U|0)-(U|4)-(U&-5)+(~U&4),3-~(U&3))+-4,L)),I(26,L)),u)),x)&&(P=jU(64,\"\"+P)),e)&&h(q(2,P.length),R,L),h(P,R,L)},xo=function(){return Z2.call(this,30)},cM=function(L,U,e){return(e=L.create().shift(),U.h).create().length||U.N.create().length||(U.h=void 0,U.N=void 0),e},QY=function(L,U,e){return b.call(this,22,L,U,e)},sF=function(L,U){function e(){this.Hz=this.hN=this.n=0}return[(U=(L=new ((e.prototype.wX=function(){return PM.call(this,\"\",88)},e).prototype.f2=function(u,R){return ae.call(this,null,26,R,5,u)},e),new e),function(u){(L.f2(u),U).f2(u)}),function(u){return U=(u=[L.wX(),U.wX()],new e),u}]},jY=function(){return lq.call(this,69,7)},mK=function(L,U,e,u,R,x){u.MU.length>R?M5(L,u,[OF,36],U):(u.MU.push(u.G.slice()),u.G[x]=void 0,N(u,x,e))},v,YL=function(L){return gO.call(this,20,8,3,L)},AP=function(){return r.call(this,12)},na=function(){return sI.call(this,10,12)},q=function(L,U,e,u){for(e=(u=-~(L&1)+-4-~(L|1),[]);0<=u;u--)e[(L|0)-1-(u|0)]=U>>8*u&255;return e},fa=function(L,U,e,u){h(q(L,(u=(e=I(14,U),I(18,U)),l)(U,e)),u,U)},qs=function(L,U,e,u,R){if((u=typeof e,u)==L)if(e){if(e instanceof Array)return\"array\";if(e instanceof Object)return u;if((R=Object.prototype.toString.call(e),\"[object Window]\")==R)return L;if(\"[object Array]\"==R||\"number\"==typeof e.length&&\"undefined\"!=typeof e.splice&&\"undefined\"!=typeof e.propertyIsEnumerable&&!e.propertyIsEnumerable(U))return\"array\";if(\"[object Function]\"==R||\"undefined\"!=typeof e.call&&\"undefined\"!=typeof e.propertyIsEnumerable&&!e.propertyIsEnumerable(\"call\"))return\"function\"}else return\"null\";else if(\"function\"==u&&\"undefined\"==typeof e.call)return L;return u},ol=function(L,U,e,u,R,x,P,O){for(R.Uk=(R.iH=UI(((R.J$=R[HM],R.Mg=GM,R).CG=Ka,17),11,R.D,{get:function(){return this.concat()}}),eY[R.D](R.iH,{value:{value:{}}})),O=0,x=[];259>O;O++)x[O]=String.fromCharCode(O);V(76,254,(X(19,(X(12,0,(r(32,R,252,(N(R,164,[0,0,(r(33,((r(64,R,(r(32,R,41,(N(R,(N(R,(r(64,R,33,(r(32,R,(N(R,(r(64,(N(R,131,[(N(R,(r(65,(r(64,R,254,(r(32,(r(32,R,393,(r(33,R,((r(33,R,508,(N(R,389,(r(65,R,(r(65,R,(N(R,81,(N(R,(N(R,29,(r(65,(r(33,R,256,(r(33,R,(R.jf=(r(64,(r(32,R,(N((r(64,R,(r(65,R,262,(pw(((r(33,(r(65,R,(N(R,(r((N(R,221,(N(R,(R.KG=(P=((R.K2=0,R).L2=(R.mS=(R.G=((R.tN=void 0,R).Ng=e,R.O=void 0,(R.yx=function(E){return UI.call(this,17,8,E)},R).i=R,(R.l=0,R).N=(R.JN=false,void 0),R.VN=0,R.u=void 0,R.n2=(R.ar=8001,25),[]),0),R.H5=0,R.Y=(R.Bz=false,void 0),R.T=false,((R.MU=[],R).B=[],R).h=void 0,(R.R=[],R.mk=false,R).gX=(R.j=null,R.Wz=(R.Zl=1,R.jQ=0,[]),R.Ir=void 0,R.F=false,0),[]),(R.vz=U,window.performance)||{}),P.timeOrigin||(P.timing||{}).navigationStart||0),400),0),0)),N(R,404,[165,0,0]),33),R,255,function(E,Q,D,m){(m=I((Q=(D=I(14,E),I)(26,E),26),E),N)(E,m,l(E,D)||l(E,Q))}),325),X8(4)),225),function(E,Q,D,m,M,n){N(E,(m=(D=l(E,(n=I((M=I(34,(Q=I(34,E),E)),34),E),M)),l(E,Q)),n),m in D|0)}),R),412,function(E,Q,D,m,M,n){N(E,(Q=l(E,(n=l((M=(m=I(22,E),D=I(30,E),I(26,E)),E),m),D)),M),n[Q])}),r)(32,R,204,function(){}),35),new QY(\"Submit\"),19,true),function(E){S(4,8,72,E)})),290),function(E,Q){(Q=l(E,I(38,E)),mK)(2,0,Q,E.i,104,400)}),R),11,[]),259),function(E,Q,D,m,M,n,Y,K,c,Z,T,C,D2,B,p,fw,H,J){for(J=42;96!=J;)75==J?(M.push(l(E,I(18,E))),J=58):42==J?(H=function(k,z){for(;T<k;)D|=iq(2,E,true)<<T,T+=8;return D>>=(z=D&(T-=k,(1<<k)-1),k),z},fw=I(30,E),T=D=0,K=(H(3)|0)+1,Q=H(5),n=0,Z=[],c=0,J=87):21==J?J=15:0==J?J=59:4==J?(C++,J=59):58==J?J=44:72==J?(B++,J=15):89==J?(r(65,E,fw,function(k,z,Kw,Re,W,w){for(w=31;97!=w;)89==w?(W.push(Re),w=54):54==w?(z++,w=58):42==w?w=Re>=Kw.length?90:83:60==w?(Re=Y[z],w=50):56==w?w=42:30==w?(k.h=S(M.slice(),k,33),k.N=S(W,k,30),w=97):31==w?(z=0,W=[],Kw=[],w=28):50==w?w=Z[z]?89:56:90==w?(Kw.push(I(14,k)),w=61):61==w?w=42:58==w?w=z<Q?60:30:28==w?w=58:83==w&&(Re=Kw[Re],w=89)}),J=96):98==J?(M=[],m=K,J=61):44==J?J=m--?75:89:87==J?J=35:59==J?J=C<Q?34:98:43==J?(p=H(1),Z.push(p),n+=p?0:1,J=41):35==J?J=c<Q?43:47:65==J?J=C=0:47==J?(D2=((n|0)-1).toString(2).length,Y=[],B=0,J=21):34==J?(Z[C]&&(Y[C]=I(14,E)),J=4):15==J?J=B<Q?18:65:41==J?(c++,J=35):18==J?(Z[B]||(Y[B]=H(D2)),J=72):61==J&&(J=44)}),R),505,function(E,Q,D,m,M){Q=l((m=0!=l(E,(D=(M=I(22,E),I)(14,E),M)),E),D),m&&N(E,400,Q)}),0),422),function(E,Q,D,m,M,n){N(E,(Q=l((M=l(E,(n=I(26,(m=I(26,(D=I(18,E),E)),E)),D)),E),m),n),+(M==Q))}),function(E,Q,D,m,M,n,Y,K,c,Z,T){for(T=71;67!=T;)71==T?(Z=I(18,E),c=I(38,E),K=I(34,E),m=I(14,E),D=l(E.i,Z),Q=l(E,c),M=l(E,m),Y=l(E,K),T=49):49==T?T=0!==D?89:67:89==T&&(n=S(2,1,3,1,M,E,Y,D,Q),D.addEventListener(Q,n,SY),l(E,141).push(function(){D.removeEventListener(Q,n,SY)}),N(E,307,[D,Q,n]),T=67)})),R),435,function(E){fa(4,E)}),[])),183),R),a)),157),function(E,Q,D){(D=(Q=I(26,E),l(E.i,Q)),D)[0].removeEventListener(D[1],D[2],SY)}),258),function(E,Q,D,m,M,n,Y,K){N(E,(K=(Y=l(E,(D=l(E,(M=I(22,(m=I(22,(Q=I(18,(n=I(38,E),E)),E)),E)),m)),Q)),l(E,M)),n),S(2,1,7,K,D,E,Y))}),X8)(4)),function(E,Q,D,m,M,n,Y,K){for(K=30;48!=K;)55==K?(E.O=Xr(32,2,false,E),E.u=void 0,K=48):22==K?K=16==Y?46:48:12==K?(D=l(E,Y),Q=l(E,m),n=l(E,M),D[n]=Q,K=22):84==K?K=2==n?55:48:46==K?(E.u=void 0,K=84):47==K?K=E.i==E?12:48:30==K&&(Y=I(22,E),M=I(22,E),m=I(30,E),K=47)})),r)(32,R,428,function(E,Q,D,m,M){for(M=83;40!=M;)83==M?M=G(98,false,E,true,Q,false)?40:72:72==M&&(m=I(34,E),D=I(22,E),N(E,D,function(n){return eval(n)}(cR(l(E.i,m)))),M=40)}),R.o6=0,388),function(E,Q,D,m,M,n,Y,K,c,Z,T,C,D2,B,p){for(p=6;28!=p;)if(87==p)C=0<C?C:1,D2=B.length,M=0,p=50;else if(29==p){for(T in Y=[],B)Y.push(T);B=(p=37,Y)}else 0==p?(Z(B.slice(M,-1-~M-~(M|C)+(~M|C)),D),p=26):14==p?(m=I(18,E),c=I(14,E),n=I(18,E),K=I(38,E),B=l(E,m),Z=l(E,c),C=l(E,n),D=l(E,K),p=76):76==p?p=\"object\"==qs(\"object\",\"splice\",B)?29:37:37==p?p=E.i==E?87:28:6==p?p=G(34,false,E,true,Q,true)?28:14:2==p?p=M<D2?0:28:26==p?(M+=C,p=2):50==p&&(p=2)}),function(E,Q,D,m,M,n,Y,K,c,Z){for(Z=87;55!=Z;)87==Z?Z=G(42,false,E,true,Q,false)?55:66:66==Z&&(m=bu(2,34,0,1,E.i),M=m.GZ,Y=m.XN,D=m.L,K=m.qU,n=D.length,c=0==n?new M[K]:1==n?new M[K](D[0]):2==n?new M[K](D[0],D[1]):3==n?new M[K](D[0],D[1],D[2]):4==n?new M[K](D[0],D[1],D[2],D[3]):2(),N(E,Y,c),Z=55)})),R),77,function(E,Q,D,m,M,n){for(n=65;60!=n;)29==n?(N(E,M,m),n=60):50==n?n=30:65==n?(M=I(18,E),D=S(E,2,86),Q=0,m=[],n=50):30==n?n=Q<D?13:29:13==n?(m.push(iq(2,E,true)),n=94):94==n&&(Q++,n=30)}),function(E,Q,D,m,M){N(E,(D=l(E,(Q=l((m=I(38,E),M=I(30,E),E),m),M)),M),D+Q)})),R),439,function(E,Q,D,m,M){N(E,(m=qs(\"object\",\"splice\",(D=l(E,(M=(Q=I(30,E),I(34,E)),Q)),D)),M),m)}),141),[]),2048)]),R),114,function(E,Q,D,m){D=I(34,(Q=iq(2,E,(m=I(38,E),true)),E)),N(E,D,l(E,m)>>>Q)}),307),0),121),function(E,Q,D,m,M){for(M=10;85!=M;)91==M?M=D?5:86:18==M?(Q=I(18,E),D[Q]=E.G[Q],M=25):25==M?(m--,M=75):10==M?(D=E.MU.pop(),M=91):90==M?(D[29]=E.G[29],D[131]=E.G[131],E.G=D,M=85):22==M?M=75:75==M?M=0<m?18:90:5==M?(m=iq(2,E,true),M=22):86==M&&(N(E,400,E.l),M=85)}),function(E){PR(E,3)})),399),0),r(64,R,58,function(E,Q,D,m,M,n){for(n=1;19!=n;)1==n?n=G(82,false,E,true,Q,false)?19:69:99==n?n=E.i==E||D==E.yx&&m==E?96:19:69==n?(M=bu(2,34,0,1,E),m=M.GZ,D=M.qU,n=99):96==n&&(N(E,M.XN,D.apply(m,M.L)),E.mS=E.Z(),n=19)}),138),{}),function(E){PR(E,4)})),N(R,30,430),425),function(E){fa(1,E)}),R).Ok=0,R),293,function(E,Q,D){(D=I(14,(Q=I(38,E),E)),N)(E,D,\"\"+l(E,Q))}),0)]),function(E,Q,D,m,M,n,Y,K){for(K=75;3!=K;)90==K?K=24:26==K?(N(E,M,Q),K=3):95==K?K=24:24==K?K=D--?68:26:75==K?(M=I(26,E),D=S(E,2,84),Q=\"\",m=l(E,218),n=m.length,Y=0,K=90):68==K&&(Y=((Y|0)+(S(E,2,85)|0))%n,Q+=x[m[Y]],K=95)})),[$o]),R),X(26,0,[pa,L],R),0),[Il,u],R),true),true,R)},Zb=function(L,U,e,u,R,x,P,O,E,Q){for(E=(O=P[2]|(Q=P[3]|L,L),L);E<U;E++)x=x>>>8|x<<24,x+=R|L,x^=O+e,R=R<<3|R>>>29,R^=x,Q=Q>>>8|Q<<24,Q+=O|L,O=O<<3|O>>>29,Q^=E+e,O^=Q;return[R>>>24&255,R>>>u&255,R>>>8&255,R>>>L&255,x>>>24&255,x>>>u&255,x>>>8&255,x>>>L&255]},wc=function(L,U,e,u,R,x){return lq.call(this,69,36,L,U,e,u,R,x)},bu=function(L,U,e,u,R,x,P,O,E,Q){for(P=(O=I(38,(x=(((E=I(22,(Q=R[TM]||{},R)),Q).XN=I(22,R),Q).L=[],R.i)==R?(iq(L,R,true)|e)-u:1,R)),e);P<x;P++)Q.L.push(I(U,R));for(Q.qU=l(R,E);x--;)Q.L[x]=l(R,Q.L[x]);return Q.GZ=l(R,O),Q},mq=function(L,U,e,u,R){return nw.call(this,48,3,L,U,e,u,R)},a=this||self,iq=function(L,U,e){return U.h?cM(U.N,U):Xr(8,L,e,U)},wO=function(L,U,e,u,R,x,P,O,E,Q,D){if(x=U[0],x==vM)e.n2=25,e.F=true,e.H(U);else if(x==HM){e.F=(R=U[1],true);try{O=e.Y||e.H(U)}catch(m){G(53,0,m,e),O=e.Y}R(O)}else if(x==TL)U[3]&&(e.T=true),U[4]&&(e.F=true),e.H(U);else if(x==pa)e.T=true,e.H(U);else if(x==Il){e.T=true;try{for(P=0;P<e.Wz.length;P++)try{D=e.Wz[P],D[0][D[1]](D[2])}catch(m){}}catch(m){}(0,U[1])(function(m,M){e.NU(m,true,M)},(e.Wz=[],function(m){X(27,0,[Ca],(m=!e.R.length,e)),m&&V(75,u,true,false,e)}),function(m){return e.sS(m)})}else{if(x==dO)return E=U[2],N(e,163,U[6]),N(e,138,E),e.H(U);x==Ca?(e.H(U),e.B=[],e.G=L,e.L2=[]):x==$o&&(Q=a.parent,\"loading\"===Q.document.readyState&&(e.j=function(m,M){function n(Y){for(Y=7;0!=Y;)7==Y?Y=M?0:47:47==Y&&(M=true,Q.document.removeEventListener(\"DOMContentLoaded\",n,SY),Q.removeEventListener(\"load\",n,SY),m(),Y=0)}(Q.document.addEventListener(\"DOMContentLoaded\",(M=false,n),SY),Q).addEventListener(\"load\",n,SY)}))}},BR=function(L,U,e,u,R){if(3==L.length){for(R=0;3>R;R++)U[R]+=L[R];for(e=[13,8,13,12,16,(u=0,5),3,10,15];9>u;u++)U[3](U,u%3,e[u])}},al=function(L,U,e,u,R){return Z2.call(this,3,L,U,e,u,R)},M5=function(L,U,e,u,R,x,P,O,E,Q,D,m){if(!U.Bz&&(Q=void 0,e&&e[0]===OF&&(Q=e[L],u=e[1],e=void 0),m=l(U,29),0==m.length&&(P=l(U,221)>>3,m.push(u,P>>8&255,P&255),void 0!=Q&&m.push(Q&255)),E=\"\",e&&(e.message&&(E+=e.message),e.stack&&(E+=\":\"+e.stack)),D=l(U,131),3<D[0])){(R=(E=jU(64,(D[0]-=(E=E.slice(0,(O=D[0],3*(O&-4)-L*(O^3)-(~O^3)+(~O|3))),x=E.length,(x|3)-(x&3)- -8+L*(x|-4)),E)),U.i),U).i=U;try{h(q(L,E.length).concat(E),325,U,12)}finally{U.i=R}}},F8=function(L,U,e,u,R,x,P,O,E,Q,D,m){for(D=55,m=L;;)try{if(D==U)break;else if(55==D)O=a.trustedTypes,E=P,D=43;else if(87==D)a.console[x](Q.message),D=19;else if(32==D)D=a.console?87:19;else{if(D==e)return E;if(39==D)m=L,D=32;else if(7==D)m=u,E=O.createPolicy(R,{createHTML:YL,createScript:YL,createScriptURL:YL}),D=19;else{if(19==D)return m=L,E;43==D&&(D=O&&O.createPolicy?7:e)}}}catch(M){if(m==L)throw M;m==u&&(Q=M,D=39)}},zM=function(L,U,e,u){try{u=L[((U|0)+2)%3],L[U]=(L[U]|0)-(L[((U&1)-1-~(U|1))%3]|0)-(u|0)^(1==U?u<<e:u>>>e)}catch(R){throw R;}},l=function(L,U,e){if(void 0===(e=L.G[U],e))throw[OF,30,U];if(e.value)return e.create();return e.create(3*U*U+4*U+-34),e.prototype},Xr=function(L,U,e,u,R,x,P,O,E,Q,D,m,M,n,Y,K,c){if(n=l(u,400),n>=u.l)throw[OF,31];for(D=(c=n,L),E=0,O=u.J$.length;0<D;)Q=c>>3,Y=c%8,m=8-(Y|0),x=m<D?m:D,M=u.B[Q],e&&(P=u,P.u!=c>>6&&(P.u=c>>6,R=l(P,16),P.Ir=Zb(0,15,3379,16,P.O,P.u,[0,0,R[1],R[U]])),M^=u.Ir[Q&O]),E|=(M>>8-(Y|0)-(x|0)&(1<<x)-1)<<(D|0)-(x|0),D-=x,c+=x;return N(u,400,(K=E,(n|0)+(L|0))),K},d=function(L,U,e,u,R,x,P,O){return EI.call(this,3,L,U,e,u,R,x,P,O)},X8=function(L,U,e){for(e=86;42!=e;)if(71==e)e=9;else if(31==e)e=9;else if(86==e)U=[],e=31;else if(62==e)U.push(255*Math.random()|0),e=71;else{if(64==e)return U;9==e&&(e=L--?62:64)}},Ms=function(L,U){return bq.call(this,true,87,L,U)},eU=function(L){return PM.call(this,\"\",12,L)},lu=function(){return X.call(this,17)},N5=function(L,U){return V.call(this,5,L,U)},h=function(L,U,e,u,R,x,P,O,E){if(e.i==e)for(x=l(e,U),325==U||389==U?(R=function(Q,D,m,M,n,Y,K,c,Z,T){for(Z=(c=1,31);;)try{if(78==c)break;else if(97==c)x.kK=Y,D=(M=Y<<3,4*(M&-5)-2*(M^4)-(M|-5)+(~M|4)),K=[0,0,O[1],O[2]],c=84;else if(84==c)Z=55,x.A$=Zb(0,15,3379,16,I(8,1,0,D,x),I(7,1,0,(D&4)-~D+(D^4)+(~D|4),x),K),c=2;else if(2==c)x.push((n=x.A$[-2-~m-(m^7)-(m|-8)],~(n&Q)-~Q+(n&~Q))),c=78;else if(1==c)m=x.length,Y=-(~m^4)-(~m&4)+(m|-5)>>3,c=43;else if(43==c)c=x.kK!=Y?97:2;else if(73==c)throw Z=31,T;}catch(C){if(31==Z)throw C;55==Z&&(T=C,c=73)}},O=l(e,164)):R=function(Q){x.push(Q)},u&&R(-~(u|255)-(u^255)+(~u&255)+(u|-256)),E=L.length,P=0;P<E;P++)R(L[P])},kL=function(L,U){for(var e=45;63!=e;)if(49==e)P++,e=27;else if(45==e)var u=(e=22,1);else if(46==e)u++,e=29;else if(22==e)e=29;else if(29==e)e=u<arguments.length?96:63;else if(56==e){var R=gc[P];e=(Object.prototype.hasOwnProperty.call(x,R)&&(L[R]=x[R]),49)}else if(96==e){var x=arguments[u];for(R in x)L[R]=x[R];var P=(e=35,0)}else 27==e?e=P<gc.length?56:46:35==e&&(e=27)},tk=function(L,U,e,u,R){return ae.call(this,null,26,U,9,u,L,R,e)},yY=function(L){return b.call(this,10,L)},rc=function(L,U,e,u,R,x,P,O,E){if(!U.Y){U.K2++;try{for(R=(P=L,E=void 0,U.l);--u;)try{if(O=void 0,U.h)E=cM(U.h,U);else{if(P=l(U,400),P>=R)break;E=l(U,(N(U,221,P),O=I(30,U),O))}G(90,e,(E&&(x=E[Ca],-(x|L)-2*~(x|2048)-(x&-2049)+2*(x|-2049))?E(U,u):M5(2,U,[OF,21,O],L),U),e,u,e)}catch(Q){l(U,30)?M5(2,U,Q,22):N(U,30,Q)}if(!u){if(U.pG){rc(0,U,(U.K2--,false),316769087187);return}M5(2,U,[OF,33],L)}}catch(Q){try{M5(2,U,Q,22)}catch(D){G(51,L,D,U)}}U.K2--}},WR=function(L,U,e,u,R,x){return l(e,((rc(L,e,((x=l(e,400),e.B)&&x<e.l?(N(e,400,e.l),mK(2,L,R,e,U,400)):N(e,400,R),false),u),N)(e,400,x),138))},g=function(L,U,e,u,R){R=this;try{ol(L,U,e,u,this)}catch(x){G(52,0,x,this),u(function(P){P(R.Y)})}},Db=\"closure_uid_\"+(1E9*Math.random()>>>0),Rl=0,uq,ko=function(L,U,e,u,R,x){for(x=(u=8,84);;)try{if(17==u)break;else if(60==u)x=52,e=function(){},a.addEventListener(\"test\",e,U),a.removeEventListener(\"test\",e,U),u=58;else if(84==u)L=false,U=Object.defineProperty({},\"passive\",{get:function(){L=true}}),u=60;else{if(68==u)return false;if(58==u)return x=84,L;39==u?(x=84,u=58):8==u&&(u=a.addEventListener&&Object.defineProperty?84:68)}}catch(P){if(84==x)throw P;52==x&&(R=P,u=39)}}(),OI={2:(y(2,27,mq,(Fr.prototype.A=(Ms.prototype.preventDefault=function(){this.defaultPrevented=true},(Ms.prototype.stopPropagation=function(){this.ia=true},Fr.prototype).g=false,function(L){for(L=66;33!=L;)21==L?L=10:7==L?(this.Dl.shift()(),L=21):10==L?L=this.Dl.length?7:33:66==L?L=this.Dl?46:33:46==L&&(L=10)}),Ms)),\"touch\"),3:\"pen\",4:\"mouse\"},Ie=\"closure_listenable_\"+(1E6*(mq.prototype.preventDefault=function(L){(mq.m.preventDefault.call(this),L=this.s,L).preventDefault?L.preventDefault():L.returnValue=false},mq.prototype.stopPropagation=function(){mq.m.stopPropagation.call(this),this.s.stopPropagation?this.s.stopPropagation():this.s.cancelBubble=true},Math.random())|0),gc=\"constructor hasOwnProperty isPrototypeOf propertyIsEnumerable toLocaleString toString valueOf\".split(\" \"),BM=0,tP=\"closure_lm_\"+(1E6*(((zL.prototype.add=function(L,U,e,u,R,x,P,O,E,Q){for(Q=40;19!=Q;)if(86==Q)E=O[x],Q=49;else if(81==Q)Q=O?89:23;else if(49==Q)Q=e?95:14;else if(89==Q)x=r(6,0,U,R,O,u),Q=52;else{if(95==Q)return E;4==Q?(E=new tk(!!u,P,this.src,R,U),E.zV=e,O.push(E),Q=95):40==Q?(P=L.toString(),O=this.X[P],Q=81):14==Q?(E.zV=false,Q=95):52==Q?Q=-1<x?86:4:23==Q&&(O=this.X[P]=[],this.YU++,Q=89)}},zL.prototype).remove=(zL.prototype.hasListener=function(L,U,e,u,R){return Z2(25,true,(e=(R=(u=void 0!==L)?L.toString():\"\",void 0!==U),false),function(x,P,O){for(O=67;23!=O;)if(19==O)O=62;else if(37==O)O=u&&x[P].type!=R||e&&x[P].capture!=U?76:51;else if(62==O)O=P<x.length?37:34;else{if(51==O)return true;if(76==O)++P,O=62;else if(67==O)P=0,O=19;else if(34==O)return false}},this.X)},function(L,U,e,u,R,x,P,O){for(O=90;79!=O;){if(7==O)return true;if(71==O)O=0==P.length?28:7;else if(28==O)delete this.X[x],this.YU--,O=7;else if(49==O)P=this.X[x],R=r(5,0,U,u,P,e),O=48;else if(37==O)O=x in this.X?49:53;else if(48==O)O=-1<R?26:97;else if(26==O)lq(69,42,true,P[R]),Array.prototype.splice.call(P,R,1),O=71;else if(90==O)x=L.toString(),O=37;else if(97==O||53==O)return false}}),zL.prototype).TV=function(L,U,e,u,R,x){return-(x=-(R=this.X[U.toString()],1),R&&(x=r(7,0,L,e,R,u)),1)<x?R[x]:null},Math.random())|0),VV={},WM=0,Yo=\"__closure_events_fn_\"+(1E9*Math.random()>>>0);((((((y(2,53,jY,Fr),jY.prototype)[Ie]=true,v=jY.prototype,v).C2=function(L){this.rX=L},v).addEventListener=function(L,U,e,u){bq(true,8,false,0,L,this,e,u,U)},v).removeEventListener=function(L,U,e,u){Z2(14,\"object\",0,u,e,this,U,L)},v).dispatchEvent=function(L,U,e,u,R,x,P,O,E,Q,D,m){for(m=28;64!=m;)if(85==m)m=R?88:39;else if(82==m)m=E.ia?34:60;else if(32==m)R=R.rX,m=85;else if(62==m)e=0,m=92;else if(67==m)m=!E.ia&&0<=e?11:82;else if(24==m)E=new Ms(E,x),m=53;else if(11==m)Q=E.currentTarget=U[e],O=JP(true,E,24,D,true,Q)&&O,m=31;else if(8==m)P=E,E=new Ms(D,x),kL(E,P),m=53;else if(31==m)e--,m=67;else if(84==m)u=[],m=33;else if(60==m)Q=E.currentTarget=x,O=JP(true,E,27,D,true,Q)&&O,E.ia||(O=JP(true,E,25,D,false,Q)&&O),m=34;else if(91==m)e++,m=12;else if(39==m)U=u,E=L,x=this.Sf,D=E.type||E,m=49;else if(92==m)m=12;else if(9==m)m=U?22:82;else if(28==m)R=this.rX,m=97;else if(12==m)m=!E.ia&&e<U.length?61:76;else if(88==m)u.push(R),m=32;else if(22==m)e=U.length-1,m=29;else if(49==m)m=\"string\"===typeof E?24:81;else if(97==m)m=R?84:39;else if(34==m)m=U?62:76;else if(61==m)Q=E.currentTarget=U[e],O=JP(true,E,26,D,false,Q)&&O,m=91;else if(53==m)O=true,m=9;else{if(76==m)return O;33==m?m=85:29==m?m=67:73==m?(E.target=E.target||x,m=53):81==m&&(m=E instanceof Ms?73:8)}},v.TV=function(L,U,e,u){return this.V.TV(L,String(U),e,u)},v).A=function(){this.rX=(jY.m.A.call(this),this.V&&y(0,5,true,this.V),null)},v.hasListener=function(L,U){return this.V.hasListener(void 0!==L?String(L):void 0,U)};var Ns;(((v=(y(2,23,eU,(((((((((v=xo.prototype,v).W=function(L,U){return\"string\"===(U=this.p2,typeof L)?U.getElementById(L):L},v.getElementsByTagName=function(L,U){return(U||this.p2).getElementsByTagName(String(L))},v).createElement=function(L,U,e){return\"application/xhtml+xml\"===(U=(e=this.p2,String(L)),e).contentType&&(U=U.toLowerCase()),e.createElement(U)},v.createTextNode=function(L){return this.p2.createTextNode(String(L))},v.appendChild=function(L,U){L.appendChild(U)},v).append=function(L,U){uu(arguments,1,\"object\",L,9==L.nodeType?L:L.ownerDocument||L.document,\"array\",\"string\")},v).canHaveChildren=function(L,U){for(U=13;10!=U;){if(14==U){switch(L.tagName){case \"APPLET\":case \"AREA\":case \"BASE\":case \"BR\":case \"COL\":case \"COMMAND\":case \"EMBED\":case \"FRAME\":case \"HR\":case \"IMG\":case \"INPUT\":case \"IFRAME\":case \"ISINDEX\":case \"KEYGEN\":case \"LINK\":case \"NOFRAMES\":case \"NOSCRIPT\":case \"META\":case \"OBJECT\":case \"PARAM\":case \"SCRIPT\":case \"SOURCE\":case \"STYLE\":case \"TRACK\":case \"WBR\":return false}return true}if(13==U)U=1!=L.nodeType?61:14;else if(61==U)return false}},v.removeNode=yY,v).contains=function(L,U,e){for(e=53;68!=e;){if(10==e)return false;if(53==e)e=L&&U?61:10;else if(61==e)e=L.contains&&1==U.nodeType?38:77;else{if(51==e)return U==L;if(77==e)e=\"undefined\"!=typeof L.compareDocumentPosition?87:52;else if(35==e)e=60;else{if(38==e)return L==U||L.contains(U);if(60==e)e=U&&L!=U?85:51;else if(85==e)U=U.parentNode,e=35;else if(52==e)e=60;else if(87==e)return L==U||!!(L.compareDocumentPosition(U)&16)}}}},t)(lu,57),lu.prototype).D8=0,lu).prototype.h$=\"\",jY)),eU).prototype,v.R6=lu.kU(),v.W=function(){return this.C},v.getParent=function(){return this.I},v).A=function(L){for(L=18;89!=L;)79==L?L=this.v?62:68:68==L?(PM(\"\",64,function(U){pw(35,U,22,true)},this),!this.lH&&this.C&&yY(this.C),this.SQ=this.I=this.C=this.yN=null,eU.m.A.call(this),L=89):62==L?(pw(35,this.v,21,true),delete this.v,L=68):18==L&&(this.Fp&&this.P(),L=79)},v.P=function(){this.Fp=((PM(\"\",65,function(L){L.Fp&&L.P()},this),this.v)&&y(0,3,true,this.v),false)},v).C2=function(L,U){for(U=53;26!=U;)if(70==U)eU.m.C2.call(this,L),U=26;else if(53==U)U=this.I&&this.I!=L?35:70;else if(35==U)throw Error(\"Method not supported\");},v).removeChild=function(L,U,e,u,R,x,P,O,E,Q,D,m,M){for(M=51;50!=M;)if(10==M)R.I=null,eU.m.C2.call(R,null),M=97;else if(39==M)M=m&&L?7:97;else if(56==M)R=L,M=26;else if(75==M)m=e,M=95;else if(33==M)P=this.yN,u=(null!==P&&m in P?P[m]:void 0)||null,M=13;else if(13==M)L=u,M=39;else if(72==M)e=L,M=75;else{if(71==M)throw Error(\"Unable to set parent component\");if(96==M)throw Error(\"Child is not in parent component\");if(7==M)E=this.yN,m in E&&delete E[m],sI(10,3,0,this.SQ,L),M=79;else if(53==M)u=null,M=13;else if(79==M)M=U?64:56;else if(51==M)M=L?16:97;else if(14==M)e=O,M=75;else if(95==M)M=this.yN&&m?33:53;else{if(60==M)return L;99==M?M=(O=L.QN)?14:29:64==M?(L.P(),L.C&&yY(L.C),M=56):26==M?M=null==R?71:10:16==M?M=\"string\"===typeof L?72:99:29==M?(Q=L.R6,D=L,x=Q.h$+\":\"+(Q.D8++).toString(36),O=D.QN=x,M=14):97==M&&(M=L?60:96)}}};var $L,iu={button:\"pressed\",checkbox:\"checked\",menuitem:\"selected\",menuitemcheckbox:\"checked\",menuitemradio:(t(na,59),\"checked\"),radio:\"checked\",tab:\"selected\",treeitem:\"selected\"},UF=((t(La,(y(2,(((((((v=na.prototype,v).OS=function(L,U,e,u,R,x,P,O,E){for(E=(P=99,74);;)try{if(3==P)break;else 64==P?P=L.S&32?83:26:99==P?P=L.Xp&32&&(e=L.eQ())?2:3:54==P?(E=6,e.blur(),P=33):33==P?(E=74,P=64):83==P?(L.dX&4&&L.Xp&4&&L.setActive(false),L.dX&32&&L.Xp&32&&QV(33,L,32,16,2,false)&&L.K(false,32),P=26):41==P?(E=74,P=33):75==P?(u.tabIndex=-1,u.removeAttribute(\"tabIndex\"),P=3):26==P?P=(x=e.hasAttribute(\"tabindex\"))?36:23:6==P?(u=e,P=14):25==P?(u.tabIndex=0,P=3):2==P?P=!U&&L.S&32?54:26:14==P?P=U?25:75:36==P?(R=e.tabIndex,x=\"number\"===typeof R&&0<=R&&32768>R,P=23):23==P&&(P=x!=U?6:3)}catch(Q){if(74==E)throw Q;6==E&&(O=Q,P=41)}},v).eQ=function(L){return L.W()},v).ES=function(){return\"goog-control\"},v).la=function(L,U,e,u,R,x,P){(x=L.getAttribute((u=($L||($L={1:\"disabled\",8:\"selected\",16:\"checked\",64:\"expanded\"}),$L[U]),\"role\"))||null)?(R=iu[x]||u,P=\"checked\"==u||\"selected\"==u?R:u):P=u,P&&t(\"aria-\",6,\"hidden\",e,P,L)},v).K=function(L,U,e,u,R,x,P){for(P=55;66!=P;)94==P?P=this.cz?38:41:39==P?P=R?94:66:38==P?((u=this.cz[L])&&this.AN(U,u,e),this.la(R,L,e),P=66):41==P?(x=this.ES(),x.replace(/\\\\xa0|\\\\s/g,\" \"),this.cz={1:x+\"-disabled\",2:x+\"-hover\",4:x+\"-active\",8:x+\"-selected\",16:x+\"-checked\",32:x+\"-focused\",64:x+\"-open\"},P=38):55==P&&(R=U.W(),P=39)},v).AN=function(L,U,e,u){(u=L.W?L.W():L)&&(e?al:N5)(u,[U])},21),La,na),56)),La).prototype.la=function(L,U,e){switch(U){case 8:case 16:t(\"aria-\",22,\"hidden\",e,\"pressed\",L);break;default:case 64:case 1:La.m.la.call(this,L,U,e)}},La.prototype.ES=function(){return\"goog-button\"},{});if(\"function\"!==((((((((((((v=(y(2,29,d,eU),d.prototype),v).dX=255,v).P=function(){(d.m.P.call(this),this).Rr&&this.Rr.detach(),this.isVisible()&&this.isEnabled()&&this.J.OS(this,false)},v).rb=0,v.Xp=39,v).S=0,v.A=function(L){for(L=91;74!=L;)91==L?(d.m.A.call(this),L=87):81==L?(pw(35,this.Rr,17,true),delete this.Rr,L=89):87==L?L=this.Rr?81:89:89==L&&(delete this.J,this.U=null,L=74)},v.t$=true,v.eQ=function(){return this.J.eQ(this)},v).AN=function(L,U,e){for(e=35;2!=e;)22==e?e=L&&this.U&&sI(10,5,0,this.U,L)?23:2:35==e?e=U?5:22:23==e?e=0==this.U.length?60:21:60==e?(this.U=null,e=21):5==e?e=L?0:2:21==e?(this.J.AN(this,L,false),e=2):0==e&&(this.U?b(64,0,L,this.U)||this.U.push(L):this.U=[L],this.J.AN(this,L,true),e=2)},v).U=null,v).isVisible=function(){return this.t$},v.isEnabled=function(){return!(this.S&1)},v).isActive=function(){return!!(this.S&4)},v).setActive=function(L){QV(33,this,4,17,2,L)&&this.K(L,4)},v).getState=function(){return this.S},v).K=function(L,U,e,u,R,x,P){for(P=44;68!=P;)11==P?(this.J.K(U,this,L),this.S=L?this.S|U:(x=this.S,(x|0)- -1+(~x|~U)),P=68):10==P?(R=!L,u=this.getParent(),P=22):37==P?P=R?17:34:44==P?P=e||1!=U?88:10:88==P?P=this.Xp&U&&L!=!!(this.S&U)?11:68:17==P?(this.isVisible()&&this.J.OS(this,R),this.K(!R,1,true),P=68):22==P?P=u&&\"function\"==typeof u.isEnabled&&!u.isEnabled()||!QV(33,this,1,20,2,!R)?68:37:34==P&&(this.setActive(false),QV(33,this,2,13,2,false)&&this.K(false,2),P=17)},typeof d))throw Error(\"Invalid component class \"+d);if(\"function\"!==typeof na)throw Error(\"Invalid renderer class \"+na);var SU=EI(15,d),SY={passive:true,capture:!(y(2,25,((t(AP,(y(2,(t(\"goog-control\",(UF[SU]=na,11),function(){return new d(null)}),31),AP,La),58)),AP.prototype).OS=function(){},AP.prototype.K=function(L,U,e,u,R){for(R=33;35!=R;)33==R?(AP.m.K.call(this,L,U,e),u=U.W(),R=81):56==R?(u.disabled=e,R=35):81==R&&(R=u&&1==L?56:35)},AP.prototype.la=function(){},QY),d),QY.prototype.A=function(){QY.m.A.call(this),delete this.fG,delete this.P5},t(\"goog-button\",16,function(){return new QY(null)}),0)},Cw=a.requestIdleCallback?function(L){requestIdleCallback(function(){L()},{timeout:4})}:a.setImmediate?function(L){setImmediate(L)}:function(L){setTimeout(L,0)},TM=String.fromCharCode(105,110,116,101,103,67,104,101,99,107,66,121,112,97,115,115),Ca=[],pa=[],$o=(g.prototype.pG=(g.prototype.xU=(g.prototype.LG=void 0,\"toString\"),false),[]),dO=[],OF=(g.prototype.xK=void 0,{}),TL=[],Il=[],vM=[],HM=[],hP=(((EF,function(){})(X8),zM,BR,xL,function(){})(sF),void 0),eY=((v=g.prototype,v).W5=function(L,U,e,u,R,x,P){return EI.call(this,17,L,U,e,u,R,x,P)},OF).constructor;v=(v.TZ=function(){return b.call(this,9)},v.FN=(v.uH=0,g.prototype.D=\"create\",v.zZ=function(){return bq.call(this,true,6)},v.Z8=function(L,U,e,u,R,x){return JP.call(this,L,U,8,e,u,R,x)},v.Z=(window.performance||{}).now?function(){return this.KG+window.performance.now()}:function(){return+new Date},function(L,U,e,u,R,x,P,O){return r.call(this,24,L,U,e,u,R,x,P,O)}),v.NU=function(L,U,e,u,R,x){return S.call(this,U,L,55,e,u,R,x)},g).prototype,v.H=function(L,U){return U=(hP=function(){return U==L?-34:22},L={},{}),function(e,u,R,x,P,O,E,Q,D,m,M,n,Y,K,c,Z,T,C,D2,B,p,fw,H,J,k,z,Kw,Re,W,w,GL,F,VY,hk,f,yV,A,q5,Jk){for(hk=(A=(F=60,f=66,undefined),false);;)try{if(20==f)break;else if(27==f)f=26;else if(42==f)f=x==Ca?59:84;else if(82==f)fw[K++]=P,f=71;else if(16==f)yV=WR(0,104,this,8001,e[1]),A=9,f=84;else{if(9==f)return yV;if(59==f){if(M=(GL=l(this,141),\"undefined\")!=typeof Symbol&&Symbol.iterator&&GL[Symbol.iterator])R=M.call(GL);else if(\"number\"==typeof GL.length)R={next:UI(17,3,0,GL)};else throw Error(String(GL)+\" is not an iterable or ArrayLike\");f=(n=R,O=n.next(),64)}else if(25==f)F=43,x=e[0],f=29;else if(98==f)F=43,M5(2,this,Jk,17),A=20,f=84;else if(22==f)F=2,E(),f=52;else if(91==f)f=x==dO?16:42;else if(84==f)F=60,U=C,f=51;else if(18==f)WR(0,104,this,e[2],e[1]),f=84;else if(51==f)undefined!==A?(f=A,A=undefined):f=20;else if(53==f)z=e[2],D=q(2,(B=l(this,404).length,-2*~(B&2)-(~B^2)+3*(~B&2)+3*(B|-3))),J=this.i,this.i=this,f=48;else if(88==f)f=x==vM?58:23;else if(74==f)f=undefined!==A?84:5;else if(87==f)fw[K++]=P&255,P>>=8,f=82;else if(8==f)F=43,f=52;else if(28==f)F=95,Re=atob(u),K=H=0,fw=[],f=27;else if(56==f)this.B=fw,this.l=this.B.length<<3,N(this,16,[0,0,0]),f=24;else if(24==f)F=43,rc(0,this,false,8001),f=84;else if(29==f)f=x==pa?17:88;else if(36==f)f=x==TL?18:91;else if(66==f)C=U,U=L,f=25;else if(26==f)f=H<Re.length?1:56;else if(79==f)f=255<P?87:82;else if(47==f)f=Z<p.length?97:95;else if(80==f)f=Q?96:14;else if(5==f)F=43,p=X8(2).concat(l(this,404)),p[1]=(D2=p[0],-1+(~D2&3)-(~D2|3)),p[3]=p[1]^D[0],p[4]=(c=p[1],w=D[1],-(c|0)-(w|0)+-2-2*~(c|w)),Q=this.YK(p),f=80;else if(17==f)u=e[1],f=28;else if(97==f)T=p[Z][this.xU](16),1==T.length&&(T=\"0\"+T),Q+=T,f=10;else if(52==f)O=n.next(),f=11;else if(60==f)f=47;else if(14==f)Z=0,Q=\"\",f=60;else if(11==f)f=O.done?73:67;else{if(81==f)return yV;if(48==f)F=17,m=l(this,29),0<m.length&&h(q(2,m.length).concat(m),404,this,15),h(q(1,this.Zl),404,this,104),h(q(1,this[HM].length),404,this),W=0,W-=(k=l(this,404).length,2*(k|5)- -1+(~k^5)),W+=l(this,399)&2047,Y=l(this,325),4<Y.length&&(W-=(Y.length|0)+3),0<W&&h(q(2,W).concat(X8(W)),404,this,10),4<Y.length&&h(q(2,Y.length).concat(Y),404,this,153),f=19;else if(95==f)Kw=Q,l(this,404).length=z.shift(),l(this,325).length=z.shift(),l(this,389).length=z.shift(),l(this,131)[0]=z.shift(),l(this,11).length=z.shift(),yV=Kw,A=81,f=84;else if(1==f)P=Re.charCodeAt(H),f=79;else if(23==f)f=x==HM?53:36;else if(10==f)Z++,f=47;else if(71==f)H++,f=26;else if(64==f)f=11;else if(96==f)Q=\"!\"+Q,f=95;else if(67==f)E=O.value,f=22;else if(19==f)F=43,this.i=J,f=74;else if(73==f)GL.length=0,f=84;else if(58==f)e[1].push(l(this,404).length,l(this,325).length,l(this,389).length,l(this,131)[0],l(this,11).length),N(this,138,e[2]),this.G[287]&&WR(0,104,this,8001,l(this,287)),f=84;else if(94==f)throw VY;}}}catch(rO){if((VY=rO,60)==F)throw rO;95==F?(Jk=rO,f=98):43==F?(A=94,f=84):17==F?(A=94,f=19):2==F&&(q5=rO,f=8)}}}();var Ka,GM=(v.sS=(v.YK=(v.ef=0,function(L,U,e,u,R){return t.call(this,L,8,U,e,u,R)}),function(){return gO.call(this,20,8,32)}),v.gb=(g.prototype[Il]=[0,0,1,1,0,1,1],0),/./),dc=pa.pop.bind(g.prototype[vM]),cR=function(L,U){return(U=F8(64,77,83,36,\"bg\",\"error\",null))&&1===L.eval(U.createScript(\"1\"))?function(e){return U.createScript(e)}:function(e){return\"\"+e}}(((Ka=(GM[g.prototype.xU]=dc,UI(17,10,g.prototype.D,{get:dc})),g).prototype.Vx=void 0,a));return(function(L){return g.prototype.Vx=L,wc});}).call(this);'].join('\\n')))(e)(R.substr(0,c),U,M,Y,n),m[1]),D=m[0];break}else 63==L?L=P?7:78:90==L?(V=15,K=\"FNL\"+p,L=78):53==L&&(K=\"FNL\"+e,L=63)}catch(Z){if(15==V)throw Z;29==V&&(p=Z,L=90)}}),[function(P){return D?D(P):\"FNL~\"},function(P){f&&f(P)}]};}).call(this); (function(){'use strict';var d=function(a){var b=0;return function(){return b<a.length?{done:!1,value:a[b++]}:{done:!0}}},f=function(){var a=document.querySelectorAll('div[data-button-type=\"multipleChoiceIdentifier\"]'),b=\"undefined\"!=typeof Symbol&&Symbol.iterator&&a[Symbol.iterator];if(b)return b.call(a);if(\"number\"==typeof a.length)return{next:d(a)};throw Error(String(a)+\" is not an iterable or ArrayLike\");};/* Copyright The Closure Library Authors. SPDX-License-Identifier: Apache-2.0*/var l=function(){this.i=new window.botguard.bg(k,function(){});this.h=this.g=null;this.i&&window.addEventListener(\"load\",this.j.bind(this))};l.prototype.j=function(){var a=this;this.g=document.getElementById(\"hiddenMultipleChoiceIdentifier\");this.h=function(){a.i.invoke(a.l)};this.g?m(this):document.addEventListener(\"submit\",this.h.bind(this))};l.prototype.l=function(a){var b=document.getElementById(\"bgresponse\");b&&(b.value=a)};var m=function(a){for(var b=function(e){a.g&&(a.g.value=e);a.h()},q=function(e,p){13===p.keyCode&&(a.g&&(a.g.value=e),a.h())},g=f(),c=g.next();!c.done;c=g.next()){c=c.value.getElementsByTagName(\"button\")[0];var h=c.value;c.addEventListener(\"click\",b.bind(a,h));c.addEventListener(\"keydown\",q.bind(a,h))}},n=document.getElementById(\"program\");if(n){var k=n.getAttribute(\"program-data\");k&&new l};}).call(this); (function(){'use strict';var aa=function(a){var b=0;return function(){return b<a.length?{done:!1,value:a[b++]}:{done:!0}}},n=\"function\"==typeof Object.defineProperties?Object.defineProperty:function(a,b,c){if(a==Array.prototype||a==Object.prototype)return a;a[b]=c.value;return a},ba=function(a){a=[\"object\"==typeof globalThis&&globalThis,a,\"object\"==typeof window&&window,\"object\"==typeof self&&self,\"object\"==typeof global&&global];for(var b=0;b<a.length;++b){var c=a[b];if(c&&c.Math==Math)return c}throw Error(\"Cannot find global object\");},ca=ba(this),p=function(a,b){if(b)a:{var c=ca;a=a.split(\".\");for(var d=0;d<a.length-1;d++){var e=a[d];if(!(e in c))break a;c=c[e]}a=a[a.length-1];d=c[a];b=b(d);b!=d&&null!=b&&n(c,a,{configurable:!0,writable:!0,value:b})}};p(\"Symbol\",function(a){if(a)return a;var b=function(f,k){this.g=f;n(this,\"description\",{configurable:!0,writable:!0,value:k})};b.prototype.toString=function(){return this.g};var c=\"jscomp_symbol_\"+(1E9*Math.random()>>>0)+\"_\",d=0,e=function(f){if(this instanceof e)throw new TypeError(\"Symbol is not a constructor\");return new b(c+(f||\"\")+\"_\"+d++,f)};return e});p(\"Symbol.iterator\",function(a){if(a)return a;a=Symbol(\"Symbol.iterator\");for(var b=\"Array Int8Array Uint8Array Uint8ClampedArray Int16Array Uint16Array Int32Array Uint32Array Float32Array Float64Array\".split(\" \"),c=0;c<b.length;c++){var d=ca[b[c]];\"function\"===typeof d&&\"function\"!=typeof d.prototype[a]&&n(d.prototype,a,{configurable:!0,writable:!0,value:function(){return da(aa(this))}})}return a});var da=function(a){a={next:a};a[Symbol.iterator]=function(){return this};return a},q=function(a){var b=\"undefined\"!=typeof Symbol&&Symbol.iterator&&a[Symbol.iterator];if(b)return b.call(a);if(\"number\"==typeof a.length)return{next:aa(a)};throw Error(String(a)+\" is not an iterable or ArrayLike\");},r=function(a,b){return Object.prototype.hasOwnProperty.call(a,b)};p(\"WeakMap\",function(a){function b(){}function c(h){var l=typeof h;return\"object\"===l&&null!==h||\"function\"===l}function d(h){if(!r(h,f)){var l=new b;n(h,f,{value:l})}}function e(h){var l=Object[h];l&&(Object[h]=function(m){if(m instanceof b)return m;Object.isExtensible(m)&&d(m);return l(m)})}if(function(){if(!a||!Object.seal)return!1;try{var h=Object.seal({}),l=Object.seal({}),m=new a([[h,2],[l,3]]);if(2!=m.get(h)||3!=m.get(l))return!1;m.delete(h);m.set(l,4);return!m.has(h)&&4==m.get(l)}catch(F){return!1}}())return a;var f=\"$jscomp_hidden_\"+Math.random();e(\"freeze\");e(\"preventExtensions\");e(\"seal\");var k=0,g=function(h){this.g=(k+=Math.random()+1).toString();if(h){h=q(h);for(var l;!(l=h.next()).done;)l=l.value,this.set(l[0],l[1])}};g.prototype.set=function(h,l){if(!c(h))throw Error(\"Invalid WeakMap key\");d(h);if(!r(h,f))throw Error(\"WeakMap key fail: \"+h);h[f][this.g]=l;return this};g.prototype.get=function(h){return c(h)&&r(h,f)?h[f][this.g]:void 0};g.prototype.has=function(h){return c(h)&&r(h,f)&&r(h[f],this.g)};g.prototype.delete=function(h){return c(h)&&r(h,f)&&r(h[f],this.g)?delete h[f][this.g]:!1};return g});p(\"Map\",function(a){if(function(){if(!a||\"function\"!=typeof a||!a.prototype.entries||\"function\"!=typeof Object.seal)return!1;try{var g=Object.seal({x:4}),h=new a(q([[g,\"s\"]]));if(\"s\"!=h.get(g)||1!=h.size||h.get({x:4})||h.set({x:4},\"t\")!=h||2!=h.size)return!1;var l=h.entries(),m=l.next();if(m.done||m.value[0]!=g||\"s\"!=m.value[1])return!1;m=l.next();return m.done||4!=m.value[0].x||\"t\"!=m.value[1]||!l.next().done?!1:!0}catch(F){return!1}}())return a;var b=new WeakMap,c=function(g){this[0]={};this[1]=f();this.size=0;if(g){g=q(g);for(var h;!(h=g.next()).done;)h=h.value,this.set(h[0],h[1])}};c.prototype.set=function(g,h){g=0===g?0:g;var l=d(this,g);l.list||(l.list=this[0][l.id]=[]);l.m?l.m.value=h:(l.m={next:this[1],v:this[1].v,head:this[1],key:g,value:h},l.list.push(l.m),this[1].v.next=l.m,this[1].v=l.m,this.size++);return this};c.prototype.delete=function(g){g=d(this,g);return g.m&&g.list?(g.list.splice(g.index,1),g.list.length||delete this[0][g.id],g.m.v.next=g.m.next,g.m.next.v=g.m.v,g.m.head=null,this.size--,!0):!1};c.prototype.clear=function(){this[0]={};this[1]=this[1].v=f();this.size=0};c.prototype.has=function(g){return!!d(this,g).m};c.prototype.get=function(g){return(g=d(this,g).m)&&g.value};c.prototype.entries=function(){return e(this,function(g){return[g.key,g.value]})};c.prototype.keys=function(){return e(this,function(g){return g.key})};c.prototype.values=function(){return e(this,function(g){return g.value})};c.prototype.forEach=function(g,h){for(var l=this.entries(),m;!(m=l.next()).done;)m=m.value,g.call(h,m[1],m[0],this)};c.prototype[Symbol.iterator]=c.prototype.entries;var d=function(g,h){var l=h&&typeof h;\"object\"==l||\"function\"==l?b.has(h)?l=b.get(h):(l=\"\"+ ++k,b.set(h,l)):l=\"p_\"+h;var m=g[0][l];if(m&&r(g[0],l))for(g=0;g<m.length;g++){var F=m[g];if(h!==h&&F.key!==F.key||h===F.key)return{id:l,list:m,index:g,m:F}}return{id:l,list:m,index:-1,m:void 0}},e=function(g,h){var l=g[1];return da(function(){if(l){for(;l.head!=g[1];)l=l.v;for(;l.next!=l.head;)return l=l.next,{done:!1,value:h(l)};l=null}return{done:!0,value:void 0}})},f=function(){var g={};return g.v=g.next=g.head=g},k=0;return c});p(\"Array.prototype.find\",function(a){return a?a:function(b,c){a:{var d=this;d instanceof String&&(d=String(d));for(var e=d.length,f=0;f<e;f++){var k=d[f];if(b.call(c,k,f,d)){b=k;break a}}b=void 0}return b}});var ea=function(a,b){a instanceof String&&(a+=\"\");var c=0,d=!1,e={next:function(){if(!d&&c<a.length){var f=c++;return{value:b(f,a[f]),done:!1}}d=!0;return{done:!0,value:void 0}}};e[Symbol.iterator]=function(){return e};return e};p(\"Array.prototype.entries\",function(a){return a?a:function(){return ea(this,function(b,c){return[b,c]})}});p(\"Array.prototype.keys\",function(a){return a?a:function(){return ea(this,function(b){return b})}});p(\"Array.prototype.values\",function(a){return a?a:function(){return ea(this,function(b,c){return c})}});p(\"Array.from\",function(a){return a?a:function(b,c,d){c=null!=c?c:function(g){return g};var e=[],f=\"undefined\"!=typeof Symbol&&Symbol.iterator&&b[Symbol.iterator];if(\"function\"==typeof f){b=f.call(b);for(var k=0;!(f=b.next()).done;)e.push(c.call(d,f.value,k++))}else for(f=b.length,k=0;k<f;k++)e.push(c.call(d,b[k],k));return e}});/* Copyright The Closure Library Authors. SPDX-License-Identifier: Apache-2.0*/var fa=fa||{},t=this||self,ha=function(a){var b=typeof a;return\"object\"!=b?b:a?Array.isArray(a)?\"array\":b:\"null\"},u=function(a){var b=typeof a;return\"object\"==b&&null!=a||\"function\"==b},ia=function(a,b,c){return a.call.apply(a.bind,arguments)},ja=function(a,b,c){if(!a)throw Error();if(2<arguments.length){var d=Array.prototype.slice.call(arguments,2);return function(){var e=Array.prototype.slice.call(arguments);Array.prototype.unshift.apply(e,d);return a.apply(b,e)}}return function(){return a.apply(b,arguments)}},v=function(a,b,c){v=Function.prototype.bind&&-1!=Function.prototype.bind.toString().indexOf(\"native code\")?ia:ja;return v.apply(null,arguments)},w=function(a,b){function c(){}c.prototype=b.prototype;a.P=b.prototype;a.prototype=new c;a.prototype.constructor=a;a.ja=function(d,e,f){for(var k=Array(arguments.length-2),g=2;g<arguments.length;g++)k[g-2]=arguments[g];return b.prototype[e].apply(d,k)}};var ka=String.prototype.trim?function(a){return a.trim()}:function(a){return/^[\\s\\xa0]*([\\s\\S]*?)[\\s\\xa0]*$/.exec(a)[1]};function x(a,b){if(Error.captureStackTrace)Error.captureStackTrace(this,x);else{var c=Error().stack;c&&(this.stack=c)}a&&(this.message=String(a));void 0!==b&&(this.cause=b)}w(x,Error);x.prototype.name=\"CustomError\";function y(a,b){a=a.split(\"%s\");for(var c=\"\",d=a.length-1,e=0;e<d;e++)c+=a[e]+(e<b.length?b[e]:\"%s\");x.call(this,c+a[d])}w(y,x);y.prototype.name=\"AssertionError\";function la(a,b,c,d){var e=\"Assertion failed\";if(c){e+=\": \"+c;var f=d}else a&&(e+=\": \"+a,f=b);throw new y(\"\"+e,f||[]);}var z=function(a,b,c){a||la(\"\",null,b,Array.prototype.slice.call(arguments,2))},ma=function(a,b){throw new y(\"Failure\"+(a?\": \"+a:\"\"),Array.prototype.slice.call(arguments,1));},A=function(a,b,c){\"number\"!==typeof a&&la(\"Expected number but got %s: %s.\",[ha(a),a],b,Array.prototype.slice.call(arguments,2));return a};var na=Array.prototype.indexOf?function(a,b){z(null!=a.length);return Array.prototype.indexOf.call(a,b,void 0)}:function(a,b){if(\"string\"===typeof a)return\"string\"!==typeof b||1!=b.length?-1:a.indexOf(b,0);for(var c=0;c<a.length;c++)if(c in a&&a[c]===b)return c;return-1};function oa(a,b){b=na(a,b);var c;if(c=0<=b)z(null!=a.length),Array.prototype.splice.call(a,b,1);return c};var pa=\"constructor hasOwnProperty isPrototypeOf propertyIsEnumerable toLocaleString toString valueOf\".split(\" \");function qa(a,b){for(var c,d,e=1;e<arguments.length;e++){d=arguments[e];for(c in d)a[c]=d[c];for(var f=0;f<pa.length;f++)c=pa[f],Object.prototype.hasOwnProperty.call(d,c)&&(a[c]=d[c])}};var C=function(a,b){if(b!==B)throw Error(\"SafeUrl is not meant to be built directly\");this.g=a};C.prototype.toString=function(){return this.g.toString()};var B={};new C(\"about:invalid#zClosurez\",B);new C(\"about:blank\",B);var ra={},sa=function(){if(ra!==ra)throw Error(\"SafeStyle is not meant to be built directly\");};sa.prototype.toString=function(){return\"\".toString()};new sa;var ta={},ua=function(){if(ta!==ta)throw Error(\"SafeStyleSheet is not meant to be built directly\");};ua.prototype.toString=function(){return\"\".toString()};new ua;var va,D;a:{for(var wa=[\"CLOSURE_FLAGS\"],E=t,xa=0;xa<wa.length;xa++)if(E=E[wa[xa]],null==E){D=null;break a}D=E}var ya=D&&D[610401301];va=null!=ya?ya:!1;function G(){var a=t.navigator;return a&&(a=a.userAgent)?a:\"\"}var za,Aa=t.navigator;za=Aa?Aa.userAgentData||null:null;var Ba={},Ca=function(){var a=t.trustedTypes&&t.trustedTypes.emptyHTML||\"\";if(Ba!==Ba)throw Error(\"SafeHtml is not meant to be built directly\");this.g=a};Ca.prototype.toString=function(){return this.g.toString()};new Ca;/* SPDX-License-Identifier: Apache-2.0*/new C(\"about:blank\",B);var Da=new C(\"about:invalid#zClosurez\",B);var Ea=function(a){this.ga=a};function H(a){return new Ea(function(b){return b.substr(0,a.length+1).toLowerCase()===a+\":\"})}var Fa=[H(\"data\"),H(\"http\"),H(\"https\"),H(\"mailto\"),H(\"ftp\"),new Ea(function(a){return/^[^:]*([/?#]|$)/.test(a)})],Ga=/^\\s*(?!javascript:)(?:[a-z0-9+.-]+:|[^:\\/?#]*(?:[\\/?#]|$))/i,Ha=[],Ia=function(){};Ja(function(a){console.warn(\"A URL with content '\"+a+\"' was sanitized away.\")});function Ja(a){-1===Ha.indexOf(a)&&Ha.push(a);Ia=function(b){Ha.forEach(function(c){c(b)})}};var Ka=Object.freeze||function(a){return a};var I=function(a,b){this.name=a;this.value=b};I.prototype.toString=function(){return this.name};var J=new I(\"OFF\",Infinity),La=new I(\"SEVERE\",1E3),Ma=new I(\"CONFIG\",700),Na=new I(\"FINE\",500),Oa=function(){},Pa,Qa=function(a,b,c){this.reset(a||J,b,c,void 0,void 0)};Qa.prototype.reset=function(){};var Ra=function(a,b){this.g=null;this.l=[];this.h=(void 0===b?null:b)||null;this.j=[];this.o={g:function(){return a}}},Sa=function(a){if(a.g)return a.g;if(a.h)return Sa(a.h);ma(\"Root logger has no level set.\");return J},Ta=function(a,b){for(;a;)a.l.forEach(function(c){c(b)}),a=a.h},Ua=function(){this.entries={};var a=new Ra(\"\");a.g=Ma;this.entries[\"\"]=a},Va,K=function(a,b){var c=a.entries[b];if(c)return c;c=K(a,b.slice(0,Math.max(b.lastIndexOf(\".\"),0)));var d=new Ra(b,c);a.entries[b]=d;c.j.push(d);return d},Wa=function(){Va||(Va=new Ua);return Va},Xa=function(a,b,c){var d;if(d=a)if(d=a&&b){d=b.value;var e=a?Sa(K(Wa(),a.g())):J;d=d>=e.value}d&&(b=b||J,d=K(Wa(),a.g()),\"function\"===typeof c&&(c=c()),Pa||(Pa=new Oa),a=new Qa(b,c,a.g()),Ta(d,a))},Ya=function(a,b){a&&Xa(a,La,b)},L=function(a,b){a&&Xa(a,Na,b)};var M=function(){this.g=(\"undefined\"==typeof document?null:document)||{cookie:\"\"}};M.prototype.set=function(a,b,c){var d=!1;if(\"object\"===typeof c){var e=c.la;d=c.ma||!1;var f=c.domain||void 0;var k=c.path||void 0;var g=c.ka}if(/[;=\\s]/.test(a))throw Error('Invalid cookie name \"'+a+'\"');if(/[;\\r\\n]/.test(b))throw Error('Invalid cookie value \"'+b+'\"');void 0===g&&(g=-1);this.g.cookie=a+\"=\"+b+(f?\";domain=\"+f:\"\")+(k?\";path=\"+k:\"\")+(0>g?\"\":0==g?\";expires=\"+(new Date(1970,1,1)).toUTCString():\";expires=\"+(new Date(Date.now()+1E3*g)).toUTCString())+(d?\";secure\":\"\")+(null!=e?\";samesite=\"+e:\"\")};M.prototype.get=function(a,b){for(var c=a+\"=\",d=(this.g.cookie||\"\").split(\";\"),e=0,f;e<d.length;e++){f=ka(d[e]);if(0==f.lastIndexOf(c,0))return f.slice(c.length);if(f==a)return\"\"}return b};M.prototype.o=function(){for(var a=(this.g.cookie||\"\").split(\";\"),b=[],c=[],d,e,f=0;f<a.length;f++)e=ka(a[f]),d=e.indexOf(\"=\"),-1==d?(b.push(\"\"),c.push(e)):(b.push(e.substring(0,d)),c.push(e.substring(d+1)));return c};var Za=new M;var $a=function(){this.H=this.H;this.g=this.g};$a.prototype.H=!1;$a.prototype.G=function(){if(this.g)for(;this.g.length;)this.g.shift()()};var N=function(a,b){this.type=a;this.g=this.target=b;this.defaultPrevented=!1};N.prototype.h=function(){this.defaultPrevented=!0};var ab=function(){if(!t.addEventListener||!Object.defineProperty)return!1;var a=!1,b=Object.defineProperty({},\"passive\",{get:function(){a=!0}});try{var c=function(){};t.addEventListener(\"test\",c,b);t.removeEventListener(\"test\",c,b)}catch(d){}return a}();var bb=function(a){bb[\" \"](a);return a};bb[\" \"]=function(){};var cb=va&&za&&0<za.brands.length?!1:-1!=G().indexOf(\"Trident\")||-1!=G().indexOf(\"MSIE\"),db=-1!=G().indexOf(\"Gecko\")&&!(-1!=G().toLowerCase().indexOf(\"webkit\")&&-1==G().indexOf(\"Edge\"))&&!(-1!=G().indexOf(\"Trident\")||-1!=G().indexOf(\"MSIE\"))&&-1==G().indexOf(\"Edge\");var O=function(a,b){N.call(this,a?a.type:\"\");this.relatedTarget=this.g=this.target=null;this.button=this.screenY=this.screenX=this.clientY=this.clientX=0;this.key=\"\";this.metaKey=this.shiftKey=this.altKey=this.ctrlKey=!1;this.state=null;this.pointerId=0;this.pointerType=\"\";this.j=null;if(a){var c=this.type=a.type,d=a.changedTouches&&a.changedTouches.length?a.changedTouches[0]:null;this.target=a.target||a.srcElement;this.g=b;if(b=a.relatedTarget){if(db){a:{try{bb(b.nodeName);var e=!0;break a}catch(f){}e=!1}e||(b=null)}}else\"mouseover\"==c?b=a.fromElement:\"mouseout\"==c&&(b=a.toElement);this.relatedTarget=b;d?(this.clientX=void 0!==d.clientX?d.clientX:d.pageX,this.clientY=void 0!==d.clientY?d.clientY:d.pageY,this.screenX=d.screenX||0,this.screenY=d.screenY||0):(this.clientX=void 0!==a.clientX?a.clientX:a.pageX,this.clientY=void 0!==a.clientY?a.clientY:a.pageY,this.screenX=a.screenX||0,this.screenY=a.screenY||0);this.button=a.button;this.key=a.key||\"\";this.ctrlKey=a.ctrlKey;this.altKey=a.altKey;this.shiftKey=a.shiftKey;this.metaKey=a.metaKey;this.pointerId=a.pointerId||0;this.pointerType=\"string\"===typeof a.pointerType?a.pointerType:eb[a.pointerType]||\"\";this.state=a.state;this.j=a;a.defaultPrevented&&O.P.h.call(this)}};w(O,N);var eb=Ka({2:\"touch\",3:\"pen\",4:\"mouse\"});O.prototype.h=function(){O.P.h.call(this);var a=this.j;a.preventDefault?a.preventDefault():a.returnValue=!1};var P=\"closure_listenable_\"+(1E6*Math.random()|0);var fb=0;var gb=function(a,b,c,d,e){this.listener=a;this.proxy=null;this.src=b;this.type=c;this.capture=!!d;this.M=e;this.key=++fb;this.J=this.L=!1},hb=function(a){a.J=!0;a.listener=null;a.proxy=null;a.src=null;a.M=null};var ib=function(a){this.src=a;this.g={};this.h=0};ib.prototype.add=function(a,b,c,d,e){var f=a.toString();a=this.g[f];a||(a=this.g[f]=[],this.h++);var k=jb(a,b,d,e);-1<k?(b=a[k],c||(b.L=!1)):(b=new gb(b,this.src,f,!!d,e),b.L=c,a.push(b));return b};var kb=function(a,b){var c=b.type;c in a.g&&oa(a.g[c],b)&&(hb(b),0==a.g[c].length&&(delete a.g[c],a.h--))},jb=function(a,b,c,d){for(var e=0;e<a.length;++e){var f=a[e];if(!f.J&&f.listener==b&&f.capture==!!c&&f.M==d)return e}return-1};var lb=\"closure_lm_\"+(1E6*Math.random()|0),mb={},nb=0,pb=function(a,b,c,d,e){if(d&&d.once)ob(a,b,c,d,e);else if(Array.isArray(b))for(var f=0;f<b.length;f++)pb(a,b[f],c,d,e);else c=qb(c),a&&a[P]?(d=u(d)?!!d.capture:!!d,rb(a),a.u.add(String(b),c,!1,d,e)):sb(a,b,c,!1,d,e)},sb=function(a,b,c,d,e,f){if(!b)throw Error(\"Invalid event type\");var k=u(e)?!!e.capture:!!e,g=tb(a);g||(a[lb]=g=new ib(a));c=g.add(b,c,d,k,f);if(!c.proxy){d=ub();c.proxy=d;d.src=a;d.listener=c;if(a.addEventListener)ab||(e=k),void 0===e&&(e=!1),a.addEventListener(b.toString(),d,e);else if(a.attachEvent)a.attachEvent(vb(b.toString()),d);else if(a.addListener&&a.removeListener)z(\"change\"===b,\"MediaQueryList only has a change event\"),a.addListener(d);else throw Error(\"addEventListener and attachEvent are unavailable.\");nb++}},ub=function(){var a=wb,b=function(c){return a.call(b.src,b.listener,c)};return b},ob=function(a,b,c,d,e){if(Array.isArray(b))for(var f=0;f<b.length;f++)ob(a,b[f],c,d,e);else c=qb(c),a&&a[P]?a.u.add(String(b),c,!0,u(d)?!!d.capture:!!d,e):sb(a,b,c,!0,d,e)},xb=function(a,b,c,d,e){if(Array.isArray(b))for(var f=0;f<b.length;f++)xb(a,b[f],c,d,e);else(d=u(d)?!!d.capture:!!d,c=qb(c),a&&a[P])?(a=a.u,b=String(b).toString(),b in a.g&&(f=a.g[b],c=jb(f,c,d,e),-1<c&&(hb(f[c]),z(null!=f.length),Array.prototype.splice.call(f,c,1),0==f.length&&(delete a.g[b],a.h--)))):a&&(a=tb(a))&&(b=a.g[b.toString()],a=-1,b&&(a=jb(b,c,d,e)),(c=-1<a?b[a]:null)&&yb(c))},yb=function(a){if(\"number\"!==typeof a&&a&&!a.J){var b=a.src;if(b&&b[P])kb(b.u,a);else{var c=a.type,d=a.proxy;b.removeEventListener?b.removeEventListener(c,d,a.capture):b.detachEvent?b.detachEvent(vb(c),d):b.addListener&&b.removeListener&&b.removeListener(d);nb--;(c=tb(b))?(kb(c,a),0==c.h&&(c.src=null,b[lb]=null)):hb(a)}}},vb=function(a){return a in mb?mb[a]:mb[a]=\"on\"+a},wb=function(a,b){if(a.J)a=!0;else{b=new O(b,this);var c=a.listener,d=a.M||a.src;a.L&&yb(a);a=c.call(d,b)}return a},tb=function(a){a=a[lb];return a instanceof ib?a:null},zb=\"__closure_events_fn_\"+(1E9*Math.random()>>>0),qb=function(a){z(a,\"Listener can not be null.\");if(\"function\"===typeof a)return a;z(a.handleEvent,\"An object listener must have handleEvent method.\");a[zb]||(a[zb]=function(b){return a.handleEvent(b)});return a[zb]};var Q=function(){$a.call(this);this.u=new ib(this);this.j=this;this.h=null};w(Q,$a);Q.prototype[P]=!0;Q.prototype.addEventListener=function(a,b,c,d){pb(this,a,b,c,d)};Q.prototype.removeEventListener=function(a,b,c,d){xb(this,a,b,c,d)};Q.prototype.dispatchEvent=function(a){rb(this);var b=this.h;if(b){var c=[];for(var d=1;b;b=b.h)c.push(b),z(1E3>++d,\"infinite loop\")}b=this.j;d=a.type||a;if(\"string\"===typeof a)a=new N(a,b);else if(a instanceof N)a.target=a.target||b;else{var e=a;a=new N(d,b);qa(a,e)}e=!0;if(c)for(var f=c.length-1;0<=f;f--){var k=a.g=c[f];e=Ab(k,d,!0,a)&&e}k=a.g=b;e=Ab(k,d,!0,a)&&e;e=Ab(k,d,!1,a)&&e;if(c)for(f=0;f<c.length;f++)k=a.g=c[f],e=Ab(k,d,!1,a)&&e;return e};Q.prototype.G=function(){Q.P.G.call(this);if(this.u){var a=this.u,b=0,c;for(c in a.g){for(var d=a.g[c],e=0;e<d.length;e++)++b,hb(d[e]);delete a.g[c];a.h--}}this.h=null};var Ab=function(a,b,c,d){b=a.u.g[String(b)];if(!b)return!0;b=b.concat();for(var e=!0,f=0;f<b.length;++f){var k=b[f];if(k&&!k.J&&k.capture==c){var g=k.listener,h=k.M||k.src;k.L&&kb(a.u,k);e=!1!==g.call(h,d)&&e}}return e&&!d.defaultPrevented},rb=function(a){z(a.u,\"Event target is not initialized. Did you call the superclass (goog.events.EventTarget) constructor?\")};var Bb=function(){};Bb.prototype.g=null;var Db=function(a){var b;(b=a.g)||(b={},Cb(a)&&(b[0]=!0,b[1]=!0),b=a.g=b);return b};var Eb,Fb=function(){};w(Fb,Bb);var Gb=function(a){return(a=Cb(a))?new ActiveXObject(a):new XMLHttpRequest},Cb=function(a){if(!a.h&&\"undefined\"==typeof XMLHttpRequest&&\"undefined\"!=typeof ActiveXObject){for(var b=[\"MSXML2.XMLHTTP.6.0\",\"MSXML2.XMLHTTP.3.0\",\"MSXML2.XMLHTTP\",\"Microsoft.XMLHTTP\"],c=0;c<b.length;c++){var d=b[c];try{return new ActiveXObject(d),a.h=d}catch(e){}}throw Error(\"Could not create ActiveXObject. ActiveX might be disabled, or MSXML might not be installed\");}return a.h};Eb=new Fb;var Hb=function(a,b,c){if(\"function\"===typeof a)c&&(a=v(a,c));else if(a&&\"function\"==typeof a.handleEvent)a=v(a.handleEvent,a);else throw Error(\"Invalid listener argument\");return 2147483647<Number(b)?-1:t.setTimeout(a,b||0)};var Ib=RegExp(\"^(?:([^:/?#.]+):)?(?://(?:([^\\\\\\\\/?#]*)@)?([^\\\\\\\\/?#]*?)(?::([0-9]+))?(?=[\\\\\\\\/?#]|$))?([^?#]+)?(?:\\\\?([^#]*))?(?:#([\\\\s\\\\S]*))?$\"),Jb=function(a,b){if(a){a=a.split(\"&\");for(var c=0;c<a.length;c++){var d=a[c].indexOf(\"=\"),e=null;if(0<=d){var f=a[c].substring(0,d);e=a[c].substring(d+1)}else f=a[c];b(f,e?decodeURIComponent(e.replace(/\\+/g,\" \")):\"\")}}};var R=function(a){Q.call(this);this.headers=new Map;this.U=a||null;this.A=!1;this.T=this.i=null;this.I=this.Z=this.O=\"\";this.B=this.X=this.N=this.W=!1;this.K=0;this.R=null;this.ca=\"\";this.S=this.ia=this.ea=!1;this.V=this.Y=null};w(R,Q);R.prototype.s=K(Wa(),\"goog.net.XhrIo\").o;var Kb=/^https?$/i,Lb=[\"POST\",\"PUT\"],Mb=[];R.prototype.fa=function(){this.H||(this.H=!0,this.G());oa(Mb,this)};R.prototype.setTrustToken=function(a){this.Y=a};R.prototype.setAttributionReporting=function(a){this.V=a};R.prototype.send=function(a,b,c,d){if(this.i)throw Error(\"[goog.net.XhrIo] Object is active with another request=\"+this.O+\"; newUri=\"+a);b=b?b.toUpperCase():\"GET\";this.O=a;this.I=\"\";this.Z=b;this.W=!1;this.A=!0;this.i=this.U?Gb(this.U):Gb(Eb);this.T=this.U?Db(this.U):Db(Eb);this.i.onreadystatechange=v(this.ba,this);this.ia&&\"onprogress\"in this.i&&(this.i.onprogress=v(function(k){this.aa(k,!0)},this),this.i.upload&&(this.i.upload.onprogress=v(this.aa,this)));try{L(this.s,S(this,\"Opening Xhr\")),this.X=!0,this.i.open(b,String(a),!0),this.X=!1}catch(k){L(this.s,S(this,\"Error opening Xhr: \"+k.message));Nb(this,k);return}a=c||\"\";c=new Map(this.headers);if(d)if(Object.getPrototypeOf(d)===Object.prototype)for(var e in d)c.set(e,d[e]);else if(\"function\"===typeof d.keys&&\"function\"===typeof d.get){e=q(d.keys());for(var f=e.next();!f.done;f=e.next())f=f.value,c.set(f,d.get(f))}else throw Error(\"Unknown input type for opt_headers: \"+String(d));d=Array.from(c.keys()).find(function(k){return\"content-type\"==k.toLowerCase()});e=t.FormData&&a instanceof t.FormData;!(0<=na(Lb,b))||d||e||c.set(\"Content-Type\",\"application/x-www-form-urlencoded;charset=utf-8\");b=q(c);for(d=b.next();!d.done;d=b.next())c=q(d.value),d=c.next().value,c=c.next().value,this.i.setRequestHeader(d,c);this.ca&&(this.i.responseType=this.ca);\"withCredentials\"in this.i&&this.i.withCredentials!==this.ea&&(this.i.withCredentials=this.ea);if(\"setTrustToken\"in this.i&&this.Y)try{this.i.setTrustToken(this.Y)}catch(k){L(this.s,S(this,\"Error SetTrustToken: \"+k.message))}if(\"setAttributionReporting\"in this.i&&this.V)try{this.i.setAttributionReporting(this.V)}catch(k){L(this.s,S(this,\"Error SetAttributionReporting: \"+k.message))}try{Ob(this),0<this.K&&(this.S=Pb(this.i),L(this.s,S(this,\"Will abort after \"+this.K+\"ms if incomplete, xhr2 \"+this.S)),this.S?(this.i.timeout=this.K,this.i.ontimeout=v(this.da,this)):this.R=Hb(this.da,this.K,this)),L(this.s,S(this,\"Sending request\")),this.N=!0,this.i.send(a),this.N=!1}catch(k){L(this.s,S(this,\"Send error: \"+k.message)),Nb(this,k)}};var Pb=function(a){return cb&&\"number\"===typeof a.timeout&&void 0!==a.ontimeout};R.prototype.da=function(){\"undefined\"!=typeof fa&&this.i&&(this.I=\"Timed out after \"+this.K+\"ms, aborting\",L(this.s,S(this,this.I)),this.dispatchEvent(\"timeout\"),this.abort(8))};var Nb=function(a,b){a.A=!1;a.i&&(a.B=!0,a.i.abort(),a.B=!1);a.I=b;Qb(a);Rb(a)},Qb=function(a){a.W||(a.W=!0,a.dispatchEvent(\"complete\"),a.dispatchEvent(\"error\"))};R.prototype.abort=function(){this.i&&this.A&&(L(this.s,S(this,\"Aborting\")),this.A=!1,this.B=!0,this.i.abort(),this.B=!1,this.dispatchEvent(\"complete\"),this.dispatchEvent(\"abort\"),Rb(this))};R.prototype.G=function(){this.i&&(this.A&&(this.A=!1,this.B=!0,this.i.abort(),this.B=!1),Rb(this,!0));R.P.G.call(this)};R.prototype.ba=function(){this.H||(this.X||this.N||this.B?Sb(this):this.ha())};R.prototype.ha=function(){Sb(this)};var Sb=function(a){if(a.A&&\"undefined\"!=typeof fa)if(a.T[1]&&4==T(a)&&2==Tb(a))L(a.s,S(a,\"Local request error detected and ignored\"));else if(a.N&&4==T(a))Hb(a.ba,0,a);else if(a.dispatchEvent(\"readystatechange\"),4==T(a)){L(a.s,S(a,\"Request complete\"));a.A=!1;try{if(Ub(a))a.dispatchEvent(\"complete\"),a.dispatchEvent(\"success\");else{try{var b=2<T(a)?a.i.statusText:\"\"}catch(c){L(a.s,\"Can not get status: \"+c.message),b=\"\"}a.I=b+\" [\"+Tb(a)+\"]\";Qb(a)}}finally{Rb(a)}}};R.prototype.aa=function(a,b){z(\"progress\"===a.type,\"goog.net.EventType.PROGRESS is of the same type as raw XHR progress.\");this.dispatchEvent(Vb(a,\"progress\"));this.dispatchEvent(Vb(a,b?\"downloadprogress\":\"uploadprogress\"))};var Vb=function(a,b){return{type:b,lengthComputable:a.lengthComputable,loaded:a.loaded,total:a.total}},Rb=function(a,b){if(a.i){Ob(a);var c=a.i,d=a.T[0]?function(){}:null;a.i=null;a.T=null;b||a.dispatchEvent(\"ready\");try{c.onreadystatechange=d}catch(e){Ya(a.s,\"Problem encountered resetting onreadystatechange: \"+e.message)}}},Ob=function(a){a.i&&a.S&&(a.i.ontimeout=null);a.R&&(t.clearTimeout(a.R),a.R=null)};R.prototype.isActive=function(){return!!this.i};var Ub=function(a){var b=Tb(a);a:switch(b){case 200:case 201:case 202:case 204:case 206:case 304:case 1223:var c=!0;break a;default:c=!1}if(!c){if(b=0===b)a=String(a.O).match(Ib)[1]||null,!a&&t.self&&t.self.location&&(a=t.self.location.protocol.slice(0,-1)),b=!Kb.test(a?a.toLowerCase():\"\");c=b}return c},T=function(a){return a.i?a.i.readyState:0},Tb=function(a){try{return 2<T(a)?a.i.status:-1}catch(b){return-1}};R.prototype.getResponseHeader=function(a){if(this.i&&4==T(this))return a=this.i.getResponseHeader(a),null===a?void 0:a};R.prototype.getAllResponseHeaders=function(){return this.i&&2<=T(this)?this.i.getAllResponseHeaders()||\"\":\"\"};var S=function(a,b){return b+\" [\"+a.Z+\" \"+a.O+\" \"+Tb(a)+\"]\"};var U=function(a){this.g=this.D=this.l=\"\";this.F=null;this.C=this.h=\"\";this.o=!1;var b;a instanceof U?(this.o=a.o,Wb(this,a.l),this.D=a.D,this.g=a.g,Xb(this,a.F),Yb(this,a.h),Zb(this,$b(a.j)),this.C=a.C):a&&(b=String(a).match(Ib))?(this.o=!1,Wb(this,b[1]||\"\",!0),this.D=V(b[2]||\"\"),this.g=V(b[3]||\"\",!0),Xb(this,b[4]),Yb(this,b[5]||\"\",!0),Zb(this,b[6]||\"\",!0),this.C=V(b[7]||\"\")):(this.o=!1,this.j=new W(null,this.o))};U.prototype.toString=function(){var a=[],b=this.l;b&&a.push(X(b,ac,!0),\":\");var c=this.g;if(c||\"file\"==b)a.push(\"//\"),(b=this.D)&&a.push(X(b,ac,!0),\"@\"),a.push(encodeURIComponent(String(c)).replace(/%25([0-9a-fA-F]{2})/g,\"%$1\")),c=this.F,null!=c&&a.push(\":\",String(c));if(c=this.h)this.g&&\"/\"!=c.charAt(0)&&a.push(\"/\"),a.push(X(c,\"/\"==c.charAt(0)?bc:cc,!0));(c=this.j.toString())&&a.push(\"?\",c);(c=this.C)&&a.push(\"#\",X(c,dc));return a.join(\"\")};U.prototype.resolve=function(a){var b=new U(this),c=!!a.l;c?Wb(b,a.l):c=!!a.D;c?b.D=a.D:c=!!a.g;c?b.g=a.g:c=null!=a.F;var d=a.h;if(c)Xb(b,a.F);else if(c=!!a.h){if(\"/\"!=d.charAt(0))if(this.g&&!this.h)d=\"/\"+d;else{var e=b.h.lastIndexOf(\"/\");-1!=e&&(d=b.h.slice(0,e+1)+d)}e=d;if(\"..\"==e||\".\"==e)d=\"\";else if(-1!=e.indexOf(\"./\")||-1!=e.indexOf(\"/.\")){d=0==e.lastIndexOf(\"/\",0);e=e.split(\"/\");for(var f=[],k=0;k<e.length;){var g=e[k++];\".\"==g?d&&k==e.length&&f.push(\"\"):\"..\"==g?((1<f.length||1==f.length&&\"\"!=f[0])&&f.pop(),d&&k==e.length&&f.push(\"\")):(f.push(g),d=!0)}d=f.join(\"/\")}else d=e}c?Yb(b,d):c=\"\"!==a.j.toString();c?Zb(b,$b(a.j)):c=!!a.C;c&&(b.C=a.C);return b};var Wb=function(a,b,c){a.l=c?V(b,!0):b;a.l&&(a.l=a.l.replace(/:$/,\"\"))},Xb=function(a,b){if(b){b=Number(b);if(isNaN(b)||0>b)throw Error(\"Bad port number \"+b);a.F=b}else a.F=null},Yb=function(a,b,c){a.h=c?V(b,!0):b;return a},Zb=function(a,b,c){b instanceof W?(a.j=b,ec(a.j,a.o)):(c||(b=X(b,fc)),a.j=new W(b,a.o));return a},V=function(a,b){return a?b?decodeURI(a.replace(/%25/g,\"%2525\")):decodeURIComponent(a):\"\"},X=function(a,b,c){return\"string\"===typeof a?(a=encodeURI(a).replace(b,gc),c&&(a=a.replace(/%25([0-9a-fA-F]{2})/g,\"%$1\")),a):null},gc=function(a){a=a.charCodeAt(0);return\"%\"+(a>>4&15).toString(16)+(a&15).toString(16)},ac=/[#\\/\\?@]/g,cc=/[#\\?:]/g,bc=/[#\\?]/g,fc=/[#\\?@]/g,dc=/#/g,W=function(a,b){this.h=this.g=null;this.j=a||null;this.l=!!b},Y=function(a){a.g||(a.g=new Map,a.h=0,a.j&&Jb(a.j,function(b,c){a.add(decodeURIComponent(b.replace(/\\+/g,\" \")),c)}))};W.prototype.add=function(a,b){Y(this);this.j=null;a=Z(this,a);var c=this.g.get(a);c||this.g.set(a,c=[]);c.push(b);this.h=A(this.h)+1;return this};var hc=function(a,b){Y(a);b=Z(a,b);a.g.has(b)&&(a.j=null,a.h=A(a.h)-a.g.get(b).length,a.g.delete(b))},ic=function(a,b){Y(a);b=Z(a,b);return a.g.has(b)};W.prototype.forEach=function(a,b){Y(this);this.g.forEach(function(c,d){c.forEach(function(e){a.call(b,e,d,this)},this)},this)};W.prototype.o=function(a){Y(this);var b=[];if(\"string\"===typeof a)ic(this,a)&&(b=b.concat(this.g.get(Z(this,a))));else{a=Array.from(this.g.values());for(var c=0;c<a.length;c++)b=b.concat(a[c])}return b};W.prototype.set=function(a,b){Y(this);this.j=null;a=Z(this,a);ic(this,a)&&(this.h=A(this.h)-this.g.get(a).length);this.g.set(a,[b]);this.h=A(this.h)+1;return this};W.prototype.get=function(a,b){if(!a)return b;a=this.o(a);return 0<a.length?String(a[0]):b};W.prototype.toString=function(){if(this.j)return this.j;if(!this.g)return\"\";for(var a=[],b=Array.from(this.g.keys()),c=0;c<b.length;c++){var d=b[c],e=encodeURIComponent(String(d));d=this.o(d);for(var f=0;f<d.length;f++){var k=e;\"\"!==d[f]&&(k+=\"=\"+encodeURIComponent(String(d[f])));a.push(k)}}return this.j=a.join(\"&\")};var $b=function(a){var b=new W;b.j=a.j;a.g&&(b.g=new Map(a.g),b.h=a.h);return b},Z=function(a,b){b=String(b);a.l&&(b=b.toLowerCase());return b},ec=function(a,b){b&&!a.l&&(Y(a),a.j=null,a.g.forEach(function(c,d){var e=d.toLowerCase();if(d!=e&&(hc(this,d),hc(this,e),0<c.length)){this.j=null;d=this.g;var f=d.set;e=Z(this,e);var k=c.length;if(0<k){for(var g=Array(k),h=0;h<k;h++)g[h]=c[h];k=g}else k=[];f.call(d,e,k);this.h=A(this.h)+c.length}},a));a.l=b};var kc=function(){this.h=void 0;this.g=null;jc(this,0);window.addEventListener(\"load\",this.o.bind(this))};kc.prototype.l=function(a){if(this.g){a=a.target;var b;if(b=Ub(a)){try{var c=a.i?a.i.responseText:\"\"}catch(f){L(a.s,\"Can not get responseText: \"+f.message),c=\"\"}b=\"OK\"===c}if(b){this.j();c=window.location;a=Yb(new U(window.location),\"/ServiceLogin\").toString();var d=void 0===d?Fa:d;a:if(d=void 0===d?Fa:d,a instanceof C)d=a;else{for(b=0;b<d.length;++b){var e=d[b];if(e instanceof Ea&&e.ga(a)){d=new C(a,B);break a}}d=void 0}void 0===d&&Ia(a.toString());a=d||Da;a instanceof C?a instanceof C&&a.constructor===C?a=a.g:(ma(\"expected object of type SafeUrl, got '\"+a+\"' of type \"+ha(a)),a=\"type_error:SafeUrl\"):Ga.test(a)||(Ia(a),a=void 0);void 0!==a&&(c.href=a)}else jc(this,5E3)}};var jc=function(a,b){a.g=setTimeout(function(){if(a.g){var c=Za.get(\"APISID\");if(c===a.h)jc(a,5E3);else{a.h=c;c=new U(\"/PassiveLoginProber\");var d=(new U(window.location)).j;c=Zb(c,d).toString();d=a.l.bind(a);var e=new R;Mb.push(e);d&&(rb(e),e.u.add(\"complete\",d,!1,void 0,void 0));e.u.add(\"ready\",e.fa,!0,void 0,void 0);e.send(c,void 0,void 0,void 0)}}},b)};kc.prototype.o=function(){document.addEventListener(\"submit\",this.j.bind(this))};kc.prototype.j=function(){this.g&&(clearTimeout(this.g),this.g=null)};new kc;}).call(this); Not your computer? Use a private browsing window to sign in. Learn more about using Guest mode Next Create account window.wiz_progress&&window.wiz_progress();window.wiz_tick&&window.wiz_tick('chA7fe');", "https://cs.brown.edu/courses/csci1730/": "cs(ci)173(0) Programming Languages Next showing: Fall 2023 Past editions. You can find newer reviews on the Critical Review site. Some old links may no longer work because they change their URLs. Offering Review Fall 2022 Fall 2021 Fall 2020 Fall 2019 Fall 2018 review Fall 2017 Fall 2016 review Fall 2015 review Fall 2014 review Fall 2013 review Fall 2012 review Fall 2010 review Fall 2008 review Fall 2007 review Fall 2005 review Fall 2004 review Fall 2003 review Fall 2002 review Fall 2001 review Fall 2000", "https://cs.brown.edu/courses/csci1730/2020/tinf.html": "\u25ba Fall 2020: Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Credits \u25ba Assignments Quizius Mystery Languages Implementation Reflection \u25bc Implementation 1 Interpreter 2 Macros 3 OMac 4 SMo LTalk 5 Type Checker 6 Type Inference 7 ACI 8 Lazy 9 Generators 10 Testing Guidelines \u25ba 6 Type Inference 6.1 Introduction 6.2 Reading 6.3 The Language 6.4 Assignment 6.5 Features to Implement 6.6 Testing 6.7 Starter Code 6.8 What To Hand In On this page: 6.1 Introduction 6.2 Reading 6.3 The Language 6.3.1 Grammar 6.4 Assignment 6.4.1 Term s 6.5 Features to Implement 6.5.1 Desugaring with Label s 6.5.2 Label Environment 6.5.3 The Inference Algorithm 6.5.3.1 Phase 1: Constraint Generation 6.5.3.2 Phase 2: Unification 6.5.4 Exceptions 6.6 Testing 6.7 Starter Code 6.7.1 Set Library 6.8 What To Hand In \u2190 prev up next \u2192 6 Type Inference 6.1 Introduction 6.2 Reading 6.3 The Language 6.3.1 Grammar 6.4 Assignment 6.4.1 Term s 6.5 Features to Implement 6.5.1 Desugaring with Label s 6.5.2 Label Environment 6.5.3 The Inference Algorithm 6.5.3.1 Phase 1: Constraint Generation 6.5.3.2 Phase 2: Unification 6.5.4 Exceptions 6.6 Testing 6.7 Starter Code 6.7.1 Set Library 6.8 What To Hand In 6.1 Introduction In this assignment, you will implement the type inference algorithm we studied in lecture on the (untyped) Paret language. 6.2 Reading Chapter 15.3.2 of PLAI 2/e. 6.3 The Language The Paret language for this assignment is nearly the same as the Typed Paret language from Type Checker , except that the type annotations on lam and empty expressions have been removed: putting them back in is, after all, the job of type inference. We have also reintroduced and and or expressions back into the language as syntactic sugar. We also have changed let from a base expression into syntactic sugar. Thus, you will need to implement a desugarer that converts and , or , and let expressions into functionally equivalent expressions. 6.3.1 Grammar The grammar of Untyped Paret is as follows: <expr> ::= <num> | <string> | true | false | (+ <expr> <expr>) | (++ <expr> <expr>) | (num= <expr> <expr>) | (str= <expr> <expr>) | (if <expr> <expr> <expr>) | <id> | (<expr> <expr>) | (first <expr>) | (rest <expr>) | (is-empty <expr>) | (link <expr> <expr>) | empty | (lam <id> <expr>) | (let (<id> <expr>) <expr>) | (and <expr> <expr>) | (or <expr> <expr>) 6.4 Assignment Refer to the support.rkt file for the definition of LExpr . As usual, we have provided a function parse , which consumes an expression in Paret\u2019s concrete syntax and returns the abstract syntax representation of that expression. However, the parser in this assignment returns an LExpr , which is exactly the same as an Expr , except that each LExpr has an additional label field and e-lam also has a param-label field. Label s are used to stand for program points in the type inference algorithm. (define-type-alias Label Symbol) Given the updated Paret language and the updated LExpr abstract syntax, you will implement two functions: desugar and type-of . desugar :: LExpr -> LExpr which consumes an abstract syntax tree (i.e. an LExpr , as returned by parse ), replaces all instances of sugar-and , sugar-or , and sugar-let with desugared equivalents, and returns the result. type-of :: LExpr -> Term that consumes a Paret program in abstract syntax form. If the program is well-typed, type-of returns the type of that program (represented as a Term as defined below); otherwise, it raises an exception. type-of should assume that it\u2019s given an LExpr from desugar . Thus, type-of should assume that there are no sugar-and s, sugar-or s, or sugar-let s in the input Expr . Once you have implemented desugar and type-of , you should use the provided type-infer function (analogous to type-check from Type Checker ) to write test cases for your type checker in your testing file. 6.4.1 Term s As discussed in lecture, Term s describe the type of a subexpression of a program and are used in the constraint generation process. The language of Term s is as follows: (define-type Term (t-var [label : Label]) (t-con [head : Symbol] [args : (Listof Term)])) t-var denotes a term variable (also referred to as a type variable ). A type variable (t-var \u2019 g123) can be read as \u201cthe type of the expression (or program position) labeled \u2019 g123 \u201d. t-con denotes a term constructor , which builds up a more complicated term from a list of subterms. For example, (t-con \u2019 -> (list (t-var \u2019 g123) (t-var \u2019 g123))) is a representation of the more familiar \u2019 a -> \u2019 a . Primitives are also represented this way. For example, (t-con \u2019 Num empty) is a representation of the type Num . For convenience, we provide helper functions to simulate the Type language of Type Checker in the language of Term . For example, (t-num) produces (t-con \u2019 Num empty) ; t-num , t-bool , t-str , t-fun , and t-list are all provided, and you can reference the support code for their definitions. However, these are helper functions and not type variants , so you will not be able to match against them in a type-case expression. 6.5 Features to Implement 6.5.1 Desugaring with Label s When producing desugared expressions, you may need to create fresh Symbol s. For example, you may need to generate new Label s for non-sugar LExpr s. To do this, you should use the built-in gensym function, which generates a unique, unused Symbol . You may also use gensym if you need to create Term s with unknown types. 6.5.2 Label Environment Your type inference algorithm should use a label environment ( LEnv ) to keep track of label identifiers that are in scope. (define-type-alias LEnv (Hashof Symbol Label)) For convenience, we provide a get-label function that consumes a LExpr and retrieves its Label . 6.5.3 The Inference Algorithm In the starter code, we provide templates for two optional helper functions: constraint-gen and unify . constraint-gen :: LExpr -> (Setof Constraint) unify :: (Setof Constraint) -> Substitution The two phases of the inference algorithm discussed in lecture (and discussed below) map to these two helper functions. We suggest using these two function templates to guide your overall type-of implementation, but they are not required\u2014we will not be testing these functions directly, and you are free to ignore them or change them as you wish. 6.5.3.1 Phase 1: Constraint Generation Recall that Constraint s relate program subexpressions by describing how they work together in a successful execution. The language of Constraint s is: (define-type Constraint (eq [l : Term] [r : Term])) Constraint s equate two Term s, often a type variable to the type of some other expression. For example, a Constraint that would be generated for the LExpr (e-num \u2019 g123 5) is: (eq (t-var 'g123) (t-num)) 6.5.3.2 Phase 2: Unification The process used to solve constraints is known as unification . In unification, a unifier algorithm is given a set of equations (e.g. Constraint s), and each Constraint maps a type variable ( t-var ) to a Term . Given a consistent set of Constraint s, we try to unify them in such a way that every t-var gets assigned the correct type. To do this, our unifier should generate a mapping from variables ( Label s) to Term s that do not contain any variables. We define the Substitution alias to represent this mapping: (define-type-alias Substitution (Hashof Label Term)) Unification should always terminate. Thus, your unifier should perform an \u201coccurs\u201d check that causes it to terminate given a circular Constraint . Specifically, given the Constraint (eq replace with) , you should raise (ti-err-fails-occurs-check replace with) if replace is a strict subterm of with . (Make sure you can construct a test case for this!) Make sure you understand why replace = with should pass the \u201coccurs\u201d check. You may find the high-level description of unification here helpful as well. 6.5.4 Exceptions The full set of exceptions is as follows: (define-type TypeInferenceError (ti-err-fails-occurs-check [replace : Term] [with : Term]) (ti-err-constructor-mismatch [t1 : Term] [t2 : Term]) (ti-err-unbound-id [name : Symbol])) Given the Constraint (eq replace with) , you should raise (ti-err-fails-occurs-check replace with) if replace is a strict subterm of with . Given the Constraint (eq t1 t2) , you should raise (ti-err-constructor-mismatch t1 t2) if t1 and t2 are t-con s with different head symbols. Given an expression that references an unbound identifier, you should raise ti-err-unbound-id with the name of the identifier. The priority of TypeInferenceError s is unspecified\u2014when multiple TypeInferenceError s could be raised in a program, your program just needs to raise one of the valid exceptions. The reason for this is that the Constraint s in a Paret program are really a set of Constraint s rather than a list of Constraint s. Thus, the order in which your unifier views each Constraint can change the order in which errors are raised. (Be careful when you\u2019re writing test cases against wheats and chaffs!) 6.6 Testing Unlike type-check from Type Checker , type-infer can produce types with variables. For example, the term (lam x x) might produce (t-fun (t-var \u2019 g123) (t-var \u2019 g123)) . Since Label s are random, writing tests for types with variables can be difficult. To help you write deterministic tests, we provide a function normalize :: Term -> Term that consumes a Term and renames all t-var label s to be lowercase letters in alphabetical order relative to how they appear in the Term . For example, normalizing the type inferred for (lam x (lam y empty)) should produce (t-fun (t-var 'a) (t-fun (t-var 'b) (t-list 'c))) which is equivalent to (t-con '-> (list (t-var 'a) (t-fun (t-var 'b) (t-list 'c)))) You should use normalize when writing test cases in your testing file, or your test cases may cause the wheats to unexpectedly fail. You are not permitted to use normalize in your actual implementation. Finally, in addition to the testing forms documented in the Testing Guidelines , we provide the following testing forms: (test-error-fails-occurs-check? name expr) (test-error-constructor-mismatch? name expr) (test-error-unbound-id? name expr) These test that the given expr raises the correct error. (Example usage can be found in the testing stencil.) 6.7 Starter Code We\u2019ve provided starter code for your implementation at type-inference.rkt and support code at support.rkt . You are not allowed to change the signature of desugar , type-of , and type-infer , but you are welcome to add any helper functions that you need for your implementation. We\u2019ve also provided a stencil for your type-check test cases at type-inference-tests.rkt and testing support code at test-support.rkt . You should check that you can run your type-inference-tests.rkt file successfully in DrRacket before submitting\u2014if you can\u2019t, it means that a definition is missing or you\u2019re trying to test a function that you shouldn\u2019t be testing. 6.7.1 Set Library As mentioned previously, it may be useful to think of the Constraint s in a Paret program as a set of Constraint s rather than a list of Constraint s. Plait does not have a built-in set library, so we provide a (Setof \u2019 a) abstraction in the support.rkt file: (Setof \u2019 a) Type for an immutable set containing elements of type \u2019 a . empty-set Creates an empty set. (set ....) Convenience macro around list->set ; returns a (Setof \u2019 a) containing all of the elements listed in .... . list->set :: (Listof \u2019 a) -> (Setof \u2019 a) Returns a (Setof \u2019 a) containing all of the elements in the input (Listof \u2019 a) . set->list :: (Setof \u2019 a) -> (Listof \u2019 a) Returns a (Listof \u2019 a) containing all of the elements in the input (Setof \u2019 a) . We also provide the following (Setof \u2019 a) utility functions: set-empty? :: (Setof \u2019 a) -> Boolean set-count :: (Setof \u2019 a) -> Number set-member? :: (Setof \u2019 a), \u2019 a -> Boolean set-add :: (Setof \u2019 a) \u2019 a -> (Setof \u2019 a) set-remove :: (Setof \u2019 a) \u2019 a -> (Setof \u2019 a) set-union :: (Setof \u2019 a), (Setof \u2019 a) -> (Setof \u2019 a) set-pick :: (Setof \u2019 a) -> (Pick \u2019 a) Picks an arbitrary element out of the set, and returns a Pick data structure. (define-type (Pick 'a) (pick-none) (pick-some [element : 'a] [rest : (Setof 'a)])) If the set is empty, a pick-none is returned. Otherwise, a pick-some is returned, and the rest of the set (without the picked value) is stored in the rest field of the pick-some . The element returned in a pick-some is not guaranteed to be the same between applications of set-pick on the same (Setof \u2019 a) . You are not required to use the provided (Setof \u2019 a) interface, but you may find it helpful\u2014especially since the templates for our suggested constraint-gen and unify functions utilize the (Setof \u2019 a) abstraction. 6.8 What To Hand In You will submit two files for this assignment: type-inference.rkt , which should be uploaded to the \u201cCode\u201d drop on Gradescope. type-inference-tests.rkt , which should be uploaded to the \u201cTests\u201d drop on Gradescope. You can update your submissions as many times as you want before the deadline. \u2190 prev up next \u2192", "https://brown-cs1570.pages.dev": "CS1570: Design and Analysis of Algorithms Fall 2023 Course Info This is a core undergraduate Computer Science course on the foundations of algorithmic theory and applications. The questions it aims to answer are: What are the different algorithmic archetypes? How can we analyze the performance of algorithms? Which design guidelines should be followed towards achieving efficient algorithms? What data structures can be used for specific algorithmic tasks? We will cover these questions and, in the process, explore the use of algorithms in important applications such as artificial intelligence, data management, network analysis, and geographic information systems. The course has lectures, written homework assignments, and exams. Syllabus Gradescope Edstem Anonymous Feedback Form Pseudocode Guide Proof Guide Lectures Lectures are held in-person on Tuesdays and Thursdays from 2:30 to 3:50p.m. in CIT 241. Lecture slides will be posted on EdStem and recordings will be available on Panopto. Lecture Topic Date Introduction 09/07 Preliminary Concepts 09/12 Comparison-Based Sorting 09/14 Searching & Non-Comparison Sorting 09/19 Greedy Algorithms I 09/21 Greedy Algorithms II 09/16 Dynamic Programming Algorithms I 09/28 Dynamic Programming Algorithms II 10/03 Divide & Conquer Algorithms I 10/05 Divide & Conquer Algorithms II 10/10 Basic Data Structures 10/12 Tree Data Structures 10/17 Hash-Based Data Structures 10/19 Graph Algorithms I 10/26 Graph Algorithms II 10/31 Text Processing & Pattern Matching 11/02 Computational Geometry I 11/07 Computational Geometry II 11/09 Limits of Computation I 11/11 Limits of Computation II 11/16 Limits of Computation III 11/28 External Memory Algorithms I 11/30 External Memory Algorithms II 12/05 Assignments All assignments must be typeset using L a T e X and submitted on Gradescope . Please refer to the syllabus for the class collaboration and late submission policy. Assignment Out Due Template Solution Getting Started 09/07 09/14 Proof Techniques 09/12 09/19 / Searching & Sorting 09/19 09/26 / Greedy Algorithms 09/26 10/03 / Dynamic Programming 10/03 10/12 / Divide & Conquer 10/12 10/19 / Data Structures 10/26 11/02 / Graph Algorithms 11/02 11/09 / String Algorithms & Computational Geometry 11/09 11/30 / Complexity Theory 11/30 12/7 / Hours Hours will follow an open format, where students can work together in groups to brainstorm solutions and ask the TA for help when needed. In order to safeguard everyone's health, please refrain from going to in-person hours if you are feeling unwell or experiencing any symptoms. Reach out to the TA staff to inquire about the availability of remote TA hours. December 2023 Sun Mon Tue Wed Thu Fri Sat 26 27 28 29 30 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 1 2 3 4 5 6 Nothing scheduled for today! Resources Course Syllabus You can find the course syllabus here! The course collaboration policy and late day policy for all assignments are also included in the syllabus. Anonymous Feedback Form If you have any feedback for the course staff, please feel free to submit it here! All submissions are welcome! L a T e X Resources For this course your solutions must be typeset using L a T e X . Below are some resources that you might find helpful: Overleaf is an online L a T e X editor that you can use to write your solutions. Overleaf L a T e X Documentation is a great resource for learning L a T e X . Detexify is a tool that allows you to draw a symbol and get the corresponding L a T e X code. Pseudocode Guide contains our recommendations for typesetting pseudocode in L a T e X . The CS1570 class file is used to apply our styles and macros for your L a T e X documents. You'll want this if you prefer not to use our Overleaf template. Department Resources The CS department provides many resources to help students succeed in their courses. Undergraduate Missive Diversity and Inclusion Student Advocates for Diversity and Inclusion Women in Computer Science MOSAIC+ Brown CS Health And Wellness If you need accommodation for your physical and mental health, please feel free to reach out to Professor De Stefani \u2014 we want to support you as much as we can in the most comfortable way for you. It is important to note that TAs should not be handling health and accomodations information , so inquiries should be directed towards the professor only . Resources for physical/mental health, accessibility, and accommodations can be found here . Staff You can reach the entire course staff at cs1570tas@lists.brown.edu , the HTA and Professor at cs1570htas@lists.brown.edu and just the Professor at lorenzo_destefani@brown.edu . Lorenzo De Stefani Professor Hammad Izhar HTA Luke Choi UTA Nishchay Parashar UTA Neil Xu UTA Michael Youssef UTA Bin Zhang UTA {\"props\":{\"pageProps\":{}},\"page\":\"/\",\"query\":{},\"buildId\":\"fbkoPTMOKwN9ZsYFVdOTr\",\"nextExport\":true,\"autoExport\":true,\"isFallback\":false,\"scriptLoader\":[]}", "https://cs.brown.edu/courses/csci1730/2021/interpreter.html": "\u25ba Fall 2021: Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Capstone Credits \u25ba Assignments SMo L Mystery Languages Implementation Analysis \u25bc Implementation 1 Stacks 1 2 Stacks 2 3 Interpreter 4 Stacks 3 5 Macros 6 OMac 7 SMo LTalk 8 Type Checker 9 Type Inference 10 ACI 11 Lazy 12 Generators 13 From Assertions to Security 14 Testing Guidelines \u25ba 3 Interpreter 3.1 Introduction 3.2 Assignment 3.3 Features to Implement 3.4 Grammar 3.5 Testing 3.6 Starter Code 3.7 What To Hand In On this page: 3.1 Introduction 3.2 Assignment 3.2.1 Errors 3.3 Features to Implement 3.3.1 Desugaring 3.3.1.1 and and or 3.3.1.2 let 3.3.2 Environment 3.3.3 Binary Operators 3.3.4 Conditionals 3.3.5 Functions 3.4 Grammar 3.4.1 Abstract Syntax 3.5 Testing 3.5.1 How We Test Tests 3.5.2 Guidelines for Testing Your Interpreter 3.5.3 Debugging 3.6 Starter Code 3.7 What To Hand In \u2190 prev up next \u2192 3 Interpreter 3.1 Introduction 3.2 Assignment 3.2.1 Errors 3.3 Features to Implement 3.3.1 Desugaring 3.3.1.1 and and or 3.3.1.2 let 3.3.2 Environment 3.3.3 Binary Operators 3.3.4 Conditionals 3.3.5 Functions 3.4 Grammar 3.4.1 Abstract Syntax 3.5 Testing 3.5.1 How We Test Tests 3.5.2 Guidelines for Testing Your Interpreter 3.5.3 Debugging 3.6 Starter Code 3.7 What To Hand In 3.1 Introduction For this assignment, you will write an interpreter for the Paret language (\u201cpared-down Pyret\u201d) described below. 3.2 Assignment We have provided a function parse which consumes an expression in the Paret language\u2019s concrete syntax, S-Exp , and returns the abstract syntax representation of that expression (an Expr ). parse :: S-Exp -> Expr parse only accepts expressions that follow Paret\u2019s grammar . You will implement two functions: desugar and interp . desugar :: Expr -> Expr which consumes an abstract syntax tree (i.e. an Expr , as returned by parse ), replaces all instances of syntactic sugar (described below) with desugared equivalents, and returns the result. interp :: Expr -> Value which consumes a desugared abstract syntax tree (i.e. the Expr returned by desugar ) and returns a Paret Value . interp should assume that it\u2019s given an Expr from desugar . If interp is given an Expr containing a sugar-* form, its behavior is undefined. Finally, interp should evaluate programs by performing a post-order traversal of the abstract syntax tree (AST): first, evaluate all of the children of an expression from left to right, then evaluate the expression itself. This makes it unambiguous which error to raise if there are multiple errors in the AST. Why evaluate our expressions from left to right? One might say we\u2019ve chosen this as a matter of convention, but ultimately the choice is completely arbitrary. Strictly speaking, we could define our language to evaluate sub-expressions from right to left and that would be just fine. What\u2019s important is that an explicit evaluation order choice is made so the language has clearly defined semantics. Once you have implemented desugar and interp , you should use the provided eval function (which wraps around those two functions and parse ) to write test cases for your interpreter. 3.2.1 Errors We have provided a function raise-error for throwing errors, as well as a type InterpError , which contains all the error cases that your interpreter might run into: #lang racket ( define-type InterpError ( err-if-got-non-boolean [ val : Value ] ) ( err-bad-arg-to-op [ op : Operator ] [ val : Value ] ) ( err-unbound-var [ name : Symbol ] ) ( err-not-a-function [ val : Value ] ) ) You can throw an error by using raise-error and providing the correct InterpError . For example: #lang racket ( raise-error ( err-bad-arg-to-op ( op-plus ) ( v-str \"str\" ) ) ) Pay careful attention to how interp \u2019s evaluation order specification impacts which errors are thrown. For example, #lang racket ( str= ( + 5 \"bad\" ) \"hello\" ) ( ++ false ( + \"bad\" 6 ) ) ( \"not function\" ( + 7 \"bad\" ) ) should all raise (err-bad-arg-to-op (op-plus) (v-str \"bad\")) . 3.3 Features to Implement 3.3.1 Desugaring Racket macros, which you\u2019ll write later in the course, are themselves syntactic sugar. However, we are not asking you to use Racket macros for anything in this assignment. As described previously, Paret contains several forms of syntactic sugar: and , or , and let . desugar should convert sugar-and , sugar-or , and sugar-let Expr s into functionally equivalent, non-sugar Expr s. There are multiple implementation strategies for desugar . Be sure to test it well: it\u2019s easy to miss some details when desugaring, especially in regards to evaluation order! 3.3.1.1 and and or and consumes two boolean expressions. It evaluates to true if both boolean expressions are true; otherwise, it evaluates to false . or consumes two boolean expressions. It evaluates to true if at least one boolean expression is true; otherwise, it evaluates to false . desugar should convert sugar-and and sugar-or Expr s in such a way that, when interp interprets the desugared code, and and or short-circuit . In and expressions, this means that if the first argument of and evaluates to false , the second argument to and is not evaluated and the and expression evaluates to false . (Similarly, if the first argument of or evaluates to true , the second argument to or should not be evaluated.) Thus, the second argument of a short-circuited expression should never throw an error. 3.3.1.2 let let should accept a single variable-value pair and a body. let evaluates the value, binds it to the variable, and evaluates the body with the newly bound variable in scope. For example, the following should evaluate to 3 : #lang racket ( let ( x 1 ) ( + x 2 ) ) let should disallow recursive definitions. That is, in (let (<var> <expr>) <body>) , <var> should be bound in <body> but not in <expr> . The desugaring of sugar-let may not be obvious, so here\u2019s a hint: What Expr (s) allow us to change the variables bound within a given environment? 3.3.2 Environment Your interpreter should use an environment, Env , to keep track of the Value s of variables in scope. (define-type-alias Env (Hashof Symbol Value)) Since Env is a Hashof , you can use Plait\u2019s built-in hash table functions on your Env . For your environment, make sure you use hash , which creates immutable hash tables! What happens if you use make-hash , which creates mutable hash tables instead? Try replacing one with the other and see. If none of your tests fail, you aren\u2019t testing enough! You should have at least one failing test, if not several, when you make this switch. interp should allow variable shadowing , meaning that if you bind a variable that is already bound, the new binding takes precedence. When in doubt, your interpreter should behave just as SMoL would. When interp encounters an unbound variable, interp should raise the err-unbound-var exception with the name of the variable. 3.3.3 Binary Operators Paret includes binary addition ( + ) and number equality testing ( num= ), as well as string appending ( ++ ) and string equality testing ( str= ). In place of having separate syntactic forms for each of + , num= , ++ , and str= , parse converts these operators into a single AST datatype variant, e-op , which denotes the operation to use via an Operator variant: #lang racket ( define-type Operator ( op-plus ) ( op-append ) ( op-str-eq ) ( op-num-eq ) ) When you implement these operators, you should use Plait\u2019s + for op-plus , string-append for op-append , string=? for op-str-eq , and = for op-num-eq . Evaluation should raise a err-bad-arg-to-op error for non-numeric values passed to + and num= operations, and for non-string values passed to ++ and str= operations. The op part of the error is the Operator that was called, and val is the Value it was given that had the wrong type. Argument types to Operator s should be checked from left to right. For example, #lang racket ( + true \"string\" ) should raise (err-bad-arg-to-op op-plus (v-bool true)) . In line with interp \u2019s evaluation order specification, err-bad-arg-to-op should only be raised after evaluating the function-position expression and its argument. 3.3.4 Conditionals if -expressions in Paret have three parts: cond , which should evaluate to a Boolean Value consq , which evaluates if cond evaluated to true altern , which evaluates if cond evaluated to false if statements should short-circuit (i.e. only evaluate the relevant branch). If cond evaluates to a non-Boolean Value , an err-if-got-non-boolean error should be raised with val being the offending Value . 3.3.5 Functions Functions in Paret are unary (i.e. they take exactly 1 argument). Here\u2019s two examples of functions and their applications: ((lam x (+ x 3)) 2) ((lam y 5) 1) These should both evaluate to 5. It\u2019s possible that when attempting to perform a function application, the value in the function position isn\u2019t actually a function; e.g., you might have (12) . In this case you should raise a err-not-a-function exception, where val is the value that was applied; e.g., 1 . In line with interp \u2019s evaluation order specification, err-not-a-function should only be raised after evaluating the function-position expression and its argument. 3.4 Grammar The grammar of Paret is as follows: <expr> ::= <num> | <string> | <var> # variable (a.k.a. identifier) | true | false | (+ <expr> <expr>) | (++ <expr> <expr>) | (num= <expr> <expr>) | (str= <expr> <expr>) | (if <expr> <expr> <expr>) | (and <expr> <expr>) | (or <expr> <expr>) | (let (<var> <expr>) <expr>) | (lam <var> <expr>) # anonymous function | (<expr> <expr>) # function application 3.4.1 Abstract Syntax Refer to Environment for the definition of Env and Binary Operators for the definition of Operator . #lang racket ( define-type Value ( v-num [ value : Number ] ) ( v-str [ value : String ] ) ( v-bool [ value : Boolean ] ) ( v-fun [ param : Symbol ] [ body : Expr ] [ env : Env ] ) ) ( define-type Expr ( e-num [ value : Number ] ) ( e-str [ value : String ] ) ( e-bool [ value : Boolean ] ) ( e-op [ op : Operator ] [ left : Expr ] [ right : Expr ] ) ( e-if [ cond : Expr ] [ consq : Expr ] [ altern : Expr ] ) ( e-lam [ param : Symbol ] [ body : Expr ] ) ( e-app [ func : Expr ] [ arg : Expr ] ) ( e-var [ name : Symbol ] ) ( sugar-and [ left : Expr ] [ right : Expr ] ) ( sugar-or [ left : Expr ] [ right : Expr ] ) ( sugar-let [ var : Symbol ] [ value : Expr ] [ body : Expr ] ) ) 3.5 Testing We care that you test programs well. Programming langauge implementations are expected to be rock-solid (when\u2019s the last time you ran into an implementation bug?). You need to uphold this standard. This isn\u2019t a course in something like AI, where we don\u2019t even know what the right answer might be! In addition to the quality and correctness of your code, you will be evaluated on the quality and correctness of your tests. 3.5.1 How We Test Tests It\u2019s probably useful for you to understand how we test your tests. What\u2019s the job of a test suite (i.e., set of tests)? It\u2019s to find errors in a program. (Examples help you understand the problem before you start writing code, tests help you catch errors in the program as and after you write it.) In short, test suites are like sorting hats, putting programs in a \u201cgood\u201d or \u201cbad\u201d bin. If you are a mathy person, you might call a test suite a classifier . So, here\u2019s how we will test your test suites. We construct a collection of implementations for the problem. Some are known to be correct (because we built them that way); we call each of these a wheat . The others are known to be incorrect (because we intentionally introduce errors); we call each of these a chaff . Your test suite\u2019s job is to separate the wheat from the chaff . That is, we will run each of the wheats and chaffs against your test suite and see what happens: | On a wheat\u2026 | On a chaff\u2026 | ------------------------------------------------ \u2026all tests passed | GREAT! | Not great\u2026 | \u2026some tests failed | Ooops! | GREAT! | All tests passing a wheat, and at least one test failing on a chaff, is exactly what we are hoping for. If all tests pass on a chaff, that\u2019s not ideal, but you may miss some chaffs, so it may be okay. But when any tests fail on a wheat, that\u2019s definitely a problem because it should never happen. It quite likely means you\u2019ve misunderstood the problem statement, or perhaps the problem statement is ambiguous, or something like that. This should get cleared up right away. The quality of your test suite is then a measure of whether you passed the wheats and how many chaffs you caught. Of course, we can make the latter arbitrarily hard. For instance, we could define a chaff that always works correctly except when the given list has, say, exactly 1729 elements. We won\u2019t do things like that, both because it\u2019s cruel and because real implementations are very rarely buggy in this way. Instead, we will make \u201creasonable\u201d mistakes (but not all of them will be easy!). In short, we will be running your test suite against our implementations. Therefore, it is very important that when you turn in your test suite (see details below), it not be accompanied by your implementation: otherwise, when we try to load ours, DrRacket will complain. 3.5.2 Guidelines for Testing Your Interpreter Please read the Testing Guidelines for guidelines on how to write tests for the Implementation assignments. For the purposes of testing, we have defined an eval function that calls parse , desugar , and interp for you. eval consumes a program in the Paret language\u2019s concrete syntax ( S-Exp ) and returns a Paret Value : eval :: S-Exp -> Value You should use eval in your testing file when writing test cases. You should not directly test desugar and interp individually in your test file (though you are welcome to and encouraged to individually test these functions in your code file). There\u2019s good reason for this: there is more than one correct desugaring, so any tests you write may be implementation-specific. (And, of course, your submitted test cases should indirectly test desugaring, because you should test that and and or let work correctly.) In addition to the testing forms documented in the Testing Guidelines , we provide the following testing form: (test-raises-interp-error? name expr interp-error) Tests that the given expr raises the given interp-error . (Example usage can be found in the testing stencil.) Finally, recall that programs can evaluate to functions. However, you may have chosen a different representation for closures than we did. Therefore, your tests in your test file should only check that such a program returned a function, and not rely on the specific function returned (because of the differences in representation). For instance, you may write: (test-pred \"My predicate test\" v-fun? (eval `{lam x 5}) #t) Reminder: In Plait, you can add a ? to the end of the name of any given type variant to create a function that returns true if the expression evaluates to that type variant. However, you may not write: (test-equal? \"Don't write this test\" (eval `{lam x 5}) (v-fun 'x (e-num 5) (hash (list )))) because our representation of closures may not match your exact representation. (You are, of course, welcome to write test cases of the latter form in your code file.) 3.5.3 Debugging You may find it useful to use Plait\u2019s trace to help understand the control flow of your interpreter. For instance, if you write (trace interp) then all subsequent calls (including\u2014and especially\u2014recursive calls) to interp will be presented with their arguments and results. Do not include calls to trace in your final submissions. 3.6 Starter Code We\u2019ve provided starter code for your implementation at interpreter.rkt and support code at support.rkt . You are not allowed to change the signature of eval , desugar , or interp , but you are welcome to \u2014 and might need to \u2014 add helper functions for your implementation. We\u2019ve also provided a stencil for your eval test cases at interpreter-tests.rkt and testing support code at test-support.rkt . You should check that you can run your interpreter-tests.rkt file successfully in DrRacket before submitting\u2014if you can\u2019t, it means that a definition is missing or you\u2019re trying to test a function that you shouldn\u2019t be testing (e.g. a helper function or interp or desugar directly). Do not modify the contents of support.rkt and test-support.rkt . 3.7 What To Hand In You will submit two files for this assignment: interpreter.rkt , which should be uploaded to the \u201cCode\u201d drop on Gradescope. interpreter-tests.rkt , which should be uploaded to the \u201cTests\u201d drop on Gradescope. You can update your submissions as many times as you want before the deadline. \u2190 prev up next \u2192", "https://brown-csci1660.github.io/handin-wiki/": "CS1660 Handin Wiki Home Bash Scripting Managing Processes Go syntax Attacks breakout env-vars listconf path-byp perm-conf racecond symlinkt exfil-pi CS1660 Handin Wiki Home Welcome to the CS1660 Handin Wiki This site contains documentation for some of the vulnerabilites available in the Handin project. Each page is labeled according to the tag listed in the handout. In addition to the vulnerability specific documentation, we have also compiled some documentation on specific technical components that may be useful for this project. Bash Scripting Everything you to know about Bash-shell programming Advanced Bash-Scripting Guide Managing Processes Linux Commands for process management Foreground and Background processes Go syntax A tour of Go Go Playground Go packages Next Built with MkDocs using a theme provided by Read the Docs . Next \u00bb var base_url = \".\"; jQuery(function () { SphinxRtdTheme.Navigation.enable(true); });", "https://cs.brown.edu/courses/csci1730/2022/interpreter.html": "\u25ba Fall 2022: Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Staff Capstone Credits \u25ba Assignments SMo L Mystery Languages Implementation Analysis \u25bc Implementation 1 Interpreter 2 Macros 3 OMac 4 SMo LTalk 5 Type Checker 6 Type Inference 7 Lazy 8 From Assertions to Security 9 Testing Guidelines \u25ba 1 Interpreter 1.1 Introduction 1.2 Assignment 1.3 Features to Implement 1.4 Grammar 1.5 Testing 1.6 Starter Code 1.7 What To Hand In On this page: 1.1 Introduction 1.2 Assignment 1.2.1 Errors 1.3 Features to Implement 1.3.1 Desugaring 1.3.1.1 and and or 1.3.1.2 let 1.3.2 Environment 1.3.3 Binary Operators 1.3.4 Conditionals 1.3.5 Functions 1.4 Grammar 1.4.1 Abstract Syntax 1.5 Testing 1.5.1 How We Test Tests 1.5.2 Guidelines for Testing Your Interpreter 1.5.3 Debugging 1.6 Starter Code 1.7 What To Hand In contents \u2190 prev up next \u2192 1 Interpreter 1.1 Introduction 1.2 Assignment 1.2.1 Errors 1.3 Features to Implement 1.3.1 Desugaring 1.3.1.1 and and or 1.3.1.2 let 1.3.2 Environment 1.3.3 Binary Operators 1.3.4 Conditionals 1.3.5 Functions 1.4 Grammar 1.4.1 Abstract Syntax 1.5 Testing 1.5.1 How We Test Tests 1.5.2 Guidelines for Testing Your Interpreter 1.5.3 Debugging 1.6 Starter Code 1.7 What To Hand In 1.1 Introduction For this assignment, you will write an interpreter for the Paret language (\u201cpared-down Pyret\u201d) described below. 1.2 Assignment We have provided a function parse which consumes an expression in the Paret language\u2019s concrete syntax, S-Exp , and returns the abstract syntax representation of that expression (an Expr ). parse :: S-Exp -> Expr parse only accepts expressions that follow Paret\u2019s grammar . You will implement two functions: desugar and interp . desugar :: Expr -> Expr which consumes an abstract syntax tree (i.e. an Expr , as returned by parse ), replaces all instances of syntactic sugar (described below) with desugared equivalents, and returns the result. interp :: Expr -> Value which consumes a desugared abstract syntax tree (i.e. the Expr returned by desugar ) and returns a Paret Value . interp should assume that it\u2019s given an Expr from desugar . If interp is given an Expr containing a sugar-* form, its behavior is undefined. Finally, interp should evaluate programs by performing a post-order traversal of the abstract syntax tree (AST): first, evaluate all of the children of an expression from left to right, then evaluate the expression itself. This makes it unambiguous which error to raise if there are multiple errors in the AST. Why evaluate our expressions from left to right? One might say we\u2019ve chosen this as a matter of convention, but ultimately the choice is completely arbitrary. Strictly speaking, we could define our language to evaluate sub-expressions from right to left and that would be just fine. What\u2019s important is that an explicit evaluation order choice is made so the language has clearly defined semantics. Once you have implemented desugar and interp , you should use the provided eval function (which wraps around those two functions and parse ) to write test cases for your interpreter. 1.2.1 Errors For throwing errors you can use Racket\u2019s error message convention which looks like (error <symbol> <message string>) where a symbol is written as a single quote followed by a variable. Such a symbol name can look like \u2019 interp-error ( \u2019 abc or \u2019 xyz would also work but we recommend keeping useful names). Here is an example of how you can throw an error: #lang racket ( error ' interp-error \"unbound variable was found\" ) Some examples of expressions that should raise errors are: #lang racket ( str= ( + 5 \"bad\" ) \"hello\" ) ( ++ false ( + \"bad\" 6 ) ) ( \"not function\" ( + 7 \"bad\" ) ) These should all throw the standard error as per the convention specified above. However, we recommend having useful messages in the strings to keep track of the types of errors and edge cases you are covering; this also comes in handy when debugging! 1.3 Features to Implement 1.3.1 Desugaring Racket macros, which you\u2019ll write later in the course, are themselves syntactic sugar. However, we are not asking you to use Racket macros for anything in this assignment. As described previously, Paret contains several forms of syntactic sugar: and , or , and let . desugar should convert sugar-and , sugar-or , and sugar-let Expr s into functionally equivalent, non-sugar Expr s. There are multiple implementation strategies for desugar . Be sure to test it well: it\u2019s easy to miss some details when desugaring! 1.3.1.1 and and or and consumes two boolean expressions. It evaluates to true if both boolean expressions are true; otherwise, it evaluates to false . or consumes two boolean expressions. It evaluates to true if at least one boolean expression is true; otherwise, it evaluates to false . desugar should convert sugar-and and sugar-or Expr s in such a way that, when interp interprets the desugared code, and and or short-circuit . In and expressions, this means that if the first argument of and evaluates to false , the second argument to and is not evaluated and the and expression evaluates to false . (Similarly, if the first argument of or evaluates to true , the second argument to or should not be evaluated.) Thus, the second argument of a short-circuited expression should never throw an error. 1.3.1.2 let let should accept a single variable-value pair and a body. let evaluates the value, binds it to the variable, and evaluates the body with the newly bound variable in scope. For example, the following should evaluate to 3 : #lang racket ( let ( x 1 ) ( + x 2 ) ) let should disallow recursive definitions. That is, in (let (<var> <expr>) <body>) , <var> should be bound in <body> but not in <expr> . The desugaring of sugar-let may not be obvious, so here\u2019s a hint: What Expr (s) allow us to change the variables bound within a given environment? 1.3.2 Environment Your interpreter should use an environment, Env , to keep track of the Value s of variables in scope. (define-type-alias Env (Hashof Symbol Value)) Since Env is a Hashof , you can use Plait\u2019s built-in hash table functions on your Env . For your environment, make sure you use hash , which creates immutable hash tables! What happens if you use make-hash , which creates mutable hash tables instead? Try replacing one with the other and see. If none of your tests fail, you aren\u2019t testing enough! You should have at least one failing test, if not several, when you make this switch. interp should allow variable shadowing , meaning that if you bind a variable that is already bound, the new binding takes precedence. When in doubt, your interpreter should behave just as SMoL would. When interp encounters an unbound variable, interp should raise an error. 1.3.3 Binary Operators Paret includes binary addition ( + ) and number equality testing ( num= ), as well as string appending ( ++ ) and string equality testing ( str= ). In place of having separate syntactic forms for each of + , num= , ++ , and str= , parse converts these operators into a single AST datatype variant, e-op , which denotes the operation to use via an Operator variant: #lang racket ( define-type Operator ( op-plus ) ( op-append ) ( op-str-eq ) ( op-num-eq ) ) When you implement these operators, you should use Plait\u2019s + for op-plus , string-append for op-append , string=? for op-str-eq , and = for op-num-eq . Evaluation should also raise an error for non-numeric values passed to + and num= operations, and for non-string values passed to ++ and str= operations. Here we throw an error when the operator is receiving the wrong type of value, for example: #lang racket ( + true \"string\" ) 1.3.4 Conditionals if -expressions in Paret have three parts: cond , which should evaluate to a Boolean Value consq , which evaluates if cond evaluated to true altern , which evaluates if cond evaluated to false if statements should short-circuit (i.e. only evaluate the relevant branch). If cond evaluates to a non-Boolean Value , an error should be raised. 1.3.5 Functions Functions in Paret are unary (i.e. they take exactly 1 argument). Here\u2019s two examples of functions and their applications: ((lam x (+ x 3)) 2) ((lam y 5) 1) These should both evaluate to 5. It\u2019s possible that when attempting to perform a function application, the value in the function position isn\u2019t actually a function; e.g., you might have (12) . In this case you should raise an error as well. 1.4 Grammar The grammar of Paret is as follows: <expr> ::= <num> | <string> | <var> # variable (a.k.a. identifier) | true | false | (+ <expr> <expr>) | (++ <expr> <expr>) | (num= <expr> <expr>) | (str= <expr> <expr>) | (if <expr> <expr> <expr>) | (and <expr> <expr>) | (or <expr> <expr>) | (let (<var> <expr>) <expr>) | (lam <var> <expr>) # anonymous function | (<expr> <expr>) # function application 1.4.1 Abstract Syntax Refer to Environment for the definition of Env and Binary Operators for the definition of Operator . #lang racket ( define-type Value ( v-num [ value : Number ] ) ( v-str [ value : String ] ) ( v-bool [ value : Boolean ] ) ( v-fun [ param : Symbol ] [ body : Expr ] [ env : Env ] ) ) ( define-type Expr ( e-num [ value : Number ] ) ( e-str [ value : String ] ) ( e-bool [ value : Boolean ] ) ( e-op [ op : Operator ] [ left : Expr ] [ right : Expr ] ) ( e-if [ cond : Expr ] [ consq : Expr ] [ altern : Expr ] ) ( e-lam [ param : Symbol ] [ body : Expr ] ) ( e-app [ func : Expr ] [ arg : Expr ] ) ( e-var [ name : Symbol ] ) ( sugar-and [ left : Expr ] [ right : Expr ] ) ( sugar-or [ left : Expr ] [ right : Expr ] ) ( sugar-let [ var : Symbol ] [ value : Expr ] [ body : Expr ] ) ) 1.5 Testing We care that you test programs well. Programming langauge implementations are expected to be rock-solid (when\u2019s the last time you ran into an implementation bug?). You need to uphold this standard. This isn\u2019t a course in something like AI, where we don\u2019t even know what the right answer might be! In addition to the quality and correctness of your code, you will be evaluated on the quality and correctness of your tests. 1.5.1 How We Test Tests It\u2019s probably useful for you to understand how we test your tests. What\u2019s the job of a test suite (i.e., set of tests)? It\u2019s to find errors in a program. (Examples help you understand the problem before you start writing code, tests help you catch errors in the program as and after you write it.) In short, test suites are like sorting hats, putting programs in a \u201cgood\u201d or \u201cbad\u201d bin. If you are a mathy person, you might call a test suite a classifier . So, here\u2019s how we will test your test suites. We construct a collection of implementations for the problem. Some are known to be correct (because we built them that way); we call each of these a wheat . The others are known to be incorrect (because we intentionally introduce errors); we call each of these a chaff . Your test suite\u2019s job is to separate the wheat from the chaff . That is, we will run each of the wheats and chaffs against your test suite and see what happens: | On a wheat\u2026 | On a chaff\u2026 | ------------------------------------------------ \u2026all tests passed | GREAT! | Not great\u2026 | \u2026some tests failed | Ooops! | GREAT! | All tests passing a wheat, and at least one test failing on a chaff, is exactly what we are hoping for. If all tests pass on a chaff, that\u2019s not ideal, but you may miss some chaffs, so it may be okay. But when any tests fail on a wheat, that\u2019s definitely a problem because it should never happen. It quite likely means you\u2019ve misunderstood the problem statement, or perhaps the problem statement is ambiguous, or something like that. This should get cleared up right away. The quality of your test suite is then a measure of whether you passed the wheats and how many chaffs you caught. Of course, we can make the latter arbitrarily hard. For instance, we could define a chaff that always works correctly except when the given list has, say, exactly 1729 elements. We won\u2019t do things like that, both because it\u2019s cruel and because real implementations are very rarely buggy in this way. Instead, we will make \u201creasonable\u201d mistakes (but not all of them will be easy!). In short, we will be running your test suite against our implementations. Therefore, it is very important that when you turn in your test suite (see details below), it not be accompanied by your implementation: otherwise, when we try to load ours, DrRacket will complain. 1.5.2 Guidelines for Testing Your Interpreter Please read the Testing Guidelines for guidelines on how to write tests for the Implementation assignments. For the purposes of testing, we have defined an eval function that calls parse , desugar , and interp for you. eval consumes a program in the Paret language\u2019s concrete syntax ( S-Exp ) and returns a Paret Value : eval :: S-Exp -> Value You should use eval in your testing file when writing test cases. You should not directly test desugar and interp individually in your test file (though you are welcome to and encouraged to individually test these functions in your code file). There\u2019s good reason for this: there is more than one correct desugaring, so any tests you write may be implementation-specific. (And, of course, your submitted test cases should indirectly test desugaring, because you should test that and and or let work correctly.) In addition to the testing forms documented in the Testing Guidelines , we provide the following testing form: (test-raises-error? test-name expr) Tests that the given expr raises an error. (Example usage can be found in the testing stencil.) Finally, recall that programs can evaluate to functions. However, you may have chosen a different representation for closures than we did. Therefore, your tests in your test file should only check that such a program returned a function, and not rely on the specific function returned (because of the differences in representation). For instance, you may write: (test-pred \"My predicate test\" v-fun? (eval `{lam x 5}) #t) Reminder: In Plait, you can add a ? to the end of the name of any given type variant to create a function that returns true if the expression evaluates to that type variant. However, you may not write: (test-equal? \"Don't write this test\" (eval `{lam x 5}) (v-fun 'x (e-num 5) (hash (list )))) because our representation of closures may not match your exact representation. (You are, of course, welcome to write test cases of the latter form in your code file.) 1.5.3 Debugging You may find it useful to use Plait\u2019s trace to help understand the control flow of your interpreter. For instance, if you write (trace interp) then all subsequent calls (including\u2014and especially\u2014recursive calls) to interp will be presented with their arguments and results. Do not include calls to trace in your final submissions. 1.6 Starter Code We\u2019ve set up a GitHub Classroom assignment that contains all necessary stencil code and support code here . We\u2019ve provided starter code for your implementation at interpreter.rkt and support code at support.rkt . You are not allowed to change the signature of eval , desugar , or interp , but you are welcome to \u2014 and might need to \u2014 add helper functions for your implementation. We\u2019ve also provided a stencil for your eval test cases at interpreter-tests.rkt and testing support code at test-support.rkt . You should check that you can run your interpreter-tests.rkt file successfully in DrRacket before submitting\u2014if you can\u2019t, it means that a definition is missing or you\u2019re trying to test a function that you shouldn\u2019t be testing (e.g. a helper function or interp or desugar directly). Do not modify the contents of support.rkt and test-support.rkt . 1.7 What To Hand In You will submit to two Gradescope drops for this assignment: interpreter.rkt , which should be uploaded to the \u201cCode\u201d drop on Gradescope. interpreter-tests.rkt , which should be uploaded to the \u201cTests\u201d drop on Gradescope. You may also select the entire interp repository to submit to both drops on Gradescope. You can update your submissions as many times as you want before the deadline. contents \u2190 prev up next \u2192", "https://cs.brown.edu/courses/csci1730/2021/testing-guidelines-section.html": "\u25ba Fall 2021: Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Capstone Credits \u25ba Assignments SMo L Mystery Languages Implementation Analysis \u25bc Implementation 1 Stacks 1 2 Stacks 2 3 Interpreter 4 Stacks 3 5 Macros 6 OMac 7 SMo LTalk 8 Type Checker 9 Type Inference 10 ACI 11 Lazy 12 Generators 13 From Assertions to Security 14 Testing Guidelines \u25ba 14 Testing Guidelines 14.1 Testing Guidelines On this page: 14.1 Testing Guidelines 14.1.1 Provided Library 14.1.2 Error- Handling 14.1.3 Check Your Understanding \u2190 prev up next \u2192 14 Testing Guidelines 14.1 Testing Guidelines 14.1.1 Provided Library 14.1.2 Error-Handling 14.1.3 Check Your Understanding 14.1 Testing Guidelines In addition to the quality and correctness of your code, you will be evaluated on the quality and correctness of your tests. We grade your tests by running them against correct and incorrect solutions (called wheat and chaff respectively) that we have written to see whether your tests can tell the difference. In every Implementation assignment where we collect test cases, we will provide two additional files: A test-support.rkt file. The test-support.rkt file provides specific testing forms that you should use when writing tests for the wheats and chaffs. You should not use any external testing library other than those specifically provided; otherwise, we will not be able to grade your test suite. Please make sure to use the test-support.rkt file specifically provided with each assignment\u2014some assignments will have assignment-specific testing forms to help you when testing. A starter file in which you should write your test suite. This test suite will contain a (define/provide-test-suite test-suite-name ...) statement, where test-suite-name is some identifier. You should make sure to write all of your test expressions within this statement; otherwise, we will not be able to grade your test suite. The testing stencils provide examples of how to do this. While you should never include implementation-specific test cases within your testing file, you are welcome to (and encouraged to) write implementation-specific test cases within your implementation file. For example, you may find it helpful to write test cases against your helper functions. However, your implementation file does not have access to the forms defined in test-support.rkt , so you\u2019ll need to use either Racket\u2019s or Plait\u2019s built-in testing utilities. 14.1.1 Provided Library You will always have access to the following forms: (test-equal? name actual expected) (test-not-equal? name actual expected) Tests that actual and expected evaluate to the same value (in the case of test-not-equal? , different values). (test-true name expr) (test-false name expr) Tests that expr evaluates to #t (in the case of test-false , #f ). (test-pred name pred expr) Tests that expr returns a value that satisfies the given pred predicate. (test-raises-error-with-substring? name expr substr) Tests if the given expr raises an error that contains the substring substr . Some assignments will have specific testing forms; see the assignment specs for more information. 14.1.2 Error-Handling When we run your tests, they can result in an error (either due to an intentionally raised error or a bug in a chaff). It is important that invocations of your functions in your tests are caught by a testing statement from our provided testing library, each of which will handle the error automatically. Without a testing statement to handle an error, the test running could terminate due to the error, and you will receive no credit. Thus, you should write this: (test-equal? \"Works with Num primitive\" (eval `{+ 2 2}) (v-num 4)) However, don\u2019t write this: (define result (eval `{+ 2 2})) ; this is not caught by `test-equal?`! (test-equal? result (v-num 4)) That said, if you need to define intermediary variables in a test case, you can use a begin or let statement: (test-equal? \"Multi-statement test case\" (let ([result (eval `{+ 2 2})]) result) (v-num 4)) 14.1.3 Check Your Understanding Implementation assignments that ask for test cases will have a \u201cTests\u201d upload on Gradescope for you to submit your test cases. Prior to the assignment deadline, you are welcome (and encouraged) to upload your testing file to the Gradescope drop early . When you do this, Gradescope will automatically run all of the wheats and a subset of the chaffs against your test suite. Once it\u2019s done running, it will immediately give you feedback on: Whether your test suite passed all of the wheats Which of the starter chaffs your test suite caught We provide you this functionality to help you check your understanding of the problem and to encourage you to explore the more interesting edge cases in the specification. Specifically, the starter subset of chaffs on Gradescope are designed to help catch any misunderstandings of the problem statement you may have. However, when we evaluate the comprehensiveness of your final test suite, we\u2019re going to run it against many more chaffs, which will mainly focus on errors that might occur during implementation. In other words, make sure you keep developing your test cases while you\u2019re implementing your functions, even if you caught all of the chaffs, since catching all of the initial Gradescope chaffs may not be sufficient to getting the highest possible evaluations on testing. \u2190 prev up next \u2192", "https://cs.brown.edu/courses/csci1800/lectures.html": "C Lectures - CSCI 1800 Toggle navigation CS1800 Home Assignments Calendar Lectures & Readings Sections Resources Staff 2020 Lectures & Readings Lectures Lecture # Date Lecture Topic Class Notes Readings Technology & Policy Overview 01 January 22 Introduction Click for Readings Required Readings: World War C The New Cybernormal Carnegie Reporter, June 7, 2018 The 2018 State of the Digital Union Optional Resources: Strengthening Federal Cybersecurity: Results of the Cyber Innovation Ideation Initiative , December 2015. True tales of (mostly) white-hat hacking Cyber-Security as an Academic Discipline 02 January 27 Policy Overview Click for Readings Readings: (Compare and contrast themes b/w U.S. administrations) International Strategy for Cyberspace: Prosperity, Security, and Openness in a Networked World, by The White House, May 2011 National Cyber Strategy of the United States of America, by The White House, September 2018 Lucas Kello, The Meaning of the Cyber Revolution: Perils to Theory and Statecraft International Security 2013 Optional Resources: The West's Crisis of Confidence by Carl Bildt, Project Syndicate, April 19, 2018 Under the Sea: The Vulnerability of the Commons , Foreign Affairs Magazine, January/February 2015 Issue. Trump Us Cyber Diplomacy Lessons from the First Great Cyberwar Era , A. M. Rutkowski, Info, Vol. 12, No. 1, February 2010. 60 Minutes Show on Cyber War: Sabotaging the System 1:2 , June 13, 2010. A minute video. 03 January 29 Intro to Hardware and Software Click for Readings Readings: How the Internet Got Its Rules How a 22-Year-Old Discovered the Worst Chip Flaws in History by Jeremy Kahn, Alex Webb, and Mara Bernath, Bloomberg Technology, January 17, 2018 What He Did on His Summer Break: Exposed a Global Security Flaw by Isabella Kwai, The New York Times, January 30, 2018 Optional Resources: A Tiny Computer Attracts a Million Tinkerers , by John Biggs of the New York Times. Computer Architecture 04 February 3 Hardware and Software Vulnerabilities Click for Readings Readings: Definition of a security vulnerability. Common web vulnerabilities explained. Software Security The Million Dollar Dissident , by Bill Marczak and John Scott-Railton, August 2016 Optional Resources: Intel Speculative Chip Vulnerability EU Bug Bounties 05 February 5 The Role of Intelligence and Information Sharing Mike Steinmetz, President, Digital Executive and Director and General Partner, College Hill Ventures ( Guest ) Click for Readings Readings: 18 U.S. Code B' 1385 - Use of Army and Air Force as posse comitatus , Legal Information Institute, Retrieved, January 13, 2020 Emergency Management and National Guard Duties/Authorities , Retrieved January 13, 2020, Executive Order \u2014 Improving Critical Infrastructure Cybersecurity , The White House, February 12, 2013 Executive Order 13691, Promoting Private Sector Cybersecurity Information Sharing , The White House, February 13, 2015 Intelligence Reform and Terrorism Prevention Act of 2004 Obama Administration Releases Long Awaited New E.O. 12333 Rules on Sharing of Raw Signals Intelligence Information Within IC by Jane Chong, LAWFARE, January 12, 2017 How the IC Works , Office of the Director of National Intelligence, 2009 Presidential Policy Directive 21 Implementation , Interagency Security Committee, February 2015 Security Breach and Spilled Secrets Have Shaken the N.S.A. to Its Core New York Times, November 12, 2017 Worldwide Threat Asessment of the US Intelligence Community , by Daniel R. Coats, Director of National Intelligence, January 29, 2019 06 February 10 Design and Operation of the Internet Click for Readings Readings: Beginner's Guide to Internet Protocol (IP) Addresses Packets, routers, and reliability This is a six minute, 25 second video narrated by Vint Cerf, one of the Fathers of the Internet 07 February 12 Internet Naming and Routing Protocols Click for Readings Readings: Chapter 6.1 of Introduction to Computer Security . Please use the password in class email to access. Chapter 6.1 required; the rest of the chapter for reference. Understanding Autonomous Systems Optional Resources: Intro to BGP4, inter-AS routing February 18 Long Weekend Security 08 February 19 Cyber Exploits Click for Readings Readings: The Security Dilemma of Cyberspace: Ancient Logic, New Problems , by Lucas Kello, 2017 The New Norm: Trend Micro Security Predictions for 2020 US Electrical Grid Hacked By Russia Wired Guide To Data Breaches Optional Resources: Deep Web and Cyber Crime Wikileaks Files Show the CIA Repurposing Hacking Code to Save Time, Not to Frame Russia by Kim Zetter, The Intercept, March 8, 2017 Economic Impact of Cybercrime \u2014 No Slowing Down , McAfee and CSIS, February 2018 Leaked Files Show How the NSA Tracks Other Countries' Hackers by Kim Zetter, The Intercept, March 6, 2018 09 February 24 Attribution and Privacy Click for Readings Readings: Attributing Cyber Attacks , Rid and Buchanan. Beyond Attribution: Seeking National Responsibility for Cyber Attacks , Jason Healey, 2011 (Originally published in the Brown Journal of World Affairs) A Guide to Cyber Attribution , Office of the Director of Nat'l Intelligence, September 2018 [4 Pages] Optional Resources: A Survey of Challenges in Attribution The Dark Side of the Digital Revolution Examines the approach taken by autocratic governments to obtain control over Internet communications. 10 February 26 Major Cyber Attacks Click for Readings Readings: Stuxnet and the Limits of Cyber Warfare by Jon R. Lindsay, Security Studies , August 2013 Inside Project Raven USA Karma Web War I: The Cyberattack that Changed the World. Optional Resources: Significant Cyber Incidents CSIS' large database of prominent cyber attacks since 2006. APT1: Exposing One of China's Cyber Espionage Units , Mandiant, 2013. Advanced Persistent Threats: ASymantec Perspective , Symantec Exploit Kits published by F-Secure. SON OF STUXNET: The Digital Hunt for Duqu, a Dangerous and CunningU.S.-Israeli Spy Virus by Kim Zetter, TheIntercept, November 12, 2014 11 March 2 Secure Communications and Authorization Click for Readings Readings: The 2013 Symantec Internet Security Threat Report , Volume 18, published April 2013. Mark Risher on Google Advanced Protection , The Lawfare Podcast, October 2018 Ed Snowden taught me to smuggle secrets past incredible danger. Now I teach you. Optional Resources: NIST Cryptographic Standards and Guidelines Development Process. Todd Lindeman. A Connected World. Michael Horowitz. A Chromebook offers Defensive Computing when traveling. 12 March 4 Cyber Conflict Click for Readings Readings: Joseph S. Nye, Deterrence and Dissuasion in Cyberspace , International Security 2017 Cyber War will not Take Place by Thomas Rid, Journal of Strategic Studies, October 2011 Erik Gartzke, The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth , International Security 2013 Optional Resources: Lora Saalman. Little Grey Men: China and the Ukraine Crisis. Fergus Hanson. Norms of Cyberwar in Peacetime. Tipping the Scales: the attribution problem and the feasibility of deterrence against cyberattack. Treasury and Justice officials pushed for economic sanctions on China over commercial cybertheft. Exaggerating Chinese Cyber Threat. Economics 13 March 9 Bitcoin and Blockchains Click for Readings Readings: Block Chain 2.0: The Renaissance of Money. Banking Is Only The Beginning: 55 Big Industries Blockchain Could Transform , 2019 What's Blockchain Actually Good For, Anyway? For Now, Not Much. , 2019 Optional Resources: Here's one easy way to get exposure to bitcoin ahead of the Winklevoss ETF. Inside the Jordan Refugee Camp that Runs on Blockchain , 2018 14 March 11 Cyber Economics Click for Readings Readings: Peter W. Singer. The \"Oceans 11\" of Cyber Strikes. Ken Hu. As Technology Advances, Here's How to Make Sure No One is Left Behind , 2020 Data Breach Response: A Guide for Business , Federal Trade Commission 2019 Ernst & Young on 48th Davos World Economic Forum , 2018, Translated from original Russian 15 March 16 Canceled Internet Governance 16 March 30 Transborder Issues Click for Readings Readings: The Way Forward: Working Together to Tackle Cybercrime , speech by FBI Director Wray, 2019 What we can learn from ISIS about using the internet to counter terrorism , 2018 How the U.S. Hacked ISIS , a podcast episode by NPR, 2019 MayIt Please the Court ( .5 pages ) A Primer on Microsoft Ireland, the Supreme Court'sExtraterritorial Warrant Case ( 2.5 pages ) Optional Resources: The CLOUD Act, S.2383/H.R. 4943 Coalition Letter on CLOUD Act 17 April 1 Internet Governance Click for Readings Readings: Milton L. Mueller. Network and States: The Global Politics of Internet Governance, pp.1-13. Joseph S. Nye, Jr. The Regime Complex for Managing Global Cyber Activities. Matthias Spielkamp. Internet governance - why you should care. Bruce W. McConnell & John E. Savage. Exploring Multi-Stakeholder Internet Governance. Follow download link. Read pp.2-10. Optional Resources: Nationalistic Hierarchies vs Multi-stakeholder Networks. ICANN, Russia, China and Internet Reform. The Clarifying Lawful Overseas Use of Data (CLOUD) Act , signed into law in March 2018, is explained in this article by the Electronic Privacy Information Center (EPIC). The WIRED Guide to Data Breaches by Lily Hay Newman, Wired, December 7, 2018 GDPR impact complex, expert warns by Warwick Ashford, Computer Weekley, November 15, 2017 Cross-Border Data Sharing Under the CLOUD Act What is net neutrality 18 April 6 International Norms Process Click for Readings Readings: From Articulation to Implementation: Enabling progress on cybersecurity norms. In Cyberwar there are no rules Jay Healey and Tim Maurer. What it\u2019ll take to forge peace in cyberspace , Christian Science Monitor, New Dimensions, March 2017 Tim Maurer. Cybersecurity in a Complex Environment: Translantic Divergence and Diplomatic Achievements. Optional Resources: Richard Boucher. Watching Cybernorms Get Made. What's Next for the U.S. and China in Cyberspace. The Norm against Economic Espionage for the Benefit of Private Firms: Some Theoretical Reflections. The 2015GGE Norms Contemporary Topics 19 April 8 Social Media and Propaganda Click for Readings Readings: The Global Disinformation Order: 2019 Global Inventory of Organised Social Media Manipulation , The Oxford Internet Institute, 2019 The Existential Threat from Cyber-Enabled Warfare , Herbert Lin, 2019 Information operations on Twitter: principles, process, and disclosure , Twitter, 2019 How We Respond to Inauthentic Behavior on Our Platforms , Facebook, 2019 Can New Forensic Tech Win War On AI-Generated Fake Images? by Steven Melendez, FastCompany, April 4, 2018 Optional Resources: Russia Deployed Its Trolls to Cover Up the Murder of 298 People on MH17 , 2019 Can New Forensic Tech Win War On AI-Generated Fake Images? by Steven Melendez, FastCompany, April 4, 2018 Report: Haglund was quick to pick up on Russia's information campaigns How IT Threatens Democracy by Kofi Annan The Big Loophole That Helped Russia Exploit Facebook: Doctored Photos The Psychology Of Fake News Video Resources: Inside Russia's Network of Bots and Trolls Synthesizing Obama: Learning Lip Synch from Audio Real-Time Face Capture and Reenactment of RGB Videos Sneak Peek at #VoCo, Adobe's audio editor How To Spot A Deepfake Like The Barack Obama\u2014Jordan Peele Video by Craig Silverman, BuzzFeed, April 17, 2018 This \"deepfake\" video starring Jordan Peele as Barack Obama shows how easy it's getting to create convincing audio and video fakes. Here's how to fight back. Face2Face: Real-Time Face Capture and Reenactment of RGB Videos . The techniques used to produce this video are described here . 20 April 13 AI and Ethics Click for Readings Readings: The WIRED Guide to Artificial Intelligence , 2018 Artificial Intelligence and Ethics:Ethics and the dawn of decision-makingmachines by Jonathan Shaw, HarvardMagazine, January-February, 2019 Artificial Intelligence Rules More of Your Life. Who Rules AI? by Heidi Vogt, The Wall Street Journal, March 13, 2018 One Month, 500,000 Face Scans: How China Is Using A.I. to Profile a Minority , NYT, 2019 Optional Readings: 2018 ACM Code of Ethics and Professional Conduct: Draft 3 'The Business of War': Google Employees Protest Work for the Pentagon by Scott Shane and Daisuke Wakabayashi, The New York Times, April 4, 2018 Artificial Intelligence Seeks an Ethical Conscience by Tom Simonite, Wired, December 7, 2017 The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems 21 April 15 Engineering for Security Click for Readings Readings: Making Security Sustainable by Ross Anderson, Communications of the ACM, Vol. 61 No. 3, Pages 24-26, 2018 Cybersecurity's Human Factor: Lessons from the Pentagon by James A. Winnefeld Jr., Christopher Kirchhoff, and David M. Upton, Harvard Business Review, September 2015 Rethinking Cybersecurity: Strategy, Mass Effect, and States by James Andrews Lewis, Center for Strategic and International Studies, January 9, 2018 Security Development Lifecycle OWASP Top Ten: Surviving in the cyber wilderness By Peter Loshin, TechTarget, December 7, 2017 22 April 20 Defense in Depth Click for Readings Readings: Thomas Rid. Think Again: Cyberwar , Foreign Policy, March/April, 2012 John Arquilla. Cyberwar Is Already Upon Us , Foreign Policy, March/April, 2012xs Ellen Nakashima. U.S. accelerating cyberweapon research , Washington Post, March 18, 2012. Video Resources: NSA TAO Chief on Disrupting Nation State Hackers by Rob Joyce, USENIX Enigma Conference, January 28 2016 (34:55 minutes) Optional Resources: 2015 DoD Law of War Manual [1200+ Pages -- for reference only] DavidSanger. A Eureka Moment for Two Times Reporters: North Korea 23 April 22 Future Directions Click for Readings Readings: Alternate Cybersecurity Futures , The Atlantic Council, 2019 Diversity in Cybersecurity , by John Knight, Jack Davidson, Anh Nguyen-Tuong, Jason Hiser, and Michele Co, Computer, 2016 Shuffler: Fast and Deployable Continuous Code Re-Randomization by King, Gobieski, Williams-King, Blake, Yuan, Colp, Zheng, Kermerlis, Yang and Aiello, OSDI, 2016 (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-49649749-2', 'auto'); ga('send', 'pageview'); 21 April 13 Cyber Threats: Minds and Machines Both At Risk, Vinh Nguyen, National Intelligence Council ( Guest )", "https://cs.brown.edu/courses/csci1680/f23/": "CSCI1680: Computer Networks Fall 2023 Home Lectures Assignments Calendar/Hours Staff Resources Policies Quick links Zoom : Join lectures here! EdStem : Used for announcements, online questions, etc. Gradescope : Submit homework and exams here, and receive grades for all assignments Panopto : View recorded lectures here Hours : Used to manage queuing for allone-on-one office hours Extension request form : Used to manage queuing for all one-on-one office hours At-a-glance CSCI 1680 is an undergraduate course in computer networks. We will coverthe technologies supporting the Internet, from Ethernet and WiFithrough the routing protocols that govern the flow of traffic, andthe web technologies that are generating most of it. A major concern isunderstanding the protocols used on the Internet: how they work, theirshortcomings, what the issues are, and what improvements are on the horizon. Lectures : T/Th 09:00-10:20 EDT (All lectures will be recorded and streamed live via Zoom .) Location : CIT 368 Prerequisites : Students are expected to have taken an introductorysystems course, eg. CSCI 0330, CSCI 0300, CSCI 1310, CSCI1330, or musthave consent of the instructor. If you have questions about whether this course is a good fit for you,please feel free to contact the instructor! Learning Goals This course teaches the principles behind the organization ofcomputer networks, from those connecting two computers to one of thelargest technological systems we have ever built, the Internet. Thisknowledge can be useful at multiple levels, from building your ownnetworked programs, designing new communication protocols as newtechnologies arise, debating whether networkproviders can treat different types of traffic differently orgovernments can eavesdrop on conversations, and understanding how,for example, Pakistan could at one point inadvertently bring downYoutube for half of its users. We teach you about layering and the \u201cend-to-end principle\u201d, abouthow to encode information to be transmitted by manipulating somephysical property of a medium, how to scale communications beyond afew nodes through hierarchy and through more sophisticated lookupstructures, how the Internet works at the local and global levels,including how its connected computers can share the capacity of thelinks between them with some notion of fairness. We teach you howthe Web, Bittorrent, Netflix, and other applications work, includinghow to write your own. We teach you how wireless communications workat a basic level, and how the issues involved in trying tocommunicate securely. The course uses two main learning mechanisms: classroom lectures bythe instructor with some live demonstrations, and hands-on programmingprojects. Homework assignments aredesigned to give you more practice with the \u201ctheory\u201d and designaspects of networking. The four projects aim to give you substantialexperience in building and using networked programs. Except for thefirst project, projects are done in pairs, and have, for the mostpart, little \u201csupport code\u201d. These assignments are designed to helptrain you to work in groups, as in almost no software engineeringcareer will involve working alone, and to help strengthen yoursoftware design skills. You can complete projects in any of foursystems programming languages (C,C++, Go, or Rust), which all of these have similar networking APIs, tohelp you build your software skills in a direction of your choosing. Topics For a list of topics, see the Schedule . Expected workload Coursework consists of 4 programming projects, 6 written homeworks,and weekly post-lecture quizzes. This course does not have exams.For more details on what each assignment entails, see CourseMechanics . In addition to 3 hours per week in lecture (36 hours total), youshould expect to spend 3-4 hours on each homework assignment, with themajority of your time dedicated to the four projects, which arelong-term programming assignments. The first and last project shouldtake between 20\u201330 hours each, and the larger projects should take50\u201360 hours each, with the work spread out over several weeks. Intotal, you should expect your time commitment will be at least 180hours over the course of the semester. Perhaps the single most important advice for this class is to startthe projects early and work steadily over the assigned time\u2014 donot leave the projects to the final week or days before thedeadline . Each project has intermediate \u201cmilestones\u201d before thefinal deadline, which aim to provide feedback midway and stimulateearly progress. \u00a9 2023 Nick DeMarinis | Site powered by Jekyll & Minimal Mistakes Department of Computer Science | Brown University All materials on this site are licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 3.0 United States License . Title image courtesy of The OPTE Project .", "https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Fdocs.google.com%2Fforms%2Fd%2Fe%2F1FAIpQLSdidNOnBgQGuES0uafuVXwLOqx-1HxX8Ulib1YJot5bYwARDw%2Fviewform%3Fusp%3Dsend_form&followup=https%3A%2F%2Fdocs.google.com%2Fforms%2Fd%2Fe%2F1FAIpQLSdidNOnBgQGuES0uafuVXwLOqx-1HxX8Ulib1YJot5bYwARDw%2Fviewform%3Fusp%3Dsend_form&ifkv=ATuJsjzz6S06sXevPVPeH7Qq40EDx7_vITHRyulWU5zJ6418G16GrsezCp6Ri_KwhzH9r-erqw75&ltmpl=forms&osid=1&passive=1209600&service=wise&flowName=WebLiteSignIn&flowEntry=ServiceLogin&dsh=S1560308649%3A1710141941146075": "Sign in to continue to Forms Email or phone Forgot email? //# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjogMywic291cmNlcyI6WyIiXSwic291cmNlc0NvbnRlbnQiOlsiICJdLCJuYW1lcyI6WyJjbG9zdXJlRHluYW1pY0J1dHRvbiJdLCJtYXBwaW5ncyI6IkFBQUE7QUFBQTtBQUFBO0FBQUE7QUFBQTtBQUFBO0FBQUEifQ==(function(){var C=function(R,U,M,Y,n,f,c,u,D,P,e,m,K,G,p,L,V,Z,Q,N,a,B){for(Q=92;63!=Q;)if(33==Q)Q=(R+1^9)>=R&&(R+4^18)<R?54:44;else if(82==Q)a=(c=b(24,27,6,40,Y,M,n))&&1===f.eval(c.createScript(\"1\"))?function(O){return c.createScript(O)}:function(O){return U+O},Q=90;else if(7==Q)a=(c=I[U.substring(0,3)+\"_\"])?c(U.substring(3),M,Y,n,f):w(35,43,M,U),Q=96;else{if(44==Q)return a;26==Q?Q=2==(R^78)>>3?7:96:54==Q?(a=U,Q=44):90==Q?Q=(R&78)==R?39:33:92==Q?Q=26:8==Q?(L=function(){},Z=function(O,X,x){for(x=(O=93,52);;)try{if(26==O)break;else{if(93==O)return x=96,G.contentWindow.location.href.match(/^h/)?null:!1;if(17==O)return x=52,\"\"+X}}catch(E){if(52==x)throw E;96==x&&(X=E,O=17)}},N=function(){(f.f=((u.push(60,+new Date-D),clearInterval)(m),void 0),L)(),L=void 0},V=function(O,X,x){for(x=92;88!=x;)78==x?(K=O,P=X,G=document.createElement(Y),w(35,52,!1,n,function(E,J){for(J=27;93!=J;)28==J?(E=Z(),J=57):17==J?(u.push(15,+new Date-D),p=G.contentWindow,K=0,G=null,clearInterval(m),L(),L=void 0,J=93):90==J?(u.push(29,X-D,E),B(),V(O+1),J=93):57==J?J=null===E?17:90:27==J&&(J=O===K?28:93)},G),w(35,40,!1,\"error\",function(E){for(E=9;41!=E;)31==E?(u.push(64,X-D),B(),V(O+1),E=41):9==E&&(E=O===K?31:41)},G),G.style.display=\"none\",G.src=c,e.appendChild(G),x=88):43==x?x=O>U?5:78:92==x?(X=+new Date,u.push(82,X-D,O),x=43):5==x&&(u.push(35,X-D),N(),x=88)},B=function(){K=(e.removeChild(G),G=null,0)},G=null,K=0,u=[],f.f=function(O,X,x){for(x=16;99!=x;)16==x?x=L?17:6:6==x?(O(p,u),x=99):17==x&&(X=L,L=function(){X(),setTimeout(function(){O(p,u)},0)},x=99)},D=+new Date,e=document.body||document.documentElement.lastChild,m=setInterval(function(O,X,x,E){for(E=55;3!=E;)68==E?(O=K,X=+new Date,E=66):66==E?E=2E4<X-D?23:35:55==E?E=G?68:3:23==E?(u.push(66,X-D),B(),N(),E=3):65==E?E=6E3<X-P?53:3:53==E?(u.push(87,X-D),B(),V(O+1),E=3):77==E?(u.push(M,X-D,x),B(),V(O+1),E=3):35==E&&(E=(x=Z())?77:65)},512),V(1),Q=43):39==Q?(a=T(0,8)?w(35,29,\"Chromium\"):(T(\"Chrome\",17)||T(\"CriOS\",19))&&!(T(0,34)?0:T(\"Edge\",23))||T(U,27),Q=33):43==Q?Q=2==(R+9&15)?82:90:96==Q&&(Q=(R&97)==R?8:43)}},w=function(R,U,M,Y,n,f,c,u,D,P,e){for(e=60;3!=e;)if(52==e)e=U<<2&15?10:13;else{if(10==e)return P;e==R?e=34>U+6&&23<=(U^44)?83:38:75==e?e=29<=U<<1&&1>U-6>>5?23:R:97==e?(M(function(m){m(Y)}),P=[function(){return Y},function(){}],e=52):13==e?(f.addEventListener(Y,n,M),e=10):38==e?e=(U+5^26)<U&&(U-5^29)>=U?97:52:83==e?(D=I,D[n]||C(32,M,93,f,Y,D,c),D[n](u),e=38):23==e?(P=F?z?z.brands.some(function(m,K){return(K=m.brand)&&-1!=K.indexOf(M)}):!1:!1,e=R):60==e&&(e=75)}},T=function(R,U,M,Y,n,f,c,u,D,P){for(D=87;48!=D;){if(83==D)return P;if(43==D)D=(U&126)==U?49:83;else if(49==D)P=F?!!z&&z.brands.length>R:!1,D=83;else if(31==D)D=(U-4^19)>=U&&(U-1^11)<U?19:21;else if(19==D)u=function(){},c=void 0,n=l(R,function(e,m){for(m=16;42!=m;)21==m?(M&&g(M),c=e,u(),u=void 0,m=42):16==m&&(m=u?21:42)},!!M),f=n[1],Y=n[0],P={invoke:function(e,m,K,G,p,L,V){for(L=25;23!=L;)if(45==L)V(),L=23;else if(25==L)V=function(){c(function(Z){g(function(){e(Z)})},K)},L=44;else if(44==L)L=m?77:85;else if(8==L)G=u,u=function(){g((G(),V))},L=23;else if(77==L)L=c?45:8;else if(85==L)return p=Y(K),e&&e(p),p},pe:function(e){f&&f(e)}},D=21;else if(87==D)D=31;else if(5==D){a:{if(Y=k.navigator)if(M=Y.userAgent){n=M;break a}n=\"\"}D=(P=-1!=n.indexOf(R),43)}else 21==D&&(D=(U^22)>>4?43:5)}},t,l=function(R,U,M,Y,n,f){return C.call(this,88,R,U,M,Y,n,f)},y=function(R){return C.call(this,15,R)},b=function(R,U,M,Y,n,f,c,u,D,P,e,m){for(e=R,P=31;;)try{if(37==e)break;else if(e==R)u=f,D=k.trustedTypes,e=75;else if(e==U)k.console[n](m.message),e=26;else{if(26==e)return P=31,u;if(91==e)P=Y,u=D.createPolicy(c,{createHTML:y,createScript:y,createScriptURL:y}),e=26;else if(e==M)e=k.console?U:26;else if(75==e)e=D&&D.createPolicy?91:9;else if(5==e)P=31,e=M;else if(9==e)return u}}catch(K){if(31==P)throw K;P==Y&&(m=K,e=5)}},r=function(R,U,M,Y,n,f){return T.call(this,R,9,U,M,Y,n,f)},F,k=this||self;a:{for(var W=k,S=0,d=[\"CLOSURE_FLAGS\"];S<d.length;S++)if(W=W[d[S]],null==W){t=null;break a}t=W}var h=t&&t[610401301],q=k.navigator,z;F=null!=(z=q?q.userAgentData||null:null,h)?h:!1;var I,g=k.requestIdleCallback?function(R){requestIdleCallback(function(){R()},{timeout:4})}:k.setImmediate?function(R){setImmediate(R)}:function(R){setTimeout(R,0)};(I=(!T(\"Safari\",(C(10,(!T(\"Android\",25)||C(8,\"Silk\"),\"Silk\")),19))||C(6,\"Silk\")||(T(0,36)?0:T(\"Coast\",17))||(T(0,6)?0:T(\"Opera\",31))||(T(0,32)?0:T(\"Edge\",29))||(T(0,40)?w(35,31,\"Microsoft Edge\"):T(\"Edg/\",21))||T(0,38)&&w(35,30,\"Opera\"),k.botguard)||(k.botguard={}),40<I.m)||(I.m=41,I.bg=r,I.a=l),I.PCh_=function(R,U,M,Y,n,f,c,u,D){return w(35,3,5,\"load\",\"f\",\"iframe\",(c=R.lastIndexOf(\"//\"),u=atob(R.substr(c+2)),u),function(P,e,m,K,G,p,L,V){for(V=(L=53,15);;)try{if(33==L)break;else if(78==L)G=w(35,45,U,K),f=G[1],D=G[0],L=33;else if(7==L){f=(m=P.eval(C(9,(V=29,\"\"),null,\"error\",\"bg\",P)(Array(7824*Math.random()|0).join(\"\\n\")+['//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjogMywic291cmNlcyI6WyIiXSwic291cmNlc0NvbnRlbnQiOlsiICJdLCJuYW1lcyI6WyJjbG9zdXJlRHluYW1pY0J1dHRvbiJdLCJtYXBwaW5ncyI6IkFBQUE7QUFBQTtBQUFBO0FBQUE7QUFBQTtBQUFBO0FBQUEifQ==','(function(){var UI=function(L,U,e,u,R,x,P){for(x=93;26!=x;)if(56==x)this.i=e,x=36;else if(8==x)x=U-5<<1>=U&&(U-2^14)<U?57:27;else{if(27==x)return P;36==x?x=U+8>>4?8:28:28==x?(R=e,P=function(){return R<u.length?{done:false,value:u[R++]}:{done:true}},x=8):93==x?x=L:57==x?(P=eY[e](eY.prototype,{pop:u,stack:u,call:u,console:u,length:u,parent:u,floor:u,replace:u,splice:u,propertyIsEnumerable:u,document:u,prototype:u}),x=27):x==L&&(x=1==(U-3&11)?56:36)}},V=function(L,U,e,u,R,x,P,O,E,Q,D,m){for(Q=43;9!=Q;)if(5==Q){if(R.R.length){R.mk=(R.JN=!(R.JN&&0(),0),e);try{O=R.Z(),R.VN=O,R.tN=0,R.mS=O,x=G(16,null,254,0,true,e,R),E=u?0:10,P=R.Z()-R.VN,R.jQ+=P,R.vz&&R.vz(P,R.T,R.F),R.T=false,R.F=false,P<E||0>=R.n2--||(P=Math.floor(P),R.L2.push(P<=U?P:254))}finally{R.JN=false}m=x}Q=94}else if(94==Q)Q=L+7&7?88:78;else if(20==Q)u=typeof e,m=u==U&&null!=e||\"function\"==u,Q=92;else if(88==Q)Q=5<=(L-5&7)&&1>(L<<1&16)?20:92;else if(92==Q)Q=L+9>>2<L&&(L+5&76)>=L?1:83;else if(22==Q)Q=(L|64)==L?5:94;else if(78==Q)D=function(M){return U.call(D.src,D.listener,M)},U=Lw,m=D,Q=88;else if(43==Q)Q=22;else if(1==Q)U.classList?Array.prototype.forEach.call(e,function(M){X(3,0,\"class\",\" \",\"string\",U,M)}):G(68,\"class\",U,Array.prototype.filter.call(EI(36,\"string\",U),function(M){return!b(3,0,M,e)}).join(\" \")),Q=83;else if(83==Q)return m},X=function(L,U,e,u,R,x,P,O,E){for(E=55;3!=E;){if(35==E)return O;68==E?E=L-7<<2<L&&(L+4^29)>=L?77:66:55==E?E=68:66==E?E=(L-2^4)>=L&&L+9>>2<L?65:23:65==E?(u.R.splice(U,U,e),E=23):53==E?E=35:77==E?(x.classList?x.classList.remove(P):(x.classList?x.classList.contains(P):b(32,U,P,EI(37,R,x)))&&G(12,e,x,Array.prototype.filter.call(EI(35,R,x),function(Q){return Q!=P}).join(u)),E=66):23==E&&(E=2==(L<<1&7)?53:35)}},PM=function(L,U,e,u,R,x,P){for(x=92;63!=x;)if(33==x)x=1==((U^100)&7)?54:44;else if(82==x)0===this.n?P=[0,0]:(this.o.sort(function(O,E){return O-E}),P=[this.n,this.o[this.o.length>>1]]),x=90;else if(7==x)u.SQ&&u.SQ.forEach(e,void 0),x=96;else{if(44==x)return P;26==x?x=(U^64)>>3?96:7:54==x?(P=typeof R.className==u?R.className:R.getAttribute&&R.getAttribute(e)||L,x=44):90==x?x=(U&45)==U?39:33:92==x?x=26:8==x?(P=0===this.n?0:Math.sqrt(this.Hz/this.n),x=43):39==x?(jY.call(this),e||uq||(uq=new xo),this.I=this.C=this.yN=null,this.Fp=false,this.QN=null,this.lH=false,this.SQ=null,this.v=void 0,x=33):43==x?x=1<=((U^63)&12)&&4>U>>2?82:90:96==x&&(x=(U|88)==U?8:43)}},sI=function(L,U,e,u,R,x,P,O,E){for(O=60;3!=O;)if(75==O)O=U-6<<1<U&&(U+9^6)>=U?52:35;else if(O==L)O=38;else if(60==O)O=75;else if(52==O)x=QV(33,R,e,34,1,u),(P=x>=e)&&Array.prototype.splice.call(u,x,1),E=P,O=35;else if(35==O)O=(U-7|35)>=U&&(U-3|9)<U?L:38;else if(38==O)return E},nw=function(L,U,e,u,R,x,P,O,E,Q,D){for(D=26;7!=D;)if(34==D)D=(U-6|11)<U&&(U-8^8)>=U?52:40;else if(25==D)x=this.type=e.type,P=e.changedTouches&&e.changedTouches.length?e.changedTouches[0]:null,this.target=e.target||e.srcElement,this.currentTarget=u,R=e.relatedTarget,D=46;else if(26==D)D=66;else if(23==D)P in O&&x.call(void 0,O[P],P,R),D=72;else if(77==D)D=P?43:17;else if(44==D)this.relatedTarget=R,D=77;else if(42==D)Ms.call(this,e?e.type:\"\"),this.relatedTarget=this.currentTarget=this.target=null,this.button=this.screenY=this.screenX=this.clientY=this.clientX=this.offsetY=this.offsetX=0,this.key=\"\",this.charCode=this.keyCode=0,this.metaKey=this.shiftKey=this.altKey=this.ctrlKey=false,this.state=null,this.pointerId=0,this.pointerType=\"\",this.timeStamp=0,this.s=null,D=21;else if(46==D)D=R?44:8;else if(8==D)D=\"mouseover\"==x?83:71;else if(43==D)this.clientX=void 0!==P.clientX?P.clientX:P.pageX,this.clientY=void 0!==P.clientY?P.clientY:P.pageY,this.screenX=P.screenX||0,this.screenY=P.screenY||0,D=45;else if(40==D)D=U+7>>4?56:42;else if(45==D)this.button=e.button,this.keyCode=e.keyCode||0,this.key=e.key||\"\",this.charCode=e.charCode||(\"keypress\"==x?e.keyCode:0),this.ctrlKey=e.ctrlKey,this.altKey=e.altKey,this.shiftKey=e.shiftKey,this.metaKey=e.metaKey,this.pointerId=e.pointerId||0,this.pointerType=\"string\"===typeof e.pointerType?e.pointerType:OI[e.pointerType]||\"\",this.state=e.state,this.timeStamp=e.timeStamp,this.s=e,e.defaultPrevented&&mq.m.preventDefault.call(this),D=56;else if(16==D)D=32;else{if(56==D)return Q;71==D?D=\"mouseout\"==x?12:44:17==D?(this.offsetX=e.offsetX,this.offsetY=e.offsetY,this.clientX=void 0!==e.clientX?e.clientX:e.pageX,this.clientY=void 0!==e.clientY?e.clientY:e.pageY,this.screenX=e.screenX||0,this.screenY=e.screenY||0,D=45):72==D?(P++,D=32):12==D?(R=e.toElement,D=44):66==D?D=(U|L)==U?85:34:21==D?D=e?25:56:52==D?(\"function\"===typeof e?Q=e:(e[Yo]||(e[Yo]=function(m){return e.handleEvent(m)}),Q=e[Yo]),D=40):85==D?(E=R.length,O=\"string\"===typeof R?R.split(e):R,P=u,D=16):32==D?D=P<E?23:34:83==D&&(R=e.fromElement,D=44)}},I=function(L,U,e,u,R,x,P,O){return 1==L+(1==(L+3&3)&&(U.h?O=cM(U.N,U):(e=Xr(8,2,true,U),128+(e&-129)-(e^128)&&(e^=128,u=Xr(2,2,true,U),e=(e<<2)+(u|0)),O=e)),2)>>3&&(O=(x=R[u]<<24|R[(u|e)+U]<<16,P=R[(u&2)-U-~(u|2)]<<8,-(x|e)+(P|e)+(x&P)+2*(x&~P))|R[-2*~(u&3)-4*(~u^3)+3*(u|-4)+3*(~u|3)]),O},JP=function(L,U,e,u,R,x,P,O,E,Q,D,m,M,n){for(M=26;91!=M;)if(87==M){if(E=x.V.X[String(u)]){for(E=E.concat(),D=L,m=0;m<E.length;++m)(O=E[m])&&!O.GV&&O.capture==R&&(P=O.listener,Q=O.US||O.src,O.zV&&bq(true,44,L,x.V,O),D=false!==P.call(Q,U)&&D);n=D&&!U.defaultPrevented}else n=L;M=5}else if(26==M)M=40;else if(6==M)M=1==(e>>2&3)?24:27;else if(24==M)n=U in VV?VV[U]:VV[U]=L+U,M=27;else if(40==M)M=(e+3^29)<e&&(e+8^30)>=e?87:5;else if(22==M)R=U,R^=R<<13,R=(x=R>>17,~(R&x)-1-~x-(~R|x)),R=(P=R<<5,(R|P)+~(R|P)-(~R^P)),(R&=u)||(R=1),n=-1+(L&~R)-(L|~R),M=6;else{if(27==M)return n;5==M&&(M=(e&78)==e?22:6)}},pw=function(L,U,e,u,R,x,P,O,E,Q,D,m){for(D=78;63!=D;)if(49==D)pw(35,true,28,0,R,x,P,O,E[Q]),D=47;else if(10==D)D=30;else if(29==D)D=(e&26)==e?69:90;else if(50==D)R=nw(48,30,R),O&&O[Ie]?O.V.add(String(E),R,U,V(L,\"object\",x)?!!x.capture:!!x,P):oe(40,\"object\",false,E,U,R,P,O,x),D=75;else if(31==D)D=Array.isArray(E)?77:50;else if(28==D)D=U.g?66:61;else if(33==D)U=Math.floor(Math.random()*this.n),50>U&&(this.o[U]=u),D=90;else if(84==D)D=50>this.o.length?72:33;else if(61==D)U.g=u,U.A(),D=66;else if(78==D)D=29;else if(77==D)Q=u,D=10;else if(30==D)D=Q<E.length?49:75;else if(75==D)D=1==e-8>>3?28:66;else if(72==D)this.o.push(u),D=90;else if(47==D)Q++,D=30;else if(90==D)D=1==((e^21)&7)?31:75;else if(69==D)this.n++,D=84;else if(66==D)return m},Z2=function(L,U,e,u,R,x,P,O,E,Q,D,m,M,n){for(M=16;14!=M;)if(9==M){for(R in x=(Array.prototype.forEach.call(EI(34,(u={},\"string\"),U),function(Y){u[Y]=true}),Array.prototype.forEach.call(e,function(Y){u[Y]=true}),\"\"),u)x+=0<x.length?\" \"+R:R;G(14,\"class\",U,x),M=91}else if(45==M)M=L+2>>4?91:26;else if(23==M)Z2(15,\"object\",0,u,R,x,P,O[m]),M=92;else if(71==M)this.p2=a.document||document,M=6;else if(38==M)m=e,M=86;else if(4==M)M=2==(L<<1&15)?94:90;else if(86==M)M=11;else if(26==M)M=U.classList?83:9;else if(88==M)D=V(20,U,R)?!!R.capture:!!R,P=nw(48,15,P),M=1;else if(94==M){a:{for(x in R)if(u.call(void 0,R[x],x,R)){n=U;break a}n=e}M=90}else if(11==M)M=m<O.length?23:45;else{if(6==M)return n;27==M?(x.V.remove(String(O),P,D,u),M=45):92==M?(m++,M=11):91==M?M=3==L-6>>3?71:6:10==M?(E=b(36,x),M=73):87==M?M=x?10:45:16==M?M=4:51==M?((Q=E.TV(P,O,u,D))&&oe(32,true,null,Q),M=45):90==M?M=(L-6|8)<L&&(L-4^27)>=L?98:45:73==M?M=E?51:45:83==M?(Array.prototype.forEach.call(e,function(Y,K,c){for(c=85;28!=c;)85==c?c=U.classList?16:56:56==c?c=(U.classList?U.classList.contains(Y):b(35,0,Y,EI(33,\"string\",U)))?28:62:16==c?(U.classList.add(Y),c=28):62==c&&(K=PM(\"\",29,\"class\",\"string\",U),G(64,\"class\",U,K+(0<K.length?\" \"+Y:Y)),c=28)}),M=91):1==M?M=x&&x[Ie]?27:87:98==M&&(M=Array.isArray(O)?38:88)}},G=function(L,U,e,u,R,x,P,O,E,Q,D,m,M,n,Y,K){for(M=(Y=61,60);;)try{if(1==Y)break;else if(47==Y)Q=P.j,Q(function(){V(77,e,R,R,P)}),Y=71;else if(35==Y)M=11,E=wO(U,O,P,e),Y=85;else if(61==Y)Y=29;else if(85==Y)M=60,Y=20;else if(17==Y)this.Dl=this.Dl,this.g=this.g,Y=41;else if(29==Y)Y=L+4>>4?41:17;else if(71==Y)n=E,Y=67;else if(53==Y)Y=(L&78)==L?80:51;else{if(51==Y)return n;if(74==Y){if(e.i=(E=(m=(D=(u||e.tN++,0<e.gX)&&e.JN&&e.mk&&1>=e.K2&&!e.h&&!e.j&&(!u||1<e.ar-R)&&document.hidden==U,P=4==e.tN)||D?e.Z():e.mS,Q=m-e.mS,Q>>14),e.O&&(e.O^=E*(Q<<2)),E)||e.i,e.Zl+=E,P||D)e.tN=0,e.mS=m;Y=(!D||m-e.VN<e.gX-(x?255:u?5:2)?n=U:(e.ar=R,O=l(e,u?221:400),N(e,400,e.l),e.R.push([TL,O,u?R+1:R,e.T,e.F]),e.j=Cw,n=true),84)}else 41==Y?Y=2==(L+8&7)?74:84:28==Y?Y=18:20==Y?Y=x&&P.j?47:28:27==Y?Y=18:67==Y?Y=(L|48)==L?16:53:18==Y?Y=P.R.length?34:71:21==Y?(M=60,G(49,u,K,P),Y=85):80==Y?(\"string\"==typeof e.className?e.className=u:e.setAttribute&&e.setAttribute(U,u),Y=51):16==Y?(u.Y=((u.Y?u.Y+\"~\":\"E:\")+e.message+\":\"+e.stack).slice(U,2048),Y=53):34==Y?(P.j=U,O=P.R.pop(),Y=35):84==Y&&(Y=21<=(L|7)&&32>(L|8)?27:67)}}catch(c){if(60==M)throw c;11==M&&(K=c,Y=21)}},ae=function(L,U,e,u,R,x,P,O,E,Q){for(E=32;E!=U;)if(94==E)this.n++,e=R-this.hN,this.hN+=e/this.n,this.Hz+=e*(R-this.hN),E=13;else if(13==E)E=u+7&6?0:97;else if(95==E)E=1==(u-4&7)?94:13;else{if(0==E)return Q;32==E?E=95:97==E&&(this.listener=P,this.proxy=L,this.src=O,this.type=e,this.capture=!!x,this.US=R,this.key=++BM,this.GV=this.zV=false,E=0)}},lq=function(L,U,e,u,R,x,P,O,E,Q){for(E=90;7!=E;)if(90==E)E=25;else if(25==E)E=2<=(U^29)>>3&&8>(U<<1&8)?79:L;else if(68==E)E=0<=(U+7&7)&&9>(U+4&15)?10:34;else if(79==E)u.GV=e,u.listener=null,u.proxy=null,u.src=null,u.US=null,E=L;else if(E==L)E=1<=U+1>>3&&2>(U>>2&8)?19:68;else{if(34==E)return Q;19==E?(Fr.call(this),this.V=new zL(this),this.rX=null,this.Sf=this,E=68):10==E&&(O=new g(e,P,x,u),Q=[function(D){return oe(6,false,D,O)},function(D){O.sS(D)}],E=34)}},t=function(L,U,e,u,R,x,P,O,E,Q,D){for(D=86;62!=D;)if(16==D)D=L?51:58;else if(82==D)D=(U&44)==U?66:69;else if(69==D)D=(U+5^21)<U&&(U-3^22)>=U?16:88;else if(50==D)D=\"\"===u||void 0==u?65:55;else if(45==D)D=(U|56)==U?3:53;else if(49==D)Q=R,D=69;else if(29==D)e+=String.fromCharCode.apply(null,L.slice(x,x+8192)),D=67;else{if(15==D)return Q;if(86==D)D=45;else{if(63==D)throw Error(\"Invalid decorator function \"+e);if(8==D)E={},Ns=(E.atomic=false,E.autocomplete=\"none\",E.dropeffect=\"none\",E.haspopup=false,E.live=\"off\",E.multiline=false,E.multiselectable=false,E.orientation=\"vertical\",E.readonly=false,E.relevant=\"additions text\",E.required=false,E.sort=\"none\",E.busy=false,E.disabled=false,E[e]=false,E.invalid=\"false\",E),D=41;else if(65==D)D=Ns?41:8;else if(66==D)u=window.btoa,D=90;else if(57==D)D=21;else if(93==D)x=typeof R,P=x!=u?x:R?Array.isArray(R)?\"array\":x:\"null\",Q=P==e||P==u&&typeof R.length==L,D=82;else if(21==D)D=x<L.length?29:25;else if(67==D)x+=8192,D=21;else if(55==D)x.setAttribute(O,u),D=15;else if(90==D)D=u?26:91;else if(53==D)D=6<=(U>>1&7)&&11>(U>>2&12)?93:82;else if(25==D)R=u(e).replace(/\\\\+/g,\"-\").replace(/\\\\//g,\"_\").replace(/=/g,\"\"),D=49;else if(41==D)P=Ns,R in P?x.setAttribute(O,P[R]):x.removeAttribute(O),D=15;else if(91==D)R=void 0,D=49;else if(3==D)L.ua=void 0,L.kU=function(){return L.ua?L.ua:L.ua=new L},D=53;else if(88==D)D=U-6&15?15:95;else if(51==D)D=\"function\"!==typeof e?63:88;else if(26==D)e=\"\",x=0,D=57;else{if(58==D)throw Error(\"Invalid class name \"+L);95==D&&(Array.isArray(u)&&(u=u.join(\" \")),O=L+R,D=50)}}}},y=function(L,U,e,u,R,x,P,O,E,Q,D){for(D=7;35!=D;)if(49==D)D=U<<2&7?59:54;else if(97==D)Q=function(){},Q.prototype=u.prototype,e.m=u.prototype,e.prototype=new Q,e.prototype.constructor=e,e.sk=function(m,M,n){for(var Y=37;74!=Y;)if(37==Y)var K=Array((Y=97,arguments).length-L),c=L;else if(29==Y)Y=c<arguments.length?24:63;else if(97==Y)Y=29;else{if(63==Y)return u.prototype[M].apply(m,K);24==Y?(K[c-L]=arguments[c],Y=49):49==Y&&(c++,Y=29)}},D=45;else if(7==D)D=1;else if(1==D)D=(U&47)==U?60:49;else if(60==D){for(P in O=L,u.X){for(R=u.X[P],x=L;x<R.length;x++)++O,lq(69,41,e,R[x]);delete u.X[P],u.YU--}D=49}else if(54==D)this.src=L,this.X={},this.YU=0,D=59;else{if(45==D)return E;59==D&&(D=(U-4^26)<U&&(U-9|27)>=U?97:45)}},bq=function(L,U,e,u,R,x,P,O,E,Q,D,m){for(D=84;23!=D;){if(58==D)return m;if(19==D)D=0==u.X[x].length?21:45;else if(76==D)D=U-8<<1>=U&&(U-3|84)<U?57:58;else if(66==D)x=R.type,D=10;else if(96==D)D=12<=(U>>1&23)&&1>(U^37)>>4?66:45;else if(47==D)D=1==(U+3&19)?82:96;else if(10==D)D=x in u.X&&sI(10,6,0,u.X[x],R)?30:45;else if(84==D)D=47;else if(2==D)pw(35,L,12,u,E,P,O,x,R),D=53;else if(29==D)D=Q<R.length?0:53;else if(82==D)m=Math.floor(this.Z()),D=96;else if(92==D)D=Array.isArray(R)?17:1;else if(21==D)delete u.X[x],u.YU--,D=45;else if(57==D)this.type=e,this.currentTarget=this.target=u,this.defaultPrevented=this.ia=false,D=58;else if(53==D)D=2==(U<<1&23)?27:76;else if(30==D)lq(69,43,e,R),D=19;else if(13==D)Q++,D=29;else if(0==D)bq(true,3,false,0,R[Q],x,P,O,E),D=13;else if(17==D)Q=u,D=4;else if(27==D){if((R=u.length,R)>e){for(P=(x=Array(R),e);P<R;P++)x[P]=u[P];m=x}else m=[];D=76}else 4==D?D=29:45==D?D=(U&43)==U?18:53:18==D?D=P&&P.once?2:92:1==D&&(E=nw(48,14,E),x&&x[Ie]?x.V.add(String(R),E,e,V(18,\"object\",P)?!!P.capture:!!P,O):oe(41,\"object\",false,R,e,E,O,x,P),D=53)}},gO=function(L,U,e,u,R,x){for(R=45;85!=R;)if(51==R)x=u,R=28;else if(R==L)this[this+\"\"]=this,R=76;else if(97==R)R=(e-7|21)<e&&e-4<<2>=e?L:76;else if(45==R)R=97;else{if(28==R)return x;76==R&&(R=2<=e+3&&3>(e>>2&U)?51:28)}},QV=function(L,U,e,u,R,x,P,O,E,Q){for(Q=6;95!=Q;)if(28==Q)E=P,Q=26;else{if(53==Q)return E;if(54==Q)E=!!(U.Xp&e)&&!!(U.S&e)!=x&&(!(P=U.rb,(P|0)-R*~e+R*~(P|e)+(P&~e))||U.dispatchEvent(oe(3,R,16,8,4,e,x)))&&!U.g,Q=29;else if(6==Q)Q=34;else if(45==Q){a:if(\"string\"===typeof x)E=\"string\"!==typeof U||U.length!=R?-1:x.indexOf(U,e);else{for(P=e;P<x.length;P++)if(P in x&&x[P]===U){E=P;break a}E=-1}Q=53}else 26==Q?Q=u>>1&1?29:54:59==Q?(x=new mq(e,this),U=R.listener,O=R.US||R.src,R.zV&&oe(L,true,null,R),P=U.call(O,x),Q=28):29==Q?Q=(u|32)==u?45:53:44==Q?Q=R.GV?25:59:25==Q?(P=true,Q=28):34==Q&&(Q=u+3>>4?26:44)}},oe=function(L,U,e,u,R,x,P,O,E,Q,D,m,M,n,Y){for(Y=95;48!=Y;)if(31==Y)u.NU(function(K){R=K},U,e),n=R,Y=57;else if(57==Y)Y=L>>1&13?13:79;else if(56==Y)Y=O.addListener&&O.removeListener?87:0;else if(96==Y){a:{switch(x){case 1:n=P?\"disable\":\"enable\";break a;case U:n=P?\"highlight\":\"unhighlight\";break a;case R:n=P?\"activate\":\"deactivate\";break a;case u:n=P?\"select\":\"unselect\";break a;case e:n=P?\"check\":\"uncheck\";break a;case 32:n=P?\"focus\":\"blur\";break a;case 64:n=P?\"open\":\"close\";break a}throw Error(\"Invalid component state\");}Y=60}else if(86==Y)Y=7>(L>>1&8)&&10<=((L|2)&15)?51:39;else if(39==Y)Y=1==(L>>1&15)?96:60;else if(76==Y)x=u.src,Y=6;else if(38==Y)Y=O?21:45;else if(41==Y)ko||(E=m),void 0===E&&(E=e),O.addEventListener(u.toString(),M,E),Y=43;else if(3==Y)Y=28;else if(52==Y)Y=O.addEventListener?41:70;else if(49==Y)bq(true,39,U,x.V,u),Y=13;else if(21==Y)bq(true,36,U,O,u),Y=44;else if(69==Y)Y=D.proxy?39:66;else if(79==Y)Y=\"number\"!==typeof u&&u&&!u.GV?76:13;else if(33==Y)O.src=e,x[tP]=e,Y=13;else{if(15==Y)throw Error(\"Invalid event type\");if(51==Y)Y=u?97:15;else if(44==Y)Y=0==O.YU?33:13;else if(95==Y)Y=86;else if(60==Y)Y=17<=L<<2&&36>(L^19)?31:57;else if(45==Y)lq(69,40,U,u),Y=13;else if(97==Y)m=V(34,U,E)?!!E.capture:!!E,(Q=b(6,O))||(O[tP]=Q=new zL(O)),D=Q.add(u,x,R,m,P),Y=69;else if(43==Y)WM++,Y=39;else if(72==Y)P=u.type,R=u.proxy,x.removeEventListener?x.removeEventListener(P,R,u.capture):x.detachEvent?x.detachEvent(JP(\"on\",P,7),R):x.addListener&&x.removeListener&&x.removeListener(R),WM--,O=b(8,x),Y=38;else{if(28==Y)return n;if(13==Y)Y=(L&93)==L?3:28;else if(66==Y)M=V(17),D.proxy=M,M.src=O,M.listener=D,Y=52;else if(87==Y)O.addListener(M),Y=43;else if(70==Y)Y=O.attachEvent?77:56;else if(77==Y)O.attachEvent(JP(\"on\",u.toString(),5),M),Y=43;else{if(0==Y)throw Error(\"addEventListener and attachEvent are unavailable.\");6==Y&&(Y=x&&x[Ie]?49:72)}}}},r=function(L,U,e,u,R,x,P,O,E,Q,D){for(D=85;87!=D;)if(22==D)D=L>>1&15?99:53;else if(93==D)D=1==(L>>2&11)?74:27;else if(8==D)D=52;else{if(79==D)return Q;if(99==D)D=(L|24)==L?92:93;else if(77==D)x++,D=52;else if(85==D)D=22;else if(92==D)P=x=0,D=8;else if(52==D)D=x<U.length?94:69;else if(27==D)D=3==(L>>2&7)?57:79;else if(53==D)N(U,e,u),u[$o]=2796,D=99;else if(94==D)P+=U.charCodeAt(x),P+=P<<10,P^=P>>6,D=77;else if(69==D)P+=P<<3,P=(R=P>>11,-(R|0)+(P&R)+(P&~R)+2*(~P&R)),O=P+(P<<15)>>>0,E=new Number(O&(1<<e)-1),E[0]=(O>>>e)%u,Q=E,D=93;else if(74==D){a:{for(O=U;O<R.length;++O)if(P=R[O],!P.GV&&P.listener==e&&P.capture==!!x&&P.US==u){Q=O;break a}Q=-1}D=27}else 57==D&&(D=79)}},S=function(L,U,e,u,R,x,P,O,E,Q,D,m,M){if((e&110)==e){for(x=(R=I(26,u),0);0<L;L--)x=x<<U|iq(2,u,true);N(u,R,x)}if(22<=e>>((e+1^((e+((e-4|82)>=(23<=(e^84)&&34>e+6&&(m=M=function(){for(var n=32;64!=n;)if(80==n){var Y=wO(null,c,x,254);n=41}else if(32==n)n=x.i==x?84:64;else if(93==n)n=u==L?50:0;else if(0==n)n=u==U?31:80;else if(50==n)X(18,0,c,x),Y=V(78,254,false,false,x),n=41;else{if(41==n)return Y;if(57==n)O&&E&&O.removeEventListener(E,M,SY),n=64;else if(31==n){var K=!x.R.length;n=((X(10,0,c,x),K)&&V(75,254,false,false,x),41)}else if(84==n)n=x.G?44:57;else if(44==n)var c=[dO,P,(n=93,R),void 0,O,E,arguments]}}),e)&&(e-7^11)<e&&(u=eY[U.D](U.Uk),u[U.D]=function(){return L},u.concat=function(n){L=n},m=u),5)^26)<e&&(e-5^29)>=e&&(R=[-52,4,-38,-38,-16,86,R,-39,-79,-61],O=hP,Q=P&7,E=eY[x.D](x.iH),E[x.D]=function(n){Q=((Q+=6+(D=n,7*P),Q)|0)-~(Q&7)+~Q},E.concat=function(n,Y,K,c){return c=(D=(Y=(n=u%16+U,+(O()|0)*n+Q+R[Q+L&7]*u*n+3*u*u*n- -1258*D+37*D*D-n*D)-111*u*u*D-148*u*D,void 0),R)[Y],R[(K=Q+69,(K|7)- -1+(~K^7))+(P&2)]=c,R[Q+((P|0)- -1+(~P|2))]=4,c},m=E),9))>=e&&(e+4^18)<e&&(u=iq(2,L,true),-~u-(~u^128)-(~u&128)+U*(~u|128)&&(u=u&127|iq(2,L,true)<<7),m=u),1)&&15>(e>>2&16))if(R=\"array\"===qs(\"object\",\"splice\",u)?u:[u],this.Y)U(this.Y);else try{P=!this.R.length,x=[],X(20,0,[vM,x,R],this),X(11,0,[HM,U,x],this),L&&!P||V(79,254,L,true,this)}catch(n){G(48,0,n,this),U(this.Y)}return m},b=function(L,U,e,u,R,x){for(R=80;97!=R;)if(46==R)R=(L&99)==L?15:67;else if(9==R)x=Math.floor(this.jQ+(this.Z()-this.VN)),R=46;else if(15==R)x=QV(33,e,U,35,1,u)>=U,R=67;else if(98==R)R=4==(L-6&15)?73:11;else if(67==R)R=1==(L-1&25)?22:47;else if(80==R)R=98;else if(73==R)x=U&&U.parentNode?U.parentNode.removeChild(U):null,R=11;else{if(5==R)return x;78==R?(d.call(this,U,e||AP.kU(),u),R=5):22==R?(e=U[tP],x=e instanceof zL?e:null,R=47):11==R?R=2==(L<<1&14)?9:46:47==R&&(R=3==((L^93)&23)?78:5)}},EI=function(L,U,e,u,R,x,P,O,E,Q,D){for(D=15;23!=D;)if(28==D)D=8;else if(31==D)D=R<U.length?83:29;else if(49==D)D=7<P?93:43;else if(74==D)D=8;else if(50==D)eU.call(this,u),D=59;else if(76==D)D=(L+3^13)>=L&&(L-1^21)<L?13:66;else if(13==D)R=0,x=[],P=0,D=16;else if(81==D)R=O?\"function\"===typeof O.kU?O.kU():new O:null,D=91;else if(83==D)u=u<<e|U[R],P+=e,D=99;else if(35==D)Q=Object.prototype.hasOwnProperty.call(U,Db)&&U[Db]||(U[Db]=++Rl),D=97;else if(16==D)D=31;else if(29==D)Q=x,D=66;else if(98==D)D=2==(L+3&6)?35:97;else if(15==D)D=76;else if(8==D)D=x?45:81;else if(99==D)D=49;else if(69==D)x=this.constructor,D=74;else if(26==D)Q=e.classList?e.classList:PM(\"\",21,\"class\",U,e).match(/\\\\S+/g)||[],D=2;else if(66==D)D=L+5>>4?98:50;else if(22==D)D=81;else if(91==D)this.J=R,D=98;else if(93==D)P-=8,x.push((O=u>>P,(O|0)-(O^255)+(~O&255))),D=86;else{if(2==D)return Q;47==D?(x=(P=Object.getPrototypeOf(x.prototype))&&P.constructor,D=28):59==D?D=(R=e)?91:69:43==D?(R++,D=31):45==D?(E=EI(16,x),D=73):97==D?D=(L|32)==L?26:2:73==D?D=(O=UF[E])?22:47:86==D&&(D=49)}},La=function(){return oe.call(this,80)},zL=function(L){return y.call(this,L,16)},EF=function(L,U,e,u,R,x,P,O,E,Q){U.push((e=(E=L[0]<<24,P=L[1]<<16,-(E&P)-1-2*~(E|P)+(~E^P)),u=L[2]<<8,~(e&u)-~u-~(e|u)+(e|~u))|L[3]),U.push((x=(R=L[4]<<24|L[5]<<16,O=L[6]<<8,-~O+2*(R&~O)+(~R^O)+(~R&O)),Q=L[7],2*(Q|0)- -1+~Q+(x&~Q))),U.push(L[8]<<24|L[9]<<16|L[10]<<8|L[11])},Lw=function(L,U,e,u,R,x){return QV.call(this,33,u,U,3,L,e,R,x)},jU=function(L,U,e,u,R,x,P,O,E,Q,D,m,M,n,Y){for(n=(m=(P=U.replace(/\\\\r\\\\n/g,\"\\\\n\"),[]),D=0);D<P.length;D++)R=P.charCodeAt(D),128>R?m[n++]=R:(2048>R?m[n++]=R>>6|192:(55296==(R&64512)&&D+1<P.length&&56320==(M=P.charCodeAt(D+1),-~(M&64512)+(M^64512)+(~M^64512))?(R=65536+((R|0)+(~R^1023)-(R|-1024)<<10)+(E=P.charCodeAt(++D),-~(E|1023)-(E&-1024)+(E|-1024)),m[n++]=(Y=R>>18,(Y|0)-(Y&-241)+(Y^240)),m[n++]=(u=(O=R>>12,(O|63)- -1+(~O^63)),(u|0)+(u&128)+~(u&128)-(u|-129))):m[n++]=(e=R>>12,223-(~e|224)),m[n++]=(x=R>>6,-(x|0)-2*~(x|63)-(x&-64)+2*(x|-64))|128),m[n++]=(Q=L+(R|-64),(Q|0)-1-(Q|-129)));return m},uu=function(L,U,e,u,R,x,P,O,E,Q,D,m){for(D=37;75!=D;)if(70==D)m(E),D=22;else if(33==D)E=L[Q],D=76;else if(76==D)D=!t(\"number\",28,x,e,E)||V(3,e,E)&&0<E.nodeType?70:49;else if(22==D)Q++,D=30;else if(87==D)D=30;else if(30==D)D=Q<L.length?33:75;else if(49==D){a:{if(E&&\"number\"==typeof E.length){if(V(19,e,E)){O=\"function\"==typeof E.item||typeof E.item==P;break a}if(\"function\"===typeof E){O=\"function\"==typeof E.item;break a}}O=false}D=(nw(48,48,\"\",0,O?bq(true,5,0,E):E,m),22)}else 37==D&&(m=function(M){M&&u.appendChild(\"string\"===typeof M?R.createTextNode(M):M)},Q=U,D=87)},N=function(L,U,e){if(400==U||221==U)L.G[U]?L.G[U].concat(e):L.G[U]=S(e,L,31);else{if(L.Bz&&16!=U)return;404==U||325==U||11==U||29==U||164==U||389==U||131==U?L.G[U]||(L.G[U]=S(27,1,43,U,e,L,150)):L.G[U]=S(27,1,75,U,e,L,9)}16==U&&(L.O=Xr(32,2,false,L),L.u=void 0)},Fr=function(){return G.call(this,3)},xL=function(L,U){function e(){this.o=(this.n=0,[])}return[function(u){(L.Pz(u),U).Pz(u)},(U=(e.prototype.ba=function(){return PM.call(this,\"\",3)},e.prototype.Pz=function(u,R){return pw.call(this,35,R,8,u)},L=new e,new e),function(u){return U=new (u=L.ba().concat(U.ba()),e),u})]},PR=function(L,U,e,u,R,x,P){((P=l(L,(R=(u=I(30,(e=(x=2*(U|0)-(U|4)-(U&-5)+(~U&4),3-~(U&3))+-4,L)),I(26,L)),u)),x)&&(P=jU(64,\"\"+P)),e)&&h(q(2,P.length),R,L),h(P,R,L)},xo=function(){return Z2.call(this,30)},cM=function(L,U,e){return(e=L.create().shift(),U.h).create().length||U.N.create().length||(U.h=void 0,U.N=void 0),e},QY=function(L,U,e){return b.call(this,22,L,U,e)},sF=function(L,U){function e(){this.Hz=this.hN=this.n=0}return[(U=(L=new ((e.prototype.wX=function(){return PM.call(this,\"\",88)},e).prototype.f2=function(u,R){return ae.call(this,null,26,R,5,u)},e),new e),function(u){(L.f2(u),U).f2(u)}),function(u){return U=(u=[L.wX(),U.wX()],new e),u}]},jY=function(){return lq.call(this,69,7)},mK=function(L,U,e,u,R,x){u.MU.length>R?M5(L,u,[OF,36],U):(u.MU.push(u.G.slice()),u.G[x]=void 0,N(u,x,e))},v,YL=function(L){return gO.call(this,20,8,3,L)},AP=function(){return r.call(this,12)},na=function(){return sI.call(this,10,12)},q=function(L,U,e,u){for(e=(u=-~(L&1)+-4-~(L|1),[]);0<=u;u--)e[(L|0)-1-(u|0)]=U>>8*u&255;return e},fa=function(L,U,e,u){h(q(L,(u=(e=I(14,U),I(18,U)),l)(U,e)),u,U)},qs=function(L,U,e,u,R){if((u=typeof e,u)==L)if(e){if(e instanceof Array)return\"array\";if(e instanceof Object)return u;if((R=Object.prototype.toString.call(e),\"[object Window]\")==R)return L;if(\"[object Array]\"==R||\"number\"==typeof e.length&&\"undefined\"!=typeof e.splice&&\"undefined\"!=typeof e.propertyIsEnumerable&&!e.propertyIsEnumerable(U))return\"array\";if(\"[object Function]\"==R||\"undefined\"!=typeof e.call&&\"undefined\"!=typeof e.propertyIsEnumerable&&!e.propertyIsEnumerable(\"call\"))return\"function\"}else return\"null\";else if(\"function\"==u&&\"undefined\"==typeof e.call)return L;return u},ol=function(L,U,e,u,R,x,P,O){for(R.Uk=(R.iH=UI(((R.J$=R[HM],R.Mg=GM,R).CG=Ka,17),11,R.D,{get:function(){return this.concat()}}),eY[R.D](R.iH,{value:{value:{}}})),O=0,x=[];259>O;O++)x[O]=String.fromCharCode(O);V(76,254,(X(19,(X(12,0,(r(32,R,252,(N(R,164,[0,0,(r(33,((r(64,R,(r(32,R,41,(N(R,(N(R,(r(64,R,33,(r(32,R,(N(R,(r(64,(N(R,131,[(N(R,(r(65,(r(64,R,254,(r(32,(r(32,R,393,(r(33,R,((r(33,R,508,(N(R,389,(r(65,R,(r(65,R,(N(R,81,(N(R,(N(R,29,(r(65,(r(33,R,256,(r(33,R,(R.jf=(r(64,(r(32,R,(N((r(64,R,(r(65,R,262,(pw(((r(33,(r(65,R,(N(R,(r((N(R,221,(N(R,(R.KG=(P=((R.K2=0,R).L2=(R.mS=(R.G=((R.tN=void 0,R).Ng=e,R.O=void 0,(R.yx=function(E){return UI.call(this,17,8,E)},R).i=R,(R.l=0,R).N=(R.JN=false,void 0),R.VN=0,R.u=void 0,R.n2=(R.ar=8001,25),[]),0),R.H5=0,R.Y=(R.Bz=false,void 0),R.T=false,((R.MU=[],R).B=[],R).h=void 0,(R.R=[],R.mk=false,R).gX=(R.j=null,R.Wz=(R.Zl=1,R.jQ=0,[]),R.Ir=void 0,R.F=false,0),[]),(R.vz=U,window.performance)||{}),P.timeOrigin||(P.timing||{}).navigationStart||0),400),0),0)),N(R,404,[165,0,0]),33),R,255,function(E,Q,D,m){(m=I((Q=(D=I(14,E),I)(26,E),26),E),N)(E,m,l(E,D)||l(E,Q))}),325),X8(4)),225),function(E,Q,D,m,M,n){N(E,(m=(D=l(E,(n=I((M=I(34,(Q=I(34,E),E)),34),E),M)),l(E,Q)),n),m in D|0)}),R),412,function(E,Q,D,m,M,n){N(E,(Q=l(E,(n=l((M=(m=I(22,E),D=I(30,E),I(26,E)),E),m),D)),M),n[Q])}),r)(32,R,204,function(){}),35),new QY(\"Submit\"),19,true),function(E){S(4,8,72,E)})),290),function(E,Q){(Q=l(E,I(38,E)),mK)(2,0,Q,E.i,104,400)}),R),11,[]),259),function(E,Q,D,m,M,n,Y,K,c,Z,T,C,D2,B,p,fw,H,J){for(J=42;96!=J;)75==J?(M.push(l(E,I(18,E))),J=58):42==J?(H=function(k,z){for(;T<k;)D|=iq(2,E,true)<<T,T+=8;return D>>=(z=D&(T-=k,(1<<k)-1),k),z},fw=I(30,E),T=D=0,K=(H(3)|0)+1,Q=H(5),n=0,Z=[],c=0,J=87):21==J?J=15:0==J?J=59:4==J?(C++,J=59):58==J?J=44:72==J?(B++,J=15):89==J?(r(65,E,fw,function(k,z,Kw,Re,W,w){for(w=31;97!=w;)89==w?(W.push(Re),w=54):54==w?(z++,w=58):42==w?w=Re>=Kw.length?90:83:60==w?(Re=Y[z],w=50):56==w?w=42:30==w?(k.h=S(M.slice(),k,33),k.N=S(W,k,30),w=97):31==w?(z=0,W=[],Kw=[],w=28):50==w?w=Z[z]?89:56:90==w?(Kw.push(I(14,k)),w=61):61==w?w=42:58==w?w=z<Q?60:30:28==w?w=58:83==w&&(Re=Kw[Re],w=89)}),J=96):98==J?(M=[],m=K,J=61):44==J?J=m--?75:89:87==J?J=35:59==J?J=C<Q?34:98:43==J?(p=H(1),Z.push(p),n+=p?0:1,J=41):35==J?J=c<Q?43:47:65==J?J=C=0:47==J?(D2=((n|0)-1).toString(2).length,Y=[],B=0,J=21):34==J?(Z[C]&&(Y[C]=I(14,E)),J=4):15==J?J=B<Q?18:65:41==J?(c++,J=35):18==J?(Z[B]||(Y[B]=H(D2)),J=72):61==J&&(J=44)}),R),505,function(E,Q,D,m,M){Q=l((m=0!=l(E,(D=(M=I(22,E),I)(14,E),M)),E),D),m&&N(E,400,Q)}),0),422),function(E,Q,D,m,M,n){N(E,(Q=l((M=l(E,(n=I(26,(m=I(26,(D=I(18,E),E)),E)),D)),E),m),n),+(M==Q))}),function(E,Q,D,m,M,n,Y,K,c,Z,T){for(T=71;67!=T;)71==T?(Z=I(18,E),c=I(38,E),K=I(34,E),m=I(14,E),D=l(E.i,Z),Q=l(E,c),M=l(E,m),Y=l(E,K),T=49):49==T?T=0!==D?89:67:89==T&&(n=S(2,1,3,1,M,E,Y,D,Q),D.addEventListener(Q,n,SY),l(E,141).push(function(){D.removeEventListener(Q,n,SY)}),N(E,307,[D,Q,n]),T=67)})),R),435,function(E){fa(4,E)}),[])),183),R),a)),157),function(E,Q,D){(D=(Q=I(26,E),l(E.i,Q)),D)[0].removeEventListener(D[1],D[2],SY)}),258),function(E,Q,D,m,M,n,Y,K){N(E,(K=(Y=l(E,(D=l(E,(M=I(22,(m=I(22,(Q=I(18,(n=I(38,E),E)),E)),E)),m)),Q)),l(E,M)),n),S(2,1,7,K,D,E,Y))}),X8)(4)),function(E,Q,D,m,M,n,Y,K){for(K=30;48!=K;)55==K?(E.O=Xr(32,2,false,E),E.u=void 0,K=48):22==K?K=16==Y?46:48:12==K?(D=l(E,Y),Q=l(E,m),n=l(E,M),D[n]=Q,K=22):84==K?K=2==n?55:48:46==K?(E.u=void 0,K=84):47==K?K=E.i==E?12:48:30==K&&(Y=I(22,E),M=I(22,E),m=I(30,E),K=47)})),r)(32,R,428,function(E,Q,D,m,M){for(M=83;40!=M;)83==M?M=G(98,false,E,true,Q,false)?40:72:72==M&&(m=I(34,E),D=I(22,E),N(E,D,function(n){return eval(n)}(cR(l(E.i,m)))),M=40)}),R.o6=0,388),function(E,Q,D,m,M,n,Y,K,c,Z,T,C,D2,B,p){for(p=6;28!=p;)if(87==p)C=0<C?C:1,D2=B.length,M=0,p=50;else if(29==p){for(T in Y=[],B)Y.push(T);B=(p=37,Y)}else 0==p?(Z(B.slice(M,-1-~M-~(M|C)+(~M|C)),D),p=26):14==p?(m=I(18,E),c=I(14,E),n=I(18,E),K=I(38,E),B=l(E,m),Z=l(E,c),C=l(E,n),D=l(E,K),p=76):76==p?p=\"object\"==qs(\"object\",\"splice\",B)?29:37:37==p?p=E.i==E?87:28:6==p?p=G(34,false,E,true,Q,true)?28:14:2==p?p=M<D2?0:28:26==p?(M+=C,p=2):50==p&&(p=2)}),function(E,Q,D,m,M,n,Y,K,c,Z){for(Z=87;55!=Z;)87==Z?Z=G(42,false,E,true,Q,false)?55:66:66==Z&&(m=bu(2,34,0,1,E.i),M=m.GZ,Y=m.XN,D=m.L,K=m.qU,n=D.length,c=0==n?new M[K]:1==n?new M[K](D[0]):2==n?new M[K](D[0],D[1]):3==n?new M[K](D[0],D[1],D[2]):4==n?new M[K](D[0],D[1],D[2],D[3]):2(),N(E,Y,c),Z=55)})),R),77,function(E,Q,D,m,M,n){for(n=65;60!=n;)29==n?(N(E,M,m),n=60):50==n?n=30:65==n?(M=I(18,E),D=S(E,2,86),Q=0,m=[],n=50):30==n?n=Q<D?13:29:13==n?(m.push(iq(2,E,true)),n=94):94==n&&(Q++,n=30)}),function(E,Q,D,m,M){N(E,(D=l(E,(Q=l((m=I(38,E),M=I(30,E),E),m),M)),M),D+Q)})),R),439,function(E,Q,D,m,M){N(E,(m=qs(\"object\",\"splice\",(D=l(E,(M=(Q=I(30,E),I(34,E)),Q)),D)),M),m)}),141),[]),2048)]),R),114,function(E,Q,D,m){D=I(34,(Q=iq(2,E,(m=I(38,E),true)),E)),N(E,D,l(E,m)>>>Q)}),307),0),121),function(E,Q,D,m,M){for(M=10;85!=M;)91==M?M=D?5:86:18==M?(Q=I(18,E),D[Q]=E.G[Q],M=25):25==M?(m--,M=75):10==M?(D=E.MU.pop(),M=91):90==M?(D[29]=E.G[29],D[131]=E.G[131],E.G=D,M=85):22==M?M=75:75==M?M=0<m?18:90:5==M?(m=iq(2,E,true),M=22):86==M&&(N(E,400,E.l),M=85)}),function(E){PR(E,3)})),399),0),r(64,R,58,function(E,Q,D,m,M,n){for(n=1;19!=n;)1==n?n=G(82,false,E,true,Q,false)?19:69:99==n?n=E.i==E||D==E.yx&&m==E?96:19:69==n?(M=bu(2,34,0,1,E),m=M.GZ,D=M.qU,n=99):96==n&&(N(E,M.XN,D.apply(m,M.L)),E.mS=E.Z(),n=19)}),138),{}),function(E){PR(E,4)})),N(R,30,430),425),function(E){fa(1,E)}),R).Ok=0,R),293,function(E,Q,D){(D=I(14,(Q=I(38,E),E)),N)(E,D,\"\"+l(E,Q))}),0)]),function(E,Q,D,m,M,n,Y,K){for(K=75;3!=K;)90==K?K=24:26==K?(N(E,M,Q),K=3):95==K?K=24:24==K?K=D--?68:26:75==K?(M=I(26,E),D=S(E,2,84),Q=\"\",m=l(E,218),n=m.length,Y=0,K=90):68==K&&(Y=((Y|0)+(S(E,2,85)|0))%n,Q+=x[m[Y]],K=95)})),[$o]),R),X(26,0,[pa,L],R),0),[Il,u],R),true),true,R)},Zb=function(L,U,e,u,R,x,P,O,E,Q){for(E=(O=P[2]|(Q=P[3]|L,L),L);E<U;E++)x=x>>>8|x<<24,x+=R|L,x^=O+e,R=R<<3|R>>>29,R^=x,Q=Q>>>8|Q<<24,Q+=O|L,O=O<<3|O>>>29,Q^=E+e,O^=Q;return[R>>>24&255,R>>>u&255,R>>>8&255,R>>>L&255,x>>>24&255,x>>>u&255,x>>>8&255,x>>>L&255]},wc=function(L,U,e,u,R,x){return lq.call(this,69,36,L,U,e,u,R,x)},bu=function(L,U,e,u,R,x,P,O,E,Q){for(P=(O=I(38,(x=(((E=I(22,(Q=R[TM]||{},R)),Q).XN=I(22,R),Q).L=[],R.i)==R?(iq(L,R,true)|e)-u:1,R)),e);P<x;P++)Q.L.push(I(U,R));for(Q.qU=l(R,E);x--;)Q.L[x]=l(R,Q.L[x]);return Q.GZ=l(R,O),Q},mq=function(L,U,e,u,R){return nw.call(this,48,3,L,U,e,u,R)},a=this||self,iq=function(L,U,e){return U.h?cM(U.N,U):Xr(8,L,e,U)},wO=function(L,U,e,u,R,x,P,O,E,Q,D){if(x=U[0],x==vM)e.n2=25,e.F=true,e.H(U);else if(x==HM){e.F=(R=U[1],true);try{O=e.Y||e.H(U)}catch(m){G(53,0,m,e),O=e.Y}R(O)}else if(x==TL)U[3]&&(e.T=true),U[4]&&(e.F=true),e.H(U);else if(x==pa)e.T=true,e.H(U);else if(x==Il){e.T=true;try{for(P=0;P<e.Wz.length;P++)try{D=e.Wz[P],D[0][D[1]](D[2])}catch(m){}}catch(m){}(0,U[1])(function(m,M){e.NU(m,true,M)},(e.Wz=[],function(m){X(27,0,[Ca],(m=!e.R.length,e)),m&&V(75,u,true,false,e)}),function(m){return e.sS(m)})}else{if(x==dO)return E=U[2],N(e,163,U[6]),N(e,138,E),e.H(U);x==Ca?(e.H(U),e.B=[],e.G=L,e.L2=[]):x==$o&&(Q=a.parent,\"loading\"===Q.document.readyState&&(e.j=function(m,M){function n(Y){for(Y=7;0!=Y;)7==Y?Y=M?0:47:47==Y&&(M=true,Q.document.removeEventListener(\"DOMContentLoaded\",n,SY),Q.removeEventListener(\"load\",n,SY),m(),Y=0)}(Q.document.addEventListener(\"DOMContentLoaded\",(M=false,n),SY),Q).addEventListener(\"load\",n,SY)}))}},BR=function(L,U,e,u,R){if(3==L.length){for(R=0;3>R;R++)U[R]+=L[R];for(e=[13,8,13,12,16,(u=0,5),3,10,15];9>u;u++)U[3](U,u%3,e[u])}},al=function(L,U,e,u,R){return Z2.call(this,3,L,U,e,u,R)},M5=function(L,U,e,u,R,x,P,O,E,Q,D,m){if(!U.Bz&&(Q=void 0,e&&e[0]===OF&&(Q=e[L],u=e[1],e=void 0),m=l(U,29),0==m.length&&(P=l(U,221)>>3,m.push(u,P>>8&255,P&255),void 0!=Q&&m.push(Q&255)),E=\"\",e&&(e.message&&(E+=e.message),e.stack&&(E+=\":\"+e.stack)),D=l(U,131),3<D[0])){(R=(E=jU(64,(D[0]-=(E=E.slice(0,(O=D[0],3*(O&-4)-L*(O^3)-(~O^3)+(~O|3))),x=E.length,(x|3)-(x&3)- -8+L*(x|-4)),E)),U.i),U).i=U;try{h(q(L,E.length).concat(E),325,U,12)}finally{U.i=R}}},F8=function(L,U,e,u,R,x,P,O,E,Q,D,m){for(D=55,m=L;;)try{if(D==U)break;else if(55==D)O=a.trustedTypes,E=P,D=43;else if(87==D)a.console[x](Q.message),D=19;else if(32==D)D=a.console?87:19;else{if(D==e)return E;if(39==D)m=L,D=32;else if(7==D)m=u,E=O.createPolicy(R,{createHTML:YL,createScript:YL,createScriptURL:YL}),D=19;else{if(19==D)return m=L,E;43==D&&(D=O&&O.createPolicy?7:e)}}}catch(M){if(m==L)throw M;m==u&&(Q=M,D=39)}},zM=function(L,U,e,u){try{u=L[((U|0)+2)%3],L[U]=(L[U]|0)-(L[((U&1)-1-~(U|1))%3]|0)-(u|0)^(1==U?u<<e:u>>>e)}catch(R){throw R;}},l=function(L,U,e){if(void 0===(e=L.G[U],e))throw[OF,30,U];if(e.value)return e.create();return e.create(3*U*U+4*U+-34),e.prototype},Xr=function(L,U,e,u,R,x,P,O,E,Q,D,m,M,n,Y,K,c){if(n=l(u,400),n>=u.l)throw[OF,31];for(D=(c=n,L),E=0,O=u.J$.length;0<D;)Q=c>>3,Y=c%8,m=8-(Y|0),x=m<D?m:D,M=u.B[Q],e&&(P=u,P.u!=c>>6&&(P.u=c>>6,R=l(P,16),P.Ir=Zb(0,15,3379,16,P.O,P.u,[0,0,R[1],R[U]])),M^=u.Ir[Q&O]),E|=(M>>8-(Y|0)-(x|0)&(1<<x)-1)<<(D|0)-(x|0),D-=x,c+=x;return N(u,400,(K=E,(n|0)+(L|0))),K},d=function(L,U,e,u,R,x,P,O){return EI.call(this,3,L,U,e,u,R,x,P,O)},X8=function(L,U,e){for(e=86;42!=e;)if(71==e)e=9;else if(31==e)e=9;else if(86==e)U=[],e=31;else if(62==e)U.push(255*Math.random()|0),e=71;else{if(64==e)return U;9==e&&(e=L--?62:64)}},Ms=function(L,U){return bq.call(this,true,87,L,U)},eU=function(L){return PM.call(this,\"\",12,L)},lu=function(){return X.call(this,17)},N5=function(L,U){return V.call(this,5,L,U)},h=function(L,U,e,u,R,x,P,O,E){if(e.i==e)for(x=l(e,U),325==U||389==U?(R=function(Q,D,m,M,n,Y,K,c,Z,T){for(Z=(c=1,31);;)try{if(78==c)break;else if(97==c)x.kK=Y,D=(M=Y<<3,4*(M&-5)-2*(M^4)-(M|-5)+(~M|4)),K=[0,0,O[1],O[2]],c=84;else if(84==c)Z=55,x.A$=Zb(0,15,3379,16,I(8,1,0,D,x),I(7,1,0,(D&4)-~D+(D^4)+(~D|4),x),K),c=2;else if(2==c)x.push((n=x.A$[-2-~m-(m^7)-(m|-8)],~(n&Q)-~Q+(n&~Q))),c=78;else if(1==c)m=x.length,Y=-(~m^4)-(~m&4)+(m|-5)>>3,c=43;else if(43==c)c=x.kK!=Y?97:2;else if(73==c)throw Z=31,T;}catch(C){if(31==Z)throw C;55==Z&&(T=C,c=73)}},O=l(e,164)):R=function(Q){x.push(Q)},u&&R(-~(u|255)-(u^255)+(~u&255)+(u|-256)),E=L.length,P=0;P<E;P++)R(L[P])},kL=function(L,U){for(var e=45;63!=e;)if(49==e)P++,e=27;else if(45==e)var u=(e=22,1);else if(46==e)u++,e=29;else if(22==e)e=29;else if(29==e)e=u<arguments.length?96:63;else if(56==e){var R=gc[P];e=(Object.prototype.hasOwnProperty.call(x,R)&&(L[R]=x[R]),49)}else if(96==e){var x=arguments[u];for(R in x)L[R]=x[R];var P=(e=35,0)}else 27==e?e=P<gc.length?56:46:35==e&&(e=27)},tk=function(L,U,e,u,R){return ae.call(this,null,26,U,9,u,L,R,e)},yY=function(L){return b.call(this,10,L)},rc=function(L,U,e,u,R,x,P,O,E){if(!U.Y){U.K2++;try{for(R=(P=L,E=void 0,U.l);--u;)try{if(O=void 0,U.h)E=cM(U.h,U);else{if(P=l(U,400),P>=R)break;E=l(U,(N(U,221,P),O=I(30,U),O))}G(90,e,(E&&(x=E[Ca],-(x|L)-2*~(x|2048)-(x&-2049)+2*(x|-2049))?E(U,u):M5(2,U,[OF,21,O],L),U),e,u,e)}catch(Q){l(U,30)?M5(2,U,Q,22):N(U,30,Q)}if(!u){if(U.pG){rc(0,U,(U.K2--,false),316769087187);return}M5(2,U,[OF,33],L)}}catch(Q){try{M5(2,U,Q,22)}catch(D){G(51,L,D,U)}}U.K2--}},WR=function(L,U,e,u,R,x){return l(e,((rc(L,e,((x=l(e,400),e.B)&&x<e.l?(N(e,400,e.l),mK(2,L,R,e,U,400)):N(e,400,R),false),u),N)(e,400,x),138))},g=function(L,U,e,u,R){R=this;try{ol(L,U,e,u,this)}catch(x){G(52,0,x,this),u(function(P){P(R.Y)})}},Db=\"closure_uid_\"+(1E9*Math.random()>>>0),Rl=0,uq,ko=function(L,U,e,u,R,x){for(x=(u=8,84);;)try{if(17==u)break;else if(60==u)x=52,e=function(){},a.addEventListener(\"test\",e,U),a.removeEventListener(\"test\",e,U),u=58;else if(84==u)L=false,U=Object.defineProperty({},\"passive\",{get:function(){L=true}}),u=60;else{if(68==u)return false;if(58==u)return x=84,L;39==u?(x=84,u=58):8==u&&(u=a.addEventListener&&Object.defineProperty?84:68)}}catch(P){if(84==x)throw P;52==x&&(R=P,u=39)}}(),OI={2:(y(2,27,mq,(Fr.prototype.A=(Ms.prototype.preventDefault=function(){this.defaultPrevented=true},(Ms.prototype.stopPropagation=function(){this.ia=true},Fr.prototype).g=false,function(L){for(L=66;33!=L;)21==L?L=10:7==L?(this.Dl.shift()(),L=21):10==L?L=this.Dl.length?7:33:66==L?L=this.Dl?46:33:46==L&&(L=10)}),Ms)),\"touch\"),3:\"pen\",4:\"mouse\"},Ie=\"closure_listenable_\"+(1E6*(mq.prototype.preventDefault=function(L){(mq.m.preventDefault.call(this),L=this.s,L).preventDefault?L.preventDefault():L.returnValue=false},mq.prototype.stopPropagation=function(){mq.m.stopPropagation.call(this),this.s.stopPropagation?this.s.stopPropagation():this.s.cancelBubble=true},Math.random())|0),gc=\"constructor hasOwnProperty isPrototypeOf propertyIsEnumerable toLocaleString toString valueOf\".split(\" \"),BM=0,tP=\"closure_lm_\"+(1E6*(((zL.prototype.add=function(L,U,e,u,R,x,P,O,E,Q){for(Q=40;19!=Q;)if(86==Q)E=O[x],Q=49;else if(81==Q)Q=O?89:23;else if(49==Q)Q=e?95:14;else if(89==Q)x=r(6,0,U,R,O,u),Q=52;else{if(95==Q)return E;4==Q?(E=new tk(!!u,P,this.src,R,U),E.zV=e,O.push(E),Q=95):40==Q?(P=L.toString(),O=this.X[P],Q=81):14==Q?(E.zV=false,Q=95):52==Q?Q=-1<x?86:4:23==Q&&(O=this.X[P]=[],this.YU++,Q=89)}},zL.prototype).remove=(zL.prototype.hasListener=function(L,U,e,u,R){return Z2(25,true,(e=(R=(u=void 0!==L)?L.toString():\"\",void 0!==U),false),function(x,P,O){for(O=67;23!=O;)if(19==O)O=62;else if(37==O)O=u&&x[P].type!=R||e&&x[P].capture!=U?76:51;else if(62==O)O=P<x.length?37:34;else{if(51==O)return true;if(76==O)++P,O=62;else if(67==O)P=0,O=19;else if(34==O)return false}},this.X)},function(L,U,e,u,R,x,P,O){for(O=90;79!=O;){if(7==O)return true;if(71==O)O=0==P.length?28:7;else if(28==O)delete this.X[x],this.YU--,O=7;else if(49==O)P=this.X[x],R=r(5,0,U,u,P,e),O=48;else if(37==O)O=x in this.X?49:53;else if(48==O)O=-1<R?26:97;else if(26==O)lq(69,42,true,P[R]),Array.prototype.splice.call(P,R,1),O=71;else if(90==O)x=L.toString(),O=37;else if(97==O||53==O)return false}}),zL.prototype).TV=function(L,U,e,u,R,x){return-(x=-(R=this.X[U.toString()],1),R&&(x=r(7,0,L,e,R,u)),1)<x?R[x]:null},Math.random())|0),VV={},WM=0,Yo=\"__closure_events_fn_\"+(1E9*Math.random()>>>0);((((((y(2,53,jY,Fr),jY.prototype)[Ie]=true,v=jY.prototype,v).C2=function(L){this.rX=L},v).addEventListener=function(L,U,e,u){bq(true,8,false,0,L,this,e,u,U)},v).removeEventListener=function(L,U,e,u){Z2(14,\"object\",0,u,e,this,U,L)},v).dispatchEvent=function(L,U,e,u,R,x,P,O,E,Q,D,m){for(m=28;64!=m;)if(85==m)m=R?88:39;else if(82==m)m=E.ia?34:60;else if(32==m)R=R.rX,m=85;else if(62==m)e=0,m=92;else if(67==m)m=!E.ia&&0<=e?11:82;else if(24==m)E=new Ms(E,x),m=53;else if(11==m)Q=E.currentTarget=U[e],O=JP(true,E,24,D,true,Q)&&O,m=31;else if(8==m)P=E,E=new Ms(D,x),kL(E,P),m=53;else if(31==m)e--,m=67;else if(84==m)u=[],m=33;else if(60==m)Q=E.currentTarget=x,O=JP(true,E,27,D,true,Q)&&O,E.ia||(O=JP(true,E,25,D,false,Q)&&O),m=34;else if(91==m)e++,m=12;else if(39==m)U=u,E=L,x=this.Sf,D=E.type||E,m=49;else if(92==m)m=12;else if(9==m)m=U?22:82;else if(28==m)R=this.rX,m=97;else if(12==m)m=!E.ia&&e<U.length?61:76;else if(88==m)u.push(R),m=32;else if(22==m)e=U.length-1,m=29;else if(49==m)m=\"string\"===typeof E?24:81;else if(97==m)m=R?84:39;else if(34==m)m=U?62:76;else if(61==m)Q=E.currentTarget=U[e],O=JP(true,E,26,D,false,Q)&&O,m=91;else if(53==m)O=true,m=9;else{if(76==m)return O;33==m?m=85:29==m?m=67:73==m?(E.target=E.target||x,m=53):81==m&&(m=E instanceof Ms?73:8)}},v.TV=function(L,U,e,u){return this.V.TV(L,String(U),e,u)},v).A=function(){this.rX=(jY.m.A.call(this),this.V&&y(0,5,true,this.V),null)},v.hasListener=function(L,U){return this.V.hasListener(void 0!==L?String(L):void 0,U)};var Ns;(((v=(y(2,23,eU,(((((((((v=xo.prototype,v).W=function(L,U){return\"string\"===(U=this.p2,typeof L)?U.getElementById(L):L},v.getElementsByTagName=function(L,U){return(U||this.p2).getElementsByTagName(String(L))},v).createElement=function(L,U,e){return\"application/xhtml+xml\"===(U=(e=this.p2,String(L)),e).contentType&&(U=U.toLowerCase()),e.createElement(U)},v.createTextNode=function(L){return this.p2.createTextNode(String(L))},v.appendChild=function(L,U){L.appendChild(U)},v).append=function(L,U){uu(arguments,1,\"object\",L,9==L.nodeType?L:L.ownerDocument||L.document,\"array\",\"string\")},v).canHaveChildren=function(L,U){for(U=13;10!=U;){if(14==U){switch(L.tagName){case \"APPLET\":case \"AREA\":case \"BASE\":case \"BR\":case \"COL\":case \"COMMAND\":case \"EMBED\":case \"FRAME\":case \"HR\":case \"IMG\":case \"INPUT\":case \"IFRAME\":case \"ISINDEX\":case \"KEYGEN\":case \"LINK\":case \"NOFRAMES\":case \"NOSCRIPT\":case \"META\":case \"OBJECT\":case \"PARAM\":case \"SCRIPT\":case \"SOURCE\":case \"STYLE\":case \"TRACK\":case \"WBR\":return false}return true}if(13==U)U=1!=L.nodeType?61:14;else if(61==U)return false}},v.removeNode=yY,v).contains=function(L,U,e){for(e=53;68!=e;){if(10==e)return false;if(53==e)e=L&&U?61:10;else if(61==e)e=L.contains&&1==U.nodeType?38:77;else{if(51==e)return U==L;if(77==e)e=\"undefined\"!=typeof L.compareDocumentPosition?87:52;else if(35==e)e=60;else{if(38==e)return L==U||L.contains(U);if(60==e)e=U&&L!=U?85:51;else if(85==e)U=U.parentNode,e=35;else if(52==e)e=60;else if(87==e)return L==U||!!(L.compareDocumentPosition(U)&16)}}}},t)(lu,57),lu.prototype).D8=0,lu).prototype.h$=\"\",jY)),eU).prototype,v.R6=lu.kU(),v.W=function(){return this.C},v.getParent=function(){return this.I},v).A=function(L){for(L=18;89!=L;)79==L?L=this.v?62:68:68==L?(PM(\"\",64,function(U){pw(35,U,22,true)},this),!this.lH&&this.C&&yY(this.C),this.SQ=this.I=this.C=this.yN=null,eU.m.A.call(this),L=89):62==L?(pw(35,this.v,21,true),delete this.v,L=68):18==L&&(this.Fp&&this.P(),L=79)},v.P=function(){this.Fp=((PM(\"\",65,function(L){L.Fp&&L.P()},this),this.v)&&y(0,3,true,this.v),false)},v).C2=function(L,U){for(U=53;26!=U;)if(70==U)eU.m.C2.call(this,L),U=26;else if(53==U)U=this.I&&this.I!=L?35:70;else if(35==U)throw Error(\"Method not supported\");},v).removeChild=function(L,U,e,u,R,x,P,O,E,Q,D,m,M){for(M=51;50!=M;)if(10==M)R.I=null,eU.m.C2.call(R,null),M=97;else if(39==M)M=m&&L?7:97;else if(56==M)R=L,M=26;else if(75==M)m=e,M=95;else if(33==M)P=this.yN,u=(null!==P&&m in P?P[m]:void 0)||null,M=13;else if(13==M)L=u,M=39;else if(72==M)e=L,M=75;else{if(71==M)throw Error(\"Unable to set parent component\");if(96==M)throw Error(\"Child is not in parent component\");if(7==M)E=this.yN,m in E&&delete E[m],sI(10,3,0,this.SQ,L),M=79;else if(53==M)u=null,M=13;else if(79==M)M=U?64:56;else if(51==M)M=L?16:97;else if(14==M)e=O,M=75;else if(95==M)M=this.yN&&m?33:53;else{if(60==M)return L;99==M?M=(O=L.QN)?14:29:64==M?(L.P(),L.C&&yY(L.C),M=56):26==M?M=null==R?71:10:16==M?M=\"string\"===typeof L?72:99:29==M?(Q=L.R6,D=L,x=Q.h$+\":\"+(Q.D8++).toString(36),O=D.QN=x,M=14):97==M&&(M=L?60:96)}}};var $L,iu={button:\"pressed\",checkbox:\"checked\",menuitem:\"selected\",menuitemcheckbox:\"checked\",menuitemradio:(t(na,59),\"checked\"),radio:\"checked\",tab:\"selected\",treeitem:\"selected\"},UF=((t(La,(y(2,(((((((v=na.prototype,v).OS=function(L,U,e,u,R,x,P,O,E){for(E=(P=99,74);;)try{if(3==P)break;else 64==P?P=L.S&32?83:26:99==P?P=L.Xp&32&&(e=L.eQ())?2:3:54==P?(E=6,e.blur(),P=33):33==P?(E=74,P=64):83==P?(L.dX&4&&L.Xp&4&&L.setActive(false),L.dX&32&&L.Xp&32&&QV(33,L,32,16,2,false)&&L.K(false,32),P=26):41==P?(E=74,P=33):75==P?(u.tabIndex=-1,u.removeAttribute(\"tabIndex\"),P=3):26==P?P=(x=e.hasAttribute(\"tabindex\"))?36:23:6==P?(u=e,P=14):25==P?(u.tabIndex=0,P=3):2==P?P=!U&&L.S&32?54:26:14==P?P=U?25:75:36==P?(R=e.tabIndex,x=\"number\"===typeof R&&0<=R&&32768>R,P=23):23==P&&(P=x!=U?6:3)}catch(Q){if(74==E)throw Q;6==E&&(O=Q,P=41)}},v).eQ=function(L){return L.W()},v).ES=function(){return\"goog-control\"},v).la=function(L,U,e,u,R,x,P){(x=L.getAttribute((u=($L||($L={1:\"disabled\",8:\"selected\",16:\"checked\",64:\"expanded\"}),$L[U]),\"role\"))||null)?(R=iu[x]||u,P=\"checked\"==u||\"selected\"==u?R:u):P=u,P&&t(\"aria-\",6,\"hidden\",e,P,L)},v).K=function(L,U,e,u,R,x,P){for(P=55;66!=P;)94==P?P=this.cz?38:41:39==P?P=R?94:66:38==P?((u=this.cz[L])&&this.AN(U,u,e),this.la(R,L,e),P=66):41==P?(x=this.ES(),x.replace(/\\\\xa0|\\\\s/g,\" \"),this.cz={1:x+\"-disabled\",2:x+\"-hover\",4:x+\"-active\",8:x+\"-selected\",16:x+\"-checked\",32:x+\"-focused\",64:x+\"-open\"},P=38):55==P&&(R=U.W(),P=39)},v).AN=function(L,U,e,u){(u=L.W?L.W():L)&&(e?al:N5)(u,[U])},21),La,na),56)),La).prototype.la=function(L,U,e){switch(U){case 8:case 16:t(\"aria-\",22,\"hidden\",e,\"pressed\",L);break;default:case 64:case 1:La.m.la.call(this,L,U,e)}},La.prototype.ES=function(){return\"goog-button\"},{});if(\"function\"!==((((((((((((v=(y(2,29,d,eU),d.prototype),v).dX=255,v).P=function(){(d.m.P.call(this),this).Rr&&this.Rr.detach(),this.isVisible()&&this.isEnabled()&&this.J.OS(this,false)},v).rb=0,v.Xp=39,v).S=0,v.A=function(L){for(L=91;74!=L;)91==L?(d.m.A.call(this),L=87):81==L?(pw(35,this.Rr,17,true),delete this.Rr,L=89):87==L?L=this.Rr?81:89:89==L&&(delete this.J,this.U=null,L=74)},v.t$=true,v.eQ=function(){return this.J.eQ(this)},v).AN=function(L,U,e){for(e=35;2!=e;)22==e?e=L&&this.U&&sI(10,5,0,this.U,L)?23:2:35==e?e=U?5:22:23==e?e=0==this.U.length?60:21:60==e?(this.U=null,e=21):5==e?e=L?0:2:21==e?(this.J.AN(this,L,false),e=2):0==e&&(this.U?b(64,0,L,this.U)||this.U.push(L):this.U=[L],this.J.AN(this,L,true),e=2)},v).U=null,v).isVisible=function(){return this.t$},v.isEnabled=function(){return!(this.S&1)},v).isActive=function(){return!!(this.S&4)},v).setActive=function(L){QV(33,this,4,17,2,L)&&this.K(L,4)},v).getState=function(){return this.S},v).K=function(L,U,e,u,R,x,P){for(P=44;68!=P;)11==P?(this.J.K(U,this,L),this.S=L?this.S|U:(x=this.S,(x|0)- -1+(~x|~U)),P=68):10==P?(R=!L,u=this.getParent(),P=22):37==P?P=R?17:34:44==P?P=e||1!=U?88:10:88==P?P=this.Xp&U&&L!=!!(this.S&U)?11:68:17==P?(this.isVisible()&&this.J.OS(this,R),this.K(!R,1,true),P=68):22==P?P=u&&\"function\"==typeof u.isEnabled&&!u.isEnabled()||!QV(33,this,1,20,2,!R)?68:37:34==P&&(this.setActive(false),QV(33,this,2,13,2,false)&&this.K(false,2),P=17)},typeof d))throw Error(\"Invalid component class \"+d);if(\"function\"!==typeof na)throw Error(\"Invalid renderer class \"+na);var SU=EI(15,d),SY={passive:true,capture:!(y(2,25,((t(AP,(y(2,(t(\"goog-control\",(UF[SU]=na,11),function(){return new d(null)}),31),AP,La),58)),AP.prototype).OS=function(){},AP.prototype.K=function(L,U,e,u,R){for(R=33;35!=R;)33==R?(AP.m.K.call(this,L,U,e),u=U.W(),R=81):56==R?(u.disabled=e,R=35):81==R&&(R=u&&1==L?56:35)},AP.prototype.la=function(){},QY),d),QY.prototype.A=function(){QY.m.A.call(this),delete this.fG,delete this.P5},t(\"goog-button\",16,function(){return new QY(null)}),0)},Cw=a.requestIdleCallback?function(L){requestIdleCallback(function(){L()},{timeout:4})}:a.setImmediate?function(L){setImmediate(L)}:function(L){setTimeout(L,0)},TM=String.fromCharCode(105,110,116,101,103,67,104,101,99,107,66,121,112,97,115,115),Ca=[],pa=[],$o=(g.prototype.pG=(g.prototype.xU=(g.prototype.LG=void 0,\"toString\"),false),[]),dO=[],OF=(g.prototype.xK=void 0,{}),TL=[],Il=[],vM=[],HM=[],hP=(((EF,function(){})(X8),zM,BR,xL,function(){})(sF),void 0),eY=((v=g.prototype,v).W5=function(L,U,e,u,R,x,P){return EI.call(this,17,L,U,e,u,R,x,P)},OF).constructor;v=(v.TZ=function(){return b.call(this,9)},v.FN=(v.uH=0,g.prototype.D=\"create\",v.zZ=function(){return bq.call(this,true,6)},v.Z8=function(L,U,e,u,R,x){return JP.call(this,L,U,8,e,u,R,x)},v.Z=(window.performance||{}).now?function(){return this.KG+window.performance.now()}:function(){return+new Date},function(L,U,e,u,R,x,P,O){return r.call(this,24,L,U,e,u,R,x,P,O)}),v.NU=function(L,U,e,u,R,x){return S.call(this,U,L,55,e,u,R,x)},g).prototype,v.H=function(L,U){return U=(hP=function(){return U==L?-34:22},L={},{}),function(e,u,R,x,P,O,E,Q,D,m,M,n,Y,K,c,Z,T,C,D2,B,p,fw,H,J,k,z,Kw,Re,W,w,GL,F,VY,hk,f,yV,A,q5,Jk){for(hk=(A=(F=60,f=66,undefined),false);;)try{if(20==f)break;else if(27==f)f=26;else if(42==f)f=x==Ca?59:84;else if(82==f)fw[K++]=P,f=71;else if(16==f)yV=WR(0,104,this,8001,e[1]),A=9,f=84;else{if(9==f)return yV;if(59==f){if(M=(GL=l(this,141),\"undefined\")!=typeof Symbol&&Symbol.iterator&&GL[Symbol.iterator])R=M.call(GL);else if(\"number\"==typeof GL.length)R={next:UI(17,3,0,GL)};else throw Error(String(GL)+\" is not an iterable or ArrayLike\");f=(n=R,O=n.next(),64)}else if(25==f)F=43,x=e[0],f=29;else if(98==f)F=43,M5(2,this,Jk,17),A=20,f=84;else if(22==f)F=2,E(),f=52;else if(91==f)f=x==dO?16:42;else if(84==f)F=60,U=C,f=51;else if(18==f)WR(0,104,this,e[2],e[1]),f=84;else if(51==f)undefined!==A?(f=A,A=undefined):f=20;else if(53==f)z=e[2],D=q(2,(B=l(this,404).length,-2*~(B&2)-(~B^2)+3*(~B&2)+3*(B|-3))),J=this.i,this.i=this,f=48;else if(88==f)f=x==vM?58:23;else if(74==f)f=undefined!==A?84:5;else if(87==f)fw[K++]=P&255,P>>=8,f=82;else if(8==f)F=43,f=52;else if(28==f)F=95,Re=atob(u),K=H=0,fw=[],f=27;else if(56==f)this.B=fw,this.l=this.B.length<<3,N(this,16,[0,0,0]),f=24;else if(24==f)F=43,rc(0,this,false,8001),f=84;else if(29==f)f=x==pa?17:88;else if(36==f)f=x==TL?18:91;else if(66==f)C=U,U=L,f=25;else if(26==f)f=H<Re.length?1:56;else if(79==f)f=255<P?87:82;else if(47==f)f=Z<p.length?97:95;else if(80==f)f=Q?96:14;else if(5==f)F=43,p=X8(2).concat(l(this,404)),p[1]=(D2=p[0],-1+(~D2&3)-(~D2|3)),p[3]=p[1]^D[0],p[4]=(c=p[1],w=D[1],-(c|0)-(w|0)+-2-2*~(c|w)),Q=this.YK(p),f=80;else if(17==f)u=e[1],f=28;else if(97==f)T=p[Z][this.xU](16),1==T.length&&(T=\"0\"+T),Q+=T,f=10;else if(52==f)O=n.next(),f=11;else if(60==f)f=47;else if(14==f)Z=0,Q=\"\",f=60;else if(11==f)f=O.done?73:67;else{if(81==f)return yV;if(48==f)F=17,m=l(this,29),0<m.length&&h(q(2,m.length).concat(m),404,this,15),h(q(1,this.Zl),404,this,104),h(q(1,this[HM].length),404,this),W=0,W-=(k=l(this,404).length,2*(k|5)- -1+(~k^5)),W+=l(this,399)&2047,Y=l(this,325),4<Y.length&&(W-=(Y.length|0)+3),0<W&&h(q(2,W).concat(X8(W)),404,this,10),4<Y.length&&h(q(2,Y.length).concat(Y),404,this,153),f=19;else if(95==f)Kw=Q,l(this,404).length=z.shift(),l(this,325).length=z.shift(),l(this,389).length=z.shift(),l(this,131)[0]=z.shift(),l(this,11).length=z.shift(),yV=Kw,A=81,f=84;else if(1==f)P=Re.charCodeAt(H),f=79;else if(23==f)f=x==HM?53:36;else if(10==f)Z++,f=47;else if(71==f)H++,f=26;else if(64==f)f=11;else if(96==f)Q=\"!\"+Q,f=95;else if(67==f)E=O.value,f=22;else if(19==f)F=43,this.i=J,f=74;else if(73==f)GL.length=0,f=84;else if(58==f)e[1].push(l(this,404).length,l(this,325).length,l(this,389).length,l(this,131)[0],l(this,11).length),N(this,138,e[2]),this.G[287]&&WR(0,104,this,8001,l(this,287)),f=84;else if(94==f)throw VY;}}}catch(rO){if((VY=rO,60)==F)throw rO;95==F?(Jk=rO,f=98):43==F?(A=94,f=84):17==F?(A=94,f=19):2==F&&(q5=rO,f=8)}}}();var Ka,GM=(v.sS=(v.YK=(v.ef=0,function(L,U,e,u,R){return t.call(this,L,8,U,e,u,R)}),function(){return gO.call(this,20,8,32)}),v.gb=(g.prototype[Il]=[0,0,1,1,0,1,1],0),/./),dc=pa.pop.bind(g.prototype[vM]),cR=function(L,U){return(U=F8(64,77,83,36,\"bg\",\"error\",null))&&1===L.eval(U.createScript(\"1\"))?function(e){return U.createScript(e)}:function(e){return\"\"+e}}(((Ka=(GM[g.prototype.xU]=dc,UI(17,10,g.prototype.D,{get:dc})),g).prototype.Vx=void 0,a));return(function(L){return g.prototype.Vx=L,wc});}).call(this);'].join('\\n')))(e)(R.substr(0,c),U,M,Y,n),m[1]),D=m[0];break}else 63==L?L=P?7:78:90==L?(V=15,K=\"FNL\"+p,L=78):53==L&&(K=\"FNL\"+e,L=63)}catch(Z){if(15==V)throw Z;29==V&&(p=Z,L=90)}}),[function(P){return D?D(P):\"FNL~\"},function(P){f&&f(P)}]};}).call(this); (function(){'use strict';var d=function(a){var b=0;return function(){return b<a.length?{done:!1,value:a[b++]}:{done:!0}}},f=function(){var a=document.querySelectorAll('div[data-button-type=\"multipleChoiceIdentifier\"]'),b=\"undefined\"!=typeof Symbol&&Symbol.iterator&&a[Symbol.iterator];if(b)return b.call(a);if(\"number\"==typeof a.length)return{next:d(a)};throw Error(String(a)+\" is not an iterable or ArrayLike\");};/* Copyright The Closure Library Authors. SPDX-License-Identifier: Apache-2.0*/var l=function(){this.i=new window.botguard.bg(k,function(){});this.h=this.g=null;this.i&&window.addEventListener(\"load\",this.j.bind(this))};l.prototype.j=function(){var a=this;this.g=document.getElementById(\"hiddenMultipleChoiceIdentifier\");this.h=function(){a.i.invoke(a.l)};this.g?m(this):document.addEventListener(\"submit\",this.h.bind(this))};l.prototype.l=function(a){var b=document.getElementById(\"bgresponse\");b&&(b.value=a)};var m=function(a){for(var b=function(e){a.g&&(a.g.value=e);a.h()},q=function(e,p){13===p.keyCode&&(a.g&&(a.g.value=e),a.h())},g=f(),c=g.next();!c.done;c=g.next()){c=c.value.getElementsByTagName(\"button\")[0];var h=c.value;c.addEventListener(\"click\",b.bind(a,h));c.addEventListener(\"keydown\",q.bind(a,h))}},n=document.getElementById(\"program\");if(n){var k=n.getAttribute(\"program-data\");k&&new l};}).call(this); (function(){'use strict';var aa=function(a){var b=0;return function(){return b<a.length?{done:!1,value:a[b++]}:{done:!0}}},n=\"function\"==typeof Object.defineProperties?Object.defineProperty:function(a,b,c){if(a==Array.prototype||a==Object.prototype)return a;a[b]=c.value;return a},ba=function(a){a=[\"object\"==typeof globalThis&&globalThis,a,\"object\"==typeof window&&window,\"object\"==typeof self&&self,\"object\"==typeof global&&global];for(var b=0;b<a.length;++b){var c=a[b];if(c&&c.Math==Math)return c}throw Error(\"Cannot find global object\");},ca=ba(this),p=function(a,b){if(b)a:{var c=ca;a=a.split(\".\");for(var d=0;d<a.length-1;d++){var e=a[d];if(!(e in c))break a;c=c[e]}a=a[a.length-1];d=c[a];b=b(d);b!=d&&null!=b&&n(c,a,{configurable:!0,writable:!0,value:b})}};p(\"Symbol\",function(a){if(a)return a;var b=function(f,k){this.g=f;n(this,\"description\",{configurable:!0,writable:!0,value:k})};b.prototype.toString=function(){return this.g};var c=\"jscomp_symbol_\"+(1E9*Math.random()>>>0)+\"_\",d=0,e=function(f){if(this instanceof e)throw new TypeError(\"Symbol is not a constructor\");return new b(c+(f||\"\")+\"_\"+d++,f)};return e});p(\"Symbol.iterator\",function(a){if(a)return a;a=Symbol(\"Symbol.iterator\");for(var b=\"Array Int8Array Uint8Array Uint8ClampedArray Int16Array Uint16Array Int32Array Uint32Array Float32Array Float64Array\".split(\" \"),c=0;c<b.length;c++){var d=ca[b[c]];\"function\"===typeof d&&\"function\"!=typeof d.prototype[a]&&n(d.prototype,a,{configurable:!0,writable:!0,value:function(){return da(aa(this))}})}return a});var da=function(a){a={next:a};a[Symbol.iterator]=function(){return this};return a},q=function(a){var b=\"undefined\"!=typeof Symbol&&Symbol.iterator&&a[Symbol.iterator];if(b)return b.call(a);if(\"number\"==typeof a.length)return{next:aa(a)};throw Error(String(a)+\" is not an iterable or ArrayLike\");},r=function(a,b){return Object.prototype.hasOwnProperty.call(a,b)};p(\"WeakMap\",function(a){function b(){}function c(h){var l=typeof h;return\"object\"===l&&null!==h||\"function\"===l}function d(h){if(!r(h,f)){var l=new b;n(h,f,{value:l})}}function e(h){var l=Object[h];l&&(Object[h]=function(m){if(m instanceof b)return m;Object.isExtensible(m)&&d(m);return l(m)})}if(function(){if(!a||!Object.seal)return!1;try{var h=Object.seal({}),l=Object.seal({}),m=new a([[h,2],[l,3]]);if(2!=m.get(h)||3!=m.get(l))return!1;m.delete(h);m.set(l,4);return!m.has(h)&&4==m.get(l)}catch(F){return!1}}())return a;var f=\"$jscomp_hidden_\"+Math.random();e(\"freeze\");e(\"preventExtensions\");e(\"seal\");var k=0,g=function(h){this.g=(k+=Math.random()+1).toString();if(h){h=q(h);for(var l;!(l=h.next()).done;)l=l.value,this.set(l[0],l[1])}};g.prototype.set=function(h,l){if(!c(h))throw Error(\"Invalid WeakMap key\");d(h);if(!r(h,f))throw Error(\"WeakMap key fail: \"+h);h[f][this.g]=l;return this};g.prototype.get=function(h){return c(h)&&r(h,f)?h[f][this.g]:void 0};g.prototype.has=function(h){return c(h)&&r(h,f)&&r(h[f],this.g)};g.prototype.delete=function(h){return c(h)&&r(h,f)&&r(h[f],this.g)?delete h[f][this.g]:!1};return g});p(\"Map\",function(a){if(function(){if(!a||\"function\"!=typeof a||!a.prototype.entries||\"function\"!=typeof Object.seal)return!1;try{var g=Object.seal({x:4}),h=new a(q([[g,\"s\"]]));if(\"s\"!=h.get(g)||1!=h.size||h.get({x:4})||h.set({x:4},\"t\")!=h||2!=h.size)return!1;var l=h.entries(),m=l.next();if(m.done||m.value[0]!=g||\"s\"!=m.value[1])return!1;m=l.next();return m.done||4!=m.value[0].x||\"t\"!=m.value[1]||!l.next().done?!1:!0}catch(F){return!1}}())return a;var b=new WeakMap,c=function(g){this[0]={};this[1]=f();this.size=0;if(g){g=q(g);for(var h;!(h=g.next()).done;)h=h.value,this.set(h[0],h[1])}};c.prototype.set=function(g,h){g=0===g?0:g;var l=d(this,g);l.list||(l.list=this[0][l.id]=[]);l.m?l.m.value=h:(l.m={next:this[1],v:this[1].v,head:this[1],key:g,value:h},l.list.push(l.m),this[1].v.next=l.m,this[1].v=l.m,this.size++);return this};c.prototype.delete=function(g){g=d(this,g);return g.m&&g.list?(g.list.splice(g.index,1),g.list.length||delete this[0][g.id],g.m.v.next=g.m.next,g.m.next.v=g.m.v,g.m.head=null,this.size--,!0):!1};c.prototype.clear=function(){this[0]={};this[1]=this[1].v=f();this.size=0};c.prototype.has=function(g){return!!d(this,g).m};c.prototype.get=function(g){return(g=d(this,g).m)&&g.value};c.prototype.entries=function(){return e(this,function(g){return[g.key,g.value]})};c.prototype.keys=function(){return e(this,function(g){return g.key})};c.prototype.values=function(){return e(this,function(g){return g.value})};c.prototype.forEach=function(g,h){for(var l=this.entries(),m;!(m=l.next()).done;)m=m.value,g.call(h,m[1],m[0],this)};c.prototype[Symbol.iterator]=c.prototype.entries;var d=function(g,h){var l=h&&typeof h;\"object\"==l||\"function\"==l?b.has(h)?l=b.get(h):(l=\"\"+ ++k,b.set(h,l)):l=\"p_\"+h;var m=g[0][l];if(m&&r(g[0],l))for(g=0;g<m.length;g++){var F=m[g];if(h!==h&&F.key!==F.key||h===F.key)return{id:l,list:m,index:g,m:F}}return{id:l,list:m,index:-1,m:void 0}},e=function(g,h){var l=g[1];return da(function(){if(l){for(;l.head!=g[1];)l=l.v;for(;l.next!=l.head;)return l=l.next,{done:!1,value:h(l)};l=null}return{done:!0,value:void 0}})},f=function(){var g={};return g.v=g.next=g.head=g},k=0;return c});p(\"Array.prototype.find\",function(a){return a?a:function(b,c){a:{var d=this;d instanceof String&&(d=String(d));for(var e=d.length,f=0;f<e;f++){var k=d[f];if(b.call(c,k,f,d)){b=k;break a}}b=void 0}return b}});var ea=function(a,b){a instanceof String&&(a+=\"\");var c=0,d=!1,e={next:function(){if(!d&&c<a.length){var f=c++;return{value:b(f,a[f]),done:!1}}d=!0;return{done:!0,value:void 0}}};e[Symbol.iterator]=function(){return e};return e};p(\"Array.prototype.entries\",function(a){return a?a:function(){return ea(this,function(b,c){return[b,c]})}});p(\"Array.prototype.keys\",function(a){return a?a:function(){return ea(this,function(b){return b})}});p(\"Array.prototype.values\",function(a){return a?a:function(){return ea(this,function(b,c){return c})}});p(\"Array.from\",function(a){return a?a:function(b,c,d){c=null!=c?c:function(g){return g};var e=[],f=\"undefined\"!=typeof Symbol&&Symbol.iterator&&b[Symbol.iterator];if(\"function\"==typeof f){b=f.call(b);for(var k=0;!(f=b.next()).done;)e.push(c.call(d,f.value,k++))}else for(f=b.length,k=0;k<f;k++)e.push(c.call(d,b[k],k));return e}});/* Copyright The Closure Library Authors. SPDX-License-Identifier: Apache-2.0*/var fa=fa||{},t=this||self,ha=function(a){var b=typeof a;return\"object\"!=b?b:a?Array.isArray(a)?\"array\":b:\"null\"},u=function(a){var b=typeof a;return\"object\"==b&&null!=a||\"function\"==b},ia=function(a,b,c){return a.call.apply(a.bind,arguments)},ja=function(a,b,c){if(!a)throw Error();if(2<arguments.length){var d=Array.prototype.slice.call(arguments,2);return function(){var e=Array.prototype.slice.call(arguments);Array.prototype.unshift.apply(e,d);return a.apply(b,e)}}return function(){return a.apply(b,arguments)}},v=function(a,b,c){v=Function.prototype.bind&&-1!=Function.prototype.bind.toString().indexOf(\"native code\")?ia:ja;return v.apply(null,arguments)},w=function(a,b){function c(){}c.prototype=b.prototype;a.P=b.prototype;a.prototype=new c;a.prototype.constructor=a;a.ja=function(d,e,f){for(var k=Array(arguments.length-2),g=2;g<arguments.length;g++)k[g-2]=arguments[g];return b.prototype[e].apply(d,k)}};var ka=String.prototype.trim?function(a){return a.trim()}:function(a){return/^[\\s\\xa0]*([\\s\\S]*?)[\\s\\xa0]*$/.exec(a)[1]};function x(a,b){if(Error.captureStackTrace)Error.captureStackTrace(this,x);else{var c=Error().stack;c&&(this.stack=c)}a&&(this.message=String(a));void 0!==b&&(this.cause=b)}w(x,Error);x.prototype.name=\"CustomError\";function y(a,b){a=a.split(\"%s\");for(var c=\"\",d=a.length-1,e=0;e<d;e++)c+=a[e]+(e<b.length?b[e]:\"%s\");x.call(this,c+a[d])}w(y,x);y.prototype.name=\"AssertionError\";function la(a,b,c,d){var e=\"Assertion failed\";if(c){e+=\": \"+c;var f=d}else a&&(e+=\": \"+a,f=b);throw new y(\"\"+e,f||[]);}var z=function(a,b,c){a||la(\"\",null,b,Array.prototype.slice.call(arguments,2))},ma=function(a,b){throw new y(\"Failure\"+(a?\": \"+a:\"\"),Array.prototype.slice.call(arguments,1));},A=function(a,b,c){\"number\"!==typeof a&&la(\"Expected number but got %s: %s.\",[ha(a),a],b,Array.prototype.slice.call(arguments,2));return a};var na=Array.prototype.indexOf?function(a,b){z(null!=a.length);return Array.prototype.indexOf.call(a,b,void 0)}:function(a,b){if(\"string\"===typeof a)return\"string\"!==typeof b||1!=b.length?-1:a.indexOf(b,0);for(var c=0;c<a.length;c++)if(c in a&&a[c]===b)return c;return-1};function oa(a,b){b=na(a,b);var c;if(c=0<=b)z(null!=a.length),Array.prototype.splice.call(a,b,1);return c};var pa=\"constructor hasOwnProperty isPrototypeOf propertyIsEnumerable toLocaleString toString valueOf\".split(\" \");function qa(a,b){for(var c,d,e=1;e<arguments.length;e++){d=arguments[e];for(c in d)a[c]=d[c];for(var f=0;f<pa.length;f++)c=pa[f],Object.prototype.hasOwnProperty.call(d,c)&&(a[c]=d[c])}};var C=function(a,b){if(b!==B)throw Error(\"SafeUrl is not meant to be built directly\");this.g=a};C.prototype.toString=function(){return this.g.toString()};var B={};new C(\"about:invalid#zClosurez\",B);new C(\"about:blank\",B);var ra={},sa=function(){if(ra!==ra)throw Error(\"SafeStyle is not meant to be built directly\");};sa.prototype.toString=function(){return\"\".toString()};new sa;var ta={},ua=function(){if(ta!==ta)throw Error(\"SafeStyleSheet is not meant to be built directly\");};ua.prototype.toString=function(){return\"\".toString()};new ua;var va,D;a:{for(var wa=[\"CLOSURE_FLAGS\"],E=t,xa=0;xa<wa.length;xa++)if(E=E[wa[xa]],null==E){D=null;break a}D=E}var ya=D&&D[610401301];va=null!=ya?ya:!1;function G(){var a=t.navigator;return a&&(a=a.userAgent)?a:\"\"}var za,Aa=t.navigator;za=Aa?Aa.userAgentData||null:null;var Ba={},Ca=function(){var a=t.trustedTypes&&t.trustedTypes.emptyHTML||\"\";if(Ba!==Ba)throw Error(\"SafeHtml is not meant to be built directly\");this.g=a};Ca.prototype.toString=function(){return this.g.toString()};new Ca;/* SPDX-License-Identifier: Apache-2.0*/new C(\"about:blank\",B);var Da=new C(\"about:invalid#zClosurez\",B);var Ea=function(a){this.ga=a};function H(a){return new Ea(function(b){return b.substr(0,a.length+1).toLowerCase()===a+\":\"})}var Fa=[H(\"data\"),H(\"http\"),H(\"https\"),H(\"mailto\"),H(\"ftp\"),new Ea(function(a){return/^[^:]*([/?#]|$)/.test(a)})],Ga=/^\\s*(?!javascript:)(?:[a-z0-9+.-]+:|[^:\\/?#]*(?:[\\/?#]|$))/i,Ha=[],Ia=function(){};Ja(function(a){console.warn(\"A URL with content '\"+a+\"' was sanitized away.\")});function Ja(a){-1===Ha.indexOf(a)&&Ha.push(a);Ia=function(b){Ha.forEach(function(c){c(b)})}};var Ka=Object.freeze||function(a){return a};var I=function(a,b){this.name=a;this.value=b};I.prototype.toString=function(){return this.name};var J=new I(\"OFF\",Infinity),La=new I(\"SEVERE\",1E3),Ma=new I(\"CONFIG\",700),Na=new I(\"FINE\",500),Oa=function(){},Pa,Qa=function(a,b,c){this.reset(a||J,b,c,void 0,void 0)};Qa.prototype.reset=function(){};var Ra=function(a,b){this.g=null;this.l=[];this.h=(void 0===b?null:b)||null;this.j=[];this.o={g:function(){return a}}},Sa=function(a){if(a.g)return a.g;if(a.h)return Sa(a.h);ma(\"Root logger has no level set.\");return J},Ta=function(a,b){for(;a;)a.l.forEach(function(c){c(b)}),a=a.h},Ua=function(){this.entries={};var a=new Ra(\"\");a.g=Ma;this.entries[\"\"]=a},Va,K=function(a,b){var c=a.entries[b];if(c)return c;c=K(a,b.slice(0,Math.max(b.lastIndexOf(\".\"),0)));var d=new Ra(b,c);a.entries[b]=d;c.j.push(d);return d},Wa=function(){Va||(Va=new Ua);return Va},Xa=function(a,b,c){var d;if(d=a)if(d=a&&b){d=b.value;var e=a?Sa(K(Wa(),a.g())):J;d=d>=e.value}d&&(b=b||J,d=K(Wa(),a.g()),\"function\"===typeof c&&(c=c()),Pa||(Pa=new Oa),a=new Qa(b,c,a.g()),Ta(d,a))},Ya=function(a,b){a&&Xa(a,La,b)},L=function(a,b){a&&Xa(a,Na,b)};var M=function(){this.g=(\"undefined\"==typeof document?null:document)||{cookie:\"\"}};M.prototype.set=function(a,b,c){var d=!1;if(\"object\"===typeof c){var e=c.la;d=c.ma||!1;var f=c.domain||void 0;var k=c.path||void 0;var g=c.ka}if(/[;=\\s]/.test(a))throw Error('Invalid cookie name \"'+a+'\"');if(/[;\\r\\n]/.test(b))throw Error('Invalid cookie value \"'+b+'\"');void 0===g&&(g=-1);this.g.cookie=a+\"=\"+b+(f?\";domain=\"+f:\"\")+(k?\";path=\"+k:\"\")+(0>g?\"\":0==g?\";expires=\"+(new Date(1970,1,1)).toUTCString():\";expires=\"+(new Date(Date.now()+1E3*g)).toUTCString())+(d?\";secure\":\"\")+(null!=e?\";samesite=\"+e:\"\")};M.prototype.get=function(a,b){for(var c=a+\"=\",d=(this.g.cookie||\"\").split(\";\"),e=0,f;e<d.length;e++){f=ka(d[e]);if(0==f.lastIndexOf(c,0))return f.slice(c.length);if(f==a)return\"\"}return b};M.prototype.o=function(){for(var a=(this.g.cookie||\"\").split(\";\"),b=[],c=[],d,e,f=0;f<a.length;f++)e=ka(a[f]),d=e.indexOf(\"=\"),-1==d?(b.push(\"\"),c.push(e)):(b.push(e.substring(0,d)),c.push(e.substring(d+1)));return c};var Za=new M;var $a=function(){this.H=this.H;this.g=this.g};$a.prototype.H=!1;$a.prototype.G=function(){if(this.g)for(;this.g.length;)this.g.shift()()};var N=function(a,b){this.type=a;this.g=this.target=b;this.defaultPrevented=!1};N.prototype.h=function(){this.defaultPrevented=!0};var ab=function(){if(!t.addEventListener||!Object.defineProperty)return!1;var a=!1,b=Object.defineProperty({},\"passive\",{get:function(){a=!0}});try{var c=function(){};t.addEventListener(\"test\",c,b);t.removeEventListener(\"test\",c,b)}catch(d){}return a}();var bb=function(a){bb[\" \"](a);return a};bb[\" \"]=function(){};var cb=va&&za&&0<za.brands.length?!1:-1!=G().indexOf(\"Trident\")||-1!=G().indexOf(\"MSIE\"),db=-1!=G().indexOf(\"Gecko\")&&!(-1!=G().toLowerCase().indexOf(\"webkit\")&&-1==G().indexOf(\"Edge\"))&&!(-1!=G().indexOf(\"Trident\")||-1!=G().indexOf(\"MSIE\"))&&-1==G().indexOf(\"Edge\");var O=function(a,b){N.call(this,a?a.type:\"\");this.relatedTarget=this.g=this.target=null;this.button=this.screenY=this.screenX=this.clientY=this.clientX=0;this.key=\"\";this.metaKey=this.shiftKey=this.altKey=this.ctrlKey=!1;this.state=null;this.pointerId=0;this.pointerType=\"\";this.j=null;if(a){var c=this.type=a.type,d=a.changedTouches&&a.changedTouches.length?a.changedTouches[0]:null;this.target=a.target||a.srcElement;this.g=b;if(b=a.relatedTarget){if(db){a:{try{bb(b.nodeName);var e=!0;break a}catch(f){}e=!1}e||(b=null)}}else\"mouseover\"==c?b=a.fromElement:\"mouseout\"==c&&(b=a.toElement);this.relatedTarget=b;d?(this.clientX=void 0!==d.clientX?d.clientX:d.pageX,this.clientY=void 0!==d.clientY?d.clientY:d.pageY,this.screenX=d.screenX||0,this.screenY=d.screenY||0):(this.clientX=void 0!==a.clientX?a.clientX:a.pageX,this.clientY=void 0!==a.clientY?a.clientY:a.pageY,this.screenX=a.screenX||0,this.screenY=a.screenY||0);this.button=a.button;this.key=a.key||\"\";this.ctrlKey=a.ctrlKey;this.altKey=a.altKey;this.shiftKey=a.shiftKey;this.metaKey=a.metaKey;this.pointerId=a.pointerId||0;this.pointerType=\"string\"===typeof a.pointerType?a.pointerType:eb[a.pointerType]||\"\";this.state=a.state;this.j=a;a.defaultPrevented&&O.P.h.call(this)}};w(O,N);var eb=Ka({2:\"touch\",3:\"pen\",4:\"mouse\"});O.prototype.h=function(){O.P.h.call(this);var a=this.j;a.preventDefault?a.preventDefault():a.returnValue=!1};var P=\"closure_listenable_\"+(1E6*Math.random()|0);var fb=0;var gb=function(a,b,c,d,e){this.listener=a;this.proxy=null;this.src=b;this.type=c;this.capture=!!d;this.M=e;this.key=++fb;this.J=this.L=!1},hb=function(a){a.J=!0;a.listener=null;a.proxy=null;a.src=null;a.M=null};var ib=function(a){this.src=a;this.g={};this.h=0};ib.prototype.add=function(a,b,c,d,e){var f=a.toString();a=this.g[f];a||(a=this.g[f]=[],this.h++);var k=jb(a,b,d,e);-1<k?(b=a[k],c||(b.L=!1)):(b=new gb(b,this.src,f,!!d,e),b.L=c,a.push(b));return b};var kb=function(a,b){var c=b.type;c in a.g&&oa(a.g[c],b)&&(hb(b),0==a.g[c].length&&(delete a.g[c],a.h--))},jb=function(a,b,c,d){for(var e=0;e<a.length;++e){var f=a[e];if(!f.J&&f.listener==b&&f.capture==!!c&&f.M==d)return e}return-1};var lb=\"closure_lm_\"+(1E6*Math.random()|0),mb={},nb=0,pb=function(a,b,c,d,e){if(d&&d.once)ob(a,b,c,d,e);else if(Array.isArray(b))for(var f=0;f<b.length;f++)pb(a,b[f],c,d,e);else c=qb(c),a&&a[P]?(d=u(d)?!!d.capture:!!d,rb(a),a.u.add(String(b),c,!1,d,e)):sb(a,b,c,!1,d,e)},sb=function(a,b,c,d,e,f){if(!b)throw Error(\"Invalid event type\");var k=u(e)?!!e.capture:!!e,g=tb(a);g||(a[lb]=g=new ib(a));c=g.add(b,c,d,k,f);if(!c.proxy){d=ub();c.proxy=d;d.src=a;d.listener=c;if(a.addEventListener)ab||(e=k),void 0===e&&(e=!1),a.addEventListener(b.toString(),d,e);else if(a.attachEvent)a.attachEvent(vb(b.toString()),d);else if(a.addListener&&a.removeListener)z(\"change\"===b,\"MediaQueryList only has a change event\"),a.addListener(d);else throw Error(\"addEventListener and attachEvent are unavailable.\");nb++}},ub=function(){var a=wb,b=function(c){return a.call(b.src,b.listener,c)};return b},ob=function(a,b,c,d,e){if(Array.isArray(b))for(var f=0;f<b.length;f++)ob(a,b[f],c,d,e);else c=qb(c),a&&a[P]?a.u.add(String(b),c,!0,u(d)?!!d.capture:!!d,e):sb(a,b,c,!0,d,e)},xb=function(a,b,c,d,e){if(Array.isArray(b))for(var f=0;f<b.length;f++)xb(a,b[f],c,d,e);else(d=u(d)?!!d.capture:!!d,c=qb(c),a&&a[P])?(a=a.u,b=String(b).toString(),b in a.g&&(f=a.g[b],c=jb(f,c,d,e),-1<c&&(hb(f[c]),z(null!=f.length),Array.prototype.splice.call(f,c,1),0==f.length&&(delete a.g[b],a.h--)))):a&&(a=tb(a))&&(b=a.g[b.toString()],a=-1,b&&(a=jb(b,c,d,e)),(c=-1<a?b[a]:null)&&yb(c))},yb=function(a){if(\"number\"!==typeof a&&a&&!a.J){var b=a.src;if(b&&b[P])kb(b.u,a);else{var c=a.type,d=a.proxy;b.removeEventListener?b.removeEventListener(c,d,a.capture):b.detachEvent?b.detachEvent(vb(c),d):b.addListener&&b.removeListener&&b.removeListener(d);nb--;(c=tb(b))?(kb(c,a),0==c.h&&(c.src=null,b[lb]=null)):hb(a)}}},vb=function(a){return a in mb?mb[a]:mb[a]=\"on\"+a},wb=function(a,b){if(a.J)a=!0;else{b=new O(b,this);var c=a.listener,d=a.M||a.src;a.L&&yb(a);a=c.call(d,b)}return a},tb=function(a){a=a[lb];return a instanceof ib?a:null},zb=\"__closure_events_fn_\"+(1E9*Math.random()>>>0),qb=function(a){z(a,\"Listener can not be null.\");if(\"function\"===typeof a)return a;z(a.handleEvent,\"An object listener must have handleEvent method.\");a[zb]||(a[zb]=function(b){return a.handleEvent(b)});return a[zb]};var Q=function(){$a.call(this);this.u=new ib(this);this.j=this;this.h=null};w(Q,$a);Q.prototype[P]=!0;Q.prototype.addEventListener=function(a,b,c,d){pb(this,a,b,c,d)};Q.prototype.removeEventListener=function(a,b,c,d){xb(this,a,b,c,d)};Q.prototype.dispatchEvent=function(a){rb(this);var b=this.h;if(b){var c=[];for(var d=1;b;b=b.h)c.push(b),z(1E3>++d,\"infinite loop\")}b=this.j;d=a.type||a;if(\"string\"===typeof a)a=new N(a,b);else if(a instanceof N)a.target=a.target||b;else{var e=a;a=new N(d,b);qa(a,e)}e=!0;if(c)for(var f=c.length-1;0<=f;f--){var k=a.g=c[f];e=Ab(k,d,!0,a)&&e}k=a.g=b;e=Ab(k,d,!0,a)&&e;e=Ab(k,d,!1,a)&&e;if(c)for(f=0;f<c.length;f++)k=a.g=c[f],e=Ab(k,d,!1,a)&&e;return e};Q.prototype.G=function(){Q.P.G.call(this);if(this.u){var a=this.u,b=0,c;for(c in a.g){for(var d=a.g[c],e=0;e<d.length;e++)++b,hb(d[e]);delete a.g[c];a.h--}}this.h=null};var Ab=function(a,b,c,d){b=a.u.g[String(b)];if(!b)return!0;b=b.concat();for(var e=!0,f=0;f<b.length;++f){var k=b[f];if(k&&!k.J&&k.capture==c){var g=k.listener,h=k.M||k.src;k.L&&kb(a.u,k);e=!1!==g.call(h,d)&&e}}return e&&!d.defaultPrevented},rb=function(a){z(a.u,\"Event target is not initialized. Did you call the superclass (goog.events.EventTarget) constructor?\")};var Bb=function(){};Bb.prototype.g=null;var Db=function(a){var b;(b=a.g)||(b={},Cb(a)&&(b[0]=!0,b[1]=!0),b=a.g=b);return b};var Eb,Fb=function(){};w(Fb,Bb);var Gb=function(a){return(a=Cb(a))?new ActiveXObject(a):new XMLHttpRequest},Cb=function(a){if(!a.h&&\"undefined\"==typeof XMLHttpRequest&&\"undefined\"!=typeof ActiveXObject){for(var b=[\"MSXML2.XMLHTTP.6.0\",\"MSXML2.XMLHTTP.3.0\",\"MSXML2.XMLHTTP\",\"Microsoft.XMLHTTP\"],c=0;c<b.length;c++){var d=b[c];try{return new ActiveXObject(d),a.h=d}catch(e){}}throw Error(\"Could not create ActiveXObject. ActiveX might be disabled, or MSXML might not be installed\");}return a.h};Eb=new Fb;var Hb=function(a,b,c){if(\"function\"===typeof a)c&&(a=v(a,c));else if(a&&\"function\"==typeof a.handleEvent)a=v(a.handleEvent,a);else throw Error(\"Invalid listener argument\");return 2147483647<Number(b)?-1:t.setTimeout(a,b||0)};var Ib=RegExp(\"^(?:([^:/?#.]+):)?(?://(?:([^\\\\\\\\/?#]*)@)?([^\\\\\\\\/?#]*?)(?::([0-9]+))?(?=[\\\\\\\\/?#]|$))?([^?#]+)?(?:\\\\?([^#]*))?(?:#([\\\\s\\\\S]*))?$\"),Jb=function(a,b){if(a){a=a.split(\"&\");for(var c=0;c<a.length;c++){var d=a[c].indexOf(\"=\"),e=null;if(0<=d){var f=a[c].substring(0,d);e=a[c].substring(d+1)}else f=a[c];b(f,e?decodeURIComponent(e.replace(/\\+/g,\" \")):\"\")}}};var R=function(a){Q.call(this);this.headers=new Map;this.U=a||null;this.A=!1;this.T=this.i=null;this.I=this.Z=this.O=\"\";this.B=this.X=this.N=this.W=!1;this.K=0;this.R=null;this.ca=\"\";this.S=this.ia=this.ea=!1;this.V=this.Y=null};w(R,Q);R.prototype.s=K(Wa(),\"goog.net.XhrIo\").o;var Kb=/^https?$/i,Lb=[\"POST\",\"PUT\"],Mb=[];R.prototype.fa=function(){this.H||(this.H=!0,this.G());oa(Mb,this)};R.prototype.setTrustToken=function(a){this.Y=a};R.prototype.setAttributionReporting=function(a){this.V=a};R.prototype.send=function(a,b,c,d){if(this.i)throw Error(\"[goog.net.XhrIo] Object is active with another request=\"+this.O+\"; newUri=\"+a);b=b?b.toUpperCase():\"GET\";this.O=a;this.I=\"\";this.Z=b;this.W=!1;this.A=!0;this.i=this.U?Gb(this.U):Gb(Eb);this.T=this.U?Db(this.U):Db(Eb);this.i.onreadystatechange=v(this.ba,this);this.ia&&\"onprogress\"in this.i&&(this.i.onprogress=v(function(k){this.aa(k,!0)},this),this.i.upload&&(this.i.upload.onprogress=v(this.aa,this)));try{L(this.s,S(this,\"Opening Xhr\")),this.X=!0,this.i.open(b,String(a),!0),this.X=!1}catch(k){L(this.s,S(this,\"Error opening Xhr: \"+k.message));Nb(this,k);return}a=c||\"\";c=new Map(this.headers);if(d)if(Object.getPrototypeOf(d)===Object.prototype)for(var e in d)c.set(e,d[e]);else if(\"function\"===typeof d.keys&&\"function\"===typeof d.get){e=q(d.keys());for(var f=e.next();!f.done;f=e.next())f=f.value,c.set(f,d.get(f))}else throw Error(\"Unknown input type for opt_headers: \"+String(d));d=Array.from(c.keys()).find(function(k){return\"content-type\"==k.toLowerCase()});e=t.FormData&&a instanceof t.FormData;!(0<=na(Lb,b))||d||e||c.set(\"Content-Type\",\"application/x-www-form-urlencoded;charset=utf-8\");b=q(c);for(d=b.next();!d.done;d=b.next())c=q(d.value),d=c.next().value,c=c.next().value,this.i.setRequestHeader(d,c);this.ca&&(this.i.responseType=this.ca);\"withCredentials\"in this.i&&this.i.withCredentials!==this.ea&&(this.i.withCredentials=this.ea);if(\"setTrustToken\"in this.i&&this.Y)try{this.i.setTrustToken(this.Y)}catch(k){L(this.s,S(this,\"Error SetTrustToken: \"+k.message))}if(\"setAttributionReporting\"in this.i&&this.V)try{this.i.setAttributionReporting(this.V)}catch(k){L(this.s,S(this,\"Error SetAttributionReporting: \"+k.message))}try{Ob(this),0<this.K&&(this.S=Pb(this.i),L(this.s,S(this,\"Will abort after \"+this.K+\"ms if incomplete, xhr2 \"+this.S)),this.S?(this.i.timeout=this.K,this.i.ontimeout=v(this.da,this)):this.R=Hb(this.da,this.K,this)),L(this.s,S(this,\"Sending request\")),this.N=!0,this.i.send(a),this.N=!1}catch(k){L(this.s,S(this,\"Send error: \"+k.message)),Nb(this,k)}};var Pb=function(a){return cb&&\"number\"===typeof a.timeout&&void 0!==a.ontimeout};R.prototype.da=function(){\"undefined\"!=typeof fa&&this.i&&(this.I=\"Timed out after \"+this.K+\"ms, aborting\",L(this.s,S(this,this.I)),this.dispatchEvent(\"timeout\"),this.abort(8))};var Nb=function(a,b){a.A=!1;a.i&&(a.B=!0,a.i.abort(),a.B=!1);a.I=b;Qb(a);Rb(a)},Qb=function(a){a.W||(a.W=!0,a.dispatchEvent(\"complete\"),a.dispatchEvent(\"error\"))};R.prototype.abort=function(){this.i&&this.A&&(L(this.s,S(this,\"Aborting\")),this.A=!1,this.B=!0,this.i.abort(),this.B=!1,this.dispatchEvent(\"complete\"),this.dispatchEvent(\"abort\"),Rb(this))};R.prototype.G=function(){this.i&&(this.A&&(this.A=!1,this.B=!0,this.i.abort(),this.B=!1),Rb(this,!0));R.P.G.call(this)};R.prototype.ba=function(){this.H||(this.X||this.N||this.B?Sb(this):this.ha())};R.prototype.ha=function(){Sb(this)};var Sb=function(a){if(a.A&&\"undefined\"!=typeof fa)if(a.T[1]&&4==T(a)&&2==Tb(a))L(a.s,S(a,\"Local request error detected and ignored\"));else if(a.N&&4==T(a))Hb(a.ba,0,a);else if(a.dispatchEvent(\"readystatechange\"),4==T(a)){L(a.s,S(a,\"Request complete\"));a.A=!1;try{if(Ub(a))a.dispatchEvent(\"complete\"),a.dispatchEvent(\"success\");else{try{var b=2<T(a)?a.i.statusText:\"\"}catch(c){L(a.s,\"Can not get status: \"+c.message),b=\"\"}a.I=b+\" [\"+Tb(a)+\"]\";Qb(a)}}finally{Rb(a)}}};R.prototype.aa=function(a,b){z(\"progress\"===a.type,\"goog.net.EventType.PROGRESS is of the same type as raw XHR progress.\");this.dispatchEvent(Vb(a,\"progress\"));this.dispatchEvent(Vb(a,b?\"downloadprogress\":\"uploadprogress\"))};var Vb=function(a,b){return{type:b,lengthComputable:a.lengthComputable,loaded:a.loaded,total:a.total}},Rb=function(a,b){if(a.i){Ob(a);var c=a.i,d=a.T[0]?function(){}:null;a.i=null;a.T=null;b||a.dispatchEvent(\"ready\");try{c.onreadystatechange=d}catch(e){Ya(a.s,\"Problem encountered resetting onreadystatechange: \"+e.message)}}},Ob=function(a){a.i&&a.S&&(a.i.ontimeout=null);a.R&&(t.clearTimeout(a.R),a.R=null)};R.prototype.isActive=function(){return!!this.i};var Ub=function(a){var b=Tb(a);a:switch(b){case 200:case 201:case 202:case 204:case 206:case 304:case 1223:var c=!0;break a;default:c=!1}if(!c){if(b=0===b)a=String(a.O).match(Ib)[1]||null,!a&&t.self&&t.self.location&&(a=t.self.location.protocol.slice(0,-1)),b=!Kb.test(a?a.toLowerCase():\"\");c=b}return c},T=function(a){return a.i?a.i.readyState:0},Tb=function(a){try{return 2<T(a)?a.i.status:-1}catch(b){return-1}};R.prototype.getResponseHeader=function(a){if(this.i&&4==T(this))return a=this.i.getResponseHeader(a),null===a?void 0:a};R.prototype.getAllResponseHeaders=function(){return this.i&&2<=T(this)?this.i.getAllResponseHeaders()||\"\":\"\"};var S=function(a,b){return b+\" [\"+a.Z+\" \"+a.O+\" \"+Tb(a)+\"]\"};var U=function(a){this.g=this.D=this.l=\"\";this.F=null;this.C=this.h=\"\";this.o=!1;var b;a instanceof U?(this.o=a.o,Wb(this,a.l),this.D=a.D,this.g=a.g,Xb(this,a.F),Yb(this,a.h),Zb(this,$b(a.j)),this.C=a.C):a&&(b=String(a).match(Ib))?(this.o=!1,Wb(this,b[1]||\"\",!0),this.D=V(b[2]||\"\"),this.g=V(b[3]||\"\",!0),Xb(this,b[4]),Yb(this,b[5]||\"\",!0),Zb(this,b[6]||\"\",!0),this.C=V(b[7]||\"\")):(this.o=!1,this.j=new W(null,this.o))};U.prototype.toString=function(){var a=[],b=this.l;b&&a.push(X(b,ac,!0),\":\");var c=this.g;if(c||\"file\"==b)a.push(\"//\"),(b=this.D)&&a.push(X(b,ac,!0),\"@\"),a.push(encodeURIComponent(String(c)).replace(/%25([0-9a-fA-F]{2})/g,\"%$1\")),c=this.F,null!=c&&a.push(\":\",String(c));if(c=this.h)this.g&&\"/\"!=c.charAt(0)&&a.push(\"/\"),a.push(X(c,\"/\"==c.charAt(0)?bc:cc,!0));(c=this.j.toString())&&a.push(\"?\",c);(c=this.C)&&a.push(\"#\",X(c,dc));return a.join(\"\")};U.prototype.resolve=function(a){var b=new U(this),c=!!a.l;c?Wb(b,a.l):c=!!a.D;c?b.D=a.D:c=!!a.g;c?b.g=a.g:c=null!=a.F;var d=a.h;if(c)Xb(b,a.F);else if(c=!!a.h){if(\"/\"!=d.charAt(0))if(this.g&&!this.h)d=\"/\"+d;else{var e=b.h.lastIndexOf(\"/\");-1!=e&&(d=b.h.slice(0,e+1)+d)}e=d;if(\"..\"==e||\".\"==e)d=\"\";else if(-1!=e.indexOf(\"./\")||-1!=e.indexOf(\"/.\")){d=0==e.lastIndexOf(\"/\",0);e=e.split(\"/\");for(var f=[],k=0;k<e.length;){var g=e[k++];\".\"==g?d&&k==e.length&&f.push(\"\"):\"..\"==g?((1<f.length||1==f.length&&\"\"!=f[0])&&f.pop(),d&&k==e.length&&f.push(\"\")):(f.push(g),d=!0)}d=f.join(\"/\")}else d=e}c?Yb(b,d):c=\"\"!==a.j.toString();c?Zb(b,$b(a.j)):c=!!a.C;c&&(b.C=a.C);return b};var Wb=function(a,b,c){a.l=c?V(b,!0):b;a.l&&(a.l=a.l.replace(/:$/,\"\"))},Xb=function(a,b){if(b){b=Number(b);if(isNaN(b)||0>b)throw Error(\"Bad port number \"+b);a.F=b}else a.F=null},Yb=function(a,b,c){a.h=c?V(b,!0):b;return a},Zb=function(a,b,c){b instanceof W?(a.j=b,ec(a.j,a.o)):(c||(b=X(b,fc)),a.j=new W(b,a.o));return a},V=function(a,b){return a?b?decodeURI(a.replace(/%25/g,\"%2525\")):decodeURIComponent(a):\"\"},X=function(a,b,c){return\"string\"===typeof a?(a=encodeURI(a).replace(b,gc),c&&(a=a.replace(/%25([0-9a-fA-F]{2})/g,\"%$1\")),a):null},gc=function(a){a=a.charCodeAt(0);return\"%\"+(a>>4&15).toString(16)+(a&15).toString(16)},ac=/[#\\/\\?@]/g,cc=/[#\\?:]/g,bc=/[#\\?]/g,fc=/[#\\?@]/g,dc=/#/g,W=function(a,b){this.h=this.g=null;this.j=a||null;this.l=!!b},Y=function(a){a.g||(a.g=new Map,a.h=0,a.j&&Jb(a.j,function(b,c){a.add(decodeURIComponent(b.replace(/\\+/g,\" \")),c)}))};W.prototype.add=function(a,b){Y(this);this.j=null;a=Z(this,a);var c=this.g.get(a);c||this.g.set(a,c=[]);c.push(b);this.h=A(this.h)+1;return this};var hc=function(a,b){Y(a);b=Z(a,b);a.g.has(b)&&(a.j=null,a.h=A(a.h)-a.g.get(b).length,a.g.delete(b))},ic=function(a,b){Y(a);b=Z(a,b);return a.g.has(b)};W.prototype.forEach=function(a,b){Y(this);this.g.forEach(function(c,d){c.forEach(function(e){a.call(b,e,d,this)},this)},this)};W.prototype.o=function(a){Y(this);var b=[];if(\"string\"===typeof a)ic(this,a)&&(b=b.concat(this.g.get(Z(this,a))));else{a=Array.from(this.g.values());for(var c=0;c<a.length;c++)b=b.concat(a[c])}return b};W.prototype.set=function(a,b){Y(this);this.j=null;a=Z(this,a);ic(this,a)&&(this.h=A(this.h)-this.g.get(a).length);this.g.set(a,[b]);this.h=A(this.h)+1;return this};W.prototype.get=function(a,b){if(!a)return b;a=this.o(a);return 0<a.length?String(a[0]):b};W.prototype.toString=function(){if(this.j)return this.j;if(!this.g)return\"\";for(var a=[],b=Array.from(this.g.keys()),c=0;c<b.length;c++){var d=b[c],e=encodeURIComponent(String(d));d=this.o(d);for(var f=0;f<d.length;f++){var k=e;\"\"!==d[f]&&(k+=\"=\"+encodeURIComponent(String(d[f])));a.push(k)}}return this.j=a.join(\"&\")};var $b=function(a){var b=new W;b.j=a.j;a.g&&(b.g=new Map(a.g),b.h=a.h);return b},Z=function(a,b){b=String(b);a.l&&(b=b.toLowerCase());return b},ec=function(a,b){b&&!a.l&&(Y(a),a.j=null,a.g.forEach(function(c,d){var e=d.toLowerCase();if(d!=e&&(hc(this,d),hc(this,e),0<c.length)){this.j=null;d=this.g;var f=d.set;e=Z(this,e);var k=c.length;if(0<k){for(var g=Array(k),h=0;h<k;h++)g[h]=c[h];k=g}else k=[];f.call(d,e,k);this.h=A(this.h)+c.length}},a));a.l=b};var kc=function(){this.h=void 0;this.g=null;jc(this,0);window.addEventListener(\"load\",this.o.bind(this))};kc.prototype.l=function(a){if(this.g){a=a.target;var b;if(b=Ub(a)){try{var c=a.i?a.i.responseText:\"\"}catch(f){L(a.s,\"Can not get responseText: \"+f.message),c=\"\"}b=\"OK\"===c}if(b){this.j();c=window.location;a=Yb(new U(window.location),\"/ServiceLogin\").toString();var d=void 0===d?Fa:d;a:if(d=void 0===d?Fa:d,a instanceof C)d=a;else{for(b=0;b<d.length;++b){var e=d[b];if(e instanceof Ea&&e.ga(a)){d=new C(a,B);break a}}d=void 0}void 0===d&&Ia(a.toString());a=d||Da;a instanceof C?a instanceof C&&a.constructor===C?a=a.g:(ma(\"expected object of type SafeUrl, got '\"+a+\"' of type \"+ha(a)),a=\"type_error:SafeUrl\"):Ga.test(a)||(Ia(a),a=void 0);void 0!==a&&(c.href=a)}else jc(this,5E3)}};var jc=function(a,b){a.g=setTimeout(function(){if(a.g){var c=Za.get(\"APISID\");if(c===a.h)jc(a,5E3);else{a.h=c;c=new U(\"/PassiveLoginProber\");var d=(new U(window.location)).j;c=Zb(c,d).toString();d=a.l.bind(a);var e=new R;Mb.push(e);d&&(rb(e),e.u.add(\"complete\",d,!1,void 0,void 0));e.u.add(\"ready\",e.fa,!0,void 0,void 0);e.send(c,void 0,void 0,void 0)}}},b)};kc.prototype.o=function(){document.addEventListener(\"submit\",this.j.bind(this))};kc.prototype.j=function(){this.g&&(clearTimeout(this.g),this.g=null)};new kc;}).call(this); Not your computer? Use a private browsing window to sign in. Learn more about using Guest mode Next Create account window.wiz_progress&&window.wiz_progress();window.wiz_tick&&window.wiz_tick('chA7fe');", "https://cs.brown.edu/courses/csci1820/": "CSCI 1820 Home Notes Assignments Staff Resources CSCI 1820 Algorithmic Foundations of Computational Biology Welcome to CSCI 1820! What is computational biology? Computational biology is an interdisciplinary field which draws upon computer science, biology and mathematics. Much biological research today relies on powerful high-throughput computational tools which apply theoretical computation principles and statistical methods to gain insights into vast datasets, enabling advances in genomics, biochemistry, epidemiology, and personalized medicine. This fundamental pairing harnesses both rigorous computational approaches to solving complex problems and centuries of biological study to infer new knowledge, verify novel findings, and probe the frontiers of current understanding. In CSCI 1820, you'll not only learn about both seminal and cutting-edge algorithms in the field of computational biology, but also have the opportunity to implement them yourself and see their power in action!", "https://cs.brown.edu/courses/csci1950-h/": "Home Asgns Docs Staff Resources Announcements: 1/22/2015 HW0 is out; it's due before Tuesday's class. CS195-H is primarily aimed at Junior/Senior Math/CS concentrators who have taken a 100-level math course that involves some topology (e.g., MA106, MA141, MA126, ...) and who know how to program, and preferably have some experience with Matlab and/or Mathematica (Click here for a very brief tutorial of Matlab). Class will meet 1:00-2:20 pm on Tuesdays and Thursdays in CIT 316 .", "https://brown-cs181-fall22.github.io/": "Home Resources Lectures Assignments Calendar Staff CS181 WELCOME TO CS 181, COMPUTATIONAL MOLECULAR BIOLOGY! QuickLinks Syllabus Collaboration Policy Late Policy Gradescope EdStem Anonymous Feedback Form Course Information The aim of this course is to provide an introduction to computational molecular biology. The course is organized into six chapters: Sequence Alignment Combinatorial Pattern Matching Phylogenetic Trees Hidden Markov Models Genome Assembly Genomic Privacy Each chapter is devoted to a class of basic computational problems related to the analysis of DNA, RNA, and protein sequences and their molecular function. Our journey in each chapter is driven by a set of beautiful algorithms. A \u201cbeautiful\u201d algorithm is one that is rigorous, practical, elegantly simple, and easy to implement. In addition to these beautiful algorithms, each chapter contains a Foundations section that gives a detailed presentation of the biological problems discussed as well as the theoretical computer science and statatistical results that led to the invention of the algorithms. This class provides a serious introduction to the field of computational biology both for potential concentrators and for those who may take only a single course in the subject. Historical note: CS181 was first taught at Brown 23 years ago by Professor Franco Preparata (i.e. before the completion of the Human Genome Project). This year\u2019s offering is the 24rd incarnation of this foundational course in computational biology. See the Resources page for a biology primer written by Prof. Preparata. FAQ Who takes the course? As an interdisciplinary course, CS181 attracts a diverse group of students. Past students have ranged from sophomores concentrating in Computer Science and Computational Biology through Ph.D. students in Computer Science, Applied Mathematics, and Biology. The course staff will do its best to ensure that all students have a chance to succeed. Please do not hesitate to talk to a member of the course staff if you have trouble deciding whether CS181 is a good fit for you. What biology background is needed? There are no biology prerequisites, and no prior biology knowledge is assumed; the material that you need to know will be covered in class. Students whose backgrounds are in the life sciences, however, will be expected to dig deeper into the biology. What computer science and mathematics background is needed? Officially, one of CS16, CS18, CS200, or CS19 (i.e. a yearlong introduction to computer science). This can be waived by the instructor (especially for life science students). Students in the course generally have some prior exposure to basic concepts of discrete math (graphs, recurrence relations), discrete probability (random variables, independence), and algorithms (big-O notation, pseudocode). What programming background is needed? This is not a programming-heavy course, although there will be programming assignments. The goal of these assignments is to gain a deeper understanding of the algorithms by implementing them and testing them on real data. Thus, some rudimentary programming skills (arrays, loops, functions, etc.) are required. Any language can be used, but common languages like Python will make it easier for the TAs to help you. I am experienced in molecular biology, but do not have any formal mathematical or computational training. Can I take the course? We attempt to make the course genuinely accessible for students without a computer science background. At the same time, all students in the class should be prepared to complete medium-scale programming assignments, learn some new mathematical concepts, and reason about algorithms in a rigorous manner. Please reach out to a member of the course staff if you are unsure of your background. I am interested in learning how to analyze *-Seq data from my (advisor's) lab. Will this course help me? Possibly, but perhaps not in the way that you expect. The goals of CS181 are to teach the algorithmic concepts that underlie a wide variety of software that is used to analyze biological data, particularly in genetics, genomics, and proteomics. The course will not teach you how to use any particular biological software package. Rather, you will learn how this software works, and more importantly for the long-term, how to think about biological problems in a computational way. Thus, when the latest and greatest technology for measuring DNA/RNA/protein is released in 5 or 10 years' time, you will have some algorithmic skills to work with this data, without waiting for the rest of the community to develop tools. If your interests are more narrowly focused on a particular, near-term application, another course might be more appropriate. Can I get graduate credit for this course? Yes! To get it, you will need to do all undergraduate coursework in the class plus a final research project defined in discussions with the professor. Work for the final project consists of (1) a piece of code implementing a new algorithm or analysis or simulation, (2) a short written paper about your project and algorithms/code, and (3) a comprehensive powerpoint and a final project presentation to the class. Please email the professor for more information about this. made with \u2661 by ezhang29, hvenkata, and the fall 2022 staff based on work by glee73 and others", "https://csci1951a-spring-2024.github.io/": "Welcome to CS1951A! Home Assignments Final Project Final Project Examples Hours Resources Staff Cannot save changes Viewing What is Data Science? Data is the core of all domains from material science to healthcare. Mastering big data requires a set of skills spanning a variety disciplines, from distributed systems to statistics to machine learning. This course will provide an overview of the wide area of data science, with a particular focus on to the tools required to store, clean, manipulate, visualize, model, and ultimately extract information from large amounts of data. Syllabus Course Calendar Lecture Slides & Material Panopto Overview 1 Instructor = Lorenzo De Stefani 2 Instructor Office Hours = Fridays 3:45 - 5:25 PM. Sign up for a slot here 3 HTA Mailing List = cs1951aheadtas@lists.brown.edu 4 Lecture Dates = Mondays & Wednesdays 5 Lecture Time = 3:00 - 4:20 PM 6 Lecture Location = Salomon Center 001 Topics Covered Database Design and SQL Web Scraping & Data Cleaning Hypothesis Testing Machine Learning Mapreduce Differential Privacy Correlation vs Causation Final Project Throughout the entire course you will be working on a data science project which seeks to answer an interesting and important real-world question. You will be collecting your own data, cleaning it, modeling it, visualizing it, and finally presenting your results in a poster session at the end of the course. You will work in groups of four, and will be assigned a mentor TA to help you through the process. Additionally, your project can be used as a capstone with just a few extra requirements, fully integrating what you will have learned in the course, and building a fully-functional data science application. Prerequisites The formal prerequisites to this course are CSCI 0160, 0180, or 0190. Additional experience in software engineering is recommended, including CSCI 0320 or 1320. This course is taught in Python 3.7, but no prior experience is necessary. We will provide several resources to get students started with Python at the beginning of the course. It is suggested that students also have experience in statistics (APMA 1650 or CSCI 1450) and linear algebra (MATH 0520, MATH 0540, or CSCI 0530) for the statistics and machine learning portion of this course. \u00a9 2024 CS1951A Staff | Computer Science Department | Brown University // function to handle on arrow click function handleArrowClick(index) { // rotate arrow var arrow = document.getElementsByClassName(\"arrow\")[index]; arrow.classList.toggle(\"arrow-collapsed\"); // collapse the section container var sectionContainer = document.getElementsByClassName(\"section-container\")[index]; // hide all p tags in section container var pTags = sectionContainer.getElementsByTagName(\"p\"); for (var i = 0; i < pTags.length; i++) { pTags[i].classList.toggle(\"p-collapsed\"); } // hide all ul tags in section container var ulTags = sectionContainer.getElementsByTagName(\"ul\"); for (var i = 0; i < ulTags.length; i++) { ulTags[i].classList.toggle(\"ul-collapsed\"); } }", "https://cs.brown.edu/courses/csci2370/2018/brown-cs237-fall18-website/ideas.html": "CSCI2370: Interdisciplinary Scientific Visualization (fall 2018) Project Ideas Home Syllabus Calendar People Gallery Links Project Ideas Ideas Compiled for Students Note: Brown-internal or password protected links are styled like this , as opposed to public links . You can also find the list of ideas proposed in previous years: 2000 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 . Proposals and Projects from Previous Years Click on the year numbers to review some of the individual project proposals students made in 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 . The resulting final projects , completed in groups, can be reviewed here for 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 .", "https://cs.brown.edu/courses/csci2370/2018/brown-cs237-fall18-website/calendar.html": "CSCI2370: Interdisciplinary Scientific Visualization (fall 2018) Calendar Home Syllabus Calendar People Gallery Links Project Ideas How to Hand Stuff In How to: We use a Google Team Drive to manage group emails and submissions. Please email the TA your prefered email account(s) and we will add you as a member (e.g., send Fumeng both your personal and brown accounts). Inside the drive, you deliver your assignments to the subfolder the_due_date / yourBrownShortID .ext. For example, Fumeng could upload her first assignment to 09-11-2018 as fyang7.txt . Due: All handins are due by 9AM the same day of class to allow for review before class. Please get your reviews and readings done in time. A significant aspect of the class is to get different points of view for interdisciplinary research problems. It\u2019ll make classes much more fun and valuable if everybody participates and expresses an opinion. It\u2019s not fair to others to make them always carry the weight of leading the discussions. Prepare for a dynamic and open discussion in almost every class. How to Read Papers and Proposals Some of the readings needed for the class are password protected due to copyright issues. These links will appear styled like this , as opposed to the public links . The user/pwd is specific to the Vis group website (VisWeb); it is not the same as your CS account. Make sure to contact the instructors to get the username and password if you forget it (we\u2019ll give it out the first day of class). Almost all of the readings we will do are online to reduce copying effort and costs, and to keep color imagery intact. Printing them for your own use is fine. Please look at the color images in color, though! Some of the files are pretty big (40-50 Mb). Finally, please respect the grant proposals you will be reading. They are not published documents and should not be circulated outside of class. Please make sure that you destroy any copies of those documents when you are finished with them for class. Calendar Week 1 (back to top) Date & Topic Assignment Thu 9/6, 2018 Introduction Goals Organization Schedule Definition of Visualization To Do Send Fumeng (fumeng_yang at brown.edu) two things: (1) your prefered gmail account(s) and (2) a small photo of yourself to include on the website ; Fumeng will send your the username and password to access the protected files. Test if you can use the team drive after Fumeng adds you. Week 2 (back to top) Date & Topic Assignment Tue 9/11, 2018 Open problems in Visualization What makes a good problem? Reading Read before class, with an eye toward your essay: Toolsmith II paper (Brooks) - this describes how to do computer science, which is the \u201chome\u201d discipline for scientific visualization. Top Scientific Visualization Research Problems (Johnson) one of the following: Visualization in Scientific Computing (McCormick, DeFanti, Brown) - set the stage for scientific visualization and its funding back in 1987. Read the executive summary and sections I-III. Skim through appendix A and read the sections that are most interesting to you. Read section A.3. Skim through appendices B and C so you have some idea of what\u2019s in them when you need the information there later. Computational Science: Ensuring America\u2019s Competitiveness (President\u2019s Information Technology Advisory Committee), also CRA NIH Workshop Recommendations and http://www.nitrd.gov/pubs/ Top 10 Unsolved Information Visualization Problems (Chen) suggested reading Part of a lobbying effort for national funding, the Data and Visualization Corridors gives a 1999 perspective on what was limiting progress in high-end visualization. Read the executive summary and quickly flip through the rest of the document to get a feel for more research topics. Bill Hibbard\u2019s vis viewpoints column The Top Five Problems that Motivated My Work . Another vis viewpoints column by David Duke et al. Do You See What I Mean? . Research and Development Agenda for visual analytics developed to define the directions and priorities for future research and development programs focused on visual analytics tools. Illuminating the Path Deliverables (9am) Personal background handed in as yourBrownShortID.txt A fictional essay, 250-750 words. The setting is 5-20 years in the future, and the story should describe how CSCI2370 influenced that future you. In particular, it should describe a plausible way that you will have solved or addressed one or more of the visualization research topics from the readings. Hand in as yourBrownShortID-2.txt, as described for personal background handin. Thu 9/13, 2018 Review and discuss NSF ITR proposal: Understanding Unsteady Bioflows through Simulation, Modeling, Visualization, Art, and Psychology (Laidlaw et al.) Evaluating project possibilities Reading These readings will give you a feel for what goes into a research grant proposal: Watch this animation on YouTube about NSF\u2019s review process NSF Grant Proposal Guide (2004) describes how to write a grant proposal. While some of the instructions are specific to NSF, much of the document gives good advice on how to write any proposal. Skim: whole thing Read: I.B, II.C.2.a-f, II.C.2.h-k, III (intro), III.A, III.E-F, VI.G Guidelines for proposal writing NSF Information Technology Research (ITR) Program Announcement . Typically, NSF accepts both unsolicited grant applications (for whatever a proposer thinks is worth doing) and solicited applications. Applications are solicited via a Program Announcement (PA), sometimes called a Request for Proposals (RFP). This is one example of what they are looking for. Read proposal: Understanding Unsteady Bioflows through Simulation, Modeling, Visualization, Art, and Psychology (Laidlaw et al.) . This is a proposal in response to the ITR solicitation. It was successful and was partially funded September 2004. You don\u2019t need to understand all, but try to get the big picture as an example of a multi-disciplinary research project. After writing your own review (see Deliverables), read NSF reviews of the proposal and add any new discussion questions to your review. Read the RFP for class projects Consult the list of project ideas Deliverables (9am) Hand in your own review for the ITR grant as yourBrownShortID .txt Hand in a list of four possible collaborators for your class project as yourBrownShortID-2 .txt. The collaborators can be from class or from other disciplines. The RFP for class projects will help you understand more about the criteria for judging a project idea. Possible collaborators can be from the class, the list of project ideas suggested by various researchers around campus, and any personal contacts you have. Describe the discipline of each possible collaborator and how it is distinct from your area. At least two must be contributors to the list of project ideas or established researchers. Collaborator\u2019s list - You will need to meet with at least three of the four possible collaborators and report on those meetings on 9/25. These meetings will help you develop the interdisciplinary part of the project. Get started scheduling these meetings and look at what you\u2019ll need to hand in as a report . Coordinate with other class members for interviewing to avoid duplicating collaborator effort. Week 3 (back to top) Date & Topic Assignment Tue 9/18, 2018 Review of NSF CAREER proposal Shape Capture and Modeling for Wrist Dynamics and Ancient Pottery Analysis using Manifold Surfaces and Signed-Distance Volume Images (Laidlaw) Evaluating project possibilities Reading NSF Faculty Early Career Development (CAREER) Program Announcement Read annual status report to NSF . Once again, this gives a feel for what NSF is interested in. Shape Capture and Modeling for Wrist Dynamics and Ancient Pottery Analysis using Manifold Surfaces and Signed-Distance Volume Images (Laidlaw). This is a second example of an interdisciplinary visualization proposal. The application areas are quite different and the proposal is more focused on visualization. Skim the whole proposal, then read the Project Summary and Project Description. After writing your own review (see Deliverables), read NSF reviews of the proposal, then add any new discussion questions to your review. Deliverables (9am) Write your own review ( using this form ) of the CAREER proposal and hand it in as yourBrownShortID.txt. Do the review before reading the NSF reviews. Continue interviewing possible collaborators. Thu 9/20, 2018 VR demos in the YURT Discuss project ideas Note: Class will meet at the YURT (180 George Street) Reading Read Request For Proposals (RFP) Browse previous CSCI2370 proposals linked on the Ideas page Deliverables (9am) Three possible proposal titles as yourBrownShortID-2.txt. For each, include a brief description, a list of participants, and your evaluation of the proposal you imagine. Use the RFP to guide your project ideas and to self-evaluate them. Week 4 (back to top) Date & Topic Assignment Tue 9/25, 2018 Review and discuss NIH proposal Quantitative Inverse Electrocardiography (Johnson) Reading Read Quantitative inverse electrocardiography (Johnson). This proposal is more than 15 years old, so the work is not current. It does show an excellent example of a successful non-clinical NIH grant proposal. Non-clinical work is often quite difficult to get funded by NIH. Note the structure of the proposal, with well-formulated hypotheses to test. Skim the whole thing and read the four sections starting with Specific Aims. Read partial list of resulting papers Read Visualization of bioelectric fields , MacLeod et al. Read NIH guide to proposals , focusing on the specification of a proposal (pg. 1-16), research plan details (pg. 17), review criteria (pg. 34), and other interesting and relevant parts you find Read this PowerPoint presentation about the NIH proposal review process Deliverables (9am) Interview reports as yourBrownShortID.txt Your review of Johnson\u2019s NIH grant as yourBrownShortID-2.txt Thu 9/27, 2018 Review and discuss NSF proposal Development of a Next-Generation Interactive Virtual-Reality Display Environment for Science (Laidlaw et al.) Reading Read MRI: Development of a Next-Generation Interactive Virtual-Reality Display Environment for Science (Laidlaw et al.) Skim HCC: Small: Collaborative Research: Immersive Visualization and 3D Interaction for Volume Data Analysis (Bowman, Socha, and Laidlaw) and CHS: Small: How Much Virtual Reality is Enough Deliverables (9am) Your review of the Cave proposal as yourBrownShortID.txt Week 5 (back to top) Date & Topic Assignment Tue 10/2, 2018 Visualization tools Visualizing multi-dimensional data Reading Read Visualization Handbook 's table of contents. For the class, see if the topics in the book suggest some readings related to your project. Are there any new ideas in there for a different project? Google for the authors' web pages and see what other stuff they are working on. If you're interested in reading more, the book is available at the Sciences Library (SciLi). Deliverables (9am) Hand in results from literature search as yourBrownShortID.txt You should do this search on the project you are most seriously considering doing out of all the ideas you have. Look here (Question 3 Where do I search for research papers? ) for links to research publications. Continue developing your project proposal, filling in any weaknesses, fleshing out the related work section, etc. Be prepared to briefly describe the project idea you are most seriously considering and any issues, concerns, problems, etc. that we can discuss in class. Thu 10/4, 2018 more \"Visualization Handbook\" Deliverables (9am) Sign up for a presentation time in the spreadsheet posted in the Google drive Collaborators Meetings & Proposal Presentations (top-level, the same file used for collaborators meetings, but use the second tab.) Preliminary proposal handed in as yourBrownShortID.pdf A template for your proposal can be downloaded here. See the README inside for more instructions. Make sure your proposal is saved as a pdf. Week 6 (back to top) Date & Topic Assignment Tue 10/9, 2018 Proposal presentations Reading Begin reading proposals from the shared Google Team Drive 10-11/Preliminary Proposals Deliverables (9am) Presentation slides handed in as yourBrownShortID_slides.pptx or pdf Thu 10/11, 2018 Improving proposals and examples \"Walking > Walking-in-Place > Flying\" Evaluating visualizations Reading \u201cWalking > Walking-in-Place > Flying, in Virtual Environments\u201d , Usoh et al., In Proceedings of SIGGRAPH, 1999. \u201cEmpirical Studies in Information Visualization Evaluation: Seven Scenarios\u201d , Lam et al., IEEE TVCG 18, 9 (September 2012). Read proposals from the shared Google Team Drive 10-11/Preliminary Proposals Deliverables (9am) Find your review assignment within the same folder / the top level of the shared drive. Review of the first-draft proposals assigned to you. Use a separate form for each review you write, and name the file proposer_by_reviewer .txt when you hand it in. For instance, if David reviews Fumeng's proposal, he should hand in a file called fyang7_by_dhl.txt. Week 7 (back to top) Date & Topic Assignment Tue 10/16, 2018 Walkthrough of a project budget Insight-based evaluation: what is it, and should you use it? Link to paper for in-class activity: \u201cAn Insight-Based Methodology for Evaluating Bioinformatics Visualizations\u201d , Saraiya et al., TVCG, 2005. Deliverables (9am) Final proposal handed in as yourBrownShortID.pdf Thu 10/18, 2018 Study section (evaluate, score, \u201cfund\u201d proposals) Link for in-class activity: Table of linked reviews and NIH-style proposal scores: {TBD} Reading Read final proposals from the shared Google Team Drive /10-18/all_proposals.pdf Find your in the spreadsheet posted within the same folder / the top level of the shared drive. Deliverables (9am) Review the final proposals assigned to you. For the final proposals, you only need to hand in reviews for the three proposals where you are R1, R2, or R3. You must read the proposals for which you are R3/R4 and be prepared to discuss them in class. Use a separate form for each review you write, and name the file proposer_by_reviewer .txt when you hand it in. For instance, if David reviews Fumeng's proposal, he should hand in a file called fyang7_by_dhl.txt. Respond to the quick questions in this form as yourBrownShortID.txt Week 8 (back to top) Date & Topic Assignment Tue 10/23, 2018 No Class! IEEE Visualization Conference in Berlin, Germany Start the CITI online course , which will certify you to perform \u201chuman subjects research\u201d, like user studies, at Brown. Thu 10/25, 2018 No Class! IEEE Visualization Conference in Berlin, Germany Finish the CITI online course and send your passing Completion Report (pdf) to the TA. If you do not pass on your first try, you must retake the quizzes until you receive a passing grade. Week 9 (back to top) Date & Topic Assignment Tue 10/30, 2018 Class cancelled Deliverables (9am) Hand in a summary statement on your \u201cPrimary\u201d proposal. Try to capture all the discussion points for the proposal. The length should be however long it takes for you to adequately summarize the discussion. Name the file proposer_by_yourBrownShortID .txt. Thu 11/1, 2018 Class cancelled Week 10 (back to top) Date & Topic Assignment Tue 11/6, 2018 Check-in on projects Review VIS 2018 program Keywords, topics in VIS papers Finding related work In class, we will quickly read and evaluate recent visualization papers from the 2018 IEEE visualization conferences. Mega-sheet with Related Work and VIS paper scores IEEE VIS 2018 Program Thu 11/8, 2018 Check-in on projects Review VIS 2018 program Relate your project to the VIS conference Week 11 (back to top) Date & Topic Assignment Tue 11/13, 2018 Check-in on project schedules What is going well? Challenges and questions Deliverables (9am) Prepare a Gatt chart for your project progress Be ready to show and discuss your project progress/Gatt chart with others in class Thu 11/15, 2018 Reading VIS 2018 papers TBD Week 12 (back to top) Date & Topic Assignment Thu 11/20, 2018 No Class. Happy Thanksgiving! If you have urgent questions, please contact Fumeng. Thu 11/22, 2018 No Class. Happy Thanksgiving! If you have urgent questions, please contact Fumeng. Week 13 (back to top) Date & Topic Assignment Tue 11/27, 2018 Week 5 check-in on project schedules Discussion of final plans for projects Remaining challenges and questions Bring in your schedules for the final 2 weeks. Project groups will have time to update the class about progress. Start your presentations. Next week, we\u2019ll have a dress rehearsal for final presentations. Look ahead in the calendar for more info about our expectations. Project progress check-in Read VIS 2018 papers Thu 11/29, 2018 Class review forms to be filled out Research abstracts: what to report and how much? In class, we will look at examples of successful two-page research abstracts. Project progress check-in Read VIS 2018 papers Week 14 (back to top) Date & Topic Assignment Tue 12/4, 2018 Week 5 check-in on project schedules Discussion of final plans for projects Remaining challenges and questions Project progress check-in Read VIS 2018 papers Thu 12/6, 2018 Class review forms to be filled out Research abstracts: what to report and how much? Project progress check-in Read VIS 2018 papers Week 15 (back to top) Date & Topic Assignment Tue 12/11, 2018 Last class Presentation Dress Rehearsal! In class, each group will deliver a 8-10 minute presentation about its project. The \u2018audience\u2019 will have 5 minutes to ask questions after each talk. You should practice your presentation before class at least three times; remember to focus on contributions and results, and don\u2019t go over 10 minutes. We will critique presentations as a class in preparation for the public final presentations. Use the feedback you receive in class to revise your final presentation. Deliverables (9am) Hand in a pdf of your slideshow (one per group). Name the file login1_login2 .pdf corresponding to the group members. Thur 12/13, 2018 Reading period Hand in a PDF of Your Draft (11:59pm EST) By the end of the day, hand in a draft of your final report. Your report should be a two-page extended abstract (pdf) for your project as yourBrownShortID.pdf. For groups, each student must write his or her own report, in which s/he is listed as the first author and the other group members as co-authors. Your abstract must match the formatting requirements for our class proceedings . Templates for Word and latex can be downloaded here . Please use the finalReport templates. See the README inside for more instructions. Week 16 (back to top) Date & Topic Assignment Mon 12/17, 2018 Final Project Presentation Present your Final Project and Results (2pm) Before the presentation slot, hand in a pdf of your slideshow (one per group). Name the file login1_login2 .pdf corresponding to the group members. Plan for 5-6 minutes of presentation. You will have access to a large display/projector to present your slides. You will have an few minutes after your talk to answer questions from the audience. Tue 12/18, 2018 Final Reports Due Hand in Final Report (11:59pm EST) By the end of the day, hand in a two-page extended abstract (pdf) for your project as yourBrownShortID.pdf. For groups, each student must write his or her own report, in which s/he is listed as the first author and the other group members as co-authors. Your abstract must match the formatting requirements for our class proceedings . Templates for Word and latex can be downloaded here . Please use the finalReport templates. See the README inside for more instructions. P.S. the link here is the same as the link for 12/13 your draft submission. If you're wondering, here's what we did last time: (2016 calendar)", "https://cs.brown.edu/courses/csci2370/2020/calendar.html": "CSCI2370: Interdisciplinary Scientific Visualization (fall 2020) Calendar Home Syllabus Calendar People Links Project Ideas How to Hand Stuff In How to: We use a Google Drive folder to manage homeworks and some other shared resources. If you haven't been added to it, please send TA, Fumeng_Yang at brown.edu, your brown email address. Inside the folder, you will deliver your assignments to the subfolder the_due_date / yourBrownShortID .ext. For example, Fumeng could upload her first assignment to 09-15-2020 as fyang7.txt . Due: All handins are due by 9AM the same day of class to allow for review before class. Please get your reviews and readings done in time. A significant aspect of the class is to get different points of view for interdisciplinary research problems. It\u2019ll make classes much more fun and valuable if everybody participates and expresses an opinion. It\u2019s not fair to others to make them always carry the weight of leading the discussions. Prepare for a dynamic and open discussion in almost every class. How to Read Papers and Proposals Some of the readings needed for the class are password protected due to copyright and privacy issues. These links will appear styled like this , as opposed to the public links . The user/pwd is specific to the Vis group website (VisWeb); it is not the same as your CS account. Make sure to contact the instructors to get the username and password if you forget it (we\u2019ll give it out the first day of class). Almost all of the readings we will do are online. Printing them for your own use is fine. Please look at the color images in color, though! Some of the files are pretty big (40-50 Mb). Finally, please respect the grant proposals you will be reading. They are not published documents and should not be circulated outside of class. Please make sure that you destroy any copies of those documents when you are finished with them for class. Calendar Week 1 (back to top) Date & Topic Assignment Thu 9/10, 2020 Introduction Goals Organization Schedule Summary of class Research contributions, Marching Cubes paper, 2018 course abstracts, 2014 course abstracts. Week 2 (back to top) Date & Topic Assignment Tue 9/15, 2020 Open problems in Visualization What makes a good problem? Logistics Send Fumeng (fumeng_yang at brown.edu) a small photo of yourself to include on the website . Make sure you can use the shared google drive. Email Fumeng if you need help. Reading Read, with an eye toward your essay (below) and also to discuss in class: Toolsmith II paper (Brooks) - this describes how to do computer science, which is the \u201chome\u201d discipline for scientific visualization. Top Scientific Visualization Research Problems (Johnson) one of the following: Visualization in Scientific Computing (McCormick, DeFanti, Brown) - set the stage for scientific visualization and its funding back in 1987. Read the executive summary and sections I-III. Skim through appendix A and read the sections that are most interesting to you. Read section A.3. Skim through appendices B and C so you have some idea of what\u2019s in them when you need the information there later. Computational Science: Ensuring America\u2019s Competitiveness (President\u2019s Information Technology Advisory Committee), also CRA NIH Workshop Recommendations and http://www.nitrd.gov/pubs/ Top 10 Unsolved Information Visualization Problems (Chen) suggested reading Part of a lobbying effort for national funding, the Data and Visualization Corridors gives a 1999 perspective on what was limiting progress in high-end visualization. Read the executive summary and quickly flip through the rest of the document to get a feel for more research topics. Bill Hibbard\u2019s vis viewpoints column The Top Five Problems that Motivated My Work . Another vis viewpoints column by David Duke et al. Do You See What I Mean? . Research and Development Agenda for visual analytics developed to define the directions and priorities for future research and development programs focused on visual analytics tools. Illuminating the Path Deliverables (9am) Personal background handed in as yourBrownShortID.txt A fictional essay, 250-750 words. The setting is 5-20 years in the future, and the story should describe how CSCI2370 will have influenced that future you. In particular, it should describe a plausible way that you will have solved or addressed one or more of the visualization research topics from the readings. Hand in as yourBrownShortID-2.txt, as described for personal background handin. Thu 9/17, 2020 Review and discuss NSF ITR proposal: Understanding Unsteady Bioflows through Simulation, Modeling, Visualization, Art, and Psychology (Laidlaw et al.) Evaluating project possibilities Reading These readings will give you a feel for what goes into a research grant proposal: Watch this animation on YouTube about NSF\u2019s review process NSF Grant Proposal Guide (2004) describes how to write a grant proposal. While some of the instructions are specific to NSF, much of the document gives good advice on how to write any proposal. Note that this is the version that was in effect when this proposal was written. There have been several versions since then, so refer to the latest when you write your own NSF proposals! Skim: whole thing Read: I.B, II.C.2.a-f, II.C.2.h-k, III (intro), III.A, III.E-F, VI.G Guidelines for proposal writing NSF Information Technology Research (ITR) Program Announcement . Typically, NSF accepts both unsolicited grant applications (for whatever a proposer thinks is worth doing) and solicited applications. Applications are solicited via a Program Announcement (PA), sometimes called a Request for Proposals (RFP). This is one example of what they are looking for. Read proposal: Understanding Unsteady Bioflows through Simulation, Modeling, Visualization, Art, and Psychology (Laidlaw et al.) . This is a proposal in response to the ITR solicitation. It was successful and was partially funded September 2004. You don\u2019t need to understand all, but try to get the big picture as an example of a multi-disciplinary research project. AFTER writing your own review (see Deliverables), read NSF reviews of the proposal and add any new discussion questions to your review. Read the RFP for class projects Consult the list of project ideas Deliverables (9am) Hand in your own review for the ITR grant as yourBrownShortID .txt Hand in a list of three possible collaborators for your class project as yourBrownShortID-2 .txt. The collaborators can be from class or from other disciplines. The RFP for class projects will help you understand more about the criteria for judging a project idea. Possible collaborators can be from the class, the list of project ideas suggested by various researchers around campus, and any personal contacts you have. Describe the discipline of each possible collaborator and how it is distinct from your area. At least two must be contributors to the list of project ideas or established researchers. Collaborator\u2019s list - You will need to meet with at least three possible collaborators and report on those meetings on 9/29. These meetings will help you develop the interdisciplinary part of the project. Get started scheduling these meetings and look at what you\u2019ll need to hand in as a report . Coordinate with other class members for interviewing to avoid duplicating collaborator effort. Week 3 (back to top) Date & Topic Assignment Tue 9/22, 2020 Review of NSF CAREER proposal Shape Capture and Modeling for Wrist Dynamics and Ancient Pottery Analysis using Manifold Surfaces and Signed-Distance Volume Images (Laidlaw) Evaluating project possibilities Reading NSF Faculty Early Career Development (CAREER) Program Announcement Read annual status report to NSF . Once again, this gives a feel for what NSF is interested in. Shape Capture and Modeling for Wrist Dynamics and Ancient Pottery Analysis using Manifold Surfaces and Signed-Distance Volume Images This is a second example of an interdisciplinary visualization proposal. The application areas are quite different and the proposal is more focused on visualization. Skim the whole proposal, then read the Project Summary and Project Description. AFTER writing your own review (see Deliverables), I would have had you read of the proposal, then add any new discussion questions to your review. But somehow the file with the reviews in it has disappeared. They are even missing from the NSF website, so I can't regenerate them as of 2020. Sorry... Deliverables (9am) Write your own review ( using this form ) of the CAREER proposal and hand it in as yourBrownShortID.txt. Do the review before reading the NSF reviews. Continue interviewing possible collaborators. Thu 9/24, 2020 Discuss project ideas Reading Read Request For Proposals (RFP) Browse previous CSCI2370 proposals linked on the Ideas page Deliverables (9am) Three possible proposal titles and summaries as yourBrownShortID-2.txt. For each, include a brief description, a list of participants, and your evaluation of the proposal you imagine. Use the RFP to guide your project ideas and to self-evaluate them. Clearly identify the research contributions. Week 4 (back to top) Date & Topic Assignment Tue 9/29, 2020 Review and discuss NIH proposal Quantitative Inverse Electrocardiography (Johnson) Discuss interviews Searching literature for related work Reading Read Quantitative inverse electrocardiography (Johnson). This proposal is more than 15 years old, so the work is not current. It does show an excellent example of a successful non-clinical NIH grant proposal. Non-clinical work is often quite difficult to get funded by NIH. Note the structure of the proposal, with well-formulated hypotheses to test. Skim the whole thing and read the four sections starting with Specific Aims. Read partial list of resulting papers Read Visualizing bioelectric fields , MacLeod et al. (sorry about the pictures...) Read NIH guide to proposals , skimming over the structure of a submission (pg. 1-15), the nfocusing on the research plan details (pg. 15-18), review criteria (pg. 34), and other interesting and relevant parts you find. Read this PowerPoint presentation about the NIH proposal review process Deliverables (9am) Interview reports as yourBrownShortID.txt Your review of Johnson\u2019s NIH grant as yourBrownShortID-2.txt Thu 10/1, 2020 Review and discuss additional NSF proposals Proposal needs? Visualizing multi-dimensional data Research contributions, yes again! Reading The following proposals give a flavor for different styles of proposal, and some of them were not funded. You do not need to read them carefully, but skim through them looking for new and interesting observations to share with the class. MRI: Development of a Next-Generation Interactive Virtual-Reality Display Environment for Science (Laidlaw et al.) and its reviews . HCC: Small: Collaborative Research: Immersive Visualization and 3D Interaction for Volume Data Analysis (Bowman, Socha, and Laidlaw) and its reviews . Here is one that was not funded: CHS: Small: How Much Virtual Reality is Enough and its reviews . I have many more proposals that you can read, particularly unfunded ones :-). If you are interested, reach out! Deliverables (9am) A list of at least five interesting and reaonably rich sharable observations for the class. Hand in as usual. Do not duplicate observations already handed in. I suggest editing your observations in the handin directory to avoid duplication. If you have less rich observations, include more! Week 5 (back to top) Date & Topic Assignment Tue 10/6, 2020 Visualization tools Paraview volume rendering Proposal challenges Reading Read Visualization Handbook 's table of contents. For the class, see if the topics in the book suggest some readings related to your project. Are there any new ideas in there for a different project? Google for the authors' web pages and see what other stuff they are working on. If you're interested in reading more, the book may be available at the Sciences Library (SciLi) -- it was at some point :-). Some chapters are likely available online. Many topics will have Wikipedia pages or other tutoial-level pages that will help you become visualization experts. Read The Value of Visualization , and The Value of Infovis . Look for ways to understand and motivate the contributions of your proposed projects. Can you find papers that cite these that are helpful? This could lead to some things for your literature review and related work sections. Deliverables (9am) Hand in results from literature search as yourBrownShortID.txt You should do this search on the project you are most seriously considering doing out of all the ideas you have. Google Scholar is the main place to search for research papers, but there is a list of other options here (Question 3 Where do I search for research papers? ). Continue developing your project proposal, filling in any weaknesses, fleshing out the related work section, etc. Be prepared to briefly describe the project idea you are most seriously considering and any issues, concerns, problems, etc. that we can discuss in class. The first item in your literature search should be the paper you think would be most valuablefor the class to all read and discuss. Clearly label it as such. Install Paraview on your computer from the first step in the tutorial. Also download the tutorial.vtk file. Bring to class. Thu 10/8, 2020 more \"Visualization Handbook\" Reading Read the three papers listed in in your co-students' literature review handins from last class. Make a listof five discussion observations or questions, just as you did for the three proposals last week.You should be focused on finishing your proposal drafts, so if you need to do these readingsquickly that is ok. Deliverables (9am) Sign up for a presentation time in the spreadsheet posted in the Google drive Collaborators Meetings & Proposal Presentations (top-level, the same file used for collaborators meetings, but use the second tab.) Preliminary proposal handed in as yourBrownShortID.pdf. This should be a full draft, ready for comments by reviewers. A template for your proposal can be template for your proposal can be downloaded here. See the README inside for more instructions. The overleaf read-only repos can be found at proposals and final reports . Make sure your proposal is saved as a pdf. Week 6 (back to top) Date & Topic Assignment Tue 10/13, 2020 Proposal presentations, 5 minutes each Reading Begin reading proposals from the shared Google Drive folder Deliverables (9am) Presentation slides handed in as yourBrownShortID_slides.pptx or pdf. David*much* prefers pptx with all videos and images embedded in the file. Google slidesis not ok... (you can create in it, but convert and submit as pptx and make surethat everything plays correctly without the presenter being you. Thu 10/15, 2020 Improving proposals and examples Insight-based evaluation: what is it, and should you use it? Evaluating visualizations Reading \u201cAn Insight-Based Methodology for Evaluating Bioinformatics Visualizations\u201d , Saraiya et al., TVCG, 2005. \u201cEmpirical Studies in Information Visualization Evaluation: Seven Scenarios\u201d , Lam et al., IEEE TVCG 18, 9 (September 2012). Read proposals from the shared Google Team Drive 10-11/Preliminary Proposals Deliverables (9am) Find your review assignment within the same folder / the top level of the shared drive. Review of the first-draft proposals assigned to you. Use a separate form for each review you write, and name the file proposer_by_reviewer .txt when you hand it in. For instance, if David reviews Fumeng's proposal, he should hand in a file called fyang7_by_dhl.txt. Week 7 (back to top) Date & Topic Assignment Tue 10/20, 2020 \"Walking > Walking-in-Place > Flying\" Walkthrough of a project budget Link to paper for in-class activity: \u201cWalking > Walking-in-Place > Flying, in Virtual Environments\u201d , Usoh et al., In Proceedings of SIGGRAPH, 1999. Deliverables (9am) Final proposal handed in as yourBrownShortID.pdf Thu 10/22, 2020 Study section (evaluate, score, \u201cfund\u201d proposals) Link for in-class activity: Table of linked reviews and NIH-style proposal scores: {TBD} Reading Read final proposals from the shared Google Team Drive /10-18/all_proposals.pdf Find your in the spreadsheet posted within the same folder / the top level of the shared drive. Deliverables (9am) Review the final proposals assigned to you. For the final proposals, you only need to hand in reviews for the three proposals where you are R1, R2, or R3. You must read the proposals for which you are R3/R4 and be prepared to discuss them in class. Use a separate form for each review you write, and name the file proposer_by_reviewer .txt when you hand it in. For instance, if David reviews Fumeng's proposal, he should hand in a file called fyang7_by_dhl.txt. Respond to the quick questions in this form as yourBrownShortID.txt Week 8 (back to top) Date & Topic Assignment Tue 10/27, 2020 IEEE Visualization Conference online Start the CITI online course , which will certify you to perform \u201chuman subjects research\u201d, like user studies, at Brown. Thu 10/29, 2020 IEEE Visualization Conference online Finish the CITI online course and send your passing Completion Report (pdf) to the TA. If you do not pass on your first try, you must retake the quizzes until you receive a passing grade. Deliverables (9am) Hand in a summary statement on your \u201cPrimary\u201d proposal. Try to capture all the discussion points for the proposal. The length should be however long it takes for you to adequately summarize the discussion. Name the file proposer_by_yourBrownShortID .txt. Week 9 (back to top) Date & Topic Assignment Tue 11/3, 2020 ELECTION DAY -- Brown Holiday No class Thu 11/5, 2020 Check-in on projects Review VIS 2020 program Relate your project to the VIS conference Deliverables (9am) Be ready to explain and discuss your project progress with others in class.A Gantt chart can be a good way to show/explain progress. Mega-sheet with Related Work and VIS paper scores Vis '20 items start on row 1209, so be prepared to do some scrolling. Week 10 (back to top) Date & Topic Assignment Tue 11/10, 2020 Vis '20 Redux Discussion with Fumeng and David about Vis Conference. Where would your project fit at the conference? Read VIS 2020 papers review IEEE VIS 2020 Program (may need login) and papers with your project in mind bring any questions about the conference Thu 11/12, 2020 Project checkins Read VIS 2020 papers prepare for project checkins continue thinking about final presentations and reports Week 11 (back to top) Date & Topic Assignment Tue 11/17, 2020 Week 5 check-in on project schedules Discussion of final plans for projects Remaining challenges and questions Project progress check-in Read VIS 2020 papers Thu 11/19, 2020 Class review forms to be filled out Research abstracts: what to report and how much? Project progress check-in Read VIS 2020 papers Week 12 (back to top) Date & Topic Assignment Tue 11/24, 2020 No class. Happy Thanksgiving! Thu 11/26, 2020 No class. Happy Thanksgiving! Week 13 (back to top) Date & Topic Assignment Tue 12/1, 2020 Penultimate class Last project progress check, finalize contributions, schedule review Prepare slides showing your contributions. Include visuals, graphs, and anyother results that will make the contributions clearer. It is fine to haveplaceholder visuals or graphs. Make sure that the captions for those makeclear what the audience should be able to see (eventually) in each slide. Deliverables (9am) Hand in a pdf of your slides Name the file login1_login2 .pdf corresponding to the group members. Thu 12/3, 2020 Last class Reading period Presentation Dress Rehearsal! e In class, each project will deliver an 8 minute presentation about their project. This is a dress rehearsal for the 8-minute final presentation on 12/8. The \u2018audience\u2019 will have 5 minutes to ask questions after each talk. You should practice your presentation before class at least three times; remember to focus on contributions and results, and don\u2019t go over 8 minutes. We will critique presentations as a class in preparation for the public final presentations. Use the feedback you receive in or after class to revise your final presentation. Deliverables (9am) Hand in a pdf of your slideshow (one per group). Name the file login1_login2 .pdf corresponding to the group members. Hand in a PDF of Your Draft (11:59pm EST) By the end of the day, hand in a draft of your final report. Your report should be a two-page extended abstract (pdf) for your project as yourBrownShortID.pdf. For groups, each student must write his or her own report, in which s/he is listed as the first author and the other group members as co-authors. Your abstract must match the formatting requirements for our class proceedings . Templates for Word and latex can be downloaded here . Please use the finalReport templates. See the README inside for more instructions. Week 14 (back to top) Date & Topic Assignment Tue 12/8, 2020 Final Project Presentation Present your Final Project and Results (2pm) Before the presentation slot, hand in a pdf of your slideshow (one per group). Name the file login1_login2 .pdf corresponding to the group members. Plan for a maximum of 8 minutes of presentation. You will have a few minutes after your talk to answer questions from the audience. Feedback on other reports (11:59pm) Provide feedback about each of the other reports in a Slack DM to the author, me, and Fumeng. Aim for suggestions that could be handled in the remaining few days, thoughts on what worked, or lessons that the authors could take with them for future projects. Thu 12/10, 2020 Final Reports Due Hand in Final Report (11:59pm EST) By the end of the day, hand in a two-page extended abstract (pdf) for your project as yourBrownShortID.pdf. For groups, each student must write his or her own report, in which s/he is listed as the first author and the other group members as co-authors. Your abstract must match the formatting requirements for our class proceedings . Templates for Word and latex can be downloaded here . Please use the finalReport templates. See the README inside for more instructions. P.S. the link here is the same as the link for your draft submission. If you're wondering, here's what we did last time: (2018 calendar)", "https://cs.brown.edu/courses/csci2370/2020/ideas.html": "Project Ideas Home Syllabus Calendar People Links Project Ideas Ideas Compiled for Students Note: Brown-internal or password protected links are styled like this , as opposed to public links . You can also find the list of ideas proposed in previous years: 2000 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 . Proposals and Projects from Previous Years Click on the year numbers to review some of the individual project proposals students made in 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 . The resulting final projects , completed in groups, can be reviewed here for 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 .", "https://cs.brown.edu/courses/csci2300/": "CSCI 2300: Human-Computer Interaction Seminar Spring 2023 This seminar covers methods for conducting research in human-computer interaction (HCI). These topics will be pursued through independent reading, assignments, and class discussion. The seminar comprises four assignments that not just apply HCI research methods but push the envelope of what has been done before. The assignments are designed to be meaningful and potentially discover something new in the field, and students will also attend HCI faculty candidate talks this semester as part of this course. We will have readings that teach HCI methods and provide examples of research contributions, sometimes alongside the reviews of those papers as they were evaluated for publication. The goal of this course is to provide students with the background necessary to perform research in HCI and the skills required to conduct human-centric research. Students who take this course should have a particular interest in HCI research, or wish to learn fundamental skills that will help them with a user interface design or usability evaluation career. There will be little or no content in this course about interface design, but students will find other topics in CSCI 1300 (User Interfaces) relevant. Enthusiastic students who have not taken CSCI 1300 should have independently gained HCI experience or be a graduate student studying a related topic, and be able to manipulate software and data to investigate the research questions posed in class. The course is capped at about 20 students, and there is no waitlist or addition enrollment possible at this point. The Collaboration Policy should be read and signed in class on February 8. Main Themes (Spring 2023) 1) HCI methods, especially empirical experimental design 2) social mechanisms in digital communication 3) self-experimentation 4) AI and crowdwork ethics 5) creatively learning and learning creativity Course Staff Instructor: Jeff Huang , 245 CIT, jeff at cs dot brown dot edu Meeting Times 4:30pm-7pm Wednesday at 241 CIT. Office hours on Wed 2:30-3:30pm. The seminar is fully in-person, without a remote option. Assignments Evaluating (S)ocial Mechanisms Compare and contrast fast-prototyped social apps that we design together that each apply different norms and constraints using a variety of mechanisms to see how small changes affect wellness, trust, privacy, and enjoyment. Self-E(x)periment Designs : Rather than conducting generalizable experiments on samples of the population, you will perform an N = 1 experiment (a self-experiment) to see how changing your behavior affects your own outcomes Constructing an (E)thical Framework : What should modern human subjects review look like for computing studies? Propose a change to the federal \"common rule\" from which institutional review boards derive their rules, to consider modern perspectives of labor, data ownership, power dynamics, and the risks of deanonymization. Measuring (C)reativity : We'll be reviewing measures of creativity and inspiration that's typically used for human-generated content, and seeing how they perform on AI-generated content. What is creativity, and is there something there that's unique to humans? Grading 15 points - Readings 13 points - HCI faculty candidate talks 18 points - Evaluating Social Mechanisms assignment 18 points - Self-Experiment Designs assignment 18 points - Constructing an Ethical Framework assignment 18 points - Measuring Creativity assignment Readings should be done before class on the date a reading is due. For each reading, please write to the Slack channel a short novel comment (not a rephrase of what someone said earlier) about the research contribution/findings from the work, and a short novel comment about your assessment of the work/paper. Comments are encouraged to be in response to existing comments in the channel. Additionally, each reading discussion will be led by two students who will work together to prepare a presentation for the class. Assignments are due at the beginning of class on the date it is marked \"in\" in the schedule below, with a midpoint check-in on the dates marked \"mid\" where we'll discuss progress so far. Students should attend at least 4 faculty candidate talks and submit a combined review of their research quality and potential, with a final comparison between the HCI research work and visions that were presented by each faculty candidate. Grading is done solely by the instructor. The thresholds for A/B/C cutoffs are 90/80/70. Time Allocation Total time spent in and out of class for this course is estimated at 180 hours. Over the 15 weeks of this course, students will spend 2 and a half hours in class each week (or 37.5 hours total). Although specific out-of-class time investments may vary for individual students, a reasonable estimate to support this course's learning outcomes is 145 total out-of class hours, or on average, about 10 hours weekly over a 15-week term. Out-of-class preparation will regularly include about 1-2 hours per class of reading and writing the comments addressing the reading (about 70 hours total), along with presentations. In addition to this ongoing preparation time, students are expected to allocate about 65 hours over the course of the term to writing the four assignments. Finally, approximately 5 hours will be spent attending HCI faculty candidate talks. Accessibility and Accommodations Statement Brown University is committed to full inclusion of all students. Please inform me early in the term if you may require accommodations or modification of any of course procedures. You may speak with me after class, during office hours, or by appointment. If you need accommodations around online learning or in classroom accommodations, please be sure to reach out to Student Accessibility Services (SAS) for their assistance (sas@brown.edu, 401-863-9588). Undergraduates in need of short-term academic advice or support can contact an academic dean in the College by emailing college@brown.edu. Graduate students may contact one of the deans in the Graduate School by emailing graduate_school@brown.edu. Classwork Schedule Day Topics / Reading Due Assignment Jan 25 Topic: overview, HCI research, and reading critically Keshav - How to Read a Paper Kostakos - The Big Hole in HCI Research Feb 1 Topic: social relationships and norms Gilbert - Predicting Tie Strength With Social Media Wei - TikTok and the Sorting Hat , Seeing Like an Algorithm , and American Idle (S) out Feb 8 Topic: social prototyping and evaluation Bernstein - The trouble with social computing systems research Epstein - Revisiting Piggyback Prototyping: Examining Benefits and Tradeoffs in Extending Existing Social Computing Systems (S) mid Feb 15 Topic: validity Ernala - Methodological Gaps in Predicting Mental Health States from Social Media: Triangulating Diagnostic Signals Losh - Reliability, Validity, Causality, And Experiments + Norvig - Warning Signs in Experimental Design and Interpretation Feb 22 Topic: experiment design Gwern - Weather and My Productivity (or one of their other QS reports) Daskalova - Lessons Learned from Two Cohorts of Personal Informatics Self-Experiments (S) in, (X) out Mar 1 Topic: interventions, causality Discussions from online about A/B experiments (read in order) [1] [2] [3] [4] Munson - The Importance of Starting With Goals in N-of-1 Studies (X) mid Mar 8 Topic: crowdwork ethics Marcus - How I Learned to Stop Worrying and Love the Crowd Alkhatib - Examining Crowd Work and Gig Work Through The Historical Lens of Piecework Mar 15 Topic: HCI ethics Brown - Five Provocations for Ethical HCI Research Amershi - Guidelines for Human-AI Interaction (X) analysis Mar 22 No in-person class, share assignment midpoint (X) in, (E) out Mar 29 Spring Break Apr 5 Topic: ideation Siangliulue - Providing Timely Examples Improves the Quantity and Quality of Generated Ideas Tohidi - Getting the Right Design and the Design Right: Testing Many Is Better Than One (E) in, (C) out Apr 12 Topic: working with participants Buchenau - Experience Prototyping Dell - \"Yours is Better!\" Participant Response Bias in HCI Apr 19 Topic: design research Odom - Slow Interaction Design Zimmerman - Research Through Design as a Method for Interaction Design Research in HCI (C) mid1 on Apr 17 Apr 26 Class moved to next week (C) mid2 May 3 Topic: systems vs evaluation Landay - I give up on CHI/UIST + Greenberg - Usability Evaluation Considered Harmful(Some of the Time) CHI - Selecting a Subcommittee (read the descriptions of each subcommittee and check out abstracts from papers that catch your eye) (C) in * We will look at the corresponding reviews for some of these papers in class to see what the original reviewers had to say about it.", "https://cs.brown.edu/courses/csci2370/2018/brown-cs237-fall18-website/": "CSCI2370: Interdisciplinary Scientific Visualization (fall 2018) Home Page Home Syllabus Calendar People Gallery Links Project Ideas Time : Tue/Thu 10:30-11:50AM Location : CIT Building, Room 506 Professor : David H. Laidlaw (CIT 521, dhl at cs.brown.edu) TA: Fumeng Yang (CIT 509, fumeng_yang at brown.edu) Description : Learn how to do interdisciplinary scientific visualization research, from soup to nuts, in one semester. Projects will involve the solution of scientific problems using computer graphics, modeling, and visualization. Working in small groups, students will identify scientific problems, propose solutions involving computational modeling and visualization, evaluate the proposals, design and implement the solutions, apply them to the problems, evaluate their success, and report on results. Examples might include interactive software systems, immersive virtual reality cave applications, quantitative analysis tools, or new applications of existing visualizations methods. Suggested prerequisites : programming experience, some graphics experience, and problem ideas. Permission of the instructor required. New! Final proceedings for 2018 are now available: (pdf) previous years: 2016 | 2014 | 2012 | 2010 | 2007 | 2006* | 2005 | 2004* | 2003 | 2002* | 2000 | 1999 * as \u201cVR Design for Science\u201d (Brown/RISD), now CS137 Brown | Brown CS | Brown CS Visualization", "https://cs.brown.edu/courses/csci2370/2020/": "CSCI2370: Interdisciplinary Scientific Visualization (fall 2020) Home Page Home Syllabus Calendar People Links Project Ideas Time : Tue/Thu 10:30-11:50AM Location : brown.zoom.us/my/laidlaw, maybe CIT 165 Professor : David H. Laidlaw (CIT 521, david_laidlaw at brown.edu, brown.zoom.us/my/laidlaw) TA: Fumeng Yang (CIT 509, fumeng_yang at brown.edu) Description : Learn how to do interdisciplinary scientific visualization research, from soup to nuts, in one semester. Projects will involve the solution of scientific problems using computer graphics, modeling, and visualization. Working in small groups, students will identify scientific problems, propose solutions involving computational modeling and visualization, evaluate the proposals, design and implement the solutions, apply them to the problems, evaluate their success, and report on results. Examples might include interactive software systems, immersive virtual reality applications, quantitative analysis tools, or new applications of existing visualizations methods. Suggested prerequisites : programming experience, some graphics experience, and problem ideas. Permission of the instructor required. previous years: 2018 | 2016 | 2014 | 2012 | 2010 | 2007 | 2006* | 2005 | 2004* | 2003 | 2002* | 2000 | 1999 * as \u201cVR Design for Science\u201d (Brown/RISD), now CS137 Brown | Brown CS | Brown CS Visualization", "https://cs.brown.edu/courses/csci2370/2021/calendar.html": "CSCI2370: Interdisciplinary Scientific Visualization (fall 2021) Calendar Home Syllabus Calendar People Links Project Ideas How to Hand Stuff In How to: We use a How to Read Papers and Proposals Some of the readings needed for the class are password protected due to copyright and privacy issues. These links will appear styled like this , as opposed to the public links . The user/pwd is specific to the Vis group website (VisWeb); it is not the same as your CS account. Make sure to contact the instructors to get the username and password if you forget it (we\u2019ll give it out the first day of class). Almost all of the readings we will do are online. Printing them for your own use is fine. Please look at the color images in color, though! Some of the files are pretty big (40-50 Mb). Finally, please respect the grant proposals you will be reading. They are not published documents and should not be circulated outside of class. Please make sure that you destroy any copies of those documents when you are finished with them for class. Calendar Week 1 (back to top) Date & Topic Assignment Thu 9/9, 2021 Introduction Goals Organization Schedule Summary of class Research contributions, Marching Cubes paper, 2018 course abstracts, 2020 course abstracts, virtual whiteboard\" for class activities. Logistics Make sure the course is in your Banner shopping cart before Friday!!! Week 2 (back to top) Date & Topic Assignment Tue 9/14, 2021 Open problems in Visualization What makes a good problem? Logistics Send David (David_Laidlaw at brown.edu) a small photo of yourself to include on the website . Make sure you can use the shared google drive. Email David if you need help. Reading Read, with an eye toward your essay (below) and also to discuss in class: Toolsmith II paper (Brooks) - this describes how to do research in computer science, which is the \u201chome\u201d discipline for scientific visualization. Top Scientific Visualization Research Problems (Johnson) one of the following: Visualization in Scientific Computing (McCormick, DeFanti, Brown) - set the stage for scientific visualization and its funding back in 1987. Read the executive summary and sections I-III. Skim through appendix A and read the sections that are most interesting to you. Read section A.3. Skim through appendices B and C so you have some idea of what\u2019s in them when you need the information there later. Computational Science: Ensuring America\u2019s Competitiveness (President\u2019s Information Technology Advisory Committee), also CRA NIH Workshop Recommendations and http://www.nitrd.gov/pubs/ Top 10 Unsolved Information Visualization Problems (Chen) suggested reading Bill Hibbard\u2019s vis viewpoints column The Top Five Problems that Motivated My Work . Another vis viewpoints column by David Duke et al. Do You See What I Mean? . Research and Development Agenda for visual analytics developed to define the directions and priorities for future research and development programs focused on visual analytics tools. Illuminating the Path Deliverables (9am) Personal background handed in as yourBrownShortID.txt A fictional essay, 250-750 words. The setting is 5-20 years in the future, and the story should describe how CSCI2370 will have influenced that future you. In particular, it should describe a plausible way that you will have solved or addressed one or more of the visualization research topics from the readings. Hand in as yourBrownShortID-2.txt, as described for personal background handin. Thu 9/16, 2021 Review and discuss NSF ITR proposal: Understanding Unsteady Bioflows through Simulation, Modeling, Visualization, Art, and Psychology (Laidlaw et al.) Evaluating project possibilities Reading These readings will give you a feel for what goes into a research grant proposal: Watch this animation on YouTube about NSF\u2019s review process NSF Grant Proposal Guide (2004) describes how to write a grant proposal. While some of the instructions are specific to NSF, much of the document gives good advice on how to write any proposal. Note that this is the version that was in effect when this proposal was written. There have been several versions since then, so refer to the latest when you write your own NSF proposals! Skim: whole thing Read: I.B, II.C.2.a-f, II.C.2.h-k, III (intro), III.A, III.E-F, VI.G Guidelines for proposal writing NSF Information Technology Research (ITR) Program Announcement . Typically, NSF accepts both unsolicited grant applications (for whatever a proposer thinks is worth doing) and solicited applications. Applications are solicited via a Program Announcement (PA), sometimes called a Request for Proposals (RFP). This is one example of what they are looking for. Read proposal: Understanding Unsteady Bioflows through Simulation, Modeling, Visualization, Art, and Psychology (Laidlaw et al.) . This is a proposal in response to the ITR solicitation. It was successful and was partially funded September 2004. You don\u2019t need to understand all, but try to get the big picture as an example of a multi-disciplinary research project. AFTER writing your own review (see Deliverables), read NSF reviews of the proposal and add any new discussion questions to your review. Read the RFP for class projects Consult the list of project ideas Deliverables (9am) Hand in your own review for the ITR grant as yourBrownShortID .txt Hand in a list of three possible collaborators for your class project as yourBrownShortID-2 .txt. The collaborators can be from class or from other disciplines. The RFP for class projects will help you understand more about the criteria for judging a project idea. Possible collaborators can be from the class, the list of project ideas suggested by various researchers around campus, and any personal contacts you have. Describe the discipline of each possible collaborator and how it is distinct from your area. At least two must be contributors to the list of project ideas or established researchers. Collaborator\u2019s list - You will need to meet with at least three possible collaborators and report on those meetings on 9/28. These meetings will help you develop the interdisciplinary part of the project. Get started scheduling these meetings and look at what you\u2019ll need to hand in as a report . Coordinate with other class members and David for interviewing to avoid duplicating collaborator effort. David will try to be present at the first meeting with each collaborator as a mostly-silent facilitator. Week 3 (back to top) Date & Topic Assignment Tue 9/21, 2021 Review of NSF CAREER proposal Shape Capture and Modeling for Wrist Dynamics and Ancient Pottery Analysis using Manifold Surfaces and Signed-Distance Volume Images (Laidlaw) Evaluating project possibilities Reading NSF Faculty Early Career Development (CAREER) Program Announcement Read annual status report to NSF . Once again, this gives a feel for what NSF is interested in. Shape Capture and Modeling for Wrist Dynamics and Ancient Pottery Analysis using Manifold Surfaces and Signed-Distance Volume Images This is a second example of an interdisciplinary visualization proposal. The application areas are quite different and the proposal is more focused on visualization. Skim the whole proposal, then read the Project Summary and Project Description. AFTER writing your own review (see Deliverables), I would have had you read of the proposal, then add any new discussion questions to your review. But somehow the file with the reviews in it has disappeared. They are even missing from the NSF website, so I can't regenerate them as of 2020. Sorry... Deliverables (9am) Write your own review ( using this form ) of the CAREER proposal and hand it in as yourBrownShortID.txt. Do the review before reading the NSF reviews. Continue interviewing possible collaborators. Thu 9/23, 2021 Discuss project ideas Reading Read Request For Proposals (RFP) Browse previous CSCI2370 proposals linked on the Ideas page Deliverables (9am) Three possible proposal titles and summaries as yourBrownShortID-2.txt. For each, include a brief description, a list of participants, and your evaluation of the proposal you imagine. Use the RFP to guide your project ideas and to self-evaluate them. Clearly identify the research contributions. Week 4 (back to top) Date & Topic Assignment Tue 9/28, 2021 Review and discuss NIH proposal Quantitative Inverse Electrocardiography (Johnson) Discuss interviews Searching literature for related work Reading Read Quantitative inverse electrocardiography (Johnson). This proposal is more than 25 years old, so the work is not current. It does show an excellent example of a successful non-clinical NIH grant proposal. Non-clinical work is often quite difficult to get funded by NIH. Note the structure of the proposal, with well-formulated hypotheses to test. Skim the whole thing and read the four sections starting with Specific Aims. Read partial list of resulting papers Read Visualizing bioelectric fields , MacLeod et al. (sorry about the pictures...) Read NIH guide to proposals , skimming over the structure of a submission (pg. 1-15), then focusing on the research plan details (pg. 15-18), review criteria (pg. 34), and other interesting and relevant parts you find. Read this PowerPoint presentation about the NIH proposal review process Deliverables (9am) Interview reports as yourBrownShortID.txt Your review of Johnson\u2019s NIH grant as yourBrownShortID-2.txt Thu 9/30, 2021 Review and discuss additional NSF proposals Proposal needs? Visualizing multi-dimensional data Research contributions, yes again! Reading The following proposals give a flavor for different styles of proposal, and some of them were not funded. You do not need to read them carefully, but skim through them looking for new and interesting observations to share with the class. MRI: Development of a Next-Generation Interactive Virtual-Reality Display Environment for Science (Laidlaw et al.) and its reviews . HCC: Small: Collaborative Research: Immersive Visualization and 3D Interaction for Volume Data Analysis (Bowman, Socha, and Laidlaw) and its reviews . Here is one that was not funded: CHS: Small: How Much Virtual Reality is Enough and its reviews . I have many more proposals that you can read, particularly unfunded ones :-). If you are interested, reach out! Deliverables (9am) A list of at least five interesting and reaonably rich sharable observations for the class. Hand in as usual. Do not duplicate observations already handed in. I suggest editing your observations in the handin directory to avoid duplication. If you have less rich observations, include more! Week 5 (back to top) Date & Topic Assignment Tue 10/5 2021 Visualization tools Paraview volume rendering Proposal challenges Reading Read Visualization Handbook 's table of contents. For the class, see if the topics in the book suggest some readings related to your project. Are there any new ideas in there for a different project? Google for the authors' web pages and see what other stuff they are working on. If you're interested in reading more, the book may be available at the Sciences Library (SciLi) -- it was at some point :-). Some chapters are likely available online. Many topics will have Wikipedia pages or other tutorial-level pages that will help you become visualization experts. Read The Value of Visualization , and The Value of Infovis . Look for ways to understand and motivate the contributions of your proposed projects. Can you find papers that cite these that are helpful? This could lead to some things for your literature review and related work sections. Deliverables (9am) Hand in results from literature search as yourBrownShortID.txt You should do this search on the project you are most seriously considering doing out of all the ideas you have. Google Scholar is the main place to search for research papers, but there is a list of other options here (Question 3 Where do I search for research papers? ). Continue developing your project proposal, filling in any weaknesses, fleshing out the related work section, etc. Be prepared to briefly describe the project idea you are most seriously considering and any issues, concerns, problems, etc. that we can discuss in class. The first item in your literature search should be the paper you think would be most valuablefor the class to all read and discuss. Clearly label it as such. Install Paraview on your computer from the first step in the tutorial. Also download the tutorial.vtk file. Bring to class. Thu 10/7, 2021 more \"Visualization Handbook\" citing related work Reading Read the top papers listed in in your co-students' literature review handins from last class. Make a listof five discussion observations or questions for each, just as you did for the three proposals last week.You should be focused on finishing your proposal drafts, so if you need to do these readingsquickly that is ok. entire Visualization Handbook Deliverables (9am) Preliminary proposal handed in as yourBrownShortID.pdf. This should be a full draft, ready for comments by peer reviewers. A template for your proposal can be template for your proposal can be downloaded here. See the README inside for more instructions. The overleaf read-only repos can be found at proposals and final reports . Make sure your proposal is saved as a pdf. Week 6 (back to top) Date & Topic Assignment Tue 10/12, 2021 Proposal presentations, 10 minutes each + 15 discussion Reading Read proposals from the shared Google Drive folder Deliverables (9am) Presentation slides handed in as yourBrownShortID_slides.pptx or pdf. David*much* prefers pptx with all videos and images embedded in the file. Google slidesis not ok... (you can create in it, but convert and submit as pptx and make surethat everything plays correctly without the presenter being you. Reviews of the first-draft proposals assigned to you . Use a separate form for each review you write, and name the file proposer_by_reviewer .txt when you hand it in. For instance, if David reviews Ugur's proposal, he should hand in a file called ugur_by_dhl.txt. Thu 10/14, 2021 Improving proposals and examples Insight-based evaluation: what is it, and should you use it? Evaluating visualizations Response to reviewers Reading and Revising \u201cAn Insight-Based Methodology for Evaluating Bioinformatics Visualizations\u201d , Saraiya et al., TVCG, 2005. \u201cEmpirical Studies in Information Visualization Evaluation: Seven Scenarios\u201d , Lam et al., IEEE TVCG 18, 9 (September 2012). Build in ideas from papers in your \"response to reviewers\" below. Deliverables (9am) Your response to reviewers document. It should be the first part of the final proposal that you hand in next week, and the handin today should also include the preliminary proposal. The response should include all the reviews, with each review point responded to following the point. Distinguish the review text from the response text -- indent one or italicize one, etc. Numbering the individual responses or the comments can help in referring back to something that was commented on and addressed in an earlier part of the response. The response should not debate the comment, it should explain how the final proposal has been changed to address the comment. (Or how it will be changed -- the changes don't have to be made yet.) This is the first time for these responses, so please ask if it's not clear what to do. Week 7 (back to top) Date & Topic Assignment Mon 10/18, 2021 Not a class; stuff due MONDAY!! Deliverables (9am) Final proposal handed in as yourBrownShortID.pdf Date & Topic Assignment Tue 10/19, 2021 Study section (evaluate, score, \u201cfund\u201d proposals) Link for in-class activity: Table of linked reviews and NIH-style proposal scores: {TBD} Reading Read final proposals from the shared Google folder Deliverables (9am) Review the final proposals . Use a separate form for each review you write, and name the file proposer_by_reviewer .txt when you hand it in. For instance, if David reviews Ugur's proposal, he should hand in a file called ugur_by_dhl.txt. Respond to the quick questions in this form as yourBrownShortID.txt Thu 10/21, 2021 \"Walking > Walking-in-Place > Flying\" Walkthrough of a project budget Maybe VIS video previews Link to paper for in-class activity: \u201cWalking > Walking-in-Place > Flying, in Virtual Environments\u201d , Usoh et al., In Proceedings of SIGGRAPH, 1999. The video preview or fast-forward URL: https://www.youtube.com/playlist?list=PLjHCTOW5ojrfs6pMGQBc33-lQ8tGTanlE The gsheet for notes/evaluations: https://docs.google.com/spreadsheets/d/1DZsxxn8iayvmLXm5EJq1fv9umD6jqKrRIglcViPq20I/edit#gid=0 Week 8 (back to top) Date & Topic Assignment Tue 10/26, 2021 IEEE Visualization Conference online Work on projects Thu 10/28, 2021 IEEE Visualization Conference online Deliverables (9am) Hand in a summary statement on your \u201cPrimary\u201d proposal. Try to capture all the discussion points for the proposal. The length should be however long it takes for you to adequately summarize the discussion. Name the file proposer_by_yourBrownShortID .txt. Week 9 (back to top) Date & Topic Assignment Tue 11/2, 2021 Check-in on projects Review VIS 2021 program Relate your project to the VIS conference Be ready to explain and discuss your project progress with others in class.A Gantt chart can be a good way to show/explain progress. Mega-sheet with Related Work and VIS paper scores Vis '21 items start on row 1574, so be prepared to do some scrolling. Thu 11/4, 2021 Read VIS 2021 papers Be prepared with any questions about the conference. Week 10 (back to top) Date & Topic Assignment Tue 11/9, 2021 Vis '20 Redux Discussion with David and grad student Fumeng about Vis Conference. Where would your project fit at the conference? review IEEE VIS 2021 Program (may need login) and papers with your project in mind Look over Fumeng Yang's google scholar profile Bring any questions about the conference Thu 11/11, 2021 Project checkins Read VIS 2021 papers prepare for project checkins continue thinking about final presentations and reports Week 11 (back to top) Date & Topic Assignment Tue 11/16, 2021 outlining final papers overleaf draft 20 minutes from ready to share Thu 11/18, 2021 Week 5 check-in on project schedules Discussion of final plans for projects Remaining challenges and questions Project progress presentation Week 12 (back to top) Date & Topic Assignment Tue 11/23, 2021 No class. Happy Thanksgiving! Thu 11/25, 2021 No class. Happy Thanksgiving! Week 13 (back to top) Date & Topic Assignment Tue 11/30, 2021 Penultimate class (not quite...) Last project progress check, finalize contributions, schedule review Prepare slides showing your contributions. Include visuals, graphs, and anyother results that will make the contributions clearer. It is fine to haveplaceholder visuals or graphs. Make sure that the captions for those makeclear what the audience should be able to see (eventually) in each slide. Deliverables (9am) Hand in a pdf of your slides Name the file login1_login2 .pdf corresponding to the group members. Thu 12/2, 2021 in-class system evaluation of project(s) Week 14 (back to top) Date & Topic Assignment Tue 12/7, 2021 Ultimate class Presentation Dress Rehearsal! In class, each project will deliver an 8 minute presentation about their project. This is a dress rehearsal for the 8-minute final presentation on 12/7. The \u2018audience\u2019 will have 5 minutes to ask questions after each talk. You should practice your presentation before class at least three times; remember to focus on contributions and results, and don\u2019t go over 8 minutes. We will critique presentations as a class in preparation for the public final presentations. Use the feedback you receive in or after class to revise your final presentation. Deliverables (9am) Hand in a pdf of your slideshow (one per group). Name the file login1_login2 .pdf corresponding to the group members. Feedback on other reports (11:59pm) Provide feedback about each of the other reports in a Slack DM to the author and David. Aim for suggestions that could be handled in the remaining few days, thoughts on what worked, or lessons that the authors could take with them for future projects. Weeks 15-16 (back to top) Date & Topic Assignment Wed 12/15, 2021, 2pm Final Project Presentation Present your Final Project and Results (2pm) Before the presentation slot, hand in a pdf of your slideshow (one per group). Name the file login1_login2 .pdf corresponding to the group members. Plan for a maximum of 8 minutes of presentation. You will have a few minutes after your talk to answer questions from the audience. Mon 12/20, 2021 Final Reports Due Hand in Final Report (11:59pm EST) By the end of the day, hand in a two-page extended abstract (pdf) for your project as yourBrownShortID.pdf. For groups, each student must write his or her own report, in which s/he is listed as the first author and the other group members as co-authors. Your abstract must match the formatting requirements for our class proceedings . Templates for Word and latex can be downloaded here . Please use the finalReport templates. See the README inside for more instructions. P.S. the link here is the same as the link for your draft submission. If you're wondering, here's what we did last time: (2020 calendar)", "https://cs.brown.edu/courses/csci2370/2021/ideas.html": "Project Ideas Home Syllabus Calendar People Links Project Ideas Ideas Compiled for Students Note: Brown-internal or password protected links are styled like this , as opposed to public links . You can also find the list of ideas proposed in previous years: 2000 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 . Proposals and Projects from Previous Years Click on the year numbers to review some of the individual project proposals students made in 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 . The resulting final projects , completed in groups, can be reviewed here for 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , 2018 , and 2020 .", "https://cs.brown.edu/courses/csci1971/": "Assignments \ufffd Lectures \ufffd Hours \ufffd Documents \ufffd Staff Class is held in person Tuesday and Thursday from 18:40-20:00 in CIT 101 . First class is Thursday Sept 7th. Welcome to 2D Game Engines! This is a largely student-run course, similar to an independent study, and you'll learn lots of techniques needed to create a fledgling game engine. These topics include animation, simple AI, collision detection, physics, and raycasting. You will create a game engine of your own over the course of the semester, adding a few features to it each week. At the same time, you will also create a series of games using your engine that demonstrate the use of the features you add. Near the end of the semester, you will design and implement a final project that uses your game engine to create a complete, polished game. Assignments to do: released design check due Tic Sep 12 Sep 13-14 Sep 19 Alc I Sep 19 Sep 20-21 Sep 26 Alc II Sep 26 Sep 27-28 Oct 3 Wiz I & Wiz Extras Oct 3 Oct 11-12 Oct 17 Wiz II & Wiz Extras & Final Project Idea Oct 17 Oct 18-19 Oct 24 Nin I & Final Project Groups DUE MON 10/30 Oct 24 Oct 25-26 Oct 31 Nin II & Nin Extras Oct 31 Nov 1-2 Nov 7 Final I Nov 7 \ufffd Nov 14 Final II Nov 14 \ufffd Nov 28 Final III Nov 28 \ufffd Dec 5 Final IV Dec 5 \ufffd Dec 19 Lectures If you have trouble accessing any of these materials, please email us! We'll be happy to make accommodations. Sep 7 Course Intro, Basic Architecture PPT Sep 12 Graphics 1, Input 1 PPT Sep 19 Component-Based Design, Game World, Viewports, Content Management PPT Sep 27 Graphics II, Collisions I PPT Oct 3 Physics I, Map Generation (Space Partitioning) PPT Oct 17 Decision Making, Pathfinding, Final Project Overview PPT Oct 24 Physics II, Collisions II PPT Oct 31 Raycasting, Saving/Loading PPT Nov 7 Sound PPT Nov 7 Data persistence PPT Nov 7 Text Boxes PPT Nov 7 Networking PPT Nov 7 Procedural Generation PPT Nov 7 Animation State Machines PPT Hours Refer to the calendar below for the most up-to-date TA hours. Check out how remote/in-person hours will work here . Design Checks take place from Wednesday-Thursday the week each assignment is released. Documents Here are some documents that might be useful to you as you take this course: Course Missive Collaboration Policy Global Requirements IntelliJ Setup Guide Git Guide Anonymous Feedback Form frequently asked questions How will remote/in-person hours work? Check out this handy guide here ! How much work is it? Based on the work from the previous few years of class, we estimate that the projects should take roughly 15-20 hours per weekly checkpoint. There is also a two hour lecture each week and a weekly design check. Do I have to be a video game expert to take this course? Nope! While it does help to have some familiarity with the different types of 2D video games out there, we will explain everything you need to know in order to do the projects. Can I take this course before CS 32? Yes. The pre-requisite for this course is any intro CS sequence. You will be maintaining and improving upon your code and projects throughout the course so this helps out a bit with preparing for CS 32. Where can I get sprites and images for the projects? There are a handful of places that you can find free assets online such as opengameart.org , itch.io , and many more. If you do use resources you find online make sure to give credit and cite. Although it isn't a part of your grade we love to see custom art and designs in submissions. Where do you go to find inspiration? Think about what kind of games you've liked playing in the past, and ask yourself how you'd improve upon them. If you were offered the chance to make a spinoff, what new direction would you take it in? There's a lot of game archetypes out there, and we won't constrain you to a single one of them. (You can absolutely turn a dungeon crawler project into Stardew Valley as long you use the same engine features.) You can make metroidvanias, puzzle games, visual novels, arcade games, simulations, remakes, whatever you want. Links for more inspiration. Can I reuse a game I make here for my CS 32 final project? That depends on how the CS 32 TA's feel about it, but in general, you can't reuse work you submitted for one class for a similar assignment in another class. Your experience creating game engines, however, will allow you to make an even better game for your CS 32 final project. Can I reuse a game I made in CS15/CS32/etc for my final project here? You can reuse the same concept, sure, but keep in mind you'll have to build it all with the game engine you wrote throughout the semester. Porting over the idea is perfectly fine, though. What should I bring to the design check? Design checks in this course are not the same as design checks in CS15/16/17/18. We expect you to have thought about the project and have a good idea of how you will solve some of the central problems it involves, but it's OK if you haven't written any code or made a diagram of your class design. The later you do your design check, though, the more progress we will expect you to have made. Why is this class sometimes designated cs1971? We have two course codes. Don't ask why\ufffdwe don't know either. Hopefully you will never see the other one. Can you show me some final projects done by students from a long time ago? Sure thing, buddy. Fall 2022: Fall 2021: Fall 2013: Fall 2012: Staff Prof. James Tompkin jtompkin he/him/his Previously pushed pixels; presently professes PowerPoints. Favorite video games : X-COM (with respect to time sunk) Currently playing : Disco Elysium and We\ud83d\udc97Katamari REROLL Daniel Cho (HTA) dcho24 he/him/his Favorite video games : Dark Souls 2 Currently playing : Terraria Josh Abramson jabrams8 he/him/his Favorite video games : Celeste Currently playing : Doom Eternal Farran Regan n/a they/them Favorite video games : Stardew Valley Currently playing : Valorant Brown University CSCI 1950N Prof. James Tompkin | cs1950ntas@lists.brown.edu", "https://cs2240.graphics/": "CSCI 2240: Advanced Computer Graphics Monday | Wednesday | Friday, 11:00am - 11:50am, CIT 368 Teaching Staff Instructor Grad TA HTA HTA Daniel Ritchie Aditya Ganeshan Coco Kaleel Anh Truong UTA UTA Mandy He Yuanbo Li Contact Information Slack This course uses Slack for announcements and discussion. If you have questions about the class materials or assignments, requests for clarification, cool graphics-related stuff you want to share, or anything else that may be of interest to the class as whole, post them here. If you have an atypical question that you are certain will not be of interest to any other student, you can DM the instructor and/or TAs. Instructor email If you want to request an extension on an assignment, discuss SEAS accommodations, or have any other issues regarding private or sensitive information, email the instructor directly. Course Calendar Course Description CSCI 2240 is an advanced computer graphics course.It assumes prior experience with the fundamentals of computer graphics, typically by having completed an introductory computer graphics course. The course explores several key areas of 3D graphics---rendering, geometry processing, simulation, and optimization---taking a mathematically-sophisticated approach to each.We will study computational approximations to the physics of light transport and the motion of deformable objects, algorithms for processing 3D triangle meshes, and optimization-based techniques for manipulating 3D shapes.The course culminates with an open-ended, group final project in which students choose a recent research paper of interest and implement the techniques it describes. Past Projects Learning Goals Students who complete this course will: Understand the physics of light transport and be able to implement approximate solutions to the rendering equation. Understand the strengths and weakness of different geometry representations and be able to build efficient algorithms for processing and manipulating meshes. Know how to pose graphics problems as quadratic optimization problems and solve the resulting sparse linear systems. Understand the continuum mechanics governing the motion of solid objects and be able to simulate them through finite element approximations. Build depth of knowledge in one area of computer graphics by completing an open-ended final project. Be able to read technical papers in the graphics literature and implement the algorithms they describe. More holistically: completing this course will take you from \"I know the fundamentals of computer graphics\" to \"I can read and implement graphics research papers and contribute to new graphics research.\" Students who complete this course will be well-prepared to begin an academic research career in computer graphics or to join an industrial research and development lab. Accordingly, this course is challenging. On your journey to becoming an independent graphics researcher/practitioner, expect to be pushed out of your comfort zone. It is totally normal to struggle with some assignments in this course (to which the TAs can attest). If you feel stuck, remember: we're here for you! Take advantage of office hours and ask for help from your fellow students on Slack. Prerequisites The following skills will be necessary for this course: Computer Graphics: This course assumes familiarity with the fundamentals of computer graphics, such as 3D transformations, viewing and projection, basic illumination models, raytracing, and OpenGL. Brown's introductory computer graphics course, CSCI 1230 , is a prerequisite for this course. Similar courses from other institutions may also be acceptable. Software Engineering: The assignments in this course, and particularly the final project, require you to design, develop, and debug large pieces of software. The project work required for CSCI 1230 should be sufficient preparation. If you took an introductory graphics course elsewhere that did not emphasize large software projects, you should have experience with building such projects from other courses. Math: The techniques we will explore in this course are based on physics concepts, involve geometric calculations in three-space, and/or require solving large systems of equations. Familiarity with linear algebra and vector calculus are important for successfully understanding and applying these techniques. If you are not sure whether you can/should take the course, we encourage you to show up to the first class and talk to the instructor. Textbook There is no required textbook this semester. Readings relevant to each course assignment will be posted on this website.Optionally, you might consider purchasing The Graphics Codex , which costs only $10 and provides reference materials which can be useful for the first part of the course (on rendering). Grading Policy Your final grade will be determined by a written assignment, four programming assignments, and a final project, as well as your in-class participation. Percentage-wise, the final grade will break down roughly as follows: 5% &nbsp &nbsp Assignment 0 16% &nbsp Assignment 1 15% &nbsp Assignment 2 14% &nbsp Assignment 3 14% &nbsp Assignment 4 30% &nbsp Final project 6% &nbsp &nbsp Class participation These percentages are estimates, and the final percentage values may vary as we deem necessary. For example, if a particular assignment turns out to be more difficult that we expected, we may (at our discretion) adjust the grade breakdown such that that assignment is less heavily weighted. Late Submissions If you submit an assignment late, 10% of the maximum possible score will be subtracted for each day that is late. Submission within 24 hours after the deadline counts as one day late, within 48 hours after the deadline counts as two days late, and so on. However, you are allowed three (3) late days for the semester. Late days will be factored in at the end of the semester and distributed such that you get the most points possible. Because we do this, use of late days will not be reflected in the initial grade report for your assignments. Sometimes there are special circumstances during the semester that result in exceptions to this late policy. All such circumstances require an official note from the Deans . In general, they only provide support notes on behalf of students who are experiencing disruptive medical or personal circumstances, including those related to Title IX situations, that affect their ability to do academic work in a timely way. You should manage other special circumstances such as interviews, personal travel or extra-curricular factors using the late day policy above. Regrade Requests If you believe that an error was made in grading one of your assignments, please submit a regrade request via Gradescope within one week of receiving your grade . Any regrade requests received after this date will not be considered. Community Service Points We like to reward students who are good course citizens. If you find (or fix!) a bug in any of our assignment code, share a useful resource with the rest of class, or make an especially helpful contribution to discussion (in class or on Slack), then the teaching staff may award you extra credit---the precise amount and how it factors in to your final grade is up to our discretion. Please note that posting solutions to (parts of) assignments is not good course citizenship, nor is showing off how much you know about something. When in doubt, talk to a member of the teaching staff before sharing with the rest of the class. Time Commitment Activity Hours In class 40 Assignments 80 = 4 + (19 x 4) Final Project 40 Office hours, Piazza, etc. 20 Total 180 Capstone This course may be used as a capstone course for an Sc.B. degree. Talk to the instructor about registering 2240 as your capstone course. Assignments Assignment Release Date Due Date 0: Radiometry in Flatland (Flatland) 1/24 2/2 1: Path Tracing (Path) 2/2 Milestone: 2/9, Final: 2/16 2: Geometry Processing (Mesh) 2/16 Milestone: 2/26, Final: 3/6 3: Finite Element Simulation (FEM) 3/6 3/20 4: As-Rigid-As-Possible Surface Modeling (ARAP) 3/18 4/5 Final Project 1/24 Proposal: 4/1, Milestone 1: 4/15, Milestone 2: 4/29, Presentation: 5/10 Two Minute Papers In the spirit of this YouTube channel , we will be starting each class with a brief student presentation of a recent research paper.Everyone is expected to present once; this is a large part of your class participation grade . Sign up for a presentation slot by filling out this spreadsheet . Empty slots in the schedule will be filled by a student selected uniformly at random from the set of students who have not yet presented. Format A brief oral presentation (with a hard cutoff at 5 minutes, so please aim to be shorter than that), accompanied by visual aid. Slides are nice, but not required: you may show figures directly from the paper, or any existing video that supplements the paper. Resources List of Suggested Papers How to Read a CS Research Paper? How to Read a Technical Paper How to Read a Paper Kayvon Fatahalian's Clear Talk Tips Course Schedule Date Topic Slides Video Assignments Jan 24 Introduction and Overview Sign the collaboration policy Google form by next class. Fill out this when2meet so we can schedule hours. Check out the Eigen tutorial . pptx video Flatland out Final project out Jan 26 Radiometry pptx video Jan 29 Rendering Equation & Monte Carlo Integration pptx video Jan 31 Path Tracing & Uniform Hemisphere Sampling pptx video Feb 2 Russian Roulette & BRDFs pptx video Path out Flatland due Feb 5 Tone mapping, more BRDFs pptx video Feb 7 Direct Lighting pptx video Feb 9 Advanced Sampling pptx video Path milestone due Feb 12 Advanced Materials & Light Transport Algorithms pptx video Feb 14 Meshes & Geometry Processing pptx video Feb 16 More Geometry Processing; Subdivision pptx video Path due Mesh out Feb 19 No class (university long weekend) Feb 21 More Subdivision pptx video Feb 23 Mesh Simplification pptx video Feb 26 More Simplification; Remeshing & Filtering pptx video Mesh milestone due Feb 28 Geometry Representations pptx video Mar 1 More Geometry Representations pptx video Mar 4 Simulation: Intro, Implementation, & Forces pptx video Mar 6 Simulation: Continuum Mechanics pptx video Mesh due FEM out Mar 8 Simulation: Finite Element Method pptx video Mar 11 Optimization Intro pptx Mar 13 Linear Solvers Mar 15 ARAP paper discussion Mar 18 ARAP discussion continued ARAP out Mar 20 Paper discussions FEM due Mar 22 Paper discussions Mar 25 No class (spring break) Mar 27 No class (spring break) Mar 29 No class (spring break) Apr 1 Weekly project group meetings begin Final project proposal due Apr 5 ARAP due Apr 15 Final project milestone 1 due Apr 29 Final project milestone 2 due May 10 Final project presentations Final project due General Course Policies Diversity & Inclusion Our intent is that this course provide a welcoming environment for all students who satisfy the prerequisites. Our TAs have undergone training in diversity and inclusion, and all members of the CS community, including faculty and staff, are expected to treat one another in a professional manner. If you feel you have not been treated in a professional manner by any of the course staff, please contact either the instructor, Ugur Cetintemel (Dept. Chair), Tom Doeppner (Vice Chair) or Laura Dobler (diversity & inclusion staff member). If you feel more comfortable speaking with a fellow student about your concern, you can (confidentially) reach out to the Diversity & Inclusion Student Advocates . We will take all complaints about unprofessional behavior seriously. Prof. Krishnamurthi has good notes on this area.To access student support services and resources, and to learn more about diversity and inclusion in CS, please visit this webpage . Brown welcomes students from all around the country and the world, and their unique perspectives enrich our learning community. To empower students whose first language is not English, an array of support is available on campus, including language and culture workshops and individual appointments. For more information, contact the English Language Learning Specialists at ellwriting@brown.edu . Academic Integrity Academic dishonesty will not be tolerated. This includes cheating, lying about course matters, plagiarism, or helping others commit a violation. Plagiarism includes reproducing the words of others without both the use of quotation marks and citation. Students are reminded of the obligations and expectations associated with the Brown Academic and Student Conduct Codes . Collaboration Policy For all assignments in this course, feel free to discuss problems, ideas, and course material with other students in the class. For written math problems whose solution is a single number, you are welcome to compare numbers with other students. However, you may not share your derivation of that number. For programming assignments, showing, copying, or any other form of sharing code is not permitted, with one exception: you may look at another student's code to help them debug under the supervision of TA at TA hours. You may use third-party software, data, or other resources (including large language models such as ChatGPT or Github Copilot), as long as they do not provide the solution directly. You must properly cite them (i.e. in your assignment README) and clearly state what work is your own. As a general policy (for this course and for the rest of your academic career): if you use any idea, text, code, or data from elsewhere, then cite it. Accommodations Brown University is committed to full inclusion of all students. Please inform the instructor if you have a disability or other condition that might require accommodations or modification of any of these course procedures. You may email the instructor, come to his office hours, or speak with him after class, and your confidentiality will be respected. We will do whatever we can to support accommodations recommended by SEAS. For more information, contact Student and Employee Accessibility Services ( SEAS ) at 401-863-9588 or SEAS@brown.edu. Students in need of short-term academic advice or support can contact one of the deans in the Dean of the College office. Mental Health Being a student can be very stressful. If you feel you are under too much pressure or there are psychological issues that are keeping you from performing well at Brown, we encourage you to contact Brown\u2019s Counseling and Psychological Services CAPS . They provide confidential counseling and can provide notes supporting extensions on assignments for health reasons. Incomplete Policy We expect everyone to complete the course on time. However, we certainly understand that there may be factors beyond your control, such as health problems and family crises, that prevent you from finishing the course on time. If you feel you cannot complete the course on time, please discuss with the instructor the possibility of being given a grade of Incomplete for the course and setting a schedule for completing the course in the upcoming year. Thanks to Tom Doeppner and Laura Dobler for text on accommodation, mental health, and incomplete policy.", "https://cs.brown.edu/courses/csci2370/2022/": "CSCI2370: Interdisciplinary Scientific Visualization (fall 2022) Home Page Home Syllabus Calendar People Links Project Ideas Time : Tue/Thu 10:30-11:50AM Location : maybe CIT 506 -- attendance mandatory! Professor : David H. Laidlaw (CIT 521, david_laidlaw at brown.edu, brown.zoom.us/my/laidlaw) Description : Learn how to do interdisciplinary scientific visualization research, from soup to nuts, in one semester. Projects will involve the solution of scientific problems using computer graphics, modeling, and visualization. Working in small groups, students will identify scientific problems, propose solutions involving computational modeling and visualization, evaluate the proposals, design and implement the solutions, apply them to the problems, evaluate their success, and report on results. Examples might include interactive software systems, immersive virtual reality applications, quantitative analysis tools, or new applications of existing visualizations methods. Suggested prerequisites : programming experience, some graphics experience, problem ideas, motivation. Permission of the instructor required. Final project reports from past years, completed in groups: 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , 2018 , 2020 , and 2021 , Websites from past years: 2021 | 2020 | 2018 | 2016 | 2014 | 2012 | 2010 | 2007 | 2006* | 2005 | 2004* | 2003 | 2002* | 2000 | 1999 * as \u201cVR Design for Science\u201d (Brown/RISD), now CS137 Brown | Brown CS | Brown CS Visualization", "https://cs.brown.edu/courses/csci2370/2021/": "CSCI2370: Interdisciplinary Scientific Visualization (fall 2021) Home Page Home Syllabus Calendar People Links Project Ideas Time : Tue/Thu 10:30-11:50AM Location : maybe CIT 506 -- attendance mandatory! Professor : David H. Laidlaw (CIT 521, david_laidlaw at brown.edu, brown.zoom.us/my/laidlaw) Description : Learn how to do interdisciplinary scientific visualization research, from soup to nuts, in one semester. Projects will involve the solution of scientific problems using computer graphics, modeling, and visualization. Working in small groups, students will identify scientific problems, propose solutions involving computational modeling and visualization, evaluate the proposals, design and implement the solutions, apply them to the problems, evaluate their success, and report on results. Examples might include interactive software systems, immersive virtual reality applications, quantitative analysis tools, or new applications of existing visualizations methods. Suggested prerequisites : programming experience, some graphics experience, problem ideas, motivation. Permission of the instructor required. Final project reports from past years, completed in groups: 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , 2018 , and 2020 . Websites from past years: 2020 | 2018 | 2016 | 2014 | 2012 | 2010 | 2007 | 2006* | 2005 | 2004* | 2003 | 2002* | 2000 | 1999 * as \u201cVR Design for Science\u201d (Brown/RISD), now CS137 Brown | Brown CS | Brown CS Visualization", "https://cs.brown.edu/courses/info/csci2420/": "CSCI2420 Probabilistic Graphical Models Not offered this year Offered most years, last taught: Fall 2018 Probabilistic graphical models provide a flexible framework for modeling large, complex, heterogeneous collections of random variables. After a brief introduction to their representational power, we provide a comprehensive survey of state-of-the-art methods for statistical learning and inference in graphical models. We discuss a range of efficient algorithms for approximate inference, including optimization-based variational methods, and simulation-based Monte Carlo methods. Several approaches to learning from data are explored, including conditional models for discriminative learning, and Bayesian methods for controlling model complexity. Programming experience required for homeworks and projects, which integrate mathematical derivations with algorithm implementations. PREREQUISITES: CSCI1420 or APMA1690. Instructor(s): CRN: None", "https://cs.brown.edu/courses/csci2590/": "CS2590: Advanced Cryptography The focus of this semester is zero-knowledge proofs and arguments. Starting from seminal works that introduced and formalized zero-knowledge, we will discuss different zero-knowledge protocols. We will see their applications in various settings such as identification protocols, secure computation and cryptocurrencies. We will then discuss more recent works on zero-knowledge succinct non-interactive arguments. [ zk-SNARGs and SNARKs] Instructor: Anna Lysyanskaya (anna@cs.brown.edu) Course TA: Apoorvaa Deshpande (acdeshpa@cs.brown.edu) Meeting Times and Location: Tuesdays and Thursdays 10:30-11:50 am, CIT 101 TA Hours: Tuesdays 3-5 pm, CIT 102 (Apoorvaa) Thursdays 3-4 pm, CIT 501 (Prof. Lysyanskaya, by appointment) Latest Updates: Problem Set 1 is out. It is due on February 21 in class. [ Link ] Sign-up sheet for presenting is now available. Please sign up before February 4. [ Link ] Course syllabus PDF file is now available. [ PDF ] Course Syllabus and Schedule: Jan 24, 2019: Class Cancelled Jan 29, 2019: Course Overview Jan 31, 2019: Introduction to zero-knowledge, Definitions [ Papers ] Proofs that yield nothing but their validity or all languages in NP have zero-knowledge proof systems [link] O Goldreich, S Micali, A Wigderson, JACM, 1991 Zero-Knowledge: A tutorial by Oded Goldriech [link] Feb 5, 2019: Lower bounds on zero-knowledge [ Papers ] On the Composition of Zero-Knowledge Proof Systems [link] O Goldreich and H Krawczyk, SIAM Journal of Computing, 1996 How to go beyond the black-box simulation barrier [link] B Barak, FOCS 2001 Definitions and properties of zero-knowledge proof systems [link] O Goldreich and Y Oren, Journal of Cryptology, 1994 Feb 7, 2019: Round complexity of zero-knowledge protocols [ Papers ] How to Construct Constant-Round Zero-Knowledge Proof Systems for NP [link] O Goldreich and A Kahan Zero Knowledge Proofs of Knowledge in Two Rounds [link] U Feige and A Shamir, CRYPTO 1989 Which Languages Have 4-Round Zero-Knowledge Proofs? [link] J Katz Feb 12 and 14, 2019: Sigma protocols and Discrete-Log-based protocols [ Papers ] Efficient signature generation by smart cards [link] C Schnorr On Sigma Protocols (Survey Paper) [link] I Damgard A signature scheme with efficient protocols [link] J Camenisch and A Lysyanskaya, SCN 2002 Feb 19, 2019: No Class (President's Day) Feb 21, 2019: Fiat-Shamir Transformation [ Papers ] How to prove yourself: Practical solutions to identification and signature problems [link] A Fiat and A Shamir, CRYPTO 1986 On the (in)security of the Fiat-Shamir paradigm [link] S Goldwasser and Kalai. Feb 26, 2019: Non-interactive zero-knowledge [ Papers ] Non-interactive zero-knowledge [link] M Blum, A De Santis, S Micali, G Persiano, SIAM Journal on Computing, 1991 Feb 28, 2019: Multi-prover Non-interactive zero-knowledge [ Papers ] Multiple Non-interactive zero-knowledge proofs under General Assumptions [link] U Feige, D Lapidot, A Shamir, SIAM Journal on Computing, 1999 March 5, 2019: NIZK Constructions based on bilinear maps [ Papers ] New Techniques for Non-interactive zero-knowledge [link] J Groth, R Ostrovsky, A Sahai, JACM 2012 March 7, 2019: Efficient Non-interactive Proofs for Bilinear Groups [ Papers ] Efficient Non-interactive Proofs for Bilinear Groups [link] J Groth and A Sahai, EUROCRYPT 2008 March 12, 2019: Randomizable and Malleable NIZK Proofs [ Papers ] Randomizable Proofs and Delegatable Anonymous Credentials [link] M Belenkiy, J Camenisch, M Chase, M Kohlweiss, A Lysyanskaya, S Meiklejohn, CRYPTO 2009 Malleable Proof Systems and Applications [link] M Chase, M Kohlweiss, A Lysyanskaya, S Meiklejohn, EUROCRYPT 2012 March 14, 2019: Fully Homomorphic Proofs [ Papers ] March 19, 2019: Computationally sound proofs, probabilistically checkable proofs (PCPs) [ Papers ] Computationally Sound Proofs [link] S Micali, FOCS 1994 March 21, 2019: Succinct NP Proofs [ Papers ] Succinct NP Proofs from an Extractability Assumption [link] G Di Crescenzo and H Lipmaa (2008) March 26 and 28, 2019: No Class (Spring Break) April 2, 2019: Succinct Non-interactive Arguments of Knowledge (SNARKs) [ Papers ] The Hunting of the SNARK [link] N Bitansky, R Canetti, A Chiesa, S Goldwasser, H Lin, A Rubinstein, E Tromer, Journal of Cryptology (2017) April 4, 2019: Implausibility of basing SNARKS on standard assumptions [ Papers ] Separating Succinct Non-Interactive Arguments From All Falsifiable Arguments [link] C Gentry and D Wichs April 9, 2019: SNARKS from Quadratic Spanning Programs [ Papers ] Quadratic Span Programs and Succinct NIZKs without PCPs [link] R Gennaro, C Gentry, B Parno, M Raykova, EUROCRYPT 2013. April 11, 2019: Efficient SNARKS from bilinear assumptions [ Papers ] On the Size of Pairing-Based Non-interactive Arguments [link] J Groth, EUROCRYPT 2016. April 16, 2019: Subversion SNARKs [ Papers ] Subversion Zero-Knowledge SNARKs [link] G Fuchsbauer, PKC 2018. April 18, 2019: Updateable CRS and Applications to zk-SNARKs [ Papers ] Updateable and Universal CRS and Applications to zk-SNARKs [link] J Groth and M Kohlweiss and M Maller and S Meiklejohn and I Miers, CRYPTO 2018. April 23, 2019: Bulletproofs [ Papers ] Bulletproofs: Short Proofs for Confidential Transactions [link] B B\u00fcnz and J Bootle and D Boneh and A Poelstra and P Wuille and G Maxwell, IEEE SnP 2018. April 25, 2019: STARKs (Transparent SNARKs) [ Papers ] Scalable, Transparent, and Post-quantum Secure Computational Integrity [link] E Ben-Sasson and I Bentov and Y Horesh and M Riabzev April 30, 2019: Last Class (Concluding Remarks on ZK Proofs and Arguments)", "https://cs.brown.edu/courses/csci2730/": "cs273 Programming Language Theory Spring 2016 Spring 2015 Fall 2011 Fall 2009 Spring 2002", "https://cs.brown.edu/courses/csci2510/": "CSCI2510: Approximation Algorithms (Spring 2018) Announcements Homework 5 , due on May 4 at 11:00 Worked through this paper on an approximation scheme for packing and covering LPs Homework 4: Problems 7.2, 8.11, 11.2, 15.5, due at beginning of class on April 11. Homework 3: Problems 6.2, 8.2, due at beginning of class on March 14. Homework 2: Problems 7.4, 7.6, 7.8, due at beginning of class on March 5. Homework 1 due at beginning of class on February 16. Syllabus The course calendar lists a guess as to topics per lecture Instructor Professor : Philip Klein (email available at directory.brown.edu , CIT 511), office hours by appointment Topics The following chapters will be emphasized Topics are subject to change. Ch 1: Introduction Ch 4: Deterministic Rounding Ch 7: Primal-Dual Method Ch 8: Cuts and Metrics Ch 11: More Deterministic Rounding Ch 12: Randomized Rounding Ch 14: More Primal-Dual Method Ch 15: More Cuts and Metrics Time permitting, sum-of-squares method Assignments Problem sets will be assigned every 1 to 2 weeks. No exams will be given. Calendar, subject to change Resources Tutorial on sum-of-squares method Description Approximation algorithms deal with NP-hard combinatorial optimization problems by efficiently constructing a suboptimal solution with some specified quality guarantees. We study techniques such as linear programming and semidefinite programming relaxations, and apply them to problems such as facility location, scheduling, bin packing, maximum satifiability or vertex cover. Prerequisite: one of the following: CSCI 1510, 1550, 1810, 1950J, 1950L, any graduate-level course on algorithms (including 2500A, 2500B, 2580). Collaboration Policy In finding solutions to the problems in this class, you are allowed to collaborate with other students in the class. However, you should not retain any written (digitally or otherwise) record from your period of collaboration, and you should write up your solutions on your own, and list the names of those with whom you collaborated. Please don't use sources other than the textbook and lectures in connection with doing the homework problems. Textbook The Design of Approximation Algorithms by David P. Williamson and David B. Shmoys.", "https://cs.brown.edu/courses/csci2750/": "CS2750 \u2013 Topics in Parallel and Distributed Computing Spring 2014 Tuesday and Thursday 1:00-2:20 CIT 368 Schedule Starting Points Course Information Grades and Assignments Course Information Simply put, the goal of this course is to hone certain coreskills essential for success as a researcher or practitioner of ComputerScience. Imagine that some day your boss, or thesisadvisor, or principal investor, or president, or spouse says \u201cyou have a weekto please bring me up to date on state-of-the-art Foozle research\u201d. Failurewill be a CLM (\u201ccareer limiting move\u201d). What will you do? The goal of this course is to take a snapshot of currentresearch topics in distributed and concurrent computing. We will start with papers published in the principal conferences in thisarea. Progress at the forefront of research is often incremental:one researcher publishes a paper posing a question or claiming a result, and a sequence of follow-on papers improve the result or alterthe question. For this reason, we willorganize our approach around the idea of clusters of papers. A cluster consists of one primary paper, the one to read if youcan read only one, together with two or three secondary papers. Theprimary paper may have been the first to formulate the problem or technique, orit may have provided the best solution to the problem, or perhaps it is simplythe most readable. Schedule Slides Course Missive Phoenix++ Grades andAssignments Participation (10%of course grade) Research papers are often poorlywritten, sometimes make exaggerated or misleading claims, and occasionallycontain errors or major ambiguities (imagine that!). I expect students tocontribute to the discussion by asking questions, making observations, andsubjecting material to critical scrutiny. These skills will be useful in anyarea of science. Most important :the course won\u2019t be any fun withoutlively participation from the studio audience. Presentations(40% of course grade) Students will work in teams of two ,and each team should plan to make about four presentations. In consultation with theinstructor, each team will: Identify a topic, Identify an primary paper (see above), and Identify two or three secondary papers. The team will give a presentation on the topic, with anemphasis on: The basic problem or technique, A critical evaluation of the primary paper, The context and depth provided by secondary papers, and Open research questions. Teams are advised, but not required, to show theirpresentations to the instructor before the presentation. Each presentation will have 80 minutes (one classperiod). At least one week before thepresentation, the team will post the primary paper to the web page. At the timeof the presentation, the team will deliver to the instructor some version ofthe presentation suitable for posting on the course web page. Depending on the course enrollment, teams may have topresent more than once. Paper Evaluations(10% of course grade) A paper evaluation form consists of: Your name The paper name Summarize the paper (no more than five sentences) Most important strengths (no more than three, one sentence each) Most important weaknesses (no more than three, one sentence each) State one problem or issue left open (no more than three sentences). Paper evaluations will be graded on a scale of one to three.The default grade is two. Insightful reviews get three, and disappointingreviews get one. Students will email evaluations of primary papers to theinstructor ( cs275.brown@gmail.com )before the start of the class in which the paper is presented. Late orincomplete evaluations get no credit. Students are required to evaluate atleast two-thirds of the primarypapers presented. PresentationEvaluations (10% of course grade) You are also required to evaluate presentations. Why? First,if you have to write a review of someone else\u2019s talk, you had better pay attention.Second, if you know that your own talk is being evaluated by the studioaudience (not just the instructor), then you may try harder to appeal to them.In the Real World\u2122, when you graduate, you will have to capture the attentionof intelligent, well-educated audiences that know little or nothing about yourfield. Sharpen your skills now. A presentation evaluation form must contain thefollowing fields: Name : Your name Presenters : who\u2019s talking? Vision : how well did the presenters explain why thearea matters? Style : did the presenters mumble, fail to make eyecontact, speak too quickly, too slowly, or what? Exposition : were the PowerPoint slides too busy, toougly, or just right? Q&A : How well did the presenters seem to know thematerial? Were they honest about admitting when they don\u2019t know something? Comments : anything else you would like to say. Presentation evaluations will be graded on a scale of one tothree. The default grade is two. Insightful evaluations get three, anddisappointing evaluations get one. Evaluations for talks where I suspect thereviewer was not physically present get zero. Presentation evaluations are intended to be helpful. It isOK to be frank (otherwise what\u2019s the point?) but be polite (no matter how youare provoked). I will merge and edit presentation evaluations and forward themto the presenters. Your evaluations will be kept anonymous, and I retain theright to edit or suppress intemperate or inappropriate comments. Students will email evaluations of presentations theinstructor ( cs275.brown@cs.brown.edu )before Friday 5:00 PM inthe week in which the presentation occurred. Late or incomplete evaluations getno credit. Students are required to evaluate at least two-thirds of the presentations. Project (30% ofcourse grade) The final project requirements are the same as for thepresentation, except that You work alone, not in a team, and You write a term paper, not a presentation. You may choose to work on the same topic as your presentation, but the papers covered should not be the same Consult the instructor if there is any question. Missive: Introduction(slides) Some StartingPoints: \u00b7 PODC 2013 \u00b7 DISC 2013 \u00b7 Transact 2013 \u00b7 ASPLOS 2013 \u00b7 EuroSys 2013 \u00b7 OSDI2012 \u00b7 PPoPP 2013 \u00b7 SPAA 2013 Some of these pages have links to the papers, and some havetitles only. You may need to use search engines or contact the authors. Instructor MauriceHerlihy Maurice Herlihy", "https://cs.brown.edu/courses/csci2950-p/": "Probabilistic Graphical Models News Lectures Assignments Resources Probabilistic Graphical Models CSCI 2950-P: Special Topics in Machine Learning, Spring 2013 Brown University Department of Computer Science Course Information See the syllabus . Instructor Professor Erik Sudderth , lastname-at-cs-dot-brown-dot-edu. Graduate Teaching Assistant Jason Pacheco , lastnamefirstinitial-at-cs-dot-brown-dot-edu. Office Hours Erik Sudderth: Tuesdays 2:30-4:00pm, CIT room 509 . Jason Pacheco: Thursdays 2:30-4:00pm, CIT room 361 . Lectures Tuesdays and Thursdays, 1:00-2:20pm, CIT room 506 . Past Courses Fall 2011: Applied Bayesian Nonparametrics . Spring 2010: Learning & Inference in Probabilistic Graphical Models . Announcements May 2, 2013 Final project presentations will be on Tuesday, May 7 at 1:00pm in Lubrano (CIT 477). Lunch will be served! April 2, 2013 We have extended the deadline for project proposals to April 4, and have also made the homework late submission policy slightly more flexible. See the assignments page. March 4, 2013 As listed on the assignments page, we have extended the deadlines for some homeworks. Course project proposals are now due on Tuesday, April 2. February 28, 2013 Additional instructions on formatting and electronic homework submission are now listed on the assignments page. February 19, 2013 See the assignments page for additional details regarding homework assignments, including handin instructions, collaboration policies, and late submission policies. Homework 1 is due on March 1, 2013. January 30, 2013 The printed course reader, containing Jordan's An Introduction to Probabilistic Graphical Models , will be available at Metcalf Copy Center by Friday morning (possibly earlier). January 29, 2013 To receive email announcements, please register for the course (as an auditor, if not taking for credit). A welcome message was sent to registered students this afternoon. January 28, 2013 Staff office hours will be held on Tuesdays and Thursdays, after lecture. Readings are posted on the course calendar . January 23, 2013 The first lecture will be held at 1:00pm on Thursday, January 24.", "https://cs.brown.edu/courses/csci2950-p/fall2011/": "Applied Bayesian Nonparametrics News Lectures Assignments Resources Applied Bayesian Nonparametrics CSCI 2950-P: Special Topics in Machine Learning, Fall 2011 Brown University Department of Computer Science Course Information See the syllabus . Instructor Professor Erik Sudderth , lastname-at-cs-dot-brown-dot-edu. Graduate Teaching Assistant Jason Pacheco , lastnamefirstinitial-at-cs-dot-brown-dot-edu. Office Hours Erik Sudderth: Mondays 2:00pm-3:00pm, Tuesdays 4:00pm-5:00pm, CIT room 509 . Jason Pacheco: Tuesdays 12:00pm-1:00pm, CIT room 361 . Further discussion in MLRG . Lectures Tuesdays and Thursdays, 2:30pm-3:50pm, CIT room 506 . Past Courses Spring 2010: Learning & Inference in Probabilistic Graphical Models . Announcements November 3, 2011 Prof. Sudderth will hold additional office hours on Friday, November 4 from 3:00-4:00pm. On Monday, November 7 his office hours will be held from 3:00-4:00pm. On Tuesday, November 8 his office hours are cancelled. November 1, 2011 The deadline for submission of project proposals has been extended until Monday, November 7 at 11:59pm. October 6, 2011 Please welcome our new part-time teaching assistant, Jason Pacheco. Jason will hold office hours on Tuesdays at noon in CIT 361, and also coordinate discussions of course material in the Machine Learning Reading Group . October 3, 2011 Prof. Sudderth's office hours are cancelled on Tuesday October 4 (due to Michael Jordan's distinguished lecture ), and Monday October 10 (due to the holiday weekend). September 21, 2011 Please follow the instructions sent to the course mailing list to submit preferences for the readings you'd like to present. Note also that the first reading comments are due on Thursday, Sept. 22. September 17, 2011 All registered students should now be members of the course's Google group brown.course.csci.2950p.2011-fall.s01 . This list will be used for reading comments, as well as course announcements.", "https://cs.brown.edu/courses/csci2950-p/spring2010/": "Learning & Inference in Probabilistic Graphical Models News Lectures Assignments Resources Learning & Inference in Probabilistic Graphical Models CSCI 2950-P: Special Topics in Machine Learning, Spring 2010 Brown University Department of Computer Science Course Information See the syllabus . Instructor Professor Erik Sudderth , lastname-at-cs-dot-brown-dot-edu. Office Hours Wednesdays 3:00pm-5:00pm, CIT room 509 . Lectures Mondays and Wednesdays, 10:30am-11:50am, CIT room 506 . Announcements May 7, 2010 Course project presentations will be held on Monday, May 10 from 10:00am-12:00pm in Lubrano (CIT 477). The deadline for submitting final project reports has been extended to Wednesday, May 19. May 3, 2010 Prof. Sudderth's normal office hours on Wednesday, May 5 are cancelled. His final office hours of the semester will instead be on Thursday, May 6 from 1:30-3:30pm. April 13, 2010 On Wednesday, April 14, the class will meet in a different room, CIT 367. We will return to CIT 506 next week. March 15, 2010 For the remainder of the semester, Prof. Sudderth's Tuesday office hours are cancelled. His Wednesday office hours have been extended to 3:00-5:00pm. March 5, 2010 All classes and office hours are cancelled for the week of March 8-12. Please check the updated schedule for more details. We will makeup these lectures during reading week (May 3-7). February 16, 2010 Addition of many links to tutorials, courses, books, and software for graphical models. These resources may be useful in preparing for course projects. February 10, 2010 A Google group, brown-cs295-p , has been setup to post comments on the course readings. Please follow these detailed instructions to join this group, and post your comments in the specified style. February 9, 2010 The primary course mailing list, cs295-p at cs, has now been setup. Students taking the course who did not receive a welcome message should contact the instructor.", "https://cs.brown.edu/courses/csci2950-u/s18/": "Special Topics on Networking and Distributed Systems Cloud 3.0 Infrastructure CSCI-2950u :: Spring 2018 :: Home Home Syllabus Schedule Resources Quick Summary This is a PhD-level course focusing on the infrastructure advancements and challenges in the next generation of cloud computing: an environment which moves beyond virtual machines and containers to flexible composition of fine-grained services. We will focus on applications, datacenters, networking, orchestration, monitoring, among other things. Focus on research: read, review and present papers, final research project Graduate students or advanced undergrads (with consent of instructor) Not a traditional networking course (not CSCI1680) We will use a conference review system (link coming soon!)to post reviews and hold discussions about papers, and Piazza for announcements and general comments / questions. It is mandatory to register for both. Overview This class is a graduate seminar that focuses on current research topics innetworking, distributed, and operating systems. The focus this semester is onadvanced networking. This course is suitable for graduate students and advanced undergraduates inComputer Science or in other disciplines that wanto to understand how recent developmentsin networking, from technology to policy impact how we use, program, and interact with networks. The course will consist of a mix of lectures by the instructor and guests, andpresentations by the students, followed by discussions. We will read a goodnumber of papers, and students will write reviews of each paper read, before theclass in which the paper is discussed. The other major component of the course is a final research project ona topic related to the course. There is considerable flexibility in the topic of the project, with apreference for topics related to the student's own research if applicable. Theprojects will preferably be done in groups of two, but individual projects are welcome. The best projects of the course could be turned into research publications with further development. Lecture time: Tu/Th 2:30-3:50 Location: Lubrano, CIT Instructor Rodrigo Fonseca rfonseca@cs.brown.edu Office: CIT 329, OH by appointment CSCI-2950u :: Spring 2018 :: Rodrigo Fonseca Last modified: 2018-01-30 22:46:20 -0500. Page design adapted from the glued ideas subtle wp theme. var gaJsHost = ((\"https:\" == document.location.protocol) ? \"https://ssl.\" : \"http://www.\"); document.write(unescape(\"%3Cscript src='\" + gaJsHost + \"google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E\")); try { var pageTracker = _gat._getTracker(\"UA-371922-7\"); pageTracker._trackPageview(); } catch(err) {}", "https://cs.brown.edu/courses/csci2951-h/": "CSCI-2951H: Algorithms for Big Data Menu Main Page Material Paper Review Form Main Page As advances in technology allow for the collection and storage of vast amounts of data, the task of efficiently analyzing the data and assessing the significance of the discoveries has become a major challenge in algorithms' design. This graduate course/seminar deals with algorithmic tools and techniques for the organization, manipulation and processing of large amounts of data. This course focuses on mathematically well founded algorithmic and statistical techniques. Instructor: Eli Upfal Time: Wednesday, 15:00 - 17:20 Location: CIT-506 Last Update: Jan 24th 2013", "https://cs.brown.edu/courses/info/csci2950-v/": "CSCI2950-V Topics in Applied Cryptography Not offered this year Offered occasionally, last taught: Fall 2020 This course surveys recent developments in applied cryptography. Research in this field is motivated by privacy and security issues that arise in practice from areas like cloud computing, databases, surveillance and finance. Topics will vary each year. Prerequisite: CSCI 1660 required; CSCI 1510 strongly recommended. Instructor(s): Seny F Kamara CRN: 16599", "https://cs.brown.edu/courses/csci2390/2023/": "CSCI 2390 : Privacy-Conscious Computer Systems Home Schedule Assignments Projects Submission Fall 2023 How can we design computer systems that protect users' privacy? This special topics course investigates this question. Course Summary. The goal of CSCI 2390 is to understand privacy-related challenges for computer systems, learn what design trade-offs we face as engineers, and to identify new research directions that might help address these challenges. We will examine research papers on distributed system design, privacy-preserving, and secure computing techniques, and discuss how to apply these ideas in practice. The goal is to understand if, and how, we can answer questions like these: What happens to information we entrust to web services (e.g., email, photo sharing, social networks); how do companies store, process, and share it? What requirements does privacy legislation \u2014 such as the EU's GDPR \u2014 impose on the computer systems involved? Can better protect this sensitive data, both against leaks and against unauthorized or unethical use? We will look at web services, datacenter systems, distributed communication systems, and machine learning systems. During class, you will present and discuss papers, finish small hands-on assignments, work on a research project, and present your project at the end of the semester. Enrollment. CSCI 2390 is a graduate-level class, but undergraduates are very welcome to enroll! Please check the prerequisites and email Malte if you're unsure whether you meet them. Logistics Instructor: Malte Schwarzkopf ( malte@cs.brown.edu ). HTA: Livia Zhu ( lzhu17@cs.brown.edu ). GTA: Kinan Dak Albab ( kdakalba@cs.brown.edu ). Time: TuTh, 2:30-3:50pm. Room: CIT 477. Missive \u2013 Syllabus Anonymous Feedback Links Prior CSCI 2390 offering: Fall 2021 , Fall 2020 , Fall 2019 . CSCI 1380: Distributed Computer Systems and MIT's 6.824: Distributed Systems Engineering . MIT's 6.S974: Decentralized Applications . window.jQuery || document.write('<script src=\"js/jquery-slim.min.js\"><\\/script>')", "https://cs.brown.edu/courses/csci2951-i/": "CSCI 2951-I: Computer Vision for Graphics and Interaction Fall 2022, MW 15:00 to 16:20, CIT 101 Instructor: James Tompkin Faculty StyleGAN interpolation video Contact Everything is through Slack. James' office hour appointment slot signups are here (top left) . Course Description How does computer vision enable new interactive graphical applications, and how can we improve them? Computer vision strives to understand, interpret, and reconstruct information about the real world from image and video data. Computer graphics models dynamic virtual worlds to be synthesized in realistic or stylized ways. In visual computing, these fields are converging since both disciplines create and exploit models describing the visual appearance of objects and scenes. Interaction allows us to explore these worlds, and to use ourselves and our environments directly as interfaces. Machine learning and deep learning allows us to define mappings between domains across vision, graphics, and interaction, and to generate new data such as images from recombining existing databases. Combined, these disciplines enable applications from the seemingly simple, like semantic photo editing, to the seemingly science fiction, like mixed reality. In this seminar course, we will discover the state of the art algorithmic contributions in computer vision which make these new applications possible. We will concentrate on recent research results that were published at top-tier conferences and journals from problem fields such as reconstruction of static and dynamic 3D scenes, computational photography and videography, multi-view camera systems, generative methods for image formation, and vision-based interaction devices. Each week, we will read state-of-the-art papers, present them, and discuss their contributions, impact, and limitations. Then, we will develop projects which implement and extend these ideas. Beyond computer vision, this course will help us learn how to quickly interpret and assess academic papers, and how to give effective and engaging presentations. Please join us! Learning Objectives Upon completion of this course, students will have: Practical experience reading academic papers, and the skill to digest them quickly; Created effective presentations to explain state-of-the-art techniques, by learning how to critique and how to respond to critique; Formed, discussed, and evaluated many project ideas, and gained experience creating structured research project proposals; Developed practical research project skills and demonstrated these on an unsolved computer vision problem; Familiarity with the state of the art in reconstructing and generating images computationally. Course Structure The course is spilt into two halves. In the first half, we will read research papers, present them, and discuss their contributions, impact, and limitations. We will build upon our analyses and discussions to propose projects which would further the state of the art. Then, in the second half, we will try and do it: we will break into teams and implement projects which further the state of the art. First Half\u2014Review, Ideation, and Proposal We will read two papers per week, and think about their successes and limitations. For each paper, everyone will submit two+ questions plus a project ideas for discussion by noon on the day of the seminar . (3-6 hours per week) In class, we will present the papers. Each student will present at least once, and depending on enrollment this could be individually or in groups. Before the presentation, each student must meet with James to go over the work. (5 hours prep; 30 minute presentation) As a class and with a student discussion leader (assigned randomly on the day), we will critique the presentation and discuss its strengths and how it could have been improved. (10 minutes) After the presentation, together we will discuss the papers in detail to understand them and to generate new ideas. Each student will act as the discussion moderator at least once. (30 minutes) In groups, we will develop these ideas into project proposals to try to extend the state of the art. We will critique these proposals in class. (2 proposals; 8 hours per proposal; self-determined but cycling groups). Second Half\u2014Implementation Teams and projects will finalize. Teams will implement their research projects. In class, we will work together to resolve problems and integrate ideas. We will review and critique progress at regular intervals. Finally, we will present our projects to the rest of the visual computing group, and eat cake. Grading 25% paper questions, contribution and improvement in discussion and critique. 25% presentation skill improvement and overall quality. 50% project effort and outcome. Time Commitment Tasks Hours In class 40 Paper reading 35 Paper presentation 5 Projects: \u2014Proposals 10 \u2014Discussion 10 \u2014Implementation 80 Total: 180 Capstone This class can be taken as a capstone. Talk to James about the expected standard and additional work across the course. Prerequisites This is a graduate course, but undergraduates are welcome! As a graduate class, we expect you to be somewhat self-guided; be prepared to read beyond the course material, and to explore and discover for yourself. Students should know something about visual computing before taking this course, e.g., having taken an existing vision, graphics, or deep learning course. Any other interested students should get in touch with James! CSCI 1230 Introduction to Computer Graphics: Should be OK for more experienced students! Knowing something about machine/deep learning will help. CSCI 1290 Computational Photography: This is a hybrid graphics/vision course, so it should put you in good stead. CSCI 1300 Interface Design: It will be tough, unless you know some more fundamental techniques in visual computing. CSCI 1420 Machine Learning: Please expect to learn some graphics by yourself. CSCI 1430 Computer Vision / ENGN 1610 Image Understanding: Some of the graphics concepts may be tougher; this isn't primarily a 'recognition' course. CSCI 1490 Deep Learning: Many topics will touch on deep learning; please expect to learn about graphics. CSCI 2240 Interactive Computer Graphics: Great! Please expect to learn about machine/deep learning by yourself. Late Submissions and Late Days Due to the form of the class, there are no late submissions or late days. We expect you to attend every session, but let James know if you have any special requirements. For sickness and other issues of wellbeing, please obtain a note from health services and we will accommodate. Course Notes Paper Reading We expect you to read every paper in preparation for the upcoming presentation and discussion. Reading these papers may be difficult initially, and students are not expected to understand everything. However, students are expected to actively engage in discussions to further their understanding of the presented material, with the help of the instructor and the class, within a supportive and creative atmosphere. Ideas that are developed during the seminar discussion are intended to directly influence your projects. Paper Presentations What is the research context for this paper? What connections exist to previous work we have read? What is the research problem that this paper is trying to solve? Cut away the extraneous details and explain it in simple terms. What is the contribution over exist works, and how significant is this contribution? What was difficult to understand in their method? Any interesting nuance or tricks? How is the work validated, and in what areas could this be improved? What is good about the work? What are the limitations of the work? How could it be improved? What comes next? Demos are welcome! Code or executables may be available for the techniques, and you should feel free to show them off. Likewise, for video material, but don't just play it without providing any insight. Leading the Discussion Each session, one student will be randomly selected as the discussion leader. They will receive a digest of the submitted questions before the seminar. Their goal is to briefly summarize the strengths and weaknesses of the technique, raise questions appropriately throughout the discussion, covers future work ideas, and keep order. Reading References How to Read and Present Academic Papers: Reading Slides PDF 2MB Keshav, How to Read a Paper, SIGCOMM Computer Communication Review (2007) DOI Fong, Reading a Computer Science Research Paper, SIGCSE Bulletin (2009) DOI McGuire, How to Read [Rendering] Research Papers, UWaterloo Advanced Ray Tracing Course (2019) PPTX Presenting Slides PPTX 10MB / PDF 4MB Fatahalian, Tips for Giving Clear Talks McGuire, How to Present a Research Paper, UWaterloo Advanced Ray Tracing Course (2019) PPTX Further reading material: General terminology: Dictionary of Computer Vision and Image Processing , by Fisher et al. If you find a word or concept that you do not understand, then please consider looking here. Note: Full text is available in 'Online Resources' section. Python Numpy Python Programmer\u2014Numpy in 5 minutes [YouTube] UCSB Numpy Tutorial Numpy Tutorial: A Simple Example-based Guide Linear Algebra: Immersive Linear Algebra , by J. Str\u00f6m, K. \u00c5str\u00f6m, and T. Akenine-M\u00f6ller. Interactive visualizations! 3 Blue 1 Brown\u2014 http://www.3blue1brown.com/ | Geometric interpretation\u2014 Linear Algebra playlist Stanford CS229 review\u2014 http://cs229.stanford.edu/section/cs229-linalg.pdf Probability: Seeing Theory\u2014 http://students.brown.edu/seeing-theory/ Magnusson\u2014Bayesian Inference\u2014 http://rpsychologist.com/d3/bayes/ Image processing: Powell\u2014Kernels\u2014 http://setosa.io/ev/image-kernels/ Neural Networks and Machine Learning: Michael Nielson\u2014 http://neuralnetworksanddeeplearning.com/ Chris Olah\u2014 http://colah.github.io/ Distill\u2014 http://distill.pub/ Wei\u2014practical advice\u2014 http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html Multi-view Geometry: Hartley and Zisserman\u2014 Multiple View Geometry in Computer Vision or online @ Brown Library Tentative Schedule Date Topic Reading / Slides More info First half\u2014Review, Ideation, and Proposal Wed 07 Sep Intro Mon 11 Sep How to read, present, question Approximating Reflectance Functions using Neural Networks, Gargan and Neelamkavil, Eurographics Workshop on Rendering Techniques 1998 Wed 13 Sep Paper\u2014overview Neural Fields in Visual Computing and Beyond , Xie and Takikawa et al., Eurographics STAR 2022 Mon 19 Sep Paper\u2014basic application Learning Continuous Image Representation with Local Implicit Image Function , Chen et al., CVPR 2021 Wed 21 Sep Paper\u2014basic application DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation , Park et al., CVPR 2019 Mon 26 Sep Paper\u2014architecture Implicit Neural Representations with Periodic Activation Functions , Sitzmann and Martel et al., NeurIPS 2020 Wed 28 Sep Paper\u2014signals BACON: Band-limited Coordinate Networks for Multiscale Scene Representation , Lindell et al., CVPR 2022 Mon 03 Oct Paper\u2014forward maps NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis , Mildenhall, Srinivasan, Tanick et al., ECCV 2020 Wed 05 Oct Paper\u2014hybrid representations Instant Neural Graphics Primitives with a Multiresolution Hash Encoding , M\u00fcller et al., SIGGRAPH 2022 Mon 10 Oct Indiginous People's Day\u2014no class Wed 12 Oct Trial proposal session Mon 17 Oct Paper\u2014priors/conditioning pixelNeRF: Neural Radiance Fields from One or Few Images , Yu et al., CVPR 2021 Wed 19 Oct Paper\u2014manipulation Decomposing NeRF for Editing via Feature Field Distillation , Kobayashi et al., NeurIPS 2022 Mon 24 Oct Paper\u2014motion VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution , Chen et al., CVPR 2022 Wed 26 Oct Paper\u2014material/lighting NeRFactor: Neural Factorization of Shape and Reflectance Under an Unknown Illumination , Zhang et al., SIGGRAPH Asia 2021 Mon 31 Oct Project market Halloween (bonus points for costumes) Wed 02 Nov Final project proposal session Second half\u2014Implementation Mon 07 Nov Paper\u2014generative images DreamFusion: Text-to-3D using 2D Diffusion , Poole et al., arXiv 2022; Zero-Shot Text-Guided Object Generation with Dream Fields , Jain et al., CVPR 2022 Wed 09 Nov Paper\u2014generative shape Learning Disentangled Neural Mesh-based Implicit Field for Geometry and Texture Editing , Yang and Bao et al., ECCV 2022 Mon 14 Nov Paper\u2014digital humans SMPLicit: Topology-aware Generative Model for Clothed People , Corona et al., CVPR 2021; PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization , Saito et al., ICCV 2019 Wed 16 Nov Studio session Mon 21 Nov Studio session Wed 23 Nov Thanksgiving\u2014no class Mon 28 Nov Studio session Wed 30 Nov Project review Mon 05 Dec Studio session Wed 07 Dec Studio session Fri 09 Dec New England Computer Vision Workshop @ MIT Class field trip Fri 16 Dec Final presentations General Policy Welcome! Our intent is that this course provide a welcoming environment for all students who satisfy the prerequisites. Our TAs have undergone training in diversity and inclusion, and all members of the CS community, including faculty and staff, are expected to treat one another in a professional manner. If you feel you have not been treated in a professional manner by any of the course staff, please contact any of James (the instructor), John Hughes (Dept. Chair), Tom Doeppner (Director of Undergraduate Studies), David Laidlaw (Director of Graduate Studies), or Laura Dobler (diversity and inclusion staff member). We will take all complaints about unprofessional behavior seriously. Your suggestions are encouraged and appreciated. Please let James know of ways to improve the effectiveness of the course for you personally, or for other students or student groups.To access student support services and resources, and to learn more about diversity and inclusion in CS, please visit http://cs.brown.edu/about/diversity/resources/ . Prof. Krishnamurthi has good notes on this area. Quiet Hours This class runs quiet hours from 9pm to 9am every day. Please do not expect a response from us via any channel. Likewise, we won't ask you to do anything between these times, either, like hand in projects. Academic Integrity, Collaboration, and Citation Feel free to talk to your friends about the concepts in the projects, and work through the ideas behind problems together, but be sure to always write your own code and perform your own write up. You are expected to implement the core components of each project on your own, but the extra credit opportunties often build on third party data sets or code. Feel free to include results built on other software, as long as you credit correctly in your handin and clearly demark your own work. In general, if you use an idea, text, or code from elsewhere, then cite it. Brown-wide, academic dishonesty is not tolerated. This includes cheating, lying about course matters, plagiarism, or helping others commit a violation. Plagiarism includes reproducing the words of others without both the use of quotation marks and citation. Students are reminded of the obligations and expectations associated with the Brown Academic and Student Conduct Codes . Accommodations Brown University is committed to full inclusion of all students. Please inform me if you have a disability or other condition that might require accommodations or modification of any of these course procedures. You may email me, come to office hours, or speak with me after class, and your confidentiality is respected. We will do whatever we can to support accommodations recommended by SEAS. For more information contact Student and Employee Accessibility Services (SEAS) at 401-863-9588 or hiddenemail('brown.edu','SEAS') Enable Javascript to see the email address . Students in need of short-term academic advice or support can contact one of the deans in the Dean of the College office. Mental Health Being a student can be very stressful. If you feel you are under too much pressure or there are psychological issues that are keeping you from performing well at Brown, we encourage you to contact Brown's Counseling and Psychological Services . They provide confidential counseling and can provide notes supporting extensions on assignments for health reasons. Incomplete Policy We expect everyone to complete the course on time. However, we certainly understand that there may be factors beyond your control, such as health problems and family crises, that prevent you from finishing the course on time. If you feel you cannot complete the course on time, please discuss with James Tompkin the possibility of being given a grade of Incomplete for the course and setting a schedule for completing the course in the upcoming year. Electronic Etiquette Laptops are discouraged, please, except for class-relevant activities, e.g., to help answer questions and show items relevant to discussion. No social media, email, etc., because it distracts not just you but other students as well. Read Shirky on this issue ( \"Why I Just Asked My Students to Put Their Laptops Away\" ), or Rockmore ( \"The Case for Banning Laptops in the Classroom\" ). We will release course lecture material online. In considering laptop use for note taking, please be aware that research has shown note taking on paper to be more efficient than on a laptop keyboard ( Mueller and Oppenheimer ), as it pushes you to summarize the content instead of transcribe it. Acknowledgements Portions of this seminar design are from Stefanie Tellex's CSCI 2951-R course, from Christian Theobalt and his CVfCG course @ Max-Planck-Institute for Informatics , with special thanks to Christian Richardt . Thanks also to James Hays and CSCI2951-T Data-Driven Computer Vision course @ Brown University , with special thanks to Genevieve Patterson . Thanks to Karras et al. (StyleGAN, CVPR 2019) and to Dmitry Nikitko , whose software I used to make the Brown CS faculty bust teaser. Thanks to Tom Doeppner and Laura Dobler for the text on accommodation, mental health, and incomplete policy. Thank you to the previous students who helped to improve this class. Previous course runs: 2019 Fall 2018 Spring 2017 Fall", "https://cs.brown.edu/courses/info/csci2951-i/": "CSCI2951-I Computer Vision for Graphics and Interaction Offered this year and most years Fall 2024 Computer vision reconstructs real world information from image and video data; computer graphics synthesizes dynamic virtual worlds; interaction lets us explore these worlds; and machine learning allows us to map between domains across vision, graphics, and interaction. In visual computing, these fields converge to exploit both models of visual appearance and databases of examples to generate and interact with new images. This enables applications from the seemingly simple, like semantic photo editing, to the seemingly science fiction, like mixed reality. In this seminar, we will discover the state-of-the-art algorithmic contributions in computer vision which make this possible. Please join us! Prerequisites: CSCI 1430, 2240, CLPS 1520, COGS 1200 or ENGN 1610. Instructor(s): James H Tompkin Course Home Page: https://cs.brown.edu/courses/csci2951-i/ Location: TBD Meeting Time: TBD Exam Group: TBD CRN: None", "https://cs.brown.edu/courses/csci2951-j/": "Topics in Advanced Algorithmics: Algorithmic Game Theory, 3D Computational Geometry, Quantum Computing Who:Claire Mathieu and Franco P. Preparata When: MF 1:30-2:50 Where: CIT 506 What: The first half of the course (up until Spring break) will be on connecting computer science to economics: introduction to mechanism design, combinatorial auctions, computational efficiency in mechanisms, profit maximization, distributed aspects, cost sharing, and online mechanisms.The second half of the course consists of two topics in algorithmic theory: 3D-computational geometry, its model and foundations, convex hulls, intersection, proximity; introduction to quantum computing, foundations, networks, notable algorithms, and a critical review. Evaluation: There will be one numerical grade for each half of the course, then the two grades will be reconciled by the two instructors into a final letter grade.Each student can choose whether they want a letter grade or prefer S/NC. Algorithmic Game Theory (Claire Mathieu) Here is how it will be. Assignments: Assignment 1 due Feb 4 at 1:30pm. Assignment 2, handed out in class, is due Feb 18 at 1:30pm, say. Office hours: M 3-5, CIT 555 and (\"and\"? Or is it \"or\"?) by appointment. Schedule: Class on Wednesday 2/13 at 1:30pm, root CIT Library (4th floor) to make up for Friday 2/8 snowday. W 2/13 First class at a special time, On Wednesday 1/23 at 1:30pm, room CIT 506. We covered: Book chapter 1 sections 1.1.1, 1.1.2, 1.1.4, 1.3.1, 1.3.3, 1.3.4, and 1.3.5. (did not finish the proof, which is not in the book) The second class will be on Friday 1/25 at 1:30pm. Please read section 1.3.5 before then so that you can follow the end of the proof. There will be no class on 1/28 and 1/31 (Claire is at a conference). To make up for it, on the week of 2/3 there will be three classes instead of two, on M 2/4, W 2/6 , and F 2/8. References: Noam Nisan, Tim Roughgarden, Eva Tardos, and Vijay V. Vazirani. Algorithmic Game Theory . Cambridge University Press, New York, NY, USA,2007. You can view the entire book online by going to the first page of the preface (viewable on Amazon for example)and folowing the instructions therein. David Bindel, Jon M. Kleinberg, and Sigal Oren. How bad is forming yourown opinion? CoRR, abs/1203.2973, 2012 Ioannis Caragiannis, Angelo Fanelli, Nick Gravin, and Alexander Skopalik. Efficient computation of approximate pure nash equilibria in congestiongames .In Proceedings of the 2011 IEEE 52nd Annual Symposium on Foundations of Computer Science, FOCS '11, pages 532{541, Washington, DC,USA, 2011. IEEE Computer Society Richard Cole, Vasilis Gkatzelis, and Vahab S. Mirrokni. Coordination mech-anisms for weighted sum of completion times in machine scheduling . CoRR,abs/1010.1886, 2010. Paul W. Goldberg, Christos H. Papadimitriou, and Rahul Savani. The com-plexity of the homotopy method, equilibrium selection, and lemke-howsonsolutions . CoRR, abs/1006.5352, 2010. Nicole Immorlica, Adam Tauman Kalai, Brendan Lucier, Ankur Moitra,Andrew Postlewaite, and Moshe Tennenholtz. Dueling algorithms . CoRR,abs/1101.2883, 2011. Jon Kleinberg and Sigal Oren. Mechanisms for (mis)allocating scienticcredit . In Proceedings of the 43rd annual ACM symposium on Theory ofcomputing, STOC '11, pages 529{538, New York, NY, USA, 2011. ACM. Stefano Leonardi and Tim Roughgarden. Prior-free auctions with orderedbidders . In Proceedings of the 44th symposium on Theory of Computing,STOC '12, pages 427{434, New York, NY, USA, 2012. ACM. 3D Computational Geometry (Franco Preparata) Quantum Computing (Franco Preparata)", "https://cs.brown.edu/courses/csci2951-l/": "CSCI 2951L: Human-Computer Interaction Seminar Spring 2014 This seminar covers methods for conducting research in human-computer interaction (HCI). These topics will be pursued through independent reading, assignments, and class discussion. The seminar comprises four assignments that not just apply HCI research methods but push the envelope. The assignments are designed to be meaningful and have the potential to be widely visible or to be published. We will have readings that teach HCI experimental research methods and provide examples of valuable contributions. The goal of this course is to provide students with the background necessary to perform research in HCI and the skills required to conduct human-centric research. There will be little or no content in this course about user interfaces, but students will find topics in CSCI 1950i (User Interfaces) relevant. Enthusiastic students who have not taken CSCI 1950i should contact the instructor for a registration override code. The class will meet in room 506, CIT from 1:00pm-1:50pm MWF. Instructor Jeff Huang , 407 CIT, jeff at cs dot brown dot edu Teaching Assistant Alexandra Papoutsaki , 507 CIT, alexpap at cs dot brown dot edu Assignments Crowdsourcing assignment Experiment with different crowdsourcing models to generate an accurate database of all computer science professors, including metadata like degrees, subfield, rank, and advisor. You will each be responsible for a handful of universities and we will aggregate the data at the end to make the database public , and publish the lessons learned. Experiment bughunt Comb through six empirical papers from CHI/UIST and identify experimental errors. We will aggregate this information to find out what are the common mistakes in HCI research, and publish our findings online. Redesign assignment Create a provocative redesign of a classic interface using the design research approach. For example, you may change the user model from action-object to object-action, or use real-world metaphors to design affordances. Popular online examples: dontclick.it , boarding pass redesign , automotive gesture touchscreens . Fitts' Law study Run a variant of the classic Fitts' Law experiment, which can be combined as a class for a meta-analysis that can potentially be submitted for publication as a class. Grading 12% Reading summaries 18% Crowdsourcing assignment 18% Redesign assignment 18% Experiment bughunt 18% Fitts' Law study 16% Participation Schedule Day Topic Reading Due Assignment Jan 22 Overview Jan 24 Introduction Grudin - Three faces of human-computer interaction Jan 27 Crowdsourcing Kittur - Crowdsourcing user studies with Mechanical Turk Crowdsourcing assignment out Jan 29 Crowdsourcing ** Marcus - How I Learned to Stop Worrying and Love the Crowd Jan 31 Crowdsourcing Feb 3 Crowdsourcing * Bernstein - Soylent: a word processor with a crowd inside Feb 5 Assignment midpoint Crowdsourcing assignment mid Feb 7 Online Experiments Kohavi - Controlled experiments on the web Feb 10 Online Experiments Discussions from online (read in order) [1] [2] [3] [4] Feb 12 Assignment review Crowdsourcing assignment due Feb 14 Experimental Methods Losh - Reliability, Validity, Causality, And Experiments Experiment bughunt out Feb 19 Experimental Methods Wobbrock - Practical Statistics for HCI (ps4hci.key.pdf Chap 1 & 2) Feb 21 Experimental Methods Kapstein - Rethinking Statistical Analysis Methods for CHI Feb 24 Experimental Methods Nuzzo - Scientific method: Statistical errors Cairn - HCI... Not As It Should Be Feb 26 Experimental Methods Dell - \"Yours is Better!\" Participant Response Bias in HCI Feb 28 Assignment midpoint Experiment bughunt mid Mar 3 Design Research Tohidi - Getting the Right Design and the Design Right: Testing Many Is Better Than One Mar 5 Design Research * Kane - Usable Gestures for Blind People Mar 7 Design Research Mar 10 Assignment review Experiment bughunt due Mar 12 Design Methodology Redesign assignment out Mar 14 Design Methodology ** Norman - The Design of Everyday Things Mar 17 Design Methodology Zimmerman - Research through design as a method for interaction design research in HCI Mar 19 Assignment mid Redesign assignment mid Mar 21 Qualitative Methods Adams - A qualitative approach to HCI research Mar 31 Methodology McGrath - Methodology Matters: Doing Research in the Behavioral and Social Sciences Apr 2 Assignment review Redesign assignment due Apr 4 Fitts' Law MacKenzie - Fitts' law as a research and design tool in human-computer interaction Fitts' Law study out Apr 7 Fitts' Law ** Soukoreff - Towards a standard for pointing device evaluation Apr 9 Fitts' Law Apr 11 Fitts' Law ** Shoemaker - Two-Part Models Capture the Impact of Gain on Pointing Performance Apr 14 Assignment midpoint Fitts' Law study mid Apr 16 Systems ** Landay - A Guide to Systems & Applications Research Olsen - Evaluating User Interface Systems Research Apr 18 Systems * Dixon - Prefab Apr 21 Systems * Fitchett - Improving Navigation-Based File Retrieval Apr 23 Assignment review Fitts' Law study due Apr 24 Social Computing Symposium * Best Paper Award winner; we will look at the corresponding reviews in class to see what reviewers liked about them. ** If you have trouble accessing this paper, an alternate link is http://cs.brown.edu/courses/csci2951-l/[lastname].pdf. Resources Course Missive Collaboration Policy Google Group Forum for Reading Comments", "https://cs.brown.edu/courses/csci2951-k/spring-2019/": "Topics in Collaborative Robotics Home Schedule Mini Proposal 1 Mini Proposal 2 Proposal Midterm Checkpoint Final Project Home The aim of this course is to study how people can collaborate withrobots on complex tasks. People who have taken the course in the pasthave completed projects that resulted in being featured in the NewYorker magazine , papers at top robotics venues. w o alums from the course, Eric Rosen and Sidd Karamcheti, were given honorable mention for the CRA Undergraduate Research award! Meeting Time: Tuesday/Thursday 10:30-12pm Meeting Location: CIT 115. Instructor: Stefanie Tellex TAs: Ben Abbatematteo Piazza: https://piazza.com/brown/spring2018/cs2961k/home After taking this course, you will be able to: Describe and critically evaluate approaches that researchers haveused to enable robots to interact with humans using language andgesture, bridging from language to perceptual and motor actions. Identify open research questions in this area. Complete a researchproject addressing one or more of these research questions. Course requirements This graduate seminar will consist of readings from the technical literature as well as a final project. Grades will be determined by: 20% Attendance and participation 10% Project proposal. 10% Midterm checkpoint 20% Project presentation. 40% Project written document. Prerequisites This class is designed to be accessible to a wide variety of studentswith different backgrounds. If you are unsure if you meet theprerequisites, please contact Stefanie. The course staff will workwith you to design a project that works for you. Freshman have takenthis class and done well. Familiarity with robotics, machine learning, computationallinguistics, and artificial intelligence are all useful. CS 141, 142,146, 148 are all good courses to have taken. We do not expectstudents to have background in all of these areas; we expect thatstudents with diverse backgrounds will teach and learn from each otherin this multi-disciplinary research area. Initial class exerciseswill help facilitate these relationships and build teams of studentsfrom different backgrounds. Class Attendance You are expected to attend each class and take part in discussions andwork with your team. If you are unable to attend class, please let thecourse staff know ahead of time. Final Project Students are expected to complete a research project that advances thestate-of-the-art in collaborative robotics. Two-person teams arestrongly encouraged for the projects, as this area is highlyinterdisciplinary and each team member can bring something unique tothe collaboration. Class exercises will facilitate project ideas andteam formation. At the end of the semester, you will write a project report, formattedas a conference paper. Final projects will be published on the courseweb site. Special Needs Please inform me if you have a disability or other condition thatmight require some modification of any of these course procedures. Youmay speak with me after class or during office hours. For moreinformation, contact Students and Employee Accessibility Services at401-863-9588 or SEAS@brown.edu. Schedule The first few classes will consist of background readings andteam-building activities. Students will perform \u201cpractice\u201d projectproposals, which will consist of a discussion and critique of thereadings. Most class meetings will be \u201clab\u201d classes where the staffwill circulate and discuss your project with you. You are expected toattend all class meetings to meet with your team, work on yourproject, and discuss progress with the course staff. You will also begiven card access to the robot lab, and you can work in the lab at anytime even when class is not meeting.", "https://cs.brown.edu/courses/csci2951-r/": "CS 2951R: Personal Informatics Seminar Spring 2016 Data science for data about you. Computing is expanding our ability to collect and process data about our everyday lives. This seminar covers personal informatics, the collection of data from daily activities for reflection and self-experimentation. We will cover methods for knowing more about yourself through using technology to track different types of data and how to interpret them, and run controlled experiments on yourself. We will learn about self-reflection and visualization, experimental design, time-series analysis and apply them to domains of location, sleep, activity, time spent, health and wellness. These topics will be pursued through independent reading, assignments, class discussion, and a semester-long self-tracking and experimentation project. Students should already be comfortable working programmatically with data, and preferably taken a course in: data science, machine learning, user interfaces, or probability/statistics. The seminar will have limited enrollment. Please fill out this form to apply . Note: if you've taken CS 1300 , then CS 2951R is more organic, smaller and intimate, less formal, and a bit more like an experiment in itself! We will use Slack for sharing content and posting comments about readings, and the only written handin will be one assignment writeup (A0). Reading comments should be interesting things you noticed in the reading that you'd like us to talk about in class. The assignments will be opportunities for you to do something fun with your own data, and you will share the findings in short \"show and tells\" in class. Course Time and Location Location: 477 CIT (Lubrano) Time: 1:00-2:20pm on Tuesdays and Thursdays Instructor Jeff Huang , 407 CIT, jeff removee @ cs .brown.edu Office hours: Tuesdays 2:30-4:00pm Schedule Day Topic Class Discussion Assignment Jan 28 Keeping Track Didion - On Keeping a Notebook Sunday Times - Memories are made of disks Feb 2 Quantified Self Wolf - The quantified self (watch the TED Talk video) Choe - Understanding Quantified-Selfers' Practices in Collecting and Exploring Personal Data A0 out Feb 4 Quantified Self Watch 2 Quantified Self talk videos Butterfield - Ethnographic Assessment of Quantified Self Meetup Groups (skim) Feb 9 Data: Location Parecki - Everywhere I've Been: Data Portraits Powered by 3.5 years of data and 2.5 million GPS Points Thudt - Visual Mementos: Reflecting Memories with Personal Data A1 out Feb 11 Data: Location Neuhaus - UrbanDiary: A Tracking Project Capturing the beat and rhythm of the city A0 discuss Feb 16 Knowing Yourself Li - Understanding my data, myself: supporting self-reflection with ubicomp technologies A1 check Feb 18 Knowing Yourself Neisser - Five kinds of self-knowledge Prepare a question for Jin Young Kim (guest visitor via Skype) A0 stage1 Feb 23 Holiday Feb 25 Time Spent Charts from the American Time Use Survey (look through the charts) Yao - A Day in the Life of Americans Short tutorial by Jeff to \"Learn D3 in 60 Seconds\" A1 share A0 stage2 Mar 1 Time Spent Scollon - Experience Sampling: Promises and Pitfalls, Strengths and Weaknesses A1 share A2 out Mar 3 Self-Visualizations Felton - Annual Reports Dancy - Data Prepare a question for Nicholas Felton (guest visitor via Skype) Mar 8 Data: Health and Wellness Bentley - Health Mashups: Presenting statistical patterns between wellbeing data and context in natural language to promote behavior change Prepare a question for Chris Dancy (guest visitor via Skype) A2 check Mar 10 Self-Experiments Roberts - The unreasonable effectiveness of my self-experimentation Augemberg - Quantified Self How-To: Designing Self-Experiments Short tutorial by Jeff to \"Learn statistical testing in 60 Seconds\" Mar 15 Self-Experiments Kratochwill - Single-Case Intervention Research Design Standards Daskalova - A Cohort of Self-Experimenters: Lessons Learned from N=1 Personal Informatics Experiments A0 stage3 Mar 17 Data: Motion and Activity O'Sullivan - Physical Computing (Sensing Movement chapter) Short tutorial by Jeff to \"Learn supervised learning in 60 Seconds\" Mar 22 Data: Motion and Activity Sachs - Sensor Fusion on Android Devices: A Revolution in Motion Processing A2 share A3 out Mar 24 Behavior Change Consolvo - Activity Sensing in the Wild: A Field Trial of UbiFit Garden A2 share Mar 29 Holiday Mar 31 Holiday Apr 5 Behavior Change Fogg - Tiny Habits Klasnja - Microrandomized Trials: An Experimental Design for Developing Just-in-Time Adaptive Interventions A3 check Apr 7 Data: Sleep Choe - SleepTight: Low-burden, self-monitoring technology for capturing and reflecting on sleep behaviors A3 share Apr 12 Data: Sleep Winter - Personal Sleep Monitors: Do They Work? Daskalova - SleepCoacher: Combining Computational and Clinician-Generated Sleep Recommendations A3 share A4 out Apr 14 Data: Social Dabbish - Understanding Email Use: Predicting Action on a Message A3 share Apr 19 Time-Series Analysis Penn State - Intervention Analysis Brodersen - Causal Impact Alonso - Autoregressive-moving-average (ARMA) model (optional) Keogh - Symbolic Aggregate approXimation (SAX) Tutorial (optional) Apr 21 Data: Social Wolfram - The Personal Analytics of My Life WolframAlpha - Personal Analytics for Facebook A4 check Apr 26 Data: Social Viegas - Digital Artifacts for Remembering and Storytelling: PostHistory and Social Network Fragments A0 check Apr 28 Models of Personal Informatics Epstein - A Lived Informatics Model of Personal Informatics A4 share May 3 Models of Personal Informatics Li - A stage-based model of personal informatics systems A4 share May 5 Show and Tell A0 share Assignments A0 \"You vs You\" - A hypothesis-driven self-experiment study you perform on yourself A1 \"The Road Taken\" - Collecting and revisiting past places you have been and routes you have taken A2 \"My Life in Pictures\" - Make visuals that allow you to compare your time spent with a larger population A3 \"From Motions to Actions\" - An exercise of classifying raw motion sensor data into activities A4 \"Unrequited Mail\" - Make an email assistant bot to let senders know when to expect a response Important things to know Collaboration policy: if you use something (code, an idea, text, etc.) that you didn't come up with yourself, cite it! By popular vote, laptops/phones should not be used in class except to share something, or to show the reading. The late policy is: extensions can be requested with a reasonable explanation. Moderating: everyone should moderate 2 papers, which involves leading the discussion (short summary and open with questions) and asking academic authors the backstory for the paper. Reading comments: you should make substantive comments for each reading on Slack (adding to the discussion). Getting help: TA Nedi can help you with the technical parts of the assignments. She has weekly office hours at Wed 11am-1pm in 409 CIT. Grading 5% Moderating - Leading reading discussions in class 20% Readings - Reading comments on Slack and discussions in class 25% Assignment A0 10% Assignment A1 15% Assignment A2 10% Assignment A3 15% Assignment A4 Papers Following This Course Self-E: Smartphone-Supported Guidance for Customizable Self-Experimentation Nediyana Daskalova, Eindra Kyi, Kevin Ouyang, Arthur Borem, Sally Chen, Sung Hyun Park, Nicole Nugent, Jeff Huang CHI 2021 Lessons Learned from Two Cohorts of Personal Informatics Self-Experiments Nediyana Daskalova, Karthik Desingh, Alexandra Papoutsaki, Diane Schulze, Han Sha, Jeff Huang IMWUT 2017 Self-Experiments Website", "https://cs.brown.edu/courses/csci2951-o/": "CS2951-O Overview Lectures Staff Foundations of Prescriptive Analytics Professor: Serdar Kadioglu | serdark@cs.brown.edu Teaching Assistant: Anirudh Narsipur | anirudh_narsipur@brown.edu Mailing Lists: {cs2951ostudent, cs2951oheadtas, cs2951otas}@lists.brown.edu Class Hours: Fri 3pm - 5:20pm Class Room: CIT 316 Office Hours: TBD Syllabus: Course Syllabus EdStem: All enrolled/prospective students should have access Academic Code: Academic Honor Code Announcements [Past offerings] Course evaluations: 2017/2018 , 2022/2023 . Course Description We are undoubtedly in the middle of an Analytics Revolution that enabled turning huge amounts data into insights, and insights into predictions about the future. At the final frontier, Prescriptive Analytics aims to identify the best possible outcome given a certain objective function and a set of constraints. With that goal in mind, this course provides students with a comprehensive overview of the theory and practice of how to apply Prescriptive Analytics through optimization technology. A wide variety of state-of-the-art techniques are studied including: Boolean Satisfiability, Constraint Programming, Linear Programming, Integer Programming, Local Search Meta-Heuristics, and Large-Scale Optimization. The students are exposed to the industrially relevant software packages such as IBM Optimization Studio. The practical challenges encountered in implementing such systems are also explored. Additionally, the life-cycle of decision support systems is discussed and problems from real-life application domains such as planning, scheduling, resource allocation, supply-chain management, and logistics are addressed. Course Objectives The primary goal of this course is to introduce the fundamental ideas behind optimization technology to the extent that you can utilize this knowledge to build your own solvers based on various paradigms. Both complete and incomplete search methods, particularly tree-search and heuristic techniques will be covered in order to present different trade-offs. By the end of this course you will be able to transform a given optimization problem into analytical models with complementary strengths, and then, tackle it using off-the-shelf general purpose solvers and/or writing your own custom solutions. This course shall also complement descriptive and predictive analytics as it connects data-centric approaches with their optimum decision-making counterpart. Inclusive Course Goals To ensure that students are able to plan around conflicts and obligations without adversely impacting their grades, we aim to set deadlines that plan around student obligations as best we can and provide extensions when appropriate. To ensure that students can voice their own concerns about the course, we aim to hold sufficient office hours and make it clear to whom students can go and how to voice their concerns.", "https://cs.brown.edu/courses/csci2951-s/": "CSCI 2951-S Distributed Computing through Combinatorial Topology Spring 2016 Instructor: Maurice Herlihy Location:CIT 477 Meeting Time:J: TTh 2:30-3:50 Updates 27 Feb Homework 1 out. Homeworks Homework 1 (due 4 March) Homework 2 (due 15 March) Homework 3 (due 4 April) Homework 4 (due 26 April) Papers for Student Presentations 7 April Marshall: Rental Harmony: Sperner'S Lemma in Fair Division 12 April Kyle: Unreliable Failure Detectors for Reliable Distributed Systems Grading Every two weeks, students will be assigned a set of exercises, most of which will be taken from the textbook. There will be 4 such homeworks. Toward the end of the class,students will also be required to present one or more research papers(the exact number will depend on enrollment).Students are welcome to form teams of 2 or 3,but a team of k students must present k papers. Each student will also do a final project consisting of a 10-page written report on a research paper (no teams). The final grade will be based on 2/3 homeworks + 1/6 presentations + 1/6 final project. Textbook: Distributed Computing Through Combinatorial Topology Tentative Calendar: Collaboration Policy You are encouraged to talk to one another about problems, homwork and otherwise, but everything you write and hand in must be your own work.Email your solution to mph@cs.brown.edu. Please submit a PDF file produced via LaTeX. Slides Introduction pptx PDF 2-process systems pptx PDF Combinatorial Topology pptx PDF Colorless Wait-Free Computation pptx PDF Colorless Tasks in Different Models pptx PDF Byzantine-Resilient Colorless Computation pptx PDF Simulations and Reductions pptx PDF Manifold Tasks pptx PDF Connectivity pptx PDF Wait-Free Computability for General Tasks pptx PDF Renaming and Oriented Manifolds pptx PDF Some suggested papers for final projects Dmitry Kozlov, Topology of the immediate snapshot complexes Michael Erdmann, On the Topology of Discrete Strategies Eli Gafni, Petr Kuznetsov, Ciprian Manolescu, A generalized asynchronous computability theorem Herbert Edelsbrunner and John Harer, Persistent Homology --- a Survey Vin de Silva and Robert Ghrist, Coverage in Sensor Networks via Persistent Homology", "https://cs.brown.edu/courses/csci2951-t/": "CSCI2951-T Data-driven Computer Vision Class Blog \u00bb Spring 2016, TR 9:00 to 10:20am, CIT 477. Instructor: Genevieve Patterson **Figure from : Deep Visual-Semantic Alignments for Generating Image Descriptions. Andrej Karpathy and Li Fei-Fei, CVPR 2015. Final Projects (May 10, 2016) Rapid content based image retrieval by Gustave Marques Netto Determining artifact date and culture from images by Christine Whalen A House Share Price Predictior using a Deep Neural Network by Adam Lesnikowski Deep Learning for Natural Image Segmentation Priors by Gabe Hope Invariant Superpixel Features for Object Detection & Localization by Sam Kelly Course Description Course Catalog Entry Investigates current research topics in data-driven object detection, scene recognition, and image-based graphics. We will examine data sources, features, and algorithms useful for understanding and manipulating visual data. We will pay special attention to methods that harness large-scale or Internet-derived data. There will be an overview of the current crowdsourcing techniques used to acquire massive image datasets. Vision topics such as scene understanding and object detection will be linked to graphics applications such as photo editing. These topics will be pursued through independent reading, class discussion and presentations, and projects involving current research problems in Computer Vision. The goal of this course is to give students the background and skills necessary to perform research in computer vision for image detection. Students should understand the strengths and weaknesses of current approaches to research problems and identify interesting open questions and future research directions. Students will hopefully improve their critical reading and communication skills, as well. Course Requirements Reading and Summaries Students will be expected to read one paper for each class. For each assigned paper, students must write a two or three sentence summary and identify at least one question or topic of interest for class discussion. Interesting topics for discussion could relate to strengths and weaknesses of the paper, possible future directions, connections to other research, uncertainty about the conclusions of the experiments, etc. Reading summaries must be posted to the class blog by 11:59pm the day before each class. Feel free to reply to other comments on the blog and help each other understanding confusing aspects of the papers. The blog discussion will be the starting point for the class discussion. If you are presenting you don't need to post a summary to the blog. Class participation All students are expected to take part in class discussions. If you do not fully understand a paper that is OK. We can work through the unclear aspects of a paper together in class. If you are unable to attend a specific class please let me know ahead of time (and have a good excuse!).Many of the papers covered in this course will have publicly available code andtutorials for running their systems and experiments. For these papers, students will beexpected to run the basic versions of the systems. Students are not expectedto re-implement an entire system or set of experiments. The purpose of these tutorialexercises is to familiarize students with running code written by other researchers. Studentswill be expected to identify strengths and weaknesses of the systems they attemptto run. Presentation(s) Depending on enrollment, students will lead the discussion of one or two papers during the semester. Ideally, students would implement some aspect of the presented material and perform experiments that help understand the algorithms. Presentations and all supplemental material should be ready one week before the presentation date so that students can meet with the instructor, go over the presentation, and possibly iterate before the in-class discussion. For the presentations it is fine to use slides and code from outside sources (for example, the paper authors) but be sure to give credit. Semester projects Students are expected to complete a state-of-the-art research project on topics relevant to the course. Students will propose a research topic part way through the semester. After a project topic is finalized, students will meet occasionally with the instructor to discuss progress. Students will present their progress on their semester project twice during the course and the course will end with final project presentations. Students will also produce a conference-formatted write-up of their project. Projects will be published on the this web page. The ideal project is something with a clear enough direction to be completed in a couple of months, and enough novelty such that it could be published in a peer-reviewed venue with some refinement and extension. Prerequisites Strong mathematical skills (linear algebra, calculus, probability and statistics) and previous imaging (graphics, vision, or computational photography) courses are needed.It is strongly recommended that students have taken one of the following courses (or equivalent courses at other institutions): CSCI 1230, Introduction to Computer Graphics CSCI 1290, Computational Photography CSCI 1430, Introduction to Computer Vision CSCI 2240, Interactive Computer Graphics ENGN 1610, Image Understanding If you aren't sure whether you have the background needed for the course, you can try reading some of the papers below or you can simply come to class during the shopping period. Textbook We will not rely on a textbook, although the free, online textbook \"Computer Vision: Algorithms and Applications\" by Richard Szeliski is a helpful resource. Grading Your final grade will be made up from 20% Reading summaries posted to class blog 20% Classroom participation and attendance, including completion of coding tutorials and project progress reports 20% Paper presentation(s), including partial system implementation or testing 40% Semester project Office Hours: Genevieve Patterson, Tuesday and Thursday 1:00-2:30pm, CIT 551 Tentative Schedule Date Paper Paper, Project page Presenter Thurs, Jan 28 Introduction; the state of vision and crowdsourcing. Genevieve Tues, Feb 2 Microsoft COCO: Common Objects in Context. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollar, and C. Lawrence Zitnick. ECCV 2014. project page , paper Genevieve Tues, Feb 2 Tropel: Crowdsourcing Detectors with Minimal Training. Genevieve Patterson, Grant Van Horn, James Hays, Serge Belongie, Pietro Perona. Human Computation (HCOMP) 2015. pdf Genevieve Thurs, Feb 4 CVPR 2014 Tutorial on Deep Learning . Graham Taylor, Marc'Aurelio Ranzato, and Honglak Lee. Read only the first two sets of labeled Introduction and Supervised learning . CVPR 2014 tutorial Genevieve Tues, Feb 9 ImageNet Classification with Deep Convolutional Neural Networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton. NIPS 2012. pdf Genevieve Thurs, Feb 11 The SUN Attribute Database: Beyond Categories for Deeper Scene Understanding. Genevieve Patterson, Chen Xu, Hang Su, James Hays. IJCV 2014. project page Genevieve Tues, Feb 16 Object Detectors Emerge in Deep Scene CNNs. Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, Antonio Torralba. ICLR, 2015. project page , arXiv Sam also read Learning Deep Features for Scene Recognition using Places Database. B. Zhou, A. Lapedriza, J. Xiao, A. Torralba, and A. Oliva. NIPS 2014. project page , pdf , demo n/a Thurs, Feb 18 Understanding Deep Image Representations by Inverting Them. Aravindh Mahendran, Andrea Vedaldi. CVPR 2015. arXiv Christine Feb 23 No class. Everyone Thurs, Feb 25 Diagnosing error in object detectors. Derek Hoiem, Yodsawalai Chodpathumwan, and Qieyun Dai. ECCV 2012. project page Genevieve Tues, Mar 1 Project Status Updates. Everyone Thurs, Mar 3 DeepBox: Learning Objectness with Convolutional Networks. Weicheng Kuo, Bharath Hariharan, Jitendra Malik. ICCV 2015. arXiv Gabe also read Selective Search for Object Recognition. J. R. R. Uijlings, K. E. A. van de Sande, T. Gevers, A. W. M. Smeulders. IJCV 2013. project page n/a Tues, Mar 8 Fast R-CNN. Ross Girshick. ICCV 2015. arXiv , code Gustavo also read Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. NIPS 2015. pdf n/a Thurs, Mar 10 Fully Convolutional Networks for Semantic Segmentation. Jonathan Long, Evan Shelhamer, Trevor Darrell. CVPR 2015. arXiv Sam Tues, Mar 15 Learning Visual Similarity for Product Design with Convolutional Neural Networks. Sean Bell, Kavita Bala. Siggraph 2015. author page , pdf Gustavo also read Learning Deep Representations for Ground-to-Aerial Geolocalization. Tsung-Yi Lin, Yin Cui, Serge Belongie, James Hays. CVPR 2015. pdf n/a Thurs, Mar 17 What makes Paris look like Paris? Carl Doersch, Saurabh Singh, Abhinav Gupta, Josef Sivic, and Alexei A. Efros. Siggraph 2012. project page Adam Tues, Mar 22 Special Presentation by Zhile Ren. Three-Dimensional Object Detection and Layout using Clouds of Oriented Gradients. Zhile Ren and Erik B. Sudderth. Zhile Ren Thurs, Mar 24 Learning Visual Biases from Human Imagination. Carl Vondrick, Hamed Pirsiavash, Aude Oliva, Antonio Torralba. NIPS 2015. project page Christine Mar 26 - Apr 3 Spring Break. Everyone Tues, Apr 5 Project Status Updates. Everyone Thurs, 4/7 Deep Neural Decision Forests. Peter Kontschieder, Madalina Fiterau, Antonio Criminisi, and Samuel Rota Bulo. ICCV 2015. Project page Gabe Tues, Apr 12 Vision for Robotics. Presentation from the Tellex Lab. n/a Stefanie Tellex and John Oberlin Thurs, Apr 14 VQA: Visual Question Answering. S. Antol*, A. Agrawal*, J. Lu, M. Mitchell, D. Batra, C. L. Zitnick, and D. Parikh. ICCV, 2015. project page , arXiv Christine also read Visual Turing test for computer vision systems. Geman, Donald, etal. Proceedings of the National Academy of Sciences 112.12 (2015):3618-3623. PNAS page n/a Tues, Apr 19 Exploring Nearest Neighbor Approaches for Image Captioning. Jacob Devlin, Saurabh Gupta, Ross Girshick, Margaret Mitchell, C Lawrence Zitnick. arXiv, 2015. arXiv Adam Thurs, Apr 21 How do humans sketch objects? Mathias Eitz, James Hays, and Marc Alexa. Siggraph 2012. project page Gabe Tues, Apr 26 Quizz: Targeted crowdsourcing with a billion (potential) users. Ipeirotis, Panagiotis G., and Evgeniy Gabrilovich. Proceedings of the23rd international conference on World wide web. ACM, 2014. pdf Gustavo Thurs, Apr 28 Transient Attributes for High-Level Understanding and Editing of Outdoor Scenes. Pierre-Yves Laffont, Zhile Ren, Xiaofeng Tao, Chao Qian, James Hays. Siggraph 2014. project page Genevieve Tues, May 3 Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. Alec Radford, Luke Metz, Soumith Chintala. 2015. project page , arXiv Sam Tues, May 10 Final Project Presentations 9am - approx. 11:30am Everyone * Note: Final Project reports due 11:59 PM EST on Tues May 10. Suggested Topics Date Paper Paper, Project page Presenter Crowdsourcing and Human Computation ? Micro Perceptual Human Computation for Visual Tasks. Yotam Gingold, Ariel Shamir, Daniel Cohen-Or. ACM Transactions on Graphics (ToG) 2012 project page ? ? Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation. R. Girshick, J. Donahue, T. Darrell, J. Malik. CVPR 2014. arXiv ? Learned Representations, ConvNets, Visualizations ? Going Deeper with Convolutions. Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich. 2014. arXiv ? Object Proposals ConvNet detection and segmentation ? Visualizing and Understanding Convolutional Networks. Matthew D Zeiler, Rob Fergus. ECCV 2014. pdf ? Weakly Supervised and Unsupervised ConvNets ? Unsupervised Visual Representation Learningby Context Prediction. Carl Doersch, Abhinav Gupta, Alexei A. Efros. ICCV 2015. project page ? Images and Words ? Visual Madlibs: Fill in the blank Description Generation and Question Answering. Licheng Yu, Eunbyung Park, Alexander C. Berg, Tamara L. Berg. ICCV, 2015. project page , pdf ? Generative ConvNets ? Learning to Generate Chairs, Tables and Cars with Convolutional Networks. Alexey Dosovitskiy, Jost Tobias Springenberg, Maxim Tatarchenko, Thomas Brox. CVPR 2015. arXiv ? ? A Neural Algorithm of Artistic Style. Leon A. Gatys, Alexander S. Ecker, Matthias Bethge. 2015. implementation , arXiv ? ? Aggregating local descriptors into a compact image representation (VLAD). H. Jegou, M. Douze, C. Schmid, and P. Perez. In Proc. CVPR, 2010. pdf ? Siamese / Ranking / Triplet ConvNets ? Joint Embeddings of Shapes and Images via CNN Image Purification. Yangyan Li, Hao Su, Charles Ruizhongtai Qi, Noa Fish, Daniel Cohen-Or, Leonidas Guibas. Siggraph Asia 2015. project page ? Attribute-based Representations ? Automatic attribute discovery and characterization from noisy web data. Berg, Tamara L., Alexander C. Berg, and Jonathan Shih. Computer VisionECCV 2010. Springer Berlin Heidelberg, 2010. 663-676. pdf ? ? Discovering the Spatial Extent of Relative Attributes. Fanyi Xiao, Yong Jae Lee. ICCV 2015. pdf ? Discriminative Feature Discovery Misc ? Learning to predict where humans look. T. Judd, K. Ehinger, F. Durand, and A. Torralba. IEEE International Conference on Computer Vision (ICCV), 2009. project page ? ? Learning a Discriminative Model for the Perception of Realism in Composite Images. Jun-Yan Zhu, Philipp Krahenbuhl, Eli Shechtman, Alexei A. Efros. ICCV 2015. project page ? ? Sketch-Based 3D Shape Retrieval Using Convolutional Neural Networks. Fang Wang, Le Kang, Yi Li. CVPR 2015. arXiv ? ? Multi-view Convolutional Neural Networksfor 3D Shape Recognition. Hang Su, Subhransu Maji, Evangelos Kalogerakis, Erik Learned-Miller. ICCV 2015. project page ? ? Sketch2Photo: Internet Image Montage. ACM SIGGRAPH ASIA 2009, ACM Transactions on Graphics. Tao Chen, Ming-Ming Cheng, Ping Tan, Ariel Shamir, Shi-Min Hu. project page ? ? Eulerian video magnification for revealing subtle changes in theworld. Wu, Hao-Yu, et al. ACM Trans. Graph. 31.4 (2012): 65. project page ? ? A High Performance CRF Model for Clothes Parsing. E Simo-Serra,S Fidler, F Moreno-Noguer, R Urtasun Computer Vision\u00d0ACCV 2014. pdf , code ? Previous topics (which you should know) Date Paper Paper, Project page Presenter Fundamental representations ? Object recognition from local scale-invariant features , David Lowe, ICCV 1999. pdf , project page ? ? Video Google: A Text Retrieval Approach to Object Matching in Videos. Sivic, J. and Zisserman, A. Proceedings of the International Conference on Computer Vision (2003) pdf , project page ? ? Histograms of Oriented Gradients for Human Detection. Navneet Dalal and Bill Triggs. In Proceedings of IEEE Conference Computer Vision and Pattern Recognition, 2005. .pdf ? ? Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories. S. Lazebnik, C. Schmid, and J. Ponce, CVPR 2006. pdf , slides ? Databases ? ImageNet: A Large-Scale Hierarchical Image Database. J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li and L. Fei-Fei. IEEE Computer Vision and Pattern Recognition (CVPR), 2009 pdf , project page ? ? LabelMe: a Database and Web-based Tool for Image Annotation. B. C. Russell, A. Torralba, K. P. Murphy, W. T. Freeman. International Journal of Computer Vision, 2008. pdf , project page ? ? 80 million tiny images: a large dataset for non-parametric object and scene recognition. A. Torralba, R. Fergus, W. T. Freeman. IEEE Transactions on Pattern Analysis and Machine Intelligence, vol.30(11), 2008. pdf , project page ? ? Describing Objects by Their Attributes. A. Farhadi, I. Endres, D. Hoiem, and D.A. Forsyth. CVPR 2009 project page ? ? SUN Database: Exploring a Large Collection of Scene Categories J. Xiao, K. Ehinger, J. Hays, A. Oliva, and A. Torralba. IJCV 2014. project page , pdf ? Other previous topics Date Paper Paper, Project page Presenter ? Painting-to-3D Model Alignment Via Discriminative Visual Elements. Mathieu Aubry, Bryan Russell Josef Sivic. ToG 2013. project page ? ? DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition. Jeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoffman, Ning Zhang, Eric Tzeng, Trevor Darrell. 2013. arXiv ? ? Image Melding: combining inconsistent images using patch-based synthesis. Soheil Darabi, Eli Shechtman, Connelly Barnes, Dan B Goldman, Pradeep Sen. Siggraph 2012. project page ? ? Ground-truth dataset and baseline evaluations for intrinsic image algorithms. R. Grosse, M.K. Johnson, E.H. Adelson and W.T. Freeman. ICCV 2009 project page ? ? Intrinsic Images in the Wild. Sean Bell, Kavita Bala, Noah Snavely. Siggraph 2014. project page ? ? First Person Hyperlapse Videos. Johannes Kopf, Michael Cohen, Richard Szeliski. Siggraph 2014. project page ? ? Depixelizing Pixel Art. Johannes Kopf and Dani Lischinski. Siggraph 2011. project page ? ? Photo tourism: Exploring photo collections in 3D. Noah Snavely, Steven M. Seitz, Richard Szeliski. Siggraph 2006. pdf , project page ? Acknowledgements This course was originally created by James Hays, and is also being taught this semester at Georgia Tech. Ideas for the organization and content of this course came from many other researchers such as Svetlana Lazebnik, Kristin Grauman, Antonio Torralba, Derek Hoeim, and Alexei Efros. Related Graduate Seminars at other Universities Learning-Based Methods in Vision (Alexei Efros, CMU and Leonid Sigal, Disney Research Pittsburgh) Object Recognition (Kristin Grauman, UT ) Object Recognition and Scene Understanding (Antonio Torralba, MIT) Machine Learning Techniques in Image Analysis (Svetlana Lazebnik, UNC) Internet Vision (Tamara Berg,Stony Brook) Visual Scene Understanding (Derek Hoiem, UIUC) Comments, questions to Genevieve Patterson .", "https://cs.brown.edu/courses/csci2951-t/finals/cwhalen/": "Motivation Who made this? Why did they make it? How old is it? Where did it come from? These are just a few questions the average visitor to any museum might have when viewing an artifact. Luckily for the visitor, objects in museums tend to be accompanied by helpful little tags, answering all of these questions and more. Though this is sufficient for the typical visitor viewing an artifact in a museum, what is a layman to do when faced with an unknown object he found in a field? How can that person answer the questions above without a helpful little tag? An expert might draw upon his knowledge of similar objects; to emulate this, and to answer \"who\" and \"when\", I have created a dataset which contains images of artifacts in the Metropolitan Museum of Art and all associated data. I used this dataset to train classifiers which predict Culture and Creation Date/Date Range for images of objects. Data Set Creation The Metropolitan Museum of Art has recently updated its online image collection, and released around 400,000 images as OASC (Open Access Scholarly Content). The Metropolitan Museum of Art appears to have around 571,722 artifacts total which have been assigned ID numbers. Not all of these artifacts have images associated with them, and some of them have more than one image associated with them. This implies that there will be fewer than 400,000 OASC artifacts with images. Downloading Image Data I have scraped the Met website using code from this github repository .For all image IDs in between 1 and 571,722, I access the content located at \"http://www.metmuseum.org/art/collection/search/ ID \".If the content on that page had the OASC tag and contained an image, then I write relevant fields to a JSON file. This process takes about 3 seconds per ID, which meansthat fully checking all IDs will take about 20 days to complete. At the time of performing analysis on the dataset, I had queried 300,000 IDs and collected approximately 80,000sets of object image/json data pairs. Culture Categories I processed the Culture field by keeping the first set of capitalized words and ignoring both parenthetical comments and words like North, East, etc. This resulted in the following list of cultures with more than 500 instances: Japanese (12802) French (9759) American(9029) Chinese(8197) Italian (6559) British(5419) German (3339) Greek (3192) Roman (2870) Cypriot (1305) Spanish (1052) Dutch (940) Indian (989) Flemish (805) Etruscan (795) Indonesian(768) Minoan (533) Date Categories There were two different types of date field contained in my data. The first was a categorical date field; date categories and their counts are displayed below: No date provided14,842 images 8000 B.C. - 2000 B.C.238 images 2000 B.C. - 1000 B.C.558 images 1000 B.C. - A.D. 15,345 images A.D. 1 - A.D. 5002,119 images A.D. 500 - A.D. 10001,219 images A.D. 1000 - A.D. 14001,076 images A.D. 1400 - A.D. 16004,970 images A.D. 1600 - A.D. 180026,813 images A.D. 1800 - A.D. 190023,112 images A.D. 1900 - present1,946 images (generally not yet released for OASC) The artifacts for which I collected information are not evenly distributed across categories. The majority (49,925 out of 82,028) of my artifacts date from between 1600 and 1900. Date Ranges The second type of date field is a description of the estimated creation date. This is entered in natural language, and usually implies either a single date or range of dates. In order to parse these dates, I used the yearrange parser from this repository . Example fields from my dataset and parsed values are shown below: ca. 1890 ->{\"start\":1890,\"end\":1890,\"circa\":true} early 19th century ->{\"start\":1800,\"end\":1824} 1800-1810 ->{\"start\":1800,\"end\":1810} 1804-14 ->{\"start\":1804,\"end\":1814} 1860s ->{\"start\":1860,\"end\":1869} June 12, 1871 ->{\"start\":1871,\"end\":1871} 1880 (?) ->{\"start\":1880,\"end\":1880,\"circa\":true} dated 1769 ->{\"start\":1769,\"end\":1769} first half of the 10th century ->{\"start\":900,\"end\":949} after 1875 ->{\"start\":1875,\"end\":1875} 4th century B.C. ->{} The yearrange parser failed on some of the values in my dataset. It was not intended to handle B.C. dates, or any dates that have fewer than 3 digits in the year, so I have only considered dates where the start year is 1000 or later. This results in a start date, and end date, and a possible circa field. The circa field will exist if there is any implied uncertainty in the provided date ranges (for example, \"ca.\", \"(?)\", \"probably\"). T-SNE I performed T-SNE on both culture and date range. I randomly selected 5000 images and 200 features from the 4096-dimensional output of the last convolutional layer of VGG-16. The results are shown below. As a future extension, I would like to make these results interactive, so that the space of images can be explored by viewing the image corresponding to any given point. The plots of the results of T-SNE on the inputs are shown below. Culture is on the left, and Date is on the right. Classification SVM on CNN Features I performed classification on culture and date category, for all images in my dataset. I used multiple 1-vs.-all SVM classifiers trained on the output of the final convolutional layer of VGG-16. (Note that the culture and date category values are all mutually exclusive.) My Culture SVMs achieve 0.533% accuracy on my test set, and the Date SVMs achieve 0.438% accuracy. The confusion matrices for the 17-class Culture categorization and the 9-class Date categorization are displayed below. Culture The values on the left are the true values for an image, and values on the top are the predicted values. If we look at the confusion matrix above, the results look promising.If we look at the \"Cypriot\" row, we see activation with other ancient Mediterranean cultures, like \"Etruscan\", \"Greek\", and \"Roman\". \"British\" often gets confused with other Europeancultures. Date Category Convolutional Neural Net I trained a CNN which took in a 128x128x3 image and output a value between 1 and 17, mapping to the culture. I trained with approximately 5000 images, with at least 600 images from each culture.I used a batch size of 100, and allowed training to run for 65 epochs. The accuracy was approximately 0.4, but it may have continued to improve if I had allowed it to run longer. Regression I also attempted regression using the start date and end date I found by parsing the date description. As in classification, I used features from the final convolutional layer of VGG-16,and performed multivariate linear regression to predict an estimated start and end date. I calculated the average interval overlap, which was the average of the percent of overlap between thetrue start and end dates and the estimated start and end dates. The average interval overlap was 15.07%. Future Extensions I would like to improve upon the date parser, to add handling for dates earlier than the year A.D. 1000. I would also like to do something with the \"circa\" field, like extending the interval by some amount based on the number of significant figures in the date. In other words, \"ca. 1000\" likely implies more uncertaintly than \"ca. 1955\", and I would like to account for this. I would like to finish downloading all items with images and the OASC tag. This will likely be updated on the github page below in the next few days. Currently, I am only using a single image per item,even though some items have many images. It may be helpful to include all images for a given item, rather than just the primary image. There is a lot more work which could be done on both classification and date regression. Finally, I would like to know how well humans perform on the same task. I would like to use this data set to run a task on Amazon Mechanical Turk, to determine human accuracy and typical human confusions. Conclusion I have created a novel dataset of ~80,000 images, which contains information on culture, date category, and date interval. I achieved 53% accuracy on classification with 17 cultures, and 43% accuracy with 9 date categories.I also was able to estimate the date interval given an image with 15% average interval overlap. Dataset Download and Details The full dataset of images and json files can be downloaded here . This currently has data for 82,238 items. \"images_full_set.zip\" is a folder which contains all images. The file name for each image is the item ID and \".jpg\". \"json-collections-data.zip\" is a folder containing all json files. The file name is the item ID which the data refers to and \".json\". \"full_art_cleaned_dated.xlsx\" is a csv file which has Image Id, Image URL, Date, Culture, and other fields. This is the cleaned data file I used for classification. References: Data Collection Metropolitan Museum of Art, www.metmuseum.org https://github.com/metmuseum-medialab/collections-api https://github.com/jeresig/node-yearrange Machine Learning CIFAR Network: http://www.vlfeat.org/matconvnet/training/ MatConvNet: http://www.vlfeat.org/matconvnet/ VGG-VeryDeep-16: `Very Deep Convolutional Networks for Large-Scale Image Recognition', Karen Simonyan and Andrew Zisserman, arXiv technical report, 2014 Visualizations T-SNE: https://lvdmaaten.github.io/drtoolbox/ , Matlab Toolbox for Dimensionality Reduction", "https://cs.brown.edu/courses/csci2951-t/finals/alesnikowski/": "A House Share Price Predictior using a Deep Neural Network Adam Lesnikowski Problem Motivations Approach Dataset Simplifying Assumptions Modifying a Classification Net for Regression deep features Support Vector Regressors Data Preparation Results Further Steps Figures Try It! http://pricepredictor.adamlesnikowski.com/ Contact http://www.adamlesnikowski.com //Update this google script for a new page! (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-75716345-1', 'auto'); ga('send', 'pageview');", "https://cs.brown.edu/courses/csci2951-t/finals/ghope/": "CSCI 2951-T Deep Learning for Natural Image Segmentation Priors Gabriel Hope May 10, 2016 Image segmentation is an important problem in computer vision. Distinguishing different objects and regions within an image is an extreamly useful preprocessing step in applications that require full scene understanding as well as many applications for image processing and editing. There are several different ways to frame the segmentation problem in computer vision. For example, semantic segmentation is a common segmentation task that can viewed as an extension of object detection. In the semantic segmentation task, rather than finding bounding box for objects of a specified class, the goal is to find the boundaries of a target object at the pixel level. In this project, I look at the more general segmentation task, where the goal is to partition an image into regions that correspond to different objects or materials in the image. Correctness in this setting is often difficult to define precisely, as objects boundaries are often ill-defined (should a t-shirt be considered the same object as the person who is wearing it?). In this case, a common proxy for \"truth\" data are human-generated segmentations of images. Above: An example of a \"good\" general segmentation for an image (from [1]). Many techniques have been proposed for the image segmentation task. Common examples include simple color-based K-means, graph-cutting approaches and Markov random fields [8]. The work in this project is based on the Spatially Dependent Pitman-Yor model from Sudderth and Jordan [1] (and extended by Ghosh and Sudderth [2]) that extends nonparametric mixture models to the segmentation problem. In this project I extend this segmentation model to make use of large amounts of labeled image data by incorporating the output of deep networks into the prior distribution on image segmentations. Nonparametric Segmentation I will first give a brief, high-level overview of the spatially dependent Pitman-Yor proecss model for segmentation. This model uses a layered approach to segmentation, where segments are intuitively considered as overlapping layers rather than strictly adjacent regions. An easy way to understand the Spatially dependent Pitman-Yor model is to first treat it as a foreground-background segmentation model. In this context, the model assumes that images are generated using the following process: First an assignment surface is randomly drawn for the image. This surface is drawn from a zero-mean Gaussian process and every point on the image has a corresponding point on the surface. In practice, this surface is represented by a \"height\" value for each pixel of the image. A draw of a Gaussian process over a finite number of points is equivalent to a draw from a multivariate Gaussian (normal) distribution, so in practice the heights for all the pixels are drawn jointly from a zero-mean multivariate Gaussian distribution. Determining what to use for the between-pixel covariances in this distribution is the fundamental problem explored in this project. Next a random threshold value is drawn from a standard normal distribution (Or this threshold is set to 0). Pixels whose height on the assignment surface are above the threshold are assigned to the forground segment, while all other pixels are assigned to the background. Each segment is given a different random distribution (such as a 3-d normal distribution) and the pixels in each segment are drawn from the corresponding distribution. Above: An illustration of assignment surfaces for different layers and the resulting segmentations (from [1]). The process above defines a distribution over possible segmentations and possible images. With a given image, the actual pixels are observed and it is possible to use variational inference to find an approximate posterior distribution for segmentation conditioned on the observed pixels. This is the technique that I used to generate the segmentations in this project. Above: The graphical model for a simplified version of the foreground-background model where the threshold is fixed at 0. Extending this model to nonparametric segmentation (segmentation with an abitrary number of segments) is straightforward. The generative process is simply repeated so that pixels assigned the forground are further segmented using the same process. This process can be repeated until there are no more pixels left in the foreground to further segment. In this case the threshold distribution is modified so that the number of segments roughly follows a power-law distribution. It's important to note that this model does not acutally work on the pixels of the image directly. Instead, as a preprocessing step, the image is dived into 1000 superpixels using the SLIC algorithm [5]. Each superpixel is represented by a 125-bin histogram of the colors in the superpixel as well as an 128-bin histogram of texton assignments. A texton is a cluster of responses from a set of texture filters. Each pixel in a given image is assigned a texton by first applying the set of filters centered at its location, then assigning the vector of responses to the nearest texton cluster. Because the superpixels are represented as histograms, the segment-specific distributions that generate them are assumed to be multinomial distributions, which in turn are drawn from a shared Dirichlet distribution. Above: An image and the corresponding SLIC superpixel segmentation. Data For this project, I used the Berkeley Image Segmentation dataset [7] (BSDS300) for evaluating segmentations and in some cases for training. This dataset consists of 300 natural photographs of a diverse set of scenes. The advantage of using this dataset is that it provides multiple human segmentations of each of the images that can be used as a proxy for ground truth segmentaions. Some examples from this dataset are shown below. Because computing each segmentation with the spatially dependent Pitman-Yor model is currently very slow, I only actually evaluted using a subset of 10 of the BSDS images. Above: An example image from the BSDS dataset along with the corresponding human segmentation(s). Learning Segmentation Priors One can modify the segmentation prior for a given image by modifying the assignment surface covariances between pixels in the image. Intuitively, the covariance between two pixels should be high if the pixels are likely to be part of the same segment and low if they are likely to be part of different segments. The simplest approach to generating pixelwise covariances is to base the covariances on the distance between pixels so that pixels that are closer in the image have a higher covariance. In order to generate distance-based covariance between two superpixels, I took the mean of the coordiates of each superpixel and applied a Gaussian kernel to the difference as a distance measure. This approach creates covariances between 0 and 1, where pixels that are very close will have a covariance close to 1 and pixels that are very apart far will have covariance close to zero. The kernel width (gamma) was chosen by eye and is set to 0.005. The core of this project is to use a data-driven approach to generating appropriate pixelwise covariances for the segmentation model. My general approach to this problem was to use existing CNNs trained on large, labeled datasets to generate some kind of prediction for each pixel in an image. These predictions are then incorporated into the pixelwise covariances to improve them over the baseline distance-based covariances. The first network that I used in the project was a fully convolutional network for semantic segmentation from Long et. al [6]. This network was trained for the semantic segmentation task on the Pascal VOC 2012 dataset. For a given image, this network outputs a 60-class (including background) probability vector at each pixel. Above: An example image from BSDS. Above: CNN predicted class probabilities for three different classes on the example image. The second network that I applied to this task was the depth map prediction network from Eigen et. al [4]. This network was trained on the NYU Depth dataset and it outputs a predicted depth at each pixel in the image. Its output is designed to approximate the output of a standard depth sensor like a Microsoft Kinect. Above: CNN predicted depth map for the example image. I considered two different approaches to incorporate the outputs of these networks into the superpixel covarianaces for each image. The first approach that I used was to simply take the mean network output for each superpixel and concatenate this output with the mean pixel location for each superpixel to create a feature vector for each superpixel (rescaling the nework output to match the scale of the pixel locations). To compute the covariance between two pixels, I then simply used the same Gaussian kernel distance as before. Above: An example segmentation using the depth-inclusive prior. For the second approach, I wanted to learn a relative weighting for each type of feature (pixel locations, semantic segmentation outputs and depth). In this case I created a feature for each pair of superpixels by concatenating the euclidean distance between the locations, the euclidean distance between the semantic segmentation output vectors and the absolute difference between the depth predictions. I then took a subsample of 500 pairs of superpixels from each of 30 random images from the BSDS dataset and trained a logistic regression classifier to predict the probability that two superpixel are part of the same segement given a vector of feature distances. The truth labels for training were taken from the human segmentations of the BSDS dataset. This approach was inspired by the Ghosh and Sudderth paper [2], which also describes a technique for translating the probability that two pixels are part of the same segment into an appropriate covariance. Evaluation The results of segmentations can be subjective, so evalutaing by generated segmentations by eye is still one of the best ways to understand the performance of a segmentation algorithm. In addition to evaluating by eye, I also used the Probibalistic Rand Index [3] measure to evaluate segmentation using the BSDS human segmentations as ground truth. This is an extension to the Rand index measure for comparing clusterings that is better suited to evaluating image segmentations. The basic Rand index is defined as the number of element pairs that are correctly identified as being part of the same group or not divided by the total number of possible element pairs in the data. A Rand index will be between 0 and 1 and a higher index is better. Results The table below summarizes the probibalistic rand index evaluation of the segmentation model under different priors, averaged over all human segmentations for the images in my test set. Prior Average PRI Pixel Distances 0.672 Pixel Distances + Semantic Output 0.695 Pixel Distances + Depth 0.683 Pixel Distances + Semantic Output (Learned Weighting) 0.526 Pixel Distances + Depth (Learned Weighting) 0.691 Pixel Distances + Semantic + Depth (Learned Weighting) 0.5912 According to this measure the best segmentation prior is the one that incorporates the output of the semantic segmentation network naively (instead of learning the relative weighting between features). Below are the segmentations from all 6 versions of the model on 2 sample images, one of the better examples and one of the worse ones. Future Work The most straighforward line of future work would be to replace the semantic segmentation or depth network that I used here with a network fine-tuned to the task of predicting pairwise pixel covariances. This is likely a difficult task that would require a vast number of general human segmentations. It could conceivably be accomplished by designing a network that maps an image into an alternate colorspace such that color distances can be mapped to covariances. Another important point of weakness in the spatially dependent Pitman-Yor process model is the representation of superpixels. As I described above, superpixels are represented as histograms of colors and texture responses across the contained pixels. This is a fairly naive representation for superpixels which may not be all that good for distinguishing object boundaries. By the nature of these features, two quite different looking superpixels could have similar representations. The representation also doesn't account for context around a superpixel and similarly doesn't account well for cases when different looking superpixels are still commonly part of the same object. A better approach to representation could be to learn representations for superpixels, possibly using convolutional neural networks. An approach in this vein would require a significant amount of additional research. As a first step, I explored replacing the texture filters used in the standard model with filters from a trained classification CNN to see if they might create features that better discriminate between different object types. The images below show the texture feature assignments of normal texture features across a sample image compared to the assignments using filters learned as the first layer output of the AlexNet CNN. While the CNN-filter responses appear to be more diverse, which could allow them to be more discriminative, the resulting segmentations are indistinguishable for this example. Discussion Ultimately, the results of this project are somewhat underwhelming. While the results show that incorporating the network ouputs can improve segmentations somewhat, the difference is very small and the small number of images that the final models were tested on means that the difference may not actually be significant. Still, it is possible that with more fine-tuning of both the pipline and the model settings, that my approach could make a more significant differnce. I intend to trying the ideas explored here in my future work on segmentation. I am particularly interested in the results of the model that incorporates estimated depth, as this model does not rely on specfic object types and could theoretically be applied to any scene regardless of content. The quality of the results was largely hampered by a number of issues the I encountered during the course of this project. Mainly these issues stemmed from the segmentation model itself. Inference for the spatially dependent Pitman-Yor process model is complex and the results can be dependent on how the algorithm is intialized, which can make comparing various tweaks to the model quite difficult. Furthermore, the code for inference is still unstable, under development (by me) and extremely slow. This made debugging difficult and made trying to fine-tune the segmentation pipeline an arduous process. Beacause iterating on changes the the priors and the model was so slow, many of the settings I used to generate the final results relied on guesswork rather than a pricipled comparison. References [1] Sudderth, Erik B., and Michael I. Jordan. \"Shared segmentation of natural scenes using dependent Pitman-Yor processes.\" Advances in Neural Information Processing Systems. 2009. [2] Ghosh, Soumya, and Erik B. Sudderth. \"Nonparametric learning for layered segmentation of natural images.\" Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on. IEEE, 2012. [3] Unnikrishnan, Ranjith, and Martial Hebert. \"Measures of similarity.\" Application of Computer Vision, 2005. WACV/MOTIONS'05 Volume 1. Seventh IEEE Workshops on. Vol. 1. IEEE, 2005. [4] Eigen, David, Christian Puhrsch, and Rob Fergus. \"Depth map prediction from a single image using a multi-scale deep network.\" Advances in neural information processing systems. 2014. [5] Achanta, Radhakrishna, et al. \"SLIC superpixels compared to state-of-the-art superpixel methods.\" Pattern Analysis and Machine Intelligence, IEEE Transactions on 34.11 (2012): 2274-2282. [6] Long, Jonathan, Evan Shelhamer, and Trevor Darrell. \"Fully convolutional networks for semantic segmentation.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. [7] Martin, David, et al. \"A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics.\" Computer Vision, 2001. ICCV 2001. Proceedings. Eighth IEEE International Conference on. Vol. 2. IEEE, 2001. [8] Szeliski, Richard. Computer vision: algorithms and applications. Springer Science & Business Media, 2010. Copyright \u00a9 Gabriel Hope 2016", "https://cs.brown.edu/courses/csci2952c/all.html": "2022 2020 2018", "https://cs.brown.edu/courses/csci2952-a/starting.html": "Some Starting Points for Presentations J. Bonneau et al. SoK: Research Perspectives and Challenges for Bitcoin and Cryptocurrencies M Herlihy. Blockchains from a Distributed Computing Perspective Bitcoin S. Nakamoto. Bitcoin: A Peer-to-Peer Electronic Cash System I Eyal and E G Sirer. Majority is not Enough:Bitcoin Mining is Vulnerable I Eyal et al. Bitcoin-NG: A Scalable Blockchain Protocol K Croman et al. On Scaling Decentralized Blockchains(A Position Paper) Y Sompolinsky and A Zohar. Accelerating Bitcoin's Transaction Processing: Fast Money Grows on Trees, Not Chains Mike Hearn. The resolution of the Bitcoin experiment Vivek Wadhwa R.I.P., Bitcoin. It\u2019s time to move on. Other Blockchains J. Chen and S. Micali. Algorand Hyperledger White Paper C Copeland and H Zhong. Tangaroa: a Byzantine Fault Tolerant Raft Tendermint E Kokoris-Kogias et al. OmniLedger: A Secure, Scale-Out, Decentralized Ledger S Popov. The Tangle L Baird. Hashgraph Smart Contracts I Sergey and A Hobor. A Concurrent Perspective on Smart Contracts L Luu et al. Making Smart Contracts Smarter N Atzei et al. A Survey of Attacks on Ethereum Smart Contracts SoK . T Dickerson et al. Adding Concurrency to Smart Contracts X Boyen et al. Blockchain-Free Cryptocurrencies Atomic Swaps M Herlihy. Atomic cross-chain Swaps . Decred cross-chain atomic swapping S Bowe and D Hopwood. Hashed Time-Locked Contract transactions Atomic cross-chain trading Offchain transactions M Green and I Miers. Bolt: Anonymous Payment Channels for Decentralized Currencies J. Poon and T Dryja. The Bitcoin Lightning Network Proof of Stake V Buterin and V Griffith. Casper the Friendly Finality Gadget Kiayias et al. Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol Consensus and Theory J.A. Garay et al. The Bitcoin Backbone Protocol: Analysis and Applications Y. Sompolinsky et al. SPECTRE: Serialization of Proof-of-work Events: Confirming Transactions via Recursive Elections A Kiayias and G Panagiotakos. On Trees, Chains and Fast Transactions in the Blockchain A Kiayias and G Panagiotakos. Speed-Security Tradeoffs in Blockchain Protocols R Pass and E Shi. The Sleepy Model of Consensus Accountability M Herlihy and M Moir. Enhancing Accountability and Trust in Distributed Ledgers", "https://cs.brown.edu/courses/csci2951-t/finals/gmarques/": "gmarques - CSCI 2951t Final Project Four top images retrieved using the leftmost image as the query Introduction Content based image retrieval tries to obtain similar images to the one used as query according to a feature. The objective is define a metric to compare this features and then obtain the k nearest neighbors for an image. For example, a basic approach would use the Euclidean distance from every pixel to the pixels in the original one. Clearly, this approach becomes extremely expensive as the set of images and the dimensions of each increase. To decrease the dimensionality of the feature different approaches are used (GIST, LSH and PCA). In addition, binary function tends to make the process even faster since the similarity function becomes the Manhattan distance. [Lin, 2015] defined a framework to use a neural network as an autoencoder. It was proved that the AlexNet fine tuned for image classification produced the state of art results in binary hash codes for image. In this work, I aim to expand the concept for object detection. Therefore, using one of the main approaches for object detection, Faster-RCNN , I trained an auto-encoder with objective to define features for object based image retrieval. Method The proposed framework is an application for the technique proposed by [Lin, 2015] in content-based image retrieval. In this work, this term refers to, given an image; images that have similar region proposals will be retrieved. Region proposals are defined as bounding boxes for an object of a specific class. In this case, Faster-RCNN is used as the object detector. This detector proves to be suitable for the task because it is a single neural network with no need for extra input or output information. Therefore, the latent layer in this network will be directly compressing the data used for object detector. It is also the state of art for object detection and it is reaching real time detection in some cases. By looking into the network structure and comparing to the original approach for ImageNet, the presence of the twin output layer (for class probability and bounding box location) does not allow a direct mapping of the framework into the network. However, in the last layers, Faster R-CNN presents a clear distinction between region localization and object classification. Following the framework, I decided to isolate the latent layer just for the classification output, as the feature will tend to ignore localization. The objective is to compress just information about the object classes. After including the new layer, the new network is fine-tuned for the desired data set. The objective it to reach a similar performance to the original detector. This indirectly proves that the information is being compressed; otherwise, the output would not perform closely to the original structure. The output of the latent layer defines the binary code according to a threshold. Implementation Details The image retrieval algorithm first defines a set of features (containing all the images that can be retrieved). These features are associated with the image. However, Faster R-CNN with the latent layer produces a feature for every proposal given the input image. In the configuration for the detector, the maximum number was 300 proposals. I did not increase this number because of processing limitations and it is out of the scope. However, most of the proposed object does not strongly define a class in the output, or if it does, many proposals will be referring the same object. As a result, these features are filtered using the object detector output as the factor to be considered. First, to address multiple proposal to the same object we apply non-max suppression. This algorithm is already implemented in Faster-RCNN. For a given set of bounding box and scores, it suppresses those with areas overlapping above a threshold; the boxes with higher scores are given priority in the suppression. The remained features are then limited by another threshold, that defines the minimum confidence in a class for a proposal. For the network a GeForce Titan was used. In terms of the neural network, there are three different configuration for Faster-RCNN. Due to the difference in terms of processing between the original (eights GPUs) and this work, the smallest network was adopted. In this case, it was Zeiler & Fergus Net , but problems to reach similar results to the original approach direct the approach towards VGG16 Net . A point that deserves mention is that even if it is deeper and more computationally expensive to train, VGG proved to be almost eight times faster. The reasons are still a topic of research. The nms rate was chosen originally from the default values. The same was done was done with the confidence threshold. For the auto encoder features the confidence was lowered to 0.6 to create more images in the set. The objective was to restrict to 1 to 2 regions per image, to keep it computational feasible and to avoid false positives. According to observations, the threshold can be selected to control the region proposals set size. In the experiments 0.3 and 0.8 for nms and confidence threshold returned 8521 features for 5000 images. Coincidentally, for the network with the autoencoder the number of features was the same. In terms of the learning rate, initially it was lowered because the network was not converging. However, by the time, the VGG16 Net proved to be reliable in terms of mAP, as the learning rate was increased the accuracy improved too. The learning rate was set in 0.01 the same used to train the original detector from ImageNet. Experiments For the experiments, first Faster-RCNN was trained in the configuration end to end that generates a single neural network responsible for the task. I followed the pre-set values in this case, 70000 interactions. The resulting network yielded 70.8% in mAP, a result close to 69.9% described in the paper. The next step was to include the latent layer and fine tune for the chosen data set. As the source code used was an implementation over Caffe, the original source code presented challenges to be extended. Consequently, I kept the same dataset to fine tune the autoencoder. It is clear that it can lead to an over fitted network. Mean accuracy for K images with images from Pascal VOC 2007 In this experiment, image proposals from 4 thousand images from PASCAL VOC 2007 were used to constitute the image set. To restrict the number of features the level of confidence and nms were used, as explained before. The testing set is composed by all the features of one thousand images from the testing dataset. The mean accuracy is calculated doing the average of the accuracy in each class. The accuracy in each class is calculated as following. Given a image proposal the k nearest neighbors are retrieved. A set of the classes present in these images are built. If the class that is in the queried proposal is in this set a hit is counted, otherwise it is a miss. Finally, these numbers are divided by the total number of classes of proposals, normalizing it. The auto encoder corresponds to 256 bits from the latent layer(whose activation function is sigmoid), the output was converted to binary with a 0.5 threshold. The fc7 is the 4096 feature from the network and pca is a 48 feature extracted from the fc7 feature through Principal Component Analysis. The last two features were not discretized. Mean accuracy for K images with images from Pascal VOC 2012 This chart presents a test with the same autoencoder but the images were taken from PASCAL VOC 2012, that includes images from the previous years. To create the pool of features, region proposals from 5000 images of the training set. To test, 2000 images from the validation set. The performance is similar to the 2007 analysis and the better performance of the auto encoder indicates that it is not as over fitted as expected. It is clear that as k increases fc7 will surpass the autoencoder performance. The worse performance of the pca in this experiment is surprising because the number of dimension was increased from 48 to 128. Accuracy per class Pascal VOC 2012 Analysing the accuracy in a finer grain, it is clear that the three approaches have the same problem. This can indicate that the problem is not related to the features, but maybe to limitations from the network. In other words, using a neural network and knn would not give a better result. However, the autoencoder outperforms other methods in with a small k. In terms of application this is important because as k increases the algorithm become less responsible for the retrieved proposals. Average time to retrieve k nearest neighbors PCA, k =1 PCA, k =5 PCA, k =10 PCA, k =20 FC7, k =1 FC7, k =5 FC7, k =10 FC7, k =20 AUTO, k =1 AUTO, k =5 AUTO, k =10 AUTO, k =20 AT 0.115 0.132 0.133 0.133 2.492 2.528 2.527 2.546 0.942 0.954 0.948 0.962 For the experiments the brute force was used as technique to get the k nearest neighbors. Comparing the average time to retrieve k images from a 5000 images set, the experiment shows that this set of different values of k practically does not affect the time. Comparing the time, the number of features affected considerably more the final time than data type. However, it is important to consider that PCA achieved the worst results and it also demands an extra step to define the model. Four top images retrieved using the leftmost image as the query Discussion and Possible next steps This approach is clearly not the most suitable for object based image retrieval as it completly ignores the location of the feature. It also demands that every proposal of the query image is considered valid. So, when the accuracy is evaluated, all three hundred proposals were used. The same strategy applied to build the set of images could be used(applying non maximum suppression and a threshold in the score). This could be done as a next experiment. Faster R-CNN also imposed some problem, specially when training the autoencoder. Changing the data set is also another. I could not use a non PASCAL VOC because of time constraints to implement the code for a new dataset. On the other hand, there are tutorial with ImageNet. For the next steps, I would highlight a technique to select the proposals to be considered in the query image. Additionally, a more complete set of experiments with different data sets. Overall, however the autoencoder outperformed fc7 and pca in the tests. It shows that, in fact, the approach improves object retrieval for object detectors. In terms of over fitting, the tests with a different data set PASCAL VOC 2012 attest that it did not damage the accuracy. References Slides presentation with more experiments Project repository Faster RCNN repository Deep Learning Binary Hash Codes repository", "https://cs.brown.edu/courses/csci2952-a/": "CS2952 A \u2013 Blockchains and Cryptocurrencies 10:30 to 11:50 Tuesdays and Thursdays CIT 368 Official Song of CS2952 A Course Information Blockchain technology promises to revolutionize how modern society deals with trust. Although cryptocurrencies such as Bitcoin are in the news, the impact of this technology is likely to extend far beyond such speculative bubbles, encompassing topics ranging from identity management, to market making, to IOT security, and also CryptoKitties The goal of this course is to take a snapshot of current research topics in blockchains and related areas. We will start with a few tutorials by the instructor, but most of the course will consist of presentations by students. Progress at the forefront of research is often incremental: one researcher publishes a paper posing a question or claiming a result, and a sequence of follow-on papers improve the result or alter the question. For this reason, we will organize our approach around the idea of clusters of papers. A cluster consists of one primary paper, the one to read if you can read only one, together with two or three secondary papers. The primary paper may have been the first to formulate the problem or technique, or it may have provided the best solution to the problem, or perhaps it is simply the most readable. Grades and Assignments Schedule & Sign-up Texts and Other Resources (under construction) Starting Points for Presentations (under construction) Instructor Maurice Herlihy , CIT 341", "https://cs.brown.edu/courses/csci2952c/": "Learning with Limited Labeled Data (Fall 2022) Course Description As machine learning is deployed more widely, researchers and practitionerskeep running into a fundamental problem: how do we get enough labeled data?This seminar course will survey research on learning when only limitedlabeled data is available. Topics covered include semi-supervised learning,transfer learning, weak supervision, few-shot learning, and zero-shot learning.Students will lead discussions on recent researchpapers and develop final research projects. Essential Info Instructor: Stephen Bach a.k.a. Steve Class Meetings: Tuesdays and Thursdays, 1-2:20 pm, CIT 316 Office Hours: See the Canvas homepage for information. Textbook: None Prerequisites: Previous experience in machine learning is required through CSCI 1420 or equivalent research experience. Important Links Canvas for discussions, assignment guidelines, and additional class resources Past years for previous reading lists (project ideas, etc.) Contact For questions, discussion, and other course-related posts, use Canvas . If you have an atypical question that you are certain does not belong onCanvas, email the instructor. Course Schedule Introduction Sep 8 Introductions, an overview of the researchtopics we will cover during the semester, how to read a research paper. Suplemental reading: Introduction to Semi-Supervised Learning. Olivier Chapelle, BernhardSch\u00f6lkopf, and Alexander Zien. In Semi-Supervised Learning, MIT Press, 2006. [PDF] [Online, requires Brown login] Incidental Supervision: Moving beyond Supervised Learning. Dan Roth.AAAI 2017. [PDF] How to Read a CS Research Paper? Philip W. L. Wong. [PDF] How to Read a Technical Paper. Jason Eisner. [Online] How to Read a Paper. S. Keshav. [PDF] Semi-Supervised Learning Sep 13 MixMatch: A Holistic Approach to Semi-Supervised Learning.David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin Raffel.Neural Information Processing Systems (NeurIPS) 2019. [PDF] [Supplemental (Zip)] [Reviews] [Code] Suplemental reading: FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence.Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang, Colin A. Raffel, Ekin Dogus Cubuk, Alexey Kurakin, and Chun-Liang Li.Neural Information Processing Systems (NeurIPS) 2020. [PDF] [Supplemental] [Reviews] [Code] Sep 15 Semi-supervised Sequence Learning.Andrew M. Dai and Quoc V. Le.Neural Information Processing Systems (NeurIPS) 2015. [PDF] [Reviews] Suplemental reading: Unsupervised Data Augmentation for Consistency Training.Qizhe Xie, Zihang Dai, Eduard Hovy, Thang Luong, and Quoc Le.Neural Information Processing Systems (NeurIPS) 2020. [PDF] [Supplemental] [Reviews] [Code] Transfer Learning Sep 20 Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu.Journal of Machine Learning Research (JMLR) 21(140):1-67, 2020. [PDF] [Blog] [Code] Suplemental reading: XLNet: Generalized Autoregressive Pretraining for Language Understanding.Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R. Salakhutdinov, and Quoc V. Le.Neural Information Processing Systems (NeurIPS) 2019. [PDF] [Supplemental (Zip)] [Reviews] Sep 22 Start of course survey due ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators.Kevin Clark, Minh-Thang Luong, Quoc V. Le, and Christopher D. Manning.International Conference on Learning Representations (ICLR) 2020. [PDF] [Reviews] [Code] Suplemental reading: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.Meeting of the North American Association for Computational Linguistics (NAACL) 2019. [PDF] Sep 27 Big Transfer (BiT): General Visual Representation Learning.Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung, Sylvain Gelly, and Neil Houlsby.European Conference on Computer Vision (ECCV) 2020. [PDF] [Code] Supplemental reading: TAGLETS: A System for Automatic Semi-Supervised Learning with Auxiliary Data.Wasu Piriyakulkij, Cristina Menghini, Ross Briden, Nihal V. Nayak, Jeffrey Zhu, Elaheh Raisi, and Stephen H. Bach.Conference on Machine Learning and Systems (MLSys) 2022. [PDF] [Code] Sep 29 Learning Transferable Visual Models From Natural Language Supervision.Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever.International Conference on Machine Learning (ICML) 2021. [PDF] [Blog] Supplemental reading: SLIP: Self-supervision meets Language-Image Pre-training.Norman Mu, Alexander Kirillov, David Wagner, and Saining Xie.ArXiv 2112.12750 2021. [PDF] Weakly Supervised Learning Oct 4 Snorkel: Rapid Training Data Creation with Weak Supervision. Alexander Ratner,Stephen H. Bach, Henry Ehrenberg, Jason Fries, Sen Wu, and Christopher R\u00e9.Proceedings of the VLDB Endowment, 11(3):269-282, 2017. [PDF] [Code] Supplemental reading: Maximum Likelihood Estimation of Observer Error-Rates Using the EM Algorithm.A. P. Dawid and A. M. Skene.Journal of the Royal Statistical Society. SeriesC (Applied Statistics), 28(1):20-28, 1979. [Online, requires Brown login] Oct 6 Weakly Supervised Sequence Tagging from Noisy Rules.Esteban Safranchik, Shiying Luo, and Stephen H. Bach.AAAI Conference on Artificial Intelligence (AAAI) 2020. [PDF] [Code] Supplemental reading: BERTifying the Hidden Markov Model for Multi-Source Weakly Supervised Named Entity Recognition.Yinghao Li, Pranav Shetty, Lucas Liu, Chao Zhang, and Le SongMeeting of the Association for Computational Linguistics (ACL) 2021. [PDF] [Code] [Video] Oct 11 Self-Training with Weak Supervision.Giannis Karamanolakis, Subhabrata Mukherjee, Guoqing Zheng, and Ahmed Hassan Awadallah.Conference of the North American Chapter of the Association for Computational Linguistics (NAACL) 2021. [PDF] [Code] [Video] Supplemental reading: WRENCH: A Comprehensive Benchmark for Weak Supervision.Jieyu Zhang, Yue Yu, Yinghao Li, Yujing Wang, Yaming Yang, Mao Yang, and Alexander Ratner.NeurIPS Datasets and Benchmarks Track 2022. [PDF] [Supplemental] [Code] [Reviews] Oct 13 Shoring Up the Foundations: Fusing Model Embeddings and Weak Supervision.Mayee F Chen, Daniel Yang Fu, Dyah Adila, Michael Zhang, Frederic Sala, Kayvon Fatahalian, and Christopher R\u00e9.Uncertainty in Artificial Intelligence (UAI) 2022. [PDF] [Supplemental (Zip)] [Reviews] Supplemental reading: Language Models in the Loop: Incorporating Prompting into Weak Supervision.Ryan Smith, Jason A. Fries, Braden Hancock, and Stephen H. Bach.ArXiv 2205.02318 2022. [PDF] Few-Shot Learning Oct 18 Prototypical Networks for Few-shot Learning.Jake Snell, Kevin Swersky, and Richard Zemel.Neural Information Processing Systems (NeurIPS) 2017. [PDF] [Supplemental (Zip)] [Reviews] Supplemental reading: Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.Chelsea Finn, Pieter Abbeel, and Sergey Levine.International Conference on Machine Learning (ICML) 2017. [PDF] Oct 20 Project proposal due Language Models are Few-Shot Learners.Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.Neural Information Processing Systems (NeurIPS) 2020. [PDF] Supplemental reading: On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? \ud83e\udd9c.Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell.ACM Conference on Fairness, Accountability, and Transparency (FAccT) 2021. [PDF] Oct 25 Learning How to Ask: Querying LMs with Mixtures of Soft Prompts.Guanghui Qin and Jason Eisner.Conference of the North American Chapter of the Association for Computational Linguistics (NAACL) 2021. [PDF] [Supplemental] [Video] Supplemental reading: The Power of Scale for Parameter-Efficient Prompt Tuning.Brian Lester, Rami Al-Rfou, and Noah Constant.Conference on Empirical Methods in Natural Language Processing (EMNLP) 2021. [PDF] [Code] [Video] Oct 27 How many data points is a prompt worth?Teven Le Scao and Alexander Rush.Conference of the North American Chapter of the Association for Computational Linguistics (NAACL) 2021. [PDF] [Supplemental] [Code] [Video] Supplemental reading: Cutting Down on Prompts and Parameters: Simple Few-Shot Learning with Language Models.Robert Logan IV, Ivana Balazevic, Eric Wallace, Fabio Petroni, Sameer Singh, and Sebastian Riedel.Findings of the Association for Computational Linguistics 2022. [PDF] [Code] Nov 1 Conditional Prompt Learning for Vision-Language Models.Kaiyang Zhou, Jingkang Yang, Chen Change Loy, and Ziwei Liu.IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2022. [PDF] [Code] Supplemental reading: DualCoOp: Fast Adaptation to Multi-Label Recognition with Limited Annotations.Ximeng Sun, Ping Hu, and Kate Saenko.ArXiv 2206.09541 2022. [PDF] Nov 3 Training language models to follow instructions with human feedback.Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe.ArXiv 2203.02155 2022. [PDF] Supplemental reading: None Nov 8 Election Day (No class) Zero-Shot Learning Nov 10 DeViSE: A Deep Visual-Semantic Embedding Model.Andrea Frome, Greg S. Corrado, Jon Shlens, Samy Bengio, Jeff Dean, Marc'Aurelio Ranzato, and Tomas Mikolov.In Neural Information Processing Systems (NeurIPS) 2015. [PDF] [Supplemental (Zip)] [Reviews] Supplemental reading: Zero-Shot Learning through Cross-Modal Transfer.Richard Socher, Milind Ganjoo, Christopher D. Manning, and Andrew Y. Ng.In Neural Information Processing Systems (NeurIPS) 2013. [PDF] [Reviews] Nov 15 Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs.Xiaolong Wang, Yufei Ye, and Abhinav Gupta.In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2018. [PDF] Supplemental reading: Rethinking Knowledge Graph Propagation for Zero-Shot Learning.Michael Kampffmeyer, Yinbo Chen, Xiaodan Liang, Hao Wang, Yujia Zhang, and Eric P. Xing.In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2019. [PDF] Nov 17 Project status report due Multitask Prompted Training Enables Zero-Shot Task Generalization.Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Stella Biderman, Leo Gao, Tali Bers, Thomas Wolf, and Alexander M. Rush.International Conference on Learning Representations (ICLR) 2022. [PDF] [Code] [Data] [Reviews] Supplemental reading: Benchmarking Generalization via In-Context Instructions on 1,600+ Language Tasks.Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi Gary Lai, Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi, Maitreya Patel, Kuntal Kumar Pal, Mehrad Moradshahi, Mihir Parmar, Mirali Purohit, Neeraj Varshney, Phani Rohitha Kaza, Pulkit Verma, Ravsehaj Singh Puri, Rushang Karia, Shailaja Keyur Sampat, Savan Doshi, Siddhartha Mishra, Sujan Reddy, Sumanta Patro, Tanay Dixit, Xudong Shen, Chitta Baral, Yejin Choi, Noah A. Smith, Hannaneh Hajishirzi, and Daniel Khashabi.ArXiv 2204.07705 2022. [PDF] [Data] Nov 22 Do Prompt-Based Models Really Understand the Meaning of Their Prompts?Albert Webson and Ellie Pavlick.Meeting of the North American Association for Computational Linguistics (NAACL) 2022. [PDF] [Code] Supplemental reading: Can language models learn from explanations in context?Andrew K. Lampinen, Ishita Dasgupta, Stephanie C. Y. Chan, Kory Matthewson, Michael Henry Tessler, Antonia Creswell, James L. McClelland, Jane X. Wang, and Felix Hill.ArXiv 2204.02329 2022 [PDF] Nov 24 Thanksgiving (No class) Nov 29 Image Segmentation Using Text and Image Prompts.Timo L\u00fcddecke and Alexander Ecker.IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2022. [PDF] [Supplemental] [Code] Supplemental reading: GLIPv2: Unifying Localization and Vision-Language Understanding.Haotian Zhang, Pengchuan Zhang, Xiaowei Hu, Yen-Chun Chen, Liunian Harold Li, Xiyang Dai, Lijuan Wang, Lu Yuan, Jenq-Neng Hwang, and Jianfeng Gao.ArXiv 2206.05836 2022. [PDF] [Code] Data Generation Dec 1 MixNMatch: Multifactor Disentanglement and Encoding for Conditional Image Generation.Yuheng Li, Krishna Kumar Singh, Utkarsh Ojha, and Yong Jae Lee.IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2020. [PDF] [Talk] [Code] [Video] Supplemental reading: Generating Object Stamps.Youssef Alami Mejjati, Zejiang Shen, Michael Snower, Aaron Gokaslan, Oliver Wang, James Tompkin, and Kwang In Kim.ArXiv 2001.02595 2020. [PDF] Dec 6 Zero-Shot Text-to-Image Generation.Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever.ArXiv 2102.12092 2021. [PDF] [Blog] Supplemental reading: Diffusion Models Beat GANs on Image Synthesis.Prafulla Dhariwal and Alexander Nichol.Neural Information Processing Systems (NeurIPS) 2021. [PDF] [Supplemental] [Reviews] Dec 20 Final project report due (No class) Learning Goals Students who complete this course will: Acquire a working knowledge of the landscape of research on machinelearning with limited labeled data. Practice identifying and critically assessing the claims,contributions, and supporting evidence in machine learning research papers. Develop their ability to share scientific ideas via writing and discussion. Gain practical experience with the course's subject matter by applying andextending it to their own research interests though an open-ended project. Grading The following standards will be used to assign grades.Anyone who doesn't complete the standards to earn a B will receive NC. To Earn an A Participate actively in class discussions by asking questions, sharingopinions, and listening carefully to others. Meet all deadlines in the course schedule related to the research project. Submit two discussion questions to Canvas by 6 PM the evening before classfor assigned readings, missing no more than 3 readings. Attend class meetings, missing no more than 3 meetings. Fulfill the requirements below to earn a B. To Earn a B Conduct an original research project related to course materials and submita written report meeting the assignment guidelines. Lead the assigned class discussion demonstrating preparation and inclusion. Submit two discussion questions to Canvas by 6 PM the evening before classfor assigned readings, missing no more than 6 readings. Attend class meetings, missing no more than 6 meetings. Estimated Time Commitment Activity Hours Class Meetings 28 Readings 65 Submitting Discussion Questions 10 Preparing to Lead Discussion 2 Project Research 60+ Project Proposal / Status 10 Project Final Report 5 Total 180+ General Course Policies Masking, COVID-19, and Other Health Issues Everyone attending class is required to wear a high-quality mask (KN95 or better).Students who are leading discussions may optionally remove their masks while presenting.Attendance and discussion question policies will be flexible with respect to COVID-19and other health issues. Please contact the instructor if you have any issues. Diversity & Inclusion The Brown computer science department has made it its mission to create andsustain a diverse and inclusive environment in which all students, faculty, andstaff can thrive. In this course, that responsibility falls on us all, students andteaching staff alike. In particular, Brown's Nondiscrimination and Anti-Harassment Policy applies to all participants. If you have not been treated in an inclusive manner by any of the course members,please contact either me (Stephen) or the department chair (Prof. Tamassia).Laura Dobler is also available as a resource for members of underrepresented groups. Additional resources are listed on the department's website. We, the computer science department, take all complaints about discrimination, harassment, and otherunprofessional behavior seriously. In addition, Brown welcomes students from all around the country and the world, and theirunique perspectives enrich our learning community. To empower students whose firstlanguage is not English, an array of support is available on campus, includinglanguage and culture workshops and individual appointments. For more information,contact the English Language Learning Specialists at ellwriting@brown.edu . Academic Integrity Academic dishonesty will not be tolerated. This includes cheating, lying aboutcourse matters, plagiarism, or helping others commit a violation. Plagiarismincludes reproducing the words of others without both the use of quotation marksand citation. Students are reminded of the obligations and expectations associatedwith the Brown Academic Code and Brown Code of Student Conduct .For project work, feel free to build on third-party software, datasets, or otherresources, as long as you credit them in your report(s) and clearly state whatwork is solely your own. As a general policy (for this course and for the rest ofyour academic career): if you use any idea, text, code, or data that you did notcreate, then cite it. Accommodations Brown University is committed to full inclusion of all students. Please informme if you have a disability or other condition that might require accommodationsor modification of any of these course procedures. You may email me, come to officehours, or speak with me after class, and your confidentiality is respected. Iwill do whatever I can to support accommodations recommended by SAS. For moreinformation contact Student Accessibility Services( SAS )at 401-863-9588 or SAS@brown.edu . Mental Health Being a student can be very stressful. If you feel you are under too muchpressure or there are psychological issues that are keeping you from performingwell at Brown, I encourage you to contact Brown\u2019s Counseling and Psychological Services CAPS .They provide confidential counseling and can provide notes supporting accommodationsfor health reasons. Incomplete Policy I expect everyone to complete the course on time. However, I understand thatthere may be factors beyond your control, such as health problems and familycrises, that prevent you from finishing the course on time. If you feel you cannotcomplete the course on time, please discuss with me (Stephen) the possibilityof being given a grade of Incomplete for the course and setting a schedule forcompleting the course in the upcoming year. Thanks to Tom Doeppner, Laura Dobler, and DanielRitchie for borrowed text. window.jQuery || document.write('<script src=\"js/vendor/jquery-3.3.1.min.js\"><\\/script>')", "https://cs.brown.edu/courses/csci2952d/": "Skip to main content CSCI 2952D: Computational Semantics Home (current) Lectures Assignments Staff Calendar Resources Natural language understanding is a holy grail of AI. And with the machine learning advancing at such a rapid pace, breakthroughs in automatic language understanding seem to be just around the corner.But what exactly are the current barriers in automating human-like language capabilities? This course will dissect what makes language understanding so challenging, including both theoretical aspects(logic, formal semantics, pragmatics, knowledge representation) and practical methods (graphical models, game theory, neural networks). The course will be project-based, and will emphasize reading andcritiquing current research in computer science, linguistics, and cognitive science. Time and place Fall 2018 TTh 10.30 - 11.50, CIT 477 (Lubrano) Instructor Ellie Pavlick Prerequisites Machine Learning (CSCI 1420) or Computational Linguistics (CSCI 1460) Discussion Forum Piazza Office Hours See calendar page Course materials Syllabus Readings Last updated December 14, 2018. Feel free to reuse any of the contents of this course or this web page. Theme provided by Bootswatch . $(document).ready(function(){ $(\"#main_page\").addClass(\"active\"); });$('#sidebar').affix({ offset: { top: 245 }});var $body = $(document.body);var navHeight = $('.navbar').outerHeight(true) + 10;$body.scrollspy({target: '#leftCol',offset: navHeight});", "https://cs.brown.edu/courses/info/csci1360/": "CSCI1360 Human Factors in Cybersecurity Offered this year and every year Fall 2024 This course is designed to push you to think about cybersecurity as an idea with both physical and virtual elements. Throughout the course, we will examine the value of information, the importance of users, and the difficult balance between security and usability. The ultimate goal of this course is to give you the intellectual and scientific framework you need to create systems that are both secure and efficient to use. The course focuses on usable security practices, but also looks deeply at the way our society influences security. Instructor(s): Ernesto Zaldivar Course Home Page: https://cs.brown.edu/courses/csci1360/ Location: TBD Meeting Time: TBD Exam Group: TBD CRN: None", "https://cs.brown.edu/courses/csci2952o/": "$(function() { $('#header').load('header.html'); $('#footer').load('footer.html'); $('#title').load('title.html'); }); Home Course Structure Schedule Policies Course Information This course is aimed at preparing graduate students and senior undergrads to do advanced work at the intersection of two important and popular fields: computer vision and robotics. The course will focus on the latest advances through lectures, readings, and discussion groups. The lectures and readings will be designed to represent a mix of classical techniques as well as the most recent advances in the two fields. The unique highlight of this course is the inclusion of a practical component: students will have to implement a project that combines computer vision and robotics by using cameras and a real robot arm. Students will form teams for this project and have exclusive access to a camera and a small robot arm both of which can be interfaced with the students' laptops. Class Time : Tu Th, 10:30am-11:50am / CIT 316 [ in-person participation required ] Ed Discussion : https://edstem.org/us/courses/35893 News Class starts on Thursday, Jan 26th. The course will require in-person participation . Please register/request override directly on Courses @ Brown with a short note on how you meet the prerequisites. There is no need to email us. Learning Goals This course has two main learning goals. Students are expected to actively participate in class including discussions and group activities. Learn about the state of the art in computer vision and robotics . We will do this by reading a curated list of research papers on relevant topics. Understand research practice in computer science , with specific focus on the computer vision and robotics communities. We will learn how to effectively read papers, make presentations, critique and discuss research, and do a group research project. The course will also include exercises and a final project with a robot arm . Prerequisites This is an advanced course primarily meant for graduate students and advanced undergrads. But students at all levels are welcome to participate if they have the necessary preparation. You must have taken one or more of the following courses (or equivalents) before enrolling. CSCI 1430 Computer Vision CSCI 1951-R Introduction to Robotics CSCI 1470 Deep Learning CSCI 1230 Introduction to Computer Graphics Other Requirements This class has some additional requirements. In-person classroom participation is required . This is a discussion-based class and we cannot support hybrid instruction. However, classroom sessions will be recorded for offline viewing. Please follow the most recent health guidance found on the Healthy Brown website. You must have a Windows/Mac/Linux laptop to interface with a robot arm . Please reach out to the instructor if you need alternative arrangements. This course has a final project. Students must use the robot arm in some way for their final project. Contact If you would like to take this course, please register/request override directly on Courses @ Brown . If you are unsure about the prerequisites, please reach out to the instructor. Instructor: Srinath Sridhar Email : srinath@brown.edu Office Hours : Book Appointment UTA: Rugved Mavidipalli Email : Rugved Mavidipalli Office Hours : Th 4pm - 6pm ( Hours )", "https://cs.brown.edu/courses/info/csci1951-i/": "CSCI1951-I CS for Social Change Not offered this year Offered occasionally, last taught: Spring 2023 In this course, students will work in a studio environment to iteratively design, build, and test technical projects in partnership with different social change organizations. Students will be placed in small teams to collaboratively work on projects that will range from, for example, developing a chatbot to aid community engagement to building a mobile app to teach STEM to refugee kids. Through the course, we will also reflect on our positionality and ethics in engaging in social impact work and what it practically means to leverage technology to create social change on an everyday basis. Enrollment limited to 12. Entry to this course is through application only. Instructor(s): Lachlan Kermode CRN: 27296", "https://cs.brown.edu/courses/info/csci2952-f/": "CSCI2952-F Distributed Systems at Scale: Microservices Management Not offered this year Offered most years, last taught: Fall 2022 This seminar investigates and explores cutting edge challenges and issues in the emerging Microservices paradigm. Microservices are a specific cloud paradigm for enabling distributed systems and applications at scale. In particular, this course builds on the foundations provided by the initial distributed systems, networking and operating systems offering (i.e., CSCI 1380, CSCI 1680, CSCI 1670) and explores how these concepts are used to realize, manage, and orchestrate microservices. The course is driven by materials from academic conferences and industrial blogs. The industrial blogs will provide context and motivation for different problems. The academic reasons will provide a deep divide into the technical details: we will focus on reading, analyzing, critiquing and brainstorming academic papers. Students taking this class should be familiar with reading academic literature, performing critical analysis, and working on open ended problems with undefined solutions. More information: http://cs.brown.edu/courses/info/csci2952-f/ Instructor(s): Theophilus A Benson CRN: 19118", "https://cs.brown.edu/courses/info/csci1951-l/": "CSCI1951-L Blockchains & Cryptocurrencies Offered this year and every year Spring 2025 Introduction to modern blockchain-based systems. Topics covered include consensus and distributed computing, examples cryptocurrencies, programming smart contracts, privacy and secrecy, transfer networks, atomic swaps and transactions, non-currency applications of blockchains, and legal and social implications. Students will do a programming project and a term project. Instructor(s): Maurice P Herlihy Location: TBD Meeting Time: TBD Exam Group: TBD CRN: None", "https://cs.brown.edu/courses/ta/": "The Undergraduate Teaching Assistant (UTA) Program Our UTA program is unlike any other. It employs more than 400 undergraduates each semester, and every one of these students is given the chance to impact their course in meaningful ways and work closely with the professor, other UTAs, and other students. Students often find being a Brown CS UTA to be a formative part of their Brown experience and build long-lasting friendships through the program. UTAs and non-UTAs alike can use this page to better understand the program and all of the amazing opportunities that lie in store for a would-be UTA! The UTA program is coordinated by the MTAs . The current MTAs are Allie Masthay, Elizabeth Jones, Christina Stepin, Tyler Gurth, Benjamin Schornstein, Nishka Pant, and Jiahua Chen. Want to learn more? Check out the following resources: UTA Hiring Publications", "https://cs.brown.edu/courses/ta/hiring/": "TA Hiring TAing is a great way to dig a little bit deeper into the material for a course, get practice working in a group of peers, interact more closely with a professor, learn something about how courses are run, make some money, and have fun doing it! If you've taken a CS class, we want you to apply! To see courses hiring TAs, please check out the courses hiring page. For detailed position descriptions, see these pages for Head TAs , Undergraduate TAs , Socially Responsible Computing TAs (formerly Ethics TAs), Head STAs , and Meta TAs . Brown University is an equal opportunity/affirmative action employer and strongly encourages applications from women, minorities, and protected persons. ( Click here for more information.) The TA hiring process is coordinated by the Meta TAs . The CS UTAs, STAs, HTAs, HSTAs, MTAs, and several other categories of student workers in the CS department are members of a collective bargaining unit represented by the Teaching Assistant Labor Organization (TALO). The employment of these student workers is subject to the 2023 Interim Agreement Between Brown and TALO [ Full Text, Plain Language Summary ]. Applications All undergraduate and Masters students are eligible to apply. (PhD students are not eligible for HTA / UTA / STA positions, but PhD students in the Computer Science department may be hired as Graduate TAs. Graduate TAs are hired separately from this process\u2014speak to your advisor if you're a Computer Science PhD student who wishes to become a Graduate TA.) The MTA application for Fall 2024 is closed. The HTA application for Fall 2024 is closed. If you wish to apply late, you should contact the professor teaching the course for permission and submit your application here . The HSTA application for Fall 2024 is closed. The UTA application for Fall 2024 is available here . The STA application for Fall 2024 is available here . Spring 2024 Hiring Timeline MTA Hiring 1/29 MTA applications open 2/2 MTA applications close @ 5pm ET 2/5 - 2/12 MTA applicants are interviewed 2/15 Latest date that all MTA applicants hear back HTA/HSTA Hiring 2/6 Fall 2024 HTA and HSTA applications open 2/10 Fall 2024 HTA and HSTA applications close @ 5pm ET 2/12 - 2/26 Fall 2024 HTA applicants are interviewed 3/4 Latest date that all Fall 2024 HTA applicants hear back UTA/STA Hiring 2/28 Fall 2024 UTA and STA applications open 3/6 Fall 2024 UTA and STA applications close @ 5pm ET 3/11 - 4/17 Fall 2024 UTA and STA applicants are interviewed 4/24 Latest date that all Fall 2024 UTA and STA applicants hear back Questions First, check out these FAQs . If you don't find an answer, contact the MTAs for questions about the hiring process, the TA program as a whole, or MTAing the professor of the course for questions about HTAing a specific course the professor or HTAs of the course for questions about UTAing a specific course the Socially Responsible Computing HTAs (HSTAs) for questions about the STA program", "https://cs.brown.edu/covid/": "COVID-19 Response Resources for CS Before continuing, please read the Brown CS 2020-21 Plan , which may replace some of the information below. Visit Brown's COVID-19 website for the most up-to-date information: Brown Coronavirus News and Information Brown University COVID-19 Site Remote Work Guide Teaching Continuity Guide Additional resources for Computer Science Students, Faculty and Staff are listed below. Working From Home Getting Started with FastX Getting Started with Zoom Connecting to CS using SSH or Mosh VPN to the CS Network Access your home directory using VS Code (requires an active VPN connection) When using VS Code connect to: fastx-cluster.cs.brown.edu Filesystem Web Interface(No VPN needed) Setting up SSHFS Getting Help Technical Staff (TStaff) Email problem@cs.brown.edu Zoom https://brown.zoom.us/j/6775943824 While observing summer hours, the Zoom room will be available (8 a.m. to 4 p.m.) Meeting ID: 677 594 3824 Phone: +1-301-715-8592 (Enter meeting ID when prompted) US Toll-Free: 877-369-0926 or 877-853-5247 Sun Lab Consultants - help with remote access consult@lists.cs.brown.edu System Status CS Classes Online Students CS Student Resources Faculty A/V Options for Teaching in CS This is an evolving document. Please send comments or suggestions to problem@cs.brown.edu .", "https://cs.brown.edu/courses/ta/pubs/": "Publications These are the documents maintained by the Meta-TAs for the UTA program. They are intended to help TAs do their job, to help students understand how to interact with their TAs, and to give others a bit of insight into how the program works in the department. These documents are maintained based heavily on suggestions from students, TAs, and faculty. By all means, if you have suggestions, please contact the Meta-TAs . Missives UTA Missive : A guide for new and returning UTAs that contains basic information about the TA program. This document is updated regularly to reflect changes in the department. (Last updated in January 2024.) HTA Missive : A guide for new and returning HTAs that contains detailed information on aspects of HTAing from hiring to policies to techincal resources. This document is updated regularly to reflect changes in the department. (Last updated in January 2024.) Links Jobs for Undergraduates : This page lists the various opportunities for undergrads to work in the department. It includes the UTA, HTA, and Meta-TA job descriptions, which are maintained by the Meta-TAs. For more information about the Socially Responsible Computing program, see here . To learn more about becoming a Socially Responsible Computing Teaching Assistant (STA), see here .", "https://cs.brown.edu/degrees/": "Applying To Our Degree Programs We offer one of the best environments in the world for both research and education. Our faculty, students, resources, and location are just some of the reasons why you should study at Brown CS . Click any of the links below to apply to the appropriate program. Graduate Study This consists of a doctoral program and two Master's programs, the Master of Science in Computer Science and the Master of Science in Cybersecurity . The latter is a fully online degree that can be completed from anywhere in the world. Doctoral students can earn a Master's degree automatically, but students admitted for a Master's don't automatically transition to the PhD track. The Data Science Initiative also offers a Master's program that prepares students from a wide range of backgrounds for careers in data science. Rooted in a research collaboration among four very strong departments (Applied Mathematics, Biostatistics, Computer Science, and Mathematics), it offers a rigorous, distinctive, and attractive education for people building careers in data science and/or big data management. Undergraduate Study Our undergraduate program pioneered the idea of undergrads contributing to teaching and research at a time when few universities even offered CS courses. Today, no other institution gives students the same opportunities to be part of the university's intellectual life, benefit from a community of collaborators, and advance the field. Undergraduate students also have the option of staying a fifth year to obtain a Master's degree.", "https://cs.brown.edu/degrees/doctoral/": "Our PhD Program Working with faculty who are leaders in the field, our PhD students conduct cutting-edge research, earning prestigious fellowships and awards . After graduation, they contribute widely to science, learning, culture, and their communities, earning honors in academia and industry. (They also throw rubber chickens at each other.) This page is for prospective PhD students. Current students, go here . We offer world-class research and education in an interdisciplinary environment (for more detail on the below, click here ): A lower student/faculty ratio than many of our peers Full financial support while completing the degree (full tuition, health insurance, a generous stipend) Teaching assistantships for students who want to hone their teaching skills Shared offices that overlook Brown's scenic campus Opportunities to serve on important committees and organize seminars and other events Students can take courses from Harvard, MIT, RISD, and other institutions without additional cost (see here for details and restrictions) \"Brown CS makes it very easy to talk to a professor and join their research group. I was very surprised how much of a family feeling the department has...here you chat with everyone at the coffee machine.\" \u2014 Emanuel Zgraggen, PhD student Additional Information How do I apply? Why is Brown a great place to study CS at all levels? What are the requirements for earning a PhD? How do I transfer graduate credit from another institution? Fill out this form and this one and send them to Elena Quinonez at fasam@cs.brown.edu. What do young researchers working in industry say about the benefits of earning a PhD? How can I learn more about the program? Read our FAQ . How can I learn more about grad school application and life? (Professor Shriram Krishnamurthi gives answers.) How do I ask additional questions? (Email link)", "https://cs.brown.edu/degrees/doctoral/applications/": "Applying To Our Doctoral Program Thanks for your interest! If you haven't already, please acquaint yourself with the PhD program (and compare it to our Master's program ). You may want to review the homepages of our faculty for information about their research interests, and if they have any instructions for applicants interested in them as a potential advisor. Please read the FAQ here . When you're ready, continue to the Official Online Application , but note the following: To request an application fee waiver , please fill out the form here . We're especially eager to waive fees for applicants from underrepresented groups. You'll be notified as soon as possible if your request has been approved. Your application will be kept on hold until you either enter a waiver code or pay the application fee. If you belong to an underrepresented group in CS and want to receive feedback and guidance on your application , please fill in this form . You'll receive guidance from current Brown CS PhD students, either in the form of feedback on your application or a Zoom guidance session, as chosen by you in the form. Participation is completely optional, and it's separate from the application process. While this program doesn't guarantee admission, we hope that it'll be useful to you. You can learn more here . Application Requirements We expect strong results from our applicants in the following: Record of grades or other academic performance Research experience or clear motivation of a research plan 3 recommendation letters (you might suggest to your letter writers that they look at this site ) TOEFL or IELTS (for applicants whose native language is not English) Note the GRE is no longer mandatory, but may be included if desired Again, please read our FAQ . How To Apply The deadline for applications (including test scores and letters of recommendation) for entry in September is December 15 . (We don't allow doctoral students to start at other times of the year.) If your recommendation letters are arriving a day or two late due to circumstances beyond your control, go ahead and email us to give us a heads up. Please visit the graduate school website and complete the entire application on-line . You can get additional information from our FAQ and from the Graduate School 's Web site. We strongly urge you to provide unofficial (scanned) copies of your transcripts as part of the electronic application. If you're accepted to the program, we'll ask you to mail an official copy of your transcript. Graduate applications are handled by a combination of Brown CS and the Graduate School. First, your application is formally processed by the Graduate School. Its content is then read by members of Brown CS, who forward their recommendations to the Graduate School. Finally, the Graduate School formally admits you to the program. Therefore, you may receive correspondence from either of these entities. Note that doctoral students can automatically earn a Master's degree on the way to completing their PhD, but Master's students don't automatically transition to the PhD track.", "https://cs.brown.edu/degrees/masters/faq/": "Frequently Asked Questions About Our Master's Program We will begin accepting applications for Fall, 2024 entry on September 1, and the deadline is January 15. Please note that Spring entry is only available for Brown undergraduates who are doing a fifth-year Master's degree. 1: How much does a Master's degree cost? Please see here . Most students take two courses per semester, but this page assumes four. Please adjust accordingly: the actual tuition cost is the per-semester figure given, divided by four, and multiplied by the number of courses taken. We also offer a small number of merit-based, full-tuition scholarships to support Brown CS diversity and inclusion goals. If you're admitted, you'll be given an opportunity to apply for them. 2: What are the admission criteria for the Master's program? We consider numerous criteria, including academic performance, letters of recommendation, and industrial experience. We also consider GRE scores, TOEFL scores (if relevant), motivation, work experience, awards, honors, prizes, and other accomplishments. Because Master's applicants are so diverse, no single set of criteria adequately covers all the cases. In more detail, we're looking for: Academic performance: The GPA isn't the only criterion. Grades in computer science and related disciplines (for example, math) count more than grades in other areas. Current undergraduates should send us your Fall semester grades. Also, we take into account the fact that at some very competitive schools it's very difficult to achieve a high GPA. Letters of recommendation: Letters must give a detailed, factual, and candid evaluation of your capabilities. Rankings and comparisons with other students are very useful. Ask your recommenders to follow these guidelines. Remind your recommenders of deadlines to ensure they meet them. We routinely find ourselves unable to admit potentially qualified students because their letters of recommendation haven't arrived in time. Work experience: Please describe any work experience you might have. Obviously, not all applicants have work experience, but for those who do, some description of it helps us better evaluate your application. General GRE scores: We don't require these, and we don't recommend that you take the GRE just for admission to our program. However, these scores provide an additional objective form of evaluation that's often helpful in determining your basic skills and comparing them to applicants from diverse backgrounds. We're aware that test performance can improve considerably with practice, some people don't perform well on tests, and that the verbal GRE is harder for some foreign applicants. TOEFL/IELTS: The TOEFL/IELTS exam is required for applicants to the Computer Science (ScM) program unless you meet one of the exemption criteria (see below): Your first language is English You have received a degree (or will obtain a degree) from an institution where English is the sole language of instruction You have received a degree (or will obtain a degree) from an institution in the following countries: Australia, Bahamas, Botswana, Cameroon, Canada (except Quebec), Ethiopia, Ghana, Ireland, Kenya, Lesotho, Liberia, Malawi, New Zealand, Nigeria, Zimbabwe, South Africa, Sierra Leone, Swaziland, Tanzania, Gambia, Uganda, United Kingdom (England, Scotland, Northern Ireland, Wales), West Indies, Zambia. If you meet one of the exemption criteria, you do not need to submit TOEFL or IELTS scores, but may choose to do so if you wish. If you do not meet one of the exemption criteria, you must submit TOEFL or IELTS exams. We don't consider applicants who have scored below 620 (PBT) or 260 (CBT) or IBT (105), and prefer scores higher than that. The corresponding minimum IELTS score is 8.0. If you need to request a TOEFL/IELTS waiver due to financial hardship, please contact masters_admissions@brown.edu . Statement: The statement that accompanies your application helps us learn more about you. Awards, honors, and prizes: Unless they're well known (for example, an NSF fellowship or graduation with honors), please give details about them (how many candidates? how many awards? what were the selection criteria?). This is especially important for foreign applicants. If these awards are really important, we'd expect your recommenders to mention them. Research experience: Research experience isn't required for Master's applicants and many of our applicants don't have any, but you can use experience you've had to demonstrate your ability to handle graduate-level computer science material. 3: Can I still apply if I don't have all the material ready by the deadline? Unfortunately not. We need a complete application, including letters of recommendation AND OFFICIAL SCORE REPORTS (including TOEFL and IELTS when needed: see 2 above) before we can make admission decisions. Note that we don't require the GRE, and we don't recommend that you take it just for admission to our program. Therefore, please give your letter writers enough time to write and mail your letters of support. 4: When can I begin study? Only in September, unless there are truly exceptional circumstances. 5: I can't afford the application fee. Can you waive it? Application Fee Waiver Guidelines: 1) The Application Fee is automatically waived for: Active duty U.S. Military personnel, as well as U.S. Military veterans. Please be sure to list your status within the application. Domestic or international applicants who are members/alumni of certain programs listed within the application. 2) If you would like to request an Application Fee Waiver based on high-financial need: Please complete the Application Fee Waiver Form found within the online application. The Application Fee Waiver Form is located under the section entitled Financial Information . You will see a link that says Application Fee Waiver Form. Please note this form is only accessible once you have started an application and selected your program of study. The Application Fee Waiver Form must be submitted no later than three days before the application deadline. Applicants will be notified by email regarding the outcome of their request and should not submit their application until receiving notification about their waiver . In addition, you will need to upload documentation that substantiates your financial hardship. 6: Do you have financial aid available for Master's students? We offer a small number of merit-based, full-tuition scholarships that are used to support Brown CS diversity and inclusion goals. If you're admitted, you'll be automatically considered for them. To find out how to apply to external sources for support, you can consult the Graduate School's web page . Also note that there are very few, if any, funding sources available for international students. While we do assist all Brown CS Master's students in finding paid internships for the summers they're here, international students must \"provide certified proof of financial support (including travel to and from America) adequate to meet annual expenses\". Please see here for details. 7: Are scans of any of the application materials acceptable? We encourage scanned copies as part of the initial application; original documents are required if you're admitted and decide to enroll here. Please send all documents to the Graduate School: Master\u2019s Study Enrollment Team Brown University 225 Dyer Street | Box T Providence RI 02912 Sending materials to the Brown Graduate School is fine, but there will be additional delays in processing these materials. 8: Do you admit students only from certain elite universities and reject ones not from there? We admit only outstanding students to our program. The institution you attended is just one of many indicators we consider. In particular, we recognize that excellent students graduate from all kinds of institutions; it's what they do there and after graduation that makes their applications stand out. Thus we do sometimes reject students from leading American and international institutions and accept students who did not attend such universities. 9: What kind of applicant are you looking for? What kinds of courses should I take before I apply to strengthen my application? There are exceptions, but typically we look for outstanding students who already have an undergraduate CS degree or the equivalent and are ready to take our Master's-level courses. Please see 2 above, where work experience, research experience, and other factors are discussed in detail. While we sometimes discount weaknesses in some areas if there are strengths in others, we'd like to see most of the following courses: An introductory Programming course An introductory Algorithms and Data Structures course A Computer Systems or a Software Engineering course (preferably both) A course on Discrete Mathematics and basic Probability A Linear Algebra course In addition, a student should have taken a more advanced course (normally offered to juniors and seniors) in at least one area of CS. 10: I've earned my Bachelor's degree from a three-year degree program. Can I still apply for a Master's degree? The three-year programs we know about, specifically those in India, are acceptable, and students from those programs can apply. If you're coming from a program with which we are not familiar, we may need information from you before acting on your application. 11: Do I have to take the GRE General exam? Brown CS doesn't require the General exam for Master's applicants. General test scores give us an additional objective form of evaluation, but on the other hand, some students have extremely strong records, and this strength is evident from their application. For such students, the General test score doesn't provide much additional information. In the end, it's your call. 12: Do I have to take the GRE Subject exam? No. Brown CS doesn't consider Subject exam results. 13: Where do I send my transcripts, score reports, and other materials? If you're admitted and prompted to do so, please send supplemental materials to: Master\u2019s Study Enrollment Team Brown University 225 Dyer Street | Box T Providence RI 02912 Sending materials to the Brown Graduate School is fine, but there will be additional delays in processing these materials 14: Should I use the institution code, the department code, or both for the GRE and TOEFL? The GRE institution code is 3094 and the GRE department code is 0402. For the TOEFL, you should use the school code, which is 3094, and the department code, 78. Note that the answers to these questions and many like them may be found here . 15: Who will be the primary readers of my application? Your application (in particular, your statement) will be read primarily by Brown CS faculty. 16: Who decides whom to admit? Officially, admissions are generated by the Graduate School of Brown University. In practice, Brown CS (specifically, a group of faculty members) evaluates your application and makes recommendations to the Graduate School, which typically follows our recommendations. 17: If admitted, will I have a faculty advisor? How will they be chosen? After admission, you will be assigned a faculty advisor based on your stated interests. If necessary, you can contact the Director of Graduate Studies for the Master's program ( cs-masters-info@brown.edu ) to request a new faculty advisor. 18: As a Master's student, what opportunities will I have to do research? How do I start a research project? We have a whole page devoted to this subject: please see here . 19: What if I have other questions? Please email us .", "https://cs.brown.edu/degrees/masters/applications/": "Applying To Our Master's Program We began accepting applications for Fall, 2024 entry on September 1, and the deadline is January 15. Please note that Spring entry is only available for Brown undergraduates who are doing a fifth-year Master's degree. Thanks for your interest in our Master's program! If you haven't already, please: acquaint yourself with the program to make sure it's a good fit for you. Note that doctoral students can automatically earn a Master's degree on the way to completing a PhD, but Master's students don't automatically transition to the PhD track. read our FAQ . It answers many of the questions you probably have. Application Requirements We expect strong results from applicants in all of the following items. While we don't require GRE scores, if you do supply them, we expect strong results here as well. Record of grades or other academic performance (current undergraduates, send us your Fall semester grades) Letters of reference (you might suggest to your letter writers that they look at this site ) TOEFL or IELTS (for applicants whose native language is not English and do not meet any of the exemption criteria) Again, please read our FAQ . Applying We will begin accepting applications for Fall, 2023 entry on September 15, and the deadline is January 15. Please note that Spring entry is only available for Brown undergraduates who are doing a fifth-year Master's degree. Once the application system has closed, it won't reopen until September for new applications. You'll be notified by the School of Professional Studies if you're admitted. Please go here to apply. You can get additional information from our FAQ and from the School of Professional Studies site. We strongly urge you to provide unofficial (scanned) copies of your transcripts as part of the electronic application. You'll be prompted to mail an official copy of your transcript if you're accepted to the program. Graduate applications are handled by a combination of Brown CS and the School of Professional Studies. First, your application is formally processed by the School of Professional Studies. Its content is then read by members of Brown CS, who then forward their recommendations to the School of Professional Studies. Finally, the School of Professional Studies formally admits you to the program. Therefore, you may receive correspondence from either Brown CS or the School of Professional Studies. Financial Aid We will be awarding a small number of full-tuition scholarships to applicants who come from disadvantaged socioeconomic backgrounds, but who have accomplishments showing that they can overcome the negative effects of their backgrounds. If you are interested in such a scholarship, we will ask you to explain, as part of the application, the nature of your socioeconomic disadvantages and the accomplishments you've achieved in spite of it. Scholarships are awarded regardless of an applicant's race, color, national origin, or gender.", "https://cs.brown.edu/degrees/misc/jobs/assignments/": "Graduate Student Jobs and Assignments (As of Fall 2023) Fac-Grad Liaison(s) (FGL) Thao Nguyen Aaron Traylor Fac-Grad-Masters Liaison (FGML) Muskaan Patel Sheridan Center Liaison Talie Massachi GSC Reps Catherine Chen Aidan LaBella Mentorship Program Czars Nihal Nayak Yanyan Ren Mental Health & Well-Being Czar Position available Facilities Czar Position available Faculty Search Czars (3 Recommended) Tuluhan Akbulut Oguzhan Colkesen Ruochen Zhang Recruitment Czars (3 Recommended) Lakshita Dodeja Orientation Czars (3 Recommended) Catherine Chen Anita De Mello Koch Sports Czar Sam Lobel PhD Lounge Czar William Rudman Social Czar(s) Position Available GCB Czar Skye Thompson TGIF Czars Benjamin Spiegel Sam Thomas Tea Czar(s) Elijah Rivera REST Czars Position available Info Khan Position available Rubber Chicken Khan Aditya Ganeshan Fridge Demon Anonymous Ergo Merc David Tao High Performance Computing Merc Sam Lobel Video Merc Position Available If you are interested in any of these positions, please contact the Fac-Grad Liaison(s) listed at the top.", "https://cs.brown.edu/degrees/masters/reqs/": "Master's Program Requirements The requirements for a Master\u2019s of Science (ScM) degree in Computer Science consist of a basic component and an advanced component. All courses must be at the 1000-level or higher. Students must have a B average over all courses used to satisfy the requirements. All courses must be taken for a grade, and all grades must be C or better (S's may not be used). The courses in your program must be approved by the Director of Graduate Studies (Master\u2019s) as well as by your advisor. You can find the Master's contract here . Basic Component The basic component consists of six courses. None of these courses may be reading and research courses (in particular, they can\u2019t be CSCI 2980). The six courses are chosen as follows: Two must be CS courses that form a pathway (see the explanation of pathways here ). One must be a CS course in an area that\u2019s not listed in the chosen pathway (it must not be a core course, must not be a grad course, and must not be a related course of the pathway). The three additional courses must be in CS or related areas, and must be approved by your advisor or the director of graduate studies (Master\u2019s). Getting this approval will require you to show that the courses are relevant to your CS interests. In general, the more non-CS courses you wish to take, the stronger your justification must be. Advanced Component The advanced component requires you to complete one of the following four 2-course options. No Reading and Research courses may be used in options 3 and 4. An \u201cadvanced course,\u201d as used below, is a 2000-level CS course. \u201cInternships,\u201d as used below, must be approved by the student\u2019s advisor and are paid work in the area of the student\u2019s Master\u2019s studies and are explained further below. The four options are: Complete a research project as two instances of CSCI 2980 supervised and approved by your research advisor. Complete a research project as two instances of CSCI 2980 supervised and approved by your research advisor, and complete an internship. Complete two advanced courses (not including CSCI 2980). Complete two advanced courses (not including CSCI 2980) and complete an internship. Note that options 2 and 4 are known as the professional track. Consult the Master's Program Handbook for details. Rationale Students entering the Master\u2019s program typically have one of two goals: they intend to pursue research careers in computer science and are preparing themselves to enter PhD programs, or they intend to become professional computer scientists and pursue careers in industry. In both cases, students should take collections of courses that not only give them strength in particular areas of computer science, but also include complementary areas that familiarize them with other ways of thinking about the field. For example, a student whose interests are in the practical aspects of designing computer systems should certainly take courses in this area, but should also be exposed to the mindset of theoretical computer science. In a rapidly changing discipline, there is much cross-fertilization among areas and students should have some experience in doing advanced work in areas not directly related to their own. Students whose goals are research careers should become involved as quickly as possible with research groups as part of their Master\u2019s studies, and demonstrate and learn about research by participating in it. The resulting research reports will serve to establish their suitability for entering PhD programs. Students whose goals are to be professional computer scientists should have some professional experience as part of their preparation. A certain amount of basic coursework is required before a student can qualify for a pedagogically useful internship. Students with limited experience in computer science should take a few advanced computer science courses before embarking on an internship. Other students, particularly those whose undergraduate degrees were at Brown, will likely have had internship experiences while undergraduates. Internships provide insights for subsequent courses and project work at Brown. Students without such experiences are at a disadvantage with respect to their peers. Thus we strongly encourage students who have not had such experience to choose one of options 2 or 4, for which internships are required. Note that these internships are not courses and the work is not evaluated as it would be for a course. Students\u2019 advisors will assist them in choosing an internship, but it is up to students themselves to ensure that they get as much benefit as possible from their experiences. They must be able to take advantage of these experiences while completing their Master\u2019s projects \u2014 we expect as high-quality work from them as we do from students who entered the program with prior internship experiences.", "https://cs.brown.edu/degrees/misc/jobs/jobs/": "Graduate Student Job Descriptions Faculty-Graduate Liaison (FGL) The FGL is a senior PhD candidate tasked with handling most faculty-grad interactions and concerns. This is the person to talk to if you hit a difficult moment in your grad career. Responsibilities include monitoring czar, khan, and merc activity, allocating office space, and controlling access to the grad nest egg. More details on the role can be found at the Fac-Grad Role Page . Faculty-Graduate-Masters Liaison (FGML) The FGML is a second-year Master's student tasked with working with the FGL to ensure faculty-grad interactions and concerns attend to the needs of the Master's students. This is the person to talk to if you hit a difficult moment in your grad career. Responsibilities include working closely with the FGL, planning and coordinating events, and checking in with Master's students to ensure things are going smoothly. Sheridan Center Liaison Coordinates announcements and solicits participation in Brown's teaching-focused trainings through the Sheridan Center. The Sheridan Center Liaison helps support the excellence in teaching expected of teaching assistants and future faculty members at Brown. Graduate Student Council (GSC) Representatives Brown CS is currently entitled to 4 representatives in the Graduate Student Council. At least one of these representatives should be a Master's student. The Council itself is a collection of grad representatives from all departments. See the GSC page for more details. The CS Reps must attend the GSC meetings and represent Brown CS in graduate school affairs. In addition, they are responsible for filing the GSC rebate form, which funds the nest egg. Mentorship Program Czars These students help coordinate the mentorship program for new PhD students \u2013 this involves recruiting new mentors each year from the pool of post-candidacy mentors, matching mentors to new PhD student mentees, and organizing any mentor-program events each term. Mental Health & Well-Being Czar The Mental Health Czar informs graduate students about Counseling and Psychological Services (CAPS) at Brown, such as relevant mental-health events on campus. The Czar is also responsible to decrease the stigma surrounding using CAPS services, and promote awareness of mental well-being. Facilities Czar The Facilities Czar represents the graduate students on the Brown CS facilities committee. This committee is responsible for allocating money for and determining the specifications of new machines, monitors, and so on. Faculty Search Czars These students assist the faculty in recruiting and hiring new faculty. There is a czar for each area of the faculty search. Responsibilities include: assisting in the creation of the short list of candidates, disseminating information about job talks to the graduate students, attending job talks in their area, organizing the graduate student-candidate interview, and presenting the graduate student opinion to the faculty search committee. Recruitment Czars The main responsibility of the Recruitment Czars is to organize the graduate-student recruitment weekends. This includes setting up faculty/student talks, organizing lunches and tours, and arranging housing. Students visiting at other times are also made welcome by the Recruitment Czars. Orientation Czars The complement to recruiting weekend is orientation week, when new students are welcomed to the department. The Orientation Czars set the week's schedule and arrange for all the appropriate talks to take place. In addition, they arrange for the yearly photo collage to be made. Prior czars have accumulated their wisdom into the Orientation Czar Guide . Sports Czar The Sports Czar (SC) informs graduate students about ongoing physical and recreational activities in the campus. The SC can also sign up intramural teams and carry out tournament registration and reimbursement processes. It is the SC's responsibility to attend the captain's meetings and scheduled sessions. The SC is the default administrator of group-specific email lists (such as soccer@cs). Finally, the SC should initiate Brown CS tournaments and arrange training sessions (time, weather, place, equipment, and so on). PhD Lounge Czar The PhD Lounge Czar is responsible for keeping track of facilities in the PhD lounge (CIT 404). Social Czars The Social Czars are responsible for keeping a sense of community in the department by organizing at least one social event a month. They are responsible for organizing the Halloween party, and helping with the department holiday party. Grad Center Bar (GCB) Czar The GCB Czar organizes the weekly Brown CS GCB hangout. TGIF Czars The TGIF Czars (there are usually two) are responsible for providing food for the weekly TGIF social hour with funds provided by Brown CS. To learn from the accumulated wisdom of prior czars, see the TGIF Czarship Guide . Tea Czars Another two-person team, the Tea Czars organize the weekly Brown CS tea and cookies. REST Czars The REST (Research Exchange Seminars with Tea) Czars host a weekly talk from a grad student designed to disseminate information about ongoing research in Brown CS and foster collaboration between disciplines. Info Khan The Info Khan is responsible for maintaining the graduate student web structure. Rubber Chicken Khan The primary responsibility of the Rubber Chicken Khan is to maintain a coop of rubber chickens. A chicken is traditionally awarded to (that is, thrown at) a PhD candidate who has successfully defended their thesis, following the faculty handshakes and preceding the champagne. The khan is also responsible for assigning the chicken thrower for each thesis defense. The chicken thrower is usually the closest friend of the chicken recipient in Brown CS. Fridge Demon The Fridge Demon is an anonymous position, responsible for the cleanliness of the department's fridges (located in CIT 302, 412, 532). Once a month, they must examine the refrigerators and discard any items that need it. D&I Administrative Merc The D&I Merc assists diversity and inclusion efforts in the graduate student recruitment process. This job involves administrative tasks (spreadsheet management), outreach, as well as coordination with the chair of the department and the diversity chair. Ergo Merc The Ergo Merc maintains the departmental ergonomic website as well as a pool of ergonomic keyboards and voice recognition software. New users are taken care of (workspace evaluations) and injured parties are led through the department and university ropes. In addition, this merc coordinates the Brown RSI-awareness campaign and collects statistics on RSI at Brown CS for reporting to the Facilities Committee. For more information, see the Ergo Merc Details . High Performance Computing (HPC) Merc The HPC Merc is primarily responsible for fielding questions and providing information/guidance related to the use of the CS department's high-performance computing resources (e.g. the in-house \"Grid\" or the department's GPU condo on the CCV's \"Oscar\" cluster). The position additionally entails communicating and working with the department technical staff regarding potential new features and changes to the existing HPC infrastructure, as well as interfacing with other university computing groups (such as CCV) for coordinating joint projects. The HPC Merc will also periodically survey the department's current HPC users about their usage patterns and solicit feedback on the state of the HPC infrastructure, and then summarize and present that information to the CS technical staff. Ideally the HPC Merc is someone with knowledge of (or interest in learning about) modern high-performance computing infrastructure and related technologies. Video Merc The Video Merc collects videos from distinguished lectures, symposiums and any other important talks the department hosts. They will then be in charge of posting them to Vimeo or other flash-based site account. This person will also take pictures at Brown CS events (receptions, the Halloween party, and so on) and organize them in a photo gallery. This position will require coordination with the Info Khan to link it from the main site. Interview Room Khan (archived) The Interview Room Khan reserves CIT 522 for students and provides the key so they can access it. Knowledge Khan (archived) The Knowledge Khan is responsible for the dissemination of exciting Brown CS research to all members of the department. The primary method used is to organize the yearly departmental retreat. Comprehensives Czar (archived) The job of the Comprehensive Exam Czar, who must be a PhD candidate, is to assist the faculty member in charge of the comprehensive exams to ensure that the exams run smoothly. During the programming exam, the comps czar monitors the process and works with the responsible faculty members to solve any problems that might occur. Calendar Czar (archived) The Calendar Czar works with AStaff, TStaff, faculty, and grads to keep track of events of interest to the Brown CS community and minimize scheduling conflicts. They collect information on classes, reading groups, lectures, lunches, lab meetings and the like and maintain an up-to-date calendar.", "https://cs.brown.edu/degrees/why-brown/interdisciplinary/": "Our Interdisciplinary Options \"Late nights in the graphics lab allowed me to see how CS could connect with other disciplines and Brown\u2019s honors program allowed me to experiment with my first truly interdisciplinary research project. All of this fed into my approach to CS, which is so beyond interdisciplinary at this point that it\u2019s hard to even give me a disciplinary label.\" \u2014 danah boyd, Microsoft Principal Researcher and Data and Society Founder Brown CS is a diverse community engaged in all aspects of research, teaching, and mentoring. Due to the importance of computational thinking in many different endeavors, we collaborate with almost every department at Brown. Undergraduate Interdisciplinary Options Our joint majors reflect our collaborative orientation, with opportunities to combine CS with four other disciplines: Applied Math-CS Computational Biology Math-CS Computer Science-Economics AB Computer Science-Economics ScB We also have strong undergraduate research groups in graphics, neuroscience, and robotics, as well as a long record of involving undergraduates in projects that span disciplinary boundaries. Graduate Interdisciplinary Options Our graduate students often have advisors in two departments, and they have a history of interdisciplinary work, from devising algorithms to improve characterization of genomic mutations in tumors to improving governmental response to natural disasters. Large-scale partnerships like the Brain Science Program (made up of more than 70 faculty from ten departments) and the Humanity Centered Robotics Initiative (faculty, students, and affiliates using robotics to tackle current world problems) make it easy for students to customize their education to match their diverse interests.", "https://cs.brown.edu/degrees/undergrad/concentrating-in-cs/": "Concentrating In Computer Science PLEASE NOTE: If you started at Brown in or before Fall 2017, you're able to use the old requirements, but we strongly recommend that you use the current requirements, which have been redesigned to serve you better. At this time, requirements for the joint-programs have not changed. The Department of Computer Science offers several A.B. and Sc.B. concentrations (a.k.a. majors) for undergraduates. The undergraduate program is designed to combine educational breadth in the areas of software, hardware, and theoretical computer science with a deeper understanding of specialized areas such as software system design, programming languages, computer architecture, artificial intelligence, the analysis of algorithms, and the theory of computation. Becoming A CS Concentrator To become a CS concentrator you must fill out the electronic application on ASK . At the time of declaration, you must also complete a program plan or contract indicating which courses you currently plan to take to complete the concentration (these can be changed later). For those declaring a pure CS concentration or a CS/Economics joint concentration, fill out the program plan in ASK ( instructions and FAQ ). For those declaring other joint concentrations or using the old concentration requirements, use the paper forms available further down on this page. Make an appointment with your concentration advisor to go over your choices and discuss the programs. All concentrators are required to meet with their concentration advisors at least once a year. This is normally done during a designated four-week period in the middle of the fall semester (the dates will be announced several weeks beforehand). Students who don't meet with their advisors during this period are subject to having their computer accounts frozen. If you have any questions and don't already have a CS advisor, contact Tom Doeppner or Kathi Fisler . Concentration Overview CS concentrators must complete an introductory sequence, take intermediate courses that provide a foundation for the upper-level courses, and complete several upper-level courses. Our requirements are built on a collection of pathways, each representing a well defined area within computer science. Concentrators interested in particular areas might choose the courses included in particular pathways. Conversely, concentrators who are unsure of their areas of interest but who have particularly enjoyed certain courses might choose pathways that include these courses. Each pathway specifies a number of core courses, a collection of related courses (including 2000-level (grad) courses), and up to three mandatory intermediate courses. Completing a pathway entails taking at least one core course, another core or related course, and the mandatory intermediate courses. A.B. students must complete one pathway; Sc.B. students must complete two pathways. Additional 1000-level (or 2000-level) courses are required as needed to get to a total of nine courses for the A.B. and fifteen courses for the Sc.B.. In addition, Sc.B. students must complete a capstone course. All CS and joint-CS concentrations, except for Computational Biology, have an optional Professional Track , which primarily supports international students working with CPT visa regulations. Concentration Requirements Please note that you may only use the 2018 requirements if you started at Brown in 2018 or earlier and the 2017 requirements if you started at Brown in 2017 or earlier. Concentration Requirements (Current) Concentration Requirements (2018) Concentration Requirements (2017) Concentration Contracts Please note that these are only for students using the 2017 Concentration Requirements. The following links are all Adobe Acrobat documents: Computer Science A.B. (old requirements only, otherwise use ASK) Computer Science Sc.B. (old requirements only, otherwise use ASK) Math-CS Sc.B. Applied Math-CS Sc.B. Computational Biology-Sc.B. Choosing an Advisor Every concentrator will have a concentration advisor, who is normally someone from the list at https://cs.brown.edu/<wbr/>degrees/undergrad/<wbr/>concentrating-in-cs/advisors . While it's not mandatory that you do so, we suggest that if there is a particular faculty member who you would like to be your advisor, that you contact them and ask if they are willing (most will most definitely be willing). If that person agrees, please email Prof. Doeppner ( twd@brown.edu ) to let him know, as he makes the assignments. If you aren't sure who you would like to have as your advisor, feel free to leave that field blank in the ASK declaration and we will assign someone for you. Note that for the joint concentrations, if you would prefer an advisor in a particular department, you must request a particular person in that department. If they're not available, we'll assign someone else in that department. Related Topics Advanced Placement Earning Honors and Awards Staying a Fifth Year and Combined Masters International Students Internship (CPT) Application FAQ for Students ASK FAQ for Advisors", "https://cs.brown.edu/degrees/undergrad/concentrating-in-cs/concentration-requirements/": "Concentration Requirements (2018) Our requirements are built on a collection of pathways , each representing a well defined area within computer science. Concentrators interested in particular areas might choose the courses included in particular pathways. Conversely, concentrators who are unsure of their areas of interest but who have particularly enjoyed certain courses might choose pathways that include these courses. The total number of courses required for the two concentrations remains the same as they were with the old requirements. There are no changes to the calculus prereq or the intro courses. Intermediate courses are now grouped into three categories. The systems-oriented category remains unchanged, but we've expanded the math-oriented category into two: math and fundamentals. The former includes linear algebra, probability and statistics, and multi-variable calculus; the latter includes discrete math and theory of computation. AB students must take three courses from at least two of the categories; ScB students must take five courses from all three of the categories -- this requirement subsumes the math requirement of the old concentration requirements. Each pathway specifies a number of core courses, a collection of related courses, and up to three mandatory intermediate courses. Completing a pathway entails taking at least one core course, another core or related course, and the mandatory intermediate courses. AB students must complete one pathway; ScB students must complete two pathways. Additional 1000-level courses are required as needed to get to nine courses for the AB and fifteen courses for the ScB. The following links state the requirements for each concentration in detail: New ScB Concentration Requirements New AB Concentration Requirements Declaring Your Concentration In ASK See our separate page of instructions on how to declare the concentration .", "https://cs.brown.edu/degrees/undergrad/concentrating-in-cs/concentration-requirements-2020/capstone/": "Capstone Courses For The ScB The following courses may be used as capstone courses, but please check with the instructor since what you do for a capstone project in the course might be different from what you would do if you are not using the course as a capstone course. CSCI 1230 with CSCI 1234 CSCI 1260 CSCI 1290 CSCI 1300 CSCI 1320 CSCI 1370 (case-by-case basis; contact the instructor) CSCI 1380 CSCI 1410 CSCI 1420 CSCI 1430 CSCI 1440 CSCI 1470 CSCI 1600 CSCI 1660 with CSCI 1620 CSCI 1670 with CSCI 1690 CSCI 1680 CSCI 1710 (formerly CSCI 1950-Y) CSCI 1730 CSCI 1760 CSCI 1950-U CSCI 1951-A CSCI 1951-C CSCI 1951-I (may be used as part of any pathway) CSCI 1951-U CSCI 1952-B CSCI 1970 (if topic is in the general area of one of your pathways) CSCI 2240 CSCI 2370 (case-by-case basis; contact the instructor) CSCI 2390 CSCI 2420 CSCI 2500-B CSCI 2510 CSCI 2950-T CSCI 2950-V CSCI 2951-I CSCI 2952-K CSCI 2952-N Students pursuing an ScB in a joint degree program, such as Math/CS, may do a capstone project within the other department. Please contact elena_quinonez@brown.edu for details. Other courses might be acceptable as capstones; please contact the Director of Undergraduate Studies ( thomas_doeppner_jr@brown.edu ) for further information. Courses that do NOT provide capstone options: CSCI 1460 To register for your capstone course, complete the Google Form that you (seniors) received in email from Elena Quinonez ( elena_quinonez@brown.edu ). Students are also required to submit a title and abstract by the end of their last undergraduate semester to be posted on the CS website.", "https://cs.brown.edu/degrees/undergrad/concentrating-in-cs/concentration-requirements-2020/declaring-the-concentration/": "Declaring The Concentration Declarations are made through ASK. The following steps describe the process. There is an FAQ at the bottom of the page. (Advisors, your FAQ is here .) Understanding The Requirements Before you declare, look at the course requirements. Useful documents include: The official requirements in the Brown bulletin/Focal Point The requirements pages for CS (same info as the bulletin, but formatted differently) The CS Concentration Handbook , which lists allowable substitutions, courses from other departments that count towards a CS concentration and other policies for concentrators. Steps To Declaring Here is a video demo of how to declare in ASK . What follows is a textual summary. Log into ASK, go to the Declarations menu, select My Declarations and follow the instructions to create a declaration. Note that the Professional Track option (in the drop-downs at the top) is intended for international students who wish to do internships under CPT. The track offers no benefits to other students. Once you create the declaration, you need to indicate the courses that you will use to satisfy the concentration requirements (the \"Course Plan\"), and map those courses onto the requirements (the \"Program Plan\"). About halfway down the main page for your declared concentration, you will see two buttons, one labeled Course Plan and the other Program Plan, with \"(Edit)\" to the right. Click on \"Edit\". This will put you in a screen that looks like the following (partially-completed plan): In the left column, add courses that you want to apply to your concentration (you can also do this through the Course Plan button on the previous page ). Once a course appears in the left column, you can drag it into the boxes for specific concentration requirements in the right column. As you drag in courses, the icons within the requirements area will change to green circles or checkmarks (indicating that you have satisfied part of the requirement). Ultimately, you want to see green icons (checkmarks or circles) for each of the high-level requirements (you must fill in the intermediate courses in pathways, even though they appear checked by default) . You can find a summary of the icons on the previous (declaration overview) page to the right of the Course/Program Plan buttons. In the screenshot, the student has dragged CS15 into a requirement, but not CS32 (which explains the different colors in the left column) In the screenshot, the student has partly satisfied the introductory courses requirement in the right column (CS16 is missing). If the student dragged in CS16, the introductory courses would be marked with a green icon (the shape depends on whether the student has finished taking or plans to take the selected courses) Check that your declaration is complete. This means: Making sure you have populated each requirement area (so you have green icons on all of them). If you aren't sure which courses or pathways you want, put in something tentative for now. Making sure you have populated the intermediate course areas of the pathways . The pathways will have green icons even without this (since the intermediate courses are also listed elsewhere). You can drag the intermediate courses into the pathways even though they are already \"used\" in the intermediate course area. Once you believe your declaration is complete, submit it for approval (using the button at the bottom of the page). Shortly after submitting, the Director of Undergraduate Studies will match you up with a concentration advisor (you may, but do not need to, request a specific advisor on the form before submitting). Your assigned advisor will review your plan with you prior to approving it (during which you can discuss and refine tentative selections). Approval does not mean that you are now required to complete the listed courses . You may change the courses (and pathways) used in your declaration at any time until part way into your last semester. Approval means \"if you finished the listed courses, you would satisfy the concentration requirements\". Students change their minds and revise their declarations all the time. The point of approving something now is to make sure that you understand the concentration requirements and have a tentative plan that you have discussed with an advisor. FAQ About Declaring The answers to many of these pertain to declaring pure CS, as opposed to a joint concentrations. If you have questions that are not answered in this FAQ, contact Professor Fisler. Do I have to identify an advisor before declaring? You may identify your own advisor if you wish, or you can let us assign you an advisor. If you don't list a preferred advisor, we will match you up with someone appropriate (based on a combination of your interests and the existing advising loads of the faculty). Even if you list a preferred advisor, we may need to assign you to someone else based on how many advisees your requested advisor is able to take on at the time you declare. Professor X agreed to be my advisor, but they aren't listed Email Tom as soon as you declare, and we can set that up. If you have an email confirming that your advisor has agreed, forward it as part of your email to Tom. The intermediate courses in the pathways are checked off automatically. So do I need to fill those in? Yes. Intermediate courses appear checked off in pathways by default because these courses get formally checked in the intermediate courses section. But your advisor still needs to see the intermediate pathway courses in place in order to review your declaration. Can I drag a course into more than one requirement in the program plan? Yes, you will need to do this with those intermediate courses that are used to satisfy pathway requirements. I chose my intermediate courses based on the old requirements, but they don't satisfy my intended pathways under the new requirements. What should I do? Declare with pathways that fit your 1000-level courses. If you don't have intermediate courses that match the pathway requirements, drag in the most appropriate intermediate course that you can (if you have to use a systems course instead of a math course, or vice versa, that's fine). The substituted course will be flagged with a warning triangle within the program plan. Your advisor can resolve this warning when reviewing and approving your declaration. (This is the easiest way to handle most cases of students who land between the old and new requirements). I planned my courses around the old requirements, and I don't see how to fit them into the new requirements. What should I do? Students who were enrolled at Brown prior to January 2018 may still graduate under the old requirements. If you feel you need to graduate under the old requirements, populate your course plan, but not the program plan. Then contact Tom or Kathi, who will help move your declaration over to the old requirements. I've already taken 22, which doesn't seem to fit many pathways. What do I do now? You can use one extra intermediate course in place of a 1000-level CS course. There's a course in another dept that I want to use as a CS 1000-level course. What do I do? Check the concentration handbook to see whether we have already made a decision on that course. If the course isn't listed as either approved or rejected, email Tom or Kathi with a link to the syllabus so we can review it. I dragged a course into my program plan but the icon for that section didn't turn green. What happened? There are several possibilities: 1) Perhaps you put the course in the wrong box. 2) You are substituting a course for the one that is formally in the requirements (such as using Math 100 for the Calc Prerequisite). Your advisor will have to check these manually. 3) There are a couple of courses for which the name of the course is slightly different across the two databases used to populate ASK information. The green icons check both course number and title, so these courses don\u2019t appear satisfied. Your advisor will inspect these cases manually. I'm trying to submit my declaration, and am getting an error that my intermediate courses are not satisfied You have to drag your intermediate courses into two places: the general intermediate course requirements, and the intermediate requirements for the individual pathways. If you are getting this error, you probably only populated the intermediate courses in one place (or you missed a course when completing one of the two kinds of requirements). The intermediate courses in the pathways will get a green checkmark automatically, even if you don't populate them (this is an artifact of having to record them in two places). You still need to drag them in, despite the checkmark. Why do some areas say \u201c0-2 credits\u201d? Our requirements need to count intermediate courses in two places: the intermediate courses requirements, and the pathway requirements. The \u201c0-n\u201d configurations in the pathways are what let us record the same course two places, while only counting it once (in the intermediate courses section) towards your total credits. The same issue applies to the ScB capstone course. I removed an intermediate course from a pathway, and it disappeared from my overall set of intermediate courses as well. What happened? The ASK development team is aware of this problem. At the moment, this is how the system behaves, however. What is \"sifting mode\"? Can I edit my program plan in that mode? Sifting mode hides all requirement areas that are not being used in your current declaration. This helps hide all the pathways that you are NOT completing, for example. Unfortunately, (a) you can\u2019t change the sifting mode while you are in Program-Plan edit mode, and (b) if sifting mode is on, you can\u2019t add courses to requirements that you weren\u2019t already using (in other words, sift is fine for reading but interacts poorly with writing). The ASK development team acknowledges that there are issues here that they need to fix. I'm considering study abroad. How do I handle that in my declaration? AB students may transfer up to two study-abroad courses to the concentration; ScB students may transfer up to three. Actual transfers get approved by Tom (as Director of Undergraduate Studies). When you fill out your declaration, take your best guess at courses you will take at Brown or transfer from elsewhere (you can always update your courses as your study abroad plans take shape). You can add a comment to your declaration about your study-abroad interests. We strongly urge you to review planned course transfers with your advisor and/or the Director of Undergraduate Studies before you leave, so that there are no surprises when you seek concentration credit upon you return. I have a question that isn't covered here or in the concentration handbook... Email Tom or Kathi with your question.", "https://cs.brown.edu/degrees/undergrad/": "Our Undergraduate Program Our undergrads have flown to Singapore to install software they designed for the Nobel Museum , built an SMS-based commodity exchange to help Ghanaian farmers , and more . They know what it's like to hear a professor say, \"I feel like I can absolutely treat my undergraduate teaching assistant as a peer.\" This page is for prospective undergrads. Incoming and current students, go here or use the links in the blue bar above. Other schools are dealing with growing interest in CS by capping the number of students who can major in it. Instead of turning applicants away, we're putting in place new programs to help first-generation and low-income students. Watch a video of CS majors answering your questions\u200b, look at our majors , or apply . \"I\u2019m inspired by the creative and innovative thinking ...faculty mentorship across departments, the strong alum network who work at startups and tech giants alike, design resources at RISD, the Providence tech community, and student organizations like Hack@Brown and the Entrepreneurship Program are all catalysts for student entrepreneurs.\" \u2014 Athyuttam (Atty) Eleti \"I'm concentrating in Math-CS. It's one of several joint majors that allow students to pursue in-depth study in both CS and another area \u2014 as well as exploring how the subjects interact. Math-CS has given me a greater degree of flexibility in my course choices; it has allowed me to both focus on more theoretical aspects of computer science and to increase my level of mathematical maturity.\" \u2014 Eli Rosenthal \"Doing CS research has been one of the most rewarding aspects of my time at Brown . It's allowed me to make meaningful relationships with my professors and with grad students in the department, and has taught me how to work in a self-directed way on projects I get to define myself...professors are open to mentoring an undergrad, and doing research at Brown also opens up opportunities to work with other universities.\" \u2014 Dana\u00eb Metaxa-Kakavouli \"Being an undergraduate teaching assistant (UTA) has been an incredible opportunity for me to grow ...Through my involvement with the UTA program, I have gained incredible mentors (professors, head TAs) and wonderful friends (fellow TAs on several different course staffs). I think the program truly reflects the culture of collaborative learning at the heart of a Brown CS education.\" \u2014 Jaclyn Zhong Find out more: student groups ( Hack@Brown , Department Undergraduate Group , Women in Computer Science , Mosaic+ ), our majors (Applied Math-CS, Computational Biology, CS, CS-Economics, and Math-CS), undergrad resources (for concentrators and non-concentrators), undergrad research , the UTA program , and other undergrad jobs . We pioneered undergraduate participation in teaching and research before many universities even offered CS courses. Today, no other institution gives you the same opportunity to be part of their intellectual life, make multidisciplinary collaborations, and advance the field. \"I never want to stop being a Brown Computer Science TA.\" \u2014 Mike Frederickson, Technical Director, Pixar \"My advisor has been a constant anchor, a mentor, a friend...Late nights in the graphics lab allowed me to see how CS could connect with other disciplines and Brown\u2019s honors program allowed me to experiment with my first truly interdisciplinary research project.\" \u2014 danah boyd, Microsoft Principal Researcher and Data and Society Founder", "https://cs.brown.edu/degrees/undergrad/concentrating-in-cs/concentration-requirements/new-concentration-requirements-faq-advisors/": "Concentration Requirements FAQ For Advisors How does the new ASK tool affect existing declarations (done in the old requirements)? It doesn't. Declarations made prior to Jan 19, 2018 are under the old requirements and are not supported by the ASK-based contracts. ASK-based contracts are only available for declarations in the new requirements. How does a current concentrator (on the old requirements) make changes to their concentration? Students declared under the old requirements should be able to continue to use ASK (and paper contracts) as they did before. ASK internally tracks which requirements were in effect when a declaration was created. What am I looking for when I review a program plan? You are looking for the hierarchical boxes to have either green icons or open-red circles with warning triangles Green icons indicate that the requirement is satisfied by the selected courses (the shape differs depending on whether the course is completed, in progress, or intended). Open red circles with warning triangles indicate that selected courses need to be checked manually --- they are either not identical to the requirement as formally stated or the requirement allows one of many courses. Intermediate courses in pathways may have green icons and warning triangles. Usually, this would indicate that a student is substituting intermediate courses from the old requirements into the new pathway requirements (which is fine while we are in transition). Warning triangles do not propagate upwards through the hierarchy, so if you see a requirement that lacks a green icon, check whether there is a warning triangle on a course within that requirement. If there is no warning triangle, then the student has left some part of the requirement unpopulated. What are we doing for students whose intermediate courses were chosen for the old requirements, and don't satisfy the pathways? Have the student declare with the pathway that meets their 1000-level courses. They should drag some intermediate courses into the slots for the pathway (even if they don't match the required ones). As long as they satisfy the overall intermediate courses for the new requirements, we will accept the substitution. You can then approve the declaration to formally accept the substitution within ASK. Can I hide the pathway and other requirement options that aren't used in a declaration? Yes, this is called \u201csifting mode\u201d. You can turn it on from the main declaration page. Part of the requirements seem to be missing. For example, a student is doing a pathway but there is no area for intermediate courses. You probably have sifting mode turned on, and the student didn't populate the intermediate courses, so those areas aren't showing. Given that intermediate courses are checked in two parts of our requirements, but can only be counted once towards the course total, intermediate courses in pathways show checked by default to students. This will lead some students to overlook this part of the requirement when they first declare. How does an advisor approve a course to get rid of the warning triangle? When you approve the declaration, all courses with warning triangles will be marked as approved and the triangles will disappear. How do I override ASK when a student has a unique situation and permission to substitute a non-standard course? Have the student populate the requirement with the non-standard course and approve the declaration. Why do some areas say \u201c0-2 credits\u201d? Our requirements need to count intermediate courses in two places: the intermediate courses requirements, and the pathway requirements. The \u201c0-n\u201d configurations in the pathways are what let us record the same course two places, while only counting it once (in the intermediate courses section). The same issue applies to the ScB capstone course. What do the icons mean? Roughly: Open red circles mark requirements with missing components Open green circles mark courses in which the student is enrolled but hasn\u2019t completed Closed red circles with X inside mark courses for which the student did not get credit Closed red circles with dashes inside mark courses that the student has not taken or has dropped", "https://cs.brown.edu/degrees/undergrad/concentrating-in-cs/honors/": "Earning Honors Brown awards two kinds of honors. The university awards Magna cum laude based on grades. The Computer Science Department awards Honors in Computer Science. The CS Department's requirements for graduating with honors are as follows: Honors candidates must have earned A's or S-with-distinction in 2/3 of the courses used towards the concentration, excluding introductory-sequence courses (CS courses numbered below 0200) and the calculus prerequisite (unless that course is also used as an intermediate math course in CS requirements). Note that the grade requirement includes courses taken in the final year. Thus, for example, if a student's grades drop below this bar in the last year, that student will not graduate with honors. Candidates must have completed 2/3 of their concentration courses by the start of their last two semesters. Candidates must choose an advisor and submit a 2-to-3 page proposal, approved by the advisor (who must be a CS faculty member), to the director of undergraduate studies before the last day to register for classes (not the end of shopping period, but two weeks after that) in their next-to-last semesters. For May 2024 graduates, that deadline is Oct 3, 2023. The proposal should describe the research question that the student will be working on, how the project fits in either to existing results or larger projects (either within the same lab or the research community in general), and what the student hopes the research will achieve (could be anything from a new technique, a theorem, a prototype implementation of a new research idea, experimental evidence of something, etc -- your advisor will know what's appropriate for your area) No particular format is required for the proposal. It should list the preliminary project title, your name, and your advisor's name. Most come in as LaTeX or Google docs saved as PDF. A ~3-page progress report must be submitted to the director of undergraduate studies by the end of the first month of the final semester. Also at this time, the student must identify a reader, who should be either a CS faculty member or a faculty member in some other Brown department who has expertise that's relevant to the thesis topic. The progress report restates the research question (which may have changed or been refined -- that's fine, just explain why), describes what the student has accomplished to date, and revises the expected outcomes accordingly. No particular format is required. A final draft of the thesis must be submitted to the student's committee and the director of undergraduate studies by April 18 for students completing their degrees in May and by December 1 for those completing their degrees in December. Students must submit to a public defense of their theses to be attended by their committees and at least two other CS faculty members. Whether a student's thesis is deemed worthy of honors is decided by a combination of the advisor, reader, and faculty present at this defense. Honors candidates should register for CSCI 1970 for both semesters they are working on the thesis. In order to see 1970 on CAB, you have to enable the checkbox to include \"independent study and research courses\". You should then be able to find your advisor's section to request the registration override. Any deviation from these rules must be approved by the head of the CS honors program (one of the Directors of Undergraduate studies, in consultation with the student's advisor). Currently, Professor Kathi Fisler serves as head of the CS honors program. Direct any questions or requests for approval to her. Students in joint concentrations must select one of the two participating departments through which to complete the honors requirements. The honors project must be done following the rules of the selected department, with the primary advisor from that department and the reader from the other joint-concentration department. In these cases, the reader must be identified at the time the student submits the initial proposal (as per item 3 above). In the (rare) case that a student wishes to pursue CS honors working with a research advisor who is not in CS, the student must identify a nominal advisor in CS (who will be the advisor of record from the registrar's perspective). The nominal advisor would effectively serve as reader. All such cases must be approved by the head of the honors program for CS. By the end of shopping period each fall, we will email all seniors a link to a form to use to inform the department that you are pursuing honors that year. You should only be filling this out if you are in your 7th semester of study,", "https://cs.brown.edu/degrees/undergrad/concentrating-in-cs/professional.track/": "Professional Track Summer internships and research experiences are nearly essential parts of a CS education, particularly if one's goal is to become a professional computer scientist. They not only give one a chance to gain experience as a practicing computer scientist, but they also provide insights for subsequent courses and project work at Brown. CS interns and undergraduate researchers do work that engages them as computer scientists and have real responsibilities. They learn a lot about the practice of computer science and are better able to make career choices. Students without them are at a disadvantage with respect to their peers when they graduate. If you are an international student with an F-1 visa, you will need to apply for a CPT so that you may do a paid internship with a company in the US. To obtain a CPT, please visit this page and follow the instructions for professional-track students. While we do not give course credit for internships, we officially recognize their importance via the optional Professional Track. The requirements for the professional tracks include all those of the standard tracks, as well as the following: Students must complete full-time professional experiences doing work that is related to their concentration programs, totalling 2-6 months, whereby each internship must be at least one month in duration in cases where students choose to do more than one internship experience. Such work is normally done at a company, but may also be at a university under the supervision of a faculty member. On completion of each professional experience or internship, the student must write and upload to ASK a reflective essay about the experience addressing the following prompts, to be approved by the student's concentration advisor: Which courses were put to use in your summer's work? Which topics, in particular, were important? In retrospect, which courses should you have taken before embarking on your summer experience or internship? What are the topics from these courses that would have helped you over the summer if you had been more familiar with them? Are there topics you should have been familiar with in preparation for your summer experience or internship, but are not taught at Brown? What are these topics? What did you learn from the experience that probably could not have been picked up from course work? Is the sort of work you did over the summer something you would like to continue doing once you graduate? Explain. Would you recommend your summer experience to other Brown students? Explain.", "https://cs.brown.edu/degrees/undergrad/research/symposium/": "Undergraduate CS Research Symposium For more information, please check out the Meta Undergraduate Research Assistants' page !", "https://cs.brown.edu/degrees/why-brown/": "Why Study At Brown CS? This page is for all prospective students: international applicants, please see the additional section below . Our remarkable students conduct cutting-edge research and combine technical strength with a great diversity of backgrounds. Our graduates have an outstanding record of innovation and maintain strong ties with each other. Students work with world-class faculty through coursework, research projects, and theses, and contribute to instruction as teaching assistants. Brown provides excellent resources: pleasant office space, quality computing equipment, several specialized labs, and an attractive building close to restaurants and shops. We're conveniently located in Providence, less than an hour from Boston and three hours from New York. We've been compiling rave reviews of our city's walkability, cultural attractions, and quality of life. If you're coming for a visit, be sure to check out this helpful guide : the College Hill, Thayer Street, Wayland Square, and Downtown neighborhoods are all nearby. We have a long tradition of strong industry partnership. Leading organizations actively recruit our graduates, and many of them are members of our Industry Partners Program . Our interdisciplinary options enrich the educational experience, exposing students to novel and fascinating problems. We pride ourselves on being a friendly and welcoming place to a diverse population of students. Brown CS fields teams in several intramural sports and often organizes picnics, games, bike rides, and other activities. International Applicants Our international ambassadors are students from other countries who would love to talk to you about their Brown CS experience. Click the map below, then move your cursor to find an ambassador from your country. Recent Brown CS Graduates Worldwide Our graduates rank high as industry pioneers and in academia as well. Recent graduates have joined the faculty at the following institutions around the world: Amherst College Brandeis University Brigham Young University Buena Vista University Carleton College Carnegie Mellon University Davidson College DePaul University ETH Zurich Florida Atlantic University Florida International University George Mason University Iowa State University Johns Hopkins University Koc University (Turkey) Le Moyne College Longwood University Louisiana State University Mississippi State University Nanyang Technological University (Singapore) Northwestern University Oakland University Ohio State University Oregon State University Pomona College Purdue University Sapienza University of Rome State University of New York at Albany University of Central Florida University of Houston University of Illinois at Chicago University of Maryland, College Park University of Massachusetts, Amherst University of Massachusetts, Lowell University of Minnesota University of Oxford University of San Francisco University of South Mississippi University of Texas, Austin Virginia Tech Williams College English-Language Courses We know that many of you may not have had the opportunity to fully develop your English language skills. If you're interested in improving them, click here for English-language courses that Brown has designed with you in mind.", "https://cs.brown.edu/events/immersionatbrown/": "Visualization and Creativity in Immersive 3D Environments -- from Cave to YURT May 20 and 21, 2015 sponsored by the Office of Brown University's 250th Anniversary, the Brown University Center for Computing and Visualization, Brown University Computing and Information Services, and the Brown University Sciences Library; the YURT has been developed with funding from NSF We are celebrating the opening of Brown's newest virtual reality environment, the YURT (YURT Ultimate Reality Theatre), in the context of the many decades of visual study that presaged it. This immersive environment fully engages our visual senses for exploration and discovery in areas as diverse as planetary geology, mathematics, visual art, digital literature, and biology. With head and body-tracking, users control a virtual world shown on a room-sized, 100 million-pixel stereo display that completely surrounds them. You have to experience this unique instrument to truly understand and appreciate it. Join us to learn about the future of virtual reality from some of the field's greatest innovators and to experience the reality for yourself. Please do two things immediately in order to attend: E-mail Jesse Polhemus to register. Please note that earlier registrants will be given preference for some events, including demonstrations. Book a hotel room if necessary: Hotel Providence (401-861-8000), the Biltmore (401-421-0700), the Wyndham Garden (401-272-5577), or the Marriott (401-272-2400). Schedule 20 WEDNESDAY morning 9am-1pm Attendees are invited to sign up for presentations in both new YURT and the legacy Cave on Wednesday morning, and subsequently on a drop-in basis throughout Thursday. YURT: 180 George St (at Brook), Cave: Granoff Center, Studio 4, N330. 30 minute guided presentations at either site may be booked here . 20 WEDNESDAY afternoon -- all talks are in Granoff's Martino Auditorium 1:30-2 pm Welcoming remarks and introduction 2-3:15 Henry Fuchs: Keynote (\"The Immersion Renaissance: Head-Worn Displays, Projectors, and the YURT\") 3:15-4pm Coffee, Tea, snacks available Granoff Center, Foyer 4-5:15pm Fritz Drury \u2018VR Design for Science\u2019 John Cayley \u2018Teaching Literary Arts in an Immersive Audiovisual Environment\u2019 5:30-6:30pm Reception and YURT Inauguration with Provost Vicki Colvin Please note the venue : Brown CIT Building, 3rd Floor Thomas J. Watson Sr. Center for Information Technology 7:30 pm Symposium dinner for SELECTED participants Venue: The Hope Club 21 THURSDAY -- all talks are in Granoff's Martino Auditorium 9:30am & throughout the day: Coffee, Tea, Pastries/Snacks Granoff Center, Foyer 10-11:15am Steven Feiner \u2018VR, AR, and the Future of User Interfaces\u2019 Tom Banchoff 11:30-12:45pm Jim Head \u2018Planetary Immersive VIrtual Reality: Transporting Astronauts and Researchers to Planetary Surfaces and Learning to Work\u2019 Dan Keefe: \u2018Magical User Interfaces: Bringing Interactivity to Immersive Science and Art\u2019 1-1:45pm Pick-up lunch boxes in Granoff center or on your own locally 2:45-4pm Joe LaViola \u20183D Spatial User Interfaces: Past, Present, and Future from the Virtual to the Real\u2019 Roderick Coover \u2018Hearts and Minds: The Interrogations Project\u2019 4-4:30pm Coffee & Tea 4:30-5:45pm Noah Wardrip-Fruin \u2018The Power of Presence with Virtual Art\u2019 Opportuntity for general discussion. 6-6:30pm Symposium closing FAQ Where can I find parking? How do I find help for my special accessibility needs? Parking may be limited, so we recommend carpooling or alternative methods of transportation if possible. You can find more information about parking and accessibility here . I'm interested in checking out the Yurt myself. Could you please help? We'd be happy to! Please e-mail Tom Sgouros .", "https://cs.brown.edu/events/dls/": "Distinguished Lecture Series Launched in 2008, this series features prominent computer scientists from academia and industry addressing topics of broad interest. Distinguished Lectures enrich Brown's academic environment by contributing to the education of our students, motivating our undergraduates to get involved in research, and bringing together students, faculty, alums, and industry partners for lively interaction and discussion. Upcoming Distinguished Lectures Our next distinguished lecture will appear here when ready. Previous Distinguished Lectures Click the title of a Distinguished Lecture to learn more about it, including (in some cases) recordings and other items. Date Topic Speaker 11/17/2019 Collaboration as a Lens for Inclusive Technical Innovation Meredith Ringel Morris (Microsoft Research) 04/18/2019 Building Machines That Learn And Think Like People Josh Tenenbaum (MIT) 10/03/2018 AI and Security: Lessons, Challenges and Future Directions Dawn Song (UC Berkeley) 09/26/2018 Hitting the Nail on the Head: Interdisciplinary Research in Computer Networking Jennifer Rexford (Princeton University) 02/08/2018 Rethinking Ubiquitous Computing to Transform Healthcare Elizabeth Mynatt (Georgia Tech) 11/30/2017 Case Studies from the Real World: The Importance of Measurement and Analysis in Building Better Systems Bianca Schroeder (University of Toronto) 10/15/2015 Personalized Search: Potential and Pitfalls Susan Dumais (Microsoft) 10/06/2015 Accelerating the Discovery of Insights from Data Laura Haas (IBM) 03/05/2015 Customizing Robots Daniela Rus (MIT) 02/12/2015 Games, Learning, and the Price of Anarchy Eva Tardos (Cornell) 12/08/2014 A Surprising Application of Differential Privacy Cynthia Dwork (Microsoft) 11/06/2014 The Power of Abstraction Barbara Liskov (MIT) 05/01/2014 Towards Theoretical Models of Natural Inputs: Aiming to Bridge the Theory/AI Divide Avrim Blum (Carnegie Mellon) 03/13/2014 Small, n=me, data Deborah Estrin (Cornell) 02/20/2014 Never-Ending Machine Learning Tom M Mitchell (Carnegie Mellon) 02/06/2014 Trustworthy Hardened Code Greg Morrisett (Harvard) 04/18/2013 Reflections on Image-Based Modeling and Rendering Richard Szeliski (Microsoft) 04/11/2013 Language Translation as Codebreaking Kevin Knight (USC) 02/21/2013 A Software Crisis? Please, sir, may I have some more? Abstract David Notkin (University of Washington) 05/05/2011 CALM Consistency: Disorderly Programming in Bloom Joseph Hellerstein (Berkeley) 11/10/2011 Provenance Everywhere Margo Seltzer (Harvard) 10/01/2011 Statistics and Computation in the Age of Massive Data Michael Jordan (Berkeley) 09/08/2011 Algorithms, Graph Theory, and the Solution of Laplacian Linear Equations Daniel Spielman (Yale) 11/18/2010 Meaning Propagation Fernando Pereira (Google) 11/04/2010 Computational Cameras: Redfining the Image Shree Nayar (Columbia) 09/23/2010 Strong LP Formulations and Primal-Dual Approximation Algorithms David Shmoys (Cornell) 04/22/2010 Theory and Applications of an Algorithm for Playing Repeated Games Rob Schapire (Princeton) 04/19/2010 Computational Thinking Jeannette Wing (NSF) 04/08/2010 Interdisciplinarity in the Age of Networks Jennifer Tour Chayes (Microsoft) 03/11/2010 An Evolution of General Purpose Processing: Reconfigurable Logic Computing Joel Emer (Intel) 03/04/2010 Information Integration: From Clio to Integration Independence Renee Miller (University of Toronto) 10/29/2009 Efficiently Learning to Behave Efficiently Michael Littman (Rutgers University) 10/20/2009 Randomized Shellsort: A Simple Oblivious Sorting Michael Goodrich (University of California at Irvine) 04/29/2009 Cyberspace- Taming the Wild West John Savage (Brown) 04/29/2009 Probabilistic Models for Complex Systems: From Cells to Bodies Daphne Koller (Stanford) 02/26/2009 Approximation Algorithms Michel Goemans (MIT) 10/16/2008 Simplicity is Complex John Maeda (President of RISD) 09/25/2008 Simple Techniques for Eliminating Fatal Errors in Software Systems Martin Rinard (MIT)", "https://cs.brown.edu/events/": "Events Browse Events Lecture Series Distinguished Lecture Series Kanellakis Memorial Lectures Life After Brown Lectures Special Events Computer Science Reunion Events Schedule For The Next Three Months: Tuesday, March 12 12:00PM, 368, Watson Center for Information Technology (CIT) Rachit Nigam: Modular Abstractions for Hardware Design Wednesday, March 13 12:00PM, 368, Watson Center for Information Technology (CIT) Konstantinos Kallas: Programmable Software Systems for Correct High-performance Applications Wednesday, March 13 4:00PM, Rm 302, 164 Angell Street Computational Infrastructures for Consolidating our Knowledge Regarding the Human Genome Thursday, March 14 12:00PM, 368, Watson Center for Information Technology (CIT) Zachary Ferguson: Democratizing Simulation as a Framework for Seamless Analysis and Computational Design Friday, March 15 12:00PM, 368, Watson Center for Information Technology (CIT) Silvia Sell\u00e1n: Stochastic Computer Graphics Wednesday, March 20 12:00PM, 368, Watson Center for Information Technology (CIT) Reto Achermann: The Foundation of Performance-aware Resilient Operating Systems Wednesday, April 3 12:00PM, 368, Watson Center for Information Technology (CIT) Jacob Schreiber: Dissecting the Cell Type-Specific Regulatory Role of Each Nucleotide in the Human Genome Friday, April 26 12:00PM - 12:50PM, 477, Watson Center for Information Technology (CIT) Aldo Pacchiano: BigAI Talk: Experiment Planning with Function Approximation", "https://cs.brown.edu/events/kanellakis/": "The Paris C. Kanellakis Memorial Lecture Series This lecture series honors Paris Kanellakis, a distinguished computer scientist who was an esteemed and beloved member of Brown CS. Paris joined us in 1981 and became a full professor in 1990. His research area was theoretical computer science, with an emphasis on the principles of database systems, logic in computer science, the principles of distributed computing, and combinatorial optimization. Upcoming Lecture We'll include information about the 2024 lecture here as soon as it's available. Previous Lectures To watch the recording of a lecture or read its abstract, click its title. Date Topic Speaker 2023 Monitoring Health and Diseases Using Radio Signals and Machine Learning Dina Katabi (MIT) 2022 Balls, Bins and Server Farms Eli Upfal (Brown CS) 2020 Back to basics \u2013 the future of Search Sridhar Ramaswamy (Neeva, Greylock Partners) 2019 Learning from Censored and Dependent Data Constantinos Daskalakis (MIT) 2018 Algorithms: Theory meets Practice Robert E. Tarjan (Princeton) 2017 Below P vs. NP: Conditional Quadratic-Time Hardness for Big Data Problems Piotr Indyk (MIT) 2016 Professor Donald Knuth Days At Brown: A Celebration Of Computer Science Donald Knuth (Stanford) 2015 The Cryptographic Lens Shafi Goldwasser (MIT) 2014 Laplacian Matrices of Graphs: Algorithms and Applications Daniel Spielman (Yale) 2013 Bursts, Cascades, and Hot Spots: A Glimpse of Some On-Line Social Phenomena at Global Scales Jon Kleinberg (Cornell) 2012 Differential Privacy: Thwarting Big Data's Evil Twin Cynthia Dwork (Microsoft) 2011 Quantum Computing: A Great Science in the Making Andrew Yao (Tsinghua University) 2010 From Philosophical to Industrial Logics Moshe Vardi (Rice University) 2009 Safety on the Wild and Wooly World-Wide Web: Sandboxing Untrusted JavaScript John C. Mitchell (Stanford) 2008 A Survey of Some Recent Research at the Border of Game Theory and Theoretical Computer Science Anna Karlin (University of Washington) 2007 A hardware-design inspired methodology for parallel programming Arvind (MIT) 2006 Whole Genome Sequencing and Imaging-Based Systems Biology Eugene Myers (Howard Hughes Medical Institute) 2005 Geiometric Optics, Linear Programming and Congestion in Sensornets Richard Karp (UC Berkeley) 2004 Hyper-Encryption via Virtual Satellite Michael Rabin (Harvard) 2003 Reconfigurable Atomic Memory for Dynamic Networks Nancy Lynch (MIT- delivered by Alex Shvartsman) 2002 Algorithmic Problems in the Internet Christos Papadimitriou (UC Berkeley) 2001 Progress in System Modeling and Testing Mihalis Yannakakis (Avaya Laboratories)", "https://cs.brown.edu/events/lifeafterbrown/": "Life After Brown Lecture Series This series features successful alums sharing their perspective on the challenges and opportunities that await Brown CS graduates in the hope that current students can benefit from their experience. Lectures are aimed primarily at undergraduates, but all are welcome to attend. Upcoming Lectures Michael Greenberg (Pomona College), 4 PM on April 25 in CIT 368 Previous Lectures Click a lecture's title to go its web page. When a recording of a lecture or other items related to it are available, links are shown below the title. Click them to learn more. Date Topic Speaker 11/06/2018 Navigating a Career in HCI Research video recording Meredith Ringel Morris (Microsoft Research) 03/06/2016 Hidden in Plain Sight: Changing the Face of the U.S. STEM Workforce video recording Mary Fernandez (MentorNet) 11/05/2015 Life After Brown Adam Leventhal (Delphix)", "https://cs.brown.edu/gcs.html?q=%22carsten%20eickhoff%22": "Search Results (function() { var cx = '011922266607150406049:pdto5qfi1q8'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://cs.brown.edu/gcs.html?q=%22amy%20greenwald%22": "Search Results (function() { var cx = '011922266607150406049:pdto5qfi1q8'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://cs.brown.edu/gcs.html?q=%22eliot%20horowitz%22": "Search Results (function() { var cx = '011922266607150406049:pdto5qfi1q8'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://cs.brown.edu/gcs.html?q=%22chris%20mascioli%22": "Search Results (function() { var cx = '011922266607150406049:pdto5qfi1q8'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://cs.brown.edu/gcs.html?q=%22james%20tompkin%22": "Search Results (function() { var cx = '011922266607150406049:pdto5qfi1q8'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://cs.brown.edu/gcs.html?q=%22seny%20kamara%22": "Search Results (function() { var cx = '011922266607150406049:pdto5qfi1q8'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://cs.brown.edu/gcs.html?q=%22sorin%20istrail%22": "Search Results (function() { var cx = '011922266607150406049:pdto5qfi1q8'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://cs.brown.edu/gcs.html?q=%22tarik%20moataz%22": "Search Results (function() { var cx = '011922266607150406049:pdto5qfi1q8'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://cs.brown.edu/gcs.html?q=%22theophilus%20benson%22": "Search Results (function() { var cx = '011922266607150406049:pdto5qfi1q8'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://cs.brown.edu/gcs.html?q=%22suresh%20venkatasubramanian%22": "Search Results (function() { var cx = '011922266607150406049:pdto5qfi1q8'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://cs.brown.edu/gcs.html?q=%22ugur%20cetintemel%22": "Search Results (function() { var cx = '011922266607150406049:pdto5qfi1q8'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://cs.brown.edu/gcs.html?q=%2522sorin%2520istrail%2522": "Search Results (function() { var cx = '011922266607150406049:pdto5qfi1q8'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://cs.brown.edu/gcs.html?q=Guillaume%20Marceau": "Search Results (function() { var cx = '011922266607150406049:pdto5qfi1q8'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://cs.brown.edu/gcs.html?q=Shriram%20Krishnamurthi": "Search Results (function() { var cx = '011922266607150406049:pdto5qfi1q8'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://cs.brown.edu/gcs.html?q=hal%20triedman": "Search Results (function() { var cx = '011922266607150406049:pdto5qfi1q8'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://cs.brown.edu/gcs.html?q=iris%20bahar": "Search Results (function() { var cx = '011922266607150406049:pdto5qfi1q8'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://cs.brown.edu/gcs.html?q=kathi%20fisler": "Search Results (function() { var cx = '011922266607150406049:pdto5qfi1q8'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();", "https://cs.brown.edu/giving/uta/": "The Undergraduate Teaching Assistant (UTA) Endowment Andy van Dam has described Undergraduate Teaching Assistants (UTAs) as a collaborative troupe spanning generations, making the future happen. Please donate today so they can continue their vital work. Fifty years ago, Brown CS pioneered the idea of computer science UTAs, and if you work in our field, you\u2019ve either met one or you were one. Serving as a UTA is an opportunity like nothing else at a critical time in a student's life, providing them with a higher level of knowledge, self-development, and often with much-needed financial support. \"When we look at our peers at Brown and see where they are today\u2026we see Brown's undergraduate TA program at work\u2026We believe it is an irreplaceable component to the department's educational leadership and success.\" \u2014 Philip Levis (Professor of Computer Science and Electrical Engineering, Stanford University, and former UTA) Due to growing enrollments over several decades, the UTA program has become far more expensive than it once was. In 2018, Brown CS completed a successful crowdfunded campaign that established a ten-million-dollar endowment to fund our UTAs . Five years later, it\u2019s clear that much more is needed: One in five Brown undergraduates is a CS or joint CS concentrator. We employ more than 325 UTAs each semester. Over 60% of CS concentrators have been a UTA at least once. The administration is making major investments in the expansion of CS and our flagship UTA program. Your gifts will bolster and accelerate our growth. That\u2019s why we\u2019re creating a two-million-dollar extension to the UTA endowment, and we need your help. Today, you can help Brown CS give the same opportunity that you may have benefited from to someone who wouldn't otherwise have it. Gifts of $50,000 or more provide naming opportunities to support hiring undergraduate teaching assistants. You can also make a smaller gift to a pooled endowment. \"TAing is about making a course that changed your life just as amazing for the next generation of students. It's about showing a student close to tears how to solve a challenging problem by giving them tools, and changing that student's experience from feeling frustrated and lost to feeling inspired and happy and powerful because of CS.\" \u2014 Alexandra Schultz (Assistant Professor of Classics, Dartmouth, Fulbright scholar, and former UTA) Click here to donate or email Nicole Peters Sisson (Senior Director of Development, Academic Initiatives) with any questions. Thank you!", "https://cs.brown.edu/news/2001/11/21/Kanellakis/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Kanellakis Lecture Series Inaugurated Posted by Amy Tarbox on Nov. 21, 2001 On 29 November 2001, at 4:00 p.m., the CS Department will hostthe firstannual Paris Kanellakis lecture: Dr. Mihalis Yannakakis, of Avaya Laboratories,will speak on ``Progress in System Modeling and Testing.''This lecture series honors Paris Kanellakis, a distinguished computer sciencetheoretician who was an esteemed and beloved member of this department.His death in a December, 1995 airplane accident was a profound loss of whichwe are especially reminded at this time of year.We are therefore all the more delighted now to inaugurate this lecture series in his memory.", "https://cs.brown.edu/news/2002/09/27/Kanellakis/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Kanellakis Lecture Series Inaugurated Posted by Amy Tarbox on Nov. 21, 2001 On 29 November 2001, at 4:00 p.m., the CS Department will hostthe firstannual Paris Kanellakis lecture: Dr. Mihalis Yannakakis, of Avaya Laboratories,will speak on ``Progress in System Modeling and Testing.''This lecture series honors Paris Kanellakis, a distinguished computer sciencetheoretician who was an esteemed and beloved member of this department.His death in a December, 1995 airplane accident was a profound loss of whichwe are especially reminded at this time of year.We are therefore all the more delighted now to inaugurate this lecture series in his memory.", "https://cs.brown.edu/news/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Brown CS PhD Candidate Ji Won Chung Implements A Sleep Regularity Index In A Popular Sleep Tracker Posted by Robayet Hossain on March 7, 2024 Ji Won Chung , a third-year PhD student advised by Jeff Huang , Brown CS faculty member and researcher in human-computer interaction, has been collaborating with the developers of Sleep as Android, a popular sleep tracking app that supports vibration on alarms, anti-snoring measures, and lucid dreaming cues. Ji Won\u2019s research focused on writing code to implement a scientifically-evaluated sleep regularity index (SRI), which is now being incorporated into the app itself, and is expected to impact the sleep patterns of millions of people worldwide. read more \u00bb Nora Ayanian Will Present Swarming Drones At SXSW 2024 Posted by Jesse Polhemus on March 5, 2024 Brown Engineering and Computer Science Associate Professor Nora Ayanian will present at the 2024 SXSW Conference, held March 8-12. SXSW provides an opportunity for the global community of digital creatives to encounter cutting-edge ideas, discover new interests, and network with other professionals who share a similar appetite for forward-focused experiences, and the 2050 track where Ayanian\u2019s presentation falls showcases long-range, big-picture thinking, with topics that range from nanotech breakthroughs and interplanetary expeditions to life-extension research and novel applications of scientific discoveries. read more \u00bb Brown CS PhD Student Eric Ewing Helps Multi-Robot Research Lift Off At Brown And Beyond Posted by Jesse Polhemus on Feb. 29, 2024 in Socially Responsible Computing Advancing a commitment to accessible robotics education, the Brown CS PhD student is researching how to simultaneously control multiple drones and teaching others how to build and operate them. read more \u00bb Four Brown CS Students Receive CRA Outstanding Undergraduate Researcher Honors Posted by Jesse Polhemus on Feb. 7, 2024 in Awards Every year, the Computing Research Assiciation (CRA) recognizes North American students who show phenomenal research potential with their Outstanding Undergraduate Researcher Award, and for 2023-2024, four Brown CS students received honors: Megan Frisella (Finalist) and Anh Truong, Qiuhong Anna Wei, and Carolyn Zech (Honorable Mention). read more \u00bb Maurice Herlihy Gives A Keynote At The International Symposium On Stabilization, Safety, And Security Of Distributed Systems And A Seminar Talk At Stevens Institute Posted by Robayet Hossain on Feb. 6, 2024 On October 4, Maurice Herlihy of Brown CS gave a keynote address at the 25th International Symposium on Stabilization, Safety, and Security of Distributed Systems, focusing on how it is necessary to rethink classical correctness conditions for distributed systems when dealing with cross-blockchain transactions. read more \u00bb Michael Littman\u2019s New Series Of Educational Videos Explores Weird, Wondrous CS Posted by Jesse Polhemus on Feb. 5, 2024 Newcomers to the field of computer science who see it as more than just a ticket to a job at a big tech company have found a kindred spirit in Brown CS faculty member Michael Littman , who has just released Weird Computer Science, a new series of educational videos . read more \u00bb A Guided Tour Of The Brown CS Digital Archive Posted by Jesse Polhemus on Jan. 24, 2024 The latest cover story from Conduit , the Brown CS annual magazine, is an intimate look at a treasure trove of our department's history. Now in its fifth year, the Brown CS Digital Archive (BCSDA) is a crowdsourced effort to curate items that have contributed to Brown CS history and preserve them permanently online, where they\u2019ll be accessible to all. The vast majority of the BCSDA\u2019s more than 400 artifacts (photos, graphics, audio, video, and even code) have been submitted by alum Paul Anagnostopoulos. In the pages below, Paul takes us behind the scenes, telling the story of developing the \u2026 read more \u00bb Brown CS Student Mattie Ji Is A Runner-Up For The Schafer Prize For Excellence In Mathematics By An Undergraduate Woman Posted by Jesse Polhemus on Jan. 19, 2024 in Awards , Diversity Almost twenty-five years ago, the Association for Women in Mathematics established the Alice T. Schafer Mathematics Prize, to be awarded to an undergraduate woman for excellence in mathematics. This year, Brown CS student Mattie Ji, a senior majoring in Mathematics, Applied Mathematics, and Computer Science, was the prize's runner-up. read more \u00bb Yong Zheng-Xin, Cristina Menghini, And Stephen Bach Earn A Socially Responsible Language Modelling Research (SoLaR) Best Paper Award Posted by Jesse Polhemus on Jan. 17, 2024 in Socially Responsible Computing , Awards At the recent conference, work (\"Low-Resource Languages Jailbreak GPT-4\") from Brown CS PhD student Yong Zheng-Xin, postdoctoral researcher Cristina Menghini of Brown\u2019s Data Science Institute, and Brown CS faculty member Stephen Bach was selected from 121 submissions to receive the workshop's Best Paper Award. read more \u00bb Vasileios Kemerlis Receives The 2023 ACM CCS Top Reviewer Award Posted by Robayet Hossain on Jan. 14, 2024 in Awards Late last year, Brown CS faculty member Vasileios (Vasilis) Kemerlis won the Top Reviewer Award for his work as a program committee member for the 2023 ACM Conference on Computer and Communications Security (CSS) , the 30th anniversary of the conference, which was held in Copenhagen, Denmark. This award is given annually to the most influential reviewers for work and service provided at CCS, which is ACM\u2019s flagship conference on computer security. read more \u00bb Page 1 of 85 next \u00bb", "https://cs.brown.edu/news/2005/03/16/Wriston/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Shriram Krishnamurthi awarded Wriston Fellowship Posted by Amy Tarbox on March 16, 2005 We\u2019re delighted to report that Shriram Krishnamurthi has been awarded a Henry Merritt Wriston Fellowship for the next academic year. Brown University gives this award to recognize (quoting from the award letter) \u201cthe distinguished contributions that our faculty make to undergraduate education\u201d. Receipt of the award entitles the faculty member to one semester\u2019s relief from teaching duties; it is the award committee\u2019s hope that \u201cby rewarding your commitment to teaching thus far with a Wriston Fellowship, we will be supporting research that will continue to enrich your teaching in the future\u201d. Shriram\u2019s application for this fellowship cited such successes as his last year\u2019s CS 190, described in his lively conduit! article ( http://www.cs.brown.edu/publications/conduit/conduit_v13n1.pdf ). Featuring the design and implementation of a routing system for Brown\u2019s SafeRIDE shuttle-bus fleet, the course was designed to stress such real-world skills as dealing with incomplete and ambiguous requirements that change over time, using prototype systems to get a better understanding of the requirements, and dealing with administrative structures whose purpose and thrust are at best orthogonal to the goals of a software project. The application also described his extensive research collaborations with undergraduates, which lead to publication at prestigious research conferences, and his TeachScheme! Outreach program that trains high-school teachers in new ways of thinking about computer science. Shriram plans to use his Wriston Fellowship to design a new course, provisionally called &quot;Computer Science for Social Scientists&quot;, and write his second textbook, &quot;Programming Languages: Application and Interpretation&quot;.", "https://cs.brown.edu/news/2004/05/04/PECASE/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Amy Greenwald Receives PECASE Award Posted by Amy Tarbox on May 4, 2004 Professor Amy Greenwald of this department has just received a prestigious PECASE (Presidential Early Career Award for Scientists and Engineers) from the National Science Foundation.John H. Marburger III, Science Advisor to the President and Director of the Office of Science and Technology Policy, presented the awards today at a White House ceremony in the Eisenhower Executive Office Building to 20 National Science Foundation (NSF) supported researchers and 37 other scientists and engineers representing programs sponsored by eight other federal departments and agencies. Amy was recognized for her research on how automated software agents can make decisions in uncertain environments such as online auctions. She recruits many young women into computer science and effectively advises graduates and undergraduates. She also serves an advisor to a summer outreach program for ninth-grade students who gain hands-on computer experience. NSF's nominees for these presidential awards are drawn from junior faculty members who have received grants from NSF's Faculty Early Career Development (CAREER) program, considered the agency's most important and prestigious awards for new faculty members who show promise as leaders in science and engineering. These scientists have also translated their work into significant education activities. Nearly 400 young faculty members are chosen each year for the CAREER awards, which range from $300,000 to more than $750,000 over five years. The awards support the work and foster growth opportunities of those most likely to become academic leaders. The NSF-supported PECASE recipients represent a little over 5 percent of all CAREER awards made in 2002. Of the 2,900 CAREER awards made since the program began in 1996, only 140 have received presidential recognition. PECASE honorees receive no additional NSF funds beyond their initial CAREER grants, but the presidential recognition carries significant prestige as recipients represent the best among young researchers and educators from the CAREER program.", "https://cs.brown.edu/news/2007/04/13/Fellowship/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) PhD student Glencora Borradaile awarded NSERC Postdoctoral Fellowship Posted by Amy Tarbox on April 13, 2007 Ph.D. student Glencora Borradaile has been awarded a National Sciences and Engineering Research Council (NSERC) Postdoctoral Fellowship. (NSERC is the Canadian equivalent of NSF.) The fellowship is tenurable at any Canadian institution for two years. Glencora's thesis research concerns designing theoretically efficient algorithms for optimization problems in planar graphs. She has worked with Philip Klein in giving a simple algorithm for finding the maximum st-flow in a directed planar graph. She has given invited talks on this result at The University of Waterloo, NYU, IBM Watson, CMU and Dartmouth. In collaboration with Philip Klein and Claire Mathieu, she has been working on designing polynomial-time approximation schemes for the Steiner tree problem in planar graphs. Both results appeared at the Symposium for Discrete Algorithms (SODA) in 2006 and 2007, respectively. Glencora will complete her Ph.D. in late 2007. For more information about this award, please see http://www.nserc.gc.ca/sf_e.asp?nav=sfnav&amp ;lbi=3a", "https://cs.brown.edu/news/2010/10/18/BenEli/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Ben Raphael and Eli Upfal Receive NSF Grant to Develop Techniques for Analysis of DNA Sequence Variants Posted by Amy Tarbox on Oct. 18, 2010 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . The National Science Foundation (NSF) awarded a research grant , in the expected amount of $500,000, to Ben Raphael and Eli Upfal to develop robust algorithmic and statistical techniques for the analysis of DNA sequence variants in the context of known and novel gene-gene interactions. These techniques will allow biomedical researchers to identify DNA variants associated with risk for various diseases, including cancer. Algorithms developed in this project will be implemented and released as open-source software for use by the biological and medical community. The project will also support the training of graduate students and undergraduate researchers.", "https://cs.brown.edu/news/2010/10/18/RT/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) BU, Brown and UC Irvine receive $3 million NSF grant Posted by Amy Tarbox on Oct. 18, 2010 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . Computer scientists from Boston University, Brown University and the University of California, Irvine, will collaborate on a grant from the National Science Foundation (NSF) in the anticipated amount of $3 million to investigate &quot;trustworthy interaction in the cloud.&quot; The cloud refers to Internet-based outsourced computation (popularly know as cloud computing), whereby shared resources, software, and information are provided to computers and other devices on demand. As one of the most promising emerging concepts in information technology, outsourced computation is transforming how IT is consumed and managed, yielding improved cost efficiencies and delivering flexible, on-demand scalability. However, despite the relatively fast growth and increased adoption of clouds, aspects related to their security, privacy, and economic value proposition remain largely unanswered and are regarded by some technology experts as impediments to broader acceptance of this approach to computing. &quot;Developing the right mechanisms for the specification and verification of trust-enhancing service-level agreements in the cloud will avert conflicts among cloud market stakeholders,&quot; says Azer Bestavros, lead principal investigator and professor of computer science at Boston University. &quot;Doing so will also improve the utility and hardness of our cyber-infrastructure, with significant benefit to our economy and society.&quot; &quot;As more and more data is being stored in the cloud, keeping that data private is becoming critical, especially for applications in finance and medicine,&quot; says Michael Goodrich, principal investigator and Chancellor's Professor at the University of California, Irvine. The project supported by the NSF grant will address these concerns by examining the feasibility of extending cloud service-level agreements to cover aspects such as integrity of outsourced services, information leakage control, and fair market pricing. The project also will explore mechanisms that verify trust-enhancing service-level agreements are being followed and develop &quot;trustworthiness&quot; guarantees and tradeoffs to cloud customers and system integrators that are both practical and useable. &quot;We envision a new generation of trusted cloud computing services where users will be able to verify the integrity of their data stored in the cloud and the correctness of computations performed in the cloud,&quot; says principal investigator Roberto Tamassia. Tamassia is chair and Plastech Professor of Computer Science at Brown University. The project's co-principal investigators include Leo Reyzin, associate professor, Jonathan Appavoo, assistant professor, and Nikos Triandopoulos, research assistant professor, at BU and Anna Lysyanskaya, associate professor, and Rodrigo Fonseca, assistant professor, at Brown. In exploring these cloud computing-related issues, the team will collaborate with researchers at leading IT industrial labs at IBM, Microsoft, NetApp, RSA (the security division of EMC) and VMware. The project also will involve BU's Center for Reliable Information Systems and Cyber Security (RISCS) and the new Massachusetts Green High-Performance Computing Center (MGHPCC) to examine broader implications and impacts of cloud technology on society. The project's ultimate goal is to define a viable marketplace for cloud computing resources in which users are assured that the services they acquire meet their performance, security, and privacy expectations.", "https://cs.brown.edu/news/2011/01/04/Ben/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Ben Raphael Awarded NSF CAREER Grant Posted by Amy Tarbox on Jan. 4, 2011 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . Ben Raphael is the latest faculty recipient of an NSF CAREER award, a highly selective grant that the National Science Foundation awards to junior faculty members who are likely to become academic leaders of the future. The project funded by Ben\u2019s CAREER grant aims to develop algorithms for new and emerging high-throughput DNA sequencing technologies. These technologies are lowering the cost of DNA sequencing by orders of magnitude, thereby enabling a variety of new biological applications. Ben plans to: *Develop novel algorithms for assembling complete genome sequences from billions of shorter DNA sequences produced by high-throughput DNA sequencing machines. *Design robust algorithms to characterize differences between individual genomes within a species using an available reference genome of the species. *Introduce combinatorial algorithms for the study of genome rearrangements in heterogeneous mixtures of DNA sequences. Examples of such mixtures are a community of microbes from an environmental sample, or a collection of cancer cells within a tumor. The proposed research will be integrated with an educational component that includes the development of an undergraduate seminar in personal genomics, a summer research experience in computational biology for high-school students, and the incorporation of a computational biology module into the Artemis summer computing camp for 9th grade girls. The Faculty Early Career Development (CAREER) Program is a Foundation-wide activity that offers the National Science Foundation's most prestigious awards in support of junior faculty who exemplify the role of teacher-scholars through outstanding research, excellent education and the integration of education and research within the context of the mission of their organizations. Such activities should build a firm foundation for a lifetime of leadership in integrating education and research. Besides his CAREER award, Ben has also received a Sloan Research Fellowship and a Career Award at the Scientific Interface from the Burroughs Wellcome Fund .", "https://cs.brown.edu/news/2010/11/23/kleinnsf/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Philip Klein, Claire Mathieu and Ph.D. Alum Glencora Borradaile Receive NSF Grant to Develop New Algorithms for Solving Optimization Problems on Planar Networks Posted by Amy Tarbox on Nov. 23, 2010 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . The National Science Foundation (NSF) has awarded a research grant , in the expected amount of $800,000, to Philip Klein , Claire Mathieu and Ph.D. alum Glencora Borradaile (now Assistant Professor in the School of Electrical Engineering and Computer Science at Oregon State University), to develop new algorithms for solving fundamental optimization problems on planar networks. Many optimization problems in networks are considered computationally difficult; some are even difficult to solve approximately. However, problems often become easier when the input network is restricted to be planar, i.e., when it can be drawn on the plane so that no edges cross each other. Such planar instances of optimization problems arise in several application areas, including logistics and route planning in road maps, image processing and computer vision, and VLSI chip design. The team plans to develop algorithms that achieve faster running times or better approximations by exploiting the planarity of the input networks. In addition, in order to address the use of optimization in the discovery of some ground truth, the investigators will develop algorithms not just for the traditional worst-case input model but also for models in which there is an unusually good planted solution; for a model of this kind, the investigators expect to find algorithms that produce even more accurate answers. In addition, new algorithms and techniques resulting from this research might enable people to quickly compute better solutions to problems arising in diverse application areas such as computer vision. Further research has the potential to be useful, for example, in the design of networks, the planning of routes in road maps, and the processing of images.", "https://cs.brown.edu/news/2011/03/01/bootstrap/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Middle-schoolers are ready, ready, ready for programming adventure Posted by Amy Tarbox on March 1, 2011 Kurt Spindler, right, and Shaopeng Zhang work with Diamon Curry, a student at Gilbert Stuart Middle School, during a lesson on programming. Credit: Mike Cohea/Brown University By Richard Lewis Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . Bootstrap, a nonprofit educational organization, pairs Brown undergraduates with middle-school students in Brown computer classrooms. The kids show up after school to learn how to make animations, video games, and other cool stuff. What they're actually getting is substantial help with mathematics. Madavin Vong\u2019s eyes lit up as the blue rocket spewed a puff of cartoonish smoke and lifted off on her computer screen. \u201cYeah!\u201d she exclaimed. \u201cWe did it!\u201d The 11-year-old Vong was excited because she had mastered the computer and math skills necessary to make the rocket soar. She was doing the programming on the Brown University campus through a class taught by Brown undergraduate students for Providence-area school children. Vong loves video games. Her favorites are ones styled on adventure, fighting, and \u2014 perhaps in an odd twist for someone so young \u2014 on time management. Now, through a program run by a nonprofit educational outfit called Bootstrap, she was getting a chance to create her own video game. \u201cBasically, I want to see how they make them,\u201d said Vong, who is in sixth grade at Gilbert Stuart Middle School. \u201cTo make [characters] move is a really cool thing.\u201d For about 10 weeks, up to a dozen middle-school students from Providence-area schools ride a bus after school to Brown to fulfill their dreams of creating their own superheroes, villains, monsters, stellar athletes, or super-organized geniuses. The video game, while real, is the hook to expose the children to computer science and to deepen their mathematics skills, according to Shriram Krishnamurthi, associate professor of computer science at Brown and a pivotal backer of the Bootstrap class. Enticing them with a straight-on programming class would be \u201ca hindrance, rather than a help,\u201d he says. \u201cThe pitch is, Wouldn\u2019t you like to write your own video game?\u201d said Krishnamurthi, who made Bootstrap\u2019s video-game software accessible via the Web and has helped with fundraising. For the students who filed into a computer room at the Center for Information Technology for the first class last month, the answer would appear to be yes. These kids, with backgrounds from Cambodia, Haiti and El Salvador, were eager to get started. Their teacher, Brown sophomore Kurt Spindler, urged caution. \u201cWe\u2019re here to make video games,\u201d he assured them, \u201cbut the thing about video games, is they\u2019re complicated.\u201d The students soon learn that\u2019s the case. They get drilled on x and y coordinates and, in a later class, are introduced to programming code needed to create shapes and animation. They seem vaguely aware of, yet little deterred, by the algebra and computer science as they furiously complete exercises in their workbooks. That\u2019s the goal behind Bootstrap, said Emmanuel Schanzer, a Providence native and the program\u2019s creator. While teaching math and computer science classes in Boston-area schools, Schanzer found that his students reacted cooly to algebra and computer programming. So Schanzer, who studied computer science in college and worked for a while at Microsoft, devised a curriculum that effectively masked the fact that his students were tackling heavy math and computer programming. That curriculum led to Bootstrap, now in its fifth year and running after-school classes for urban schoolchildren in Austin, Texas, the Bay Area in California, Boston, New York, and Providence. \u201cI had my life plan,\u201d Schanzer related. \u201cI\u2019d make my millions and then go on to teaching. But I realized I wanted to teach full time.\u201d Brown\u2019s involvement with Bootstrap began in spring 2010, with undergraduates teaching the after-school class at the middle schools. The class now takes place at the university, with transportation provided by the Providence After School Alliance. Each semester, about a half-dozen Brown students volunteer to teach, making the instruction for the middle-schoolers more of a hands-on tutorial than an impersonal lecture. \u201cSometimes, the kids are like, \u2018Oh, why are we doing this? I want to play video games,\u2019\u201d said Spindler, wearing a black Bootstrap T-shirt with \u201cI program my own video games\u201d on the front. \u201cOther times, they say, \u2018Oh my, computer science is so cool. I want to go to college.\u2019 That is exciting and visceral.\u201d It\u2019s too early to know whether Vong will attend college, but she\u2019s well on her way to creating her own video game \u2014 and enjoying the ride. \u201cWe have a long way to go, [but] I\u2019m ready for the adventure,\u201d she says during a short break. \u201cReady, ready.\u201d", "https://cs.brown.edu/news/2011/03/21/Ben/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Ben Raphael Awarded NSF CAREER Grant Posted by Amy Tarbox on Jan. 4, 2011 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . Ben Raphael is the latest faculty recipient of an NSF CAREER award, a highly selective grant that the National Science Foundation awards to junior faculty members who are likely to become academic leaders of the future. The project funded by Ben\u2019s CAREER grant aims to develop algorithms for new and emerging high-throughput DNA sequencing technologies. These technologies are lowering the cost of DNA sequencing by orders of magnitude, thereby enabling a variety of new biological applications. Ben plans to: *Develop novel algorithms for assembling complete genome sequences from billions of shorter DNA sequences produced by high-throughput DNA sequencing machines. *Design robust algorithms to characterize differences between individual genomes within a species using an available reference genome of the species. *Introduce combinatorial algorithms for the study of genome rearrangements in heterogeneous mixtures of DNA sequences. Examples of such mixtures are a community of microbes from an environmental sample, or a collection of cancer cells within a tumor. The proposed research will be integrated with an educational component that includes the development of an undergraduate seminar in personal genomics, a summer research experience in computational biology for high-school students, and the incorporation of a computational biology module into the Artemis summer computing camp for 9th grade girls. The Faculty Early Career Development (CAREER) Program is a Foundation-wide activity that offers the National Science Foundation's most prestigious awards in support of junior faculty who exemplify the role of teacher-scholars through outstanding research, excellent education and the integration of education and research within the context of the mission of their organizations. Such activities should build a firm foundation for a lifetime of leadership in integrating education and research. Besides his CAREER award, Ben has also received a Sloan Research Fellowship and a Career Award at the Scientific Interface from the Burroughs Wellcome Fund .", "https://cs.brown.edu/news/2011/06/16/Eli/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Eli Upfal Selected as Chalmers Jubilee Distinguished Visiting Professor Posted by Amy Tarbox on June 22, 2010 Eli Upfal was recently invited to serve as the Chalmers Jubilee Distinguished Visiting Professor for 2010. Chalmers is a Swedish university of technology in which research and teaching are conducted on a broad front within technology, natural science and architecture. The Jubilee Distinguished Visiting Professor Chair was created by the Swedish government when Chalmers university celebrated its 150 year anniversary in 1979. To goal of the visiting chair is bring new skills to the University while strengthening international relations. According to Eli, &quot;I look forward to working on interesting research problems with Devdatt Dubhashi and his students. There are also exciting opportunities to create new collaborations. Chalmers has been one of the world's leaders in statistical research and I look forward to collaborating on new ways to integrate statistical concepts and methods in algorithmic research. This is especially useful in applications with large datasets, such as computational biology, web browsing and social networking.\u201d", "https://cs.brown.edu/news/2011/06/01/franco/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Brown University and National University of Singapore Launch Second Concurrent Degree Program Posted by Amy Tarbox on June 1, 2011 In addition to advancing the field at a local and national level, Brown CS community members have a global impact on education and research. For more articles on Brown CS around the world click here . Brown University and the National University of Singapore (NUS) have established a concurrent degree program in computer science. Participants are selected from the top ten percent of NUS computer science concentrators and on completion of the program, will concurrently receive degrees from NUS and Brown: a bachelor\u2019s degree in computer science from NUS and a master\u2019s degree in computer science from Brown. This new program follows up the concurrent computational biology degree program , the first concurrent degree launched by Brown and NUS, which awards students a bachelor\u2019s degree in computational biology from NUS and a master\u2019s degree in computer science with a special designation in computational biology from Brown. Franco Preparata , who has been a visiting faculty at NUS for several years, is the main architect of both programs and will provide vision and leadership for them at Brown. \u201cWe are pleased to expand our educational collaboration with a prestigious world-class institution and we look forward to welcoming to the department the first participants in the program,\u201d said Department Chair Roberto Tamassia.", "https://cs.brown.edu/news/2011/07/21/avd/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Sharp Labs Provides Grant to Andy van Dam and his Research Team Posted by Amy Tarbox on July 21, 2011 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . Sharp Laboratories of America has recently provided a grant and a just released commercial product, a 60 inch touch LCD display, to Andy van Dam and his research team to foster a collaboration in research on touch-enabled user interfaces. Brown\u2019s LADS application (Large Artwork Displayed on the Surface) designed to showcase such large format artworks as the enormous Garibaldi Panorama ran without any changes on this Windows 7 supported device. Work is underway to prototype a small-team collaboration scenario to take advantage of the Sharp interactive whiteboard. The scenario uses WorkTop , another application being developed in the group that focuses on the organization of knowledge work and provides an integrated environment for annotating and linking a variety of document types such as text, images, and video with fine-grained, bi-directional hyperlinks. The current version of WorkTop is being enhanced with touch-based gestures, digital ink and character recognition to allow input and manipulation by touch and marker at the white board.", "https://cs.brown.edu/news/2011/09/12/stanugur/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Stan Zdonik and Ugur Cetintemel Receive NSF Grant to Develop Data Management System for Massive Scale Scientific Data Posted by Amy Tarbox on Sept. 12, 2011 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . The National Science Foundation (NSF) awarded a grant , in the expected amount of $736,987, to Stan Zdonik and Ugur Cetintemel to conduct research towards building a scientific database (SciDB), a system designed and optimized to support data-driven scientific applications. The aim of SciDB is to do for science what relational databases did for the business world, namely to provide a high performance, commercial-quality and scalable data management system appropriate for many science domains. In contrast to existing database systems, SciDB is based on a multidimensional array data model and includes multiple features specific to and critical for science: provenance, uncertainty, versions, time travel, science-specific operations, and in situ data processing. No existing system offers all these features in a general, highly scalable and usable engine. SciDB will thus significantly advance the state-of-the-art in data management in addition to supporting domain scientists in data-driven discovery. This grant is part of a $2.4M Large NSF grant that also funds research teams in University of Washington, MIT, Portland State University and University of Wisconsin-Madison.", "https://cs.brown.edu/news/2012/06/25/3DS/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Three Day Startup Successfully Launched at Brown Posted by Amy Tarbox on June 25, 2012 Undergrad Anne Kenyon founded Brown\u2019s 3 Day Startup (3DS) weekend, which was held in early April with the support of the department, Google, 10Gen, and Teespring. The idea of 3 Day Startup is simple: start a technology company over the course of three days. Work space was available for an entire weekend, 25 students with a range of backgrounds were selected and top-notch entrepreneurs and investors were onsite to help pick the best ideas for software startups during the Friday brainstorming session. Students then worked to release a minimal prototype by Sunday night, when they gave their product presentations. The goal of 3DS is to build enough momentum among a network of motivated people to sustain a company beyond the weekend. \u201cMany students at Brown have cool startup ideas, and all have different skill sets, so they need a way to meet and see each other in action -- working together for three straight days is a perfect way to find those with whom you work well to accomplish something of value,\u201d said Anne. \u201cEveryone seemed to get a lot out of the weekend, particularly from the mentors who have insight based on years of experience -- they said things I would never have thought of, but make so much sense. Makes us realize how much we have to learn, that business is really non-trivial.\u201d 3DS is an academic program designed to teach entrepreneurial skills in an extreme hands-on environment and enable students to start companies. The 3DS program brings together students ranging from freshmen to freshly-minted PhDs, with diverse backgrounds, including computer science, business, engineering, law, design, communications and others. Participants gain experience in cross-disciplinary collaboration, brainstorming and ideation, and group productivity, including ad-hoc leadership and decision-making under severe time constraints. \u201c3DS is way more than a hackathon and we were more than coders. We went out and collected customer feedback as we rapidly assembled and programmed our live demo. We had to quickly fix complaints and adopt suggestions. Everything was in flux; I had never experienced anything like it,\u201d said attendee Ryan McVerry. In addition to Anne, David Borcsok, Gabi Lewis and T. Luke Sherwin all of Brown, helped to organize the event. Mentors included CS alums Spiros Eliopoulos (Co-Founder, CTO Tracelytics) and Keith Dreibelbis (Google).", "https://cs.brown.edu/news/2011/12/22/pascal/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Pascal Van Hentenryck Receives Docteur Honoris Causa from l'Universite de Nantes Posted by Amy Tarbox on Dec. 22, 2011 In addition to advancing the field at a local and national level, Brown CS community members have a global impact on education and research. For more articles on Brown CS around the world click here . The University of Nantes recently presented Pascal Van Hentenryck with the title of Doctor Honoris Causa at the 2011 ceremony of the doctors at the Cit\u00e9 des Congr\u00e8s de Nantes. In the University\u2019s 50th year, Pascal was the sole recipient of this prize and the first computer scientist to ever receive it. This is Pascal\u2019s second doctor honoris causa , the first from the Universit\u00e9 catholique de Louvain in 2008. The ceremony and Pacal\u2019s talk are available (in French) on the University\u2019s website and on YouTube .", "https://cs.brown.edu/news/2012/02/01/james/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) James Hays Receives NSF CAREER Award Posted by Amy Tarbox on Feb. 1, 2012 James Hays is the latest faculty recipient of an NSF CAREER award, a highly selective grant that the National Science Foundation awards to junior faculty members who are likely to become academic leaders of the future. The research funded by James\u2019s CAREER grant aims to understand, represent, and enhance scenes at the Internet-scale. James and his team are investigating &quot;detail synthesis&quot; tasks which alleviate camera shake, motion blur, defocus, or low resolution. A key insight behind this research is that Internet scale photo collections and scene matching provide an ideal, context-specific statistical model which can be used to insert convincing texture and object detail. To improve scene matching the team will study attribute-based representations of scenes. Attributes are a powerful intermediate representation for the next generation of big data imaging research. James and his team are also developing a new introductory course for Brown students to explore big data computing across scientific disciplines and are creating an online community for visual computing education to benefit students interested in photography and programming. The Faculty Early Career Development (CAREER) Program is a Foundation-wide activity that offers the National Science Foundation's most prestigious awards in support of junior faculty who exemplify the role of teacher-scholars through outstanding research, excellent education and the integration of education and research within the context of the mission of their organizations. Such activities should build a firm foundation for a lifetime of leadership in integrating education and research. James received his B.S. in Computer Science from Georgia Institute of Technology in 2003 and completed his PhD in Computer Science at Carnegie Mellon University in 2009, where he was the recipient of a National Science Foundation Graduate Research Fellowship. He joined Brown after serving as a Postdoctoral scholar at MIT.", "https://cs.brown.edu/news/2012/08/16/newfac2012/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Michael Littman Returns to Brown with Professor Appointment; Tim Kraska and Paul Valiant to Join the Department as Assistant Professors Posted by Amy Tarbox on Aug. 16, 2012 The Department is thrilled to announce the addition of three new faculty members for the 2012-2013 academic year. PhD alum Michael Littman \u201996 and Paul Valiant will begin teaching in September and Tim Kraska will join the department in January. Michael previously spent many years as the director of the Rutgers Laboratory for Real-Life Reinforcement Learning and served as the department chair from 2009 until June 2012. His expertise includes artificial intelligence and machine learning. Tim will come to Brown after serving as a postdoctoral scholar at the University of California at Berkeley, working in the AMP Lab on Big Data management and hybrid human/machine database systems. Paul is also a postdoctoral scholar at the University of California at Berkeley in the Theory of Computation group. He received his PhD from MIT and his interests include cryptographic and algorithmic game theory and coding theory. Our three new faculty members will help serving our growing population of graduate and undergraduate students. \u201cWe are thrilled to have these three exceptionally bright and talented scholars join our department,\u201d said Chair Roberto Tamassia. \u201cWe are all looking forward to welcoming them to Brown in the coming academic year.\u201d Michael Littman After earning his PhD from Brown University in 1996, Michael worked as an assistant professor at Duke University, a member of technical staff in AT&T's AI Principles Research Department, and was most recently associate professor and chair in the computer science department at Rutgers. He is on the executive council of the American Association for AI, the advisory board of the Journal of AI Research, and serves as an action editor of the Journal of Machine Learning Research. His research in artificial intelligence focuses on designing software systems that improve their behavior with experience. His educational focus is on making academic computer science accessible to the general public. \u201cIt's a dream come true to be coming back to Brown,\u201d said Michael. \u201cWhen I was here as a student, I was very focused on my narrow research area. This time, I'm very excited to get to know the undergraduates and to work with faculty both within and outside Computer Science. It's a very exciting time to be a Computer Scientist and I would love to see the whole Brown community benefiting from the fantastic opportunities enabled by our ideas.\u201d Tim Kraska Tim received his PhD from the Swiss Federal Institute of Technology Zurich (ETH) in Switzerland, master\u2019s degrees from Westf\u00e4lische Wilhelms-Universit\u00e4t M\u00fcnster in Germany and University of Sydney in Australia and a Bachelor of Science in Information Systems also from Westf\u00e4lische Wilhelms-Universit\u00e4t M\u00fcnster. He received a Swiss National Science Foundation Prospective Researcher Fellowship (2010), a DAAD Scholarship (2006), a University of Sydney Master of Information Technology Scholarship for outstanding achievement (2005), the University of Sydney Siemens Prize (2005), and a VLDB best demo award (2011). Tim\u2019s current focus is on Big Data management and hybrid human / machine data base systems. According to Tim, \u201cBrown\u2019s strong interdisciplinary and friendly environment with its excellent faculty and students make it a truly outstanding university. I am very excited to be joining the CS department and to be part of making it one of the leading places for big data research.\u201d Paul Valiant Paul received his PhD from MIT and master\u2019s degrees from both MIT and Stanford and a Bachelors degree from Stanford. He was previously a postdoctoral researcher at MIT. Paul received a NSF Mathematical Sciences Postdoctoral Research Fellowship, the Best Student Paper Award at the Theory of Cryptography Conference in 2008 and a National Defense Science and Engineering Graduate Fellowship. His interests include statistics, learning and property testing; cryptography; auctions and game theory; protein folding; evolution; fluid dynamics and computational approaches to the other sciences. \u201cI am very excited to be joining the collaborative and forward-looking community of Brown's Computer Science Department,\u201d said Paul. \u201cComputation has been constantly challenging us to change how we think about the world, and I am particularly intrigued by the new perspectives it offers on deep problems in the other sciences. At Brown I look forward to engaging with students and faculty from many departments and backgrounds to learn how to tackle these challenges.\u201d", "https://cs.brown.edu/news/2012/10/03/BigData/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Brown awarded $1.5M for new Big Data tools Posted by Amy Tarbox on Oct. 3, 2012 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . Eli Upfal, Fabio Vandin, and Ben Raphael, from left, are developing Big Data analytical tools that make sense of large datasets and eliminate the noise of data errors. Credit: Mike Cohea/Brown University. By Kevin Stacey As datasets expand and new generations of faster computers arrive, users urgently require more powerful algorithms to make sense of Big Data. Brown computer scientists have received a $1.5-million award from the National Science Foundation and the National Institutes of Health to conduct research on new analytical tools for Big Data. Computer scientists from Brown University have been awarded $1.5 million to develop new computer algorithms and statistical methods to analyze large, complex datasets. Funding for the project comes from a joint initiative of the National Science Foundation and the National Institutes of Health aimed at supporting fundamental research on Big Data. Eli Upfal , professor of computer science, will lead the research with fellow computer science professors Ben Raphael and Fabio Vandin . Brown\u2019s funding allotment is the second largest of the eight grants awarded under the program this year, according to the official NSF/NIH announcement. Upfal and his colleagues will test their new methods on genomics data. Nowhere are the challenges of Big Data more evident than in genomics. As techniques for sequencing genes have become faster and cheaper, researchers have compiled mountains of new data. The trick now is trying to make sense of it all \u2014 picking out significant trends and ignoring all the unimportant \u201cnoise\u201d that inevitably accumulates in large datasets. \u201cThese datasets have all the good and bad properties of Big Data,\u201d Upfal said. \u201cThey\u2019re big, noisy, and require very complicated statistical analysis to obtain useful information.\u201d One of the aims of this project is to develop better computational tools to isolate genetic mutations that drive cancer by comparing gene sequences of healthy tissue to those of cancerous tissue. The problem is that not every mutation found in cancerous cells is important. There could be thousands of mutations in each cell that don\u2019t actually contribute to cancer growth. They\u2019re simply insignificant, random mutations. An effective computer algorithm will be able to identify with statistical certainty the mutations that actually matter, keeping doctors from chasing millions of red herrings. But that\u2019s not the only problem Upfal and his team will try to address. There\u2019s also the fact that the lab tools used to sequence genes sometimes record information inaccurately. The error rate varies between sequencing techniques but it\u2019s significant, and analytical tools need to deal with that problem as well. One of the thrusts of the Brown project is finding algorithms that address these problems in a way that can be verified statistically. The output of traditional machine learning algorithms, Upfal said, is generally not confirmed in an objective way. Take search engines as an example. If the search algorithm consistently returns the kinds of results users are looking for, they\u2019ll keep using it and the algorithm will be deemed successful. But that evaluation is subjective and largely unquantifiable. \u201cIn scientific applications, you need something that can be analyzed rigorously,\u201d Upfal said. \u201cWe need to know the confidence level of the outcome.\u201d So a key aspect of this project will be combining traditional machine learning algorithms with the most rigorous of statistical methods. Daunting as the obstacles may be, Upfal and his colleagues have already had success in addressing them. Last year they developed an algorithm called HotNet that helps to isolate clusters of mutated genes that can cause cancer. They\u2019re hoping to build on that success with this new grant. Ultimately, Upfal said, the team hopes to develop new tools that can be broadly applied not only to genomics data but also to other Big Data problems like the analysis of large-scale social networks.", "https://cs.brown.edu/news/2013/06/18/phd-student-jeff-rasley-receives-nsf-graduate-research-fellowship/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Ph.D. Student Jeff Rasley Receives NSF Graduate Research Fellowship Posted by Angel Murakami on June 18, 2013 Computer Science PhD graduate student Jeff Rasley has received a National Science Foundation Graduate Research Fellowship, a prestigious and highly competitive program. Jeff is broadly interested in networks, distributed systems, and security. His current research is on network profiling of \"big data\" workloads, which aims to better understand the interaction and performance of data center networks and \u201cbig data\u201d computing frameworks such as Hadoop. He is advised by Rodrigo Fonseca . Jeff joins our other PhD students who have been recently supported by NSF Graduate Fellowships: Connor Gramazio, Michael Hughes, Dae Il Kim, Mark Leiserson, and Layla Oesper.", "https://cs.brown.edu/news/2013/06/07/michael-littman-honored-2013-aaai-classic-paper-award/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Michael Littman Honored With 2013 AAAI Classic Paper Award Posted by Angel Murakami on June 7, 2013 The Association for the Advancement of ArtificialIntelligence (AAAI) has selected the 1994 paper Acting Optimally in Partially ObservableStochastic Domains by Anthony R. Cassandra, Leslie Pack Kaelbling, and Michael Littman ,then a Brown CS graduate student, for a 2013 AAAI Classic Paper Award. Thisaward was established in 1999 to honor author(s) of paper(s) deemed mostinfluential from a specific conference year. This year's award recognizespapers from the Twelfth National Conference on Artificial Intelligence thattook place in 1994 in Seattle, Washington. \u201cBack in 1994, we were fascinated by the idea that an agentcan make optimal decisions in spite of not knowing all the facts,\u201d statedMichael Littman. \u201cThe math wasoriginally developed in the operations research community, but we found that itwas a perfect fit for the kinds of problems AI people are interested inaddressing. These days, the notion ofpartial observability is a standard part of the AI vernacular.\u201d In academia a 'classic paper' is one that changes thedirection of the field, typically because it identifies a \u201csweet spot\u201d\u2014a placewhere one can accomplish a lot without incurring overwhelming complexity. This paper is a classic \"classicpaper,\" added Professor Eugene Charniak. Michael Littman", "https://cs.brown.edu/news/2014/03/14/iman-hajirasouliha-receives-nserc-fellowship/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Iman Hajirasouliha Receives NSERC Fellowship Posted by Jesse Polhemus on March 14, 2014 Postdoctoral Research Associate Iman Hajirasouliha of Brown University\u2019s Computer Science Department and the Center for Computational Molecular Biology (CCMB) has just received a Postdoctoral Fellowship from the Natural Sciences and Engineering Research Council of Canada (NSERC) for his proposal (\u201cAlgorithms for constructing ancestral history of deep-sequenced tumors\u201d) on cancer heterogeneity. Iman is the second member of BrownCS to receive the fellowship, joining Glencora Borradaile, who received hers in 2007. \u201cIt\u2019s very exciting and gratifying,\u201d he says. \u201cI knew that this fellowship is competitive, and I was thrilled that my proposal was accepted. It shows the importance of computational methods to help combat a very complex disease.\u201d Iman goes on to explain that we find ourselves at a pivotal moment in cancer research. Only in recent years have scientists discovered that mutations thought of collectively by the general public (for example, breast cancer or lung cancer) actually vary considerably from person to person. Perhaps even more interestingly, heterogeneous mutations can exist across a single tumor. \u201cThe goal here and now,\u201d Iman says, \u201cis to characterize that heterogeneity.\u201d The Postdoctoral Fellowships Program, which is in the amount of $40,000 per year for two years, offers an attractive opportunity to continue that effort. It was created to support researchers of promise at a crucial moment in their careers, with the goal of creating a pool of Canadians with top-quality research and scientific skills to supply the Canadian government, industry, and higher education system. NSERC Postdoctoral Fellowships are extremely competitive, and only a few are awarded each year to Canadians working at institutions in other countries. \u201cThis fellowship is well-deserved,\u201d says Ben Raphael, Associate Professor of BrownCS and Director of the CCMB, who has supervised Iman\u2019s recent work. \u201cHe\u2019s one of the star PhDs in his research area, and I\u2019m equally proud of his abilities as a mentor and collaborator.\u201d Iman returns the compliment with a broad smile. \u201cI\u2019m really grateful to Ben and the colleagues of mine that have made this opportunity possible. Thank you all.\u201d", "https://cs.brown.edu/news/2014/04/01/erik-sudderth-wins-nsf-career-award/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Erik Sudderth Wins NSF CAREER Award Posted by Jesse Polhemus on April 1, 2014 AssistantProfessor Erik Sudderth of Brown University\u2019s Computer Science Department has just won a National Science Foundation CAREER Award for his work onBayesian nonparametric learning for large-scale structure discovery. It\u2019saccompanied by a grant in the expected amount of more than $509,000. He joinsmultiple previous Brown CS faculty winners, including (most recently) James Hays , Ben Raphael ,and ChadJenkins . CAREER Awards are the most prestigious awards given by theNational Science Foundation (NSF) in support of outstanding junior facultyteacher-scholars who excel at research, education, and integration of the twowithin the context of an organizational mission. Themotivations for Sudderth\u2019s research start with very large datasets, which couldinclude anything from the videos available on YouTube to the complete corpus of New York Times articles. Parametric statistical learning algorithms workby tuning model parameters to match a user-specified list of properties, or\"statistics\", of the data. When these algorithms are used to analyzeimages and video, for instance, humans are required to laboriously collectexamples of objects of interest (for example, people, cars, and buildings).\u201cThis puts real limits on what can be learned from even very big datasets,\u201dErik explains, \u201cbecause the model\u2019s structure has to be manually specified byexperts.\u201d Anonparametric model, however, allows its structure and complexity to bedetermined from the data itself, so it can grow naturally as the data grows.This allows for algorithms that are capable of \u201cunsupervised\u201d learning, andbecause less manual supervision is needed, such methods are muchmore broadly applicable. The real-world applications for models ofthis kind are almost limitless: helping computers analyze photographs to differentiateobjects from their surroundings, or allowing robots to determine humancognitive states based on facial expressions, or finding communities withinsocial networks by analyzing patterns of collaboration. \u201cErik\u2019sinnovative research is highly regarded in both computer science andstatistics,\u201d comments BrownCS Department Chair Roberto Tamassia . \u201cTheprestigious NSF CAREER award is one more indication that Erik is a leader inthe important field of Bayesian nonparametric statistical methods.\u201d Iflaypeople find the mathematical and computational methods underlying this worka bit daunting, Sudderth already has their needs in mind. \u201cWe\u2019re very eager,\u201dhe says, \u201cto put useful tools into the hands of people who don\u2019t yet know whatnonparametric methods can provide. The five-year term of the grant lets us takea long-term perspective and address the full data analysis process, from modelsto algorithms to usable software.\u201d In addition to supporting research, the CAREERgrant funds a three-pronged outreach and education plan that includes: (1)an accessible Python software package to allow for easier data analysis, (2)interdisciplinary research projects involving undergraduate students withtraining in other sciences or the humanities, and (3) two week-long summerschools on Bayesian nonparametrics to be held at Brown's Institute for Computational andExperimental Research in Mathematics (ICERM). Sudderth\u2019scolleagues are eager to see the project begin. \u201cErik does excellent work on allaspects of Bayesian nonparametric models,\u201d says Professor MichaelLittman , \u201cfrom devising new mathematical structures, to applying them tointeresting problems in text and vision processing, to developing fasteralgorithms that handle larger and more complex problems, to providing toolkitsso others can leverage these advances in their own work. I'm delighted that theNSF recognized his contributions and promise with a prestigious CAREER award.\u201d \u201cThisis a big honor,\u201d Erik concludes. \u201cThis award is about making interdisciplinarylinks. It\u2019s vital for computer scientists to understand how our code andalgorithms are challenged by complicated, messy datasets, and it\u2019s equallyimportant for those in other fields to see how computer science can be used tohelp understand their data. I\u2019m extremely excited.\u201d", "https://cs.brown.edu/news/2014/05/29/browncs-celebrates-35-years/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) BrownCS Celebrates 35 Years Posted by Jesse Polhemus on May 29, 2014 by Kevin Stacey (Science News Officer, Physical Sciences) As the Brown community came together to celebrate Commencement in the University\u2019s 250th year, computer science alumni reunited this weekend to celebrate another anniversary. This year marks the 35th year of Brown\u2019s Department of Computer Science , which was founded in 1979. Much has changed in computer science in those 35 years. The department started with one general-purpose computer: a lone Digital VAX-11/780. It was joined shortly thereafter, in 1981, by another of the same model. The two were affectionately dubbed Nancy and Sluggo after the cartoon characters. Nancy, which now resides as a museum piece on the third floor of Brown\u2019s Center for Information Technology Building, boasted a whopping 512 kilobytes of memory and 67 megabytes of disk space. It was state-of-the-art at the time, but today, an iPhone 5 has about 18,000 times more computing power. In the years that followed, things ramped up quickly. \u201cWe wrote a proposal to the National Science Foundation for an infrastructure grant to provide funding to purchase computers for the department for both research and teaching,\u201d said John Savage, the An Wang Professor of Computer Science and one of the department\u2019s founders. \u201cBy the fall of 1983, we had the first electronic classroom populated with powerful workstations.\u201d Today, the department boasts several labs filled with computers for student use, and a cluster consisting of 180 different computers and 1,800 central processing units for intensive research. What hasn\u2019t changed in those 35 years is the department\u2019s commitment to groundbreaking research and graduate education, coupled with an undergraduate experience that is second to none. \u201cThat\u2019s a tradition I\u2019m very proud of,\u201d said Andries van Dam, the Thomas J. Watson Jr. University Professor of Technology and Education, professor of computer science, and the department\u2019s first chair. Early years While the department was formed in 1979, the story of computer science at Brown goes back more than a decade earlier. In 1965, van Dam, who was awarded the second Ph.D. ever in the burgeoning field of computer science, joined the faculty in the Division of Applied Mathematics. Two years later, Savage joined the faculty in what was then the Division of Engineering. Along with Peter Wegner, also in Applied Mathematics, the trio formed the core of what would become Brown\u2019s program in computer science. Making the leap from program to department met with some early resistance, van Dam says. \u201cStarting a Department of Computer Science in an age where people appreciate the discipline on one hand but don\u2019t think of it on equal terms as they do their own discipline on the other, has been a bit of a rough ride at times,\u201d he said. \u201cBut I'm pleased to report that overall Brown has treated us well. These days the University truly values the contributions computer science can make.\u201d One of the founding principles of the department was articulated in a mission statement developed very early. The faculty chose a theme for the department: balancing theory and practice. \u201cWe asked the question: What distinguishes us from other institutions?\u201d Savage said. \u201cThere was Cornell, which was very theoretical. The faculty was dominated by people with mathematical backgrounds. One of the other leading departments was Carnegie Mellon, and they were primarily experimentally oriented. So we looked at our interests and found we had some people interested in the theoretical side of the house and others in the more applied side of the house. So we chose that theme for that reason.\u201d Research in the early days of the department was very much focused on building the foundations of a discipline in its infancy. Brown faculty made crucial contributions in those early years. Van Dam worked with his students on the earliest hypertext systems, precursors to modern webpages with hyperlinks. He was also a pioneer in the field of computer graphics. He was co-author of the textbook Computer Graphics: Principles and Practice , considered to be \u201cthe Bible\u201d of computer graphics. His research and books are widely recognized to have been influential in creating computer-aided design systems and modern animated films. Having invited him to the premiere of the blockbuster Toy Story , Steve Jobs presented van Dam with a book on the making of the film that included the inscription, \u201cYou made it so.\u201d Savage made crucial theoretical contributions to the coding and decoding of information for storage and transmission. He showed that these processes were intimately related to the size and depth of the circuits on which they are computed. He wrote the first book on this topic, known as circuit complexity, which is now a cornerstone of theoretical computer science. Peter Wegner did seminal work on the theory and practice of programming languages. He pioneered object-oriented programming, a paradigm shift that led to modern computer languages like C ++ , Java, Python and others. \u201cThanks to John, Andy, and Peter, Brown became internationally known for computer science research in the \u201960s and \u201970s, well before the CS department was founded,\u201d said Roberto Tamassia, the Plastech Professor of Computer Science and current department chair. Founded on undergraduate education While pioneering research helped to put the department on the map, a priority was placed on undergraduate instruction from the beginning. \u201cYou can look at the development of computer science and see that Brown was essentially unique in those early days in that we taught computer science not just at the graduate level but also at the undergraduate level,\u201d van Dam said. \u201cI was told by the top schools in computer science at the time that it was wrong to teach undergraduates computer science. They felt computer science should be a specialized graduate school-only discipline, and those departments didn\u2019t really take undergraduates seriously until the late \u201990s in some cases. So Brown was a full 30 years ahead of other institutions in terms of offering degrees in undergraduate computer science.\u201d That meant taking conscious steps to make sure that top faculty balanced their research and teaching responsibilities. \u201cIt is very much part of our departmental culture that everybody teaches at every level,\u201d van Dam said. \u201cDespite the fact that we\u2019ve become rather larger than we ever anticipated, Brown has preserved a sense that undergraduates matter as much as graduate students.\u201d That meant limiting, to some extent, the number of graduate students each professor would take on. \u201cOne of the many foundational issues we tackled was what kind of department we wanted to be. Do we want to be big, or do we want to be in the Brown tradition of \u2018small is beautiful?\u2019\u201d van Dam said. \u201cWe tried to settle how many Ph.D. students we wanted to have with classic math or computer science humor. We bounded the number between e [Euler\u2019s constant] and Pi. So on average, each professor should have between 2.7 and 3.14 graduate students.\u201d Countless students, both graduate and undergraduate, have gone on to successful careers both in academia and industry. Van Dam counts at least seven graduates who have gone on to chair computer science departments around the country, including powerhouse departments at MIT and the University of Washington\u2013Seattle. Others have taken top executive positions at companies like Intel, Microsoft, and Google. Today, that commitment to undergraduate education is buttressed by a program that puts undergraduate teaching assistants in all the lower-level classes. Tamassia refers to the undergraduate teaching assistants program as the department\u2019s \u201cflagship program.\u201d For every undergraduate course, Brown aims to provide one undergraduate TA for every 10 students. The TAs hold extensive office hours to tutor fellow students, while helping professors in the creative endeavor of developing new assignments and projects. \u201cThe TAs develop leadership and communication skills while gaining a deeper understanding of the material,\u201d Tamassia said. \u201cThis system has been copied at other institutions. It has worked extremely well.\u201d The Future is Bright Initiatives like the undergraduate TA program have helped the department manage a tremendous growth in enrollment. In the last six years, the enrollment in undergraduate computer science courses has tripled and computer science has become the second-largest declared concentration on campus. This year, a record number of degrees were awarded to 114 undergraduate computer science concentrators and 59 master\u2019s and Ph.D. students. \u201cIncreasing interest in computer science on the part of students is a global phenomenon,\u201d Tamassia said. \u201cThe most important reason is that computer science is becoming pervasive in society, in business, in science, and in the way people interact. There are more and more exciting careers opening up for our graduates. There\u2019s a need for computer scientists in all other sectors of the economy.\u201d The department has 26 highly decorated tenured and tenure-track faculty . Research in the department has taken on a decidedly outward-facing character, Savage says, with researchers forming new partnerships across campus and across disciplines. A burgeoning robotics group is working to expand the use of robots in healthcare, education, industry, and elsewhere. Brown\u2019s Center for Computational Biology is bringing the power of computers to problems in the life sciences, including the development of algorithms to help unravel the genetic underpinnings of cancer. The artificial intelligence group continues to develop strategies to help machines better solve problems and interact with people. The graphics, visualization, and interaction group continues a long tradition of creating new ways for people to leverage the power of computers through novel human-computer interfaces, immersive virtual reality, pen computing, behavioral modeling, and internet-scale image analysis. The data systems group is addressing the big data challenges faced by the industry, sciences, and engineering fields by developing highly scalable and usable data management and analytics software. Other faculty are involved in foundational hardware and software systems research ranging from computer architecture to computer networks, distributed computing, and programming environments. Finally, a number of faculty are attacking the grand challenge of securing cyberspace in an increasingly digital world with a broad approach that includes cryptographic foundations, programming languages, cloud computing, and Internet governance. A list of research areas pursued by faculty in the department is available online . Above all, the department has maintained its standing as one of the top computer science programs in the country. \u201cPossibly the most distinguishing feature of the department is that we compete with departments that are much larger in size,\u201d Tamassia said. \u201cWe have truly outstanding faculty members. Our people are at the top of the field.\u201d", "https://cs.brown.edu/news/2014/09/26/chad-jenkins-and-his-team-help-develop-nasa-software/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Chad Jenkins And His Team Help Develop NASA Software Posted by Jesse Polhemus on Sept. 26, 2014 by Kevin Stacey (Science News Officer, Physical Sciences) Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . A group of computer scientists from Brown were at the Johnson Space Center in Houston recently for a week-long marathon of intensive coding to build new software for the Robonaut 2 and other NASA robots. The coding marathon, known in the computer science vernacular as a hackathon, was a partnership between NASA, Brown, and the University of Texas\u2013Austin. The work was part of a NASA grant awarded recently to Chad Jenkins, associate professor of computer science and engineering at Brown. Jenkins\u2019 lab builds user interfaces that can control robots of all kinds with an off-the-shelf web browser. The system can be adapted for even the most complex robots, and NASA wants Jenkins and his team to adapt the interface for the humanoid robot, Robonaut 2 \u2014 \u201cR2.\u201d As it is now, R2 can be controlled only from computers with specialized software that can communicate with R2\u2019s operating system. The interface Jenkins and his team are developing creates a software bridge that enables a web browser to communicate with that operating system. That means all of the R2\u2019s complex capabilities could be accessed from virtually any computer or even from tablets. The goal of the hackathon was to lay the groundwork for the project. Jenkins was joined at the hackathon by research scientist John Raiti, undergraduate student Matt Wong, and David Lu, a researcher from Washington University working with Jenkins\u2019s lab. \u201cBefore the hackathon started we only had a first pass of a web interface,\u201d Raiti said. \u201cBut by the end we were able to demonstrate through simulation a working interface for control of the Robonaut 2.\u201d By simulation, Raiti is referring to a virtual version of R2 that runs on a computer server. Operating the real thing comes later. There are currently two R2s, one aboard the International Space Station and one operating at the Johnson Space Center. The earthbound version is used to test code and do safety checks for the orbiting version. The new web interface will enable the R2 on earth to be controlled from a Web connection anywhere. Astronauts could control the orbiting R2 with nothing more than a tablet. Matt Wong, a rising senior and computer science concentrator, relished the chance work on the project and make the trip to Johnson Space Center. His work on the project this summer was supported by Brown\u2019s Karen T. Romer Undergraduate Teaching and Research Awards program. \u201cThe hackathon also gave me an opportunity to meet more people involved with robotics, as we worked alongside several NASA employees as well as a group from UT\u2013Austin,\u201d Wong said. \u201cIt was a really rewarding experience.\u201d He and his fellow hackers churned out thousands of lines of code during the week. The group was pleased with what they were able to accomplish. \u201cMost of the work I did at the hackathon revolved around setting up the basic structure to enable communication between our [browser-based] front-end and the back-end server on which robot code actually runs,\u201d Wong said. \u201cWe made good progress at the hackathon, but there's still a good amount of work to be done before the web interface is fully functional.\u201d Wong said he looks forward to continuing his work on the project when school starts again. For Jenkins, the R2 project is part of a broader effort to make robots more accessible to more people. His lab has already designed web interfaces that can control the PR2 household assistance robot, quadricopter drones, and other devices. \u201cThe idea is that we want to be able to make robots available to everybody in the world through the Internet, using the web browser,\u201d Jenkins said. \u201cThis is our way of getting robots out of the lab and into the world.\u201d", "https://cs.brown.edu/news/2014/11/11/philip-klein-wins-nsf-grant-optimization-planar-graphs-and-beyond/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Philip Klein Wins NSF Grant For Optimization In Planar Graphs And Beyond Posted by Jesse Polhemus on Nov. 11, 2014 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . Klein\u2019s recent project (\u201cFast and accurate optimization in planar graphs and beyond\u201d) has won a grant in the expected amount of $1.2M from the National Science Foundation (NSF), shared with Professor Jeff G. Erickson of the University of Illinois at Urbana-Champaign. Klein\u2019s research involves discovering and analyzing algorithms for optimization problems in graphs, problems such as traveling salesman , shortest paths , network design , clustering , graph decomposition , and facility location . The grant supports work aimed at discovering algorithms that are designed specifically for planar graphs---graphs that can be drawn on a plane so that no edges cross. When the input graph is required to be a planar graph, we can achieve faster running times and more accurate approximations than we know how to achieve in general. Road maps are nearly planar, so planar-graph algorithms are applicable to problems in logistics and planning in road maps. Grids are planar, so some problems in image processing can be addressed using planar-graph algorithms.", "https://cs.brown.edu/news/2015/03/17/jeff-huang-wins-nsf-crii-grant-and-salomon-award/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Jeff Huang Wins NSF CRII Grant And Salomon Award Posted by Jesse Polhemus on March 17, 2015 in Awards Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . Less than two years after his arrival at Brown University \u2019s Computer Science Department , Assistant Professor Jeff Huang has received a Richard B. Salomon Faculty Research Award from Brown\u2019s Office of the Vice-President for Research as well as a National Science Foundation (NSF) Computer and Information Science and Engineering (CISE) Research Initiation Initiative (CRII) grant. CRII is a new program aimed at encouraging research independence among scientists in their first academic position, and Jeff is its first grant recipient at Brown CS. The Salomon Award, given annually, was established to support excellence in scholarly work by providing funding for selected faculty research projects of exceptional merit with preference given to junior faculty who are in the process of building their research portfolio. Jeff joins multiple previous Brown CS winners, including Stefanie Tellex , Rodrigo Fonseca , and Ugur Cetintemel . \u201cThis research is about democratizing eye tracking,\u201d Jeff explains. \u201cIt\u2019s extraordinarily useful in applications ranging from human-computer interaction studies to medical research, but the tracking devices are highly specialized, can cost tens of thousands of dollars, and are difficult to calibrate and use. That\u2019s restricted their availability to mostly on-site labs.\u201d \u201cOn the other hand,\u201d he says, \u201cmany of us have one of the low-end webcams that are widely available around the world. I intend to provide one of the first opportunities for turning them into tools fit for professional study. This can be done by using user interactions to continuously calibrate the eye tracker during regular activity.\u201d Jeff\u2019s earlier research reveals that when a user clicks on a web page, they first look where they intend to click, and that the eye is likely to be two to four characters to the right of the last typed character on the screen. Webcam images during these user interactions can be collected by the website to use as cues for what the user\u2019s pupil looks like when that user interacts with a particular location. Future observations of the pupil can be matched to past instances with similar-looking pupils as the eye tracking system collects mapping of pupil features to eye-gaze locations on the page, allowing a model to infer the eye-gaze location even when the user is not interacting. \u201cCollaborating with Jeff is an exceptional experience,\u201d says PhD candidate Alexandra Papoutsaki , one of his collaborators. \u201cHe has a diverse background and can bring together concepts from different domains. As part of designing our first eye-tracking algorithm, we\u2019re working with Professor James Hays and his Master\u2019s student, Patsorn Sangkloy .\u201d \u201cIt's a challenging problem,\u201d Patsorn says, \u201cespecially when people's eyes can be so different. I think we've made good progress, and I can't wait to see where eye-tracking could lead to.\u201d \u201cI believe it\u2019s going to play an important role in the development of future technology,\u201d says Alexandra. \u201cEye-tracking is far more inclusive than touch or click interactions and can even be used by people with motor impairments. Once it reaches a stable phase, I think that we\u2019ll be surprised by the unexpected uses that appear.\" \u201cThis is special because it frees eye tracking from the confines of the lab,\u201d Jeff says. \u201cSharing my work and source code will set this technique loose so it can be used in a broad range of applications. With no need to install additional software, eye tracking can go anywhere. Think of the possible output: everything from new types of online games to superior website navigation for the impaired to improved search engine results could become part of the natural Web experience of everyday users.\u201d", "https://cs.brown.edu/news/2015/05/07/nobel-laureates-scholars-discuss-computation-future-their-fields/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Nobel Laureates, Scholars To Discuss Computation In The Future Of Their Fields At May 12-15 Symposium Posted by Jesse Polhemus on May 7, 2015 by Kevin Stacey (Science News Officer, Physical Sciences) A group of scholars including three Nobel laureates will gather at Brown for a week-long series of talks on the future of their fields and honoring the legacy of computer pioneer and scientific polymath John von Neumann. The \u201cBrown University 250th Anniversary Symposium : The Next 250 Years,\u201d May 12-15, 2015, will feature talks in economics, physics, computer science, and brain science. PROVIDENCE, R.I. [Brown University] \u2014 John von Neumann was without doubt one of the 20th century\u2019s greatest minds. He is considered to be one of the founders of digital computing, pioneered game theory as a model of decision-making, and made critical contributions in the fields of physics, applied mathematics, and engineering. Next week, renowned scholars including three Nobel laureates and a Turing Prize winner will give lectures at Brown in economics, physics, computer science, and brain science. Speakers will reflect on what the future may hold for their disciplines, while emphasizing von Neumann\u2019s vision of \u201ccomputation as a scientific lens.\u201d Fourteen von Neumann lectures will be given over four days, May 12-15, 2015. Each day\u2019s session will include a \u201csweat box session\u201d \u2014 an intensive question-and-answer forum with some of the day\u2019s speakers. \u201cVon Neumann was dedicated to the idea that we should tackle the hardest problems, working in symbiosis on the most abstract and most practical aspects of the problem in an intra-math, inter-sciences, cross-cultures, interdisciplinary approach,\u201d said Sorin Istrail, the Julie Nguyen Brown Professor of Computational and Mathematical Sciences. \u201cVon Neumann\u2019s seminal research is organically aligned with Brown\u2019s research mission across departments, inspiring us as we focus on the next generation of research problems.\u201d The week\u2019s talks are free, open to the public, and will be held in Brown\u2019s Center for Information Technology. The lectures will be webcast live . Speakers will include: Kenneth Arrow, winner of the 1972 Nobel Prize in Economics; Leon Cooper, Brown professor and winner of the 1972 Nobel Prize in Physics; Frank Wilczek, winner of the 2004 Nobel Prize in Physics; Leslie Valiant, winner of the 2010 ACM Turing Award; and Freeman Dyson, physicist and mathematician, reflecting on his experience as a colleague of von Neumann\u2019s at the Institute for Advanced Study. The full schedule of 14 lectures, with information about the speakers, is available online . The symposium was organized by Brown professors Cooper (physics), Istrail (computer science), Stuart Geman (applied mathematics), and Roberto Serrano (economics). Each considers von Neumann a hero and has tried to incorporate his vision into research and teaching. This is the second von Neumann symposium to be held at Brown. The prior event, the kick-off the John von Neumann Distinguished Lecture Series, was held at Brown in 2010 . The event is co-sponsored by Brown\u2019s Office of the President, Office of the Provost, Office of the Vice President for Research, Office of Brown\u2019s 250th Anniversary, Department of Computer Science, Department of Economics, Department of Neuroscience, Department of Physics, Center for Computational Biology, and Department of Biostatistics. It is hosted by the Department of Computer Science.", "https://cs.brown.edu/news/2015/05/11/visualization-and-creativity-immersive-3d-environments-cave-yurt-may-20-21-2015/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Visualization And Creativity In Immersive 3D Environments -- From Cave To YURT: May 20-21, 2015 Posted by Jesse Polhemus on May 11, 2015 sponsored by the Office of Brown University's 250th Anniversary, the Brown University Center for Computing and Visualization, Brown University Computing and Information Services, and the Brown University Sciences Library; the YURT has been developed with funding from NSF For more CS News and CS Blog articles about the Yurt, please click here . We are celebrating the opening of Brown's newest virtual reality environment, the YURT (YURT Ultimate Reality Theatre), in the context of the many decades of visual study that presaged it. This immersive environment fully engages our visual senses for exploration and discovery in areas as diverse as planetary geology, mathematics, visual art, digital literature, and biology. With head and body-tracking, users control a virtual world shown on a room-sized, 100 million-pixel stereo display that completely surrounds them. You have to experience this unique instrument to truly understand and appreciate it. Join us to learn about the future of virtual reality from some of the field's greatest innovators and to experience the reality for yourself. Please do two things immediately in order to attend: E-mail Jesse C. Polhemus to register. Please note that some events have already reached maximum attendance. Book a hotel room if necessary: Hotel Providence (401-861-8000), the Biltmore (401-421-0700), the Wyndham Garden (401-272-5577), or the Marriott (401-272-2400). Agenda All talks will be in Martinos Auditorium, Granoff Center, with other locations indicated below. Wednesday, May 20 9am-1pm Attendees will be invited to sign up for presentations in both new YURT and the legacy Cave on Wednesday morning, and subsequently on a drop-in basis throughout Thursday with priority given to those registered for the symposium, and any free spaces then offered to the Brown community at large. YURT: 180 George St (at Brook) Cave: Granoff Center, Studio 4, N330 Guided presentations from 9am to 1pm at both sites will last 45 minutes 1:30-2 pm Welcoming remarks and introduction 2:15-3:30 pm Keynote by Henry Fuchs 3:30-4 pm Coffee, tea, snacks available Granoff Center, Foyer 4-5:15 pm Fritz Drury and John Cayley (\"Teaching in Immersive Audiovisual Environments: 'VR Design for Science' and 'Cave Writing'\") 5:30-6:30 pm Reception and YURT Inauguration with Provost Vicki Colvin (Please note the venue: Brown CIT Building, 3rd Floor, Thomas J. Watson Sr. Center for Information Technology) 7:30 pm Symposium dinner for selected participants (Please note the venue: The Hope Club) Thursday, May 21 9:30 am and throughout the day: coffee, tea, pastries, and snacks Granoff Center, Foyer 10-11:15 am Steven Feiner and Tom Banchoff 11:30-12:45 pm Jim Head 1-1:45 pm Pick up lunch boxes in Granoff Center or on your own locally 2:45-4 pm Joe LaViola (\"3D User Interfaces in Virtual Environments: Past, Present, and Future\") and Roderick Coover 4-4:30 pm Coffee and tea 4:30-5:45 pm Noah Wardrip-Fruin (\"The Power of Presence with Virtual Art\") and Dan Keefe (\"Magical User Interfaces: Bringing Interactivity to Immersive Science and Art\") 6-6:30pm Symposium closing FAQ Where can I find parking? How do I find help for my special accessibility needs? Parking may be limited, so we recommend carpooling or alternative methods of transportation if possible. You can find more information about parking and accessibility here . I have another question. Could you please help? We'd be happy to! Please e-mail or call 401-863-7600.", "https://cs.brown.edu/news/2015/05/15/michael-littman-wins-ifaamas-influential-paper-award/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Michael Littman Wins IFAAMAS Influential Paper Award Posted by Jesse Polhemus on May 15, 2015 in Awards Professor Michael Littman of Brown University 's Department of Computer Science has just won the International Foundation for Autonomous Agents and Multi-Agent Systems (IFAAMAS)'s Influential Paper Award for work (\" Markov games as a framework for multi-agent reinforcement learning \") originally published at the Proceedings of the Eleventh International Conference on Machine Learning (ICML) in 1994. The award was established by IFAAMAS in 2006 to recognize publications that have made seminal contributions to the field. Such papers represent the best and most influential work in the area of autonomous agents and multi-agent systems. These papers might, therefore, have proved a key result, led to the development of a new sub-field, demonstrated a significant new application or system, or simply presented a new way of thinking about a topic that has proved influential. This award, following shortly after his 2013 AAAI Classic Paper Award, is another example of the continued recognition of Michael's insight, influence, and distinguished contributions to the field. Congratulations!", "https://cs.brown.edu/news/2015/05/22/brown-cs-launches-undergraduate-teaching-assistant-endowment/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Brown CS Launches A $10,000,000 Fundraising Campaign For An Undergraduate Teaching Assistant Endowment Posted by Jesse Polhemus on May 22, 2015 Brown University 's Department of Computer Science (Brown CS) today announces the start of a fundraising campaign to build a $10,000,000 endowment for its Undergraduate Teaching Assistant (UTA) program. The campaign's web site, with testimonials from former UTAs such as Mike Fredrickson of Pixar and Philip Levis of Stanford University, is at https://cs.brown.edu/giving . Announced by President Christina Paxson, Provost Vicki Leigh Colvin, and Department Chair Ugur Cetintemel, the endowment will be a landmark investment in a key element of the Brown CS educational mission. UTAs contribute to all aspects of instruction and play a mentoring role that's vital to the quality of coursework, the educational experience of their peers, and their own personal growth. One in nine Brown undergraduates is a CS or joint CS concentrator and one in seven took a CS course this year Brown CS employs almost 200 UTAs each semester, with some courses requiring over 30 assistants At last count, over 60% of CS concentrators have been a UTA at least once Until last year, the Brown CS UTA budget hadn't changed since 2006, while enrollment grew 273%. \"Our UTA program,\" says Ugur Cetintemel, \"is the most distinctive of its kind. It creates a highly interactive and social learning environment that helps students master the technical material by teaching it, while allowing them to develop important interpersonal skills such as communication, team work and leadership. It's the combination of these ingredients, which are often absent from the standard diet of undergraduates, that prepare them remarkably well for whatever they choose to pursue in their future careers.\" \"We would like to continue to offer this opportunity for generations to come. There is also a real need now for an expanded UTA program due to the exploding interest in CS courses. This endowment will be a permanent source to secure the health and future of this unique program. It's one of the best investments we can make in the education of our students, many of whom graduate to become leaders and innovators in information technology and other fields.\" Brown CS is looking forward to an exciting campaign that will permanently benefit our students and any industries, disciplines, and communities where they contribute. Please send any questions to donate@cs.brown.edu .", "https://cs.brown.edu/news/2015/05/18/celebrate-andy-50-years-cs-brown/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Celebrate With Andy: 50 Years Of CS At Brown Posted by Jesse Polhemus on May 18, 2015 As the department approaches its silver anniversary, Brown CS is making a comprehensive effort to document our early history online and in print. Our themes are the intellectual daring of our academic home, the making of things never before imagined, and the spirit of community that\u2019s guided the entire effort. Throughout, our storytellers will be the faculty and alumni whose examples go before us. This article is the first in that series. Andy would like to mention that in the writing of this piece, he remembered many other stories and many other key contributors that we were unable to include due to space limitations. The semicentennial festivities known as Celebrate With Andy , to be held on May 22, mark three golden anniversaries for the Brown CS family: fifty years of the UTA program, undergraduate involvement in research, and Andy van Dam at Brown. A thousand words don\u2019t suffice to tell the history of those three \u201cinstitutions\u201d, but one picture from our archives evokes something of their spirit. Believed to be taken at Commencement 1977, it shows van Dam and five others (Heather Claflin \u201877, Peter Relson \u201877, Douglas Dixon \u201877, the late David Notkin \u201877, and Henri Bulterman \u201871 \u201877 ScM ), some in regalia and some not. Laughter and conversation are passing diagonally across the scene, and just for a moment, neither in the center of the composition nor at the Golden Mean, Andy has turned to the camera very casually: \u201cLook at the great people we\u2019ve got here!\u201d It\u2019s time for a toast. Romulus and Remus are fables: Brown CS doesn\u2019t require a founding myth because the true history of these three \u201cinstitutions\u201d is compelling enough. This article, however, will give only an abbreviated version of that story and tell just a fraction of the anecdotes. (We\u2019d rather you join us in person or via livestream on May 22.) Instead, in preparation for all the fun of Celebrate With Andy , let\u2019s take a few moments now to go back in time to reflect, enjoy, and celebrate. A Random Sequence The story of CS at Brown begins, humbly enough, in a bathroom. In 1962, Andy\u2019s wife, Debbie, was teaching high school French, and one of her National Education Association magazines had ended up as his bathroom reading material. \u201cI read an article,\u201d he remembers, \u201cabout teaching students at Bronx High School of Science to program and thought, \u2018That\u2019s ridiculous! I\u2019m in grad school, just learning to do that!\u2019 But it kept bugging me, and I figured that it wasn\u2019t quantum physics, that they could certainly learn logical thinking.\u201d So in 1962 he began a summer program of his own, showing Philadelphia area high school students and their teachers how to program, and even managed to obtain his first NSF grant, to support this novel project. \u201cRunning this course is how I fell in love with teaching,\u201d van Dam says, noting that the program continued on after his tenure. Alumni of the pioneering effort include Elliot Perlman, a prominent local ophthalmologist who today counts Andy and Tom Doeppner among his clients; our own Steve Reiss was a later graduate. \u201cI was teaching programming,\u201d Andy says, \u201cbut in my own first course in grad school, I didn\u2019t actually get to use a computer because Penn\u2019s sole computer was too scarce a resource. We wrote machine code on paper and had our programs hand-corrected, but at least I got to see the mainframe!\u201d He describes as \u201cpseudo-religious\u201d the experience of standing not just in the the machine room of UNIVAC 1, but inside its main memory, a little room consisting of a thousand words of memory implemented with mercury-filled acoustic delay lines. \u201cMy arrival at Brown is based on a nearly random sequence of happenstance events,\u201d says Andy. \u201cReading the magazine article was the second one. The first was an unplanned conversation that got me into computer science to begin with. I was a hard-core electronics engineer, with an offer from Bell Labs to go design transistor circuits. But I went to grad school to learn more about the field, and my officemate mentioned that there was a new course on computers: \u2018We both have electives, so how about this new Computers and Automata course??\u2019 Up until that point, I\u2019d only worked on analog computers, not digital ones, and I fell in love and switched my field. Over the years, and even now, as I interview new TAs, hundreds of people have shared similar experiences with me: taking a CS class at random, falling in love, and realizing for the first time what they want to do with their professional lives. It\u2019s many people\u2019s story, not just mine.\u201d The third random event was the one that brought Andy to Brown. \u201cReading that magazine,\u201d he says, \u201cled to teaching, and teaching led to a phone call three years later from a graduate of the summer program, James Castellan, who was then a student in Applied Math at Brown.\u201d Castellan called Andy after van Dam had all but accepted his first academic job elsewhere, asking if Andy knew that they were recruiting a CS person in what students called \u201cApple Math\u201d at the time. \u201cI don\u2019t know anything about Brown or Applied Math,\u201d Andy replied, adding that he\u2019d essentially already made his decision. Jim persisted, saying that Brown was the perfect place because of its emphasis on undergraduate teaching. \u201cI spent one day here,\u201d Andy says, \u201cand knew it was the right place because of their early history using computers in Applied Math and Engineering and especially because of the undergraduate emphasis.\u201d The clincher, he adds, was when the Chairman of Applied Mathematics excused himself in the middle of Andy\u2019s candidate interview to go teach a first-year course. Thinking Of Themselves As Computer Scientists Understanding the genesis of undergraduate teaching assistants and undergraduate research is impossible without seeing the context of specialization and the department\u2019s formation. Future articles will address this issue in depth, and be narrated by others, but these new roles for undergraduates were were born in what van Dam calls those \u201cworkaholic, all-consuming, frantic\u201d early days. \u201cFor some time,\u201d Andy says, \u201cthere had already been LISP and FORTRAN programming courses at Brown, but I was brought to Brown to create a formal computer science track within the Division of Applied Mathematics. Applied Math didn\u2019t see CS as something self-standing, but by the late \u201860s, after John Savage and Peter Wegner and several others came to Brown, undergraduates began thinking of themselves as computer scientists: your degree would say \u2018Applied Mathematics\u2019 on it, but effectively, you were a computer scientist.\u201d Andy, John, and Peter initially proposed a Center for Computer Science, but --amazing in retrospect-- the University\u2019s response to the proposal was negative, and so the three colleagues drafted a two-division program uniting CS-oriented faculty and courses from Applied Math and Engineering. In essence, it was a trial department, followed by the official establishment of the Brown CS Department. Andy was the Program Director and reported to both Division Chairs; in the final year of three, John served as Acting Director in his absence until Andy returned from his sabbatical at CERN and the University of Geneva in the summer of 1979 to become Chair of the new Department. When the time came to start a computer science degree program at all three levels (undergraduate, Master\u2019s, and PhD), competing universities were anything but amenable to the idea of undergraduate CS education. \u201cHere\u2019s the thing,\u201d van Dam explains. \u201cEven if we didn\u2019t call it that, Brown almost exclusively pioneered the idea of an undergraduate CS program, which our competitors said was premature specialization -- they thought students should wait to specialize in CS at the few grad schools that offered programs at that time.\u201d \u201cThe genesis of undergraduate participation in teaching and research has to be contextualized by the fact that in 1965, teaching computer science as a degree program, not just a few programming courses, to undergrads at all was novel. Teaching these various topics in computer science that were being taught at the graduate level elsewhere to undergraduates, even beginning undergraduates, worked at Brown because of the high quality of the students who were willing to be part of this \u2018total immersion\u2019 style of learning.\u201d \u201cOffering teaching and research assistant opportunities to undergrads,\u201d he says, \u201cwas even more unusual, indeed was viewed with everything from skepticism to outright hostility. Hardly anyone said, \u2018What a fantastic idea!\u2019 Everyone was used to four years of preparation as an undergraduate, then n years of graduate work before you could contribute to a science. But we\u2019re different. CS was and is young, experimental, and open for undergrads to contribute. And undergraduate participation in research in all fields has become commonplace, especially in the last decade.\u201d Born Of Necessity: The UTA Program In 1965, a single, intense full-year course could cover much of the breadth, if not the depth, of the systems-oriented portion of the discipline, not including theory, AI, numerical analysis, and a few other topics. Andy insisted that students couldn\u2019t learn to be good programmers by solving small \u201ctoy\u201d problems; they had to write significantly-sized programs, each taking multiple weeks. Not just checking for the right answer but giving useful feedback on structure, style, and efficiency required careful reading and one-on-one help with concepts and debugging. In a class with forty students, it was impossible for one graduate TA and a professor to provide this level of attention, no matter how little sleep they were getting, so van Dam asked for help from students who had taken a prior programming course. In that first cohort, he remembers Bill Adcock; Dan Bergeron, who also subsequently got his PhD with Andy and became Chairman of the CS Department at UNH and went with him and a group of six other of Andy\u2019s students for his first sabbatical in 1971 at the University of Nijmegen in Andy\u2019s country of origin; and Dennis Ruggles, among others. \u201cThe undergraduate teaching assistants,\u201d Andy explains, \u201cthough they were initially called graders, didn\u2019t just grade programs -- they not only provided one-on-one help to students but also became active participants in course design and in subsequent years read research papers and brought new ideas into the curriculum. In fact, they did everything graduate TAs did, becoming producers and not just consumers of education. We kept modifying the course as we went along, but the one constant was the highly-appreciated UTA system.\u201d Few people appreciate it more than Ed Lazowska \u201872, who will lead the first (\u201cStone Age\u201d) panel for Celebrate With Andy . He says, \u201cI\u2019m a faculty member precisely because of the UTA program. I went to grad school because Andy told me to. In some way, everything I do professionally today is due to him.\u201d To provide feedback for the course, students wrote detailed, multi-page evaluations, something that was almost unheard of in 1965. As Bob Munck recalls, \u201cAlso after every class, the graders would sit around on the floor of Andy's office (later my office) and critique the lecture and him. I'd never seen anything like it.\u201d On his commute home from work, Andy would listen to tape recordings of his lectures, filling the empty minutes with self-critiques: \u201cBoy, was that a clumsy explanation! Get rid of the \u2018um\u2019s and the \u2018you know\u2019s.\u201d Presentation skills are still something that van Dam is keenly interested in. \u201cToday\u2019s equivalent of \u2018you know\u2019 is \u2018like\u2019, which I try to stamp out in all students who work with me. I\u2019ve given up on \u2018awesome\u2019.\u201d An interesting aspect of the UTA program is that the system has essentially never been challenged by students due to the built-in checks and balances. \u201cBy having rotating TAs and detailed rubrics,\u201d Andy says, \u201cyou create fairness. It\u2019s a system that\u2019s at least as fair as having a single faculty member grading. Besides, a single faculty member, even assisted by a few graduate TAs, can\u2019t begin to read that many programs at the required level of detail, and students recognize that. Part of the checks and balances is that faculty members are responsible for assigning the final grades, and I personally review all borderline grades, hoping to find evidence for promotion to the next grade bin.\u201d Originally something made up as they went along, the UTA program matured over a period of decades. Iteration and gradual regularization brought cross-course norms and standards that are used today by almost all Brown CS courses. \u201cIn my opinion,\u201d says Andy, \u201cWe have the most systemic TA program, and there\u2019s a well-defined appeal system in place to address any grading errors.\u201d In some classes, van Dam explains, even PhD students are in a course with undergraduate TAs, but it works: for a particular topic, in a particular course, the younger student knows more. He drops his voice an octave to imitate a disbelieving critic. \u201cUndergrads grading grad students? How can that work?\u201d His own warm bark of a laugh is flung out with the response: \u201cJust fine -- in fifty years, I\u2019ve never had a complaint from a grad student! They respect competence as much as I do.\u201d Fearless, Ambitious: Undergraduate Research After undergraduates had successfully assisted with teaching, the logical next step was assisting with research; the logical choice of accommodation for a research team was a shared room. If these conclusions seem obvious, listen to Andy\u2019s description of what happened: \u201cApplied Math had never seen anything like it! The biggest room in the building as this nerve center, six hundred square feet for me and an admin and four or five student researchers, going in and out at all hours of the night. They saw us as these unwashed hippie kids, loud adolescents -- how could they possibly do research?\u201d \u201cWe occupied the entire basement, too,\u201d says Ed, \u201cdozens of desks, cheek-to-jowl. What really drove the Applied Math faculty crazy is that we were constantly running from the basement to the third floor. We had weekly project meetings in Andy's office, lined with bookshelves and filing cabinets surrounding the desks, where several dozen students would cram in, with no room to breathe.\u201d \u201cThe schleps, as we called them,\u201d Andy continues, \u201cwere a group of more than a dozen undergraduates apprenticing in the group who contributed in every capacity, from getting lunch to reading research papers and explaining them to me to see if they were usable in class. They worked with a few Master\u2019s and PhD students, including the late Charles Strauss, Dan Bergeron, and Jim Michener, among others. The bullpen was noisily chaotic, but we were young, and kids have powers of concentration that adults don\u2019t. The best part was the selective eavesdropping and peripheral conversations, learning by accident from the people around you. My graphics group still works that way: we strongly encourage everyone to be in the graphics lab together multiple nights per week.\u201d \u201cResulting in at least five geek-geek marriages,\u201d notes Bob Munck, crediting the fact that women were fully equal contributors in Andy\u2019s group from the beginning. These were the days in which the IBM /360 Model 50, which started with 256KB of memory and no disks and was upgraded to 512KB and a disk array, served the entire university. Normally, users keypunched their programs on decks of \u201cIBM cards\u201d and submitted jobs that were processed in batches, many hours later. Andy\u2019s group, doing graphics research on their IBM 2250 display (courtesy of an IBM research grant), were allowed small chunks of time during third shift to debug their programs, where an occasional crash that brought down the mainframe was reluctantly tolerated by the operators. Stories of how Andy and company were at times dilatory with food and candy wrapper disposal, how they allowed dogs (and therefore, without putting too fine a point on it, the things dogs do) into the machine room, and how they bought far more Girl Scout cookies than were strictly necessary from \u201cBig Grace\u201d, the head operator, are better left for Celebrate With Andy . At the time, these quarter-of-a-million-dollar displays (in 1967 dollars: close to two million in today\u2019s money) were rare indeed, and letting undergraduates have access to them was even rarer. With Brown\u2019s acquisition of the 360/67, Andy\u2019s group became one of the earliest users of virtual memory and virtual machine-based time-sharing. \u201cAmong the many firsts,\u201d Andy explains, \u201cBob Munck and other students built time-sharing systems to run in a partition of the OS on the 360/50. Even before his graduation, Bob took the highly unusual step of teaching portions of my courses, on assembly language and other systems topics.\u201d \u201cSteve Carmody was another student in my first course in 1965, and is still associated with CIS at Brown. He was a leader in the group project to design and implement the first hypertext system on commercial equipment in 1967, the Hypertext Editing System (HES). HES was co-designed with Ted Nelson, coiner of the term \u2018hypertext\u2019. HES was followed by FRESS (File Retrieval and Editing System), which was an active project for more than a decade, starting in 1968. Many undergraduates contributed to its design and implementation, including the late Bob Wallace, who was one of the seven original founders of Microsoft and the inventor of shareware with his utility, PC-Write.\u201d As part of the LSD (Language for Systems Development) project to define a systems programming language and create an optimizing compiler for it, led by Dan Bergeron as a PhD student, Andy recalls the thrill of having exclusive access to some highly sought-after IBM software. \u201cWe were using a proprietary systems dialect of the standard language, PL/I, called PL/S,\u201d he says. \u201cIt was never used by anyone else outside the company, and even years later, I\u2019d get calls from people within IBM, wondering if I could tell them about this mysterious language that they\u2019d heard about but weren\u2019t able to get a hold of.\u201d \u201cWe were also among the very first to do simple distributed computing by attaching graphics mini-computers to a mainframe. The late George Stabler and Rick Harrington,\u201d Andy adds, \u201ca PhD student and undergraduate, respectively, designed, implemented, and published the first remote procedure call (RPC) protocol to allow code modules on the graphics satellite and code modules on the mainframe to call each other, and even to let code migrate to do load balancing from one to the other, at least a decade before other organizations reinvented the idea of RPC. To make our microprogrammed multiprocessor graphics satellite even more real-time, undergraduate Hal Webber designed and built the first high-performance, microprogrammable 3D and 4D homogeneous coordinate transformation engine, SIMALE, now part of our Computer Museum. PhD student Jack Stankovic, who became the Department Chair at UVA, and I ran the first workshops on distributed computing in the 1970\u2019s.\u201d \u201cThe whole idea about being a research assistant,\u201d says Ed Lazowska, \u201cwas that Andy asked us to figure out how to do things that hadn\u2019t been done before. It was the first time that someone had treated me as an intellectual peer and showed confidence that I could do the tasks that adults could do. The whole group was remarkable, and Andy and Charles had an extraordinary impact on me. They totally captured my imagination.\u201d Even the briefest look at Strauss\u2019s research gives a powerful sense of the time. For the first time, his work with a light pen and specially-designed stereoscope that fused left and right images on a split screen allowed the user to navigate a live, 3D stereo representation of the layout of pipes in an oil refinery, helping identify potential interference between pipes. For the computer user of today, the world in which mainframes rented for tens of thousands of dollars per month is scarcely thinkable. Looking that many decades into the past, we might be impressed to find graphics of any kind, even 2D. Yet in this case, 2D wasn\u2019t sufficient, and neither was static 3D: Brown had to pioneer not just 3D graphics but interactive 3D stereo motion graphics to provide the functionality required. Working with Professor Tom Banchoff of the Math Department, Charles was the first to provide real-time manipulation and visualization of M\u00f6bius strips and 4D geometry: hypercubes and hyper tori. \u201cBanchoff-Straus Productions\u201d continued for decades and produced impactful movies of manipulations of 4D geometry, which were greatly aided by Hal Webber\u2019s SIMALE. \u201cUp until this point, computers were used almost entirely for crunching numbers, and computers with graphics were for oil companies and car and airplane manufacturers,\u201d says Ed, whose Brown independent concentration was titled \u201cNon-Numerical Computer Science\u201d. \u201cWith HES and FRESS, we were working with text! Not just text, but WYSIWYG hypertext. It wasn\u2019t until that point,\u201d says Ed, \u201cthat you could actually put the word \u2018personal\u2019 in front of the word \u2018computer,\u2019 although our PC was a multi-million dollar mainframe. That\u2019s all Andy.\u201d Andy shrugs. \u201cWe were just fearless, we had ambitious ideas, didn\u2019t really know what was possible and what was not. I had all those smart and highly motivated kids available, so we took wild, crazy ideas and ran with them.\u201d Creative Expression What\u2019s the common link between undergraduate teaching assistants and undergraduate researchers? \u201cCreating knowledge,\u201d says Ed, \u201cnot absorbing knowledge. Creativity. Teaching and research both need this in spades.\u201d Janete Perez \u201806, who will lead the third (\u201cMachine Age\u201d) panel at Celebrate With Andy , says, \u201cI wanted to be a UTA like high schoolers want to be on the varsity football team...To add to a class, make it more fun, be part of it all...Andy finds the kids that are really excited, not just the straight-A students. He teaches you to work hard and be disciplined, but really to be creative.\u201d Interestingly, van Dam\u2019s thoughts move in a similar line when asked about the theme of his life\u2019s work: \u201cFrom the time I saw Sutherland\u2019s mind-blowing Sketchpad movie in \u201864, I\u2019ve loved human-computer interaction and the visual; I really value creative expression in various media.\u201d \u201cWatching the Sketchpad movie,\u201d he says, \u201cwas another random event that changed my life forever. At the time, computing was done by entering programs and data via punch cards or teletype tape. Programs were run in batches and dealt with numeric data. Sutherland showed the world interactivity, humans working with computers in real-time, and he showed us communicating through drawing and manipulating images directly. It was beyond revolutionary, and like the other random events, it ended up completely determining my career. When advisees come to me obsessed with making a commitment to one research area, I tell them to relax: \u2018You\u2019re going to experience ideas that\u2019ll change your point of view. Be open, experiment, try different things. You\u2019ll change your mind a half-dozen times.\u2019 It was true then and it\u2019s a hundred times more true now.\u201d But back then or now, what could be a taller order than trying to foster creativity? After hundreds of thousands of years of human history, our understanding of our creative powers is still incomplete. But let\u2019s try. Ed shares a visual from the height of the late 60\u2019s hippie era that we\u2019ll return to later: driving in a Volkswagen bus in mid-winter to northern Virginia, where the group programmed a special version of FRESS for a 3-lettered federal agency while locked in a Faraday cage and monitored by armed guards when they went to the bathroom. \u201cThere was no working heater in the bus (of course),\u201d adds Steve Carmody, \u201cso for the entire trip people took turns sitting atop a multi-platter disk, trying to keep it warmer than the frigid air inside the bus.\u201d Now let\u2019s try to press Andy again for the secret of bringing out people\u2019s creativity. Asked for heroes of the recent past, he divides them into those outside his field (Einstein, Feynman, Gandhi, King, Mandela) and those inside: Engelbart, Turing, von Neumann, Maurice Wilkes. \u201cDouglas Engelbart was just amazing, but he unfortunately never had the direct impact he should have had...he had trouble explaining his vision, and sadly is only remembered for inventing the mouse, probably the least important of his huge number of inventions in the oNLine System, NLS, from which so many of our modern ideas of word- and idea-processors derive.\u201d Hearing that, anyone who has known van Dam for five minutes is going to think the same thing: Andy doesn\u2019t have a problem explaining or sharing his vision . Whether it was inspiring Janete and her peer UTAs to create elaborate skits for CS15 class with classically-trained musicians playing instruments, or getting a bunch of tie-dyed rebels to bring peace and love into the fortress of unsmiling agents, Andy van Dam fosters creativity through personal connection. \u201cStudents relate to him,\u201d Janete says. \u201cMore than fifty years younger, they relate to him because he relates to who they are.\u201d \u201cAndy believes in the power of young students,\u201d adds Ed. \u201cHe taught me that impact and excellence are a multidimensional quantity...we can\u2019t hire or admit people or motivate them to do great work through just one lens.\u201d When we ask Andy about a common theme for both undergraduate teaching assistants and researchers, there\u2019s a long pause. \u201cThe idea that you can do serious work before the PhD is almost unique to CS,\u201d he says. \u201cWe did it fifty years ago, and it\u2019s true to a fare-thee-well today...it\u2019s about skilled and creative analysis and synthesis; I try to create a productive, challenging but nurturing environment for creatives to make things that are, to use the Jobs phrase, insanely great .\u201d Responsibility, Then And Now Norm Meyrowitz \u201881, who will lead the second (\u201cIron Age\u201d) panel at Celebrate With Andy , also believes that giving responsibility to young students was (and is) key. \u201cWe were seventeen, eighteen, nineteen, creating all the assignments for an entire class. I was a junior, writing a windows manager program, a twenty-year-old with other twenty-year-olds presenting our research to the NSF.\u201d Did this seem strange at the time? \u201cIt just felt like something we were supposed to do!\u201d Norm replies. \u201cRemember, the only PC then was the Apple II: there were no mice, no graphics, no hypertext in general use. There were thousands of areas that nobody had started researching yet, so it was exciting. So Andy, Bill Shipp [then Vice-Provost of Computing and a professor of biology], and I --at the ripe old age of 23!-- raised 17 million dollars to put hundreds of graphical workstations on campus. The workstation effort led to the development of the Intermedia hypermedia system --which looked like the Web and worked on a LAN in 1985-- by me along with many of Andy's former students. Andy gave us incredible responsibility as undergrads, and that bred confidence in future endeavors.\u201d Their confidence was clearly justified: the third extant HTML message ever created, by Tim Berners-Lee for his own research team, was about Intermedia. Responsibility and confidence are both in full view at a January, 2015 meeting of Andy\u2019s group in the CIT Library. Students and researchers sit at a long table with their laptops, tablets, and smartphones; their mentor is leaning back in a chair, dressed in familiar sweater-over-the-shoulders style with arms crossed. His laptop (a ThinkPad touch tablet) is closed, and his smartphone only emerges for a momentary calendar check. \u201cThe batch inputter is going pretty well,\u201d says a student. Andy\u2019s eyes narrow a little as he grins. \u201cDid I hear \u2018pretty well\u2019 or \u2018very well\u2019 in there?\u201d \u201cWe\u2019re working on the user interface, but we haven\u2019t caught the edge cases yet. We\u2019ll be done by end of day, then test.\u201d \u201cNo more guesswork,\u201d says Andy on another feature. \u201cWe may have to take over these transactions ourselves.\u201d The atmosphere in the room is immediately recognizable to anyone who has worked in a production environment, in the technology sector, or in any setting where efficiency matters. The students are obstacle-oriented, focused, going back and forth seamlessly. Andy lets them converse, answering each other\u2019s questions and asking for clarification when necessary. The sophistication of the students could be envied by professionals twice their age, and it\u2019s mirrored in the vocabulary that van Dam uses in his comments: bona fides , rubric , interregnum , kibbitz . Later, he\u2019ll credit this to \u201cgrowing up surrounded by people who use language well\u201d and not being a native speaker of English, but the fact remains: this is the way that someone addresses responsible peers, not children. For the hearer, confidence follows naturally. After an impromptu test of a new feature on an Android tablet works better than expected, the table explodes in cheers: \u201cYay!...Wow!...Show that again!\u201d \u201cSee you next week,\u201d Andy says at the end. \u201cSame bat time, same bat station.\u201d Getting It Done \u201cFifty years later,\u201d Ed says, \u201cevery generation tells the same stories.\u201d \u201cAndy always said that we\u2019re here to make the future happen,\u201d Norm adds. \u201cResearch is a byproduct of having a vision of the future and sharing it through teaching, instilling it in generation after generation. Research is just those people making the vision happen, getting it done...As teaching assistants or researchers, everyone from first-years to PhD students, Andy had us think of ourselves as a collaborative troupe spanning the generations. Every day, we put on a show and did our best. After you leave Brown, the troupe still exists for you in the community, the camaraderie.\u201d Celebrate With Andy is only one night, but it carries a thank-you that doesn\u2019t end to Andy and everybody else for our past half-century. The troupe goes on, making the future happen.", "https://cs.brown.edu/news/2015/06/01/watch-video-celebrate-andy-50-years-cs-brown/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Watch Video From Celebrate With Andy: 50 Years Of CS At Brown Posted by Jesse Polhemus on June 1, 2015 On Friday, May 22, 2015, the Brown CS family gathered in Pizzitola Sports Center to celebrate three golden anniversaries: the Undergraduate Teaching Assistant program, undergraduate participation in research, and Andy van Dam at Brown. The tributes and reminiscences were insightful, heartfelt, eloquent, and often extremely funny. You can watch a full video of the formal program here .", "https://cs.brown.edu/news/2015/06/22/dazzling-boston-globe-attends-yurts-launch-and-inaugural-symposium/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) \"Dazzling\": The Boston Globe Attends The Yurt's Launch And Inaugural Symposium Posted by Jesse Polhemus on June 22, 2015 For more CS News and CS Blog articles about the Yurt, please click here . The June 20, 2015 edition of the Boston Globe includes a front-page story on Brown University 's new fully immersive 3D virtual reality environment, the Yurt. Reporting from the symposium that marked the Yurt's launch, Amanda Katz describes the rise of VR as a medium, the Yurt's remarkable technical achievements, and the hope of its creators, led by Professor David Laidlaw of Brown Computer Science , to accelerate science and discover new uses for cutting-edge virtual reality. The entire article is available here .", "https://cs.brown.edu/news/2015/09/30/brown-cs-introductory-course-enrollment-sets-records/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Brown CS Introductory Course Enrollment Sets Records Posted by Jesse Polhemus on Sept. 30, 2015 To read more stories about the Brown CS department's increasing enrollment click here . Enrollment in Brown Computer Science\u2019s core introductory courses is continuing to accelerate year after year: In the past year alone, CS 015 (Introduction to Object-Oriented Programming and Computer Science) has seen 20% growth, arriving at a record-setting 391 students. At this time four years ago, CS 017 (CS: An Integrated Introduction) had 154 students enrolled. Currently, it\u2019s 214, an increase of more than 38%. Final enrollment of CS 019 (Accelerated Introduction to Computer Science) has more than doubled over the past four years, rising from 27 to 60 students. What can we derive from these statistics? Among other conclusions, the parallel growth of all three courses suggests that Brown CS has successfully answered growing interest in our field by establishing multiple entrances that allow for varied definitions of computer science and its many uses.", "https://cs.brown.edu/news/2015/09/30/enrollment-soars-1-5-students-taking-brown-cs-course/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Enrollment Soars: 1 In 5 Students Is Taking A Brown CS Course Posted by Jesse Polhemus on Sept. 30, 2015 To read more stories about the Brown CS department's increasing enrollment click here . As enrollment in Brown CS courses continues to accelerate, a few statistics help give a sense of the tremendous year-on-year growth: One in six Brown undergraduates took a CS course last year. This year, it's one in five. Not only have total enrollments increased by 990 students in the past four years, more than 40% of that growth was in the last year alone. Individual courses also show remarkable expansion: CS 33 (formerly CS 31) has increased from 128 to 286 students in four years, more than doubling its enrollment CS 15 has grown by more than 20% just in the past year, reaching a record-setting 391 students. CS 1300 had 52 students two years ago, then 160 students last year. This year, it has 293.", "https://cs.brown.edu/news/2015/10/07/mace-roelke-and-fonseca-win-best-paper-award-sosp-2015/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Mace, Roelke, And Fonseca Win A Best Paper Award At SOSP 2015 Posted by Jesse Polhemus on Oct. 7, 2015 in Awards Brown University Computer Science (Brown CS) PhD Candidate Jonathan Mace , Ryan Roelke '15 (now at Vertica), and Brown CS Assistant Professor Rodrigo Fonseca have just received one of three Best Paper Awards at the 25th Association for Computing Machinery (ACM) Symposium on Operating Systems Principles (SOSP 2015), currently being held in Monterey, California. SOSP is often considered the leading forum for researchers and developers of computer operating systems, and their research compared favorably with more than two dozen entries selected from over 300 global submissions, covering a wide range of theory and practice. Jonathan, Ryan, and Rodrigo\u2019s work (\u201c Pivot Tracing: Dynamic Causal Monitoring for Distributed Systems \u201d) addresses the challenge of monitoring and troubleshooting distributing systems with a monitoring framework that combines techniques from both the dynamic instrumentation and causal tracing literature. Pivot Tracing gives users, at runtime, the ability to define arbitrary metrics at one point of the system, while being able to select, alter, and group by events meaningful at other parts of the system, even when crossing component or machine boundaries. The result is a dynamic and extensible solution that enables cross-tier analysis between inter-operating applications with low execution overhead. \"This is the first framework we are aware of,\u201d Rodrigo says, \u201cthat allows you to ask questions about a system as it runs, while causally combining metrics across its distributed components.\"", "https://cs.brown.edu/news/2015/10/13/erik-sudderth-and-collaborators-advance-seismic-monitoring-and-nuclear-non-proliferation-earning-top-prize-bayesian-analysis/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Erik Sudderth And Collaborators Advance Seismic Monitoring And Nuclear Non-Proliferation, Earning A Top Prize In Bayesian Analysis Posted by Jesse Polhemus on Oct. 13, 2015 in Awards Few things are less abstract than an earthquake or more important than nuclear non-proliferation, and one of the top awards in Bayesian analysis highlights how complex statistical models can be used to solve problems that go far beyond theory. The International Society for Bayesian Analysis (ISBA, which sponsors leading journals and conferences) presents the Mitchell Prize in annual recognition of an outstanding paper that uses Bayesian analysis to solve an important applied problem. This year, Professor Erik Sudderth of Brown University \u2019s Computer Science Department and his collaborators (Professor Stuart Russell of University of California, Berkeley and Nimar S. Arora of Bayesian Logic, Inc. and BetaZi) have received the award for their research in seismic monitoring. Their work (\u201c NET-VISA: Network Processing Vertically Integrated Seismic Analysis \u201d), which was also highlighted (\u201c Global Seismic Monitoring: A Bayesian Approach \u201d) at the Twenty-Fifth Conference on Artificial Intelligence (AAAI-11), involves automated processing of multiple seismic signals, a central problem in both geophysics and nuclear treaty verification. \u201cAround the globe,\u201d Erik explains, \u201cone of the most important mechanisms for nuclear non-proliferation is the global sensor network that identifies seismic events and their locations. As part of the Comprehensive Nuclear Test Ban Treaty, it\u2019s a key tool to ensure that nuclear weapons aren\u2019t being tested. Unfortunately, identifying true seismic events at a global scale is a complex task. Our Bayesian seismic monitoring system rigorously models geophysical uncertainty to avoid missed events. In the end, we reduce them by 60% compared to a highly advanced baseline system, and we even find events missed by expert human analysts. As worldwide interest in mitigating the risks of nuclear proliferation grows, improving the accuracy of seismic signal processing becomes more urgent every day. We\u2019re tremendously proud to use statistical machine learning to contribute to an area of global importance.\u201d", "https://cs.brown.edu/news/2015/12/11/stefanie-tellex-and-john-oberlins-award-winning-video-earns-brown-cs-new-baxter-robot/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Stefanie Tellex And John Oberlin's Award-Winning Video Earns Brown CS A New Baxter Robot Posted by Jesse Polhemus on Dec. 11, 2015 by Kevin Stacey (Science News Officer, Physical Sciences) Brown University \u2019s Humans to Robots Lab is about to get a new robot, thanks to Stefanie Tellex\u2019s video-making skills. Tellex, assistant professor of computer science and the lab\u2019s principal investigator, entered the Rethink Robotics Video Challenge. The Boston-based company asked users of its \u201cBaxter\u201d robot to submit videos showing Baxter solving real-world problems, whether in research, manufacturing, or education. Tellex took first place (with a little help from the band AC/DC and graduate student John Oberlin) for her video about teaching Baxter to manipulate objects from experience. The grand prize: A spanking new Baxter \u2014 the lab\u2019s third \u2014 is on its way from Rethink. On a factory floor, robots do a great job of picking up and manipulating objects that they\u2019ve been programmed to handle. However, picking up objects that they\u2019ve never encountered before can be a big problem for even the most sophisticated robots. Tellex has developed an algorithm that enables Baxter to learn how to pick up new objects by repeatedly trying (and often failing) to do so. Over time, the robot learns how best to pick up the object, and can do so successfully on future attempts. \u201cAt night or on weekends, Baxters are just sitting there in labs doing nothing,\u201d Tellex said. \u201cIf we could get all 300 research Baxters working on this during what would normally be down time, we could reach our goal of a million objects in only about 11 days.\u201dTellex is hoping to recruit other researchers who use Baxters users to scan objects as well. She\u2019s calls it the Million Object Challenge . Tellex\u2019s work has been the subject of recent stories on National Public Radio and in MIT Technology Review .", "https://cs.brown.edu/news/2015/11/06/touch-art-gallery-tag-continues-global-expansion-nobel-museumnobel-mediamicrosoft-collaboration/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Touch Art Gallery (TAG) Expands Worldwide With A Nobel Museum/Nobel Media Collaboration Posted by Jesse Polhemus on Nov. 6, 2015 Brown University 's Department of Computer Science (Brown CS) today announces a major milestone for the Touch Art Gallery (TAG) project, one of the most visible recent successes of the department's undergraduate research program. Working under the direction of Professor Andy van Dam , a group of entirely undergraduate researchers in the Graphics Lab has demonstrated the power of technology to enhance research and learning with two state-of-the-art museum experiences that focus on Alfred Nobel's final Will and the 900 Nobel laureates to date. The experiences, a collaboration between Brown University, the Nobel Museum, and Nobel Media, use a uniquely compelling form of interaction to give new life to documents that hold a significant place in human history. They debut in Singapore on November 7 during the two-day \"Future of Learning\" Nobel Media Conference at Nanyang Technological University, but enthusiastic news coverage has already begun, with Channel NewsAsia devoting a television news segment to these \"ideas that changed the world\". TAG is sponsored by Microsoft, and the experiences are hosted on two 82-inch Microsoft touch displays, a 55-inch touch display, and six smaller Surface touch tablets. They'll be housed at the ArtScience Museum in Singapore for the next three months, where they're projected to be seen by thousands of visitors. Afterward, the experiences will be incorporated into a larger traveling exhibit by the Nobel Museum. From the start of the project, students in their earliest years of higher education have made contributions that rival the efforts of far more experienced peers in the technology sector. Both experiences were tested by some fifty undergraduate students at Brown, many of them from van Dam's introductory Java programming class. The testing sessions provided valuable feedback on user interaction with the experiences, and many design decisions were fine-tuned after the user studies. The current TAG team leader, Trent Green, traveled to Singapore to oversee the exhibit's installation, interacting with multiple Nobel laureates while still a sophmore. The first of the experiences focuses on Alfred Nobel's final Will, in which he set aside part of his fortune to fund annual prizes for the top global researchers and practitioners in the fields of physics, chemistry, literature, physiology and medicine, and peace. It uses a digital scan of the hand-written Will as its anchor, using key words and phrases in the document to tell the story of Nobel's life as an inventor and industrialist as well as the establishment of the Nobel Foundation after his death. From the Will interface, visitors can link to related collections of high-resolution images, which can be explored in depth via pan and pinch-zoom gestures that are familiar to any smart phone user. They can also watch \"interactive tours\", which combine audio narration as well as panning and zooming images. Unlike traditional videos, the tours can be paused at any time to allow touch interaction with the visual elements on screen. For many of the images, additional information is also provided to viewers via a sidebar. The second experience focuses on the 900 laureates who have won Nobel Prizes since the first award ceremony in 1901, the most recent of whom were announced this October and will be honored this December. Images of the laureates are displayed in a grid on screen and can be filtered via combined queries over prize category, gender, and decade filters and also searched by name or other metadata fields such as country of origin. Touching a laureate's image launches a pop-up with more information about the contributions that led to their Nobel Prize recognition. \"It's been exciting for us to work on a project that will have such high visibility,\" says Lucy van Kleunen, the previous undergraduate TAG team leader. \"Designing large display touch exhibits has also been an instructive research experience in user interface and experience design for a large screen form-factor.\"", "https://cs.brown.edu/news/2016/03/07/bootstrap-plays-key-role-cs4ri-expansion-cs-education-rhode-island/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Bootstrap Plays A Key Role In CS4RI Expansion Of CS Education In Rhode Island Posted by Jesse Polhemus on March 7, 2016 Bootstrap is a computer science literacy curriculum used by 10,000 students in 17 states and five countries whose founders include two Brown CS faculty members, Kathi Fisler (adjunct) and Shriram Krishnamurthi . Starting today, it's playing a key role in the new Computer Science for Rhode Island (CS4RI) effort, which brings together a coalition of partners to offer low or no-cost options for K-12 schools to expand CS education. \"Bootstrap is excited to partner with Governor Raimondo's team to enrich math and computing education for students across Rhode Island,\" says Shriram. \"The CS4RI initiative will get students computing creatively and thriving mathematically so that they graduate high school prepared with skills that matter.\" CS4RI is among the most comprehensive statewide computer science initiatives in the country, and it takes a coalition approach by combining national leadership with homegrown talent to reduce barriers to providing quality computer science education and professional development. Its goal is to have CS taught in every public school in Rhode Island by December, 2017. \"Brown is proud,\" says President Christina Paxson, \"to be a part of a project that positions Rhode Island as a leader in efforts to bring computer science education to students statewide. The Bootstrap curriculum, developed in part by Brown faculty, teaches essential skills that can propel students toward fields with significant opportunities in tomorrow's world. It\u2019s exciting that Bootstrap will be part of this initiative, which is so important for our state, and I thank Governor Raimondo and her team for their work.\"", "https://cs.brown.edu/news/2015/12/15/brown-cs-announces-10000-randy-f-pausch-82-computer-science-undergraduate-summer-research-award/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Brown CS Announces The $10,000 Randy F. Pausch '82 Computer Science Undergraduate Summer Research Award Posted by Jesse Polhemus on Dec. 15, 2015 Brown University 's Department of Computer Science (Brown CS) is glad to announce a significant milestone in the continued growth of our undergraduate research program. A generous gift from Peter Norvig '78 has established the Randy F. Pausch '82 Computer Science Undergraduate Summer Research Award, which provides $10,000 annually to support an undergraduate engaged in an intensive faculty-student summer research partnership at Brown CS. Norvig, now a Director of Research at Google and a thought leader in the areas of artificial intelligence, natural language processing, information retrieval, and software engineering, was drawn to Brown as an undergraduate by the open curriculum and his interests in computer science and linguistics, which he studied in high school. \"Computer science seemed much simpler then,\" he says. \"We went slower, and we had the advantage of being able to cover the entire field. But if you wanted a piece of software, you usually had to write it yourself.\" His gift honors the life and work of Randy F. Pausch '82, a renowned expert in computer science, human-computer interaction, and design who died of complications from pancreatic cancer in 2008 and whose \"Last Lecture\" has been widely praised. \"I didn't know Randy when I was at Brown,\" Peter says, \"but we met afterward and corresponded for many years. His story is inspiring, and this is an opportunity to remember him.\" Norvig sees this award as a \"multiplier\" that will amplify the value of his gift and extend it through time. \"I'm interested in students with a wide range of personalities and interests,\" he says, \"and in putting students and faculty together. In the past, we had to build all our own tools, and we didn't have time to combine computer science with other fields. Now, there are so many opportunities to do so. I think it's a wise choice: you invest in things that you think will do good, and educating a student allows them to help add to the things that you're already trying to accomplish.\" \"This is a prestigious award,\" says Department Chair Ugur \u00c7etintemel, \"It's the first of its kind, and we hope it inspires many others. It's going to fund one of our exceptional students whose work reflects the high standards and values for which Randy was recognized. We're truly grateful to Peter for honoring Randy's life and accomplishments by creating this lasting research opportunity for our best and brightest.\" To apply, no later than February 15, 2016, students should email Associate Professor (Research) and Vice Chair Tom Doeppner either: (A) a copy of their summer UTRA application or (B) a two-page description of their proposed research and a letter of support from the Brown CS faculty member they intend to work with. For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "https://cs.brown.edu/news/2018/06/06/shriram-krishnamurthi-wins-sigsoft-influential-educator-award/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Shriram Krishnamurthi Wins The SIGSOFT Influential Educator Award Posted by Jesse Polhemus on June 6, 2018 in Awards Click the links that follow for more news items about awards won by Brown CS faculty and Shriram Krishnamurthi . Professor Shriram Krishnamurthi of Brown University 's Department of Computer Science (Brown CS) has just received the SIGSOFT Influential Educator Award. Presented annually, it's given to an educator or educators who have made significant contributions to, and impact on, the field of software engineering through accomplishments as teachers, mentors, researchers (in education or learning), authors, and/or policy makers. In particular, the award committee noted Shriram's contributions to the advancement of the research and practice of software engineering. The award is international recognition of continued strength in education at Brown CS, and it follows recent awards for three faculty members and one PhD student that highlight campus-wide recognition of the Department's teaching excellence. It comes less than halfway into a busy year in which Shriram has already given keynote addresses at Programming 2018 and elsewhere , written a cover story for Communications of the ACM , and been appointed to co-lead the CACM Research Highlights Editorial Board . With this win, he joins Brown alum Barbara Ryder and the late David Notkin, a Brown CS alum, who won the prestigious award in 2015 and 2012, respectively. The full list of winners dating back to 2009 is available here . For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://cs.brown.edu/news/2018/08/02/tellexs-outreach-inspires-high-school-student-study-robotics-then-teach/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Tellex's Outreach Inspires A High School Student To Study CS, Then Teach Posted by Jesse Polhemus on Aug. 2, 2018 Click the link that follows for more news about Brown CS outreach and Stefanie Tellex . \"These are kids who would never have seen a real robotics lab otherwise,\" says Annalisa Marchessault, Pre-Engineering Instructor at Providence Career and Technical Academy (PCTA), one of New England's premier technical high schools. \"Many of them don't even realize the magnitude of what Stefanie has done for them.\" She's talking about Professor Stefanie Tellex of Brown University 's Department of Computer Science (Brown CS), whose four-year outreach effort with the school's students has produced some inspiring results. Jose Toribio, one of the program's alums, is not only studying robotics but helping teach it to the next generation of students. Now almost a decade old, Providence Career and Technical Academy allows students to choose a particular area of technology and then pursue their studies with a mix of internships and classwork. Computer science has always been a popular subject, and four years ago, Annalisa's predecessor approached Stefanie with a request that Tellex share her robotics work with PCTA students in the Engineering program. The response was surprising: along with giving a talk, Tellex invited students to come and work with drones and robots in her Humans To Robots lab during the summer. \"What makes Stefanie amazing is that she's so approachable,\" Annalisa says. \"She reaches out, she wants everyone to learn, and nothing could have been better than giving our kids an opportunity to learn like this locally, working alongside Brown students.\" Jose Toribio was part of Stefanie's second cohort. For someone with a lifelong interest in computers, the Humans To Robots lab was filled with exciting possibilities. He says, \"I liked how open the program was. If I came up with an idea, everyone was ready to think about how it could be achieved.\" Jose mentions that giving public demonstrations of drones he'd built with fellow students was one of the things he enjoyed most. (One of his demos was recently seen by Richard M. Locke, Brown's Provost.) \"At one of them,\" he remembers, \"I met someone from Google who was from Providence, someone just like us. It was really exciting to feel that connection to her.\" Maybe part of the excitement was because Jose was beginning to think about being a role model himself. After completing his second summer with Stefanie's lab, he ran the program for the five juniors and seniors who joined the following year, and accepted Annalisa's offer to serve as PCTA's Robotics Coach. This summer, he taught a high school course as part of Summer@Brown and mentored two high school students doing paid internships with Stefanie's lab. \"It's wonderful to see Jose's eagerness to share knowledge,\" Stefanie says. \"He's the sort of person that when he first came into the lab, he immediately started showing another high school student how to solder. PCTA students have been a strong asset in hardware design and creating documentation for the course for the high school level. I'm excited to continue working with them as our project grows!\" Now studying computer science at Rhode Island College, Jose says that it's a chance to revisit the important high school years that passed by so quickly: \"It's incredible to see the next generation of students doing what I did. I love being able to share my experience and show them different ways to look at an experiment.\" When he graduates, he's hoping to move to a bigger city and continue his engineering work, particularly in the area of robotic vision. \"I just want to thank Stefanie and Annalisa,\" Jose says. \"Without them, I might be programming, but I'd never have had this chance to work up close with robots.\" Annalisa expects that there are big things in store for him. \"Two of the most amazing things about this program,\" she says, \"are Jose and Stefanie themselves. For kids in Jose's position, seeing how he wanted to go and learn, then come back and volunteer, is the coolest thing. He's someone like them, so they feel comfortable, and they see that everything he's done is attainable for them. And Stefanie doesn't have to do what she does, but she always makes the time. Thanks to her, these kids have seen possibilities for their lives that they'd never known about.\" For more information, click the link that follows to contact Brown CS Communication Outre ach Specialist Jesse C. Polhemus .", "https://cs.brown.edu/news/2018/09/14/andy-van-dam-has-been-named-siggraph-academy-contributions-computer-graphics/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Andy Van Dam Has Been Named To The SIGGRAPH Academy For Contributions To Computer Graphics Posted by Rujul Singh on Sept. 14, 2018 in Awards Click the links that follow for more news about Andy van Dam and recent awards won by Brown CS faculty members SIGGRAPH, a special interest group for the Association for Computing Machinery, is one of the world\u2019s largest communities of researchers, artists, developers, and filmmakers dedicated to the advancement of computer graphics and interactive techniques. Their Awards Committee has recently announced that Professor Andy van Dam of Brown University\u2019s Department of Computer Science (Brown CS) has been named to the ACM SIGGRAPH Academy, an honorary group of individuals known for contributions to the field of computer graphics as well as impact through research directives and innovations. \"It's a great honor to be in the first class of inductees into the SIGGRAPH Academy. When in 1967 I co-founded SICGRAPH, the precursor to SIGGRAPH, computer graphics wasn't even recognized as a specialty within the then new field of CS, and now SIGGRAPH is the dominant Special Interest Group in ACM, running the largest annual conference. And the Visual Computing Group in our department has six faculty and a senior lecturer, as many people as founded our department in 1979!\", he says. Already recognized by the ACM as a pioneer in the field of graphics (previously winning the ACM Karl V. Karlstrom Outstanding Educator Award, and the ACM SIGGRAPH Steven A. Coons Award), Andy continues to innovate in the computer graphics realm. For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus", "https://cs.brown.edu/news/2018/10/05/michael-littman-receives-browns-presidential-faculty-award/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Michael Littman Receives Brown's Presidential Faculty Award Posted by Jesse Polhemus on Oct. 5, 2018 in Awards Click the link that follows for more news about Michael Littman and recent awards won by Brown CS faculty . Out of more than 700 faculty members, two are chosen each year for Brown University 's Presidential Faculty Award, and this semester, President Christina Paxson selected Professor Michael Littman of the Department of Computer Science (Brown CS). Established in 2013, the Presidential Faculty Award recognizes members of Brown\u2019s distinguished faculty who are conducting especially important and innovative scholarship. Michael is the first Brown CS recipient of the award, and it comes only months after he received the Philip J. Bray Award for Excellence in Teaching in the Physical Sciences . Prior winners of the Presidential Faculty Award include Bonnie Honig (Professor of Modern Culture and Media and Professor of Political Science), Jill Pipher (Elisha Benjamin Andrews Professor of Mathematics and Founding Director of the Institute for Computational and Experimental Research in Mathematics), and David Berson (Sidney A. Fox and Dorothea Doctors Fox Professor of Ophthalmology and Visual Sciences). Michael will receive a research stipend of $5,000 and give a Presidential Faculty Lecture to provide an opportunity for faculty members in other disciplines to learn about his work. A list of previous winners is available here . For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://cs.brown.edu/news/2019/01/18/nakul-gopalan-eric-rosen-daniel-ullman-david-whitney-win-hyundai-visionary-challenge/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Nakul Gopalan, Eric Rosen, Daniel Ullman, And David Whitney Win The Hyundai Visionary Challenge Posted by Rujul Singh on Jan. 18, 2019 in Awards Click the link that follows for more news items about our students competing at hackathons and other events. The Hyundai Visionary Challenge is a competition to ignite learning, exploration, and development in the realm of smart mobility. It\u2019s meant to accelerate research innovations in smart mobility that drive the creation of sustainable cities across the globe, and awards teams across a broad spectrum of categories. Encompassing biology-inspired mobility, digital phenotyping, and man-machine partnership, these categories all aim to inspire new ways of thinking to impact the world. This year, Brown CS PhD students Nakul Gopalan, Eric Rosen, and David Whitney along with Brown CLPS PhD student Daniel Ullman (whose team was advised by Stefanie Tellex) have won the annual award for their proposal, \u201cImproving Man-Machine Partnership using Mixed Reality Social Feedback from Robots.\u201d \u201cI really enjoyed being able to talk about and explore the applications of our work in the business world,\u201d explains David as he describes the group\u2019s project, \u201cand I saw the potential for VR to be truly transformative for society.\u201d In essence, the team\u2019s goal was to increase the efficiency of communication between robots and human workers in the workplace. As it stands, robots are very unsafe to human coworkers. Humans can\u2019t predict the future actions of automated robots, which vastly reduces robot effectiveness on the job. The idea to solve this issue is to have workers in warehouses wear augmented reality headsets to see the future actions of moving robots in real time, minimizing collisions and significantly improving workplace output. This tool would foster interaction between humans and machines, making for a much safer work environment. It may sound futuristic, but the team has set high goals for this project, and plans to continue working and refining this man-machine partnership idea in the upcoming years. For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse Polhemus.", "https://cs.brown.edu/news/2019/02/28/evan-cater-wins-randy-f-pausch-computer-science-undergraduate-summer-research-award/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Evan Cater Wins The Randy F. Pausch Computer Science Undergraduate Summer Research Award Posted by Jesse Polhemus on Feb. 28, 2019 in Awards Click the links that follow for more news items about Michael Littman , Peter Norvig , and the Randy F. Pausch '82 Computer Science Undergraduate Summer Research Award . The Randy F. Pausch '82 Computer Science Undergraduate Summer Research Award , given this year to Evan Cater to support his work with Brown CS Professor Michael Littman , recognizes strong achievement from young students and offers them the opportunity to partner with faculty and advance work that began in the undergraduate research program. A generous gift from Peter Norvig '78 (a Director of Research at Google and a thought leader in the areas of artificial intelligence, natural language processing, information retrieval, and software engineering) established the award, which provides $10,000 annually to support an undergraduate engaged in an intensive faculty-student summer research partnership. The gift honors the life and work of Randy F. Pausch '82, a renowned expert in computer science, human-computer interaction, and design who died of complications from pancreatic cancer in 2008. \"His story is inspiring,\" Peter says, \"and this is an opportunity to remember him.\" Evan explains that he began collaborating with Michael as a first-year student, working alongside a Master's student on Variational Autoencoders with Deep Q-Networks, a type of reinforcement learning (RL) algorithm. \"We couldn't get the idea working,\" he says, \"and the project fizzled out, but it piqued my interest in both RL and Variational Inference. I've revisited these ideas in conjunction over the past couple of years, and this proposal and research project will hopefully synthesize my thoughts on the subject.\" And what might that look like? First, some background. \"Any time we have robotics or computer programs interacting with the real world,\" Evan says, \"there exists a lot of uncertainty. When deploying a program that, for example, modulates the power grid, or a self-driving bus that carts children to school, a lot is at stake. Storms can impede driving, hard drives can fail, car accidents happen, and programs can seg-fault. When faced with uncertainty, we want to make sure our Artificial Intelligence can make decisions. The agents interact with the world over time, so we can formalize this problem as learning good policies (or actions) over time, under uncertainty.\" To construct agents that operate under uncertainty, he says, it's necessary to categorize uncertainties. For example, epistemic uncertainty is created by a lack of data, whereas aleatoric uncertainty is the result of random changes in the environment. \"My work,\" Evan says, \"is a research study on a unified view of uncertainty in Deep Reinforcement Learning. First, we'll provide a taxonomy and vocabulary to describe the various uncertainties used in reinforcement learning. Next, we'll compare and contrast different contemporary papers, clearly distinguishing the types of uncertainty each paper considers and how the papers interact. The study will also provide some theoretical comparisons between the types of uncertainty. Finally, we'll use the study to inform the design of a new set of algorithms based on the insights ascertained. My hypothesis is that techniques from Variational Inference can be used as a unifying tool for the competing techniques.\" With the summer only months away, Evan tells us that he can't wait to explore, read, and tinker: \"I'm ecstatic and really thankful to all the students and professors that got me here. I remember being a first-year student sitting in on Michael's lab meetings and catching every tenth word. Flustered, a couple of seniors and PhD students took me under their wings and pointed me in the right direction. I owe everything to those student mentors and Michael for nurturing me as a researcher. Michael has been helpful and understanding, supportive during the rough weeks, and he sparks creativity in all of his students. I often look forward to our exploratory debates and deep dives into 'what is really going on'.\" Evan's eagerness and excitement is exactly what Peter Norvig is looking for. He sees this award as a multiplier that will amplify the value of his gift and extend it through time. \"In the past,\" he says, \"we had to build all our own tools, and we didn't have time to combine computer science with other fields. Now, there are so many opportunities to do so. I think it's a wise choice: you invest in things that you think will do good, and educating a student allows them to help add to the things that you're already trying to accomplish.\" For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://cs.brown.edu/news/2019/04/18/george-konidaris-wins-nsf-career-award-autonomous-robotic-learning/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) George Konidaris Wins An NSF CAREER Award For Autonomous Robotic Learning Posted by Jesse Polhemus on April 18, 2019 Click the links that follow for more news about George Konidaris , other Brown CS NSF CAREER Award winners , and other recent awards won by our faculty . \"Robotics is no longer primarily a hardware problem, but largely one of software,\" says Professor George Konidaris of Brown CS . \"We already have highly physically capable robots, but our ability to program them is still quite limited. Ideally, we\u2019d like to be able to give the robot a what goal (e.g. the light should be switched on), and have the robot figure the how part of the problem out itself. But we\u2019re a long way from that, and a major reason why is that we don\u2019t know how to get away from the plethora of tiny low-level details a robot has to deal with \u2013every pixel, and every motor signal\u2013 to the kinds of high-level planning at which humans excel.\" Konidaris\u2019s recent work has been focused on the theoretical foundations of the problem of abstraction, and last year he published a paper that introduced a new theoretical framework for helping robots learn to reason abstractly. \u201cThat work felt like a great step,\u201d says George, \u201cbut it wasn\u2019t yet really practical, because the robot must learn every aspect of every new task from scratch.\u201d Earlier this month, George won a National Science Foundation (NSF) CAREER Award that will help him tackle that challenge by applying his new theoretical framework to the problem of designing robots that view the world in an object-centric way: they will learn to manipulate objects, build abstract internal representations of those objects, and reuse these representations to generalize across similar objects. His aim is to build the foundation for a new family of algorithms that will enable robots to reason and plan in complex scenarios in the real world by getting the most mileage out of the learning they\u2019ve already done. CAREER Awards are given in support of outstanding junior faculty teacher-scholars who excel at research, education, and integration of the two within the context of an organizational mission, and George joins multiple previous Brown CS winners of the award, including (most recently) Theophilus Benson , Stefanie Tellex , Jeff Huang , and Rodrigo Fonseca . For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://cs.brown.edu/news/2019/03/06/rhode-island-robot-block-party-returns-april-13/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Rhode Island Robot Block Party Returns On April 13 Posted by Jesse Polhemus on March 6, 2019 in Diversity The robots return! Rhode Island Robot Block Party will take place on Saturday, April 13, 2019, from 12-4 PM at the WaterFire Arts Center (475 Valley Street). The event, an expo founded by the Rhode Island Students of the Future in partnership with Brown University 's Humanity Centered Robotics Initiative and Brown CS , highlights the innovation of our state's robotic community. Bringing together industry, universities, community organizations, and K-12 schools, it's open to the public and includes numerous pieces of robotic equipment that range from ocean exploration devices to animatronic toys. It was a Rhode Island Monthly Editor's Choice \"Best of\" Award winner in 2015. Recent exhibitors included: University Exhibits and Demonstrations RISD students demonstrated the rover they built for the NASA Human Exploration Rover Challenge. The Brown Robotics Lab demonstrated cloud robotics technologies and quadrotor and telepresence robots. Brown University Planetary Geosciences and NASA Solar System Exploration Virtual Institute (SSERVI). The SSERVI Evolution and Environment of Exploration Destinations (SEEED) team is hosted by Brown University and MIT. NASA and international space probes are exploring all the planets of the solar system and will reach Pluto this summer. Come see pictures of Mars from the sophisticated Curiosity rover, and share close-up images of the surface of a comet. Meet scientists from Brown University who are exploring the planets and satellites of the Solar System and learn of their discoveries and future plans for human and robotic exploration! Human 2 Robots Lab demonstrated the pick and place capabilities of the Baxter industrial robot, created by Rethink Robotics. The Laboratory for Engineering Man/Machine Systems (Computer Vision @ LEMS) displayed their Blindfind project. The Brown IEEE Robotics Olympiad Micromouse competition held their annual competition at the Robot Block Party. University of Rhode Island Graduate School of Oceanography displayed the autonomous kayak and Lagrangian floats used to explore shallow coastal waters. The URI RoboBoat team and the Robotics Laboratory for Complex Underwater Environments (R-CUE) teamed up to display the URI Autonomous Surface Vehicle; a pair of flying robots; at least two underwater robots; and a variety of 'soft robotics' prototypes use for underwater grasping and manipulation. Roger Williams University School of Engineering, Computing and Construction Management demonstrated a student built, human scale mobile robot allowing for virtual telepresence. Salve Regina University School of Business Studies and Technology displayed student technology projects. New England Institute of Technology had a demonstration of robotics, quad-copters, and support products. Manufacturing and Community Organizations Hasbro demonstrated their animatronic toy line, FurReal Friends. igus, inc displayed their movement machine and iglide and echain products. The Rhode Island Computer Museum presented \u201cRobots on the Run\u201d an activity that explains basic circuits and programmable electronics in hobby robots. FabNewport demonstrated ArtBots that create original works of art. IEEE Providence Section demonstrated their role in the robotics industry and professional development of engineers. The Providence Children\u2019s Museum provided the Rigamajig play area which encourages hands on exploration of mechanical design concepts. BLT Robotics displayed a Robotic Vertical Hydroponic Farm. Members of Make:'s book publishing team joined the Robot Block Party to show off projects from some of our recent and soon-to-be-published books. They had hands-on interactive projects you can play with from our upcoming Getting Started with littleBits book, some 3d-printed-in-place objects, and some Raspberry Pi demos. AS220 Labs showed a new line of electronics kits and some drawing machines from the Lab. Robotix Learning Solutions demonstrated their affordable robot that helps teach kids (4-18 years) how to code in an easy and interactive way. Student Exhibits Coventry: Alan Shawn Feinstein Middle School students built a robotic claw that can pick up a ball and a Chain Reaction Machine. East Greenwich: Our Lady Of Mercy School had over 30 students building autonomous parade floats and interactive robotics projects. The students range from age 6-12. East Providence: Martin Middle School had middle school students building autonomous parade floats and interactive projects. Middletown/Newport: Newport Community School brought students who built autonomous parade floats. All Saints STEAM Academy students displayed their Arduino robots and several other interactive projects. Their Jr. FIRST LEGO League team demonstrated their Think Tank project. The Aquidneck Island 4-H club runs robotics programs for kids aged 9-18. AIR Strike 78, their FIRST Robotics team demonstrated their award-winning robot. Narragansett: The Pier School exhibited classroom robotics projects. Providence: Providence Career and Tech Academy demonstrated engineering and robotics projects completed by their engineering students. Wheeler School exhibited projects built by lower and middle school students. FRC 2780 Robotics Team, based at Wheeler School, demonstrated their FIRST Robotics Robot. Lincoln School demonstrated Tetrix robots built by the Robotics I & II classes, plus a demonstration of our FIRST Tech Challenge bot with field elements from the 2015 FTC game, Cascade Effect. Mount Pleasant High School demonstrated their student robotics projects. Nathan Bishop Middle School demonstrated their student robotics projects. The College Crusade is a community-based robotics teams, composed of Cranston & Providence youth. They demonstrated a rover. Riverside: Riverside Middle School students buildt autonomous parade floats, and interactive projects. Gordon School students worked on interactive robotics projects and a Chain Reaction Machine. Warren: Kickemuit Middle School built a chain reaction machine. West Warwick: 21st Century Community Learning Center, YMCA at John Deering Middle School featured students demonstrating autonomous parade floats.", "https://cs.brown.edu/news/2019/05/20/david-abel-wins-presidential-award-excellence-teaching/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) David Abel Wins A Presidential Award For Excellence In Teaching Posted by Rujul Singh on May 20, 2019 in Awards Click the links that follow for more news items about David Abel , other winners of the Presidential Award , and other awards won by our students. PhD candidate David Abel of Brown CS , who just recently proposed his thesis and expects to graduate with a PhD in Computer Science and a Master\u2019s in Philosophy next spring, has been recognized for an accomplishment beyond his achievements in research. Chosen out of hundreds of graduate students with teaching appointments, Dave was one of only four to win the Presidential Award for Excellence in Teaching. The award, given annually at the University Awards ceremony, recognizes outstanding pedagogical achievement. Its criteria span from teaching that influences and inspires students to learn to development of curriculum and resources that promote student learning. Dave began his teaching journey in 2014 as a TA for Stefanie Tellex, teaching CS 1410 (an undergraduate Artificial Intelligence class). After being nominated as a \u201cgreat TA\u201d by the students in the class, he became a TA for CS 8 (A First Byte of Computer Science), an introductory computer science class for non-majors taught by Professor Michael Littman with enrollment of 109 students. During his semester of teaching the course, Dave was consistently praised by his students, with many citing his \u201cenergy, availability, and thoughtfulness\u201d as being key to fostering an environment for intellectual curiosity. Dave was instrumental in implementing an optional python unit in the class that gave students the opportunity to learn a language used widely in industry. As a testament to his teaching abilities, a full 98.5% of respondents rated the class as effective or very effective when Michael took a sabbatical and Dave ran the class on his own. Not limited to the classroom, Dave has been involved in a variety of activities that may very well have had an even greater impact on the Brown community. Along with fellow CS PhD students Nediyana Daskalova and Amariah Becker, Dave has been heavily involved in designing and running peer mentorship program in the department. His initiative pairs up post-candidacy PhD students with first year PhD students, ensuring that new students have proper guidance regarding finding research, working with their advisor, and establishing work-life balance. Keeping with the spirit of mentorship, Dave has been a primary research advisor for several Brown undergraduates as well. Over the past few years, he has co-authored 11 papers with many undergraduate students, guiding them through the research process. Dave has clearly shown himself to be a remarkable teacher, both in and outside the classroom. As he finishes up his graduate studies, it's evident that his work has made a personal impact on the many dozens of students with whom he has worked. For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse Polhemus.", "https://cs.brown.edu/news/2019/06/17/michael-littman-has-been-named-acm-fellow/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Michael Littman Has Been Named An ACM Fellow Posted by Jesse Polhemus on June 17, 2019 in Awards Click the links that follow for more news about Michael Littman and other Brown CS ACM Fellows . In a ceremony on June 15, 2019, the Association for Computing Machinery (ACM), the world\u2019s largest educational and professional computing society, elevated Professor Michael Littman of Brown CS to the rank of Fellow, the organization's highest membership grade, for contributions to the design and analysis of sequential decision-making algorithms in artificial intelligence. The ACM Fellows Program, initiated in 1993, celebrates the exceptional contributions of leading members of the computing field, and Michael joins a distinguished list of colleagues to whom the ACM and its members look for guidance and leadership in computing and information technology. \"It was an honor to be selected as a Fellow,\" Michael says, \"and I really enjoyed the ceremony and hearing about all the remarkable achievements of the big award winners. Computing is such an exciting field right now and getting to see so many important figures in the field in one place was a total trip.\" Michael earned his doctorate from Brown CS in 1996 and has been a member of the faculty since 2012. Currently co-directing Brown \u2019s Humanity-Centered Robotics Initiative , he works mainly in reinforcement learning, but has done research in machine learning, game theory, computer networking, partially observable Markov decision process solving, computer solving of analogy problems, and other areas. He's earned multiple awards for teaching and research and has served on the editorial boards for The J ournal of Machine Learning Research and The J ournal of Artificial Intelligence Research . He served as General Chair of the International Conference on Machine Learning and Program Chair of the Association for the Advancement of Artificial Intelligence (AAAI) Conference in 2013. He's also an AAAI Fellow and Co-Chair of the upcoming Reinforcement Learning and Decision Making Conference, to be held in 2019 in Montreal. Michael is the eighth ACM Fellow among current Brown CS faculty. Others include Maurice Herlihy , Philip Klein , Franco Preparata , John Savage , Roberto Tamassia , Eli Upfal , Andy van Dam , and Stan Zdonik . For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://cs.brown.edu/news/2019/06/18/brown-cs-undergraduate-atsunobu-kotani-teaches-robots-handwriting-and-drawing/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Brown CS Undergraduate Atsunobu Kotani Teaches Robots Handwriting And Drawing Posted by Jesse Polhemus on June 18, 2019 by Kevin Stacey (Science News Writer, Physical Sciences) Click the links that follow for more news about Stefanie Tellex and other accomplishments by Brown CS students . An algorithm developed by Brown University computer scientists enables robots to put pen to paper, writing words using stroke patterns similar to human handwriting. It\u2019s a step, the researchers say, toward robots that are able to communicate more fluently with human co-workers and collaborators. \u201cJust by looking at a target image of a word or sketch, the robot can reproduce each stroke as one continuous action,\u201d said Atsunobu Kotani, an undergraduate student at Brown who led the algorithm\u2019s development. \u201cThat makes it hard for people to distinguish if it was written by the robot or actually written by a human.\u201d The algorithm makes use of deep learning networks that analyze images of handwritten words or sketches and can deduce the likely series of pen strokes that created them. The robot can then reproduce the words or sketches using the pen strokes it learned. In a paper presented at the International Conference on Robotics and Automation in May, the researchers demonstrated a robot that was able to write \u201chello\u201d in ten languages that employ different character sets. The robot was also able to reproduce rough sketches, including one of the Mona Lisa. Stefanie Tellex , an assistant professor of computer science at Brown and Kotani\u2019s advisor, says that what makes this work unique is the ability of the robot to learn stroke order from scratch. \u201cA lot of the existing work in this area requires the robot to have information about the stroke order in advance,\u201d Tellex said. \u201cIf you wanted the robot to write something, somebody would have to program the stroke orders each time. With what Atsu has done, you can draw whatever you want and the robot can reproduce it. It doesn\u2019t always do the perfect stroke order, but it gets pretty close.\u201d Another remarkable aspect of the work, Tellex says, is how the algorithm was able to generalize its ability to reproduce strokes. Kotani trained his deep learning algorithm using a set of Japanese characters, and showed that it could reproduce the characters and the strokes that created them with around 93 percent accuracy. But much to the researchers\u2019 surprise, the algorithm wound up being able to reproduce very different character types it had never seen before \u2013 English print and cursive, for example. \u201cWe would have been happy if it had only learned the Japanese characters,\u201d Tellex said. \u201cBut once it started working on English, we were amazed. Then we decided to see how far we could take it.\u201d Tellex and Kotani asked everyone who works in Tellex\u2019s Humans to Robots lab to write \u201chello\u201d in their native languages, which included Greek, Hindi, Urdu, Chinese and Yiddish among others. The robot was able to reproduce them all with reasonable stroke accuracy. \u201cI feel like there\u2019s something really beautiful about the robot writing in so many different languages,\u201d Tellex said. \u201cI thought that was really cool.\u201d But the system\u2019s masterwork may be its copy of Kotani\u2019s Mona Lisa sketch. He drew his sketch on a dry erase board in Tellex\u2019s lab, and then allowed the robot to copy it \u2013fairly faithfully on the same board\u2013 just below Kotani\u2019s original. \u201cIt was early morning that our robot finally drew the Mona Lisa on the whiteboard,\u201d Kotani said. \u201cWhen I came back to the lab, everybody was standing around the whiteboard looking at the Mona Lisa and asking me if [the robot] drew this. They couldn\u2019t believe it.\u201d It was a big moment for Kotani because \u201cit was the moment that our robot defined what\u2019s beyond mere printing.\u201d An ink jet printer can recreate an image, but it does so with a print head that goes back in forth building the image line by line. But this was the robot creating an image with human-like strokes, which to Kotani is \u201csomething much more humane and expressive.\u201d Key to making the system work, Kotani says, is that the algorithm uses two distinct models of the image it\u2019s trying to reproduce. Using a global model that considers the image as a whole, the algorithm identifies a likely starting point for making the first stroke. Once that stroke has begun, the algorithm zooms in, looking at the image pixel by pixel to determine where that stroke should go and how long it should be. When it reaches the end of the stroke, the algorithm again calls the global model to determine where the next stroke should start, then it\u2019s back to the zoomed-in model. This process is repeated until the image is complete. Both Kotani and Tellex say the work is a step toward better communication between people and robots. Ultimately, they envision robots that can leave Post-it Notes, take dictation or sketch diagrams for their human coworkers and collaborators. \u201cI want a robot to be able to do everything a person can do,\u201d Tellex said. \u201cI\u2019m particularly interested in a robot that can use language. Writing is a way that people use language, so we thought we should try this.\u201d For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://cs.brown.edu/news/2020/11/18/new-brown-cs-program-researching-socially-responsible-ai-students-hugs/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) A New Brown CS Program: Researching Socially-Responsible AI With Students From HUGs Posted by Jesse Polhemus on Nov. 18, 2020 in Socially Responsible Computing , Diversity Click the links that follow for more news about diversity and inclusion at Brown CS , our Socially Responsible Computing program , Amy Greenwald , Jeff Huang , Daniel Ritchie , or James Tompkin . At Brown CS and around the globe, interest in AI and related topics is soaring. CSCI 1470 Deep Learning , only a few years old, today has an enrollment of over 350 students, the department's second largest. But as computer scientists hope to expand the field to historically underrepresented groups (HUGs), students from demographics that have born the brunt of algorithmic bias and deepfakes may be understandably hesitant to take part. A new program aims to change that. Thanks to an exploreCSR award from Google, Professors Amy Greenwald , Jeff Huang , Daniel Ritchie , and James Tompkin are launching a program for college students from HUGs in CS that will expose them to socially-responsible ways that AI can be used to realize creative visions . Working virtually at first due to the COVID-19 pandemic, students from around the country will become research associates, paired with Brown graduate student mentors (where possible, from similar HUGs) to conduct individualized research experiences, each culminating in a substantial artifact. In short, it's a behind-the-scenes look at how CS research operates, normalized and without pretentions, that students can use as a building block for future careers. \"Brown is uniquely qualified for this kind of experience,\" says Daniel, \"not only due to our diversity and inclusion programs and our efforts to integrate socially responsible computing across our entire curriculum , but because we're the headquarters of the Leadership Alliance. It's a nationwide consortium of higher educational institutions dedicated to training and mentoring a diverse population of students to take up research leadership positions in academia, industry, and government. CS faculty have mentored visiting students as part of Leadership Alliance programs in the past, and we'll be collaborating with them on this effort (and other upcoming outreach initiatives) to coordinate professional networking and other opportunities for participating students.\" Thanks to the department's strong AI and visual computing groups, research topics are many and varied, including creative deepfake detection, mimicking high-end photography, structured image editing, adversarial shape generation, 3D augmented reality sketching, and building AI to play games. Opportunities for projects include literature reviews, replication studies, research apprenticeships, and independent research projects. Although activities will be conducted virtually, the program will culminate in an in-person visit to campus, centered around a symposium in which students present their findings alongside Brown undergrads. \"I'm excited to see how this 'virtual research associate' approach goes,\" says Daniel. \"It's really different from the typical outreach approach of bringing students in for a short workshop that lasts maybe for a long weekend. I'm hopeful that having a longer timeline, where students get to really experience a research culture over the span of a semester, can have a more lasting impact on attracting students to CS research careers. And we'll still bring students to campus at the end of this experience, for them to meet with their mentors and collaborators and present their research alongside Brown undergrads, as their research peers.\" For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://cs.brown.edu/news/2021/07/09/leonhard-spiegelberg-wins-facebook-fellowship/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Leonhard Spiegelberg Wins A Facebook Fellowship Posted by Livia Gimenes on July 9, 2021 in Awards Click here to find out more about other recent accomplishments by Brown CS students . Brown CS PhD student Leonhard Spiegelberg has received a Facebook Fellowship for his research on systems for big data analytics. His paper \u201cTuplex: Data Science in Python at Native Code Speed\u201d was also published at the ACM Special Interest Group on Management of Data conference. The Facebook Fellowship provides awards to outstanding PhD candidates currently conducting research in the fields of computer vision, programming languages, computational social science, databases, and more. This year, 26 candidates were selected out of 2,163 applicants to receive tuition and fees paid as well as a stipend of $42,000. Leonhard\u2019s research focuses on building more efficient and productive ways of processing large amounts of data. \u201cAs a data scientist, you want to focus on the data and the data questions, not on debugging, tuning, and fixing the tools you need to answer them,\u201d Leonhard says. \u201cHence, I asked myself whether there isn\u2019t a better way to have the high productivity of a high-level language like Python without having to sacrifice performance when scaling out to large datasets.\" At Brown, Leonhard worked in the systems and database groups , advised by Brown CS Professor Malte Schwarzkopf. Leonhard is the lead developer of Tuplex , a new framework that facilitates the processing of large datasets. \"Data science is part of nearly every business today, and Leonhard's research makes data scientists more productive and energy-efficient by compiling Python code to highly efficient machine code. Pulling this off required a rare combination of skills: Leonhard wrote Tuplex, a Python compiler and a parallel execution framework similar to the popular Apache Spark, completely from scratch,\u201d says Malte. \u201cHe is amazingly quick and efficient at turning ideas into code, and has been a fantastic mentor to several undergraduate students who are working on the project. I\u2019m delighted that Facebook chose Leonhard for this prestigious fellowship and therefore supports his research going forward.\u201d Leonhard joins Brown CS alum Jonathan Mace as the second Brown CS recipient of the fellowship. For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "https://cs.brown.edu/news/2021/08/09/wrenn-nelson-and-krishnamurthi-win-programming-editors-choice-award/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Wrenn, Nelson, And Krishnamurthi Win The <Programming> Editors' Choice Award Posted by Jesse Polhemus on Aug. 9, 2021 in Awards Click the links that follow for more news about Shriram Krishnamurthi , Tim Nelson , Jack Wrenn , and other recent accomplishments by Brown CS faculty and students . New research ( \u201cUsing Relational Problems to Teach Property-Based Testing\u201d ) by Brown CS PhD student Jack Wrenn and Professors Tim Nelson and Shriram Krishnamurthi has recently won the annual Editors\u2019 Choice Award for Volume 5 of The Art, Science, and Engineering of Programming , popularly known as <Programming> . \u201cI think this paper,\u201d writes editor Professor Jeremy Gibbons of Oxford University, \u201cclearly epitomises the spirit of the journal: not just elegant technical work, but also a careful discussion of how properly to evaluate it.\u201d In their work, the authors discuss the use of relational problems (those for which an input may admit multiple valid outputs) to motivate the use of property-based testing (PBT) libraries. In addition to describing problems that they\u2019ve developed for use, they introduce a simple method to evaluate the accuracy of student specifications and demonstrate that students can do quite well at PBT for these problems. Recent days have brought two other honors for Shriram: he received an Outstanding Reviewer Award for stellar service on <Programming> \u2019s Standing Review Committee and a Distinguished Reviewer Award for the International Conference on Software Engineering (ICSE) 2021. For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://cs.brown.edu/news/2021/12/17/brown-cs-student-sreshtaa-rajesh-wins-cadence-women-technology-scholarship/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Brown CS Student Sreshtaa Rajesh Wins A Cadence Women In Technology Scholarship Posted by Jesse Polhemus on Dec. 17, 2021 in Awards , Diversity Click the link that follows for more news about other recent accomplishments by Brown CS students . Each year, Cadence, a computational software company focusing on tools for electronic design automation, awards its Women in Technology Scholarship to support and celebrate young women who are starting their careers. Recently, Brown CS student Sreshtaa Rajesh was declared one of the winners, earning a $5,000 stipend. \"Your impressive academic achievements, professor recommendations, and drive to shape the future of technology set you apart from the many talented women we considered,\" writes Academic Network Program Manager Mallory Clemons of Cadence. \"We are excited for what the future holds for you and the impact you will make in technology.\" Sreshtaa's letters of recommendation were written by Brown CS Professors R. Iris Bahar , who worked with her on a summer research project, and Shriram Krishnamurthi , her CS advisor, with whom she's taken courses and for whom she served as Head Teaching Assistant. Iris explains that Sreshtaa's work with her was broadly applicable to artificial intelligence planning in domains where there is uncertainty, such as partial occlusion or inaccurate sensor readings. These types of problems can be represented by frameworks known as Partially\u2010Observable Markov Decision Processes (POMDPs). A POMDP features a set of possible \u201cstates\u201d that the agent could be in, as well as a probability distribution over the set, known as the belief state. Sampling from the belief state informs the agent what state it is most likely in, given all the previous observations it has gotten from the environment. Each time the agent takes an action, it receives a new observation which it then uses to update this belief state and inform future actions. There are several algorithms that exist to solve POMDPs: one such is Partially\u2010Observable Monte Carlo Planning (POMCP). At each step in the process, the algorithm runs many random look\u2010ahead simulations to determine the best action to take next. The challenge for using this algorithm is that in order to achieve a \u201chigh reward\u201d result, a large number of simulations are required, making the process extremely computationally expensive for large domain real\u2010world problems. Sreshtaa worked closely with one of Iris's PhD students to parallelize the most expensive part of POMCP: building the look\u2010ahead search tree and running the simulations. \"Oftentimes,\" Iris writes in her recommendation letter, \"when I assign undergraduate students to work with my graduate students, they just follow specific directions given to them. In Sreshtaa\u2019s case, she was very proactive in offering suggestions, testing out new ideas, and helping implement and debug the parallel algorithm. Specifically, she developed different reward functions for selecting the best action, translated na\u00efve implementations of the code to one using pthreads, explored the use of hashmaps to improve code efficiency, and wrote a plotting script to parse the output of our algorithm. In the end, with the parallelized version, we were able to cut down the runtime of the original POMCP algorithm by almost 50%.\" For more information, click the link that follows to contact Brown CS Communication and Outreach Specialist Jesse C. Polhemus .", "https://cs.brown.edu/news/2022/06/06/rldm-2022-brings-over-500-reinforcement-learning-researchers-brown/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) RLDM 2022 Brings Over 500 Reinforcement Learning Researchers To Brown Posted by Jesse Polhemus on June 6, 2022 Click the links that follow for more news about George Konidaris , Michael Littman , and other recent accomplishments by our faculty. This week, Brown University hosts the Multi-disciplinary Conference on Reinforcement Learning and Decision Making (RLDM), bringing over 500 of the field\u2019s thought leaders to Providence and demonstrating Brown\u2019s continued status as one of the world\u2019s leading centers for reinforcement learning (RL) research and study. Attendees will include the field's founders, Andy Barto and Rich Sutton, and many others who have made seminal contributions, including Peter Dayan, who in 2017 received a Brain Prize for identifying how RL principles explain the workings of the dopamine system in the brain and its implications for human decision-making and its disorders. \u201cThe RL field has been incredibly influential for developing new principles of brain function,\u201d says Professor Michael Frank. \u201cThis conference is a fertile ground by which research communities with shared goals in understanding natural and artificial intelligence can augment each other and catalyze new discoveries. We\u2019re thrilled to host it at Brown.\u201d RLDM is an interdisciplinary conference, hosting two families of RL researchers who often work in parallel: those studying computational reinforcement-learning algorithms, and those who use reinforcement learning as a model of decision-making in the brain and reciprocally develop new RL algorithms to better capture the mechanisms by which the brain solves RL problems, and to inspire developments in AI. Brown is home to some of the field\u2019s leading researchers in both families, the former at Brown CS (Professors Amy Greenwald, George Konidaris, Michael Littman, and Stefanie Tellex) and the latter at the Carney Institute for Brain Science and its Center for Computational Brain Science (Professors Wael Asaad, David Badre, Theresa Desrochers, Oriel FeldmanHall, Michael Frank, Matthew R. Nassar, Frederike Petzschner, and Amitai Shenhav). The conference features invited talks from speakers on both sides of the artificial/natural divide, including Brown's own Professor Stefanie Tellex from the CS side and Professors Oriel FeldmanHall and Frederike Petzschner from the natural side. Professor Arif Hamid of the University of Minnesota, former postdoctoral trainee with Professors Michael Frank and Christopher Moore of the Carney Institute, will also present a revised understanding of the dopamine system with implications for RL based on work they did at Brown. Other speakers are listed here . The main meeting will be single-track, consisting of a mixture of invited and contributed talks, tutorials, and poster sessions. For those unable to attend, all invited and contributed talks will be recorded and made public within a few days after the talks. Professor Michael Littman of Brown CS is General Co-Chair of the event, along with New York University\u2019s Professor Catherine Hartley. The two served as program chairs for the 2019 conference. This year\u2019s Program Chairs are Professor Roshan Cools of Radboud University Nijmegen and Peter Stone of University of Texas at Austin. Local Chairs are Professor Michael Frank, Director of the Carney Center for Computational Brain Science and Professor of Cognitive, Linguistic, and Psychological Sciences (CLPS), and Professor George Konidaris of Brown CS. The Social Chair is Professor Amitai Shenhav of CLPS. Sponsors include the Carney Institute for Brain Science, Sony AI, Microsoft, DeepMind, the Vector Institute, and Google. \u201cReinforcement learning is at the very core of the entire Artificial Intelligence enterprise,\u201d says Professor George Konidaris of Brown CS, \u201cbecause it\u2019s the only machine learning paradigm that focuses on how an agent's interaction with the world can help it achieve its goals. It's incredibly exciting to have RL researchers from all over the world \u2013 including my home country of South Africa! \u2013 converging on Brown, which in the last decade or so has become a world center for RL research.\u201d He added, \u201cIt's going to be great to see everyone again!\u201d For more information, click the link that follows to contact Brown CS Communication and Outreach Specialist Jesse C. Polhemus .", "https://cs.brown.edu/news/2022/05/17/zachary-espiritu-wins-norman-k-meyrowitz-81-award/": "Brown CS News Categories Awards ( 185 articles ) Socially Responsible Computing ( 43 articles ) Diversity ( 29 articles ) Zachary Espiritu Wins The Norman K. Meyrowitz '81 Award Posted by Jesse Polhemus on May 17, 2022 in Awards Click the links that follow for more news about Zachary Espiritu , Norm Meyrowitz , and other recent accomplishments by our students . Brown University 's Department of Computer Science has just announced that Zachary Espiritu, a Brown CS student, SPOC (Systems Programmer, Operator, and Consultant), and one of the four Meta-TAs who coordinate the Undergraduate Teaching Assistant program , has just won the Norman K. Meyrowitz '81 Award. Named for an alum known for his contributions to the department, the award recognizes exceptionally meritorious service to Brown CS and is accompanied by a cash prize of five hundred dollars. \"Zach was a super-competent UTA, HTA, and MTA,\" says Brown CS Professor Tom Doeppner , Vice Chair and Director of Undergraduate Studies. \"He excelled in research, particularly in cybersecurity, but was also sought out for his research skill in other areas. He took time off from school to undergo cancer treatment, which he pulled through to the relief of everyone.\" Norm Meyrowitz feels similarly. \u201cI\u2019ve worked with Zach over the past year,\" he says, \"and I can certify that he has done amazingly at a job way more complicated than the one done by the person after whom the award is named.\u201d For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "https://cs.brown.edu/people/alysyans/": "Anna Lysyanskaya James A. and Julie N. Brown Professor of Computer Science Brown University Box 1910 Providence, RI 02912 (401) 863-7600 * anna at cs.brown.edu Homepage Brief bio Contact info Research Teaching Tweets Welcome to my homepage! I am James A. and Julie N. Brown Professor of Computer Science at the Computer Sciencedepartment at Brown University . My research area is Cryptography. Of particular importance in myresearch are privacy-enhancing technologies that allow individuals togo about their daily online lives without disclosing unnecessarypersonal data. I am most proud of my work on anonymous credentials andelectronic cash. I am also interested in more broad and foundationalcryptographic questions. If you are a prospective Ph.D. student interested in Cryptography, I encourage you to apply to the Brown CS department . Current Ph.D. students: Leah Rosenbloom, Scott Griffy, Victor Youdom Kemmoe Past Ph.D. students: Mira Belenkiy Melissa Chase Alptekin K\u00fcp\u00e7\u00fc . Feng-Hao Liu Foteini Baldimtsi Elizabeth Crites Apoorvaa Deshpande Megumi Ando This semester (Spring 2024), I am teaching CSCI1040: The Basics of Cryptographic Systems .In the Fall, I will be on Sabbatical.", "https://cs.brown.edu/people/avandam/": "Andries van Dam Thomas J. Watson, Jr. University Professor of Technology and Education and Professor of Computer Science Brown University, Box 1910, Providence, RI 02912 phone: (401) 863-7640, fax: (401) 863-7657 email: avd@cs.brown.edu Andries van Dam (Andy) has been on Brown's faculty since 1965, and was one of the Computer Science Department's co-founders and its first Chairman, from 1979 to 1985. He was a Principal Investigator and was the Director from 1996-1998 in the NSF Science and Technology Center for Graphics and Visualization , a research consortium including Brown, Caltech, Cornell, North Carolina (Chapel Hill), and the University of Utah. He served as Brown's first Vice President for Research from 2002-2006. Professor van Dam received his B.S. degree with Honors in Engineering Sciences from Swarthmore College in 1960 and his M.S. and Ph.D. from the University of Pennsylvania in 1963 and 1966, respectively. Recent Events Celebrating CHM 2021 Fellow Andy van Dam Andy van Dam has devoted his life's work to revolutionizing how people and ideas connect through computers, how people and computers connect through interactive graphics, how scholars connect through digital humanities education, and how technology and society can connect in ways that are good for humanity. AREC Distinguished Lectures Series: Andy van Dam \"Reflections on Hypertext, the Online World, and Societal Impact\" Computer graphics legend, Andries (Andy) van Dam is co-designer of HES and FRESS, the first and second hypertext systems allowing information to connect through hyperlinks. Crucial to the development of modern markup and browsing technology, van Dam's work influenced how we use the web today. He founded the computer science department at Brown University and served as its first chair from 1979-1985. A pioneer in his field, he co-authored Computer Graphics: Principles and Practice, a textbook that defined computer graphics that remains the classic standard introduction into the field. Credited with founding SICGRAPH, van Dam's distinguished career includes receiving the ACM Karl V. Karlstrom Outstanding Educator Award, the SIGGRAPH Steven A. Coons Award for Outstanding Creative Contributions to Computer Graphics, the IEEE Centennial Medal, and honorary doctorates from Darmstadt Technical University, Swarthmore College, the University of Waterloo, and ETH Zurich. ACM Hypertext 2019 Andy van Dam Keynote \"Reflections on a Half-Century of Hypertext\" Is It Time to Declare Victory and Go Home? Or \"Hypertext: The Web wasn't the Beginningand the Web isn't the End\" - Norm Meyrowitz CSCI 1951V: Hypertext/Hypermedia:The Web Was Not the Beginning and the Web Is Not the End CSCI1951-V, \"Hypertext/Hypermedia: The Web Was Not the Beginning and the Web Is Not the End,\" looks at hypertext systems that came before and after the World Wide Web as a basis for discussing what next generation hypertext systems could look like. Students will be doing writing assignments, reading, annotating, and writing technical papers, participating in in-class brainstorming sessions, discussing materials in a roundtable format, and developing software prototypes with Javascript and the state-of-the-art MERN (MongoDB, Express, React and Node.js) stack. Students will learn not only about hypertext, but will use that knowledge to develop full-stack applications using modern technologies and high-level software architectures as they prototype systems of the future. The course will be capped at 35 students to facilitate participation and discussion. Research His research has concerned computer graphics, hypermedia systems, post-WIMP user interfaces, including pen-centric computing, and educational software. He has been working for over four decades on systems for creating and reading electronic books with interactive illustrations for use in teaching and research. Publications The completely rewritten third edition of the widely used reference book Computer Graphics: Principles and Practice , co-authored with John F. Hughes, Morgan McGuire, David Sklar, James D. Foley, Steven K. Feiner, and Kurt Akeley, was released at ACM SIGGRAPH 2013 and is available from Amazon. Prof. Hughes wrote a description of the extensive changes and additions in the new version on the CS Blog: New Edition of Computer Graphics: Principles and Practice Earlier editions include: Fundamentals of Interactive Computer Graphics, co-authored with J.D. Foley, was published by Addison-Wesley in 1982; the expanded successor, Computer Graphics: Principles and Practice, co-authored with J.D. Foley, S.K. Feiner, and J.F. Hughes, was published in June of 1990. An undergraduate version, by the same four authors and D. Phillips, Introduction to Computer Graphics, was published in 1993. Pascal on the Macintosh - a Graphical Approach, co-authored with David Niguidula, was published by Addison-Wesley in 1987. Object-Oriented Programming in Pascal, A Graphical Approach, co-authored with D. Brookshire Conner, and David Niguidula was published in April, 1995. Frontiers of Human-Centered Computing, OnLine Communities and Virtual Environments, (with Rae Earnshaw, Richard Guedj, and John Vince [Eds]) was published in February 2001, and Object-Oriented Programming in Java: A Graphical Approach, co-authored with Kathryn E. Sanders was published by Addison-Wesley in 2005. van Dam has authored or coauthored over 100 papers, which are listed in his Curriculum Vitae . Courses CS123 - Introduction to Computer Graphics lectures are available for downloading in PDF format. CS15 - Introduction to Object-Oriented Programming and Computer Science lectures are available for downloading in PDF format. Awards Among his awards are the Society for Information Display's SpecialRecognition Award (1974), the IEEE Centennial Medal (1984), theNational Computer Graphics Association's Academic Award (1990), theACM SIGGRAPH Steven A. Coons Award (1991), the L. Herbert BallouUniversity Professor Chair (1992), the ACM Karl V. Karlstrom Outstanding Educator Award (1994), the Thomas J. Watson, Jr.University Professor of Technology and Education Chair (1995), the IEEE James H. Mulligan, Jr. Education Medal (1999), and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education (2000). In 1994 he became an IEEE Fellow and an ACM Fellow.He received an honorary Ph.D. from Darmstadt Technical University in Germany (1995), an honorary Ph.D. from SwarthmoreCollege (1996), an honorary Ph.D. from the Faculty of Mathematics, University of Waterloo (2007), and an honorary Ph.D. from the Department of Computer Science, ETH Zurich (2008). In 1996 he was inducted into the National Academy of Engineering, in 2000 he became a Fellow of the American Academy of Arts and Sciences, in 2002 he received the CRA Distinguished Service award and the Brown University Sheridan Teaching award, and in 2004 was elected a fellow of the American Association for the Advancement of Science. Professional Activities In 1967, Professor van Dam co-founded ACM SIGGRAPH and from 1985 through 1987 was Chairman of the Computing Research Association. He has been Associate Editor of the \"ACM Transactions on Graphics\" (1981-1986), Editorial Board Member of \"Computers and Graphics\", Pergamon Press (1983 -1994), Advisory Editor, \"Journal of Visual Languages and Computing\", Academic Press (1989-1998), and Editorial Board Member of the \"IEEE Transactions on Visualization and Computer Graphics\", (1994-1998). From 1991 - 2006 he served on the Microsoft Research Technical Advisory Board (MSR TAB). Hobbies grandchildren, eating well, and outdoor sports--especially sea-kayaking, scuba-diving, mountain biking, skiing and backpacking. Andy -- Switzerland -- August 2016 CS15 , CS123 gfx_www@cs.brown.edu", "https://cs.brown.edu/people/bcz/": "Intra-Mural Football Champs, 2001", "https://cs.brown.edu/people/bjm/": "", "https://cs.brown.edu/people/bjm/bio/": "Barbara Meier Home Teaching Research Creative Visual Effects Images Animations Drawings/Paintings Interests Publications Bio Contact Info Links Biography Barbara Meier is an animator and teaches computer animation at Brown University in Providence, Rhode Island. Her research interests include non-photorealistic rendering and creating tools for artists that build on artists\u2019 preferred working methods. In her art work, she designs new visual styles of animation that combine traditional and computer techniques. Previously, Meier created visual effects for feature films in Hollywood at Pacific Data Images, Cinesite, and Hammerhead Productions, and developed a painterly rendering technique for Fantasia 2000 at Walt Disney Feature Animation. She received BA and MS degrees in Computer Science from Brown and studied animation and illustration at the Rhode Island School of Design, Art Center College of Design, and the Museum School in Boston. Meier lives in Barrington, Rhode Island with her husband and two sons. // Created by Cassidy Laidlaw in 2009 for vis.cs.brown.edu// Do not modify or remove this text(function() { if(document.location.href.indexOf(\"http://www.cs.brown.edu/~bjm/\")==0) { url = document.location.href.substring(\"http://www.cs.brown.edu/~bjm/\".length); document.location.assign(\"http://cs.brown.edu/people/bjm/\"+url); } else if(document.location.href.indexOf(\"http://cs.brown.edu/~bjm/\")==0) { url=document.location.href.substring(\"http://cs.brown.edu/~bjm/\".length); document.location.assign(\"http://cs.brown.edu/people/bjm/\"+url); } else if(document.location.href.indexOf(\"cs.brown.edu/people/bjm/\") != -1) { var _gaq = _gaq || []; _gaq.push(['_setAccount', 'UA-18038129-1']); _gaq.push(['_trackPageview']); (function() { var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })(); } })();", "https://cs.brown.edu/people/apapouts/faculty_dataset.html": "Dataset of 2200 faculty in 50 top US Computer Science Graduate Programs Alexandra Papoutsaki*, Hua Guo, Danae Metaxa-Kakavouli, Connor Gramazio, Jeff Rasley, Wenting Xie, Guan Wang, Jeff Huang Brown University, Providence, RI, USA * Any questions or comments should be sent to alexpap@cs.brown.edu The Dataset We provide the first free dataset of all professors in 50 top US Computer Science Graduate Programs. We believe that we offer a valuable resource to the academic community and to anyone who is interested in the shape of the Computer Science in the most competitive institutes of the US. You can download the database from here if you want to explore the data. To avoid conflicts you can only download and comment on the spreadsheet. You do not need to be signed in with a Google account. How to fix an incorrect entry If you find any errors, you can right-click the cell you want to fix and add a comment . We will double-check your correction and we will accept your change accordingly. How to insert a new professor If you cannot find a professor you can right-click and add a comment in one of the empty lines in the bottom of the spreadsheet. Try to insert as many of the required fields as possible. How to use this dataset Here is a list of suggestions: Look up faculty in a particular area when applying to grad schools Track Alumni Chose what field to study (!) Look at what is the breakdown of research areas per department Disclaimer We do not make any guarantee on the quality of the data. As you can read below, we used crowdsourcing techniques to create this database. We expect about 80% of our data to be correct.We need your help to fix any errors that are still left. Did you know? Here are some interesting facts we found when analysed the data. Last version of dataset that was used was downloaded on Wednesday, October 22th, 2014 08:53 PM(EDT) . Largest fields of research These are the fields of research according to their popularity. Field of Research Number of Professors Algorithms & Theory 296 Networks & Communications 168 Artificial Intelligence 151 Hardware & Architecture 142 Bioinformatics & Computational Biology 131 Security & Privacy 130 Human-Computer Interaction 129 Graphics 118 Distributed & Parallel Computing 101 Machine Learning & Pattern Recognition 99 Programming Languages 98 Computer Vision 95 Scientific Computing 89 Software Engineering 83 Databases 80 Operating Systems 71 Natural Language & Speech 58 Computer Education 49 Real-Time & Embedded Systems 35 Data Mining 32 Multimedia 16 Information Retrieval 6 World Wide Web 5 Where do most professors get their bachelors from? These are the universities with at least 10 BSc alumns that provide the largest number of BSc among the professors in 50 top universities. Bachelors University Number of Professors Massachusetts Institute of Technology - USA 117 Harvard University - USA 66 Cornell University - USA 46 University of California - Berkeley - USA 43 Indian Institute of Technology - Madras - India 37 Tsinghua University - Beijing - China 33 Indian Institute of Technology - Kanpur - India 32 Stanford University - USA 32 Princeton University - USA 32 Carnegie Mellon University - USA 31 Brown University - USA 29 Yale University - USA 25 Indian Institute of Technology - Bombay - India 24 Rice University - USA 23 University of Michigan - USA 21 Georgia Institute of Technology - USA 20 California Institute of Technology - USA 19 Indian Institute of Technology - Delhi - India 19 University of Illinois at Urbana-Champaign - USA 18 University of Science and Technology of China - China 18 Duke University - USA 17 Indian Institute of Technology - Kharagpur - India 16 Peking University - Beijing - China 16 University of California - Los Angeles - USA 15 National Taiwan University - Taipei - Taiwan 15 Columbia University - USA 14 University of Toronto - Canada 14 Pennsylvania State University - USA 14 University of Texas - Austin - USA 13 Technion-Israel Institute of Technology - Israel 13 National Technical University of Athens - Greece 13 Purdue University - USA 12 University of Wisconsin - Madison - USA 12 Hebrew University of Jerusalem - Israel 12 Polytechnic University of Bucharest - Romania 11 Dartmouth College - USA 11 Birla Institute of Technology and Science - Pilani - India 10 Where do most professors get their doctorate degree from? These are the universities with at least 10 PhD alumns that provide the largest number of PhD among the professors in 50 top universities. 10 universities account for ~50% of all PhDs students that become faculty in 50 top universities! Doctorate University Number of Professors Massachusetts Institute of Technology - USA 251 University of California - Berkeley - USA 181 Stanford University - USA 146 Carnegie Mellon University - USA 121 University of Illinois at Urbana-Champaign - USA 82 Cornell University - USA 68 Princeton University - USA 66 University of Washington - USA 63 Georgia Institute of Technology - USA 54 Harvard University - USA 51 University of Texas - Austin - USA 50 University of Wisconsin - Madison - USA 45 University of Pennsylvania - USA 40 University of Maryland - College Park - USA 39 University of California - Los Angeles - USA 34 University of Michigan - USA 34 California Institute of Technology - USA 32 Columbia University - USA 31 University of Toronto - Canada 27 Purdue University - USA 26 University of Southern California - USA 26 University of North Carolina - Chapel Hill - USA 25 Yale University - USA 24 University of Massachusetts - Amherst - USA 24 Brown University - USA 23 University of California - San Diego - USA 22 University of Minnesota - Twin Cities - USA 22 State University of New York - Stony Brook - USA 22 New York University - USA 21 Rice University - USA 21 Pennsylvania State University - USA 20 University of Rochester - USA 18 University of Utah - USA 18 University of Virginia - USA 16 Ohio State University - USA 16 University of California - Irvine - USA 15 University of Chicago - USA 15 Hebrew University of Jerusalem - Israel 13 University of Colorado Boulder - USA 12 Johns Hopkins University - USA 12 Duke University - USA 12 Rutgers - State University of New Jersey - New Brunswick - USA 10 University of California - Santa Barbara - USA 10 Computer Science Department Sizes In order to interpret correctly the above data you would need to know the size of each department. University Size (in faculty) Carnegie Mellon University 131 Georgia Institute of Technology 93 Massachusetts Institute of Technology 80 University of California - Irvine 61 University of Maryland - College Park 60 University of Michigan 59 Northwestern University 59 University of California - San Diego 57 University of Illinois at Urbana-Champaign 57 University of California - Berkeley 54 University of Southern California 54 Duke University 52 Stanford University 52 University of Washington 49 Columbia University 48 Purdue University 48 North Carolina State University 47 University of Utah 45 Texas A&M University 42 University of Florida 40 University of California - Los Angeles 40 Virginia Polytechnic Institute and State University 39 University of Colorado Boulder 39 Rutgers - State University of New Jersey - New Brunswick 39 Ohio State University 38 University of Wisconsin - Madison 38 University of Texas - Austin 38 New York University 37 University of Massachusetts - Amherst 37 State University of New York - Stony Brook 36 Cornell University 36 University of Minnesota - Twin Cities 34 Pennsylvania State University 33 University of California - Santa Barbara 32 Princeton University 32 University of North Carolina - Chapel Hill 31 University of California - Davis 31 University of Pennsylvania 31 Brown University 30 University of Chicago 29 Johns Hopkins University 29 Rensselaer Polytechnic Institute 29 Harvard University 25 University of Virginia 23 Arizona State University 23 Washington University - St. Louis 21 University of Rochester 20 Yale University 20 University of Pittsburgh 20 Rice University 20 Boston University 19 University of Arizona 18 California Institute of Technology 15 Dartmouth College 12 New hires since 2009 by University University Number of hires since 2009 Carnegie Mellon University 24 Georgia Institute of Technology 19 University of Michigan 17 University of Colorado Boulder 15 Ohio State University 14 University of Washington 12 University of Southern California 12 Stanford University 12 Columbia University 11 University of Chicago 10 State University of New York - Stony Brook 10 Johns Hopkins University 10 Massachusetts Institute of Technology 10 University of Utah 10 Cornell University 10 Rutgers - State University of New Jersey - New Brunswick 10 University of Illinois at Urbana-Champaign 10 University of Florida 9 New York University 9 Duke University 9 Brown University 9 University of California - Berkeley 8 University of North Carolina - Chapel Hill 8 Texas A&M University 8 University of California - Santa Barbara 8 University of Maryland - College Park 8 University of Wisconsin - Madison 7 North Carolina State University 7 University of Massachusetts - Amherst 7 University of California - San Diego 7 University of Texas - Austin 7 University of Pennsylvania 7 Northwestern University 7 Harvard University 6 Princeton University 6 Dartmouth College 5 Purdue University 5 Virginia Polytechnic Institute and State University 5 Pennsylvania State University 5 Rensselaer Polytechnic Institute 5 Washington University - St. Louis 5 University of California - Irvine 5 University of Rochester 4 University of Virginia 4 University of Minnesota - Twin Cities 4 University of California - Los Angeles 4 California Institute of Technology 4 Rice University 4 Boston University 3 Arizona State University 2 Yale University 2 University of Pittsburgh 2 University of Arizona 1 New hires since 2009 by Field of Research Field of Research Number of hires since 2009 Algorithms & Theory 61 Human-Computer Interaction 34 Machine Learning & Pattern Recognition 32 Artificial Intelligence 30 Bioinformatics & Computational Biology 29 Security & Privacy 28 Networks & Communications 27 Computer Vision 23 Distributed & Parallel Computing 21 Graphics 18 Hardware & Architecture 17 Software Engineering 15 Databases 15 Programming Languages 13 Natural Language & Speech 11 Scientific Computing 11 Data Mining 10 Computer Education 9 Operating Systems 9 Real-Time & Embedded Systems 8 Multimedia 1 The Paper A paper titled \"Crowdsourcing from Scratch: A Pragmatic Experiment in Data Collection by Novice Requesters\" has been accepted at HCOMP 2015. Supplemental Analysis by Prof. Jeff Huang Professor Jeff Huang has released a detailed analysis that accompanies this dataset on his website. He reports Composition of Computer Science Departments, Hiring Trends of Universities, andEducational Background of Professors. You can find his analysis here . Ranking based on the Number of Papers in Theory Professor Mohammad Taghi Hajiaghayi and his student Saeed Seddighin of University of Maryland, along with researchers from MIT created a revised ranking of CS Departments based on our dataset and the number of papers in Theory. They intend to release a ranking for other CS areas soon. You can find their ranking here . Visual Exploration of Data PhD student M. Adil Yalcin of University of Maryland incorporated our dataset in keshif . You can perform various queries and see the results in an accessible GUI. Behind the scenes This dataset is the outcome of a seminar course on Human-Computer Interaction taught by Professor Jeff Huang in the Department of Computer Science of Brown University , during the academic semester of Spring 2014. As part of an assignment , 19 students were given $30 each and were asked to come up with different strategies that would allow them to employ workers on Amazon Mechanical Turk, in order to collect a full record of all professors in 5 top Computer Science Graduate Programs. Our goal was to create a full record of all Computer Science professors in 50 top Graduate Programs, according to the popular ranking of US News .For now, we restrict the professors to only Full, Associate, or Assistant. Lecturers, Researchers, Teaching faculty are not allowed momentarily. We also only allow professors of the 50 provided universities.In the future we wish to expand this database to fully reflect the status of each Computer Science department. For each professor we require 10 pieces of information Name : Full Name University : The name of the university they teach JoinYear : When they joined that department of Computer Science as faculty Rank : One of Full, Associate, Assistant Subfield : Main field of research. One of the 20 fields reported by Microsoft Academic Bachelors : University they acquired their BSc degree from Masters : University they acquired their MSc degree from Doctorate : University they acquired their PhD degree from PostDoc : University or Company they did their post-doctoral training Sources : at least one link to the source that contains the above information Since we ended up with 2 instances of each department we managed to increase the accuracy of the database by merging them into a single dataset. Special Thanks This work would not be possible without the hard work of 19 exceptional students. We would like to thank: Suliman Alsowelim, Ali Erman Celen, Eda Celen, Connor Gramazio, Hua Guo, Scott Houde, Chris Johnson-Roberson, Danae Metaxa-Kakavouli, Amia Oberai, Alexandra Papoutsaki, Jeff Rasley, Jiangnan Shangguan, Erica Silverstein, Chris Tanner, Guan Wang, Wenting Xie, Fan Yang, Charles Yeh, and Zhe Zhao. Special thanks also to Lucas Kang for curating the dataset over the summer of 2014. And of course thanks to all of you, anonymous or not, contributors. var sc_project=9762582; var sc_invisible=1; var sc_security=\"c69a20ef\"; var scJsHost = ((\"https:\" == document.location.protocol) ?\"https://secure.\" : \"http://www.\");document.write(\"<sc\"+\"ript type='text/javascript' src='\" +scJsHost+\"statcounter.com/counter/counter.js'></\"+\"script>\");", "https://cs.brown.edu/people/bnacar/": "Benjamin Ewing Nacar Brown University 2012 Sc. B. Computer Science (also finished a concentration in Classics) CS31 TA (Fall 2010) Sunlab Consultant (Fall 2011-Spring 2012) CS146 Head TA (Spring 2012) Tstaff, Systems Programmer (2015-2022) Musical projects Ben Nacar's Home Page YouTube channel (insearchofthemuses) Other Ben Nacar's Other Stuff Contact benjamin_nacar at alumni dot brown dot edu bnacar at cs dot brown dot edu ben at bennacar dot com CS Home People", "https://raphael-group.github.io/research/": "Research Teaching Publications Software Projects AncesTree Binary Tree Partition CHISEL CNT-ILP CNT-MD CoMEt Dendrix GASV & GASVPro Gremlin HATCHet HotNet HotNet2 MAGI MASCoTE MoDL Multi-Dendrix MultiBreak-SV NAIBR NBC PASTRI PREGO RAIG SPRUCE Survival Analysis TADtree THetA/THetA2 WExT People News research We develop algorithms and mathematical models to address biological problems. Major areas of interest include computational cancer genomics, human structural variation, and comparative genomics. The motivation for many of our current projects derives from the tremendous advances in DNA sequencing technology over the past few years. Next-generation DNA sequencing machines have lowered the cost of DNA sequencing by orders of magnitude, and enabled a variety of new applications such as personal genome sequencing and cancer genome sequencing. Computational Cancer Genomics We develop algorithms to study somatic mutations that drive cancer progression. Specific areas of interest include: Identification of genome rearrangements (including translocations, inversions, deletions, and duplications) in cancer genomes. We designed the RAIG and NBC algorithms to detect recurrent and independent copy number aberrations. Reconstruction of highly scrambled cancer genomes and the mechanisms that produce them. We introduced the PREGO algorithm to combine rearrangement breakpoints and copy number data in cancer genomes.Study of changes in gene structure and regulation that result from these rearrangements. Cancer Genome Evolution. Cancer is a microevolutionary process in a population of cells that reproduce (via cell division) and acquire new mutations. Extracting information about the process of tumor evolution from bulk sequencing data containing mixtures of cells demands novel computational approaches. We developed several algorithms to study intra-tumor heterogeneity and tumor evolution including THetA , rec-BTP , and AncesTree . Network and pathway-based analysis of somatic mutations. We designed the HotNet and HotNet2 algorithms for de novo identification of mutated subnetworks in large-scale protein-protein interaction networks using somatic mutation data from multiple cancer patients. De novo identification of combinations of mutually exclusive mutations. Early cancer sequencing studies demonstrated that in many cases somatic mutation of a single gene in a pathway (e.g. a pathway controlling cell growth) is sufficient to perturb this pathway. This implies that when examining somatic mutations from many patients, mutations in the same pathway will exhibit a pattern of mutual exclusivity. We designed Dendrix , Multi-Dendrix and CoMEt algorithms for de novo identification of one or more sets of mutually exclusive mutations. Comparative Genomics We study the role of structural variation (genome rearrangements, segmental duplications, and repeats) in evolution and human genetics. Sequencing Structural Variants We are developing scalable and robust algorithms to identify structural variants in individual genomes and to compare structural variants across individuals using various second and third generation DNA sequencing technologies. We introduced Geometric Analysis of Structural Variants (GASV) a geometric method that explicitly computes the information that each measurement reveals about the boundaries (breakpoints) of a structural variant and quantifies the uncertainty associated with this measurement. We are designing algorithms to maximize the effectiveness of emerging single-molecule sequencing technologies for detecting and assembling complex structural variants and for de novo genome assembly. In particular, we designed the MultiBreak-SV algorithm for long-read and strobe read sequencing data from Pacific Biosciences . Other Research We have also worked on a number of other areas in computational biology. Examples include: Visualization and collaborative annotation of genomics data (O\u2019Brien et al. 2010, Leiserson et al. 2015) Chromatin organization (Weinreb and Raphael 2015). Proteomics (Nguyen et al. 2009, Ritz et al. 2009), Metagenomic studies of protein family diversity (Yooseph et al. 2006) Multiple sequence alignment with block rearrangements (Raphael, et al. 2004) Motif finding (Raphael, Liu and Varghese, 2004) See the publications page for further details. \u00a9 Raphael Research Group 2014-2017 Princeton University Department of Computer Science (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-47814233-1', 'brown.edu'); ga('send', 'pageview'); var sc_project=9594876; var sc_invisible=1; var sc_security=\"fcd5c198\"; var scJsHost = ((\"https:\" == document.location.protocol) ? \"https://secure.\" : \"http://www.\"); document.write(\"<sc\"+\"ript type='text/javascript' src='\" + scJsHost+ \"statcounter.com/counter/counter.js'></\"+\"script>\");", "https://cs.brown.edu/people/dhl/": "David H. Laidlaw Computer Science Brown University Visualization Research Lab lab research pages Research Interests Caltech graphics group Beckman Institute Biology division web pages Some of the projects I am directing and participating in are alsodescribed in the scientific visualization pages of the Brown Graphics Group. Check out the VR Wiki that my cs1951t class has been building. My CV lists publications, teaching,service, funding, and has links to papers. List of allpublications at DPLP , and at PubMed diffusion MRI data Questions, comments, suggestions? E-mail me: dhl@cs.brown.edu Office: CIT 521 Snail mail: Box 1910, Computer Science Department Brown University Providence, RI 02912 Packages: Computer Science Dept 115 Waterman St 4th floor Providence, RI 02906 401-863-7600 (voice) 401-863-7657 (fax) For students If you are in CS, See my tips for advisees page var gaJsHost = ((\"https:\" == document.location.protocol) ? \"https://ssl.\" : \"http://www.\");document.write(unescape(\"%3Cscript src='\" + gaJsHost + \"google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E\")); var pageTracker = _gat._getTracker(\"UA-4338065-1\");pageTracker._initData();pageTracker._trackPageview();", "https://cs.brown.edu/people/dc65/": "Do Kook (DK) Choe Hi, I am DK. I am interested in Natural Langauge Processing and Deep Learning. I am a member of Descartes headed by Ray Kurzweil at Google. While interning in 2015 with Yun-hsuan Sung and Brian Strope , I built a prototype of a Natural Language Understanding (NLU) system, which now serves Allo , Smart Reply and other products. Now I work on improving the NLU system and exploring its new applications. I developed a state-of-the-art parser and received my PhD from Brown University under the supervision of Eugene Charniak . In the summer of 2014, I was an intern at IBM Research working on parsing with David McClosky and Jennifer Chu-Carroll . During my undergrad at NYU, I did research with David Sontag on MAP inference. Contact me at dokookchoe@gmail.com . Publications EMNLP, November 2016 Parsing as Language Modeling Do Kook Choe, Eugene Charniak EMNLP, September 2015 Syntactic Parse Fusion Do Kook Choe, David McClosky, Eugene Charniak ACL, July 2015 Parsing Paraphrases with Joint Inference (extended version) Do Kook Choe, David McClosky ACL, July 2015 Sparse, Contextually Informed Models for Irony Detection: Exploiting User Communities, Entities and Sentiment Byron C. Wallace, Do Kook Choe, Eugene Charniak ACL, June 2014 Humans Require Context to Infer Ironic Intent (so Computers Probably do, too) Byron C. Wallace, Do Kook Choe, Laura Kertz, Eugene Charniak EMNLP, October 2013 Naive Bayes Word Sense Induction Do Kook Choe, Eugene Charniak UAI, August 2012 Efficiently Searching for Frustrated Cycles in MAP Inference David Sontag, Do Kook Choe, Yitao Li", "https://cs.brown.edu/people/eupfal/home.htm": "Home Biography Publications Research Teaching Editorial Consulting Brown University P.O. Box 1910 Providence, RI 02912 USA Voice: 401-863-7645 Fax: 401-863-7657 Mail: eli@cs.brown.edu I'm the Rush C. Hawkins professor of computer science at Brown University, during 2002 -2007 I was also the department chair. Before coming to Brown in 1998 I was a researcher and project manager at the IBM Almaden Research Center in California, and a professor at the Weizmann Institute in Israel. I received an undergraduate degree in mathematics and statistics and a doctorate degree in computer science from the Hebrew University in Jerusalem, Israel. My research focuses on the design and analysis of algorithms. In particular I'm interested in randomized algorithms and probabilistic analysis of algorithms. Applications range from combinatorial and stochastic optimization to routing and communication networks, computational biology, and computational finance. Visit our Research Group Page My Erdos number is 2, and I am a mathematical descendant of Eli Shamir, Jacques Hadamard (4th generation), Simeon Denis Poisson (8th generation) and Pierre-Simon Laplace (9th generation). . Designed by Ahmed Idrissi", "https://cs.brown.edu/people/echarnia/": "Eugene Charniak ec@cs.brown.edu Box 1910, Computer Science Department Brown University Providence, RI 02912 401-863-7636 (voice) 401-863-7657 (fax) Finger me. Index: Books Recent Publications Biographical Material CS 241 Natural Language Processing at Brown Software Books Statistical Language Learning , Cambridge: MIT Press(1993) Introduction to ArtificialIntelligence (with Drew McDermott), Reading MA: Addison-Wesley (1985) Artificial Intelligence Programming (now in a second edition) (with Chris Riesbeck, Drew McDermott, andJames Meehan), Hillsdale NJ: Lawrence Erlbaum Associates (1980, 1987) Computational Semantics , (withYorick Wilks), Amsterdam: North-Holland (1976) Publications in Statistical Language Processing Parsing and Speech Immediate-Head Parsing for Language Models Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics(2001)An abstract and gzipped postscript version areavailable. Edit Detection and Parsing for TranscribedSpeech (with Mark Johnson).Proceedings of the 2nd Meeting of the North American Chapter of theAssociation for Computational Linguistics, pp 118-126 (2001)An abstract and gzipped postscript version areavailable. Lexical Semantics and Anaphora Unsupervised learning of name structure fromcoreference data Proceedings of the 2nd Meeting of the North American Chapter of theAssociation for Computational Linguistics, pp 48-54 (2001)An abstract and gzippedpostscript version are available. Finding parts in very large corpora (with Matthew Berland), Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pp 57-64 (1999)An abstract and postscript version areavailable. A statistical approach to anaphora resolution ,(with Niyu Ge and John Hale),Proceedings of the Sixth Workshop on Very Large Corpora(1998).An abstract and postscript version areavailable. Noun-phrase co-occurrence statistics for semi-automatic semantic lexicon construction ,(with Brian Roark),Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics(1998)An abstract anda postscript version are available. Efficient Parsing Edge-based best-first chart parsing ,(with Sharon Goldwater and Mark Johnson),Proceedings of the Sixth Workshop on Very Large Corpora (1998)An abstract and postscript version areavailable. New figures of merit for best-first probabilistic chart parsing , (with Sharon Caraballo) Computational Linguistics , (1998).A postscript version is available. Statistical Parsing A Maximum-Entropy-Inspired Parser Proceedings of NAACL-2000An abstract and postscript version are available. Statistical techniques for natural language parsing AI Magazine. (1997).An abstract and postscript version are available. Statistical parsing with a context-free grammar and word statistics ,Proceedings of the Fourteenth National Conference on Artificial IntelligenceAAAI Press/MIT Press, Menlo Park (1997).An abstract and postscript version are available. Tree-bank grammars ,Technical Report CS-96-02,Department of Computer Science, Brown University (1996).An abstract and postscript version are available. A statistical syntactic disambiguation program and what it learns , (withMurat Ersan), TR CS-95-29 Brown University, Department of Computer Science (1996). (In Symbolic, Connectionist, and Statistical Approaches to Learning for Natural Language Processing ,S. Wermter, E. Riloff, and G. Scheler Eds.,New York: Springer (1996).)An abstract and postscript version are available. Part-of-Speach Tagging Taggers for parsers , (withGlenn Carroll, John Adcock, Antony Cassandra, Yoshihiko Gotoh,Jeremy Katz, Michael Littman, and John McCann),Artificial Intelligence (forthcoming).An abstract and postscript version are available.The techreport version is also available. Equations for part-of-speech tagging , withCurtis Hendrickson, Neil Jacobson, and Mike Perkowitz,Proceedings of the Eleventh National Conference on Artificial Intelligence,Menlo Park: AAAI Press/MIT Press (1993) 784-789.An abstract and postscript version are available. Software nlparser To inspire research into parsing, I thought it might be interestingto publicize a list of sentences on which my parser performspoorly. Look here. Biographical Material Eugene Charniak is Professor of ComputerScience . and Cognitive Scienceat Brown University.He received an A.B. degree in Physics from University ofChicago and a Ph.D. from M.I.T. in Computer Science. He haspublished four books: Computational Semantics , withYorick Wilks (1976); Artificial Intelligence Programming (now in a second edition) with Chris Riesbeck, Drew McDermott, andJames Meehan (1980, 1987); Introduction to ArtificialIntelligence with Drew McDermott (1985); and StatisticalLanguage Learning (1993). He is a Fellow of the AmericanAssociation of Artificial Intelligence and was previously a Councilorof the organization. His research has always been in the area oflanguage understanding or technologies which relate to it, such asknowledge representation, reasoning under uncertainty, and learning.Over the last few years he has been interested in statisticaltechniques for language understanding. His research in this area hasincluded work in the subareas of part-of-speech tagging,probabilistic context-free grammar induction, and, more recently,syntactic disambiguation through word statistics, efficient syntacticparsing, and lexical resource acquisition through statistical means.", "https://cs.brown.edu/people/epavlick/": "Research (current) Teaching Data Contact Ellie Pavlick I am an Assistant Professor of Computer Science and Linguistics at Brown University , and a Research Scientist at Google Deepmind . I lead the Language Understanding and Representation (LUNAR) Lab, which seeks to understand how language \"works\" and to build computational models which can understand language the way that humans do. My lab's projects focus on language broadly construed, and often includes the study of capacities more general than language, including conceptual representations, reasoning, learning, and generalization. We are interested in understanding how humans acheive these things, how computational models (especially large language models and similar types of \"black box\" AI systems) achieve these things, and what insights can be gained from comparing the two. We often collaborate with researchers outside of computer science, including cognitive science, neuroscience, and philosophy. For more information on my current research priorities, please visit the LUNAR Lab page . My Google Scholar page is probably the best place to see what my students, collaborators, and I have been up to most recently. Copyright \u00a9 Ellie Pavlick 2017", "https://cs.brown.edu/people/eupfal/": "Home Biography Publications Research Teaching Editorial Consulting Brown University P.O. Box 1910 Providence, RI 02912 USA Voice: 401-863-7645 Fax: 401-863-7657 Mail: eli@cs.brown.edu I'm the Rush C. Hawkins professor of computer science at Brown University, during 2002 -2007 I was also the department chair. Before coming to Brown in 1998 I was a researcher and project manager at the IBM Almaden Research Center in California, and a professor at the Weizmann Institute in Israel. I received an undergraduate degree in mathematics and statistics and a doctorate degree in computer science from the Hebrew University in Jerusalem, Israel. My research focuses on the design and analysis of algorithms. In particular I'm interested in randomized algorithms and probabilistic analysis of algorithms. Applications range from combinatorial and stochastic optimization to routing and communication networks, computational biology, and computational finance. Visit our Research Group Page My Erdos number is 2, and I am a mathematical descendant of Eli Shamir, Jacques Hadamard (4th generation), Simeon Denis Poisson (8th generation) and Pierre-Simon Laplace (9th generation). . Designed by Ahmed Idrissi", "http://www.cs.pomona.edu/~apapoutsaki/": "About Publications Teaching Miscellaneous Alexandra Papoutsaki she/her/hers alexandra.papoutsaki@pomona.edu I am an Associate Professor in Computer Science at Pomona College .I received my PhD fromthe Department of Computer Science at Brown University , under the guidance of Prof. Jeff Huang .I completed my masters at Brown while working with Prof. Benjamin Raphael and hold a B.Sc. from Athens University of Economics and Business . My research focuses on Human-Computer Interaction and in particular on the methodology ofeye tracking.For a long time, my goal has been to democratize eye tracking by using webcams instead ofrelying on specialized equipment.Recently, I have started looking on the effect of gaze sharing on remote collaborations, aline of research that is supported by NSF .I am also interested in health informatics and crowdsourcing and I used to work oncomputational biology. Curriculum Vitae Publications Cross-Language Music Recommendation Exploration Stefanos Stoikos, David Kauchak, Douglas Turnbull, Alexandra Papoutsaki ICMR 2023 Webcam-based eye tracking to detectmind wandering and comprehension errors Stephen Hutt, Aaron Wong, Alexandra Papoutsaki , Ryan S. Baker, Joshua I. Gold,Caitlin Mills Behavior Research Methods, (2023). ReadabilityResearch: An Interdisciplinary Approach Sofie Beier, Sam Berlow, Esat Boucaud, Zoya Bylinskii, Tianyuan Cai, Jenae Cohn, KathyCrowley, Stephanie L Day, Tilman Dingler, Jonathan Dobres, Jennifer Healey, Rajiv Jain,Marjorie Jordan, Bernard Kerr, Qisheng Li, Dave B Miller, Susanne Nobles, AlexandraPapoutsaki , Jing Qian, Tina Rezvanian, Shelley Rodrigo, Ben D Sawyer, Shannon MSheppard, Bram Stein, Rick Treitman, Jen Vanek, Shaun Wallace, Benjamin Wolfe Foundations and Trends in Human-Computer Interaction, (2022), 16(4), 214-324. Designing Flexible Longitudinal Regimens:Supporting Clinician Planning for Discontinuation of Psychiatric Drugs Eunkyung Jo, Myeonghan Ryu, Georgia Kenderova*, Samuel So*, Bryan Shapiro, AlexandraPapoutsaki , Daniel A. Epstein CHI 2022:352 (first round; 12.5% acceptance rate) Theelephant in the room: attention to salient scene features increases with comedicexpertise Ori Amir, Konrad J. Utterback*, Justin Lee*, Kevin S. Lee*, Suehyun Kwon*, Dave M.Carroll*, Alexandra Papoutsaki Cognitive Processing, (2022), 10.1007/s10339-022-01079-0 Understanding Delivery ofCollectively Built Protocols in an Online Health Community for Discontinuation ofPsychiatric Drugs Alexandra Papoutsaki , Samuel So*, Georgia Kenderova*, Bryan Shapiro, Daniel A.Epstein PACM Human-Computer Interaction 5(CSCW2): 420 (2021) Case Studies on the Motivation andPerformance of Contributors Who Verify and Maintain In-Flux Tabular Datasets Shaun Wallace, Alexandra Papoutsaki , Neilly H. Tan*, Hua Guo, Jeff Huang PACM Human-Computer Interaction 5(CSCW2): 448 (2021) Effects of Shared Gaze on Audio- VersusText-Based RemoteCollaborations Grete Helena K\u00fctt*, Teerapaun Taprasert*, Jay Rodolitz*, Bernardo Moyza*, Samuel So*,Georgia Kenderova*, Alexandra Papoutsaki PACM Human-Computer Interaction 4(CSCW2): 136 (2020) Eye-Write: Gaze Sharing for CollaborativeWriting Grete Helena K\u00fctt*, Kevin Lee*, Ethan Hardacre*, Alexandra Papoutsaki CHI 2019:497 (24% acceptance rate) The Eye of the Typer: A Benchmark and Analysisof Gaze Behavior during Typing Alexandra Papoutsaki , Aaron Gokaslan*, James Tompkin, Yuze He, Jeff Huang ETRA 2018:16 (34% acceptance rate) Dataset Remotion: A Motion-Based Capture andReplay Platform of Mobile Device Interaction for RemoteUsability Testing Jing Qian, Arielle Chapin*, Alexandra Papoutsaki , Fumeng Yang, Klaas Nelissen,Jeff Huang ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, (2018) 2(2), 77 Website Lessons Learned from Two Cohorts ofPersonal Informatics Self-Experiments Nediyana Daskalova, Karthik Desingh, Alexandra Papoutsaki , Diane Schulze*, HanSha, Jeff Huang ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, (2017) 1(3): 46 SearchGazer: Scalable Webcam EyeTracking for Remote Studies of Web Search Alexandra Papoutsaki , James Laskey*, Jeff Huang CHIIR 2017 (42% acceptance rate, Best Paper Finalist ) Website Software WebGazer: Scalable Webcam Eye TrackingUsing User Interactions Alexandra Papoutsaki , Patsorn Sangkloy, James Laskey*, Nediyana Daskalova, JeffHuang, James Hays IJCAI 2016 (25% acceptance rate) Website Software Crowdsourcing from Scratch: APragmatic Experiment in Data Collection by Novice Requesters Alexandra Papoutsaki , Hua Guo, Danae Metaxa-Kakavouli*, Connor Gramazio, JeffRasley, Wenting Xie*, Guan Wang, Jeff Huang HCOMP 2015 (30% acceptance rate, Best Paper Finalist ) Website Analysis Data Scalable Webcam Eye Tracking by Learningfrom User Interactions Alexandra Papoutsaki CHI 2015 Extended Abstracts Genome-Wide SurvivalAnalysis of Somatic Mutations in Cancer Mark D.M. Leiserson, Fabio Vandin, Hsin-Ta Wu, Jason R. Dobson, Jonathan V. Eldridge*,Jacob L. Thomas*, Alexandra Papoutsaki , Younhun Kim, Beifang Niu, Michael McLellan,Michael S. Lawrence, Abel Gonzalez-Perez, David Tamborero, Yuwei Cheng, Gregory A. Ryslik,Nuria Lopez-Bigas, Gad Getz, Li Ding, Benjamins J. Raphael Nature Genetics, (2015) 47(2): 106-114 Website Software AccurateComputation of Survival Statistics in Genome-Wide Studies Fabio Vandin, Alexandra Papoutsaki , Benjamin Raphael, Eli Upfal PLoS Computational Biology, (2015) 11(5): e1004071 Genome-WideSurvival Analysis of Somatic Mutations in Cancer Fabio Vandin, Alexandra Papoutsaki , Benjamin Raphael, Eli Upfal RECOMB 2013 (19.2% acceptance rate, Best Paper Award ) Website *: Denotes undergraduate student at the time of writing. Teaching Experience CS 051-A: Intro to Computer Science with Topics in AI Spring 2019 , Spring 2022 , Spring 2023 Instructor , Department of Computer Science - Pomona College CS 062: Data Structures and Advanced Programming Fall 2017 , Spring 2018 , Fall 2018 , Spring 2019, Fall 2019 , Spring 2020 , Fall 2021 , Fall 2023 Instructor , Department of Computer Science - Pomona College CS 124: User Interfaces and User Experience Fall 2017,Spring 2018,Spring 2019,Fall 2021 Instructor , Department of Computer Science - Pomona College CS 190: Computer Science Senior Seminar Fall 2018, Fall 2019 , Fall 2023 Instructor , Department of Computer Science - Pomona College CS 188: Computer Science Colloquium 2019-2020 Instructor , Department of Computer Science - Pomona College CS1950N: Topics in 2D Games Fall 2016 Instructor , Department of Computer Science - Brown University FinalProjects CS0931: Introduction to Computation for the Humanities and Social Sciences Fall 2015 Instructor , Department of Computer Science - Brown University Seminar in Human Computer Interaction Spring 2015 and Spring 2014 Teaching Assistant , Department of Computer Science - Brown University Instructor: Prof. Jeff Huang Brown Computer Sciencewithout Borders Spring 2012 and Spring 2013 Teaching Assistant , Department of Computer Science - Brown University \u00a9 Alexandra Papoutsaki | Design: HTML5 UP . var sc_project = 8508354;var sc_invisible = 1;var sc_security = \"bd9ce18b\";var scJsHost = ((\"https:\" == document.location.protocol) ?\"https://secure.\" : \"http://www.\");document.write(\"<sc\" + \"ript type='text/javascript' src='\" +scJsHost +\"statcounter.com/counter/counter.js'></\" + \"script>\");", "https://cs.brown.edu/people/faculty/bjm.html": "Barbara J. Meier Distinguished Senior Lecturer in Computer Science Office: CIT 401 Phone: 401-863-7604 Email: barbara_meier @@ @brown.edu Assistant: Dawn T Reed Research Areas: Graphics and Visualization Teaching: Fall 2024 CSCI1250 Introduction to Computer Animation Spring 2025 (not teaching) Home Page I teach introductory and intermediate computer animation. In the intro course, students learn the steps of the animation production pipeline including story/script writing, planning, modeling, shading, lighting, animating, and compositing. They use commercial software to complete exercises and a short finished animation. In the intermediate course, students learn the technical workflows for character modeling, rigging, animating, shading, and lighting in more depth. My research is in computer graphics techniques. My focus is creating and using tools for artists. Past work includes WYSIWYG NPR, or \"What you see is what you get non-photorealistic rendering.\" In this prototype system, artists draw directly on 3d models to create stylized silhouettes, shading, and decal designs. I also worked on the Accessible Color Project to make color easier to use in graphics programs for both novices and experts. Some of this work resulted in Interactive Color Palette Tools. I am interested in figuring out ways that artists, especially animators, can use computers in conjunction with their current skills to alleviate some of the tedium of creating scores of images as well as to explore new looks and techniques. In addition, I work on personal animated films and have an oil painting practice.", "https://cs.brown.edu/people/faculty/amy/": "Amy R Greenwald Professor of Computer Science Office: CIT 383 Phone: 401-863-7678 Email: amy @@ @cs.brown.edu Assistant: Lori Agresti Research Areas: Artificial Intelligence, Multi-Agent Systems, Reinforcement Learning, Algorithmic Game Theory Teaching: Fall 2024 (not teaching) Spring 2025 CSCI1440 Algorithmic Game Theory CSCI2440 Advanced Algorithmic Game Theory Publications by Amy R Greenwald Home Page In our increasingly networked world, fewer and fewer decisions can be made in isolation. Consequently, AI agents \"artificially intelligent, programmed decision-makers\" must cooperate, compete, and trade with other agents, both human and artificial. This trend drives Amy Greenwald's twin research goals: first, the effort to design and implement AI agents that interact effectively in multiagent environments; second, the effort to understand, explain, and accurately predict the dynamics of such interactions. In pursuing these goals, Prof. Greenwald draws from theoretical and practical sources, including a variety of disciplines such as AI, decision theory, game theory, and economics.", "https://cs.brown.edu/people/eg29/": "Esha Ghosh Contact: esha [underscore] ghosh [at] brown [dot] edu I am a Ph.D candidate at Brown University working with Professor Roberto Tamassia . I am interested in applied cryptography and computer security. My current research addresses the security and privacy of cloud storage and cloud applications with work on authenticated data structures, verifiable computation, efficient and zero-knowledge verification of queries on outsourced data, and data integrity protocols. My other interests include algorithms and data structures. My research is supported in part by the U.S. National Science Foundation and by the Paris C. Kanellakis Fellowship at Brown University. I was supported by Coline M. Makepeace Fellowship for the academic year 2012-13. Before joining Brown as a grad student, I completed my MS (by research) at the Theory group at IIT Madras in India under the guidance of Professor C. Pandu Rangan . My masters thesis was on Hamiltonicity and Longest Path Problem on Special Classes of Graphs.During my masters, I interned at the Distributed Systems group at Siemens Research under the mentorship of Mr. Subhas K. Ghosh and I worked on Independent Spanning Trees problem on Optical Transpose Interconnect System. After finishing my masters, I was a Project Associate in the Fixed Parameter Algorithms group at IMSc , India between December 2011 and July 2012 and I was mentored by Dr. Saket Saurabh. Internships: I am interning with the Cloud Storage and Security group at IBM Research Zurich from June - December 2016. I spent the summer of 2015 interning in the Constructive Security group at Microsoft Research Cambridge. Recent Work in Security and Privacy: Hash First, Argue Later: Adaptive Verifiable Computations on Outsourced Data Dario Fiore, Cedric Fournet, Esha Ghosh, Markulf Kohlweiss, Olga Ohrimenko and Bryan Parno In: CCS 2016 Authenticated Range & Closest Point Queries in Zero-Knowledge Esha Ghosh, Olga Ohrimenko and Roberto TamassiaIn: PETS 2016 Zero-Knowledge Accumulators and Set Operations Esha Ghosh, Olga Ohrimenko, Dimitrios Papadopoulos, Roberto Tamassia and Nikos TriandopoulosTo appear: ASIACRYPT 2016 Fully-Dynamic Verifiable Zero-Knowledge Order Queries for Network Data Esha Ghosh, Michael T. Goodrich, Olga Ohrimenko and Roberto Tamassia In: SCN 2016 Verifiable Order Queries and Order Statistics on a List in Zero-Knowledge Esha Ghosh, Olga Ohrimenko and Roberto Tamassia In: ACNS 2015 This work won the Best Student Paper award at ACNS and was covered in Brown CS news . Posters and Talks: I gave talks on Efficient Zero-Knowledge Authenticated Data Structures at Microsoft Research, Redmond (hosted by Dr. Melissa Chase) in March 2016 and at University of Maryland (hosted by Prof. Jonathan Katz) in November 2015. Zero-Knowledge Authenticated Order Queries and Applications Esha Ghosh, Michael T. Goodrich, Olga Ohrimenko and Roberto TamassiaIn: IEEE Symposium on Security and Privacy 2015 and In: New England Security Day 2015 I gave invited talks at R. C. Bose Centre for Cryptology and Security, ISI Kolkata , India and IIIT Delhi , India in December 2014 and gave a short talk at CRYPTO 2014 rump session. Work in Graph Algorithms: Faster Parameterized Algorithms for Deletion to Split Graphs. (Extended version) Esha Ghosh, Sudeshna Kolay, Mrinal Kumar, Pranabendu Misra, Fahad Panolan, Ashutosh Rai, and M.S. Ramanujan In: Algorithmica April 2015, Volume 71, Issue 4 Faster Parameterized Algorithms for Deletion to Split Graphs. Esha Ghosh, Sudeshna Kolay, Mrinal Kumar, Pranabendu Misra, Fahad Panolan, Ashutosh Rai, and M.S. Ramanujan In: SWAT 2012 On Fault Tolerance and Hamiltonicity of Optical Transpose Interconnection System of Non-Hamiltonian Base Graphs Esha Ghosh, Subhas K. Ghosh, and C. Pandu Rangan A Polynomial Time Algorithm for Longest Paths in Biconvex Graphs Esha Ghosh, N. S. Narayanaswamy, and C. Pandu Rangan In: WALCOM 2011 Other: I TA-ed for Professor Anna Lysyanskaya in Fall 2014 for the course Models of Computation . During my MS at IIT Madras, I had TA-ed for Advanced Topics in Formal Languages and Automata I have been the external reviewer for Cryptology and Network Security (CANS) 2016, Public Key Cryptography (PKC), 2016, ACM Conference on Computer and Communications Security (CCS), 2014 and 2016 and Workshop on Privacy in the Electronic Society (WPES) 2014.", "https://cs.brown.edu/people/faculty/alysyans/": "Anna A Lysyanskaya James A. and Julie N. Brown Professor of Computer Science Office: CIT 501 Phone: 401-863-7605 Email: alysyans @@ @cs.brown.edu Assistant: Lori Agresti Research Areas: Security and Cryptography Teaching: Fall 2024 (not teaching) Spring 2025 CSCI1040 The Basics of Cryptographic Systems Publications by Anna A Lysyanskaya Home Page Anna Lysyanskaya's primary research area is cryptography, the study of protecting communication and computation against malicious users. The fundamental problems in this area are secure communication, authentication of data, pseudorandomness, and secure multi-party computation. Prof. Lysyanskaya wrote her Ph.D. thesis on digital signature schemes and their applications in protocols. Her thesis explores the uses of digital signature schemes in cryptographic protocols, as well as proposes several signature schemes especially suitable for use in protocols. Cryptography in general, and signature schemes in particular, depends on computational assumptions. A proof that a scheme is unbreakable amounts to showing that solving a certain computational problem is infeasible in any reasonable time. Unconditional proofs of infeasibility of problems relevant to cryptography are not known, and they would imply that P is different from NP. Therefore, in cryptography we have to settle for assumptions that certain tasks are infeasible. Prof. Lysyanskaya is interested in such issues as efficient and provably secure cryptographic protocols, minimal complexity assumptions for achieving security in various settings, and secure distributed computation.", "https://cs.brown.edu/people/faculty/avandam/": "Andries van Dam Thomas J. Watson Jr. University Professor of Technology and Education, Professor of Computer Science Office: CIT 465 Phone: 401-863-7640 Email: avandam @@ @cs.brown.edu Assistant: Lisa Manekofsky Research Areas: Graphics and Visualization Teaching: Fall 2024 CSCI0150 Introduction to Object-Oriented Programming and Computer Science Spring 2025 (not teaching) Publications by Andries van Dam Home Page Tell us a little about your background: educational, professional, personal, etc. I am originally from the Netherlands but immigrated with my parents in 1952. Originally trained as an electronic engineer at Swarthmore College and then University of Pennsylvania for graduate school, I switched to computer science after taking my first course and falling in love with the material. I got the second Ph.D. explicitly in CS in the US, in 1966 in Penn's brand new CS degree program, and came to Brown in 1965 because of its emphasis on undergraduate teaching. I was founding chairman of the Department in 1979. What do you focus on in your research? Any recent advances? My main interest is in interactive computer graphics, as reflected by my first technical paper: \"Computer-Driven Displays and their Use in Man-Machine Interaction (1966)\". The Brown Graphics Group is the longest continuously running graphics research group in the world, and CS123, Introduction to Computer Graphics, is similarly the longest-running graphics course. For nearly two decades I've been most interested in post-WIMP UI's, including Virtual Reality and pen- and touch-computing. What do you like teaching classes about? I love teaching beginners, whether in programming/CS or in graphics. Getting students hooked and often changing their lives is a source of great satisfaction. How did you become interested in computer science? Taking an elective in the brand-new area of digital computers and programming, to get some relief from the normal math-intensive EE courses What is your favorite thing about Brown? The unending stream of great undergraduates who fall in love with the subject as I did, and have great enthusiasm and work ethic. The undergraduate TA and RA programs I started in 1965 are a continuing source of pleasure for me, and have led to nearly 40 students that I worked with over the decades to become academics, the achievement I am most proud of. Any hobbies or passions? Outdoor activities (mountain and road biking, skiing, sea-kayaking, scuba-diving, backpacking), my three grandkids, eating and drinking well.", "https://cs.brown.edu/people/faculty/dhl/": "David H. Laidlaw Professor of Computer Science Office: CIT 521 Phone: 401-863-7647 Email: dhl @@ @cs.brown.edu Assistant: Dawn T Reed Research Areas: Human-Computer Interaction, Graphics and Visualization, Computational Biology, Data Science, Design Teaching: Fall 2024 CSCI2370 Interdisciplinary Scientific Visualization Spring 2025 (not teaching) Publications by David H. Laidlaw Home Page David Laidlaw is interested in visualization and modeling applications of computer graphics and computer science to other scientific disciplines. Applications give a real-world direction to computational research and are also compelling because they can provide concrete answers to questions about how our world works. He is working with researchers in, for example, archaeology, developmental neurobiology, medical imaging, orthopaedics, art, cognitive science, remote sensing, and fluid mechanics to develop new computational applications and to understand their strengths and weaknesses. Some applications he is particularly interested in are visualization of multivalued multidimensional imaging data, comparisons of virtual and nonvirtual environments for scientific tasks, and applications of art and perception to visualization.", "https://cs.brown.edu/people/faculty/eupfal/": "Eli Upfal Rush C. Hawkins Professor of Computer Science Office: CIT 319 Phone: 401-863-7645 Email: eupfal @@ @cs.brown.edu Primary Research Areas: Theory, Algorithms and Theory, Randomized Algorithms and Probabilistic Analysis, Machine Learning, Data Science Secondary Research Areas: Artificial Intelligence, Computational Biology, Deep Learning, Security Teaching: Fall 2024 (not teaching) Spring 2025 CSCI1550 Probabilistic Methods in Computer Science Publications by Eli Upfal Home Page Eli Upfal's general research area is theory of computation: trying to apply rigorous mathematical tools to the design and analysis of computer algorithms. He is particularly interested in applications of probability theory and combinatorics to this area. Randomness comes up in two aspects of the study of algorithms: randomized algorithms and probabilistic analysis of algorithms. Randomized algorithms are algorithms that make random choices during their execution. In many cases the randomized algorithms are more efficient, simpler and easier to program than their deterministic counterparts. Probabilistic analysis of algorithms attempt to characterize the average-case performance of algorithms on typical inputs. This issue is important in computation problems for which there are no efficient solutions for all possible inputs. Recent work includes: Developing probabilistic techniques for studying the long-term behavior of dynamic computer processes such as communication, load balancing, cashing, and paging; a novel combinatorial design improving the design of sequencing by hybridization (SBH) microchips; and stochastic analysis of commodity trading strategies.", "https://cs.brown.edu/people/faculty/fprepara/": "Franco Preparata An Wang Professor Emeritus of Computer Science Phone: 401-863-7649 Email: fprepara @@ @cs.brown.edu Research Areas: Algorithms and Theory, Computational Biology Publications by Franco Preparata Home Page Following early research in switching and coding, culminating in the discovery of the nonlinear Preparata codes, for the past three decades the focus of Franco Preparata's research has been the design and analysis of algorithms in their most general connotation. With the remarkable evolution of computer technology, his research interests have been correspondingly evolving. He has been deeply interested in fundamental algorithms and data structures, VLSI computation and layout, and parallel algorithms. Perhaps the most enduring interest has been computational geometry, a spin-off of algorithmic research aimed at the systematic investigation of methods for the most efficient solution of geometric problems. Geometric problems are ubiquitous in human activities. Sporadic, and frequently inefficient, computer solutions had been proposed before, but in the mid-1970s computational geometry emerged as a self-standing discipline targeted at this important area. The goal of computational geometry is to analyze the combinatorial structure of specific problems as the underpinning of efficient algorithms for their solution. The field burgeoned, and in the mid-1980s Prof. Preparata wrote a textbook on the subject that helped establish it in the instructional arena. Today an enormous body of geometric algorithms is known and this knowledge is increasingly indispensable in several applied areas such as geographic information systems, computer graphics, and computer-aided design and manufacturing. Within the last area, Prof. Preparata has also contributed to computational metrology: the assessment of the geometric quality of manufactured parts. As another example of computer science interacting with other fields, today his main research focus is computational biology (also called \"bioalgorithmics\"), an emerging discipline that entails the development and use of mathematical and computer science techniques to solve problems in molecular biology. Since the discovery of the structure of DNA about 50 years ago and the digital underpinning of molecular biology, huge amounts of data have been generated in this field, making it necessary to resort to sophisticated computer science techniques for their analysis.", "https://cs.brown.edu/people/faculty/": "Faculty {\"Nora Ayanian\": [[\"Robotics\", \"Artificial Intelligence\", \"Multi-Agent Systems\"], [\"Tenure-Stream\"]], \"Stephen Bach\": [[\"Machine Learning\", \"Artificial Intelligence\", \"Data Science\"], [\"Tenure-Stream\"]], \"Ugur Cetintemel\": [[\"Data Science\", \"Database Systems\", \"Distributed Systems\"], [\"Tenure-Stream\"]], \"Yu Cheng\": [[\"Algorithms and Theory\", \"Machine Learning\"], [\"Tenure-Stream\"]], \"Nicholas A DeMarinis\": [[], [\"Lecturer-Stream\"]], \"Lorenzo De Stefani\": [[\"Algorithms and Theory\", \"Machine Learning\", \"Randomized Algorithms and Probabilistic Analysis\"], [\"Lecturer-Stream\"]], \"Thomas W Doeppner\": [[\"Computer Systems\"], []], \"Timothy H Edgar\": [[\"Security Policy\"], []], \"Kathi Fisler\": [[\"Computing Education\", \"Programming Languages\", \"Formal Methods\"], []], \"Amy R Greenwald\": [[\"Artificial Intelligence\", \"Multi-Agent Systems\", \"Reinforcement Learning\", \"Algorithmic Game Theory\"], [\"Tenure-Stream\"]], \"Maurice P Herlihy\": [[\"Distributed Systems\"], [\"Tenure-Stream\"]], \"Ellis Hershkowitz\": [[\"Algorithms and Theory\"], [\"Tenure-Stream\"]], \"Jeff Huang\": [[\"Human-Computer Interaction\", \"Design\", \"Data Science\"], [\"Tenure-Stream\"]], \"John F Hughes\": [[\"Graphics and Visualization\"], [\"Tenure-Stream\"]], \"Deborah Hurley\": [[], []], \"Sorin Istrail\": [[\"Algorithms and Theory\", \"Computational Biology\"], [\"Tenure-Stream\"]], \"Vasileios Kemerlis\": [[\"Security\", \"Computer Systems\", \"Software Engineering\"], [\"Tenure-Stream\"]], \"Philip Klein\": [[\"Algorithms and Theory\"], [\"Tenure-Stream\"]], \"George D Konidaris\": [[\"Artificial Intelligence\", \"Machine Learning\", \"Robotics\"], [\"Tenure-Stream\"]], \"Shriram Krishnamurthi\": [[\"Programming Languages\", \"Computing Education\", \"Networking\", \"Security and Cryptography\", \"Software Engineering\", \"Formal Methods\", \"Human-Computer Interaction\"], [\"Tenure-Stream\"]], \"David H. Laidlaw\": [[\"Human-Computer Interaction\", \"Graphics and Visualization\", \"Computational Biology\", \"Data Science\", \"Design\"], [\"Tenure-Stream\"]], \"Robert Y. Lewis\": [[\"Formal Methods\", \"Programming Languages\", \"Theory\", \"Computing Education\"], [\"Lecturer-Stream\"]], \"Michael L. Littman\": [[\"Artificial Intelligence\", \"Machine Learning\", \"Reinforcement Learning\", \"Robotics\", \"Algorithmic Fairness\"], [\"Tenure-Stream\"]], \"Anna A Lysyanskaya\": [[\"Security and Cryptography\"], [\"Tenure-Stream\"]], \"Barbara J. Meier\": [[\"Graphics and Visualization\"], [\"Lecturer-Stream\"]], \"Peihan Miao\": [[\"Security and Cryptography\", \"Theory\"], [\"Tenure-Stream\"]], \"Tim Nelson\": [[\"Computing Education\", \"Software Engineering\", \"Formal Methods\", \"Algorithms and Theory\", \"Networking\", \"Programming Languages\"], [\"Lecturer-Stream\"]], \"Julia Netter\": [[], []], \"Bernardo Palazzi\": [[\"Security and Cryptography\"], []], \"Ellie Pavlick\": [[\"Artificial Intelligence\", \"Machine Learning\", \"Data Science\", \"Natural Language Processing\"], [\"Tenure-Stream\"]], \"Steven P Reiss\": [[\"Software Engineering\", \"Design\", \"Formal Methods\", \"Graphics and Visualization\", \"Human-Computer Interaction\", \"Security and Cryptography\"], [\"Tenure-Stream\"]], \"Daniel C Ritchie\": [[\"Graphics and Visualization\", \"Artificial Intelligence\", \"Machine Learning\", \"Deep Learning\", \"Computer Vision\"], [\"Tenure-Stream\"]], \"Malte Schwarzkopf\": [[\"Computer Systems\", \"Distributed Systems\", \"Database Systems\"], [\"Tenure-Stream\"]], \"Ritambhara Singh\": [[\"Machine Learning\", \"Deep Learning\", \"Computational Biology\"], [\"Tenure-Stream\"]], \"Srinath Sridhar\": [[\"Computer Vision\", \"Machine Learning\", \"Deep Learning\", \"Artificial Intelligence\", \"Robotics\", \"Human-Computer Interaction\"], [\"Tenure-Stream\"]], \"Chen Sun\": [[\"Computer Vision\", \"Artificial Intelligence\", \"Machine Learning\", \"Deep Learning\"], [\"Tenure-Stream\"]], \"Roberto Tamassia\": [[\"Security and Cryptography\", \"Algorithms and Theory\", \"Data Science\"], [\"Tenure-Stream\"]], \"Stefanie A Tellex\": [[\"Artificial Intelligence\", \"Machine Learning\", \"Robotics\"], [\"Tenure-Stream\"]], \"James H Tompkin\": [[\"Graphics and Visualization\", \"Computer Vision\", \"Human-Computer Interaction\"], [\"Tenure-Stream\"]], \"Eli Upfal\": [[\"Theory\", \"Algorithms and Theory\", \"Randomized Algorithms and Probabilistic Analysis\", \"Machine Learning\", \"Data Science\", \"Artificial Intelligence\", \"Computational Biology\", \"Deep Learning\", \"Security\"], [\"Tenure-Stream\"]], \"Andries van Dam\": [[\"Graphics and Visualization\"], [\"Tenure-Stream\"]], \"Nikos Vasilakis\": [[\"Computer Systems\", \"Distributed Systems\", \"Security\", \"Programming Languages\"], [\"Tenure-Stream\"]], \"Suresh Venkatasubramanian\": [[\"Algorithmic Fairness\", \"Algorithms and Theory\", \"Machine Learning\"], [\"Tenure-Stream\"]], \"Ernesto Zaldivar\": [[\"Security\", \"Security Policy\", \"Human-Computer Interaction\"], []], \"Stanley B Zdonik\": [[\"Database Systems\", \"Distributed Systems\"], [\"Tenure-Stream\"]], \"Milda Zizyte\": [[\"Formal Methods\", \"Robotics\", \"Software Engineering\", \"Computing Education\"], [\"Lecturer-Stream\"]], \"Karianne Bergen\": [[\"Data Science\", \"Machine Learning\", \"Computational Geosciences\", \"Signal Processing\"], [\"Tenure-Stream\"]], \"Roger B Blumberg\": [[], []], \"Adam Blumenthal\": [[\"Virtual Reality\", \"Human-Computer Interaction\", \"Design\", \"Natural Language Processing\"], []], \"Vanessa Cho\": [[], []], \"Pedro F Felzenszwalb\": [[\"Artificial Intelligence\", \"Machine Learning\", \"Algorithms and Theory\", \"Computer Vision\", \"Data Science\"], [\"Tenure-Stream\"]], \"Ian Gonsher\": [[\"Robotics\", \"Design\"], []], \"Serdar Kadioglu\": [[\"Algorithms and Theory\", \"Artificial Intelligence\", \"Machine Learning\", \"Data Science\"], []], \"Ronald Parr\": [[], []], \"Sohini Ramachandran\": [[\"Computational Biology\", \"Data Science\", \"Machine Learning\"], [\"Tenure-Stream\"]], \"Sherief Reda\": [[\"Computer Systems\", \"Computer Architecture\", \"Deep Learning\"], [\"Tenure-Stream\"]], \"Thomas R Serre\": [[], [\"Tenure-Stream\"]], \"Donald L Stanford\": [[\"Security and Cryptography\", \"Human-Computer Interaction\", \"Computer Architecture\"], []], \"Gabriel Taubin\": [[\"3D Scanning\", \"3D Photography\", \"Digital Geometry Processing\", \"Geometric Modeling\", \"Graphics and Visualization\", \"Computer Vision\"], [\"Tenure-Stream\"]], \"Alan M Usas\": [[\"Computing Education\", \"Security and Cryptography\", \"Computer Systems\"], []], \"R. Iris Bahar\": [[\"Computer Architecture\", \"Computer Systems\", \"Robotics\"], []], \"Carsten Binnig\": [[\"Database Systems\"], []], \"Thomas L Dean\": [[\"Artificial Intelligence\", \"Computational Biology\", \"Computer Vision\", \"Deep Learning\", \"Human-Computer Interaction\", \"Machine Learning\", \"Natural Language Processing\", \"Reinforcement Learning\", \"Robotics\"], []], \"Seny F Kamara\": [[\"Security and Cryptography\"], []], \"Joseph J Laviola\": [[\"Human-Computer Interaction\", \"Graphics and Visualization\", \"Robotics\"], []], \"Norm Meyrowitz\": [[\"Software Engineering\", \"Human-Computer Interaction\"], []], \"Franco Preparata\": [[\"Algorithms and Theory\", \"Computational Biology\"], []], \"Matteo Riondato\": [[\"Data Science\", \"Randomized Algorithms and Probabilistic Analysis\"], []], \"John E Savage\": [[\"Security Policy\", \"Theory\"], []], \"Tom Sgouros\": [[\"Algorithmic Fairness\", \"Software Engineering\", \"Data Science\"], []], \"Alper Ahmetoglu\": [[\"Artificial Intelligence\", \"Robotics\", \"Deep Learning\"], []], \"Gianluca Brero\": [[], []], \"Will Crichton\": [[], []], \"Gayathri Garimella\": [[], []], \"David Paulius\": [[\"Robotics\", \"Artificial Intelligence\", \"Natural Language Processing\"], []], \"Jake Russin\": [[], []]} Research Areas Profile Tags Reset Filters 3D Photography 3D Scanning Algorithmic Fairness Algorithmic Game Theory Algorithms and Theory Artificial Intelligence Computational Biology Computational Geosciences Computer Architecture Computer Systems Computer Vision Computing Education Data Science Database Systems Deep Learning Design Digital Geometry Processing Distributed Systems Formal Methods Geometric Modeling Graphics and Visualization Human-Computer Interaction Machine Learning Multi-Agent Systems Natural Language Processing Networking Programming Languages Randomized Algorithms and Probabilistic Analysis Reinforcement Learning Robotics Security Security Policy Security and Cryptography Signal Processing Software Engineering Theory Virtual Reality Lecturer-Stream Tenure-Stream Primary No Match found Nora Ayanian Associate Professor of Computer Science and Engineering Office: CIT 449 Robotics \u2022 Artificial Intelligence, Multi-Agent Systems Fall 2024: (not teaching) \u2022 Spring 2025: CSCI1952-Z Profile \u2022 Home Page Stephen Bach Assistant Professor of Computer Science Office: CIT 335 Machine Learning, Artificial Intelligence, Data Science Fall 2024: (not teaching) \u2022 Spring 2025: CSCI1420 Profile \u2022 Home Page Ugur Cetintemel Khosrowshahi University Professor of Computer Science Office: CIT 437 Data Science, Database Systems, Distributed Systems Fall 2024: CSCI1270 \u2022 Spring 2025: CSCI2270 Profile \u2022 Home Page Yu Cheng Assistant Professor of Computer Science Office: CIT 413 Algorithms and Theory, Machine Learning Fall 2024: CSCI2952-Q \u2022 Spring 2025: CSCI1952-Q Profile \u2022 Home Page Nicholas A DeMarinis Lecturer in Computer Science Office: CIT 317 Fall 2024: CSCI0200 , CSCI1680 \u2022 Spring 2025: CSCI0300 , CSCI1310 , CSCI1620 , CSCI1660 , CSCI2660 Profile Lorenzo De Stefani Lecturer in Computer Science Office: CIT 435 Algorithms and Theory \u2022 Machine Learning, Randomized Algorithms and Probabilistic Analysis Fall 2024: CSCI1010 , CSCI1570 \u2022 Spring 2025: CSCI1951-A Profile \u2022 Home Page Thomas W Doeppner Associate Professor of Computer Science (Research), Vice Chair of Computer Science Office: CIT 405 Computer Systems Fall 2024: CSCI0081 , CSCI0082 , CSCI0330 , CSCI1330 \u2022 Spring 2025: CSCI0081 , CSCI0082 , CSCI1670 , CSCI1690 , CSCI2670 Profile \u2022 Home Page Timothy H Edgar Professor of the Practice of Computer Science Security Policy Fall 2024: CSCI1805 , CSCI1860 \u2022 Spring 2025: CSCI1952-X , CSCI2952-S Profile Kathi Fisler Professor of Computer Science (Research) Office: CIT 309 Computing Education, Programming Languages, Formal Methods Fall 2024: (not teaching) \u2022 Spring 2025: CSCI0200 Profile \u2022 Home Page Amy R Greenwald Professor of Computer Science Office: CIT 383 Artificial Intelligence, Multi-Agent Systems, Reinforcement Learning, Algorithmic Game Theory Fall 2024: (not teaching) \u2022 Spring 2025: CSCI1440 , CSCI2440 Profile \u2022 Home Page Maurice P Herlihy An Wang Professor of Computer Science Office: CIT 341 Distributed Systems Fall 2024: CSCI1760 \u2022 Spring 2025: CSCI1951-L Profile \u2022 Home Page Ellis Hershkowitz Assistant Professor of Computer Science Office: CIT 507 Algorithms and Theory Profile \u2022 Home Page Jeff Huang Associate Professor of Computer Science, Associate Chair of Computer Science Office: CIT 245 Human-Computer Interaction, Design, Data Science Profile \u2022 Home Page John F Hughes Professor of Computer Science, Associate Chair of Computer Science Office: CIT 365 Graphics and Visualization Fall 2024: CSCI0170 \u2022 Spring 2025: (not teaching) Profile \u2022 Home Page Deborah Hurley Professor of the Practice of Computer Science Fall 2024: CSCI1870 \u2022 Spring 2025: CSCI2002 Profile \u2022 Home Page Sorin Istrail James A. & Julie N. Brown Professor of Computational and Mathematical Sciences Office: CIT 523 Algorithms and Theory, Computational Biology Fall 2024: CSCI1810 , CSCI2810 \u2022 Spring 2025: CSCI1820 , CSCI2820 Profile \u2022 Home Page Vasileios Kemerlis Assistant Professor of Computer Science Office: CIT 505 Security, Computer Systems \u2022 Software Engineering Fall 2024: CSCI1650 \u2022 Spring 2025: CSCI2951-U Profile \u2022 Home Page Philip Klein Professor of Computer Science Office: CIT 503 Algorithms and Theory Fall 2024: (not teaching) \u2022 Spring 2025: CSCI0500 , CSCI2500-B Profile \u2022 Home Page George D Konidaris Associate Professor of Computer Science Office: CIT 447 Artificial Intelligence, Machine Learning, Robotics Fall 2024: (not teaching) \u2022 Spring 2025: CSCI2951-X Profile \u2022 Home Page Shriram Krishnamurthi Professor of Computer Science Office: CIT 377 Programming Languages, Computing Education, Networking, Security and Cryptography, Software Engineering, Formal Methods, Human-Computer Interaction Fall 2024: CSCI0190 , CSCI1730 \u2022 Spring 2025: (not teaching) Profile \u2022 Home Page David H. Laidlaw Professor of Computer Science Office: CIT 521 Human-Computer Interaction, Graphics and Visualization, Computational Biology, Data Science, Design Fall 2024: CSCI2370 \u2022 Spring 2025: (not teaching) Profile \u2022 Home Page Robert Y. Lewis Lecturer in Computer Science Office: CIT 433 Formal Methods, Programming Languages \u2022 Theory, Computing Education Fall 2024: CSCI1260 \u2022 Spring 2025: CSCI0220 Profile \u2022 Home Page Michael L. Littman University Professor of Computer Science Office: CIT 301 Artificial Intelligence, Machine Learning, Reinforcement Learning, Robotics \u2022 Algorithmic Fairness Profile \u2022 Home Page Anna A Lysyanskaya James A. and Julie N. Brown Professor of Computer Science Office: CIT 501 Security and Cryptography Fall 2024: (not teaching) \u2022 Spring 2025: CSCI1040 Profile \u2022 Home Page Barbara J. Meier Distinguished Senior Lecturer in Computer Science Office: CIT 401 Graphics and Visualization Fall 2024: CSCI1250 \u2022 Spring 2025: (not teaching) Profile \u2022 Home Page Peihan Miao Assistant Professor of Computer Science Office: CIT 511 Security and Cryptography, Theory Fall 2024: CSCI1510 \u2022 Spring 2025: CSCI1515 Profile \u2022 Home Page Tim Nelson Lecturer in Computer Science Office: CIT 355 Computing Education, Software Engineering, Formal Methods \u2022 Algorithms and Theory, Networking, Programming Languages Fall 2024: CSCI0112 , CSCI0320 , CSCI1340 \u2022 Spring 2025: CSCI0320 , CSCI1340 , CSCI1710 Profile \u2022 Home Page Julia Netter Adjunct Assistant Professor of the Practice of Computer Science Office: Arnold Lab 309 Fall 2024: (not teaching) \u2022 Spring 2025: CSCI1952-B Profile \u2022 Home Page Bernardo Palazzi Adjunct Professor of the Practice of Computer Science Security and Cryptography Fall 2024: (not teaching) \u2022 Spring 2025: CSCI1660 , CSCI1880 , CSCI2660 Profile \u2022 Home Page Ellie Pavlick Manning Assistant Professor of Computer Science, Assistant Professor of Linguistics Office: CIT 333 Artificial Intelligence, Machine Learning, Data Science, Natural Language Processing Fall 2024: CSCI1460 \u2022 Spring 2025: (not teaching) Profile \u2022 Home Page Steven P Reiss Professor of Computer Science Office: CIT 403 Software Engineering, Design, Formal Methods, Graphics and Visualization, Human-Computer Interaction, Security and Cryptography Fall 2024: CSCI2340 \u2022 Spring 2025: CSCI2340 Profile \u2022 Home Page Daniel C Ritchie Eliot Horowitz Assistant Professor of Computer Science Office: CIT 445 Graphics and Visualization, Artificial Intelligence, Machine Learning, Deep Learning, Computer Vision Fall 2024: CSCI1230 , CSCI1234 , CSCI2230 \u2022 Spring 2025: CSCI1950-U , CSCI2240 Profile \u2022 Home Page Malte Schwarzkopf Assistant Professor of Computer Science Office: CIT 525 Computer Systems, Distributed Systems \u2022 Database Systems Fall 2024: (not teaching) \u2022 Spring 2025: CSCI0300 , CSCI1310 Profile \u2022 Home Page Ritambhara Singh Assistant Professor of Computer Science Office: BOB 313 Machine Learning, Deep Learning, Computational Biology Fall 2024: (not teaching) \u2022 Spring 2025: CSCI1470 , CSCI2470 Profile \u2022 Home Page Srinath Sridhar Assistant Professor of Computer Science Office: CIT 407 Computer Vision, Machine Learning, Deep Learning, Artificial Intelligence, Robotics \u2022 Human-Computer Interaction Fall 2024: CSCI1430 \u2022 Spring 2025: CSCI1430 , CSCI2952-O Profile \u2022 Home Page Chen Sun Assistant Professor of Computer Science Office: CIT 379 Computer Vision, Artificial Intelligence, Machine Learning, Deep Learning Fall 2024: (not teaching) \u2022 Spring 2025: CSCI2952-N Profile \u2022 Home Page Roberto Tamassia James A. and Julie N. Brown Professor of Computer Science, Chair of Computer Science Office: CIT 473 Security and Cryptography, Algorithms and Theory, Data Science Fall 2024: CSCI2951-E \u2022 Spring 2025: (not teaching) Profile \u2022 Home Page Stefanie A Tellex Associate Professor of Computer Science, Associate Professor of Engineering Office: CIT 375 Artificial Intelligence, Machine Learning, Robotics Profile \u2022 Home Page James H Tompkin John E. Savage Assistant Professor of Computer Science Office: CIT 547 Graphics and Visualization, Computer Vision, Human-Computer Interaction Fall 2024: CSCI1290 , CSCI1950-N , CSCI2951-I \u2022 Spring 2025: (not teaching) Profile \u2022 Home Page Eli Upfal Rush C. Hawkins Professor of Computer Science Office: CIT 319 Theory, Algorithms and Theory, Randomized Algorithms and Probabilistic Analysis, Machine Learning, Data Science \u2022 Artificial Intelligence, Computational Biology, Deep Learning, Security Fall 2024: (not teaching) \u2022 Spring 2025: CSCI1550 Profile \u2022 Home Page Andries van Dam Thomas J. Watson Jr. University Professor of Technology and Education, Professor of Computer Science Office: CIT 465 Graphics and Visualization Fall 2024: CSCI0150 \u2022 Spring 2025: (not teaching) Profile \u2022 Home Page Nikos Vasilakis Assistant Professor of Computer Science Office: CIT 555 Computer Systems, Distributed Systems, Security, Programming Languages Fall 2024: (not teaching) \u2022 Spring 2025: CSCI1380 Profile \u2022 Home Page Suresh Venkatasubramanian Professor of Data Science and Computer Science Algorithmic Fairness \u2022 Algorithms and Theory, Machine Learning Fall 2024: (not teaching) \u2022 Spring 2025: CSCI1951-Z Profile Ernesto Zaldivar Associate Professor of the Practice of Computer Science Security, Security Policy, Human-Computer Interaction Fall 2024: CSCI1360 \u2022 Spring 2025: CSCI1800 Profile Stanley B Zdonik Professor of Computer Science Office: CIT 363 Database Systems, Distributed Systems Fall 2024: (not teaching) \u2022 Spring 2025: CSCI2270 Profile \u2022 Home Page Milda Zizyte Lecturer in Computer Science Office: CIT 429 Formal Methods, Robotics, Software Engineering, Computing Education Fall 2024: CSCI0111 , CSCI1600 \u2022 Spring 2025: CSCI0111 , CSCI1952-Y Profile Affiliated On Campus No Match found Karianne Bergen Assistant Professor of Earth, Environmental, and Planetary Sciences and Data Science, Assistant Professor of Computer Science Data Science, Machine Learning, Computational Geosciences, Signal Processing Profile \u2022 Home Page Roger B Blumberg Visiting Scholar in Computer Science Office: 113 MacMillan Profile \u2022 Home Page Adam Blumenthal Visiting Scientist in Computer Science Office: CIT 408 Virtual Reality, Human-Computer Interaction, Design, Natural Language Processing Profile \u2022 Home Page Vanessa Cho Adjunct Professor of Practice of Computer Science Profile Pedro F Felzenszwalb Professor of Engineering Artificial Intelligence, Machine Learning, Algorithms and Theory, Computer Vision, Data Science Profile \u2022 Home Page Ian Gonsher Assistant Professor of the Practice of Engineering Robotics, Design Profile Serdar Kadioglu Adjunct Associate Professor of Computer Science Algorithms and Theory, Artificial Intelligence, Machine Learning, Data Science Fall 2024: (not teaching) \u2022 Spring 2025: CSCI2951-O Profile \u2022 Home Page Ronald Parr Visiting Professor of Computer Science Fall 2024: (not teaching) \u2022 Spring 2025: CSCI2951-F Profile Sohini Ramachandran Director of the Data Science Institute, Hermon C. Bumpus Professor of Biology, Professor of Computer Science Computational Biology, Data Science, Machine Learning Profile \u2022 Home Page Sherief Reda Professor of Engineering, Professor of Computer Science Computer Systems, Computer Architecture, Deep Learning Profile \u2022 Home Page Thomas R Serre Thomas J. Watson, Sr. Professor of Science Profile Donald L Stanford Adjunct Professor of the Practice of Computer Science Office: CIT 223 Security and Cryptography, Human-Computer Interaction, Computer Architecture Fall 2024: CSCI0020 \u2022 Spring 2025: (not teaching) Profile \u2022 Home Page Gabriel Taubin Professor of Engineering, Professor of Computer Science 3D Scanning, 3D Photography, Digital Geometry Processing, Geometric Modeling, Graphics and Visualization, Computer Vision Profile \u2022 Home Page Alan M Usas Adjunct Professor of the Practice of Computer Science Computing Education, Security and Cryptography, Computer Systems Profile Affiliated Off Campus No Match found R. Iris Bahar Professor Emerita of Engineering, Professor Emerita of Computer Science, Adjunct Professor of Engineering Computer Architecture, Computer Systems, Robotics Profile \u2022 Home Page Carsten Binnig Visiting Scientist in Computer Science Database Systems Profile \u2022 Home Page Thomas L Dean Professor Emeritus of Computer Science Artificial Intelligence, Computational Biology, Computer Vision, Deep Learning, Human-Computer Interaction, Machine Learning, Natural Language Processing, Reinforcement Learning, Robotics Profile \u2022 Home Page Seny F Kamara Visiting Associate Professor of Computer Science Security and Cryptography Profile \u2022 Home Page Joseph J Laviola Visiting Scholar in Computer Science Human-Computer Interaction, Graphics and Visualization, Robotics Profile Norm Meyrowitz Former Adjunct Professor of the Practice of Computer Science. Visiting Scholar. Software Engineering \u2022 Human-Computer Interaction Profile \u2022 Home Page Franco Preparata An Wang Professor Emeritus of Computer Science Algorithms and Theory, Computational Biology Profile \u2022 Home Page Matteo Riondato Visiting Scientist in Computer Science Data Science \u2022 Randomized Algorithms and Probabilistic Analysis Profile \u2022 Home Page John E Savage An Wang Professor Emeritus of Computer Science Security Policy \u2022 Theory Profile \u2022 Home Page Tom Sgouros Research Associate in Computer Science Algorithmic Fairness, Software Engineering \u2022 Data Science Profile \u2022 Home Page Post Docs No Match found Alper Ahmetoglu Postdoctoral Research Associate in Computer Science Office: CIT 303 Artificial Intelligence, Robotics, Deep Learning Profile \u2022 Home Page Gianluca Brero Postdoctoral Research Associate in Data Science Profile Will Crichton Postdoctoral Research Associate in Computer Science Profile Gayathri Garimella Postdoctoral Research Associate in Computer Science Profile David Paulius Postdoctoral Research Associate in Computer Science Office: CIT 303 Robotics, Artificial Intelligence \u2022 Natural Language Processing Profile \u2022 Home Page Jake Russin Postdoctoral Research Associate in Computer Science Profile", "https://cs.brown.edu/people/faculty/mlittman.html": "Michael L. Littman University Professor of Computer Science Office: CIT 301 Phone: 401-863-7634 Email: mlittman @@ @cs.brown.edu Assistant: Lori Agresti Primary Research Areas: Artificial Intelligence, Machine Learning, Reinforcement Learning, Robotics Secondary Research Areas: Algorithmic Fairness Publications by Michael L. Littman Home Page", "https://cs.brown.edu/people/faculty/jsavage/": "John E Savage An Wang Professor Emeritus of Computer Science Phone: 401-863-7642 Email: john_savage @@ @brown.edu Assistant: Lori Agresti Primary Research Areas: Security Policy Secondary Research Areas: Theory Publications by John E Savage Home Page Tell us a little about your background: educational, professional, personal, etc. I was educated as a coding, communication, and information theorist at MIT but became a theoretical computer scientist in order to understand why decoders for error correcting codes were so much bigger than encoders. The result was a series of papers and a book (Complexity of Computing, 1976) that demonstrated that the size and depth of a circuit are key measures of the computational complexity of the function that is computed by the circuit. Circuit complexity is now a principal topic in theoretical computer science. After completing my PhD at MIT, I worked for Bell Laboratories in New Jersey. Within three years I was off to Brown as an engineering faculty member. In the early 1970s it became apparent to Andy van Dam and Peter Wegner, who were in Applied Math, and me that we should pool our resources and form the Program in Computer Science. By the late 1970s we saw that we needed to have departmental status if we were going to obtain the resources needed to ensure that Brown could take advantage of this new, exploding research area called \"computer science.\" Starting a new department was a challenge to all of us. Some of us had to serve as chair. Andy was our first chair and I was the second, serving from 1985 to 1991. Recruiting a high quality faculty was our first priority, which we did very successfully and continue to do today. Outside of Computer Science but within Brown I have served on many faculty committees and as chair of many key committees. At the professional level I have served on several editorial boards and committees as well as a member of the visiting committee for the MIT Department of Electrical Engineering and Computer Science, my undergraduate and graduate department, which was a great deal of fun. On the personal side, my wife and I have four children all of whom graduated from Brown and are leading interesting and happy lives. We have traveled with them on sabbatical leaves to the Netherlands, France, and England. What do you focus on in your research? Any recent advances? I am now very actively involved in cybersecurity from both a policy and technology point of view. This is an interest that I developed as a result of spending the 2009-2010 academic year in the U.S. Department of State as a Jefferson Science Fellow. Over the last decade I have also done research and published on computational nanotechnology, the I/O efficiency of multicore chips, and coded computation. The latter involves adding redundancy to data so that if errors occur during a computation, they can be corrected. What do you like teaching classes about? I like to teach computer sciencecourses that involve models of computation and related analysis. I'm a big believer in developing good models from which one can derive important limitations on computation through analysis. My last book, Models of Computation, published in 1998, deals with this topic. I also like to teach courses that involve both policy and technology in cybersecurity. This is an area whose importance has risen rapidly recently due to the globalization of the Internet and the fact that our software, hardware and networks were not designed with security in mind. How did you become interested in computer science? As explained above, I became a computer scientist (by accident) in order to understand why decoders for error correcting codes, as seen in practice, were so much more complex than the encoders that added redundancy to messages. What is your favorite thing about Brown? I very much like the atmosphere at Brown. Faculty, students and staff are generally happy being here. They are all nice, pleasant and intelligent people. It's fun to be around them. Any hobbies or passions? I enjoy exploring ideas. Cybersecurity is my current focus. I also read extensively in science and foreign policy and have many friends who are scientists with whom I exchange ideas. At one time, I did the same with friends in economics.", "https://cs.brown.edu/people/faculty/mph.html": "Maurice P Herlihy An Wang Professor of Computer Science Office: CIT 341 Phone: 401-863-7646 Email: mph @@ @cs.brown.edu Research Areas: Distributed Systems Teaching: Fall 2024 CSCI1760 Multiprocessor Synchronization Spring 2025 CSCI1951-L Blockchains & Cryptocurrencies Publications by Maurice P Herlihy Home Page Tell us a little about your background: educational, professional, personal, etc. I have an A.B. from Harvard in Math, and a Ph.D. from MIT in CS. I have worked, in one role or another, in four research labs: Xerox PARC, DEC CRL, Microsoft Cambridge (UK), and Sun Labs New England. I have taught at CMU and Brown. What do you focus on in your research? Any recent advances? The shift to multicore architectures changes everything. Multiprocessors and concurrency, once an exotic subculture, has become mainstream. What do you like teaching classes about? Things that excite me. How did you become interested in computer science? When I graduated, I knew nothing about CS, but I needed a job. I was hired to write FORTRAN programs for minimum wage, and one thing led to another. What is your favorite thing about Brown? The enthusiasm of the students. Any hobbies or passions? Tango, birding.", "https://cs.brown.edu/people/faculty/mlittman/": "Michael L. Littman University Professor of Computer Science Office: CIT 301 Phone: 401-863-7634 Email: mlittman @@ @cs.brown.edu Assistant: Lori Agresti Primary Research Areas: Artificial Intelligence, Machine Learning, Reinforcement Learning, Robotics Secondary Research Areas: Algorithmic Fairness Publications by Michael L. Littman Home Page", "https://emanuelzgraggen.com/": "Emanuel Zgraggen Co-founder and CEO at Einblick. Former Postdoctoral Associate at MIT's CSAIL Database Group where I worked with Tim Kraska My research interests include HCI, InfoVis and Data Science and I'm currently working on interactive tools for visual data exploration and analysis. I got my Ph.D. from at Brown University where I was advised by Andy van Dam. Einblick - Startup I was a co-founder and CEO of Einblick. Einblick was a next-generation, AI-native, multi-modal data notebook to build workflows and data apps. Founded in 2019, aquired by Databricks in 2024. I was a co-founder and CEO of Einblick. Einblick was a next-generation, AI-native, multi-modal data notebook to build workflows and data apps. Founded in 2019, <a class=\"text-zinc-500 transition underline hover:text-zinc-900\" href=\"https://www.databricks.com/blog/welcome-data-intelligence-platform-databricks-einblick\">aquired by Databricks in 2024.</a> Overview Video Natural Language Video Interactive Data Science Northstar is an interactive data science plattform that combines data exploration with automated machine learning. Northstar is an interactive data science plattform that combines data exploration with automated machine learning. SIGMOD DEEM Paper Video Progressive Visualizations We investigated how progressive visualizations affect users in exploratory data analysis scenarios. Through a controlled experiment, we compared progressive visualizations to blocking and instantaneous visualizations. We investigated how progressive visualizations affect users in exploratory data analysis scenarios. Through a controlled experiment, we compared progressive visualizations to blocking and instantaneous visualizations. TCVG 2017 Paper Summary Video Visual Regular Expressions (s|qu)eries (pronounced \u201cSqueries\u201d) is a visual query interface for creating queries on sequences (series) of data based on regular expressions. (s|qu)eries (pronounced \u201cSqueries\u201d) is a visual query interface for creating queries on sequences (series) of data based on regular expressions. CHI 2015 Paper Summary Video Interactive Data Exploration PanoramicData is a hybrid pen and touch system for visual data exploration. PanoramicData is a hybrid pen and touch system for visual data exploration. Infovis 2014 Paper Video Handwritten Spreadsheets Tableur is a spreadsheet-like pen- and touch-based system that revolves around handwriting recognition - all data is represented as digital ink. Tableur is a spreadsheet-like pen- and touch-based system that revolves around handwriting recognition - all data is represented as digital ink. CHI 2016 LBW Paper Video Multiple Comparisons Problem The goal of visualizations is to facilitate data-driven insight discovery. But what if the insights are spurious? Features or patterns in visualizations can be perceived as relevant insights, even though they arise from noise. The goal of visualizations is to facilitate data-driven insight discovery. But what if the insights are spurious? Features or patterns in visualizations can be perceived as relevant insights, even though they arise from noise. CHI 2018 Paper Summary Video Progressive Sequence Mining ProSecCo is an algorithm for progressive mining of frequent sequences: it processes the dataset in blocks and outputs a high-quality approximation. ProSecCo is an algorithm for progressive mining of frequent sequences: it processes the dataset in blocks and outputs a high-quality approximation. ICDM 2018 Paper Interactive Analytics Vizdom is an interactive visual analytics system that scales to large datasets through progressive computation. Vizdom is an interactive visual analytics system that scales to large datasets through progressive computation. VLDB Demo 2015 Paper Health Video Election Video \u00a9 Emanuel Zgraggen. All rights reserved. (self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null]) self.__next_f.push([1,\"1:HL[\\\"/_next/static/media/171883e03d2067b6-s.p.woff2\\\",\\\"font\\\",{\\\"crossOrigin\\\":\\\"\\\",\\\"type\\\":\\\"font/woff2\\\"}]\\n2:HL[\\\"/_next/static/media/c4c7b0ec92b72e30-s.p.woff2\\\",\\\"font\\\",{\\\"crossOrigin\\\":\\\"\\\",\\\"type\\\":\\\"font/woff2\\\"}]\\n3:HL[\\\"/_next/static/media/c9a5bc6a7c948fb0-s.p.woff2\\\",\\\"font\\\",{\\\"crossOrigin\\\":\\\"\\\",\\\"type\\\":\\\"font/woff2\\\"}]\\n4:HL[\\\"/_next/static/css/adcd84c2a27c91ed.css\\\",\\\"style\\\",{\\\"crossOrigin\\\":\\\"\\\"}]\\n0:\\\"$L5\\\"\\n\"]) self.__next_f.push([1,\"6:I[7690,[],\\\"\\\"]\\n8:I[1749,[\\\"749\\\",\\\"static/chunks/749-5befec773f53c7a6.js\\\",\\\"772\\\",\\\"static/chunks/app/(default)/page-a611c727de586b18.js\\\"],\\\"Image\\\"]\\n9:I[3403,[\\\"534\\\",\\\"static/chunks/app/(default)/layout-c5ac713dbe361a7d.js\\\"],\\\"\\\"]\\na:I[5613,[],\\\"\\\"]\\nb:I[1778,[],\\\"\\\"]\\n11:I[8955,[],\\\"\\\"]\\nc:{\\\"fontFamily\\\":\\\"system-ui,\\\\\\\"Segoe UI\\\\\\\",Roboto,Helvetica,Arial,sans-serif,\\\\\\\"Apple Color Emoji\\\\\\\",\\\\\\\"Segoe UI Emoji\\\\\\\"\\\",\\\"height\\\":\\\"100vh\\\",\\\"textAlign\\\":\\\"center\\\",\\\"display\\\":\\\"flex\\\",\\\"flexDirection\\\":\\\"column\\\",\\\"alignItems\\\":\\\"center\\\",\\\"justifyContent\\\":\\\"center\"]) self.__next_f.push([1,\"\\\"}\\nd:{\\\"display\\\":\\\"inline-block\\\",\\\"margin\\\":\\\"0 20px 0 0\\\",\\\"padding\\\":\\\"0 23px 0 0\\\",\\\"fontSize\\\":24,\\\"fontWeight\\\":500,\\\"verticalAlign\\\":\\\"top\\\",\\\"lineHeight\\\":\\\"49px\\\"}\\ne:{\\\"display\\\":\\\"inline-block\\\"}\\nf:{\\\"fontSize\\\":14,\\\"fontWeight\\\":400,\\\"lineHeight\\\":\\\"49px\\\",\\\"margin\\\":0}\\n12:[]\\n\"]) self.__next_f.push([1,\"5:[[[\\\"$\\\",\\\"link\\\",\\\"0\\\",{\\\"rel\\\":\\\"stylesheet\\\",\\\"href\\\":\\\"/_next/static/css/adcd84c2a27c91ed.css\\\",\\\"precedence\\\":\\\"next\\\",\\\"crossOrigin\\\":\\\"\\\"}]],[\\\"$\\\",\\\"$L6\\\",null,{\\\"buildId\\\":\\\"HHjEo12hn5230EGWGhqfr\\\",\\\"assetPrefix\\\":\\\"\\\",\\\"initialCanonicalUrl\\\":\\\"/\\\",\\\"initialTree\\\":[\\\"\\\",{\\\"children\\\":[\\\"(default)\\\",{\\\"children\\\":[\\\"__PAGE__\\\",{}]}]},\\\"$undefined\\\",\\\"$undefined\\\",true],\\\"initialSeedData\\\":[\\\"\\\",{\\\"children\\\":[\\\"(default)\\\",{\\\"children\\\":[\\\"__PAGE__\\\",{},[\\\"$L7\\\",[[\\\"$\\\",\\\"section\\\",null,{\\\"className\\\":\\\"relative bg-zinc-800 after:pointer-events-none after:absolute after:right-0 after:top-0 after:hidden after:h-full after:w-96 after:bg-gradient-to-l after:from-zinc-800 md:after:block\\\",\\\"children\\\":[[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"pointer-events-none absolute inset-0 -z-10 rounded-bl-[100px] bg-gray-50\\\",\\\"aria-hidden\\\":\\\"true\\\"}],[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"mx-auto max-w-6xl px-4 sm:px-6\\\",\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"pb-12 pt-32 md:pb-20 md:pt-40\\\",\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"relative mx-auto flex max-w-xl flex-col text-center md:max-w-none md:flex-row md:text-left\\\",\\\"children\\\":[[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"md:w-[640px]\\\",\\\"children\\\":[[\\\"$\\\",\\\"h1\\\",null,{\\\"className\\\":\\\"bg-gradient-to-r from-zinc-200 to-zinc-400 bg-clip-text pb-4 font-inter-tight text-4xl font-bold text-transparent md:text-5xl\\\",\\\"data-aos\\\":\\\"fade-right\\\",\\\"data-aos-delay\\\":\\\"100\\\",\\\"children\\\":\\\"Emanuel Zgraggen\\\"}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"mb-10 text-lg text-gray-500\\\",\\\"data-aos\\\":\\\"fade-right\\\",\\\"data-aos-delay\\\":\\\"200\\\",\\\"children\\\":\\\"Co-founder and CEO at Einblick. Former Postdoctoral Associate at MIT's CSAIL Database Group where I worked with Tim Kraska\\\"}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"mb-10 text-lg text-gray-500\\\",\\\"data-aos\\\":\\\"fade-right\\\",\\\"data-aos-delay\\\":\\\"200\\\",\\\"children\\\":\\\"My research interests include HCI, InfoVis and Data Science and I'm currently working on interactive tools for visual data exploration and analysis. I got my Ph.D. from at Brown University where I was advised by Andy van Dam.\\\"}]]}],[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"mx-auto hidden max-w-sm md:-mt-0 md:ml-16 md:block lg:-mt-12\\\",\\\"data-aos\\\":\\\"fade-left\\\",\\\"data-aos-duration\\\":\\\"1100\\\",\\\"children\\\":[\\\"$\\\",\\\"$L8\\\",null,{\\\"src\\\":{\\\"src\\\":\\\"/_next/static/media/hero.d8d358f1.png\\\",\\\"height\\\":584,\\\"width\\\":786,\\\"blurDataURL\\\":\\\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAGCAQAAABUDBdwAAAAcUlEQVR42gFmAJn/ANaj36TOpryBwvXZ/vj1+u0Apf+z/4v/sbu67p75s+u54wBrvKm5ibiTdaagh6d+nWaXAMmYub3Mq7NhwZXQjsGLr3AAuLuk48fNq3udurawo6ueiwCjYqR4nmi6Utybwo7Wib1v6NdCITCTXXQAAAAASUVORK5CYII=\\\",\\\"blurWidth\\\":8,\\\"blurHeight\\\":6},\\\"className\\\":\\\"opacity-60 md:max-w-none\\\",\\\"width\\\":\\\"584\\\",\\\"height\\\":\\\"659\\\",\\\"priority\\\":true,\\\"alt\\\":\\\"Hero Illustration\\\"}]}]]}]}]}]]}],[\\\"$\\\",\\\"section\\\",null,{\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"py-12 md:py-20\\\",\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"mx-auto max-w-6xl px-4 sm:px-6\\\",\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"mx-auto grid max-w-xs gap-8 sm:max-w-none sm:grid-cols-2 sm:gap-4 md:grid-cols-3 lg:gap-8\\\",\\\"children\\\":[[\\\"$\\\",\\\"article\\\",\\\"Einblick - Startup\\\",{\\\"className\\\":\\\"flex flex-col rounded-lg border border-transparent [background:linear-gradient(theme(colors.white),theme(colors.zinc.50))_padding-box,linear-gradient(120deg,theme(colors.zinc.300),theme(colors.zinc.100),theme(colors.zinc.300))_border-box] sm:col-span-2\\\",\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex grow flex-col p-5 pt-6\\\",\\\"children\\\":[[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"mb-1 flex items-center space-x-3\\\",\\\"children\\\":[\\\"$\\\",\\\"h3\\\",null,{\\\"className\\\":\\\"font-inter-tight font-semibold text-zinc-900\\\",\\\"children\\\":\\\"Einblick - Startup\\\"}]}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"w-full grow pb-1 text-sm text-zinc-500\\\",\\\"dangerouslySetInnerHTML\\\":{\\\"__html\\\":\\\"I was a co-founder and CEO of Einblick. Einblick was a next-generation, AI-native, multi-modal data notebook to build workflows and data apps. Founded in 2019, \\u003ca class=\\\\\\\"text-zinc-500 transition underline hover:text-zinc-900\\\\\\\" href=\\\\\\\"https://www.databricks.com/blog/welcome-data-intelligence-platform-databricks-einblick\\\\\\\"\\u003eaquired by Databricks in 2024.\\u003c/a\\u003e\\\"}}],[\\\"$\\\",\\\"a\\\",null,{\\\"href\\\":\\\"assets/video/user-interface-overview.mp4\\\",\\\"children\\\":[\\\"$\\\",\\\"figure\\\",null,{\\\"children\\\":[\\\"$\\\",\\\"$L8\\\",null,{\\\"className\\\":\\\"w-5/6 object-cover object-left pb-1 sm:h-auto sm:object-contain\\\",\\\"src\\\":\\\"assets/einblick.png\\\",\\\"width\\\":342,\\\"height\\\":280,\\\"alt\\\":\\\"Feature Post 02\\\"}]}]}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"w-full grow text-sm text-zinc-500\\\",\\\"children\\\":\\\"I was a co-founder and CEO of Einblick. Einblick was a next-generation, AI-native, multi-modal data notebook to build workflows and data apps. Founded in 2019, \\u003ca class=\\\\\\\"text-zinc-500 transition underline hover:text-zinc-900\\\\\\\" href=\\\\\\\"https://www.databricks.com/blog/welcome-data-intelligence-platform-databricks-einblick\\\\\\\"\\u003eaquired by Databricks in 2024.\\u003c/a\\u003e\\\"}],[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex flex-wrap space-x-2 divide-x divide-zinc-400 pt-3 text-xs text-zinc-500\\\",\\\"children\\\":[[\\\"$\\\",\\\"a\\\",\\\"0\\\",{\\\"className\\\":\\\"text-zinc-500 transition hover:text-zinc-900\\\",\\\"href\\\":\\\"assets/video/user-interface-overview.mp4\\\",\\\"children\\\":\\\"Overview Video\\\"}],[\\\"$\\\",\\\"a\\\",\\\"1\\\",{\\\"className\\\":\\\"text-zinc-500 transition hover:text-zinc-900 pl-2\\\",\\\"href\\\":\\\"assets/video/prompt-example-1.mp4\\\",\\\"children\\\":\\\"Natural Language Video\\\"}]]}]]}]}],[\\\"$\\\",\\\"article\\\",\\\"Interactive Data Science\\\",{\\\"className\\\":\\\"flex flex-col rounded-lg border border-transparent [background:linear-gradient(theme(colors.white),theme(colors.zinc.50))_padding-box,linear-gradient(120deg,theme(colors.zinc.300),theme(colors.zinc.100),theme(colors.zinc.300))_border-box]\\\",\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex grow flex-col p-5 pt-6\\\",\\\"children\\\":[[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"mb-1 flex items-center space-x-3\\\",\\\"children\\\":[\\\"$\\\",\\\"h3\\\",null,{\\\"className\\\":\\\"font-inter-tight font-semibold text-zinc-900\\\",\\\"children\\\":\\\"Interactive Data Science\\\"}]}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"w-full grow pb-1 text-sm text-zinc-500\\\",\\\"dangerouslySetInnerHTML\\\":{\\\"__html\\\":\\\"Northstar is an interactive data science plattform that combines data exploration with automated machine learning.\\\"}}],[\\\"$\\\",\\\"a\\\",null,{\\\"href\\\":\\\"assets/video/northstar.mp4\\\",\\\"children\\\":[\\\"$\\\",\\\"figure\\\",null,{\\\"children\\\":[\\\"$\\\",\\\"$L8\\\",null,{\\\"className\\\":\\\"w-5/6 object-cover object-left pb-1 sm:h-auto sm:object-contain mx-auto\\\",\\\"src\\\":\\\"assets/northstar.png\\\",\\\"width\\\":342,\\\"height\\\":280,\\\"alt\\\":\\\"Feature Post 02\\\"}]}]}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"w-full grow text-sm text-zinc-500\\\",\\\"children\\\":\\\"Northstar is an interactive data science plattform that combines data exploration with automated machine learning.\\\"}],[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex flex-wrap space-x-2 divide-x divide-zinc-400 pt-3 text-xs text-zinc-500\\\",\\\"children\\\":[[\\\"$\\\",\\\"a\\\",\\\"0\\\",{\\\"className\\\":\\\"text-zinc-500 transition hover:text-zinc-900\\\",\\\"href\\\":\\\"assets/pdf/alpine_meadow_deem.pdf\\\",\\\"children\\\":\\\"SIGMOD DEEM Paper\\\"}],[\\\"$\\\",\\\"a\\\",\\\"1\\\",{\\\"className\\\":\\\"text-zinc-500 transition hover:text-zinc-900 pl-2\\\",\\\"href\\\":\\\"assets/video/northstar.mp4\\\",\\\"children\\\":\\\"Video\\\"}]]}]]}]}],[\\\"$\\\",\\\"article\\\",\\\"Progressive Visualizations\\\",{\\\"className\\\":\\\"flex flex-col rounded-lg border border-transparent [background:linear-gradient(theme(colors.white),theme(colors.zinc.50))_padding-box,linear-gradient(120deg,theme(colors.zinc.300),theme(colors.zinc.100),theme(colors.zinc.300))_border-box]\\\",\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex grow flex-col p-5 pt-6\\\",\\\"children\\\":[[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"mb-1 flex items-center space-x-3\\\",\\\"children\\\":[\\\"$\\\",\\\"h3\\\",null,{\\\"className\\\":\\\"font-inter-tight font-semibold text-zinc-900\\\",\\\"children\\\":\\\"Progressive Visualizations\\\"}]}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"w-full grow pb-1 text-sm text-zinc-500\\\",\\\"dangerouslySetInnerHTML\\\":{\\\"__html\\\":\\\"We investigated how progressive visualizations affect users in exploratory data analysis scenarios. Through a controlled experiment, we compared progressive visualizations to blocking and instantaneous visualizations.\\\"}}],[\\\"$\\\",\\\"a\\\",null,{\\\"href\\\":\\\"assets/pdf/progressive_jrnl.pdf\\\",\\\"children\\\":[\\\"$\\\",\\\"figure\\\",null,{\\\"children\\\":[\\\"$\\\",\\\"$L8\\\",null,{\\\"className\\\":\\\"w-5/6 object-cover object-left pb-1 sm:h-auto sm:object-contain mx-auto\\\",\\\"src\\\":\\\"assets/progressive.png\\\",\\\"width\\\":342,\\\"height\\\":280,\\\"alt\\\":\\\"Feature Post 02\\\"}]}]}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"w-full grow text-sm text-zinc-500\\\",\\\"children\\\":\\\"We investigated how progressive visualizations affect users in exploratory data analysis scenarios. Through a controlled experiment, we compared progressive visualizations to blocking and instantaneous visualizations.\\\"}],[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex flex-wrap space-x-2 divide-x divide-zinc-400 pt-3 text-xs text-zinc-500\\\",\\\"children\\\":[[\\\"$\\\",\\\"a\\\",\\\"0\\\",{\\\"className\\\":\\\"text-zinc-500 transition hover:text-zinc-900\\\",\\\"href\\\":\\\"assets/pdf/progressive_jrnl.pdf\\\",\\\"children\\\":\\\"TCVG 2017 Paper\\\"}],[\\\"$\\\",\\\"a\\\",\\\"1\\\",{\\\"className\\\":\\\"text-zinc-500 transition hover:text-zinc-900 pl-2\\\",\\\"href\\\":\\\"assets/video/progressive.mp4\\\",\\\"children\\\":\\\"Summary Video\\\"}]]}]]}]}],[\\\"$\\\",\\\"article\\\",\\\"Visual Regular Expressions\\\",{\\\"className\\\":\\\"flex flex-col rounded-lg border border-transparent [background:linear-gradient(theme(colors.white),theme(colors.zinc.50))_padding-box,linear-gradient(120deg,theme(colors.zinc.300),theme(colors.zinc.100),theme(colors.zinc.300))_border-box]\\\",\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex grow flex-col p-5 pt-6\\\",\\\"children\\\":[[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"mb-1 flex items-center space-x-3\\\",\\\"children\\\":[\\\"$\\\",\\\"h3\\\",null,{\\\"className\\\":\\\"font-inter-tight font-semibold text-zinc-900\\\",\\\"children\\\":\\\"Visual Regular Expressions\\\"}]}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"w-full grow pb-1 text-sm text-zinc-500\\\",\\\"dangerouslySetInnerHTML\\\":{\\\"__html\\\":\\\"(s|qu)eries (pronounced \u201cSqueries\u201d) is a visual query interface for creating queries on sequences (series) of data based on regular expressions.\\\"}}],[\\\"$\\\",\\\"a\\\",null,{\\\"href\\\":\\\"assets/video/squeries_v1.0.mp4\\\",\\\"children\\\":[\\\"$\\\",\\\"figure\\\",null,{\\\"children\\\":[\\\"$\\\",\\\"$L8\\\",null,{\\\"className\\\":\\\"w-5/6 object-cover object-left pb-1 sm:h-auto sm:object-contain mx-auto\\\",\\\"src\\\":\\\"assets/squeries.png\\\",\\\"width\\\":342,\\\"height\\\":280,\\\"alt\\\":\\\"Feature Post 02\\\"}]}]}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"w-full grow text-sm text-zinc-500\\\",\\\"children\\\":\\\"(s|qu)eries (pronounced \u201cSqueries\u201d) is a visual query interface for creating queries on sequences (series) of data based on regular expressions.\\\"}],[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex flex-wrap space-x-2 divide-x divide-zinc-400 pt-3 text-xs text-zinc-500\\\",\\\"children\\\":[[\\\"$\\\",\\\"a\\\",\\\"0\\\",{\\\"className\\\":\\\"text-zinc-500 transition hover:text-zinc-900\\\",\\\"href\\\":\\\"assets/pdf/chi2015-squeries.pdf\\\",\\\"children\\\":\\\"CHI 2015 Paper\\\"}],[\\\"$\\\",\\\"a\\\",\\\"1\\\",{\\\"className\\\":\\\"text-zinc-500 transition hover:text-zinc-900 pl-2\\\",\\\"href\\\":\\\"assets/video/squeries_v1.0.mp4\\\",\\\"children\\\":\\\"Summary Video\\\"}]]}]]}]}],[\\\"$\\\",\\\"article\\\",\\\"Interactive Data Exploration\\\",{\\\"className\\\":\\\"flex flex-col rounded-lg border border-transparent [background:linear-gradient(theme(colors.white),theme(colors.zinc.50))_padding-box,linear-gradient(120deg,theme(colors.zinc.300),theme(colors.zinc.100),theme(colors.zinc.300))_border-box]\\\",\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex grow flex-col p-5 pt-6\\\",\\\"children\\\":[[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"mb-1 flex items-center space-x-3\\\",\\\"children\\\":[\\\"$\\\",\\\"h3\\\",null,{\\\"className\\\":\\\"font-inter-tight font-semibold text-zinc-900\\\",\\\"children\\\":\\\"Interactive Data Exploration\\\"}]}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"w-full grow pb-1 text-sm text-zinc-500\\\",\\\"dangerouslySetInnerHTML\\\":{\\\"__html\\\":\\\"PanoramicData is a hybrid pen and touch system for visual data exploration.\\\"}}],[\\\"$\\\",\\\"a\\\",null,{\\\"href\\\":\\\"assets/video/panodata.mp4\\\",\\\"children\\\":[\\\"$\\\",\\\"figure\\\",null,{\\\"children\\\":[\\\"$\\\",\\\"$L8\\\",null,{\\\"className\\\":\\\"w-5/6 object-cover object-left pb-1 sm:h-auto sm:object-contain mx-auto\\\",\\\"src\\\":\\\"assets/panodata.jpg\\\",\\\"width\\\":342,\\\"height\\\":280,\\\"alt\\\":\\\"Feature Post 02\\\"}]}]}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"w-full grow text-sm text-zinc-500\\\",\\\"children\\\":\\\"PanoramicData is a hybrid pen and touch system for visual data exploration.\\\"}],[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex flex-wrap space-x-2 divide-x divide-zinc-400 pt-3 text-xs text-zinc-500\\\",\\\"children\\\":[[\\\"$\\\",\\\"a\\\",\\\"0\\\",{\\\"className\\\":\\\"text-zinc-500 transition hover:text-zinc-900\\\",\\\"href\\\":\\\"assets/pdf/PanoramicData.pdf\\\",\\\"children\\\":\\\"Infovis 2014 Paper\\\"}],[\\\"$\\\",\\\"a\\\",\\\"1\\\",{\\\"className\\\":\\\"text-zinc-500 transition hover:text-zinc-900 pl-2\\\",\\\"href\\\":\\\"assets/video/panodata.mp4\\\",\\\"children\\\":\\\"Video\\\"}]]}]]}]}],[\\\"$\\\",\\\"article\\\",\\\"Handwritten Spreadsheets\\\",{\\\"className\\\":\\\"flex flex-col rounded-lg border border-transparent [background:linear-gradient(theme(colors.white),theme(colors.zinc.50))_padding-box,linear-gradient(120deg,theme(colors.zinc.300),theme(colors.zinc.100),theme(colors.zinc.300))_border-box] sm:col-span-2\\\",\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex grow flex-col p-5 pt-6\\\",\\\"children\\\":[[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"mb-1 flex items-center space-x-3\\\",\\\"children\\\":[\\\"$\\\",\\\"h3\\\",null,{\\\"className\\\":\\\"font-inter-tight font-semibold text-zinc-900\\\",\\\"children\\\":\\\"Handwritten Spreadsheets\\\"}]}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"w-full grow pb-1 text-sm text-zinc-500\\\",\\\"dangerouslySetInnerHTML\\\":{\\\"__html\\\":\\\"Tableur is a spreadsheet-like pen- and touch-based system that revolves around handwriting recognition - all data is represented as digital ink.\\\"}}],[\\\"$\\\",\\\"a\\\",null,{\\\"href\\\":\\\"assets/video/Tableur%201.0.mp4\\\",\\\"children\\\":[\\\"$\\\",\\\"figure\\\",null,{\\\"children\\\":[\\\"$\\\",\\\"$L8\\\",null,{\\\"className\\\":\\\"w-5/6 object-cover object-left pb-1 sm:h-auto sm:object-contain\\\",\\\"src\\\":\\\"assets/tableur.png\\\",\\\"width\\\":342,\\\"height\\\":280,\\\"alt\\\":\\\"Feature Post 02\\\"}]}]}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"w-full grow text-sm text-zinc-500\\\",\\\"children\\\":\\\"Tableur is a spreadsheet-like pen- and touch-based system that revolves around handwriting recognition - all data is represented as digital ink.\\\"}],[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex flex-wrap space-x-2 divide-x divide-zinc-400 pt-3 text-xs text-zinc-500\\\",\\\"children\\\":[[\\\"$\\\",\\\"a\\\",\\\"0\\\",{\\\"className\\\":\\\"text-zinc-500 transition hover:text-zinc-900\\\",\\\"href\\\":\\\"assets/pdf/tableur.pdf\\\",\\\"children\\\":\\\"CHI 2016 LBW Paper\\\"}],[\\\"$\\\",\\\"a\\\",\\\"1\\\",{\\\"className\\\":\\\"text-zinc-500 transition hover:text-zinc-900 pl-2\\\",\\\"href\\\":\\\"assets/video/Tableur%201.0.mp4\\\",\\\"children\\\":\\\"Video\\\"}]]}]]}]}],[\\\"$\\\",\\\"article\\\",\\\"Multiple Comparisons Problem\\\",{\\\"className\\\":\\\"flex flex-col rounded-lg border border-transparent [background:linear-gradient(theme(colors.white),theme(colors.zinc.50))_padding-box,linear-gradient(120deg,theme(colors.zinc.300),theme(colors.zinc.100),theme(colors.zinc.300))_border-box]\\\",\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex grow flex-col p-5 pt-6\\\",\\\"children\\\":[[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"mb-1 flex items-center space-x-3\\\",\\\"children\\\":[\\\"$\\\",\\\"h3\\\",null,{\\\"className\\\":\\\"font-inter-tight font-semibold text-zinc-900\\\",\\\"children\\\":\\\"Multiple Comparisons Problem\\\"}]}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"w-full grow pb-1 text-sm text-zinc-500\\\",\\\"dangerouslySetInnerHTML\\\":{\\\"__html\\\":\\\"The goal of visualizations is to facilitate data-driven insight discovery. But what if the insights are spurious? Features or patterns in visualizations can be perceived as relevant insights, even though they arise from noise.\\\"}}],[\\\"$\\\",\\\"a\\\",null,{\\\"href\\\":\\\"assets/pdf/mcp.pdf\\\",\\\"children\\\":[\\\"$\\\",\\\"figure\\\",null,{\\\"children\\\":[\\\"$\\\",\\\"$L8\\\",null,{\\\"className\\\":\\\"w-5/6 object-cover object-left pb-1 sm:h-auto sm:object-contain mx-auto\\\",\\\"src\\\":\\\"assets/mcp.png\\\",\\\"width\\\":342,\\\"height\\\":280,\\\"alt\\\":\\\"Feature Post 02\\\"}]}]}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"w-full grow text-sm text-zinc-500\\\",\\\"children\\\":\\\"The goal of visualizations is to facilitate data-driven insight discovery. But what if the insights are spurious? Features or patterns in visualizations can be perceived as relevant insights, even though they arise from noise.\\\"}],[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex flex-wrap space-x-2 divide-x divide-zinc-400 pt-3 text-xs text-zinc-500\\\",\\\"children\\\":[[\\\"$\\\",\\\"a\\\",\\\"0\\\",{\\\"className\\\":\\\"text-zinc-500 transition hover:text-zinc-900\\\",\\\"href\\\":\\\"assets/pdf/mcp.pdf\\\",\\\"children\\\":\\\"CHI 2018 Paper\\\"}],[\\\"$\\\",\\\"a\\\",\\\"1\\\",{\\\"className\\\":\\\"text-zinc-500 transition hover:text-zinc-900 pl-2\\\",\\\"href\\\":\\\"assets/video/mcp.mp4\\\",\\\"children\\\":\\\"Summary Video\\\"}]]}]]}]}],[\\\"$\\\",\\\"article\\\",\\\"Progressive Sequence Mining\\\",{\\\"className\\\":\\\"flex flex-col rounded-lg border border-transparent [background:linear-gradient(theme(colors.white),theme(colors.zinc.50))_padding-box,linear-gradient(120deg,theme(colors.zinc.300),theme(colors.zinc.100),theme(colors.zinc.300))_border-box]\\\",\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex grow flex-col p-5 pt-6\\\",\\\"children\\\":[[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"mb-1 flex items-center space-x-3\\\",\\\"children\\\":[\\\"$\\\",\\\"h3\\\",null,{\\\"className\\\":\\\"font-inter-tight font-semibold text-zinc-900\\\",\\\"children\\\":\\\"Progressive Sequence Mining\\\"}]}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"w-full grow pb-1 text-sm text-zinc-500\\\",\\\"dangerouslySetInnerHTML\\\":{\\\"__html\\\":\\\"ProSecCo is an algorithm for progressive mining of frequent sequences: it processes the dataset in blocks and outputs a high-quality approximation.\\\"}}],[\\\"$\\\",\\\"a\\\",null,{\\\"href\\\":\\\"assets/pdf/prosecco.pdf\\\",\\\"children\\\":[\\\"$\\\",\\\"figure\\\",null,{\\\"children\\\":[\\\"$\\\",\\\"$L8\\\",null,{\\\"className\\\":\\\"w-5/6 object-cover object-left pb-1 sm:h-auto sm:object-contain mx-auto\\\",\\\"src\\\":\\\"assets/prosecco.png\\\",\\\"width\\\":342,\\\"height\\\":280,\\\"alt\\\":\\\"Feature Post 02\\\"}]}]}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"w-full grow text-sm text-zinc-500\\\",\\\"children\\\":\\\"ProSecCo is an algorithm for progressive mining of frequent sequences: it processes the dataset in blocks and outputs a high-quality approximation.\\\"}],[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex flex-wrap space-x-2 divide-x divide-zinc-400 pt-3 text-xs text-zinc-500\\\",\\\"children\\\":[[\\\"$\\\",\\\"a\\\",\\\"0\\\",{\\\"className\\\":\\\"text-zinc-500 transition hover:text-zinc-900\\\",\\\"href\\\":\\\"assets/pdf/prosecco.pdf\\\",\\\"children\\\":\\\"ICDM 2018 Paper\\\"}]]}]]}]}],[\\\"$\\\",\\\"article\\\",\\\"Interactive Analytics\\\",{\\\"className\\\":\\\"flex flex-col rounded-lg border border-transparent [background:linear-gradient(theme(colors.white),theme(colors.zinc.50))_padding-box,linear-gradient(120deg,theme(colors.zinc.300),theme(colors.zinc.100),theme(colors.zinc.300))_border-box] sm:col-span-2\\\",\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex grow flex-col p-5 pt-6\\\",\\\"children\\\":[[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"mb-1 flex items-center space-x-3\\\",\\\"children\\\":[\\\"$\\\",\\\"h3\\\",null,{\\\"className\\\":\\\"font-inter-tight font-semibold text-zinc-900\\\",\\\"children\\\":\\\"Interactive Analytics\\\"}]}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"w-full grow pb-1 text-sm text-zinc-500\\\",\\\"dangerouslySetInnerHTML\\\":{\\\"__html\\\":\\\"Vizdom is an interactive visual analytics system that scales to large datasets through progressive computation.\\\"}}],[\\\"$\\\",\\\"a\\\",null,{\\\"href\\\":\\\"assets/video/vizdom_v1.0.mp4\\\",\\\"children\\\":[\\\"$\\\",\\\"figure\\\",null,{\\\"children\\\":[\\\"$\\\",\\\"$L8\\\",null,{\\\"className\\\":\\\"w-5/6 object-cover object-left pb-1 sm:h-auto sm:object-contain\\\",\\\"src\\\":\\\"assets/vizdom.png\\\",\\\"width\\\":342,\\\"height\\\":280,\\\"alt\\\":\\\"Feature Post 02\\\"}]}]}],[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"w-full grow text-sm text-zinc-500\\\",\\\"children\\\":\\\"Vizdom is an interactive visual analytics system that scales to large datasets through progressive computation.\\\"}],[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex flex-wrap space-x-2 divide-x divide-zinc-400 pt-3 text-xs text-zinc-500\\\",\\\"children\\\":[[\\\"$\\\",\\\"a\\\",\\\"0\\\",{\\\"className\\\":\\\"text-zinc-500 transition hover:text-zinc-900\\\",\\\"href\\\":\\\"assets/pdf/vizdom.pdf\\\",\\\"children\\\":\\\"VLDB Demo 2015 Paper\\\"}],[\\\"$\\\",\\\"a\\\",\\\"1\\\",{\\\"className\\\":\\\"text-zinc-500 transition hover:text-zinc-900 pl-2\\\",\\\"href\\\":\\\"assets/video/vizdom_v1.0.mp4\\\",\\\"children\\\":\\\"Health Video\\\"}],[\\\"$\\\",\\\"a\\\",\\\"2\\\",{\\\"className\\\":\\\"text-zinc-500 transition hover:text-zinc-900 pl-2\\\",\\\"href\\\":\\\"assets/video/election_1.0.mp4\\\",\\\"children\\\":\\\"Election Video\\\"}]]}]]}]}]]}]}]}]}]],null]]},[null,[\\\"$\\\",\\\"$L9\\\",null,{\\\"children\\\":[\\\"$\\\",\\\"$La\\\",null,{\\\"parallelRouterKey\\\":\\\"children\\\",\\\"segmentPath\\\":[\\\"children\\\",\\\"(default)\\\",\\\"children\\\"],\\\"loading\\\":\\\"$undefined\\\",\\\"loadingStyles\\\":\\\"$undefined\\\",\\\"loadingScripts\\\":\\\"$undefined\\\",\\\"hasLoading\\\":false,\\\"error\\\":\\\"$undefined\\\",\\\"errorStyles\\\":\\\"$undefined\\\",\\\"errorScripts\\\":\\\"$undefined\\\",\\\"template\\\":[\\\"$\\\",\\\"$Lb\\\",null,{}],\\\"templateStyles\\\":\\\"$undefined\\\",\\\"templateScripts\\\":\\\"$undefined\\\",\\\"notFound\\\":[[\\\"$\\\",\\\"title\\\",null,{\\\"children\\\":\\\"404: This page could not be found.\\\"}],[\\\"$\\\",\\\"div\\\",null,{\\\"style\\\":{\\\"fontFamily\\\":\\\"system-ui,\\\\\\\"Segoe UI\\\\\\\",Roboto,Helvetica,Arial,sans-serif,\\\\\\\"Apple Color Emoji\\\\\\\",\\\\\\\"Segoe UI Emoji\\\\\\\"\\\",\\\"height\\\":\\\"100vh\\\",\\\"textAlign\\\":\\\"center\\\",\\\"display\\\":\\\"flex\\\",\\\"flexDirection\\\":\\\"column\\\",\\\"alignItems\\\":\\\"center\\\",\\\"justifyContent\\\":\\\"center\\\"},\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"children\\\":[[\\\"$\\\",\\\"style\\\",null,{\\\"dangerouslySetInnerHTML\\\":{\\\"__html\\\":\\\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\\\"}}],[\\\"$\\\",\\\"h1\\\",null,{\\\"className\\\":\\\"next-error-h1\\\",\\\"style\\\":{\\\"display\\\":\\\"inline-block\\\",\\\"margin\\\":\\\"0 20px 0 0\\\",\\\"padding\\\":\\\"0 23px 0 0\\\",\\\"fontSize\\\":24,\\\"fontWeight\\\":500,\\\"verticalAlign\\\":\\\"top\\\",\\\"lineHeight\\\":\\\"49px\\\"},\\\"children\\\":\\\"404\\\"}],[\\\"$\\\",\\\"div\\\",null,{\\\"style\\\":{\\\"display\\\":\\\"inline-block\\\"},\\\"children\\\":[\\\"$\\\",\\\"h2\\\",null,{\\\"style\\\":{\\\"fontSize\\\":14,\\\"fontWeight\\\":400,\\\"lineHeight\\\":\\\"49px\\\",\\\"margin\\\":0},\\\"children\\\":\\\"This page could not be found.\\\"}]}]]}]}]],\\\"notFoundStyles\\\":[],\\\"styles\\\":null}],\\\"params\\\":{}}],null]]},[null,[\\\"$\\\",\\\"html\\\",null,{\\\"lang\\\":\\\"en\\\",\\\"children\\\":[\\\"$\\\",\\\"body\\\",null,{\\\"className\\\":\\\"__variable_e66fe9 __variable_82602e font-inter antialiased bg-white text-zinc-900 tracking-tight\\\",\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"className\\\":\\\"flex flex-col min-h-screen overflow-hidden supports-[overflow:clip]:overflow-clip\\\",\\\"children\\\":[\\\"$\\\",\\\"$La\\\",null,{\\\"parallelRouterKey\\\":\\\"children\\\",\\\"segmentPath\\\":[\\\"children\\\"],\\\"loading\\\":\\\"$undefined\\\",\\\"loadingStyles\\\":\\\"$undefined\\\",\\\"loadingScripts\\\":\\\"$undefined\\\",\\\"hasLoading\\\":false,\\\"error\\\":\\\"$undefined\\\",\\\"errorStyles\\\":\\\"$undefined\\\",\\\"errorScripts\\\":\\\"$undefined\\\",\\\"template\\\":[\\\"$\\\",\\\"$Lb\\\",null,{}],\\\"templateStyles\\\":\\\"$undefined\\\",\\\"templateScripts\\\":\\\"$undefined\\\",\\\"notFound\\\":[[\\\"$\\\",\\\"title\\\",null,{\\\"children\\\":\\\"404: This page could not be found.\\\"}],[\\\"$\\\",\\\"div\\\",null,{\\\"style\\\":\\\"$c\\\",\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"children\\\":[[\\\"$\\\",\\\"style\\\",null,{\\\"dangerouslySetInnerHTML\\\":{\\\"__html\\\":\\\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\\\"}}],[\\\"$\\\",\\\"h1\\\",null,{\\\"className\\\":\\\"next-error-h1\\\",\\\"style\\\":\\\"$d\\\",\\\"children\\\":\\\"404\\\"}],[\\\"$\\\",\\\"div\\\",null,{\\\"style\\\":\\\"$e\\\",\\\"children\\\":[\\\"$\\\",\\\"h2\\\",null,{\\\"style\\\":\\\"$f\\\",\\\"children\\\":\\\"This page could not be found.\\\"}]}]]}]}]],\\\"notFoundStyles\\\":[],\\\"styles\\\":null}]}]}]}],null]],\\\"initialHead\\\":[false,\\\"$L10\\\"],\\\"globalErrorComponent\\\":\\\"$11\\\",\\\"missingSlots\\\":\\\"$W12\\\"}]]\\n\"]) self.__next_f.push([1,\"10:[[\\\"$\\\",\\\"meta\\\",\\\"0\\\",{\\\"name\\\":\\\"viewport\\\",\\\"content\\\":\\\"width=device-width, initial-scale=1\\\"}],[\\\"$\\\",\\\"meta\\\",\\\"1\\\",{\\\"charSet\\\":\\\"utf-8\\\"}],[\\\"$\\\",\\\"title\\\",\\\"2\\\",{\\\"children\\\":\\\"Home - Creative\\\"}],[\\\"$\\\",\\\"meta\\\",\\\"3\\\",{\\\"name\\\":\\\"description\\\",\\\"content\\\":\\\"Page description\\\"}],[\\\"$\\\",\\\"meta\\\",\\\"4\\\",{\\\"name\\\":\\\"next-size-adjust\\\"}]]\\n7:null\\n\"]) self.__next_f.push([1,\"\"])", "https://cs.brown.edu/people/faculty/jeffh/": "Jeff Huang Associate Professor of Computer Science, Associate Chair of Computer Science Office: CIT 245 Phone: 401-863-5808 Email: jeff_huang @@ @brown.edu Assistant: Dawn T Reed Research Areas: Human-Computer Interaction, Design, Data Science Publications by Jeff Huang Home Page", "https://cs.brown.edu/people/faculty/sbz.html": "Stanley B Zdonik Professor of Computer Science Office: CIT 363 Phone: 401-863-7648 Email: sbz @@ @cs.brown.edu Assistant: Lori Agresti Research Areas: Database Systems, Distributed Systems Teaching: Fall 2024 (not teaching) Spring 2025 CSCI2270 Topics in Database Management Publications by Stanley B Zdonik Home Page Stan Zdonik's research interests include database systems, object-oriented databases, query processing, data dissemination, mobile computing and stream processing.", "https://cs.brown.edu/people/faculty/sbach/": "Stephen Bach Assistant Professor of Computer Science Office: CIT 335 Email: sbach @@ @cs.brown.edu Research Areas: Machine Learning, Artificial Intelligence, Data Science Teaching: Fall 2024 (not teaching) Spring 2025 CSCI1420 Machine Learning Home Page", "https://cs.brown.edu/people/faculty/twd.html": "Thomas W Doeppner Associate Professor of Computer Science (Research), Vice Chair of Computer Science Office: CIT 405 Phone: 401-863-7633 Email: twd @@ @cs.brown.edu Research Areas: Computer Systems Teaching: Fall 2024 CSCI0081 TA Apprenticeship: Full Credit CSCI0082 TA Apprenticeship: Half Credit CSCI0330 Introduction to Computer Systems CSCI1330 Computer Systems (Master's students only) Spring 2025 CSCI0081 TA Apprenticeship: Full Credit CSCI0082 TA Apprenticeship: Half Credit CSCI1670 Operating Systems CSCI1690 Operating Systems Laboratory CSCI2670 Operating Systems Home Page Thomas Doeppner is interested in operating systems and everything related to them. He wrote one of the first threads packages for Unix and has dabbled in threads and concurrency ever since. With the help of a number of top undergraduate students, he worked on tools for measuring and analyzing performance of concurrent programs, particularly on shared-memory multiprocessors. He also designed and implemented an object-oriented threads package for C++, using ideas borrowed from Sun's Spring operating system. More recently, he worked with wireless devices and mobile computers, building an infrastructure for sharing information in settings such as lectures, seminars, and face-to-face meetings. He is currently interested in the area of operating system support for security. He is investigating means for running arbitrary programs without fear of the consequences. In the distant past he did work in proving the correct of parallel programs and published papers in STOC, POPL, and PODC.", "https://cs.brown.edu/people/gdk/index.html": "George Konidaris Director: Intelligent Robot Lab Associate Professor Department of Computer Science Brown University, Providence RI gdk@cs.brown.edu Home | IRL | Research | Teaching | Publications | Software | CV Welcome to my home page. I'm an Associate Professor of Computer Science and director ofthe Intelligent Robot Lab at Brown , which forms part of bigAI (Brown Integrative, General AI) . My group and I conduct research driven by the overarching scientific goal of understanding the fundamental computational processes that generateintelligence, and using them to design a generally-intelligent robot. I am also the co-founder of two technology startups.I co-founded, and serve as the Chief Roboticist of, Realtime Robotics , a startup based on our research on robot motion planning , and that aims to make robotic automation simpler, better, and faster. I also co-founded Lelapa AI , a commercial AI research lab focused on technology by and for Africans, and based in Johannesburg, South Africa. If you're considering applying to the PhD program at Brown to study in my lab, please see this page . Research My research aims tobuild intelligent, autonomous, general-purpose robots that are generally capable in a wide variety of tasksand environments. I focus on understanding how todesign agents that learn abstraction hierarchies that enable fast, goal-oriented planning.I develop andapply techniques from machine learning, reinforcement learning, optimal control and planningto construct well-grounded hierarchies that result in fast planning for common cases,andare robust to uncertainty atevery level of control. I believe that it will take advances in all of these areas, and additionally advances in how to integrate these areas,to solve the AI problem. You can find an approachable (and short!) summary to some of my recent thinking on how to build generally intelligent agentsin the following review paper: G.D. Konidaris. On TheNecessity of Abstraction . Current Opinion in Behavioral Sciences 29(Special Issue on Artificial Intelligence),pages 1-7, October 2019. ... and in my recent invited talk at CoRL 2019 in Osaka, which is a good summary of my lab's work over the last few years: This recent journal paper is a good indicator of my interests - it combines ideas fromhierarchical reinforcement learning, probabilistic machine learning, task-level planning, and roboticsto create a robot that autonomously learns an abstract symbolic model of an environment and then uses it to plan: G.D. Konidaris, L.P. Kaelbling, and T. Lozano-Perez. From Skills to Symbols: Learning Symbolic Representationsfor Abstract High-Level Planning . Journal of Artificial IntelligenceResearch 61, pages 215-289, January 2018. Of course, the video is a lot more accessible: Other than that, here are a few sample project pages: Constructing High-Level Symbolic Representations for Planning . Autonomous Robot Skill Acquisition . Planning for the Decentralized Control of Multi-Robot Teams . Robot Motion Planning on a Chip . The Fourier Basis . Teaching I am currently teaching: CSCI 2951X: Reintegrating AI (Spring 2024) I have previously taught the following classes at Brown: CSCI 2951X: Reintegrating AI (Spring 2023) CSCI 1410: Artificial Intelligence (Fall 2022) CSCI 2951X: Reintegrating AI (Fall 2021) CSCI 1410: Artificial Intelligence (Fall 2021) CSCI 2951X: Reintegrating AI (Spring 2021) CSCI 2951X: Reintegrating AI (Spring 2020) CSCI 1410: Artificial Intelligence (Fall 2019) CSCI 2951X: Reintegrating AI (Spring 2018) CSCI 1410: Artificial Intelligence (Fall 2018) CSCI 1410: Artificial Intelligence (Fall 2017) CSCI 1410: Artificial Intelligence (Spring 2017) I taught the following classes when I was at Duke: CPS 590.2: Hierarchical Robot Learning and Planning (Fall 2014) CPS 270: Introduction to Artificial Intelligence (Spring 2015) CPS 590: Decision Making for Robots and Autonomous Systems (Fall 2015) CPS 270: Introduction to Artificial Intelligence (Spring 2016) var sc_project=724703; var sc_invisible=0; var sc_security=\"5a7b3b9d\"; var scJsHost = \"https://\";document.write(\"<sc\"+\"ript type='text/javascript' src='\" +scJsHost+\"statcounter.com/counter/counter.js'></\"+\"script>\");", "https://cs.brown.edu/people/faculty/rtamassi/": "Roberto Tamassia James A. and Julie N. Brown Professor of Computer Science, Chair of Computer Science Office: CIT 473 Phone: 401-863-7600 Email: roberto_tamassia @@ @brown.edu Assistant: Kate Correia Research Areas: Security and Cryptography, Algorithms and Theory, Data Science Teaching: Fall 2024 CSCI2951-E Topics in Computer System Security Spring 2025 (not teaching) Publications by Roberto Tamassia Home Page Contact Information Alternate email: roberto_tamassia@brown.edu My assistant: Kate Correia (katherine_correia@brown.edu) Q&A with Roberto Tell us a little about your background: educational, professional, personal, etc. I am originally from Italy. Franco Preparata was my doctoral advisor at the University of Illinois at Urbana-Champaign. After completing my PhD in 1988, I joined Brown, where I am currently James A. and Julie N. Brown Professor of Computer Science and Chair of the Department of Computer Science. What do you focus on in your research? Any recent advances? My primary research area is computer security and applied cryptography. Recent work includes methods and system prototypes for searchable encryption. I am also interested in design and analysis of algorithms, graph drawing, geometric computing, data management, and information visualization. What do you like teaching classes about? I like teaching classes that cover both theory and practical implementations. In 2005, I developed a course on computer systems security that can be taken by students as early as the second year. How did you become interested in computer science? As an undergraduate at the University of Rome, I was an electrical engineering concentrator. What got me interested in computer science was a course on programming and data structures taught by Carlo Batini, who eventually became my first academic mentor. What is your favorite thing about Brown? The synergism between excellence in research and in teaching. Any hobbies or passions? I am interested in classical music and finance. I enjoy stand-up paddleboarding, ocean kayaking, and cross-country skiing.", "https://cs.brown.edu/people/fprepara/": "Franco P. Preparata An Wang Professor of Computer Science franco@cs.brown.edu Address/Phone/Fax Department of Computer Science Center for Geometric Computing Brown University Biographical Sketch &nbsp Recent papers &nbsp Teaching &nbsp Computational Biology &nbsp The 101 Forum", "https://cs.brown.edu/people/faculty/twd/": "Thomas W Doeppner Associate Professor of Computer Science (Research), Vice Chair of Computer Science Office: CIT 405 Phone: 401-863-7633 Email: twd @@ @cs.brown.edu Research Areas: Computer Systems Teaching: Fall 2024 CSCI0081 TA Apprenticeship: Full Credit CSCI0082 TA Apprenticeship: Half Credit CSCI0330 Introduction to Computer Systems CSCI1330 Computer Systems (Master's students only) Spring 2025 CSCI0081 TA Apprenticeship: Full Credit CSCI0082 TA Apprenticeship: Half Credit CSCI1670 Operating Systems CSCI1690 Operating Systems Laboratory CSCI2670 Operating Systems Home Page Thomas Doeppner is interested in operating systems and everything related to them. He wrote one of the first threads packages for Unix and has dabbled in threads and concurrency ever since. With the help of a number of top undergraduate students, he worked on tools for measuring and analyzing performance of concurrent programs, particularly on shared-memory multiprocessors. He also designed and implemented an object-oriented threads package for C++, using ideas borrowed from Sun's Spring operating system. More recently, he worked with wireless devices and mobile computers, building an infrastructure for sharing information in settings such as lectures, seminars, and face-to-face meetings. He is currently interested in the area of operating system support for security. He is investigating means for running arbitrary programs without fear of the consequences. In the distant past he did work in proving the correct of parallel programs and published papers in STOC, POPL, and PODC.", "https://cs.brown.edu/people/gdk/": "George Konidaris Director: Intelligent Robot Lab Associate Professor Department of Computer Science Brown University, Providence RI gdk@cs.brown.edu Home | IRL | Research | Teaching | Publications | Software | CV Welcome to my home page. I'm an Associate Professor of Computer Science and director ofthe Intelligent Robot Lab at Brown , which forms part of bigAI (Brown Integrative, General AI) . My group and I conduct research driven by the overarching scientific goal of understanding the fundamental computational processes that generateintelligence, and using them to design a generally-intelligent robot. I am also the co-founder of two technology startups.I co-founded, and serve as the Chief Roboticist of, Realtime Robotics , a startup based on our research on robot motion planning , and that aims to make robotic automation simpler, better, and faster. I also co-founded Lelapa AI , a commercial AI research lab focused on technology by and for Africans, and based in Johannesburg, South Africa. If you're considering applying to the PhD program at Brown to study in my lab, please see this page . Research My research aims tobuild intelligent, autonomous, general-purpose robots that are generally capable in a wide variety of tasksand environments. I focus on understanding how todesign agents that learn abstraction hierarchies that enable fast, goal-oriented planning.I develop andapply techniques from machine learning, reinforcement learning, optimal control and planningto construct well-grounded hierarchies that result in fast planning for common cases,andare robust to uncertainty atevery level of control. I believe that it will take advances in all of these areas, and additionally advances in how to integrate these areas,to solve the AI problem. You can find an approachable (and short!) summary to some of my recent thinking on how to build generally intelligent agentsin the following review paper: G.D. Konidaris. On TheNecessity of Abstraction . Current Opinion in Behavioral Sciences 29(Special Issue on Artificial Intelligence),pages 1-7, October 2019. ... and in my recent invited talk at CoRL 2019 in Osaka, which is a good summary of my lab's work over the last few years: This recent journal paper is a good indicator of my interests - it combines ideas fromhierarchical reinforcement learning, probabilistic machine learning, task-level planning, and roboticsto create a robot that autonomously learns an abstract symbolic model of an environment and then uses it to plan: G.D. Konidaris, L.P. Kaelbling, and T. Lozano-Perez. From Skills to Symbols: Learning Symbolic Representationsfor Abstract High-Level Planning . Journal of Artificial IntelligenceResearch 61, pages 215-289, January 2018. Of course, the video is a lot more accessible: Other than that, here are a few sample project pages: Constructing High-Level Symbolic Representations for Planning . Autonomous Robot Skill Acquisition . Planning for the Decentralized Control of Multi-Robot Teams . Robot Motion Planning on a Chip . The Fourier Basis . Teaching I am currently teaching: CSCI 2951X: Reintegrating AI (Spring 2024) I have previously taught the following classes at Brown: CSCI 2951X: Reintegrating AI (Spring 2023) CSCI 1410: Artificial Intelligence (Fall 2022) CSCI 2951X: Reintegrating AI (Fall 2021) CSCI 1410: Artificial Intelligence (Fall 2021) CSCI 2951X: Reintegrating AI (Spring 2021) CSCI 2951X: Reintegrating AI (Spring 2020) CSCI 1410: Artificial Intelligence (Fall 2019) CSCI 2951X: Reintegrating AI (Spring 2018) CSCI 1410: Artificial Intelligence (Fall 2018) CSCI 1410: Artificial Intelligence (Fall 2017) CSCI 1410: Artificial Intelligence (Spring 2017) I taught the following classes when I was at Duke: CPS 590.2: Hierarchical Robot Learning and Planning (Fall 2014) CPS 270: Introduction to Artificial Intelligence (Spring 2015) CPS 590: Decision Making for Robots and Autonomous Systems (Fall 2015) CPS 270: Introduction to Artificial Intelligence (Spring 2016) var sc_project=724703; var sc_invisible=0; var sc_security=\"5a7b3b9d\"; var scJsHost = \"https://\";document.write(\"<sc\"+\"ript type='text/javascript' src='\" +scJsHost+\"statcounter.com/counter/counter.js'></\"+\"script>\");", "https://cs.brown.edu/people/gsatas/": "Gryte Satas gsatas at cs.brown.edu Box 1910, Computer Science Department Brown University Providence, RI 02912 401-863-7600 CS Home Page", "https://cs.brown.edu/people/irisbahar/index.html": "Research (current) Students Teaching Publications Contact News and Upcoming Travel 9/3/2020 PhD student Yanqi (Jasmine) Liu presented her work at FPL . 4/6/2020 Undergrad student Casey Nelson wins Randy F. Pausch summer research award. R. Iris Bahar I am a Professor of Computer Science and Engineering at Brown University . I hold a joint appointment in the School of Engineering and Department of Computer Science . My research interests lie broadly in the areas of computer system design and electronic design automation. In particular, my research focuses on energy-efficient and reliable computing, from the system level to device level. Past research topics have included modelling thermal noise effects in nanoscale circuits, design of noise- and error-immune circuits, approximate computing (from systems to circuits), and memory synchronization techniques for multiprocessor systems. Most recently, my research interests have led me to explore applications for near-data processing and design of robust machine learning techniques for robot scene perception. More information about my research, teaching, and service can be found on my Brown University research page. Below is a brief overview of a few of my recent research projects. Concurrent Near-Data Processing Architectures Recent advances in memory architectures have provoked renewed interest in near-data-processing (NDP) as way to alleviate the \u201cmemory wall\u201d problem. An NDP architecture places logic circuits, such as simple processors, in close proximity to memory. This is distinct from processing-in-memory (PIM) where logic computation is effectively integrated into the memory cells/arrays. More -> Robust and Computationally-Efficient Scene Perception Technological advancements have led to a proliferation of robots using machine learning systems to assist humans in a wide range of tasks. However, we are still far from accurate, reliable, and resource-efficient operations of these systems. More -> Modeling of Fundamental Noise Effects in Nanoscale Circuits Near-threshold and sub-threshold voltage designs have been identified as possible solutions to overcome the limitations introduced by energy consumption in modern VLSI circuits. However, aggressive voltage and gate length scaling will reduce the reliability of logic circuits due to the increasing impact of noise and variability effects. More -> Managing Microarchitecture Timing Violations with Hardware Transactional Memory Scaling of semiconductor devices has enabled higher levels of integration and performance improvements at the price of making devices more susceptible to the effects of static and dynamic variability. Adding safety margins (guardbands) on the operating frequency or supply voltage prevents timing errors but has a negative impact on performance and energy consumption. More -> Copyright \u00a9 R. Iris Bahar 2020", "https://cs.brown.edu/people/jcmace/xtrace_viz/swimlane.html?id=850b29dd6d48c13d.json": "", "https://cs.brown.edu/people/faculty/stellex/": "Stefanie A Tellex Associate Professor of Computer Science, Associate Professor of Engineering Office: CIT 375 Phone: 401-863-6898 Email: stellex @@ @cs.brown.edu Assistant: Suzanne M Alden Research Areas: Artificial Intelligence, Machine Learning, Robotics Home Page", "https://cs.brown.edu/people/hg12/": "Hua Guo huag (at) cs (dot) brown (dot) edu 553 CIT Box 1910, Computer Science Department Brown University Providence, RI 02912 About Me In 2015 - 2016, I am a fifth year PhD student in Computer Science Department in Brown University. I work in the Visualization Research Lab , and my advisor is Professor David Laidlaw . Before starting my study at Brown, I received my B.S. degree in Computer Science and Mathematics from Hong Kong University of Science and Technology. Research My research centers on human-centered design and evaluation of visual analytics tools to support scientific reasoning. No matter what computational methods we apply to extract, transform, and summarize information, information needs to be processed by human users at the end to be converted into knowledge and decisions, and visual analytics applications need to help human process information more effectively. Therefore, my research aims to inform the design of visual analysis tools by studying how users perceive, interact with, and ultimately make sense of the visualized data. I have been collaborating with experts outside Computer Science, primarily brain scientists, to distill visualization research problems from their needs while developing tools that can help them in their work. Publications Papers A Case Study Using Visualization Interaction Logs and Insight Metrics to Understand How Analysts Arrive at Insights IEEE VAST , 2015 Hua Guo , Steven R. Gomez, Caroline Ziemkiewicz, and David H. Laidlaw Representing Uncertainty in Graph Edges: An Evaluation of Paired Visual Variables IEEE Transactions on Visualization and Computer Graphics , 2015 Hua Guo , Jeff Huang, and David H. Laidlaw Crowdsourcing from Scratch: A Pragmatic Experiment in Data Collection by Novice Requesters HCOMP , 2015 Alexandra Papoutsaki, Hua Guo , Danae Metaxa, Jeff Rasley, Jeff Huang An Insight- and Task-based Methodology for Evaluating Spatiotemporal Visual Analytics IEEE VAST , 2014 Steven R. Gomez, Hua Guo , Caroline Ziemkiewicz, and David H. Laidlaw Different Strokes for Different Folks: Visual Presentation Design Between Disciplines IEEE InfoVis , 2012 Steven R. Gomez, Radu Jianu, Caroline Ziemkiewicz, Hua Guo , and David H. Laidlaw Extended Abstracts and Posters Visualization to Facilitate Structured Exploration of Published Findings in Rat Brain Connectivity IEEE InfoVis (Poster session) , 2013 Hua Guo , Steven R. Gomez, Mark J. Schnitzer, David H. Laidlaw Toward a visual interface for brain connectivity analysis ACM CHI (Poster session) , 2013 Hua Guo , Arthur Yidi, Steven R. Gomez, Mark J. Schnitzer, David Badre, David H. Laidlaw Incorporating GOMS analysis into the design of an EEG data visual analysis tool IEEE InfoVis (Poster session) , 2012 Hua Guo , Diem Tran, and David H. Laidlaw", "https://cs.brown.edu/people/jcmace/xtrace_viz/swimlane.html?id=spark.json": "", "https://cs.brown.edu/people/jcmace/xtrace_viz/swimlane.html?id=c0d0c0add1f23721.json": "", "https://cs.brown.edu/people/jhughes/home.htm": "John Hughes Professor of Computer Science Current Activities Research Projects Office Hours For Fall 2012: Mondays, 1:00 - 2:00 PM, and by email appointment Biography, CV, and Contact Courses CS 224 - Interactive Computer Graphics, Spring 2010 CS 16 - Introduction to Algorithms and Data Structures, Spring 2010", "https://cs.brown.edu/people/jsavage/blockchain.html": "Blockchain Technologies and Cryptocurrencies Prof. John E. Savage Brown University Brown University Courses CS 2952 A \u2014 Blockchains and Cryptocurrencies Lecture 13 of CSCI 1800, Cybersecurity and International Relations Observations about the Internet and Cryptocurrencies Motto of the Internet Engineering Community: We reject: kings, presidents and voting. We believe in: rough consensus and running code. Appears in \"A Cloudy Crystal Ball \u2014 Visions of the Future,\" by David Clark, 24th Internet Engineering Task Force, 1992 A Declaration of the Independence of Cyberspace by John Perry Barlow, February 8, 1996 A Declaration of the Dependence of Cyberspace by Moshe Y. Vardi, Communications of the ACM, Vol. 61 No. 3, Page 9, 2018 CryptoCurrency Facts Opinions about Blockchain Technologies Just Another Day for Bitcoin \u2014 a 25% Plunge: Digital currency down 48% from December high amid growing regulatory scrutiny by Mike Bird and Gregor STuart Hunter, The Wall Street Journal, January 16, 2018 Blockchain's Broken Promises by Nouriel Roubini, Project Syndicate, January 26, 2018 The Blockchain Pipe Dream by Nouriel Roubini and Preston Byrne, Project Syndicate, March 5, 2018 Why Blockchain Will Survive, Even If Bitcoin Doesn't: Latest blockchain applications could bring overdue change to critical, if unsexy, functions in shipping, real estate and ... diamonds by Christopher Mims, The Wall Street Journal, March 11, 2018 Blockchain is not only crappy technology but a bad vision for the future by Kai Stinchcombe, Medium, April 5, 2018 \"Projects based on the elimination of trust have failed to capture customers' interest because trust is actually so damn valuable.\" The Blockchain Movement is Underway. What Should CEOs Know? , FTI Journal, May 2018 187 THINGS THE BLOCKCHAIN IS SUPPOSED TO FIX , by Eric Griffin, Wired, May 25, 2018 Alternatives to Blockchain by Jimmy Song, Medium, May 23, 2018 Monetary Policy in the Digital Age: Crypto assets may one day reduce demand for central bank money by Dong He, International Monetary Fund, June 2018 This article analyzes the consequences of replacing a fiat currency with a cryptocurrency. Top banker batters Bitcoin for sucky scalability, security: Australia's Reserve Bank sees no need for national cryptocurrencies, for now by Simon Sharwood, The Register, June 27 2018 Tony Richard, head of payments policy at Australia's Reserve Bank, highlights the scaling problems associated with the Bitcoin currency. This Year's Blockchain Craze Mirrors the Early Days of the Internet by Iris Zhao, The Council on Foreign Relations, December 20, 2018 Remember Bitcoin? Some Investors Might Want to Forget by Nellie Bowles, The New York Times, December 27, 2018 Raising Money in the Crypto World Has Gotten a Lot Harder: The market for initial coin offerings, which boomed last year, has ground to a halt by Paul Vigna, The Wall Street Journal, March 31, 2019 Amid Bitcoin Uncertainty, 'the Smart Money Knows That Crypto Is Not Ready' by Nathaniel Popper, The New York Times, April 2, 2019 Introduction to Bitcoins The Crypto-Currency: Bitcoin and its mysterious inventor by Joshua Davis, The New Yorker, October 10, 2011 The author provides an introduction to bitcoin and describes his attempt to identify its author, Satoshi Nakamoto. How Bitcoin Works Under the Hood , CuriousInventor, YouTube, January 31, 2017 (A transcript of the video is available here .) This 22:24 minute video provides a technical introduction to bitcoin, the world's first cryptocurrency. It defines bitcoin transfers and explains how bitcoin ownership is certified, how transfers occur using a decentralized public blockchain, and the role of miners who collect transfers, solve a hard computational problem to obtain a proof of work, and form a block and append it to the blockchain. It also explains the verification process that each miner does to verify the ownership of bitcoin and the work of other miners, thereby realizing a system of trust without invoking a trusted centralized broker. The State of the Ethereum Network: After months of intense attention on blockchain technology and the Ethereum blockchain, we pull together statistics from across the network to provide a snapshot of Ethereum today, its past, and its roadmap ahead , Consensus, June 1, 2018 Blockchain Technologies Introduction to Blockchains What is blockchain? The most disruptive tech in years by LucasMearian, Computerworld, January 18,2018 This article provides a high-level textual description of blockchains. What is Blockchain? , Centre for International Governance Innovation, YouTube, January 4, 2018 This 6:26 minute video provides a quick overview of the operation ofblockchains and their importance. Blockchains: How They Work and Why They'll Change the World byMorgen E. Peck, IEEE Spectrum, September 28, 2017 This article provides more depth than the video and introduces the conceptof smart contracts . Blockchain by Margaret Rouse, TechTarget, SearchCIO.com, July 26, 2017 SPECIAL REPORT: BLOCKCHAIN WORLD , IEEE Spectrum, September 28, 2017 This is a collection of 11 articles on blockchain technology. Decentralized Blockchain-Based Electronic Marketplaces by Hemang Subramanian, Communications of the ACM, January 2018(A video providing an overview of blockchains is available here .) MIT's Blockchain Site Maurice Herlihy's Site for CSCI 2952-A Understanding The DAO Attack by David Siegel, Coindesk, June 25, 2016 Realizing Policy Goals through Blockchain Technology , Centre for International Governance Innovation, July 6, 2017 SPECIAL REPORT: BLOCKCHAIN WORLD , IEEE Spectrum Wall Street Firms to Move Trillions to Blockchains in 2018 by AmyNordrum, IEEE Spectrum, September 29,, 2017 Do You Need a Blockchain? by Morgen E. Peck, IEEE Spectrum,September 29, 2017Money pp 239-278, September 1, 2016 50+ Examples of How Blockchains are Taking Over the World by MatteoGianpietro Zago, Medium, May 30, 2018 DealBook , The New York Times, June 27,2018 Demystifying the Blockchain by Andrew Ross Sorkin, The New YorkTimes, June 27, 2018 Confused About Blockchains? Here's What You Need to Know by Nathaniel Popper, The New York Times, June 27, 2018 Industries, Looking for Efficiency, Turn to Blockchains by Laura Shin, The New York Times, June 27,2018 The People Leading the Blockchain Revolution by Nathaniel Popper, The New York Times, June 27, 2018 A Guide to the World of Blockchain by Nathaniel Popper and Guilbert Gates, The New York Times, June 27, 2018 Scaling Issues Ensuring Network Scalibility: How to Fight Blockchain Bloat byAndrew Wagner, BitcoinMagazine, November 6, 2014 What is the Lightning Network and how can it help Bitcoin scale? by Elizabeth Stark, coincenter, September 15, 2016 Blockchains don't scale. Not today, at least. But there's hope. by Preethi Kasireddy, Hackernoon, August 23, 2017 Bitcoin Hasn't Replaced Cash, but Investors Don't Care by Nathaniel Popper, December 6, 2017 This article states that Bitcoin can handle about 5 transactions persecond whereas Visa is able to handle about 25,000 transactions per second. Plasma: Scalable Autonomous Smart Contracts by Joseph Poon and Vitalik Buterin, Working Draft, August 11, 2017 Bitcoin Lightning Network \u2014 7 Things You Should Know by LukasSchor, Medium, January 10, 2018 The State of Scaling Ethereum: A concise overview of the challenges and solutions to scaling the Ethereum Network , Consensy, April 24, 2018 Ethereum's Casper and Sharding New Design by Michael K. Spencer, Medium, June 16, 2018 Blockchain phase 2: Will it scale? by Lucas Mearian, Computerworld, August 15, 2018 As blockchain grows in popularity, so does the conundrum of how to scale it while maintaining or boosting performance so it can compete with today's transaction networks. Mutable Blockchains Accenture's Blockchain Redaction Solution by Martha Bennett, Accenture, April 2017 Redactable Blockchain \u2013or\u2013 Rewriting History in Bitcoin andFriends by Giuseppe Ateniese, Bernardo Magri, Daniele Venturi and Ewerton Andrade, The International Association for Cryptologic Research, May 11, 2017 Consensus Algorithms Proof of Stake FAQ , by Moshe Simantov, GitHub, 2018 Casper the Friendly Gadget by Buterin and Griffith Incentives in Casper the Friendly Gadget by Vitalik Buterin, Ethereum, August 27, 2017 Decentralization in Bitcoin and Ethereum Networks by Gencer, Basu, Eyal, Renesse, and Sirer, Cornell University, January 11, 2018 When IoT met blockchain by Frederic Paul, Networkworld, January 26, 2018 A Concurrent Perspective on Smart Contracts by Ilya Sergey and Aquinas Hobor, arXiv.org, February 17, 2017 IBM sees blockchain as ready for government use by Lucas Mearian, Computerworld, February 14, 2018 The Eureka Moment That Made Bitcoin Possible: A key insight for the technology came to a physicist almost three decades ago at a Friendly's restaurant in New Jersey by Amy Whitaker, May 25, 2018 Scaling Nakamoto Consensus to Thousands of Transactions per Second by Chenxing Li, Peilun Li, Dong Zhou, Wei Xu, Fan Long, and Andrew Chi-Chih Yao, arXiv:1805.03870, August 31, 2019 Solida: A Blockchain Protocol Based on Reconfigurable Byzantine Consensus by Ittai Abraham, Dahlia Malkhi, Kartik Nayak, Ling Ren, and Alexander Spiegelman, arXiv 1612.02916, November 18, 2017 Ethereum Plans to Cut Its Absurd Energy Consumption by 99 Percent by Peter Fairley, IEEE Spectrum, January 2, 2019 Cryptocurrency Vulnerabilities BatchOverflow Exploit Creates Trillions of Ethereum Tokens, Major Exchanges Halt ERC20 Deposits by Sam Town, Cryptoslate, April 25, 2018 Majority Is Not Enough: Bitcoin Mining Is Vulnerable by Ittay Eyal and Emin G\u00fcn Sirer, CACM, July 2018 Problems with Smart Contracts The Curious Case of 184 Billion Bitcoin by Bruno, January 14, 2018 The author explains how a failure to check for integer overflow in the Bitcoin softwareallowed two units of about 184 million bitcoin to be created and sent toaccounts in 2010 until corrected. Blockchains from a Distributed Computing Perspective by MauriceHerlihy, Brown University, January 16, 2018 \"This article is a tutorial on the basic notions and mechanismsunderlying blockchains, colored by the perspective that much of theblockchain world is a disguised, sometimes distorted, mirror-imageof the distributed computing world.\" Maurice also explains how a failureto understand this lead to the theft of about $50 Million from theDecentralized Autonomous Organization (DAO) in 2016 by exploiting poorlydesigned \"smart contracts.\" An Overview of Cryptocurrency Consensus Algorithms by Phil Glazer,HackerNoon, March 14, 2018 This Yale Technology Could Fix Blockchain's Security Issues and Make It a Lot More Viable , Office of Cooperative Research, Yale University,2018 A team at Yale has developed technology to simplify verification of thecorrectness of smart contracts. When smart contracts are embedded inblockchains, they are permanent. If they contain errors, misuse ofblockchain data can occur. The only way to fix this is to execute a hardfork, which requires rebuilding the blockchain from the point of the error. Databases for Blockchains Concerto: A High Concurrency Key-Value Store with Integrity by Arvind Arasu, Ken Eguro, Raghav Kaushik, Donald Kossmann,Pingfan Meng, Vineet Pandey, and Ravi Ramamurthy, Procs.2017 ACM International Conference on Management of Data (SIGMOD), Pages 251-266 Available Blockchain Implementations Hyperledger Consortium , a product of the Linux Foundation. (See this article .) Microsoft wants to make blockchain networks enterprise-ready with its new Coco Framework by Frederic Lardinois, TechCrunch, August 10, 2017 Announcing the Coco Framework for enterprise blockchain networks , Mark Russinovich, CTO, Microsoft Azure, August 10, 2017 Corda , a distributed ledger technology. Corda is an open source blockchain project designed for business from the start. Only Corda allows you to build interoperable blockchain networks that transact in strict privacy. Corda's smart contract technology allows businesses to transact directly, with value. Quorum by J. P. Morgan Quorum\u2122 is an enterprise-ready distributed ledger and smart contract platform. The Bitcoin Mining Process Bitcoin Reward Halving Countdown In one chart, here's how much it costs to mine bitcoin in your state , by Ryan Vlastelica, MarketWatch, December 18, 2017 A (Short) Guide to Blockchain Consensus Protocols by Amy Castor, coindesk, March 4, 2017 What Is Cryptocurrency \u2014 How It Works, History & Bitcoin Alternatives by Brian Martucci, Money Crashers Crypto Mining \u2014 ETH \u2014 Not Worth Starting by Tyler, Medium, May 25, 2018 Cryptocurrencies Bitcoin: A Peer-to-Peer Electronic Cash System by Satoshi Nakamoto, published on the cryptography mailing list metzdowd.com. 100 Cryptocurrencies Described in Four Words or Less , by Nate Murray, TechCrunch, November 19, 2017 Want to really understand how bitcoin works? Here's a gentle primer by Timothy B. Lee, Ars Technica, December 15, 2017 Five myths about bitcoin by Joseph Bonneau and Steven Goldfeder, The Washington Post, December 15, 2017 Bitcoin's Academic Pedigree by Arvind Narayanan, Jeremy Clark, Communications of the ACM, Vol. 60 No. 12, Pages 36-45, December 2017 Algorand: Scaling Byzantine Agreements for Cryptocurrencies by Yossi Gilad, Rotem Hemo, Silvio Micali, Georgios Vlachos, and Nickolai Zeldovich, SOSP 2017 Algorand provides a new way to create distributed ledgers that avoids important problems that arise with traditional blockchains. A 39:46 minute video of a talk given at Berkeley by Silvio Micali explains the basic concepts is available here . A longer and more complete 1:12:46 video produced by the ACM is available here . Merrill Lynch Bars Trading of Bitcoin Fund, Futures: Firm has already denied clients access to the bitcoin futures markets by Lisa Beilfuss, The Wall Street Journal, January 3, 2018 Russia and Venezuela's Plan to Sidestep Sanctions: Virtual Currencies by Nathaniel Popper, Oleg Matsnev and Ana Vanessa Herrero, The New York Times, January 3, 2018 Rise of Bitcoin Competitor Ripple Creates Wealth to Rival Zuckerberg by Nathaniel Popper, The New York Times, January 4, 2018 SEC warns cryptocurrency investors of rampant illegal trading by Sylvan Lane, The Hill, January 4, 2018 Ripple Steals Bitcoin's Thunder, Surges 1,135% in a Month by Paul Vigna, The Wall Street Journal, January 5, 2018 Initial Coin Offerings and Cryptocurrencies Will be a Priority for FINRA in 2018 by Linn Foster Freedman, Robison + Cole, January 11, 2018 MoneyGram Signs Deal to Work With Currency Startup Ripple: Money-transfer company will run a pilot program testing XRP, a digital currency by Paul Vigna and Peter Rudegeair, The Wall Street Journal, January 11, 2018 Beyond the Bitcoin Bubble: Yes, it's driven by greed \u2014 but the mania for cryptocurrency could wind up building something much more important than wealth. by Steven Johnson, The New York Times, January 16, 2018 New Cyberattack on Cryptocurrency Investors Came From North Korea, Report Says by Jonathan Cheng, The Wall Street Journal, January 17, 2018 Credit Card Companies Don't Want You to Buy Bitcoin With Plastic by AnnaMaria Andriotis and Paul Vigna, The Wall Street Journal, January 25, 2018 Cryptocurrency botnets are rendering some companies unable to operate by Dan Goodin, ArsTechnica, February 2, 2018 Bitcoin's Plunge Weighs on Coin Offerings by Paul Vigna, The Wall Street Journal, February 7, 2018 A $232 Million Cryptocurrency Fight Comes to a Close: Tezos team can move forward after nonprofit foundation chief who was locked in a battle for control of funds steps down by Paul Vigna, The Wall Street Journal, February 22, 2018 What Bitcoin Rout? Sales of New Digital Tokens Are Still Soaring by Paul Vigna, The Wall Street Journal, February 22, 2018 Bitcoin's Underlying Incentives by Yonatan Sompolinsky, Aviv Zohar Communications of the ACM, Vol. 61 No. 3, Pages 46-53, 2018 Bitcoin Price , Business Insider Bitcoin Diamond/Super Bitcoin/BitCore: What You Need To Know by Jimmy Song, Medium, January 3, 2018 Top Cryptocurrency Primer Guide in Bite Sized Notes by Michael Spencer, Medium, May 27, 2018 Bitcoin Drop Sparks Broad Cryptocurrency Selloff by Paul Vigna, The Wall Street Journal, June 22, 2018 Crypto Pioneer David Chaum Says He's Built a Better Bitcoin: A new platform, called Elixxir, promises to improve on bitcoin's speed by processing thousands of transactions a second by Paul Vigna, The Wall Street Journal, September 19, 2019 Cryptocurrency Exchanges Cryptocompare This site lists the current price in various currencies of 1994 cryptocurrencies. Bitcoin Plunges as South Korea Crafts Cryptocurrency Crackdown: South Korea is preparing a bill to ban the trading of cryptocurrencies on exchanges by Eun-Young Jeong and Gregor Stuart Hunter, The Wall Street Journal, January 11, 2018 This week's Bitcoin crash was all about fraud and regulation by Simon Chandler, The Verge, January 18, 2018 The Programmer at the Center of a $100 Billion Crypto Storm by Paul Vigna and Jim Oberman, The Wall Street Journal, January 23, 2018 What's Bitcoin Worth? A New Plan to Bring Discipline to Crypto Prices by Alexander Osipovich, The Wall Street Journal, January 19, 2018 Financial regulators subpoena major bitcoin exchange by Ali Breland, The Hill, January 30, 2018 Cryptocurrency Firm Coinbase in Talks to Become SEC-Regulated Brokerage by Dave Michaels, The Wall Street Journal, April 6, 2018 Other Countries Forge Ahead on Crypto Regulations by Laura Shin, The New York Times, June 27, 2018 Bots Are Manipulating Price of Bitcoin in 'Wild West of Crypto': Abusive softrware runs largely unchecked on crypto exchanges, prompting regulatory concern by Paul Vigna and Alexander Osipovich, The Wall Street Journal, October 2, 2018 Initial Coin Offerings HoweyCoins PRE-ICO SALE IS LIVE! The SEC Has an Opportunity You Won't Want to Miss: Act Now! , U.S. Securities and Exchange Commission The SEC has created a website advertisiting a fake initial coin offering (ICO). Cryptocurrency ICO Stats 2018 , CoinSchedule The Failure Rate of ICOs is Skyrocketing in 2018 by Michael K. Spencer, Medium, August 9, 2018 Cryptocurrency Scandals A Painful Lesson For The Ethereum Community by Frances Coppola, Forbes, July 21, 2016 Bitcoin: $64m in cryptocurrency stolen in 'sophisticated' hack, exchange says by Samuel Gibbs, The Guardian, December 7, 2017 Japanese Cryptocurrency Exchange Coincheck to Pay Back Customers by Peter Landers, The Wall Street Journal, January 27, 2018 Bitcoin wallets vulnerable to security hacks , University of Ediburgh Cryptocurrency botnets are rendering some companies unable to operate by Dan Goodin, ArsTechnica, February 2, 2018 BitGrail cryptocurrency exchange loses $170 million in Nano tokens \"... the checks for whether you had a sufficient balance to withdraw were only implemented as client-side JavaScript\" Cryptocurrency Worth $170 Million Missing From Italian Exchange: BitGrail says it lost about 17 million tokens of Nano by Paul Vigna, The Wall Street Journal, February 10, 2018 Inside the World's Bigggest Cryptocurrency Hack \u2014 and How the Scammers Pulled it Off by Rob Wile, Money, January 29, 2018 Feds charge former bitcoin exchange with fraud by Ali Breland, The Hill, February 21, 2018 Crypto Wallet Vs. Address: Believe it or not, there's a difference! by Kenny Li, Hackernoon, May 22, 2018 About $1.2 billion in cryptocurrency stolen since 2017 by Gertrude Chavez-Dreyfuss, Reuters, May 24, 2018 Policing Cryptocurrencies Has Become a Game of Whack-a-Mole for Regulators by Peter J. Henning, The New York Times, May 31, 2018 Making Bitcoin Legal by Ross Anderson, Ilia Shumailov and Mansoor Ahmed, Cambridge University Computer Laboratory, 2018 The authors identify existing law that can be applied to making bitcoin legal. Bitcoin Falls Sharply After Another Cryptocurrency Exchange Is Hacked: The largest cryptocurrency has lost more than half its value this year by Steven Russolillo, The Wall Street Journal, June 10, 2018 Bitcoin's Price Was Artificially Inflated, Fueling Skyrocketing Value, Researchers Say by Nathaniel Popper, The New York Times, March 30, 2018 \"A concentrated campaign of price manipulation may have accounted for at least half of the increase in the price of Bitcoin and other big cryptocurrencies last year.\" Major cryptocurrency exchange Bithumb halts trading after more than $31 million hack by Brian Murphy, The Washington Post, June 19, 2018 Inside the Crypto World's Biggest Scandal by Gideon Lewis-Kraus, Wired, June 19, 2018 A Fifth of All Bitcoin Is Missing. These Crypto Hunters Can Help by Elliott Krause, The Wall Street Journal, July 5, 2018 Cryptocurrency's Criminal Revolution by Tyler Eliot Bettilyon, Medium, July 12, 2018 Cryptocurrency Exchanges Are Getting Hacked Because It's Easy: Regulatory gaps and insufficient levels of defense have made some exchanges simple to breach by Steven Russolillo and Eun-Young Jeong, The Wall Street Journal, July 16, 2018 Traders Are Talking Up Cryptocurrencies, Then Dumping Them, Costing Other Millions: 'Pump groups' fuel millions in trading activity, with price rises followed by quick falls by Shane Shifflett and Paul Vigna, The Wall Street Journal, August 5, 2018 The Big Blockchain Lie by Nouriel Roubini, Project Syndicate, Octobr 15, 2018 ICO Firms Paid Themselves $24 Billion Absent of Accountability or Much Effort by Shaurya Malwa, CRYPTOSLATE, January 18, 2019 A 'Blockchain Bandit' is Guessing Private Keys and Scoring Millions by Andy Greenberg, WIRED, April 23, 2019 A new cryptocurrency mining malware uses leaked NSA exploits to spread across enterprise networks by Zack Whittaker, TechCrunch, April 25, 2019 Blockchain and Cryptocurrency Governance BitLicense Regulatory Framework , New York State Russia and Venezuela's Plan to Sidestep Sanctions: Virtual Currencies by Nathaniel Popper, Oleg Matsnev and Ana Vanessa Herrero, The New York Times, January 3, 2018 U.S. Sanctions Weapon Is Under Threat, but Not From Bitcoin by Keith Johnson and Elias Groll, Foreign Policy, January 24, 2018 Bitcoin's real story isn't the rampant speculation, but its untold potential by Steve Forbes, The Hill, January 18, 2018 Cryptocurrencies Are Top of Mind for G20 Finance Ministers: Anonymity and borderless transactions create a perfect climate for money laundering by Samantha St. Amand, Centre for International Governance Innovation, February 20, 2018 Women in Cryptocurrencies Push Back Against 'Blockchain Bros' by Nellie Bowles, The New York Times, February 25, 2018 G20 leaders to hold fire on cryptocurrencies amid discord: sources by Francesco Canepa, Reuters, March 19, 2018 Bitcoin Could Become Illegal Almost Everywhere, After Shocking Discovery in The Blockchain: There's something hidden inside it. by Peter Dockrill, Science Alert, March 22, 2018 Venture Capitalists Seek 'Safe Harbor' for Virtual Currencies by Nathaniel Popper, The New York Times, April 19, 2018 A Former Top Wall Street Regulator Turns to the Blockchain by Nathaniel Popper, The New York Times, April 22, 2018 The Crypto Crime Wave Is Here: From stickups and drug deals to white-collar scams, cryptocurrency-related crime is soaring and law enforcement is scrambling to keep up by Corinne Ramey, The Wall Street Journal, April 26, 2018 Blockchain Will Be Theirs, Russian Spy Boasted at Conference by Nathaniel Popper, April 29, 2018 Cryptocurrency Regulation Update (May 2018) by Phil Glazer, Hackernoon, May 1, 2018 Recent Trends in Virtual Currency Regulation, Enforcement, and Litigation by Sharon Brown-Hruska and Trevor Wagener, NERA, May 21, 2018 Regulatory uncertainty could stymy blockchain adoption: Even as companies seek to integrate the distributed ledger technology into their business models, uncertainty about the regulatory landscape is seen as a major stumbling block. By Lucas Mearian, Computerworld, June 7, 2018 Decentralized Blockchain Governance by Daniel Larimer, Medium, June 20, 2018 State of Cryptocurrencies: Summer 2018 by Adam Tach\u00e9, Hackernoon, June 23, 2018 Cryptocurrency Regulation Update (June 2018) by Phil Glazer, Hackernoon, June 12, 2018 COINBASE DOUBLES DOWN ON THE FUTURE OF DIGITAL IDENTITY by Gregory Barber, Wired, August 15, 2018 Energy Consumption The Hard Math Behind Bitcoin's Global Warming Problem by Adams Rogers, Wired, December 15, 2017 There Is Nothing Virtual About Bitcoin's Energy Appetite by Nathaniel Popper, The New York Times, January 21, 2018 Bitcoin's alarming carbon footprint , Spyros Fonteinis, Nature, Vol. 554, February 8, 2018 Cryptocurrency mining in Iceland is using so much energy, the electricity may run out by Rick Noack, The Washington Post, February 13, 2018 Bitcoin Mania Triggers Miner Influx to Rural Washington by Alison Sider, The Wall Street Journal, February 11, 2018 Salon to use readers' computers to mine cryptocurrency by Julia Manchester, The Hill, February 13, 2018 Salon Is Asking Readers to Mine Cryptocurrency if They Don't Want to See Ads by AAron Mark, Slate, February 13, 2018 Is Bitcoin a Waste of Electricity, or Something Worse? by Binyamin Appelbaum, The New York Times, February 28,2018 Cryptocurrency mining is neither wasteful nor uneconomic by Stuart Wimbush, Nature, March 21, 2018 Why it's time to stop mining cryptocurrency and look to the future of blockchain: The time has come to stop mining cryptocurrencies. , by Alex Stand, Medium, April 3, 2018 Iceland Takes Hard Look at Tech Boom Sparked by Its Cheap, Bountiful Power by Zeke Turner, The Wall Street Journal, April 19, 2018 By 2030, data centers and all internet-related activity, from streaming video to analyzing financial data to storing software, photos and emails, could use more electricity than all of China did in 2018. Deconstructing the Blockchain to Approach Physical Limits by Vivek Bagaria, Sreeram Kannan, David Tse, Giulia Fanti, and Pramod Viswanath, axXiv:1810.08092, October 18, 2018 Ethereum Plans to Cut Its Absurd Energy Consumption by 99 Percent by Peter Fairley, IEEE Spectrum, January 2, 2019 Commercial Offerings IBM and Stellar Are Launching Blockchain Banking Across Multiple Countries by Jeff John Roberts, Fortune, October 16, 2017 An overview of Stellar is given here . A comparison of Stellar with other blockchains is available here . And a detailed explanation of Stellar is given here . Need help on blockchain? These are the top three experts: How IBM, Microsoft and Accenture have made themselves consultants of choice by Finbarr Toesland, The Times of London,, November 16 2017 Google Is Working on Its Own Blockchain-Related Technology by Olga Kharif and Mark Bergen, Bloomberg Technology, March 2,1 2018 Twitter is joining Facebook and Google in banning cryptocurrency advertisements: The ban isn't yet official, but should be soon. by Kurt Wagner, recode, March 19, 2018 Google to Ban Ads for Cryptocurrencies: New policy follows Facebook's lead, takes effect in June by Lara O'Reilly and Douglas MacMillan, The Wall Street Journal, March 13, 2018 Goldman Sachs to Open a Bitcoin Trading Operation by Nathaniel Popper, The New York Times, May 2, 2018 IBM partners Stronghold for new digital stable coin by Gertrude Chavez-Dreyfuss, Reuters, July 17, 2018 Blockchain Efforts Move Beyond the Hype: 'This is Happening Now' by Matthew Leising, Bloomberg, July 19, 2018 Cryptocurrency Startups Combine as Wall Street Blockchain Effort Falters by Paul Vigna, The Wall Street Journal, September 10, 2018 Advice on Blockchains Blockchain How this technology could impact the CFO Blockchain reaction: Tech plans for critical mass Blockchain: the hype, the opportunity and what you should do by Angus Champion de Crespigny, Ernst & Young LLP, 2016 NISTIR 8202 (Draft) Blockchain Technology Overview by Dylan Yaga (NIST), Peter Mell (NIST), Nik Roby (G2), Karen Scarfone (Scarfone Cybersecurity), NIST Interledger Currency Exchanges Interledger: How to Interconnect All Blockchains and Value Networks by Evan Schwartz and Vanessa Pestritto, Medium, October 3, 2018 Curated List of Publications by Philippe Camacho Papers on Bitcoins, Blockchains, and Smart Contracts Miscellaneous What is the Privacy Coin Matrix? by Michael Spencer, Medium, May 21, 2018 News Reports Ethereum is Not Secure and it's Delayed its Upgrade again by Michael K. Spencer, Medium, January 16, 2019 John Savage", "https://cs.brown.edu/people/jsavage/deterrence.html": "Cyber Deterrence Prof. John E. Savage Brown University Deterrence Methods Cyberdeterrence and Cyberwar by Martin Libicki, Rand, 2009 Deception, Disinformation, and Strategic Communications: How One Interagency Group Made a Major Difference by Fletcher Schoen and Christopher J. Lamb, Institute for National Strategic Studies, Strategic Perspective, No. 11, National Defense University, June 2012 Toward Theory for Dissuasion (or Deterrence) by Denial: Using Simple Cognitive Models of the Adversary to Inform Strategy by Paul K. Davis, RAND NSRD WR-1027, January 2014 \"This Working Paper grew out a conference paper presented at the Munk School of the University of Toronto, October 18-20, 2013. The conference, Deterrence by Denial: Theory, Practice, and Empiricism, was co-organized by the Munk School of Global Affairs and the Center for Security Studies, ETH Zurich.\" How the United States Can Win the Cyberwar of the Future: Cold War-era deterrence theory won't cut it anymore. by P.W. Singer, Foreign Policy, December 18, 2015 \"There is perhaps no national security problem more 21st century in both its definition and form than cybersecurity. And yet to solve it, the ready solution in nearly every U.S. national security conversation today is that tried and true 20th-century framework of deterrence.\" Cyber-Deterrence by Kim Taipale, Boston Global Forum, December 12, 2016 Raising the Consequences of Hacking American Companies: Why the United States Needs an Explicit Cyber Deterrence Policy for the Private Sector by David A. Simons, CSIS, October 2017 Deterrence and Dissuasion in Cyberspace by Joseph S. Nye Jr., International Security, Vol. 41, No. 3, Winter 2016/2017 Deterring Cyberattacks How to Reduce Vulnerability by Susan Hennessy, Foreign Affairs, November/December 2017 Botched CIA Communications System Helped Blow Cover of Chinese Agents:The number of informants executed in the debacle is higher thaninitially thought. by Zach Dorfman, Foreign Policy, August 15, 2018 Revealed: Pentagon Push to Hack Nuke Missiles Before They Launch: A former U.S. official calls the 2017 Pentagon policy document an 'exercise to legally justify a potential attack on a North Korean missile on the launchpad.' From the article: \"The Pentagon has embraced a controversial policy of destroying enemy nuclear missiles before they launch, an internal policy document from May 2017 shows. Itb bs an effort that appears to include executing cyberattacks against missile control systems or components.\" The Pentagon document Declaratory Policy,Concept of Operations and Employment Guidelines for Left-of-LaunchCapability is cited in the news article. Is Deterrence Possible? by Timothy M. McKenzie, Colonel USAF, Air University, January 2017 Hacking Back Hacking Back Without Cracking Up by Jeremy Rabkin, Ariel Rabkin, Aegis Paper Series No.1606, Hoover Institution, June 28, 2016 The authors examine the risks and rewards of hacking back and conclude that it is worth conducting experiments to determine its effectiveness. It also refers to some interesting sources. The Digital Vigilantes Who Hack Back: American companies that fall victim to data breaches want to retaliate against the culprits. But can they do so without breaking the law? by Nicholas Schmidle, The New Yorker, May 7, 2018 This article provides an excellent introduction to hacking back. It cites CFAA, provides analogies for hacking back such as use of dye packs by banks, and discusses nascent effortsB to legalize some types of hackback, which some call vigilantism. It also highlights the difficulty of attributing hackers, calls attention to \"escalation dominance,\" and notes that hackers do make serious personal threats against those hacking back. Several experts warn that hacking back can be very dangerous and could lead to cyberwar. Assessment of Deterrence Strategies Not The Cyber Deterrence the United States Wants by Jason Healey, Council on Foreign Relations, June 11, 2018 What War Games Tell Us About the Use of Cyber Weapons in a Crisis by Jacquelyn G. Schneider, The Council on Foreign Relations, June 21,2018 The Limits of Deterrence Theory in Cyberspace by Mariarosaria Taddeo, Philos. Technol. (2018) 31: 339. I ... argue that ... applicability [of deterrence] to cyberspace is limited and that these limits are not trivial. Cyber Offense On the Theft and Reuse of Advanced Offensive Cyber Weapons by Gil Baram, Defense One, June 19, 2018 Symantec warns of China-based espionage campaign targeting satellites by Olivia Beavers, The Hill, June 20, 2018 Trump, Seeking to Relax Rules on U.S. Cyberattacks, Reverses Obama Directive: Administration has faced pressure to show that it is taking seriously national-security cyberthreats by Dustin Volz, The Wall Street Journal, August 15, 2018 Legality of Cyber Operations US DoD Laws of War Manual (Updated December 2016) Page 1012 of Chapter XVI applies these laws to Cyber Operations. Section 16.1.2.1 Examples of Cyber Operations on page 1012 refers to the pre-emplacement of capabilities or weapons . Ex-NSA Hackers Worry China And Russia Will Try to Arrest Them: The US government has been indicting foreign government hackers, and American government hackers are worried China and Russia might start doing the same to them. by Lorenzo Franceschi-Bicchierai, Motherboard, December 1, 2017 Guide to Cyberspace Operations The Cyber Security Forum Initiative The Joint Force Commander's Guide to Cyberspace Operations by Brett T. Williams, USAF John Savage", "https://cs.brown.edu/people/jhughes/": "John Hughes Professor of Computer Science Current Activities Research Projects Office Hours For Fall 2012: Mondays, 1:00 - 2:00 PM, and by email appointment Biography, CV, and Contact Courses CS 224 - Interactive Computer Graphics, Spring 2010 CS 16 - Introduction to Algorithms and Data Structures, Spring 2010", "https://cs.brown.edu/people/jrasley/": "Jeff Rasley Email: jeffra / cs brown edu Twitter: @jeffra45 Office: 339 CIT 115 Waterman Street Computer Science Department Brown University Providence, RI 02912 Update 2018-05: I have accepted a Research SDE position at Microsoft. I am a Ph.D. candidate advised by Rodrigo Fonseca , primarily interested in distributed systems, networks, and security. I am supported by the NSF Graduate Research Fellowship Program . I completed my undergrad at the University of Washington where I studied computer science. During my time at UW I primarily worked with Justin Cappos on topics related to sandbox security and API Write-Once-Run-Anywhere verification. I also worked on the GENI supported peer-to-peer testbed called Seattle . More details can be found in my CV . News 2017-08: Our work with MSR on ''application-aware'' resource scheduling in the context of hyperparameter exploration in deep learning systems was accepted to Middleware 2017! 2017-03: I will (again) be spending the summer at Microsoft Research in Redmond working with Yuxiong He , Minjia Zhang , and Wenhan Wang in the Deep Learning Optimizations team continuing our work on ''application-aware'' resource scheduling. 2016-02: I will be spending the summer at Microsoft Research in Redmond working with Yuxiong He , Olatunji Ruwase , and Trishul Chilimbi on topics related to building an ''application-aware'' resource scheduler for distributed deep neural network frameworks. 2016-02: Presenting a poster on queue manangement for cluster schedulers at NSDI '16 . 2016-01: Our work with Microsoft CISL and MSR on queue management for cluster schedulers was accepted to EuroSys 2016! 2015-10: Giving a talk on queue management in cluster schedulers at the 2nd annual New England Networking and Systems Day . 2015-10: Thanks to the generosity of the NSF and SwitchOn I will be attending the SwitchOn Workshop in S\u00e3o Paulo which aims to foster collaborations between the U.S. and Brazil. 2015-09: I was elected as Faculty-Graduate Liaison ( FGL ) in my department! 2015-02: Thanks to ACM SIGCOMM and others for a travel grant to attend the 5th PhD School on Traffic Monitoring and Analysis in Barcelona. 2015-01: I will be spending the summer as a Microsoft Research Intern at the Cloud and Information Services Lab (CISL) in Mountain View, CA. I will be working with Konstantinos Karanasos , Sriram Rao , and Srikanth Kandula on some interesting topics related to scheduling in large shared compute clusters. 2015-02: Thanks to ACM SIGCOMM and others for a travel grant to attend the 5th PhD School on Traffic Monitoring and Analysis in Barcelona. 2015-01: I will be spending the summer as a Microsoft Research Intern at the Cloud and Information Services Lab (CISL) in Mountain View, CA. I will be working with Konstantinos Karanasos , Sriram Rao , and Srikanth Kandula on some interesting topics related to scheduling in large shared compute clusters. 2014-12: As part of CS Education Week , I will be again visiting Nathan Bishop Middle School to help students with an \"Hour of Code\". 2014-11: I will be a graduate TA for Distributed Computer Systems taught by Tom Doeppner and Rodrigo Fonseca in the Spring '15 semester. 2014-11: Giving an invited talk at UBC about our low-latency network monitoring work. Plus attending IMC '14 via a generous travel grant. 2014-10: Presenting a poster on low-latency network monitoring at the first annual New England Networking and Systems Day at the Hariri Institute at Boston University. 2014-04: Our work on low-latency network monitoring will be appearing at SIGCOMM '14! 2014-04: Presenting a poster on low-latency network monitoring at NSDI '14 via a generous travel grant from USENIX. 2014-03: Poster judge at NEUCS '14 . 2014-03: I will be spending the summer at VMware in the NSX (i.e., Nicira) group. 2014-02: I will be presenting our paper \"Low-latency Network Monitoring via Oversubscribed Port Mirroring\" at the Open Networking Summit's Research Track. 2013-12: Visiting Nathan Bishop Middle School to help students with an Hour of Code . 2013-09: Attending IMC '13 via a generous travel grant by the NSF. 2013-06: NSF Graduate Research Fellowship Awardee (2013), Brown blog post 2013-04: Poster judge at NEUCS '13 . Sadly, the event was canceled. 2013-03: I will be at IBM Research in Austin working with Colin Dixon and Eric Rozner this summer. More... Publications, Posters, etc. Accelerating Large Scale Deep Learning Inference through DeepCPU at Microsoft Minjia Zhang, Samyam Rajbandari, Wenhan Wang, Elton Zheng, Olatunji Ruwase, Jeff Rasley, Jason Li, Junhua Wang, and Yuxiong He. To appear at the 2019 USENIX Conference on Operational Machine Learning (OpML '19) . Santa Clara, CA, 2019 HyperDrive: Exploring Hyperparameters with POP Scheduling Jeff Rasley, Yuxiong He, Feng Yan, Olatunji Ruwase, Rodrigo Fonseca. In proceedings of the ACM/IFIP/USENIX Middleware 2017 . Las Vegas, NV, 2017 [ pdf ] Efficient Queue Management for Cluster Scheduling Jeff Rasley, Konstantinos Karanasos, Srikanth Kandula, Rodrigo Fonseca, Milan Vojnovic, Sriram Rao. In proceedings of the 2016 European Conference on Computer Systems ( EuroSys '16 ). London, UK, 2016 [ pdf ] Poster at the 13th USENIX Symposium on Networked Systems Design and Implementation ( NSDI 2016 ). Santa Clara, CA, 2016 Detecting Latent Cross-Platform API Violations Jeff Rasley, Eleni Gessiou, Tony Ohmann, Yuriy Brun, Shriram Krishnamurthi, Justin Cappos. In proceedings of the IEEE International Symposium on Software Reliability Engineering (ISSRE) 2015 [ pdf ] Runtime Verification of Portable Programming Interfaces Jeff Rasley. Undergraduate Honors Thesis . Computer Science and Engineering, University of Washington, June 2011 Crowdsourcing from Scratch: A Pragmatic Experiment in Data Collection by Novice Requesters Alexandra Papoutsaki, Hua Guo, Danae Metaxa-Kakavouli, Connor C. Gramazio, Jeff Rasley, Wenting Xie, Guan Wang, Jeff Huang. In proceedings of the AAAI Conference on Human Computation and Crowdsourcing (HCOMP) 2015. Best Paper Award Runner Up [ site , pdf ] Planck: Millisecond-scale Monitoring and Control for Commodity Networks Jeff Rasley, Brent Stephens, Colin Dixon, Eric Rozner, Wes Felter, Kanak Agarwal, John Carter, Rodrigo Fonseca. In proceedings of the 2014 ACM Conference on SIGCOMM . Chicago, IL, 2014 [ pdf ] [ slides ] Poster at the 11th USENIX Symposium on Networked Systems Design and Implementation ( NSDI 2014 ). Seattle, WA, 2014 [ poster ] Talk at the 2014 Open Networking Summit (Research Track). Santa Clara, CA, March 2014 [ pdf ] [ slides ] Talk at the 2015 Open Networking User Group (Research Track). Columbia University, New York, NY, May 2015 Seattle: The Internet as a Testbed. Jeff Rasley, Monzur Muhammad, Alex Hanson, Sebastian Morgan, Alan Loh, Justin Cappos. Poster at the 8th USENIX Symposium on Networked Systems Design and Implementation ( NSDI 2011 ). Boston, MA, 2011 Retaining Sandbox Containment Despite Bugs in Privileged Memory-Safe Code Justin Cappos, Armon Dadgar, Jeff Rasley, Justin Samuel, Ivan Beschastnikh, Cosmin Barsan, Arvind Krishnamurthy, and Thomas Anderson. The 17th ACM Conference on Computer and Communications Security ( CCS 2010 ). Chicago, IL, 2010 [ pdf ] $(function(){ $('[data-toggle]').on('click', function(){ var id = $(this).data(\"toggle\"), $object = $(id), className = \"open\"; if ($object) { if ($object.hasClass(className)) { $object.removeClass(className) $(this).text(\"More...\"); } else { $object.addClass(className) $(this).text(\"Less...\"); } } });}); var _gaq = _gaq || []; _gaq.push(['_setAccount', 'UA-35512405-1']); _gaq.push(['_trackPageview']); (function() { var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })();", "https://cs.brown.edu/people/jbazik/": "These are for me: Slashdot Debian News Debian Bits Debian Micronews RIPTA #1 Providence Weather This is my home page. I also have a more formal profile page on our website. Long ago I wrote xmx , an X protocol multiplexor. I do lots of Django programming lately. Visit my neighborhood . Test .", "https://cs.brown.edu/people/jsavage/pubs.html": "Department of Computer Science Brown University Recent Research Publications by John E. Savage Derek S. Reverson and John E. Savage, Cybersecurity Convergence: Digital Human and National Security , Orbis, Vol. 64, No. 4, 2020, p. 555-570. Ryan Maness, Derek S. Reveron, John Savage, and Alan Cytryn, Creating a Safe and Prosperous Cyberspace: The Path to Ise-Shima Cybersecurity Norms , The Bridge, August 2, 2017. Allan Cytryn, Nazli Choucri, Michael Dukakis, Ryan C. Maness, Tuan Nguyen, Derek Reveron, John E. Savage and David Silbersweig, Keynote Address for 2016 Cybersecurity Day , Boston Global Forum, December 12, 2016. Allan Cytryn and John E. Savage, Action Plan to Block Cyberattacks in Vietnam , a Report Produced by the Boston Global Forum for the Government of Vietnam, August 2016. Greg Austin, Bruce McConnell, and Jan Neutze with contributions from Shen Yi and John Savage, Promoting International Cyber Norms: A New Advocacy Forum , EastWest Institute, Breakthrough Group Report on Promoting Measures of Restraint in Cyber Armaments, by December 2015. John E. Savage and Bruce McConnell, Exploring Multi-Stakeholder Internet Governance , EastWest Institute, January 20, 2015. Desh Ranjan, John E. Savage, and Mohammad Zubair, Upper and Lower I/O Bounds for Pebbling r-Pyramids , Journal of Discrete Algorithms, Vol. 14, pp. 2-12, 2012. Melissa Hathaway, and John E. Savage, Stewardship of Cyberspace: Duties for Internet Service Providers , CyberDialogue2012, Munk School of Global Affairs, University of Toronto, March 2012. Desh Ranjan, John E. Savage and Mohammad Zubair, Upper and Lower Bounds for Pebbling r Pyramids , Journal of Discrete Algorithms, published online December 7, 2011. Les Bloom and John E. Savage, On Cyber Peace , Issue Brief, Atlantic Council, August 2011. Desh Ranjan, John E. Savage and Mohammad Zubair, Strong I/O Lower Bounds for Binomial and FFT Computation Graph , Procs. COCOON, August 2011. Desh Ranjan, John E. Savage and Mohammad Zubair, Upper and Lower I/O Bounds for Pebbling r-Pyramids , Procs. IWOCA 2010, July 2010 (London). Eric Rachlin and John E. Savage, Stochastic Nanoscale Addressing for Logic , Procs. NANOARCH 2010, June 2010 (Anaheim, CA). John E. Savage and Mohammad Zubair, Cache-Optimal Algorithms for Option Pricing , ACM Transactions on Mathematical Software, Vol. 17, No. 1, pp. 1-30 (2010). John E. Savage and Mohammad Zubair, Evaluating Multicore Algorithms on the Unified Memory Model ), Scientific Programming, Vol. 17, Issue 4, pp. 295-308 (2009). John E. Savage and Mohammad Zubair, A Unified Model for Multicore Architectures, Procs. 1st Int. Forum on Next-Generation Multicore/Manycore Technologies, Nov. 24-25, 2008 (Cairo, Egypt). Eric Rachlin and John E. Savage, Nanowire Addressing with Randomized-Contact Decoders ,Theoretical Computer Science, Vol. 408, Issues 2-3, pp. 241-261, October, 2008. Eric Rachlin and John E. Savage, A Framework for Coded Computation 1 ,Procs. IEEE International Symposium on Information Theory, pp. 2342-2346, July 6-11, 2008. Jennifer Long and John E. Savage, Modeling and Analysis of a Membrane-Based Randomized-Contact Decoder ,Procs. NSTI-Nanotech 2008, Vol. 3, pp. 80-83, June 1-5, 2008. Eric Rachlin and John E. Savage, Analysis of a Mask-Based Decoder ,IEEE Transactions on Computers, February 2008. Eric Rachlin and John E. Savage, Radial Addressing of Nanowires ,ACM J. Emerging Technologies in Computing Systems, Vol. 2, No. 2, pp. 129-154, April 2006. Eric Rachlin and John E. Savage, Nanowire Addressingwith Randomized-Contact Decoders ,Procs. IEEE/ACM Int. Conf. on Computer-Aided Design (ICCAD), 2006. Benjamin Gojman, Eric Rachlin, and John E. Savage, Evaluation of Design Strategies for Stochastically Assembled Nanoarray Memories ,ACM J. on Emerging Technologies in Computing Systems, Vol. 1, No. 2, pp. 73-108, July 2005. Eric Rachlin, John E. Savage, and Benjamin Gojman, Analysis of a Mask-Based Decoder ,Proceedings of the IEEE Computer Society Annl. Symp. on VLSI,A. Smailagic and N. Ranganathan (Eds.), May 11-12, 2005, pp. 6-13. Lee-Ad Gottlieb, John E. Savage, and Arkady Yerukhimovich, Efficient Data Storage in Large Nanoarrays ,Theory of Computing Systems, Vol. 38, pp. 503-536, 2005. Benjamin Gojman, Eric Rachlin, and John E. Savage,\" Decoding of Stochastically Assembled Nanoarrays \"Proceedings of the 2004 Int. Symp. on VLSI,February 19-20, 2004. Andr\u00e9 DeHon describing work with Charles M. Lieber, Patrick Lincoln, and John E. Savage, Sub-lithographic Semiconductor Computing Systems ,HotChips 15 (HotChips-15, August 17--19, 2003). Andr\u00e9 DeHon, Patrick Lincoln, and John E. Savage,\" Stochastic Assembly of Sublithographic Nanoscale Interfaces \" IEEE Transactions in Nanotechnology , Vol. 2, No. 3,pp. 165-174, (2003). P. Fischer, F.P. Preparata, and J.E. Savage, \" Generalized Scans and Solution of Tridiagonal Systems ,\" Theoretical Computer Science, 255, pp. 423-436 (2001) J.E. Savage, A.L. Selman, and C. Smith \" History and Contributions of Theoretical Computer Science ,\" Advances in Computers , Vol. 55, pp. 171-183, (2001). J.G. Castanos and J.E. Savage, \" Repartitioning Unstructured Adaptive Meshes ,\" Procs. 2000 Int. Parallel andDistributed Proc. Symp. (IPDPS'00) , Cancun, Mexico, pp. 823-832, (May 1-5, 2000). J.G. Castanos and J.E. Savage, \" ParallelRefinement of Unstructured Meshes ,\" Procs. IASTEDConference on Paralleland Distributed Computing and Systems (PDCS'99) , Nov. 3-6, 1999. J.G. Castanos and J.E. Savage, \" PARED: aFramework for the Adaptive Solution of PDEs ,\" Procs. Eighth IEEEInt. Symp. High Performance Distributed Computing (HPDC'99), August 3-6,1999. J.G. Castanos and J.E. Savage, \" The DynamicAdaptation of Parallel Mesh-Based Computation ,\" Procs. of the Eighth SIAMConf. on Parallel Processing for Scientific Computation, March 14-17,1997.pp.169-180 (March 1995). J.E. Savage \" Extending the Hong- Kung Model to Memory Hierarchies ,\" in Computing and Combinatorics, e.d. Ding-Zhu Du and Ming Li, pp.270-281, Lecture Notes in Computer Science, Springer Verlag, vol. 959(1995). J.E. Savage, \" A Model for Multi-GrainedParallelism ,\" Procs. 6th Annl. ACM Symp. on Parallel Algorithms andArchitectures, pp. 330-335, Cape May, NJ (June 27-29, 1994). J.E. Savage and M.G. Wloka, Parallelism in Graph Partitioning , Journal of Parallel and Distributed Computing, 13, pp. 257-272 (November 1991). The PARED Distributed FEM System CLICK HERE mpeg_play Professional Reports Authored and Co-Authored by John E. Savage Condon, Edelsbrunner, Emerson, Fortnow, Haber, Karp, Leivant, Lipton, Lynch,Parberry, Papadimitriou, Rabin, Rosenberg, Royer, Savage, Selman, Smith,Tardos, and Vitter, Challenges for Theory ofComputing: Report of an NSF-Sponsored Workshop on Research in TheoreticalComputer Science SIGACT News, June 1999. Condon, Fich, Frederickson, Goldberg, Johnson, Loui, Mahaney, Raghavan,Savage, Selman, and Shmoys, StrategicDirections in Research in Theory of Computing , by Loui et al, ACMComputing Surveys, December 1996. J.E. Savage, Theoretical Computer Science inTransition (PDF) , A Report Prepared for the ACM Strategic Directions Workshop, June 1996. Brown Faculty Bulletin Articles J.E. Savage, The Growth of Brown Since 1955 , Brown Faculty Bulletin , (1996). J.E. Savage, Budgetary Priorities for Brown , Brown Faculty Bulletin ,Volume XII, Number 2, (April 1999). J.E. Savage, The Role of Tenure in Higher Education , Brown Faculty Bulletin , Volume X, Number 2 (May, 1998) J.E. Savage, Strategic Directions Task Force Reports: An Evaluation , Brown Faculty Bulletin , Volume X, Number 1 (November, 1997). John Savage", "https://cs.brown.edu/people/jlaviola/": "Joseph J. LaViola Jr., Ph.D. Although I am still an adjunct faculty at Brown, I am now an Assistant Professor in the School of Electrical Engineering and Computer Science at the University of Central Florida.My current web page can be found HERE . Latest News: 3D User Interfaces: Theory and Practice has been translated into Japanese and Chinese. Written withmy colleagues Doug Bowman (Virginia Tech), Ernst Kruijff (FraunhoferIMK), and Ivan Poupyrev (Sony CSL), it is the first comprehensivetext/reference book on 3D user interfaces. Order your copy from, Amazon , Barnes and Noble , or directly from Addison-Wesley . I am an adjunct assistant professor (Research) in the BrownUniversity Computer Science Department. I work with Andries van Dam , Robert Zeleznik. , and members of the MicrosoftCenter for Research on Pen-Centric Computing . My interests includepen-based computing, user interfaces, human motion estimation, virtualreality, and computer graphics. My Resume My Publications Courses and Projects Predictive Tracking MathPad 2 (My PhD Work) In addition to my academic pursuits, I also started JJL Interface Consultants, Inc. , aconsulting business specializing in a number of user interaction services. Check out pictures of my office mate!! Dinger's Softball Box 1910, Computer Science Department Brown University Providence, RI 02912 401-863-7662 (voice) 401-863-7657 (fax) jjl@cs.brown.edu Finger me.", "https://cs.brown.edu/people/lbsun/deblur2013/deblur2013iccp.html": "Edge-based Blur Kernel Estimation Using Patch Priors Libin Sun 1 Sunghyun Cho 2 Jue Wang 2 James Hays 1 1 Brown University 2 Adobe Research Abstract Blind image deconvolution, i.e., estimating a blur kernelk and a latent image x from an input blurred image y, is aseverely ill-posed problem. In this paper we introduce a newpatch-based strategy for kernel estimation in blind deconvolution.Our approach estimates a \"trusted\" subset of x byimposing a patch prior specifically tailored towards modelingthe appearance of image edge and corner primitives.To choose proper patch priors we examine both statisticalpriors learned from a natural image dataset and a simplepatch prior from synthetic structures. Based on the patchpriors, we iteratively recover the partial latent image x andthe blur kernel k. A comprehensive evaluation shows thatour approach achieves state-of-the-art results for uniformlyblurred images. Paper patchdeblur_iccp2013.pdf , 11MB Supplementary Materials 1. Mathematical Derivations 2. Additional Results Slides SUN_patchdeblur_ICCP2013.zip Citation Libin Sun, Sunghyun Cho, Jue Wang, James Hays. Edge-based Blur Kernel Estimation Using Patch Priors.Proceedings of the IEEE International Conference on Computational Photography (ICCP), 2013. Bibtex @inproceedings{patchdeblur_iccp2013, author = {Libin Sun and Sunghyun Cho and Jue Wang and James Hays}, title = {Edge-based Blur Kernel Estimation Using Patch Priors}, booktitle = {Proc. IEEE International Conference on Computational Photography}, year = {2013}} MatLab Code Available upon request, please contact Libin Sun (lbsun at cs.brown.edu). Test Set our synthetic test set (blurred + 1% noise) [80 images x 8 kernels = 640 images, 240MB] Full Results all results [80 images x 8 kernels x 7 methods, with (cropped) ground truth images and kernels, 1.3GB] All evaluations are done using the center portion of the images, discarding 50 pixels from each border. PSNR, SSIM and error ratios are computed based on best alignment. Note: few of the methods failed to produce output on some of the test images due to their code crashing, hence less than 640 output images are included for these methods. reference images [80 images x 8 kernels = 640 images, 243MB] Deblurred using groundtruth kernels and Zoran's EPLL-GMM [ICCV 2011] for the final non-blind deconvolution step. This is considered the performance upper bound when computing error ratios. Sample Results Quantitative Evaluation Results on test set (32 images) from Levin et al 2011 Results on our test set (640 images) Graphics, Visualization & Interaction Group Comments, questions to Libin Sun .", "https://cs.brown.edu/people/malte/research/pbc/": "Data Privacy by Construction Home Publications Can software offer better data privacy by construction ? Web services that store and process sensitive personal data are critical to the digital economy today, but are often built without sufficient attention to users' rights over their data and its privacy. But doing a good job at data privacy is difficult, and requires substantial manual effort that costs billions of dollars every year. The goal of this research project is to develop new software systems that fundamentally \"democratize\" good privacy practices, make it easy for users and web service operators to handle data in compliance with privacy laws, and retain or improve the performance of today's software. Privacy-Compliant Storage Systems. Easier compliance with privacy laws ( GDPR , CCPA ) using off-the-shelf software. Privacy laws like the European Union's General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) give users new rights to control their data, with non-compliance carrying the risk of steep fines. But with today's systems, compliance with these rights requires onerous manual labor, particularly from small and medium-sized organizations. We are designing new storage and data processing systems that automate compliance with privacy legislation. Realizing this \"compliance by construction\" requires innovation in system design: for example, we are developing a new database architecture that replaces relational tables (which mix different users' data) with per-user micro-databases (\u00b5DBs) as a primary abstraction. Making such a federation of \u00b5DBs efficient requires new techniques to track the impact of changes to users' \u00b5DBs on derived data, and our system relies on dataflow computing , a well-understood technique from scalable big data processing , to make compliant-by-construction web services efficient. Kinan Justus Ishan Aaron Benjamin Raj Artem Leonhard Malte Flexible User Data Control with Edna. New user data control choices via systematic data sealing in web services. Privacy in complex, data-rich applications is hard. Consider a user who wants to remove their account from a service: even once all their data is found, only some of it should be removed; other data should be anonymized or decorrelated (for legal reasons, or to maintain application utility for other users). Or, a user might wish to disavow and anonymize some of their contributions, but retain others. Some of these transformations should also be reversible in case the user wants to return or reassociate with their data. Edna is a library that helps web applictions implement secure data sealing and revealing without breaking application functionality for other users. Edna helps developers generate privacy transformations for database-backed web applications from a high-level specification and preexisting data relationships. Edna helps simplify privacy transformations that applications use today (such as account deletion), but also goes beyond and makes it easier to support fine-grained and nuanced policies that would be cumbersome to implement manually today (e.g., structural decorrelation of data, or \"decay\" of identifying information over time). Lily Hannah Eddie Frans Malte Publications Edna: Disguising and Revealing User Data in Web Applications Lillian Tsai, Hannah Gross, Eddie Kohler, Frans Kaashoek, Malte Schwarzkopf SOSP 2023 K9db: Privacy-Compliant Storage For Web Applications By Construction Kinan Dak Albab, Ishan Sharma, Justus Adam, Benjamin Kilimnik, Aaron Jeyaraj, Raj Paul, Artem Agvanian, Leonhard Spiegelberg, Malte Schwarzkopf OSDI 2023 Retrofitting GDPR Compliance onto Legacy Databases Archita Agarwal, Marilyn George, Aaron Jeyaraj, Malte Schwarzkopf VLDB 2022 Privacy Heroes Need Data Disguises Lilian Tsai, Malte Schwarzkopf, Eddie Kohler HotOS 2021 GDPR Compliance by Constructiono Malte Schwarzkopf, Eddie Kohler, M. Frans Kaashoek, Robert Morris Poly 2019 workshop at VLDB 2019 Getting involved If you're a Brown CS student and excited about this research, consider taking CSCI 2390: Privacy-Conscious Computer Systems . If you're curious about our work, reach out to Malte Schwarzkopf . Support This work is supported by a National Science Foundation (NSF) CAREER award and a Google Research Scholar Award . Back to top \u00a9 Malte Schwarzkopf . \u00b7 Last updated November 09, 2023", "https://cs.brown.edu/people/malte/": "Malte Schwarzkopf Assistant Professor ETOS and Systems Groups Computer Science Department , Brown University malte@cs.brown.edu CIT 525 I'm interested in computer systems, especially distributed systems, operating systems, and privacy-preserving systems. In Spring 2024, I'm teaching CSCI 0300/1310: Fundamentals of Computer Systems . Outside of CS, I enjoy history, woodworking, biking, and art. News 2023/05: The Omega paper wins the Test-of-Time Award at EuroSys 2023 ! 2023/05: Received a Barrett Hazeltine Citation for Excellence in Teaching, Guidance, and Support from Brown's Class of 2023. 2022/04: Received Brown's Henry Merritt Wriston Fellowship for 2022. 2021/04: Received a Google Research Scholar award. 2021/02: Received an NSF CAREER award for my work on privacy-compliance by construction in web applications . Publications [ all ] Edna: Disguising and Revealing User Data in Web Applications [ ACM ] Lillian Tsai, Hannah Gross, Eddie Kohler, Frans Kaashoek, Malte Schwarzkopf SOSP 2023 K9db: Privacy-Compliant Storage For Web Applications By Construction [ usenix ] [ code ] Kinan Dak Albab, Ishan Sharma, Justus Adam, Benjamin Kilimnik, Aaron Jeyaraj, Raj Paul, Artem Agvanian, Leonhard Spiegelberg, Malte Schwarzkopf OSDI 2023 Towards Increased Datacenter Efficiency with Soft Memory [ SIGOPS ] [ ACM ] Megan Frisella, Shirley Loayza Sanchez, Malte Schwarzkopf HotOS 2023 Unleashing True Utility Computing with Quicksand [ SIGOPS ] [ ACM ] Zhenyuan Ruan, Shihang Li, Kaiyan Fan, Marcos K. Aguilera, Adam Belay, Seo Jin Park, Malte Schwarzkopf HotOS 2023 Nu: Achieving Microsecond-Scale Resource Fungibility with Logical Processes [ usenix ] Zhenyuan Ruan, Seo Jin Park, Marcos K. Aguilera, Adam Belay, Malte Schwarzkopf NSDI 2023 Retrofitting GDPR Compliance onto Legacy Databases [ VLDB ] Archita Agarwal, Marilyn George, Aaron Jeyaraj, Malte Schwarzkopf VLDB 2022 Privacy Heroes Need Data Disguises [ SIGOPS ] [ ACM ] Lillian Tsai, Malte Schwarzkopf, Eddie Kohler HotOS 2021 Best presentation runner-up Tuplex: Data Science in Python at Native Code Speed [ ACM ] [ web ] [ code ] Leonhard F. Spiegelberg, Rahul Yesantharao, Malte Schwarzkopf, Tim Kraska SIGMOD 2021 AIFM: High-Performance, Application-Integrated Far Memory [ usenix ] [ code ] Zhenyuan Ruan, Malte Schwarzkopf, Marcos Aguilera, Adam Belay OSDI 2020 Shared Arrangements: practical inter-query sharing for streaming dataflows [ VLDB ] Frank McSherry, Andrea Lattuada, Malte Schwarzkopf, Timothy Roscoe VLDB 2020 GDPR Compliance by Construction Malte Schwarzkopf, Eddie Kohler, M. Frans Kaashoek, Robert Morris Poly 2019 workshop at VLDB 2019 Learning Scheduling Algorithms for Data Processing Clusters [ ACM ] [ arXiv:1810.01963 ] [ website ] Hongzi Mao, Malte Schwarzkopf, Shaileshh Bojja Venkatakrishnan, Zili Meng, Mohammad Alizadeh SIGCOMM 2019 \u2013 (See also our related ICLR'19 paper on reducing variance in training!) Towards Multiverse Databases [ ACM ] Alana Marzoev, Lara Timb\u00f3 Ara\u00fajo, Malte Schwarzkopf, Samyukta Yagati, Eddie Kohler, Robert Morris, M. Frans Kaashoek, Sam Madden HotOS 2019 Conclave: secure multi-party computation on big data [ ACM ] [ extended TR (with proofs) ] [ code ] Nikolaj Volgushev, Malte Schwarzkopf, Ben Getchell, Andrei Lapets, Mayank Varia, Azer Bestavros EuroSys 2019 Noria: dynamic, partially-stateful data-flow for high-performance web applications [ usenix ] [ website ] [ code ] Jon Gjengset, Malte Schwarzkopf, Jonathan Behrens, Lara Timb\u00f3 Ara\u00fajo, Martin Ek, Eddie Kohler, M. Frans Kaashoek, Robert Morris OSDI 2018 Firmament: fast, centralized cluster scheduling at scale [ usenix ] [ web ] [ code ] \u2013 Now available for Kubernetes! Ionel Gog, Malte Schwarzkopf, Adam Gleave, Robert N. M. Watson, Steven Hand OSDI 2016 Queues don't matter when you can JUMP them! [ usenix ] [ website ] Matthew P. Grosvenor, Malte Schwarzkopf, Ionel Gog, Robert N. M. Watson, Andrew W. Moore, Steven Hand, Jon Crowcroft NSDI 2015 Best paper award Musketeer: all for one, one for all in data processing systems [ ACM ] [ website ] [ code ] Ionel Gog, Malte Schwarzkopf, Natacha Crooks, Matthew P. Grosvenor, Allen Clement, Steven Hand EuroSys 2015 Omega: flexible, scalable schedulers for large compute clusters Malte Schwarzkopf, Andy Konwinski, Michael Abd-El-Malek, John Wilkes EuroSys 2013 Best student paper award Test-of-Time Award Ciel : a universal execution engine for distributed data-flow computing Derek G. Murray, Malte Schwarzkopf, Christopher Smowton, Steven Smith, Anil Madhavapeddy, Steven Hand NSDI 2011 Students Justus Adam Howie Chen Kinan Dak Albab Lillian Tsai (at MIT, with Frans Kaashoek, Eddie Kohler) Artem Agvanian Aijah Garcia Megan Frisella Shirley Loayza Sanchez Carolyn Zech Alumni: Livia Zhu (ScB, \u2192 Databricks) Leonhard Spiegelberg (PhD, with Tim Kraska; \u2192 Snowflake) Sreshtaa Rajesh (ScB, \u2192 MIT Lincoln Labs) Raj Paul (ScB, \u2192 Oracle) Vic Li (MSc, \u2192 University of Washington) Benjamin Kilimnik (ScB \u2192 New Relic) Aaron Jeyaraj (ScB \u2192 Crusoe Energy) Hannah Gross (ScB, \u2192 MIT) Benjamin Givertz (ScB, \u2192 Twitch) Ishan Sharma (MSc, \u2192 AWS) Yunzhi Shao (MSc, \u2192 Amazon) Sinan Pehlivanoglu (MSc, \u2192 VMware) Eleonora Kiziv (ScB, \u2192 Google) Jon Gjengset (MIT PhD, \u2192 AWS) Jackie Bredenberg (MIT MEng , \u2192 Ab Initio) Samyukta Yagati (MIT UROP, \u2192 UC Berkeley) Gina Yuan (MIT MEng , \u2192 Stanford) Lara Timb\u00f3 Ara\u00fajo (MIT MEng , \u2192 Airbnb) Courses Spring 2024: CSCI 0300: Fundamentals of Computer Systems Fall 2023: CSCI 2390: Privacy-Conscious Computer Systems Spring 2023: CSCI 0300: Fundamentals of Computer Systems Fall 2022: Junior Faculty Teaching Relief Spring 2022: CSCI 0300: Fundamentals of Computer Systems Fall 2021: CSCI 2390: Privacy-Conscious Computer Systems Spring 2021: CSCI 0300: Fundamentals of Computer Systems Fall 2020: CSCI 2390: Privacy-Conscious Computer Systems Spring 2020: CSCI 1310: Fundamentals of Computer Systems Fall 2019: CSCI 2390: Privacy-Conscious Computer Systems Spring 2018: 6.824: Distributed Systems Engineering (at MIT) Support My research is supported by the NSF , Google , Microsoft , and VMware . Personal Before joining Brown, I was a postdoc in the PDOS group at MIT CSAIL. Prior to MIT, I spent several enjoyable years doing my PhD in the NetOS group in the other Cambridge . You can find me on Twitter and GitHub . My wife, Julia Netter , is a political philosopher.", "https://jeffhuang.com/": "Jeff Huang Brown University home@jeffhuang.com Home Research Students CV HCI@Brown 245 CIT 115 Waterman Street Providence RI 02912 401-863-5808 home@jeffhuang.com Office Hours: Tues 2-3pm Drop in only, no appointments Until May 7 in 2024, except Mar 26 I'm an Associate Professor and Associate Chair of Computer Science at Brown University. My research is in Human-Computer Interaction, where my research is building personalized systems based on user behavior data. These systems are applied to attention, mobile, user experience, and health. I am primarily funded by the NSF, NIH, and ARO, and have received the NSF CAREER award, Facebook Fellowship, and ARO Young Investigator Award. My Ph.D. is in Information Science from the University of Washington in Seattle, and my masters and undergraduate degrees are in Computer Science from the University of Illinois at Urbana-Champaign (UIUC). Before joining Brown, I analyzed search behavior at Microsoft Research, Google, Yahoo, and Bing; and co-founded World Blender, a Techstars-backed startup that made geolocation mobile games. Brown University students interested in joining my group should review our active projects and read about the expectations . Ph.D. applicants please read the Student FAQ . Teaching User Interfaces Fall 2013 , Fall 2014 , Fall 2015 , Fall 2016 , Fall 2017 , Fall 2018 , Fall 2019 , Fall 2020 , Fall 2022 HCI Seminar Spring 2014 , Spring 2015 , Spring 2018 , Spring 2020 , Spring 2023 Livestreaming Reimagined Spring 2021 Computer Science Research Methods Spring 2019 Personal Informatics Seminar Spring 2016 Information Retrieval Fall 2010 (University of Washington) Computer Science Open Data Data analysis about professors, rankings, best papers, and stipends CS Faculty Composition and Hiring Trends [source: Drafty CS Professors ] Bias in Computer Science Rankings [source: CS Open Rankings ] Who Wins CS Best Paper Awards ? [source: Best Paper Awards in Computer Science ] Verified Computer Science Ph.D. Stipends [ contribute ] The Endlessness of Publishing Behind the scenes: the struggle for each paper to get published This page is designed to last , a manifesto for preserving content on the web Illustrative notes for obsessing over publishing aesthetics On Long-Term Self-Tracking My productivity app is a never-ending .txt file The Coronavirus pandemic has changed our sleep behavior Extracting data from tracking devices by going to the cloud Papers from my Research Group Negotiating Dyadic Interactions through the Lens of Augmented Reality Glasses Ji Won Chung, Jenny Fu, Zachary Deocadiz-Smith, Malte Jung, Jeff Huang DIS 2023 filtered.ink: Creating Dynamic Illustrations with SVG Filters Tongyu Zhou, Connie Liu, Joshua Yang, Jeff Huang CHI 2023 [website] \"Together but not together\": Evaluating Typing Indicators for Interaction-Rich Communication Zainab Iftikhar, Yumeng Ma, Jeff Huang CHI 2023 FocalPoint: Adaptive Direct Manipulation for Selecting Small 3D Virtual Objects Jiaju Ma, Jing Qian, Tongyu Zhou, Jeff Huang IMWUT 2023 Bridging the Social Distance: Offline to Online Social Support during the COVID-19 Pandemic Gabriela Hoefer, Talie Massachi, Neil G Xu, Nicole Nugent, Jeff Huang CSCW 2022 The UX Factor: Using Comparative Peer Review to Evaluate Designs through User Preferences Sarah Bawabe, Laura Wilson, Tongyu Zhou, Ezra Marks, Jeff Huang CSCW 2021 (Honorable Mention Award, Impact Recognition Award) [website] Case Studies on the Motivation and Performance of Contributors Who Verify and Maintain In-Flux Tabular Datasets Shaun Wallace, Alexandra Papoutsaki, Neilly H. Tan, Hua Guo, Jeff Huang CSCW 2021 Portalware: Exploring Free-Hand AR Drawing with a Dual-Display Smartphone-Wearable Paradigm Jing Qian, Tongyu Zhou, Meredith Young-Ng, Jiaju Ma, Angel Cheung, Xiangyu Li, Ian Gonsher, Jeff Huang DIS 2021 Self-E: Smartphone-Supported Guidance for Customizable Self-Experimentation Nediyana Daskalova, Eindra Kyi, Kevin Ouyang, Arthur Borem, Sally Chen, Sung Hyun Park, Nicole Nugent, Jeff Huang CHI 2021 [website] Sochiatrist: Signals of Affect in Messaging Data Talie Massachi, Grant Fong, Varun Mathur, Sachin Pendse, Gabriela Hoefer, Jessica Fu, Chong Wang, Nikita Ramoji, Nicole Nugent, Megan Ranney, Daniel Dickstein, Michael Armey, Ellie Pavlick, Jeff Huang CSCW 2020 [website] Sketchy: Drawing Inspiration from the Crowd Shaun Wallace, Brendan Le, Luis Leiva, Aman Haq, Ari Kintisch, Gabrielle Bufrem, Linda Chang, Jeff Huang CSCW 2020 [website] SleepBandits: Guided Flexible Self-Experiments for Sleep Nediyana Daskalova, Jina Yoon, Yibing Wang, Cintia Araujo, Guillermo Beltran, Nicole Nugent, John McGeary, Joseph Jay Williams, Jeff Huang CHI 2020 [website] Portal-ble: Intuitive Free-Hand Manipulation in Unbounded Smartphone-based Augmented Reality Jing Qian, Jiaju Ma, Xiangyu Li, Benjamin Attal, Haoming Lai, James Tompkin, John Hughes, Jeff Huang UIST 2019 [website] Rewind: Automatically Reconstructing Everyday Memories with First-Person Perspectives Neille-Ann Tan, Han Sha, Eda Celen, Phucanh Tran, Kelly Wang, Gifford Cheung, Philip Hinch, Jeff Huang IMWUT 2018 Remotion: A Motion-Based Capture and Replay Platform of Mobile Device Interaction for Remote Usability Testing Jing Qian, Arielle Chapin, Alexandra Papoutsaki, Fumeng Yang, Klaas Nelissen, Jeff Huang IMWUT 2018 [website] The Eye of the Typer: A Benchmark and Analysis of Gaze Behavior during Typing Alexandra Papoutsaki, Aaron Gokaslan, James Tompkin, Yuze He, Jeff Huang ETRA 2018 [website] Lessons Learned from Two Cohorts of Personal Informatics Self-Experiments Nediyana Daskalova, Karthik Desingh, Alexandra Papoutsaki, Diane Schulze, Han Sha, Jeff Huang IMWUT 2017 Drafty: Enlisting Users to be Editors who Maintain Structured Data Shaun Wallace, Lucy van Kleunen, Marianne Aubin-Le Quere, Abraham Peterkin, Yirui Huang, Jeff Huang HCOMP 2017 [website] SearchGazer: Webcam Eye Tracking for Remote Studies of Web Search Alexandra Papoutsaki, James Laskey, Jeff Huang CHIIR 2017 (Best Paper Finalist) [website] Master Maker: Understanding Gaming Skill through Practice and Habit from Gameplay Behavior Jeff Huang, Eddie Yan, Gifford Leung, Nachiappan Nagappan, Thomas Zimmermann topiCS (Topics in Cognitive Science), 9(2), 2017 SleepCoacher: A Personalized Automated Self-Experimentation System for Sleep Recommendations Nediyana Daskalova, Dana\u00eb Metaxa, Adrienne Tran, Nicole Nugent, Julie Boergers, John McGeary, Jeff Huang UIST 2016 [website] WebGazer: Scalable Webcam Eye Tracking Using User Interactions Alexandra Papoutsaki, Patsorn Sangkloy, James Laskey, Nediyana Daskalova, Jeff Huang, James Hays IJCAI 2016 [website] Crowdsourcing from Scratch: A Pragmatic Experiment in Data Collection by Novice Requesters Alexandra Papoutsaki, Hua Guo, Dana\u00eb Metaxa, Connor Gramazio, Jeff Rasley, Wenting Xie, Guan Wang, Jeff Huang HCOMP 2015 (Best Paper Finalist) Masters of Control: Behavioral Patterns of Simultaneous Unit Group Manipulation in StarCraft 2 Eddie Yan, Jeff Huang, Gifford Cheung CHI 2015 Papers Led by Collaborators Epigraphics: Message-Driven Infographics Authoring Tongyu Zhou, Jeff Huang, Gromit Chan CHI 2024 Understanding the Needs of Enterprise Users in Collaborative Python Notebooks Catherine Li, Talie Massachi, Jordan Eschler, Jeff Huang CHI 2023 case study Increased sleep duration and delayed sleep timing during the COVID-19 pandemic Robin K. Yuan, Kirsi-Marja Zitting, Liyaan Maskati, Jeff Huang Scientific Reports, 12(10937), 2022 [website] Personalized Font Recommendations: Combining ML and Typographic Guidelines to Optimize Readability Tianyuan Cai, Shaun Wallace, Tina Rezvanian, Jonathan Dobres, Bernard Kerr, Samuel Berlow, Jeff Huang, Ben D. Sawyer, Zoya Bylinskii DIS 2022 Days with and without self-injurious thoughts and behaviors: Impact of childhood maltreatment on adolescent online social networking Lauren R. Grocott, Anneliese Mair, Janine N. Galione, Michael F. Armey, Jeff Huang, Nicole R. Nugent Journal of Adolescence, 94(5), 2022 Dually Noted: Layout-Aware Annotations with Smartphone Augmented Reality Jing Qian, Qi Sun, Curtis Wigington, Han L. Han, Tong Sun, Jennifer Healey, James Tompkin, Jeff Huang CHI 2022 Towards Individuated Reading Experiences: Different Fonts Increase Reading Speed for Different Individuals Shaun Wallace, Zoya Bylinskii, Jonathan Dobres, Bernard Kerr, Sam Berlow, Rick Treitman, Nirmal Kumawat, Kathleen Arpin, Dave B. Miller, Jeff Huang, Ben D. Sawyer TOCHI (Transactions on Computer-Human Interaction), 29(4), 2022 Scalable Scalable Vector Graphics: Automatic Translation of Interactive SVGs to a Multithread VDOM for Fast Rendering Michail Schwab, David Saffo, Nicholas Bond, Shash Sinha, Cody Dunne, Jeff Huang, James Tompkin, Michelle Borkin TVCG (Transactions on Visualization and Computer Graphics), 28(9), 2022 [website] Evaluating Pan and Zoom Timelines and Sliders Michail Schwab, Sicheng Hao, Olga Vitek, James Tompkin, Jeff Huang, Michelle Borkin CHI 2019 [website] EasyPZ.js: Interaction Binding For Pan and Zoom Visualizations Michail Schwab, James Tompkin, Jeff Huang, Michelle Borkin VIS 2019 short paper [website] Investigating the Effectiveness of Cohort-Based Sleep Recommendations Nediyana Daskalova, Bongshin Lee, Jeff Huang, Chester Ni, Jessica Lundin IMWUT 2018 SEEDE: Simultaneous Execution and Editing in a Development Environment Steven Reiss, Qi Xin, Jeff Huang ASE 2018 An Analysis of Automated Visual Analysis Classification: Interactive Visualization Task Inference of Cancer Genomics Domain Experts Connor Gramazio, Jeff Huang, David Laidlaw TVCG (Transactions on Visualization and Computer Graphics), 24(8), 2017 Strokes of Insight: User Intent Detection and Kinematic Compression of Mouse Cursor Trails Daniel Mart\u00edn-Albo, Luis Leiva, Jeff Huang, R\u00e9jean Plamondond IPM (Information Processing & Management), 52(6), 2016 Learning Behaviors via Human-Delivered Discrete Feedback Robert Loftin, Bei Peng, James MacGlashan, Michael Littman, Matthew Taylor, Jeff Huang, David Roberts JAAMAS (Autonomous Agents and Multi-Agent Systems), 30(1), 2016 Representing Uncertainty in Graph Edges: An Evaluation of Paired Visual Variables Hua Guo, Jeff Huang, David Laidlaw TVCG (Transactions on Visualization and Computer Graphics), 21(10), 2015 Building a Better Mousetrap: Compressing Mouse Cursor Activity for Web Analytics Luis Leiva, Jeff Huang IPM (Information Processing & Management), 51(2), 2015 [website] A Strategy-Aware Technique for Learning Behaviors from Discrete Human Feedback Robert Loftin, James MacGlashan, Bei Peng, Matthew Taylor, Michael Littman, Jeff Huang, David Roberts AAAI 2014 Papers as a Student Mastering the Art of War: How Patterns of Gameplay Influence Skill in Halo Jeff Huang, Thomas Zimmermann, Nachiappan Nagappan, Charles Harrison, Bruce Phillips CHI 2013 (Best Paper Finalist) RevMiner: An Extractive Interface for Navigating Reviews on a Smartphone Jeff Huang, Oren Etzioni, Luke Zettlemoyer, Kevin Clark, Christian Lee UIST 2012 Improving Searcher Models Using Mouse Cursor Activity Jeff Huang, Ryen White, Georg Buscher, Kuansan Wang SIGIR 2012 User See, User Point: Gaze and Cursor Alignment in Web Search Jeff Huang, Ryen White, Georg Buscher CHI 2012 No Search Result Left Behind: Branching Behavior with Browser Tabs Jeff Huang, Thomas Lin, Ryen White WSDM 2012 Large-Scale Analysis of Individual and Task Differences in Search Result Page Examination Strategies Georg Buscher, Ryen White, Susan Dumais, Jeff Huang WSDM 2012 Remix and Play: Lessons from Rule Variants in Texas Hold'em and Halo 2 Gifford Cheung and Jeff Huang CSCW 2012 Interactive Search Support for Difficult Web Queries Abdigani Diriye, Giridhar Kumaran, Jeff Huang ECIR 2012 No Clicks, No Problem: Using Cursor Movements to Understand and Improve Search Jeff Huang, Ryen White, and Susan Dumais CHI 2011 (Best Paper Finalist) Starcraft from the Stands: Understanding the Game Spectator Gifford Cheung and Jeff Huang CHI 2011 Optimal Strategies for Reviewing Search Results Jeff Huang and Anna Kazeykina AAAI 2010 Assessing the Scenic Route: Measuring the Value of Search Trails in Web Logs Ryen White and Jeff Huang SIGIR 2010 (Best Paper Award) Studying Trailfinding Algorithms for Enhanced Web Search Adish Singla, Ryen White, and Jeff Huang SIGIR 2010 Conversational Tagging in Twitter Jeff Huang, Katherine Thornton, and Efthimis Efthimiadis Hypertext 2010 short paper Parallel Browsing Behavior on the Web Jeff Huang and Ryen White Hypertext 2010 short paper Analyzing and Evaluating Query Reformulation Strategies in Web Search Logs Jeff Huang and Efthimis Efthimiadis CIKM 2009 (Best Student Paper Finalist) Graphstract: Minimal Graphical Help for Computers Jeff Huang and Michael Twidale UIST 2007 Curious about the backstory behind my papers ? Workshop Papers Learning Something from Nothing: Leveraging Implicit Human Feedback Strategies Robert Loftin, Bei Peng, James MacGlashan, Michael Littman, Matthew Taylor, Jeff Huang, David Roberts RO-MAN 2014 Influence of Gameplay on Skill in Halo Reach Jeff Huang, Thomas Zimmermann, Nachiappan Nagappan, Charles Harrison, Bruce Phillips CHI Games User Research Workshop 2013 Web User Interaction Mining from Touch-Enabled Mobile Devices Jeff Huang and Abdigani Diriye HCIR Workshop 2012 On the Value of Page-Level Interactions in Web Search Jeff Huang HCIR Workshop 2011", "https://cs.brown.edu/people/meta-ta/": "Meta-TAs The Meta TAs coordinate the UTA Program . A more detailed jobdescription is available here . (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-34495025-1', 'auto'); ga('send', 'pageview');", "https://cs.brown.edu/people/orgs/artemis/2018/index.html": "The Artemis Project Empowering Students of Underrepresented Genders in STEM", "https://cs.brown.edu/people/nmeyrowi/": "Norman K Meyrowitz (Norm, nkm) Adjunct Professor of the Practice of Computer Science Brown University Cell: 415-505-9115 E-mail: nkm@brown.edu Professional Bio Casual Bio I\u2019m originally from Brooklyn (before it was hipster). I graduated from Brown in 1981 with Sc.B. CS. My computer science specialties are Hypertext, Multimedia, and Web Software. I have been fortunate eneough to do both academic research and build commercial software. I ran a research institute at Brown in the 1980s, then went to industry to develop lots of products at Macromedia (now Adobe). My wife \u2014 also a Brown alum \u2014 and I have lived in San Francisco since 1991 (way before it was hipster). I am a foodie, and if the food starts with \"P\" (pastrami, pizza, or porchetta), I am probably either cooking it or eating it. In the distant past I did newspaper writing and design, and in the recent past did architectural plans for friends as a hobby. User's Guide to Norm Back in the late 1980s, I wrote a memo to all of the folks at our research institute outlining the kind of environment I hope we could build. It helped people figure out what makes me tick, but from then to the present, people have circulated it as a more general guide to building and being a part of great organization. It is linked here if it is of interest to you. Curriculum Vitae", "https://faculty.cc.gatech.edu/~hays/": "James Hays Associate Professor, School of Interactive Computing , College of Computing , Georgia Institute of Technology My research interests span computer vision, robotics, and machine learning. I work on problems related to recognition, synthesis, and manipulation.My research often involves finding new data sources to exploit (e.g. geotagged imagery) or creating new data sets where none existed (e.g. sketches or grasps). Before joining Georgia Tech, I was the Manning Assistant Professor of Computer Science at Brown University . I was a postdoc at MIT with Antonio Torralba ,completed my Ph.D. at Carnegie Mellon University with Alexei Efros ,and received my B.S. from Georgia Tech. I am the recipient of the Alfred P. Sloan Fellowship, the NSF CAREER award, and the PAMI Mark Everingham Prize. From 2017 to 2022 I was a Principal Scientist at Argo AI researching self-driving vehicle perception. I am currently working with Overland AI on off-road autonomous vehicles. contact email: hays@gatech.edu office: CODA S1155B mail: 756 West Peachtree st NW, Suite 12E Atlanta, GA 30308 Teaching CS 4476-A: Computer Vision Fall 2023 [previous offering, fall 2022] [previous offering, spring 2022] [previous offering, fall 2021] [previous offering, spring 2021] [previous offering, fall 2018] [previous offering, fall 2017] [previous offering, fall 2016] [previous offering, fall 2015] [previous offering, fall 2013] [previous offering, fall 2011] CS 7476: Advanced Computer Vision Spring 2024 [Previous offering, fall 2020] [Previous offering, spring 2018] [Previous offering, spring 2017] [Previous offering, spring 2016] Similar course, Fall 2014 [Previous offering, spring 2013] [Previous offering, spring 2012] [Previous offering, fall 2010] CS 129: Computational Photography Fall 2012 [Previous offering, spring 2011] [Previous offering, spring 2010] Students and Collaborators Ph.D. Students Benjamin Wilson Akshay Krishnan Mengyu Yang Former Ph.D. Students Cusuh Ham now at Adobe Patrick Grady now at META Amit Raj now at Google Sean Foley now at NASA John Lambert now at Waymo Patsorn Sangkloy now at Phranakhon Rajabhat University Samarth Brahmbhatt now at Overland AI Nam Vo now at Roku Genevieve Patterson Libin \"Geoffrey\" Sun now at Apple Previous Postdoc Pierre-Yves Laffont now at Meta Visiting Students Daniel Brooks (Telecom ParisTech) Tsung-Yi Lin now at Nvidia Huaijin \"George\" Chen now at Vayu Mathias Eitz Master's Student Researchers Akash Kumar, Shenhao Jiang, Kapilan Baskar, Vishwas Uppoor alumni: Nitin Kodialbail, Jianan Gao, Govin Vatsan, Vasavi Gajarla, Laura Jeyaseelen, Varun Agrawal, Nate Burnell, Xiaofeng Tao, Chao Qian, Chen Xu, Yipin Zhou , Hang Su , Vibhu Ramani, Paul Sastrasinh, Vazheh Moussavi, Yun Zhang, David Dufresne, Sirion Vittayakorn Undergraduate Researchers alumni: Wenqi Xian, Cusuh Ham, Lawrence Moore, Sonia Phene, Eric Jang, Hari Narayanan, Sam Birch, Leela Nathan, Eli Bosworth, Jung Uk Kang, Reese Kuppig, Fuyi Huang, Travis Webb Recorded Talks \" Thermal Imaging for Grasp Understanding \" at Machines Can See 2020 . \" Argoverse 2020 Competitions \" at CVPR 2020 Workshop on Autonomous Driving . \" What we learned from Argoverse + 3D for Free \" at ICML 2020 Workshop on AI for Autonomous Driving . Highlighted Recent Papers The Un-Kidnappable Robot: Acoustic Localization of Sneaking People. Mengyu Yang, Patrick Grady, Samarth Brahmbhatt, Arun Balajee Vasudevan, Charles C. Kemp, and James Hays. ICRA 2024. Project page , arXiv ZeroFlow: Fast Zero Label Scene Flow via Distillation. Kyle Vedder, Neehar Peri, Nathaniel Chodosh, Ishan Khatri, Eric Eaton, Dinesh Jayaraman, Yang Liu, Deva Ramanan, and James Hays. ICLR 2024. Project page , arXiv PressureVision++: Estimating Fingertip Pressure from Diverse RGB Images. Patrick Grady, Jeremy A. Collins, Chengcheng Tang, Christopher D. Twigg, Kunal Aneja, James Hays, and Charles C. Kemp. WACV 2024. arXiv , WACV paper Lidar Panoptic Segmentation and Tracking without Bells and Whistles. Abhinav Agarwalla, Xuhua Huang, Jason Ziglar, Francesco Ferroni, Laura Leal-Taixe, James Hays, Aljosa Osep, and Deva Ramanan. IROS 2023. Project page , arXiv Learning Lightweight Object Detectors via Multi-Teacher Progressive Distillation. Shengcao Cao, Mengtian Li, James Hays, Deva Ramanan, Yu-Xiong Wang, and Liangyan Gui. ICML 2023. ICML paper Soft Augmentation for Image Classification. Yang Liu, Shen Yan, Laura Leal-Taixe, James Hays, Deva Ramanan. CVPR 2023. CVF Page Modulating Pretrained Diffusion Models for Multimodal Image Synthesis. Cusuh Ham, James Hays, Jingwan Lu, Krishna Kumar Singh, Zhifei Zhang, Tobias Hinz. Siggraph 2023 Conference. Project Page LANe: Lighting-Aware Neural Fields for Compositional Scene Synthesis. Akshay Krishnan, Amit Raj, Xianling Zhang, Alexandra Carlson, Nathan Tseng, Sandhya Sridhar, Nikita Jaipuria, James Hays. arXiv, April 2023. arXiv Visual Estimation of Fingertip Pressure on Diverse Surfaces using Easily Captured Data. Patrick Grady, Jeremy A. Collins, Chengcheng Tang, Christopher D. Twigg, Kunal Aneja, James Hays, Charles C. Kemp. arXiv, January 2023. arXiv Far3Det: Towards Far-Field 3D Detection. Shubham Gupta, Jeet Kanjani, Mengtian Li, Francesco Ferroni, James Hays, Deva Ramanan, Shu Kong. WACV 2023. CVF page PressureVision: Estimating Hand Pressure from a Single RGB Image. Patrick Grady, Chengcheng Tang, Samarth Brahmbhatt, Christopher D. Twigg, Chengde Wan, James Hays, and Charles C. Kemp. ECCV 2022 Oral. arXiv A Sketch is Worth a Thousand Words: Image Retrieval with Text and Sketch. Patsorn Sangkloy, Wittawat Jitkrittum, Diyi Yang, and James Hays. ECCV 2022. arXiv CoGS: Controllable Generation and Search from Sketch and Style. Cusuh Ham, Gemma Canet Tarres, Tu Bui, James Hays, Zhe Lin, and John Collomosse. ECCV 2022. Project page , arXiv SALVe: Semantic Alignment Verification for Floorplan Reconstruction from Sparse Panoramas. John Lambert, Yuguang Li, Ivaylo Boyadzhiev, Lambert Wixson, Manjunath Narayana, Will Hutchcroft, James Hays, Frank Dellaert, and Sing Bing Kang. ECCV 2022. Argoverse 2: Next Generation Datasets for Self-driving Perception and Forecasting. Benjamin Wilson , William Qi, Tanmay Agarwal, John Lambert, Jagjeet Singh, Siddhesh Khandelwal, Bowen Pan, Ratnesh Kumar, Andrew Hartnett, Jhony Kaesemodel Pontes, Deva Ramanan, Peter Carr, and James Hays NeurIPS Datasets and Benchmarks 2021 Argoverse 2 home page , NeurIPS page Trust, but Verify: Cross-Modality Fusion for HD Map Change Detection. John Lambert and James Hays. NeurIPS Datasets and Benchmarks 2021 Argoverse 2 home page , NeurIPS page ANR: Articulated Neural Rendering for Virtual Avatars. Amit Raj , Julian Tanke, James Hays, Minh Vo, Carsten Stoll, and Christoph Lassner. CVPR 2021. Project page , arXiv PVA: Pixel-aligned Volumetric Avatars. Amit Raj , Michael Zollhoefer, Tomas Simon, Jason Saragih, Shunsuke Saito, James Hays, and Stephen Lombardi. CVPR 2021. Project page , arXiv Scene Flow from Point Clouds with or without Learning. Jhony Kaesemodel Pontes , James Hays, Simon Lucey. 3DV 2020 Oral. Project page , arXiv 3D for Free: Crossmodal Transfer Learning using HD Maps. Benjamin Wilson , Zsolt Kira, and James Hays. arXiv preprint arXiv:2008.10592, August 2020. arXiv Tide: A general toolbox for identifying object detection errors Daniel Bolya, Sean Foley, James Hays, Judy Hoffman. ECCV 2020 spotlight. Project page , arXiv ANR: Articulated Neural Rendering for Virtual Avatars. Amit Raj , Julian Tanke, James Hays, Minh Vo, Carsten Stoll, Christoph Lassner. arXiv preprint arXiv:2012.12890, December 2020. Project page , arXiv Computational discrimination between natural images based on gaze during mental imagery. Xi Wang , Andreas Ley ,Sebastian Koch, James Hays, Kenneth Holmqvist ,and Marc Alexa . Scientific Reports, August 2020. Open Access Article Related earlier conference paper: The Mental Image Revealed by Gaze Tracking. Xi Wang , Andreas Ley ,Sebastian Koch, David Lindlbauer ,James Hays, Kenneth Holmqvist ,and Marc Alexa . CHI 2019. Project Page , ML@GT blog post ContactPose: A Dataset of Grasps with Object Contact and Hand Pose. Samarth Brahmbhatt , Chengcheng Tang, Chris Twigg, Charlie Kemp, and James Hays ECCV 2020. Project page , arXiv MSeg: A Composite Dataset for Multi-domain Semantic Segmentation. John Lambert , Zhuang Liu, Ozan Sener, James Hays, and Vladlen Koltun. CVPR 2020. Project page , Paper ContactGrasp: Functional Multi-finger Grasp Synthesis from Contact Samarth Brahmbhatt , Ankur Handa, James Hays, and Dieter Fox IROS 2019. Project page , arXiv paper Towards Markerless Grasp Capture. Samarth Brahmbhatt, Charlie Kemp, and James Hays. CVPR 2019 CV for AR/VR Workshop. Project page , arXiv Argoverse: 3D Tracking and Forecasting With Rich Maps. Ming-Fang Chang* , John Lambert* , Patsorn Sangkloy* , Jagjeet Singh* , Slawomir Bak , Andrew Hartnett, De Wang, Peter Carr, Simon Lucey , Deva Ramanan , and James Hays. *co-first authors CVPR 2019 oral. Paper , Argoverse project page and data , API code (Github) ContactDB: Analyzing and Predicting Grasp Contact via Thermal Imaging. Samarth Brahmbhatt , Cusuh Ham , Charlie Kemp , and James Hays. CVPR 2019 oral and best paper finalist. Project page , Blog post Composing Text and Image for Image Retrieval - An Empirical Odyssey. Nam Vo , Lu Jiang , Chen Sun , Kevin Murphy , Jia Li , Fei-Fei Li , andJames Hays. CVPR 2019 oral. Paper (arXiv) , Code (Github) Generalization in Metric Learning: Should the Embedding Layer be the Embedding Layer? Nam Vo andJames Hays. WACV 2019 Paper (arXiv) , Code (Github) Revisiting IM2GPS in the Deep Learning Era. Nam Vo , Nathan Jacobs , and James Hays. ICCV 2017. Project Page , Paper (arXiv) Scribbler: Controlling Deep Image Synthesis with Sketch and Color. Patsorn Sangkloy , Jingwan Lu , Chen Fang , Fisher Yu , and James Hays. CVPR 2017. Project Page , Paper (arXiv) , Adobe Max Demo The Sketchy Database: Learning to Retrieve Badly Drawn Bunnies. Patsorn Sangkloy , Nathan Burnell, Cusuh Ham, James Hays. Siggraph 2016. Project Page , Paper Earlier Papers (click to expand) Informative Features for Model Comparison. Wittawat Jitkrittum , Heishiro Kanagawa , Patsorn Sangkloy ,James Hays, Bernhard Sch\u00f6lkopf , and Arthur Gretton . NeurIPS 2018. Paper (arXiv) SwapNet: Garment Transfer in Single View Images Amit Raj , Patsorn Sangkloy , Huiwen Chang,James Hays, Duygu Ceylan , and Jingwan Lu . ECCV 2018. Project page , Paper MapNet: Geometry-Aware Learning of Maps for Camera Localization Samarth Brahmbhatt , Jinwei Gu , Kihwan Kim , James Hays, and Jan Kautz . CVPR 2018. Paper (arXiv) SketchyGAN: Towards Diverse and Realistic Sketch to Image Synthesis. Wengling Chen and James Hays. CVPR 2018. Paper (arXiv) TextureGAN: Controlling Deep Image Synthesis with Texture Patches. Wenqi Xian, Patsorn Sangkloy , Varun Agrawal,Amit Raj, Jingwan Lu , Chen Fang , Fisher Yu , and James Hays. CVPR 2018. Paper (arXiv) On Convergence and Stability of GANs. Naveen Kodali, Jacob Abernethy , James Hays, and Zsolt Kira . arXiv, May 2017. Paper (arXiv) DeepNav: Learning to Navigate Large Cities. Samarth Brahmbhatt , James Hays. CVPR 2017. Paper (arXiv) StuffNet: Using 'Stuff' to Improve Object Detection. Samarth Brahmbhatt , Henrik I. Christensen , James Hays. WACV 2017. Paper (arXiv) Localizing and Orienting Street Views Using Overhead Imagery. Nam Vo , James Hays. ECCV 2016. Project Page , Paper COCO Attributes: Attributes for People, Animals, and Objects. Genevieve Patterson , James Hays. ECCV 2016. Paper WebGazer: Scalable Webcam Eye Tracking Using User Interactions. Alexandra Papoutsaki , Patsorn Sangkloy , James Laskey, Nediyana Daskalova , Jeff Huang , James Hays. IJCAI 2016. Project Page , Paper Learning to Match Aerial Images with Deep Attentive Architectures. Hani Altwaijry , Eduard Trulls, James Hays, Pascal Fua, and Serge Belongie. CVPR 2016. Paper Solving Small-piece Jigsaw Puzzles by Growing Consensus. Kilho Son , Daniel Moreno, James Hays, David B. Cooper. CVPR 2016. Project Page , Paper Tropel: Crowdsourcing Detectors with Minimal Training. Genevieve Patterson, Grant Van Horn, Serge Belongie, Pietro Perona, James Hays HCOMP 2015 Best paper runner-up . Paper Learning Deep Representations for Ground-to-Aerial Geolocalization. Tsung-Yi Lin, Yin Cui, Serge Belongie, and James Hays. CVPR 2015 (Oral). Paper Transient Attributes for High-Level Understanding and Editing of Outdoor Scenes. Pierre-Yves Laffont, Zhile Ren, Xiaofeng Tao, Chao Qian, and James Hays. Siggraph 2014. Project Page , Paper Good Image Priors for Non-blind Deconvoluton: Generic vs Specific. Libin Sun, Sunghyun Cho, Jue Wang, and James Hays. ECCV 2014. Project Page Solving Square Jigsaw Puzzles with Loop Constraints. Kilho Son , James Hays, and David B. Cooper. ECCV 2014. Project Page , Paper Microsoft COCO: Common Objects in Context. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollar, and C. Lawrence Zitnick. ECCV 2014. Project Page , Paper The SUN Attribute Database: Beyond Categories for Deeper Scene Understanding. Genevieve Patterson , Chen Xu, Hang Su, and James Hays. International Journal of Computer Vision. vol. 108:1-2, 2014. Pp 59-81. Project Page , Paper Previously published as: SUN Attribute Database: Discovering, Annotating, and Recognizing Scene Attributes. Genevieve Patterson and James Hays. CVPR 2012. Paper Basic level scene understanding: categories, attributes and structures. Jianxiong Xiao, James Hays, Bryan C. Russell, Genevieve Patterson, Krista A. Ehinger, Antonio Torralba, and Aude Oliva. Frontiers in Psychology, 2013, 4:506. This paper is a survey of recent work related to the SUN database. Paper Cross-View Image Geolocalization. Tsung-Yi Lin, Serge Belongie, and James Hays. CVPR 2013. Paper FrameBreak: Dramatic Image Extrapolation by Guided Shift-Maps. Yinda Zhang, Jianxiong Xiao, James Hays, and Ping Tan. CVPR 2013. Project Page , Paper Edge-based Blur Kernel Estimation Using Patch Priors. Libin \"Geoffrey\" Sun , Sunghyun Cho , Jue Wang , and James Hays. ICCP 2013. Project Page , Paper Dating Historical Color Images. Frank Palermo, James Hays, and Alexei A Efros. ECCV 2012. Project Page , Paper How do humans sketch objects? Mathias Eitz , James Hays, and Marc Alexa . Transactions on Graphics (TOG) - Proceedings of ACM SIGGRAPH 2012. Project Page , Paper Previously presented as: Learning to classify human object sketches Mathias Eitz and James Hays. ACM SIGGRAPH 2011 Talks Program. Super-resolution from Internet-scale Scene Matching. Libin \"Geoffrey\" Sun and James Hays. International Conference on Computational Photography (ICCP) 2012. Project Page , Paper Quality Assessment for Crowdsourced Object Annotations. Sirion Vittayakorn and James Hays. British Machine Vision Conference (BMVC) 2011. Project page , Paper , Bibtex Sun database: Exploring a large collection of scene categories Jianxiong Xiao, Krista Ehinger, James Hays, Aude Oliva, and Antonio Torralba. International Journal of Computer Vision (IJCV) 2014. Project page , Paper , Browse database Previously published as: SUN Database: Large-scale Scene Recognition from Abbey to Zoo Jianxiong Xiao, James Hays, Krista Ehinger, Aude Oliva, and Antonio Torralba. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2010. Paper Scene categorization and detection: the power of global features James Hays, Jianxiong Xiao, Krista Ehinger, Aude Oliva, and Antonio Torralba. Vision Sciences Society annual meeting (VSS) 2010. We present the S cene UN derstanding (SUN) database containing 899 categories and 130,519 images. We use 397 well-sampledcategories to benchmark numerous algorithms for scene recognition. We measure human scene classification performanceon the SUN database and compare this with computational methods. Ph.D. Thesis: Large Scale Scene Matching for Graphics and Vision Thesis Page Our visual experience is extraordinarily varied and complex. The diversity of the visual world makes it difficult for computer vision to understand images and for computer graphics to synthesize visual content. But for all its richness, it turns out that the space of \"scenes\" might not be astronomically large. With access to imagery on an Internet scale, regularities start to emerge - for most images, there exist numerous examples of semantically and structurally similar scenes. Is it possible to sample the space of scenes so densely that one can use similar scenes to \"brute force\" otherwise difficult image understanding and manipulation tasks? This thesis is focused on exploiting and refining large scale scene matching to short circuit the typical computer vision and graphics pipelines for image understanding and manipulation. Image Sequence Geolocation with Human Travel Priors Evangelos Kalogerakis, Olga Vesselova, James Hays, Alexei A. Efros, and Aaron Hertzmann. IEEE International Conference on Computer Vision (ICCV '09) Project Page An empirical study of Context in Object Detection Santosh Divvala, Derek Hoiem, James Hays, Alexei A. Efros, and Martial Hebert. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2009. Project Page , Paper New: Book chapter with expanded geolocalization experiments. Large-Scale Image Geolocalization James Hays and Alexei Efros. Multimodal Location Estimation of Videos and Images. Pages 41-62. 2014. Paper , Bibtex Previously published as: IM2GPS: estimating geographic information from a single image James Hays and Alexei Efros. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2008. Paper . CVPR 2008 Project Page . Google Tech Talk . Abstract :Estimating geographic information from an image is an excellent, difficult high-level computer vision problem whose time has come. The emergence of vast amounts of geographically-calibrated image data is a great reason for computer vision to start looking globally - on the scale of the entire planet! In this paper, we propose a simple algorithm for estimating a distribution over geographic locations from a single image using a purely data-driven scene matching approach. For this task, we will leverage a dataset of over 6 million GPS-tagged images from the Internet. We represent the estimated image location as a probability distribution over the Earth's surface. We quantitatively evaluate our approach in several geolocation tasks and demonstrate encouraging performance (up to 30 times better than chance). We show that geolocation estimates can provide the basis for numerous other image understanding tasks such as population density estimation, land cover estimation or urban/rural classification. Scene Completion Using Millions of Photographs James Hays and Alexei Efros . Transactions on Graphics (SIGGRAPH 2007). August 2007, vol. 26, No. 3. Project Page , SIGGRAPH Paper , CACM Paper , CACM Technical Perspective by Marc Levoy , Bibtex Abstract : What can you do with a million images? In this paper we present a new image completion algorithm powered by a huge database of photographs gathered from the Web. The algorithm patches up holes in images by finding similar image regions in the database that are not only seamless but also semantically valid. Our chief insight is that while the space of images is effectively infinite, the space of semantically differentiable scenes is actually not that large. For many image completion tasks we are able to find similar scenes which contain image fragments that will convincingly complete the image. Our algorithm is entirely data-driven, requiring no annotations or labelling by the user. Unlike existing image completion methods, our algorithm can generate a diverse set of image completions and we allow users to select among them. We demonstrate the superiority of our algorithm over existing image completion approaches. Interactive Tensor Field Design and Visualization on Surfaces Eugene Zhang , James Hays,and Greg Turk . IEEE Transaction on Visualization and Computer Graphics, 2007, Vol 13(1), pp 94-107. Project Page , Paper , Bibtex This research project was primarily Eugene's work and I played only a small role. Image De-fencing Yanxi Liu , Tamara Belkina, James Hays, and Roberto Lublinerman . IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2008. Paper , Bibtex We introduce a novel image segmentation algorithm that uses translational symmetry as the primary foreground/background separation cue. We use texture-based inpainting to recover an un-occluded background. Discovering Texture Regularity as a Higher-Order Correspondence Problem James Hays, Marius Leordeanu , Alexei Efros , and Yanxi Liu . European Conference on Computer Vision (ECCV) 2006. Paper , Bibtex We find arbitrarily distorted regular patterns in real images by treating lattice-finding as a higher-order assignment problem. We leverage previous work from Marius Leordeanu and Martial Hebert to approximate the optimal assignment under second-order constraints. Source code available upon request, although thiscode by Minwoo Park et al. is likely more accurate and faster. Quantitative Evaluation of Near Regular Texture Synthesis Algorithms Steve Lin , James Hays, Chenyu Wu , Vivek Kwatra , and Yanxi Liu IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2006 Paper , Bibtex Quantitative evaluation is difficult for texture synthesis. Ground truth is not well defined. But for certain textures you can objectively decide whether an algorithm has failed or not. Regular and near-regular textures imply a definite structure that should be preserved. We tested several popular algorithms on a large group of structured textures. In addition to the CVPR 2006 paper, a more detailed technical report is available. Near-Regular Texture Database - link Online Database We created a database of regular and near-regular textures for other researchers to use. You can submit your own textures, as well, and help the database grow. Digital Papercutting Yanxi Liu , James Hays, Ying-Qing Xu , and Harry Shum SIGGRAPH 2005 Sketch Sketch , Bibtex Papercutting is a widespread and ancient artform which, as far as we could tell, had no previous computational treatment. We developed algorithms to analyze the symmetry of papercut patterns and produce efficient folding and cutting plans. Near-Regular Texture Analysis and Manipulation Yanxi Liu , Steve Lin , and James Hays.SIGGRAPH 2004 Project page , Paper , Bibtex Abstract: A near-regular texture deviates geometrically and photometrically from a regular congruent tiling. Although near-regular textures are ubiquitous in the man-made and natural world, they present computational challenges for state of the art texture analysis and synthesis algorithms. Using regular tiling as our anchor point, and with user-assisted lattice extraction, we can explicitly model the deformation of a near-regular texture with respect to geometry, lighting and color. We treat a deformation field both as a function that acts on a texture and as a texture that is acted upon, and develop a multi-modal framework where each deformation field is subject to analysis, synthesis and manipulation. Using this formalization, we are able to construct simple parametric models to faithfully synthesize the appearance of a near-regular texture and purposefully control its regularity. Image and Video Based Painterly Animation James Hays and Irfan Essa . NPAR 2004 . Project Page , Paper , Bibtex We extend previous non-photorealistic rendering work to handle video significantly better by temporally constraining brush stroke properties in addition to other improvements. Support My research has been funded by a Sloan Fellowship, NSF Career award (1149853), Sandia National Labs, NSF medium 1563727, IARPA's Finder program (FA8650-12-C-7212), and gifts from Intel, Google, Microsoft, Pixar, Adobe, and Argo AI.", "https://nediyana.github.io/": "0 Nediyana Daskalova About Me Projects Publications Updates About me I am a Research Scientist at Spotify in Boston. Before that, I completed my PhD in Computer Science, at Brown University , where I was fortunate to be advised by Jeff Huang , and I was a part of the Human-Computer Interaction research group . My research interests are in human-computer interaction and personal informatics with a special focus on sleep-tracking and self-experiments. CV LinkedIn Twitter Updates December 2021: Our paper with summer intern Savvas Petridis was accepted to IUI'22 . December 2020: The Self-E paper (the last chapter of my thesis!) was accepted to CHI 2021. July 2020: I started as a Research Scientist at Spotify. May 24, 2020: I graduated from my PhD. April 9, 2020: I defended my thesis! Research Projects Self-E: a self-experimentation app that helps users optimize various aspects of their lives. Website - Android App - iOS App SleepBandits (a.k.a. SleepCoacher 2.0): a self-experimentation app that helps users optimize their sleep. Website - Android App - iOS App Publications Self-E: Smartphone- Supported Guidance for Customizable Self-Experimentation. Nediyana Daskalova , Eindra Kyi*, Kevin Ouyang*, Arthur Borem, Sally Chen, Sung Hyun Park, Nicole Nugent, and Jeff Huang. ACM Conference on Human Factors in Computing Systems ( CHI 2021 ) PDF - Video SleepBandits: Guided Flexible Self-Experiments for Sleep Nediyana Daskalova , Jina Yoon, Lisa Wang, Cintia Araujo, Guillermo Beltran, Nicole Nugent, John McGeary, Joseph Jay Williams, Jeff Huang. ACM Conference on Human Factors in Computing Systems ( CHI 2020 ) PDF - Video Investigating the Effectiveness of Cohort-Based Sleep Recommendations Nediyana Daskalova , Bongshin Lee, Jeff Huang, Chester Ni, Jessica Lundin. ( Ubicomp 2018 ). PDF Cohorts of Self-Experimenters: Lessons Learned from Personal Informatics Self-Experiments Nediyana Daskalova , Karthik Desingh, Alexandra Papoutsaki, Diane Schulze, Heather Sha, and Jeff Huang. ( Ubicomp 2017 ). PDF \"If a person is emailing you, it just doesn't make sense\": Exploring Changing Consumer Behaviors in Email Frank Bentley, Nediyana Daskalova , Nazanin Andalibi. ACM Conference on Human Factors in Computing Systems ( CHI 2017 ). PDF SleepCoacher: A Personalized Automated Self-Experimentation System for Sleep Recommendations Nediyana Daskalova, Danae Metaxa-Kakavouli, Adrinne Tran, Nicole Nugent, Julie Boergers, John McGeary, and Jeff Huang. ACM User Interface Software and Technology Symposium ( UIST 2016 ). PDF - Video - Source Code Webgazer: Scalable webcam eyetracking using user interactions Alexandra Papoutsaki, Patsorn Sangkloy, James Laskey, Nediyana Daskalova , Jeff Huang, and James Hays. In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence ( IJCAI 2016 ). PDF - Website Informing Design of Suggestion and Self-Monitoring Tools through Participatory Experience Prototypes Nediyana Daskalova , Nathalie Ford, Ann Hu, Kyle Moorehead, Ben Wagnon, and Janet Davis. The 9th International Conference on Persuasive Technology ( Persuasive 2014 ). PDF Case Studies and Other Publications HeyPillow: Computationally Guided Sleep Behavior Study Through Sensing Nediyana Daskalova , Jiaju Ma, Tiffany Chen, Valerie Nguon, Jing Qian, Chonghui Chen and Jeff Huang. ACM Conference on Human Factors in Computing Systems ( CHI 2019 ). Workgroup on Interactive Systems in Health (WISH). Poster. Video Personalized Behavior-Powered Systems for Guiding Self-Experiments Nediyana Daskalova . ACM Conference on Human Factors in Computing Systems ( CHI 2018 ). Doctoral Consortium. PDF Comparing the Reliability of Amazon Mechanical Turk and Survey Monkey to Traditional Market Research Surveys Nediyana Daskalova, Brooke White. ACM Conference on Human Factors in Computing Systems ( CHI 2017 ). Case Study. PDF It's All About Coupons: Exploring Coupon Use Behaviors in Email Nediyana Daskalova , Frank Bentley, Nazanin Andalibi. ACM Conference on Human Factors in Computing Systems ( CHI 2017 ). Case Study. PDF Awards and Scholarships ACM-W Scholarship for attending UIST 2016 Best Aging in Place Hack at MIT's Grand Hack 2016 Article CRA-W Grad Cohort Workshop Scholarships 2015, 2016 Dropbox Scholarship for Grace Hopper Celebration of Women in Computing (GHC) 2013", "https://cs.brown.edu/people/joberlin/": "John Oberlin Computer Science PhD Student Brown University CIT 311 oberlin - at - cs - dot - brown - dot - expected domain Introduction I am a graduate student in Computer Science at Brown University. I started herein 2011 after transferring from U Chicago. I joined Stefanie Tellex in the Humans to Robots Laboratory in Fall 2014. My research involves the jointsolution of problems from artificial intelligence, robotics, computer vision,and control systems. My approaches emphasize a combination of theory andengineering. I have been strongly influenced by design patterns and algorithms,and I draw from my background in analysis and physics when appropriate. Before 2011 I worked at Havok in SF for a year and a half, and before that Ispent two years earning an MA in Math at UC Berkeley. My undergraduate degree is from FSU in Mathematics. Interests I am a fan of cats, trees, water, wind, and tea. Papers P. F. Felzenszwalb , J. G. Oberlin Multiscale Fields of Patterns Advances in Neural Information Processing Systems (NIPS). 2014. P. F. Felzenszwalb , J. G. Oberlin Multiscale Fields of Patterns (arXiv:1406.0924) S. Naderi Parizi , J. Oberlin, P. Felzenszwalb Reconfigurable Models for Scene Recognition IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2012 Last edited 6/2/2015.", "https://brown-wics.github.io/website/": "You need to enable JavaScript to run this app.", "https://cs.brown.edu/people/pfelzens/": "Pedro Felipe Felzenszwalb Professor of Engineering and Computer Science Office: Barus & Holley 355 Phone: (401) 863-1531 Email: pff (at) brown.edu Office hours: Thursday 1pm-2pm in B&H 355 CV Research My main research interests are in computer vision, artificial intelligence, machine learning and discrete algorithms. I have worked on a range of different problems within computer vision, including the \u201clow-level\u201d problem of image restoration, the \"mid-level\" problem of image segmentation, and the \u201chigh-level\u201d problem of object recognition. My research involves connections between computer vision and artificial intelligence to a variety of areas including combinatorial optimization, stochastic models, machine learning, and natural language processing. Papers Talk slides Code PhD students and Postdocs 3D printing Teaching Fall 2022: Linear System Analysis (ENGN 1570) Spring 2023: Topics in Optimization (ENGN 2912P) Fall 2023: Linear System Analysis (ENGN 1570) Spring 2024: Pattern Recognition and Machine Learning (ENGN 25220) Person detection in the PASCAL challenge (deformable part model) Curve detection with the min-cover algorithm Random shapes defined by a stochastic context-free grammar Contour completion with belief propagation Mailing address: Box D Brown University 184 Hope St. Providence, RI 02912", "https://cs.brown.edu/people/pfelzens/engn1610/": "ENGN 1610 Image Understanding Instructor Pedro Felzenszwalb Lectures: T/Th 10:30-11:50 PM Barus & Holley 751 Office hours: Monday 2-3 PM Course description Image processing is a technology experiencing explosive growth; it iscentral to medical image analysis and transmission, industrialinspection, image enhancement, indexing into pictorial and videodatabases, e.g., WWW, and to robotic vision, face recognition, andimage compression. This senior-level undergraduate course coverstheoretical underpinnings of this field and includes a series ofpractical MATLAB image processing projects. ENGN 1570 is recommendedbut not required. Topics Image formation Low-level image processing 3D reconstruction Motion estimation Image segmentation Object recognition Reference Computer Vision: Algorithms and Applications. Szeliski. Springer. A draft PDF is available here . Calendar Topic 1: Image Formation Topic 2: Image Filtering and Edge detection Topic 3: Multiview geometry and stereo matching Topic 4: Image Segmentation Topic 5: Graph algorithms Topic 6: Template matching Topic 7: Convolutional Neural Networks Topic 8: Geometric Methods for Recognition Topic 9: Motion and Optical flow Readings Assignments 1) Szeliski chapter 2 2) Edge detection Handout and Additional examples 3) Mean shift and feature space analysis 4) Dynamic Programming and Graph Algorithms 5) Object Detection 6) LeNet paper (pages 1 to 11) 7) AlexNet paper 8) Optical flow review paper 9) Dense Optical flow paper Homework Using images in MATLAB: example.m Assignment 1 and test images Due: Wednesday February 19 Assignment 2 and test images Due: Monday March 9 Assignment 3 and files Due: Monday March 9 Assignment 4 and data Due: Friday May 1", "https://malk.in/": "Publications Courses Join Hello my name is Nathan Malkin I'm an assistant professor in the Department of Informatics at New Jersey Institute of Technology (NJIT) in the New York City metro area. Previously, I received my PhD in computer science from UC Berkeley and was a postdoctoral researcher at the University of Maryland . Email Github LinkedIn I'm looking for students to join my lab! Learn more about the roles I'm recruiting for. Research My field of research is usable security and privacy (also known as human-centered security and privacy). It lies at the intersection of (cyber)security & privacy with human-computer interaction & social computing . My goal is to make technology more private and secure by studying and simplifying people's decisions. I use observations and experiments, as well as surveys and interviews, to understand how human factors contribute to privacy and security problems. I then design systems to overcome these challenges and empirically validate them with user studies and real-world deployments. Currently, I'm working on privacy for the Internet of Things , improving the digital safety of at-risk users , and helping developers create more secure software. Previous work has focused on privacy controls for always-listening devices , including smart speakers and smart TVs . I've also drawn on behavioral economics to help users make security decisions while avoiding cognitive biases . See my publications for more details of my research. Teaching Spring 2024: IS/CS 698 \u2013 Human Factors in Security and Privacy Past: teaching assistant for computer security , CS theory , software engineering Guest lectures: Cornell Tech , Columbia/Barnard Professional service 2024: USENIX Security , PETS 2023: USENIX Security , IEEE Security & Privacy , NDSS , CHI , SecHOPE Special Recognitions for Outstanding Reviews: ACM CHI 2017, 2018, 2021, 2022, 2023, 2024 Please consider submitting your work to these and other usable security venues ! And now for something completely different \u00d7 My email address is: nathan.malkin at njit.edu", "https://cs.brown.edu/people/pkp/": "Phirum Peang Box 1910, Computer Science Department Brown University Providence, RI 02912 401-863-7600 (voice) 401-863-7657 (fax)", "https://cs.brown.edu/people/pklein/": "Home Publications Teaching Philip N. Klein Professor of Computer Science Brown University Box 1910 Providence, RI 02912 email: philip@brown.edu or klein@brown.edu Research Interests Algorithms Data Structures Combinatorial Optimization Approximation Algorithms Graphs planarity.org , a resource page for Optimization Algorithms on Planar Graphs Teaching Recipient of the 2007 Philip J. Bray Award for Excellence in Teaching in the Sciences . Courses originated: TheMatrix in Computer Science Computer Science: An Integrated Introduction I and II (with Leslie P. Kaelbling ) Design and Analysis of Algorithms Topics in Advanced Algorithms Solving Hard Problems in Combinatorial Optimization: Theory and Systems (with Pascal Van Hentenryck ) Secrets and Promises: A Course on Cryptography for Nonmajors Other Courses Taught: IntroductiontoDiscrete Structures and Probability MOOC (massive open online course): Coding the Matrix: Linear Algebra through Computer Science Applications Other Recipient of the NSF Presidential Young Investigator Award (1991) ACM Fellow (2010) Radcliffe Fellow (2015-2016) Program Chair of ACM-SIAM Symposium on Discrete Algorithms (SODA 2017) Creator of Coding the Matrix Author of Coding the Matrix: Linear Algebra through Applications to Computer Science Author of A Cryptography Primer: Secrets and Promises Co-author of Optimization Algorithms for Planar Graphs", "https://cs.brown.edu/people/pw/": "Peter Wegner I am the former editor-in-chief of ComputingSurveys and of The Brown Faculty Bulletin. Some of my current research interests are interaction, compound andactive document systems (such as OpenDoc , JavaBeans and ActiveX ),object oriented programming, and programming languages. Here are some of my papers on Interaction: Date Paper Sep. '95 OOPSLA 95Tutorial Notes: Models and Paradigms of Interaction Apr '96 Coordinationas Constrained Interaction ,LNCS 1061, pp. 28-33, April 1996 May '97 Why InteractionIs More Powerful Than Algorithms , Communications of the ACM. ,May 1997 December '96 InteractiveSoftware Technology , Handbook of Computer Science and Engineering,CRC Press, 1996. May. '97 Frameworksfor Compound Active Documents , work in Progress May. '97 InteractiveFoundations of Computing, Final Draft , Theoretical Computer Science,February 1998 Jan. '98 A ResearchAgenda for Interactive Computing , work in Progress May '98 TowardsEmpirical Computer Science , The Monist, Spring 1999 July '98 Persistenceas a Form of Interaction * , Brown Technical Report CS 98-07, July 1998 January '99 MathematicalModels of Interactive Computing * ,Brown Technical Report CS 99-13 January '99 Interactionas a Framework for Modeling * ,LNCS #1565, April '99 February '99 CoinductiveModels of Finite Computing Agents * ,Electronic Notes in Theoretical Computer Science, March 1999 February '99 InteractiveVisual Programming: Principles and Examples , work in Progress March'99 Modeling,Formalization, and Intuition , Brown Faculty Bulletin, March '99 May '99 Modelsof Interaction , ECOOP '99 Course Notes June '99 Interaction,Computability, and Church's Thesis * ,work in Progress June '99 Draftof ECOOP'99 Banquet Speech , Lisbon, Portugal Aug. '00 An InteractiveViewpoint on the Role of UML * ,Book chapter, published in Unified Modeling Language: Systems Analysis, Design, and Development Issues , Idea Group Publishing, 2001. May. '02 Paraconsistency of Interactive Computation * ,PCL 2002 (Workshop on Paraconsistent ComputationalLogic), Denmark, July 2002 Jun. '02 ComputationBeyond Turing Machines * (RTF), Communications of the ACM , April 2003 Jun. '03 Turing'sIdeas and Models of Computation .Book chapter, in Alan Turing: Life and Legacy of a Great Thinker ,ed. Christof Teuscher,Springer 2004 (co-authored with Eugene Eberbach, Dina Goldin) Jun. '05 The Church-Turing Thesis: Breaking the Myth * (PDF),Presented at CiE 2005, Amsterdam; LNCS 3526, Springer 2005, pp. 152-168 Mar. '06 Principlesof Problem Solving * , Communications of the ACM , July 2006 Sep. '06 InteractiveComputation: the New Paradigm. Published by Springer-Verlag in September2006 (co-edited with Dina Goldin, Scott Smolka) Jan. '08 Refutingthe Strong Church-Turing Thesis: the Interactive Nature of Computing * (PDF),accepted for publication in Minds and Machines . * co-authoredwith Dina Goldin ; here is herlist of paperson interaction . Peter Wegner Box 1910, Computer Science Department Brown University Providence, RI 02912 pw@cs.brown.edu Finger me. 401-863-7600 (voice) 401-863-7657 (fax)", "https://cs.brown.edu/people/sdollins/home.html": "Steven C. Dollins, Ph.D. no longer enslaved in the scrolls I completed my Ph.D. in the Brown Computer Graphics Group in the Computer Science Department at Brown University in May, 2002. I am currently the C.E.O. and portfolio manager for Dollins InvestmentAdvisors, LLC in Fremont, California. I maintain a page of Handy Mathematics Facts for Graphics . My research interests include: Large scale, distributed virtual environments Procedural and multi-resolution modeling, animation, and computing Physical simulation including collision detection and response 3-D user interaction including navigation and object manipulation Game programming Kinetic art Applying object-oriented programming language technology to graphics systems Thesis: On-the-fly Procedurally Generated Interactive Worlds For my thesis, I worked on the authoring and plausible emulation of procedurally generated, multi-resolution geometry and behaviors for large scale, interactive virtual environments (the real goal is to come up with a thesis topic that is buzzword complete). By behaviors , I mean attributes of objects, such as their geometry, color, position, and motion, that change over time and in response to events triggered by time, by other entities in the world, or by the user. Game Programming For the spring of 1996, a group of students in our department created what at Brown is called a GISP, or Group Independent Study Project, on game programming for which I acted as one of the TAs. The course consisted of two parts: (1) a series of research topics presented by the students and followed up with small programming assignments and (2) a final project done as part of a small group. The topics we covered in the initial part of the course were: networking network topologies, UNIX sockets, data synchronization graphics coordinate systems, object geometry representations, DOOM-style texture-mapping simulation physical simulation, numerical methods, collision detection and response artificial intelligence autonomous agents interacting with an environment, state machines, path planning user interfaces defining and limiting user degrees of freedom, presentation of information Academic History I received my Bachelor's degree in Mathematics and Computer Science from the University of Illinois at Urbana-Champaign in May of 1992. While at UIUC, I was the chairperson for the student ACM SIGGRAPH. (I have been a member of the international ACM SIGGRAPH since 1990.) I also worked in the Software Technology Group at the National Center for Supercomputing Applications (NCSA) . They started work on Mosaic, the precursor to both Netscape Navigator and Microsoft's Internet Explorer, just as I left. While at Illinois, I wrote a game called Netspace that became a project of the student SIGGRAPH and which we showed off at UIUC's Engineering Open House in both '91 and '92. Netspace was a networked, multi-player, outer space dogfight game that ran over a network of PCs using TCP/IP. The networking and much of the game play was written by Christopher Wilson and Jon Mittelhauser who worked with me at NCSA. After leaving Illinois, they went on to work on Microsoft's Internet Explorer and Netscape's Navigator, respectively. I graduated from the Mt. Lebanon High School in 1988. Mt. Lebanon is a suburb in the South Hills of Pittsburgh, Pennsylvania (which is at the western end of the state, near Ohio). Family My family tree . Personal Amusements Most of my personal interests are reflected by my rather extensive list of bookmarks , many of which are probably out of date. Contact Information 33400 Turnstone Pl. Fremont, CA 94555 650-773-0725 (cell) Email me at steven [at] dollins . org. My PGP key . 1,742,455,679 10 = steven 36 Steven C. Dollins", "https://cs.brown.edu/people/rfonseca/": "Rodrigo Fonseca Top News Teaching Research Students Publications Service Personal email office 329, CIT Building. Office hours by appointment. mail Box 1910, Brown University 115 Waterman St Providence , RI 02912 phone 401-863-6533 (voice) 401-863-7657 (fax) DBLP \u2022 Google Scholar \u2022 MSFT Academic Search About I am an associate professor at Brown University 's Computer Science Department . My work revolves around distributed systems, networking, and operating systems. Broadly, I am interested in understanding the behavior of systems with many components for enabling new functionality, and making sure they work as they should. In particular, I'm interested in how to build, operate, and diagnose large scale Internet systems; and in networking and power management in embedded distributed systems such as sensor networks. I'm updating this page. Take a look at my CV for the authoritative information. News Feb-2020 I'm starting as a Principal Researcher at Microsoft Research Nov-2019 I'm the General Chair for SoCC'2020! Stay tuned. Nov-2019 Was PC co-chair for HotNets 2019 , with Sylvia Ratnasamy. The workshop was a big success! May-2019 Congratulations to Dr. Da Yu, PhD #5! Going to Microsoft, to work on Azure Networking. May-2019 Congratulations to Dr. Jeff Rasley, PhD #4! Going to Microsoft, to work on AI Infrastructure at Bing. Jan-2019 Going for an 8-month visit to Microsoft Research in Redmond, WA! Oct-2018 New NSF grant: Network-centric IoT Security, with Theo Benson May-2018 Congratulations to Dr. Jonathan Mace , PhD #3! He is starting as a tenure track faculty at MPI-SWS! Oct-2017 Keynote at The 17th International Conference on Runtime Verification, RV\u201917. Seattle, WA Jul-2017 Now Associate Professor with Tenure! Jun-2017 Busy summer: I'll be spending the summer in Palo Alto, with Flowtune . Jeff will be at MSR in Seattle, Da at Alibaba, Seattle, and Jon at Facebook in Cambridge Apr-2017 Congratulations to Dr. Marcelo Martins, PhD #2! Mar-2017 NSDI Test of Time Award for X-Trace! With George Porter, Ion Stoica, Scott Shenker, and Randy Katz! Nov-2016 Switches are Monitors Too! presented at HotNets Oct-2016 Raja presented our paper 'Principled Workflow-centric Tracing of Distributed Systems' at SoCC. Aug-2016 Went to Floripa, Brasil for Sigcomm. We had a paper at the main conference, a paper in the Workshop on QoE, and I gave an invited talk at NetPL. May-2016 cDVD, on fair bandwidth allocation for competing DASH video streams, accepted at Internet-QoE 2016! Apr-2016 2DFQ accepted to Sigcomm 2016, which will be in Brazi! Apr-2016 Teaching Networking in the Fall! Apr-2016 NetEx [pdf] , our architecture for a network marketplace inside of a datacenter, accepted for HotCloud ! Feb-2016 Teaching Distributed Systems with Tom Doeppner Jan-2016 Yak, joint work with my student Jeff Rasley and Microsoft, accepted into Eurosys 2016! Oct-2015 Pivot Tracing gets best paper award at SOSP! Oct-2015 Presented \"We are Tracing like it's 1973\" [ pptx ] at the Open Zipkin workshop in San Francisco Sep-2015 Presented ' We are Losing Tack: a Case for Causal Metadata in Distributed Systems ' at the 16th Asilomar HPTS May-2015 Good Summer looking ahead: Jeff and Jonathan will have internships at Microsoft Research, Da will go to HP Labs May-2015 Jonathan will be presenting our work \"Retro: Targeted Resource Management in Multi-tenant Distributed Systems\" at NSDI 2015 ! This is join work with Peter Bodik and Madan Musuvathi from Microsoft Research. Apr-2015 Our paper \"Simon: Scriptable Interactive Monitoring for SDNs\", accepted at SOSR'15 ! Joint work with Da Yu , Yiming Li, Tim Nelson , and Shriram Krishnamurthi . Apr-2015 Our paper \"Exodus: Toward Automatic Migration of Enterprise Network Configurations to SDNs\" accepted at SOSR'15 ! Joint work with Tim Nelson , Andrew Ferguson, and Shriram Krishnamurthi . Apr-2015 Marcelo 's paper \"Selectively Taming Background Android Apps to Improve Battery Lifetime\" accepted at USENIX ATC, joint work with Justin Cappos . Mar-2015 Won an NSF CAREER Award on \"Understanding the Performance of Distributed Systems Through Causal Tracing\" Feb-2015 Teaching CS-138 Distributed Systems with Tom Doeppner. Oct-2014 Co-organizing the first New England Networking and Systems Day , Oct 24th, at the Hariri Institute at BU. We will gather more than 90 participants with many talks, posters, and much discussion time. Sep-2014 I recently documented (in Portuguese) an attack to a bank website in Brazil that got some media attention Sep-2014 The Brown-Brazil Initiative is hosting my former advisor Prof. Virgilio Almeida for the innaugural talk of the Fall Lecture Series. Sep-2014 Our paper \" Towards General-Purpose Resource Management in Shared Cloud Services \" (with my PhD student Jon Mace , Peter Bodik , and Madan Musuvathi ) was accepted for publication at HotDep'14, the 10th Workshop on Hot Topics in System Dependability! Sep-2014 Teaching Computer Networks this fall! Aug-2014 Jeff Rasley successfully presented \"Planck: Millisecond-scale Monitoring and Control for Commodity Networks\" at Sigcomm 2014. Apr-2014 Our paper \"Planck: Millisecond-scale Monitoring and Control for Commodity Networks\" was accepted for publication at Sigcomm 2014. See you in Chicago! Apr-2014 Very proud of my first minted PhD student, Andrew Ferguson . Congrats, Andrew! Mar-2014 Jeff Rasley will be interning at VMWare, and Marcelo at Intel. Feb-2014 Teaching Advanced Networking as a special topics class, focusing on Datacenter Networking and SDNs. Jan-2014 I'll be part of the Program Committees for Sigcomm 2014 and IMC 2014! Dec-2013 I'm part of the Program Committee for HotMobile 2014! July-2013 NSF NeTS Grant on Participatory Networking, to advance SDNs northbound APIs! July-2013 Our paper \"Growth Analysis of a Large ISP\" was accepted at IMC ! May-2013 Highly successful internship season for students! Andrew is going to the SDN group at Google (with Amin Vahdat), Jeff is going to IBM Research in Austin (with Collin Dixon), Jonathan is going to MSR Redmond (with Peter Bodik)! Apr-2013 We are going to Sigcomm 2013 to present our paper on Participatory Networking ! Congrats to Andrew Ferguson, Arjun Guha, Chen Liang, and Shriram Krishnamurthi! Apr-2013 Chen Liang accepted as a PhD student at Duke University! Congrats, Chen! Jan-2013 Teaching Advanced Networking as a special topics class, focusing on Datacenter Networking and SDNs. Dec-2012 Our paper \"Application Modes\" accepted for publication at HotMobile 2013 ! Sep-2012 Big welcome to Jeff Rasley (new PhD student), Jonathan Mace (new advisee), and Matheus Caldas (visiting PhD student from UFMG, Brazil)! Sep-2012 Teaching CS168, Computer Networks this spring. Jul-2012 Spending the summer at MSR Redmond, with Victor Balh's group Jul-2012 Our paper PARMA: A Parallel Randomized Algorithm for Approximate Association Rule Mining in MapReduce accepted at CIKM 2012! Jun-2012 Program Committee Member for NSDI'13! May-2012 Our paper Hierarchical Policies for Software Defined Networks accepted for publication at the HotSDN 2012 workshop, co-held with Sigcomm 2012! Apr-2012 Nathan's paper C-MR: Continuously Executing MapReduce Workflows on Multi-Core Processors accepted for publication at the MAPREDUCE 2012 workshop! Apr-2012 Andrew presented Jockey: Guaranteed Job Latency in Data Parallel Clusters at Eurosys 2012 . Work with Srikanth Kandula and Peter Bod\u00edk from Microsoft Research. Mar-2012 Our paper Participatory Networking accepted for publication at HotICE'12 , co-held with NSDI'12. Mar-2012 External Review Committee Member for OSDI 2012! Feb-2012 Google funds research on distributed tracing! Sep-2011 Teaching CSCI2950-U in Fall 2011, focusing on Large-scale data intensive computing Jul-2011 I will be co-chairing HotClouds'12 with Dave Maltz, from MSR! May-2011 Solomon Award from Brown University to work on energy managdtent in Wireless Sensor Networks! Sep-2010 NSF funds research on security in Cloud Computing . Jun-2010 Program committee for NSDI'11 ! Jun-2010 Intel funds research on 'Whole-platform Energy Usage of Software Activities' Jun-2010 Andrew's poster on block placdtent in Hadoop accepted at the USENIX ATC May-2010 Teaching CSCI1680 'Computer Networks' in Spring 2011 May-2010 Teaching CSCI2950-U 'Special Topics on Networking and Distributed Systdts' in Fall 2010 Apr-2010 Experiences with X-Trace paper presented on INM/WREN 2010 More... Teaching Fall 2019 CSCI1680 Computer Networks . Previous: F'16 , F'16 , F'16 , F'14 , F'12 , S'12 , S'11 Spring 2018 CSCI1380 Distributed Systems . Previous: S'17 S'15 Spring 2017 Advanced Networking . Previous: S'14 - CSCI2950-U Advanced Networking: SDNs and Datacenter Networking , S'13 , F'11 , F'10 , F'09 Research Projects Participatory Networking The PANE project aims to allow end-user applications to help in the configuration of a network. PANE is both a paradigm and a prototype SDN controller that solves the problem of privilege delegation and conflict resolution when unprivileged users are given read and write access to network services, configuration, and state. Read more... Mobile Device Energy We are interested in improving the battery life of mobile devices. Today's mobile devices' need for energy far surpasses their battery capacity to allow for unrestricted use and long battery life. Users must prioritize their usage to avoid running out of battery. However, for a user to do this efficiently is almost impossible: it requires knowledge of the energy and power characteristics of the applications and of the hardware components of the particular phone. This leads to a poor experience and to frustration. We propose an OS abstraction, Application Modes, that allow applications and the OS to collaborate in exposing to the user only what she cares about and understands: the tradeoff between battery lifetime and functionality. Read our HotMobile paper for an introduction to our approach. Tracing Distributed Systems Distributed systems are growing ever more complex, spanning many layers of abstraction, machines, and administrative domains, and integrating code written, deployed, and operated by different people. In these scenarios it becomes increasingly difficult to understand how a system behaves, and, especially, how and why it fails. Causal tracing is a technique that captures the causality of events across all of these components, layers, and machines, and eases the task of understanding complex distributed systems. There are a multitude of causal tracing systems and frameworks, including many research and industry projects. Examples include our own X-Trace project [ GitHub ], as well as systems such as Google's Dapper, Twitter's Zipkin, and Cloudera's HTrace. We are interested in how to extract information from both complex individual traces and across traces, to identify root causes of problems, detect unexpected anomalies, and make tracing more efficient, by biasing trace sampling and detail capture to maximize trace information on a fixed performance budget. Older Projects Quanto Fine-grained tracking of energy usage in wireless sensor networks, Quanto determines which applications used how much energy on each hardware component, even for applications that span multiple network nodes. Collection Tree Protocol Robust all-to-few routing in wireless sensor networks, CTP is de-facto routing protocol for TinyOS 2.x, and formed the basis for IETF's RPL (Routing over Low Power and lossy networks) - RFC 6550 . Beacon Vector Routing BVR is an anchor-based pseudo-geographical any-to-any routing protocol for wireless sensor networks. Students I am really very fortunate to work with an amazing set of students! Graduate Students Michael Markovitch (PhD) Alumni Linnan Wang PhD 2021. Now at NVidia Nicholas DeMarinis PhD 2021. Now at Brown! Jeff Rasley - PhD 2019. Now at Microsoft. Da Yu - PhD 2019. Now at ByteDance Jonathan Mace - PhD 2018. Now at MPI-SWS Marcelo Martins - PhD 2017 Sofware Analysis and Development for Energy Effciency in Mobile Devices\u201d . Now at Apple. Andrew D. Ferguson - PhD 2014 Policy Delegation and Migration for Software-Defined Networks . Now at Google. Junyang Chen - ScM 2016 George Hongkai Sun - ScM 2016 Wilson Cusack - AB 2016 - Honors Rui Zhou - ScM 2014 Datacenter Network Large Flow Detection and Scheduling from the Edge . Now at Google. Jonathan Leavitt - ScB 2014. Honors Thesis: End-to-End Tracing Models: Analysis and Unification. Now at Google. Matheus Caldas (Visiting PhD from UFMG ) Chen Liang - ScM 2013, now a PhD student at Duke. ScM Project: Software Defined Network Support for Real Distributed Systems Basil Crow - ScM 2012, now at Delphix. Thesis: Time and Energy Profiling in Production Sensor Networks with Quanto Sunil Mallya - ScM 2011, co-founder at Neon Labs , now at Amazon. Thesis: Entracker: Energy Tracker for Homes Jake Eakle (ScM 2011), now at Teespring. Sandy Ryza - ScB 2012, now at Cloudera. Honors Thesis: Solving Hard Problems with Lots of Computers Walter Blaurock - ScB 2011, now at Next Big Sound. Project: Automatic Scaling of Cloud-Based Web Applications Selected Publications All Publications . . , ( ) , pp. , In , pp. , , (Eds.), , , . ISBN: . [ BibTex ] [ pdf ] [ talk ] [ video ] [ doi ] Professional Activities Conference Organization 2015 Co-Organizer, 2nd New England Networking and Systems Day 2014 Co-Organizer, 1st New England Networking and Systems Day Doctoral Symposium, IC2E 2014 2012 Program Co-Chair: HotCloud'12 Technical Program Committee 2016 Eurosys'16, USENIX ATC'16, NSDI'16, SBRC'16 2015 SBRC'15, DCOSS'15, NSDI'15, HotCloud'15, DSN'15 2014 SIGCOMM'14 PC, IMC'14 PC, HotMobile 2014, Eurosys'14 Ext. Review Committee 2013 NSDI'13 PC, TRIOS, SOCC'13 2012 OSDI'12 Ext. Review Committee, Middleware'12, HotDep'12, MAD'12, IGCC'12, DSN'12 2011 NSDI'11, DSN'11, CoNEXT'11, HotPower'11, HotCloud'11, NetDB'11 2010 ... Personal You can find some of my photography as @319studio on Instagram, or at 500px . I almost never tweet as @rodrigo_fonseca . My wife Paula runs an amazing party design business, Festiva Party Design , check it out! Back to top Template and css from Twitter bootstrap. Publications list automatically generated from BibTeX using Exhibit . //create a virtual path for Google Analytics //trackOutgoing is a function that takes a url as a parameter var trackOutgoing = _trackOutgoing('from-index/'); //attach bibtex expansion to the BibTeX links var pubnodes = document.getElementsByClassName(\"publication\"); for (var i = 0; i < pubnodes.length; i++) { attachToggleBehavior(pubnodes[i]); } $(document).ready(function() { $('#older-news').on('show', function () { $('#news-button').button('less') }) $('#older-news').on('hidden', function() { $('#news-button').button('reset') }) });", "https://cs.brown.edu/people/rpatel59/": "About Research+Code Blog About Research+Code Blog About I'm a fourth-year PhD student at Brown University advised by (the incredible) Ellie Pavlick . I also work with Stefanie Tellex , George Konidaris , Michael Littman , and a lot of the other wonderful people at Brown. As an undergrad, I was advised by Ani Nenkova and Byron Wallace in various areas of machine learning and language processing. My research uses language to structure reinforcement learning, aiming towards building more intelligent and interpretable agents that can learn to use language to communicate and coordinate with each other. Language can be a powerful tool to help agents learn and adapt from small amounts of human-intelligible data. I'm specifically interested in (1) using the structure of language to aid reinforcement learning and multi-agent algorithms, (2) allowing language to be used for communication between agents and (3) methods for better interpretability of models that use language to allow safer and more ethical systems. Apart from work, I enjoy reading vast amounts of literature, various kinds of music and mostly just programming for fun. Feel free to reach out with research related questions or otherwise! Email: romapatel@brown.edu Github: roma-patel Office: CIT 527 Appropriate Incongruities in Prototype Theory Research What I\u2019m most interested in is creating frameworks that incorporate language knowledge, RL exploration strategies and human-level inference, to work towards building systems that reason and act at a level that is at par with human intelligence. This includes augmenting existing reinforcement learning algorithms with language supervision, allowing multi-agent algorithms to use and extend to natural language, as well as modeling and probing interactions between agents to better interpret and explain their behaviours. Where I've Been Microsoft Research: Microsoft Turing Academic Program Worked with Dean Carignan, Saurabh Tiwary, Pooya Moradi, Ali Alvi and others at MSR.Summer 2021-current. DeepMind, London: Research Intern (Multi-agent Reinforcement Learning) Worked with Angeliki Lazaridou, Richard Everett, Edward Hughes and Yoram Bachrach. Summer 2020. Google AI, Mountain View: Research Intern (Vision and Language Reinforcement Learning) Worked with Alex Ku and Jason Baldridge. Summer 2019. Johns Hopkins University: Jelinek Summer Workshop on Speech and Language Technology (JSALT) Worked with Ellie Pavlick, Brown University; Sam Bowman, New York University; Tal Linzen, Johns Hopkins University. Summer 2018. Max Planck Institute: Cornell, Maryland, Max Planck Pre-doctoral Research School (CMMRS) Summer 2018. University of Pennsylvania: Undergraduate Researcher Worked with Ani Nenkova, University of Pennsylvania and Byron Wallace, Northeastern University. Summer 2017-18. Princeton University: Program in Algorithmic and Combinatorial Thinking (PACT) Led by Rajiv Gandhi, Rutgers University, Camden. Summer 2016. Tutorials Recognising Multimodal Entailment. Afsaneh Shirazi, Arjun Gopalan, Arsha Nagrani, Cesar Ilharco, Christina Liu, Gabriel Barcik, Jannis Bulian, Jared Frank, Lucas Smaira, Qin Cao, Ricardo Marino, Roma Patel. ACL 2021. Papers 2022 Mapping Language Models to Grounded Conceptual Spaces. Roma Patel and Ellie Pavlick. ICLR 2022. Generalising to New Domains by Mapping Natural Language to Lifted LTL. Eric Hsiung, Hiloni Mehta, Junchi Chu, Xinyu Liu, Roma Patel, Stefanie Tellex, George Konidaris. ICRA 2022. 2021 Does linguistic bias affect generative language models? Roma Patel and Ellie Pavlick. EMNLP 2021. Game-theoretic Vocabulary Selection for Text Classification Tasks Roma Patel, Marta Garnelo, Ian Gemp, Chris Dyer and Yoram Bachrach. NAACL 2021. Affordance-based Robot Object Retrieval Thao Nguyen, Nakul Gopalan, Roma Patel, Ellie Pavlick, Stefanie Tellex. AuRO 2021. 2020 Room-Across-Room: Multilingual Vision-and Language Navigation with Dense Spatiotempral Grounding Alexander Ku*, Peter Anderson*, Roma Patel, Eugene Ie, Jason Baldridge. EMNLP 2020. On the Relationship Between Structure in Natural Language and Models of Sequential Decision Processes Roma Patel*, Rafael Rodriguez-Sanchez*, George Konidaris. LAREL Workshop, ICML 2020. Grounding Language to Non-Markovian Tasks with No Supervision of Task Specifications. Roma Patel, Ellie Pavlick, Stefanie Tellex. RSS 2020. Robot Object Retrieval with Contextual Natural Language Queries. Thao Nguyen, Nakul Gopalan, Roma Patel, Matthew Corsaro, Ellie Pavlick, Stefanie Tellex. RSS 2020. 2019 How to Get Past Sesame Street: Sentence-Level Pretraining Beyond Language Modeling Alex Wang, Jan Hula, Patrick Xia, Raghavendra Pappagari, R. Thomas Mccoy, Roma Patel, Najoung Kim, Ian Tenney, Yinghui Huang, Katherin Yu, Shuning Jin, Berlin Chen, Benjamin Van Durme, Edouard Grave, Ellie Pavlick and Samuel R. Bowman. ACL 2019. PDF Planning with State Abstractions for Non-Markovian Task Specifications Yoonseon Oh, Roma Patel, Thao Nguyen, Baichuan Huang, Ellie Pavlick, Stefanie Tellex. RSS 2019. PDF Learning Visually Grounded Meaning Representations with Sketches Roma Patel, Stephen Bach and Ellie Pavlick. How2 Workshop, ICML 2019. PDF Learning to Ground Language to Temporal Logical Form. Roma Patel, Ellie Pavlick and Stefanie Tellex. SpLU & RoboNLP Workshop, NAACL 2019. PDF Probing What Different NLP Tasks Teach Machines about Function Word Comprehension Najoung Kim, Roma Patel, Adam Poliak, Alex Wang, Patrick Xia, R. Thomas McCoy, Ian Tenney, Alexis Ross, Tal Linzen, Benjamin Van Durme, Samuel R. Bowman, Ellie Pavlick. StarSEM. 2019. (Best Paper Award!) PDF Looking for ELMo's Friends: Sentence-Level Pretraining Beyond Language Modeling. Samuel R. Bowman, Ellie Pavlick, Edouard Grave, Benjamin Van Durme, Alex Wang, Jan Hula, Patrick Xia, Raghavendra Pappagari, R. Thomas McCoy, Roma Patel, Najoung Kim, Ian Tenney, Yinghui Huang, Katherin Yu, Shuning Jin, and Berlin Chen. Unpublished manuscript. 2019. PDF i 2018 Modeling Ambiguity in Text: A Corpus of Legal Literature. Roma Patel and Ani Nenkova. Unpublished manuscript. 2018. PDF A Corpus with Multi-Level Annotations of Patients, Interventions and Outcomes to Support Language Processing for Medical Literature. Benjamin Nye, Jessy Li, Roma Patel, Yinfei Yang, Iain Marshall, Ani Nenkova and Byron Wallace. ACL 2018. PDF Syntactic Patterns Improve Information Extraction for Medical Literature Roma Patel, Yinfei Yang, Iain Marshall, Ani Nenkova and Byron Wallace. NAACL 2018. PDF Lectures and Invited Talks Columbia University, Data Science Institue Title: Learning from Patterns for Information Extraction for Medical Literature Princeton University, PACT Summer Program Title: Network Flows In today's garden path sentences: The prime number few. Powered by w3.css // Used to toggle the menu on small screens when clicking on the menu buttonfunction myFunction() { var x = document.getElementById(\"navDemo\"); if (x.className.indexOf(\"w3-show\") == -1) { x.className += \" w3-show\"; } else { x.className = x.className.replace(\" w3-show\", \"\"); }}", "https://cs.brown.edu/people/sbach/": "Stephen Bach Assistant Professor Computer Science Department Brown University, Providence, RI sbach@cs.brown.edu CIT 335 Home | BATS | Projects | Publications | Teaching | CV My latest research is on improving the processes by which humans teach and instruct computers.That includes engineering training data, with methods like programmatic weak supervision,as well as learning to generalize from fewer examples, with methods like zero-shot andfew-shot learning.Often, our group's methods focus on exploiting high-level, symbolic or otherwise semanticallymeaningful domain knowledge.Lately I'm particularly excited by the ways these directions intersect.Applications of our work include information extraction, image understanding,scientific discovery, and other areas of data science. News Our work on GPT-4 and low-resource languages won the Best Paper Award at the NeurIPS Workshop on Socially Responsible Language Modelling Research (SoLaR) 2023 ! Our paper exploring strategies for using CLIP as a pseudolabeler for prompt tuning will appear at NeurIPS 2023! Our work on integrating large language models into weak supervision is accepted to the ACM/IMS Journal of Data Science! Alfred is accepted to ACL 2023 as a demo ! Alfred is a prototype system for prompted weak supervision. New preprints out on weak supervision in non-stationary environments and assessing the compositional abilities of CLIP . Our paper on learning to compose soft prompts is accepted to ICLR 2023! We show that foundation models like CLIP can be fine-tuned to be better at composing concepts into novel combinations. BATS I lead the BATS machine learning research group. In the tradition of groups like LINQS and DAGS , BATS stands for \"Bach's Awesome Teamof Students.\" Ph.D. Students Reza Esfandiarpoor Yeganeh Kordi Aidan LaBella Nihal Nayak Francisco Piedrahita-Velez (Co-advised with Michael Littman ) Jasper Solt (Co-advised with Jonathan Pober ) Zheng-Xin Yong Peilin Yu Max Zuo (Co-advised with Michael Littman ) Post-Doc Cristina Menghini Master's and Undergrad Students Charlie Duong Sarah Liu Oliver Nan Kevin Scroggins Avi Trost Alumni (Role, Year, Next Position) Andy Delworth (Undergrad, 2023, Hive AI) Chace Hayhurst (Undergrad + Master's, 2023, MIT Lincoln Laboratory) Andrew Yuan (Undergrad, 2023, IMC Trading) Ross Briden (Undergrad, 2022, Affirm) George Hu (Undergrad, 2022, Master's at Stanford) Top Piriyakulkij (Undergrad, 2022, Ph.D. at Cornell) Gaurav Sharma (Master's, 2022, MathWorks) Tom Liu (Undergrad, 2022, Scale AI) Jessica Dai (Undergrad, 2021, Ph.D. at UC Berkeley) Tiffany Ding (Undergrad + Master's, 2021, Ph.D. at UC Berkeley) Amy Pu (Undergrad, 2021, Google) Dylan Sam (Undergrad, 2021, Ph.D. at Carnegie Mellon) Berkan Hiziroglu (Master's, 2020, Amazon) Angie Kim (Undergrad, 2020, The New York Times) Esteban Safranchik (Undergrad, 2020, Ph.D. at U. Washington) Projects T0 is a family of large languagemodels fine-tuned for zero-shot task generalization. In collaboration with manyothers in the BigScienceWorkshop , we showed that by fine-tuning T5 on many variations of prompts forsupervised tasks, the resulting model could generalize to completely new taskslike natural language inference. All the models are publicly available, and T0++ is probably thebest one to use for new tasks. We also built an IDE and repository for promptdevelopment called PromptSource ( ACL demo paper ) that containsover 2,000 prompted tasks. ZSL-KG is a framework for zero-shot learning with common sense knowledge graphs. ZSL-KG learns to identify classes described as nodes in a knowledge graph. We have applied it toboth text and image tasks. ZSL-KG uses a novel graph neural network encoder calledtransformer graph convolutional network (TrGCN). TrGCN increases the expressivityof traditional inductive graph neural networks by using small transformers toaggregate nodes. TAGLETS is a system forautomatic semi-supervised learning with auxiliary data. It automatically exploits all available data, including labeled, unlabeled, and auxiliary data, for a giventask to produce a single classifier. TAGLETS extracts relevant auxiliary data fortraining using SCADs, a database of auxiliary data aligned with concepts inConceptNet, and passes all relevant data to an ensemble of user-specified modules,which are trained and distilled into a final classifier. WISER is a framework for programmatic weak supervision in sequence-tagging domains liked named entityrecognition. Users write tagging rules that tag sequence elementslinking rules that guide how those elements should be grouped into coherentspans. We introduced this approach to avoid the common problem of \"candidategeneration,\" in which users first have to heuristically convert their problemfrom sequence tagging to classification. Now users can supervise the taggingprocess with rules directly! Snorkel is a framework for creating noisytraining labels for machine learning. It uses statistical methods to combine weaksupervision sources like heuristic rules and task-related data sets, i.e., distantsupervision, which are far less expensive to use than hand labeling data. With theresulting estimated labels, users can train many kinds of state-of-the-art models.Snorkel is used at numerous technology companies like Google, research labs, andagencies like the FDA. Probabilistic soft logic is a formalism forbuilding statistical models over relational data like knowledge bases and socialnetworks. PSL programs define hinge-loss MRFs, a type of probabilistic graphicalmodel that admits fast, convex optimization for MAP inference, which makes themvery scalable. Researchers around the world have used PSL for bioinformatics,computational social science, natural language processing, information extraction,and computer vision. Teaching In spring semesters, I teach machine learning (CSCI 1420). In fall semesters, I usually teach a seminar on learning with limited labeled data (CSCI 2952-C). (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-98213367-1', 'auto'); ga('send', 'pageview');", "https://browncsdug.com/": "Skip to content /*! elementor - v3.19.0 - 28-02-2024 */.elementor-heading-title{padding:0;margin:0;line-height:1}.elementor-widget-heading .elementor-heading-title[class*=elementor-size-]>a{color:inherit;font-size:inherit;line-height:inherit}.elementor-widget-heading .elementor-heading-title.elementor-size-small{font-size:15px}.elementor-widget-heading .elementor-heading-title.elementor-size-medium{font-size:19px}.elementor-widget-heading .elementor-heading-title.elementor-size-large{font-size:29px}.elementor-widget-heading .elementor-heading-title.elementor-size-xl{font-size:39px}.elementor-widget-heading .elementor-heading-title.elementor-size-xxl{font-size:59px} BROWN CS DUG /*! elementor - v3.19.0 - 28-02-2024 */.elementor-widget-text-editor.elementor-drop-cap-view-stacked .elementor-drop-cap{background-color:#69727d;color:#fff}.elementor-widget-text-editor.elementor-drop-cap-view-framed .elementor-drop-cap{color:#69727d;border:3px solid;background-color:transparent}.elementor-widget-text-editor:not(.elementor-drop-cap-view-default) .elementor-drop-cap{margin-top:8px}.elementor-widget-text-editor:not(.elementor-drop-cap-view-default) .elementor-drop-cap-letter{width:1em;height:1em}.elementor-widget-text-editor .elementor-drop-cap{float:left;text-align:center;line-height:1;font-size:50px}.elementor-widget-text-editor .elementor-drop-cap-letter{display:inline-block} Empowering Brown undergraduate students in computer science. view our events Join us on Discord Community Connect and network with a community of passionate computer science students at Brown. Academic Programs Access resources and learn more about the academic opportunities you have at Brown and in the CS department. Career Programs Discover professional opportunities and prepare for internships and jobs in computer science. CS DUG Events See below for event announcements and other news from the CS DUG! To be the first to hear about our events, we recommend you join our Discord server. CS Formal 2023 Date: Friday, November 17th Time: 9:00pm \u2013 1:00am Location: Sayles Hall CS Course Fair (Spring 2024) Date: Monday, November 6, 2023 Time: 4:20pm \u2013 5:20pm Location: CIT Third-Floor Atrium CS DUG x AMDUG Careers Panel Date: Sunday, October 15, 2023 Time: 3:30pm \u2013 5:00pm Location: Barus & Holley 168 /*! elementor - v3.19.0 - 28-02-2024 */.elementor-widget-image{text-align:center}.elementor-widget-image a{display:inline-block}.elementor-widget-image a img[src$=\".svg\"]{width:48px}.elementor-widget-image img{vertical-align:middle;display:inline-block} About Us The Computer Science DUG works with the Brown CS department to best support undergraduates concentrating in CS! We are here to help you make the most out of your academics at Brown and achieve all your career goals. Learn more Mission Statement The Brown Computer Science Departmental Undergraduate Group, more fondly called the CS DUG, was created to empower the undergraduate community of Brown\u2019s Computer Science department, increase undergraduate participation, and continue Brown\u2019s legacy of involved undergraduates. Organizing a broad range of activities from social mixers to technical talks, the DUG is always interested in new ideas to foster campus engagement and has historically been involved in many undergraduate computer science events. Activities and Events The DUG organizes a broad range of activities from social mixers to technical talks. The DUG is always interested in new ideas to foster computer science on campus and has historically been involved in many undergraduate computer science events. Let\u2019s talk! Students can contact us with suggestions! Companies can contact us with recruitment opportunities or other offers! Let's talk: [email protected] var NeveProperties = {\"ajaxurl\":\"https:\\/\\/browncsdug.com\\/wp-admin\\/admin-ajax.php\",\"nonce\":\"88fd69b7ac\",\"isRTL\":\"\",\"isCustomize\":\"\",\"infScroll\":\"enabled\",\"maxPages\":\"0\",\"endpoint\":\"https:\\/\\/browncsdug.com\\/wp-json\\/nv\\/v1\\/posts\\/page\\/\",\"query\":\"[]\",\"lang\":\"en_US\"}; var html = document.documentElement;var theme = html.getAttribute('data-neve-theme') || 'light';var variants = {\"logo\":{\"light\":{\"src\":\"https:\\/\\/browncsdug.com\\/wp-content\\/uploads\\/2021\\/10\\/LogoTransparent.png\",\"srcset\":\"https:\\/\\/browncsdug.com\\/wp-content\\/uploads\\/2021\\/10\\/LogoTransparent.png 1894w, https:\\/\\/browncsdug.com\\/wp-content\\/uploads\\/2021\\/10\\/LogoTransparent-300x90.png 300w, https:\\/\\/browncsdug.com\\/wp-content\\/uploads\\/2021\\/10\\/LogoTransparent-1024x309.png 1024w, https:\\/\\/browncsdug.com\\/wp-content\\/uploads\\/2021\\/10\\/LogoTransparent-768x232.png 768w, https:\\/\\/browncsdug.com\\/wp-content\\/uploads\\/2021\\/10\\/LogoTransparent-1536x463.png 1536w\",\"sizes\":\"(max-width: 1894px) 100vw, 1894px\"},\"dark\":{\"src\":\"https:\\/\\/browncsdug.com\\/wp-content\\/uploads\\/2021\\/10\\/LogoTransparent.png\",\"srcset\":\"https:\\/\\/browncsdug.com\\/wp-content\\/uploads\\/2021\\/10\\/LogoTransparent.png 1894w, https:\\/\\/browncsdug.com\\/wp-content\\/uploads\\/2021\\/10\\/LogoTransparent-300x90.png 300w, https:\\/\\/browncsdug.com\\/wp-content\\/uploads\\/2021\\/10\\/LogoTransparent-1024x309.png 1024w, https:\\/\\/browncsdug.com\\/wp-content\\/uploads\\/2021\\/10\\/LogoTransparent-768x232.png 768w, https:\\/\\/browncsdug.com\\/wp-content\\/uploads\\/2021\\/10\\/LogoTransparent-1536x463.png 1536w\",\"sizes\":\"(max-width: 1894px) 100vw, 1894px\"},\"same\":true}};function setCurrentTheme( theme ) {var pictures = document.getElementsByClassName( 'neve-site-logo' );for(var i = 0; i<pictures.length; i++) {var picture = pictures.item(i);if( ! picture ) {continue;};var fileExt = picture.src.slice((Math.max(0, picture.src.lastIndexOf(\".\")) || Infinity) + 1);if ( fileExt === 'svg' ) {picture.removeAttribute('width');picture.removeAttribute('height');picture.style = 'width: var(--maxwidth)';}var compId = picture.getAttribute('data-variant');if ( compId && variants[compId] ) {var isConditional = variants[compId]['same'];if ( theme === 'light' || isConditional || variants[compId]['dark']['src'] === false ) {picture.src = variants[compId]['light']['src'];picture.srcset = variants[compId]['light']['srcset'] || '';picture.sizes = variants[compId]['light']['sizes'];continue;};picture.src = variants[compId]['dark']['src'];picture.srcset = variants[compId]['dark']['srcset'] || '';picture.sizes = variants[compId]['dark']['sizes'];};};};var observer = new MutationObserver(function(mutations) {mutations.forEach(function(mutation) {if (mutation.type == 'attributes') {theme = html.getAttribute('data-neve-theme');setCurrentTheme(theme);};});});observer.observe(html, {attributes: true}); var elementorFrontendConfig = {\"environmentMode\":{\"edit\":false,\"wpPreview\":false,\"isScriptDebug\":false},\"i18n\":{\"shareOnFacebook\":\"Share on Facebook\",\"shareOnTwitter\":\"Share on Twitter\",\"pinIt\":\"Pin it\",\"download\":\"Download\",\"downloadImage\":\"Download image\",\"fullscreen\":\"Fullscreen\",\"zoom\":\"Zoom\",\"share\":\"Share\",\"playVideo\":\"Play Video\",\"previous\":\"Previous\",\"next\":\"Next\",\"close\":\"Close\",\"a11yCarouselWrapperAriaLabel\":\"Carousel | Horizontal scrolling: Arrow Left & Right\",\"a11yCarouselPrevSlideMessage\":\"Previous slide\",\"a11yCarouselNextSlideMessage\":\"Next slide\",\"a11yCarouselFirstSlideMessage\":\"This is the first slide\",\"a11yCarouselLastSlideMessage\":\"This is the last slide\",\"a11yCarouselPaginationBulletMessage\":\"Go to slide\"},\"is_rtl\":false,\"breakpoints\":{\"xs\":0,\"sm\":480,\"md\":768,\"lg\":1025,\"xl\":1440,\"xxl\":1600},\"responsive\":{\"breakpoints\":{\"mobile\":{\"label\":\"Mobile Portrait\",\"value\":767,\"default_value\":767,\"direction\":\"max\",\"is_enabled\":true},\"mobile_extra\":{\"label\":\"Mobile Landscape\",\"value\":880,\"default_value\":880,\"direction\":\"max\",\"is_enabled\":false},\"tablet\":{\"label\":\"Tablet Portrait\",\"value\":1024,\"default_value\":1024,\"direction\":\"max\",\"is_enabled\":true},\"tablet_extra\":{\"label\":\"Tablet Landscape\",\"value\":1200,\"default_value\":1200,\"direction\":\"max\",\"is_enabled\":false},\"laptop\":{\"label\":\"Laptop\",\"value\":1366,\"default_value\":1366,\"direction\":\"max\",\"is_enabled\":false},\"widescreen\":{\"label\":\"Widescreen\",\"value\":2400,\"default_value\":2400,\"direction\":\"min\",\"is_enabled\":false}}},\"version\":\"3.19.4\",\"is_static\":false,\"experimentalFeatures\":{\"e_optimized_assets_loading\":true,\"e_optimized_css_loading\":true,\"additional_custom_breakpoints\":true,\"block_editor_assets_optimize\":true,\"ai-layout\":true,\"landing-pages\":true,\"e_image_loading_optimization\":true,\"e_global_styleguide\":true},\"urls\":{\"assets\":\"https:\\/\\/browncsdug.com\\/wp-content\\/plugins\\/elementor\\/assets\\/\"},\"swiperClass\":\"swiper-container\",\"settings\":{\"page\":[],\"editorPreferences\":[]},\"kit\":{\"active_breakpoints\":[\"viewport_mobile\",\"viewport_tablet\"],\"global_image_lightbox\":\"yes\",\"lightbox_enable_counter\":\"yes\",\"lightbox_enable_fullscreen\":\"yes\",\"lightbox_enable_zoom\":\"yes\",\"lightbox_enable_share\":\"yes\",\"lightbox_title_src\":\"title\",\"lightbox_description_src\":\"description\"},\"post\":{\"id\":85,\"title\":\"Brown%20CS%20DUG%20%C2%BB%20Student%20Information%20Hub%20for%20Computer%20Science\",\"excerpt\":\"\",\"featuredImage\":false}};", "https://cs.brown.edu/people/staff/kkirman/": "Kathy Kirman Billings Project and Financial Manager Office: CIT 572 Phone: 401-863-7627 Email: kathleen_kirman @@ @brown.edu", "https://cs.brown.edu/people/seny/": "Home Papers Talks Lab Blog Seny Kamara Associate Professor, Brown University Lab: Encrypted Systems Lab ( blog) email: seny@brown.edu twitter: @senykam pub key: B80B 84AC 9C5D 174D Overview I am an Associate Professor of Computer Science at Brown University and a Distinguished Scientist at MongoDB where I manage the Advanced CryptographyResearch Group. Before its acquisition by MongoDB, I was co-founder and ChiefScientist at Aroki Systems. Prior to that, I was a research scientist at Microsoft Research . My research is in cryptography and is driven by real-world problems fromprivacy, security and surveillance. I have worked extensively on the design andcryptanalysis of encrypted search algorithms, which are efficient algorithms tosearch on end-to-end encrypted data. I maintain interests in various aspectsof theory and systems, including applied and theoretical cryptography, datastructures and algorithms, databases, networking, game theory and technology policy. I co-direct the Encrypted Systems Lab and amaffiliated with the CAPS group, the Data ScienceInitiative , the Center for Human Rights and HumanitarianStudies and the Policy Lab . If you are interested in working in the Encrypted Systems Lab, please read this before sending me an email. In the Fall, I teach Algorithms for thePeople ( blog ); a course that surveys, critiques andaspires to address the ways in which computer science & technology affectmarginalized communities. News Check out and attend the first Workshop on the Theory and Practice of Encrypted Search (TPES) An article on the Aroki acquisition and MongoDB\u2019s queryable encryption [ Wired , TechCrunch ] I recently did a Q&A with Nature My congressional testimony to the U.S. House Committee on Space, Science and Technology [ written , video ] Our report on End-to-End Encryption and Content Moderation with CDT is available [ blog report ] Check out our collaboration with Brown\u2019s CSREA on Technology and Structural Inequity Our collaboration with Sen. Wyden (D-OR) on an encrypted gun registry appeared at Oakland \u201821 [ paper , Wired , Brown ] I gave a keynote at CRYPTO 2020 on Crypto for the People [ video , slides , Wired , Brown ] Check out our new blog Algorithms for the People on tech & marginalized communities Thank you to Google for the Faculty Research Award! My congressional testimony to the Financial Services Committee of the U.S. House of Representatives [ written , video ] I\u2019m teaching a new course this semester that explores if and how cryptography can help marginalized groups Slides for my encrypted search tutorial @ SAC: intro , leakage attacks , leakage suppression Check out the Brown Center for Human Rights and Humanitarian Studies A few articles about MongoDB\u2019s new Field Level Encryption and how we helped review it [ Wired , Decipher , Brown CS ] Thank you to Mozilla and the Responsible CS challenge for their support! Videos of the ICERM workshop on encrypted search are up! Check out Archita and Tarik\u2019s talks! A discussion with PBS\u2019s White House Chronicle on developments in crypto and CS [ video ] Check out Pixek , our end-to-end encrypted photo app! You can read/hear moreabout it at Wired , BoingBoing , the CBCSpark podcast, Real-WorldCrypto and OURSA You can find our National Academies of Science report on encryption and exceptional access here Advising Postdoc: Tarik Moataz (2016-2019) PhD students: Marilyn George , Victor Youdom Kemmoe , Kweku Kwegyir-Aggrey ,Leah Rosenbloom (co-advised with Anna Lysyanskaya), Lucy Qin , Graduated PhD students: Archita Agarwal , Ghous Amjad , Sam Zhao (co-advised with Stan Zdonik) MSR interns: Sherman Chow , Anurag Khandelwal , Xianrui Meng , Naveed Muhammad , Tarik Moataz , Olya Ohrimenko , Charalampos Papamanthou , Mariana Raykova , Ben Riva , Saeed Sadeghian ,Lei Wei Teaching CS2952-v: Algorithms for the People CS2950-v: Topics in Applied Cryptography: Crypto for Social Good CS16: Introduction to Algorithms and Data Structures Recent Papers ( Full List ) Outside Looking In: Approaches to Content Moderation in End-to-End Encrypted Systems Seny Kamara, Mallory Knodel, Emma Llans\u00f3, Greg Nojeim, Lucy Qin, Dhanaraj Thakur, Caitlin Vogus Report for Center for Democracy and Technology \u201821 (report pdf ) Cryptanalysis of Encrypted Search with LEAKER: A framework for LEakage AttacK Evaluation on Real-world data Seny Kamara, Abdelkarim Kati, Tarik Moataz, Thomas Schneider, Amos Treiber, Michael Yonli IACR ePrint (full pdf , code ) Structured Encryption and Dynamic Leakage Suppression Marilyn George, Seny Kamara, Tarik Moataz Eurocrypt \u201821 (proceedings pdf ) A Decentralized and Encrypted National Gun Registry Seny Kamara, Tarik Moataz, Andrew Park, Lucy Qin IEEE Symposium on Security and Privacy (Oakland) \u201821 (full pdf , Lucy\u2019s talk video , Wired ) Encrypted Databases: From Theory to Practice Zheguang Zhao, Seny Kamara, Tarik Moataz, Stan Zdonik Conference on Innovative Data Systems Research (CIDR) \u201821 (proceedings pdf ) Adversarial Level Agreements for Two-Party Protocols Marilyn George, Seny Kamara IACR ePrint (full pdf ) Encrypted Key Value Stores Archita Agarwal, Seny Kamara Indocrypt \u201820 (proceedings pdf ) Encrypted Blockchain Databases Daniel Adkins, Archita Agarwal, Seny Kamara, Tarik Moataz Advances in Financial Technologies \u201820 (full pdf , blog ) Towards Untrusted Social Video Verification to Combat Deepfakes via Face Geometry Consistency Eleanor Tursman, Marilyn George, Seny Kamara, James Tompkin Media Forensics CVPR Workshop \u201820 (proceedings pdf , Eleanor\u2019s Talk ) An Optimal Relational Database Encryption Scheme Seny Kamara, Tarik Moataz, Stan Zdonik, Zheguang Zhao IACR ePrint (full pdf ) Encrypted Distributed Hash Tables Archita Agarwal, Seny Kamara IACR ePrint (full pdf , blog , Archita\u2019s talk ) Revisiting Leakage-Abuse Attacks Laura Blackstone, Seny Kamara, Tarik Moataz NDSS \u201820 (full pdf ) Computationally Volume-Hiding Structured Encryption Seny Kamara, Tarik Moataz Eurocrypt \u201819 (full pdf ) Forward and Backward Private Searchable Encryption with SGX Ghous Amjad, Seny Kamara, Tarik Moataz Eurosec \u201819 (proceedings pdf ) Encrypted Databases for Differential Privacy Archita Agarwal, Maurice Herlihy, Seny Kamara, Tarik Moataz PETS \u201819 (full pdf ) Breach-Resistant Structured Encryption Ghous Amjad, Seny Kamara, Tarik Moataz PETS \u201819 (full pdf ) SQL on Structurally-Encrypted Databases Seny Kamara, Tarik Moataz Asiacrypt \u201818 (full pdf ) 3rd most influential paper in cryptography from 2018 Structured Encryption and Leakage Suppression Seny Kamara, Tarik Moataz, Olya Ohrimenko CRYPTO \u201818 (proceedings pdf ) National Academies Consensus Report: Decrypting the Encryption Debate . F. Cate (Chair), D. Boneh, F. Chang, S. Charney, S. Goldwasser, D. Hoffman, S. Kamara, D. Kris, S. Landau, S.Lipner, R. Littlehale, K. Martin, H. Rishikof, P. Weinberger. ( report , overview@Lawfare ) Boolean Searchable Symmetric Encryption with Worst-Case Sub-Linear Complexity Seny Kamara, Tarik Moataz Eurocrypt \u201817 (proceedings pdf ) Projects Pixek: an end-to-end encrypted camera app Martin Zhu, Tarik Moataz, Seny Kamara ( overview+app ; Video@RWC18 ; Video@OURSA ; Wired ; CBC Spark ; BoingBoing ) Clusion: an open source encrypted search library Tarik Moataz, Seny Kamara ( overview ; code ) Signal Search Joe Engelman, Sam Zhao, Tarik Moataz, Seny Kamara ( overview ; code ) Essays & Surveys Summer School @ Selected Areas in Cryptography (SAC), 2019 Encrypted Search: Intro and Basics Encrypted Search: Leakage Attacks Encrypted Search: Leakage Suppression How to Search on Encrypted Data [ 1 , 2 , 3 , 4 , 5 ] Is the NSA Metadata Program Legal? Restructuring the NSA Metadata Program ( MIT Tech Review ) Are Compliance and Privacy Always at Odds? ( Lawfare ) How Not to Learn Cryptography", "https://scivis.at/": "Johannes Novotny, PhD. Publications Talks Teaching CV Johannes Novotny Researching Medical Visualization and Deep-Learning at VRVis Follow Vienna, Austria VRVis ResearchGate Github Google Scholar ORCID About - Johannes Novotny I am currently a Senior Research Engineer at the VRVis Zentrum f\u00fcr Virtual Reality und Visualisierung Forschungs-GmbH , one of Austria\u2019s 25 Competence Centers for Excellent Technologies (COMET) . As part of the Biomedical Image Informatics group , I am following my research interests in the improvement of medical image analysis through a fusion of novel rendering styles with machine-learning methods and immersive output devices. I obtained my PhD. degree in David H. Laidlaw\u2019s Visualization Research Lab ( VRL ) at Brown University in 2020, with my work focusing on \u201cUsing Virtual Reality Effectively in Scientific Data Exploration - Perception, Usability and Design in Immersive Displays\u201d. Before my research work at Brown University, I worked as a research scholar at the UC Davis VIDi group to develop remote real-time volume rendering applications. I hold an M.S. degree in visual computing and a BSc. degree in medical computer science from the Vienna University of Technology . Sitemap Follow: GitHub Feed \u00a9 2024 Johannes Novotny. Powered by Jekyll & AcademicPages , a fork of Minimal Mistakes . (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', '', 'auto'); ga('send', 'pageview');", "https://cs.brown.edu/people/staff/pvars/": "Paul D Vars Senior Hardware Technician Phone: 401-863-7625 Email: pvars @@ @cs.brown.edu", "https://cs.brown.edu/people/sk/": "Shriram Krishnamurthi Professor of Computer Science Brown PLT and CS Ed ; Bootstrap Computer Science Department Brown University Contact (with Calendar ) Papers Talks Teaching Service Personal I do not have a research area so much as a research vision : Abstractions are essential for progress in computing. Abstractions can also be hard to understand and learn. But abstraction is also beautiful . How do we help people effectively learn about abstractions? My goal is quite simply to make progress on as many angles as possibleof this vision. My work is informed by my background. I was primarily trained in programming languages , but I have since trained myself in various aspects of software engineering , formal methods , HCI , security , and networking .Over the years I have contributed to several innovative anduseful software systems: JavaScript tools , Flowlog , Racket (formerly DrScheme), WeScheme , Margrave , Flapjax , FrTime , Continue , FASTLINK , (Per)Mission ,and more.Currently, I mainly work on Pyret .For more of what I've been doing lately, please see my research group's blog . Since 2016 [ manifesto ], I have devoted a substantial portion of my time and energy to the hardest problem I've worked on: computing education research . It's the hardest because it requires substantial work on both technical and human-factors fronts; the audience is often unsophisticated and vulnerable; and if you screw up, you can do real damage to not only individuals but also the field and society. The research vision above is the distillation of the direction of my computing education research. I have been doing computing outreach since 1995. You may may know me through my (co-authored) books like HtDP , PLAI ,or DCIC (formerly PAPL ).Our current outreach program, Bootstrap , is usedinternationally to integrate computing into math, physics,social studies, and other disciplines. I have been privileged to work with a group of impressive PhD students: Paul Graunke , Greg Cooper , Jay McCarthy , Danny Yoo , Arjun Guha , Tim Nelson , Joe Politz , Hannah Quay-de la Vallee , Justin Pombrio , and Jack Wrenn ; and currently, Kuang-Chen Lu , Elijah Rivera , and Siddhartha Prasad . I have also been delighted to work with several outstanding post-docs: Serge Egelman , Ben Lerner , Tim Nelson , Tess Strickland , Tristan Dyer , Ben Greenman ; and currently, Will Crichton . Finally, I've equally chuffed to have done research with several excellent master's students and over 50 amazing undergraduates. I'm honored to be a recipient of SIGPLAN's Robin Milner Young Researcher Award , SIGPLAN's Distinguished Educator Award (jointly), SIGSOFT's Influential Educator Award , SIGPLAN's Software Award (jointly), and Brown University's Wriston Fellowship . Disclosure : My work has been supported financially by theUS National Science Foundation,DARPA,Amazon,Bloomberg,Cisco,Code.org,CSNYC,the ESA Foundation,Fujitsu,General Motors,Google,Infosys,Jane Street Capital,Meta,RelationalAI,Roblox,the State of Rhode Island, andTripAdvisor.I believe my views have not beenswayed by this support, but I provide this information so you canjudge for yourself. My names are not spelled Sriram or Shiram or Khrishnamurthi or Krishnamurthy orKrishnamurti (like the philosopher). Find me, o search engine, findme!", "https://www.tamassia.net": "Search this site .rrJNTc{opacity: 0;}.bKy5e{pointer-events: none; position: absolute; top: 0;} Skip to main content Skip to navigation Roberto Tamassia Isabel Cruz DOCS_timing['navv'] = new Date().getTime(); Roberto Tamassia James A. & Julie N. Brown Professor of Computer Science Chair, Department of Computer Science Brown University CV Contact Faculty Affairs Manager: Kate Correia In Memoriam: Isabel Cruz Journal of Graph Algorithms and Applications Copyright 2021-23 Roberto Tamassia. All rights reserved. September 15, 2023 Google Sites Report abuse Page details Page updated Google Sites Report abuse DOCS_timing['cov']=new Date().getTime();", "https://cs.brown.edu/people/staff/jbazik/": "John Bazik Director of Information Technology Office: CIT 573 Phone: 401-863-7624 Email: john_bazik @@ @brown.edu Home Page John has more than thirty years of experience as a software engineer and system administrator. As Director of Information Technology, he leads the Computer Science Department's Technical Staff which maintains the systems and services that support the department's research and educational mission. Vendors : I am not the droid you are looking for. For Brown campus-wide IT, visit https://it.brown.edu/about/leadership .", "http://jrenzhile.com": "Zhile Ren Email: jrenzhile -at- gmail.com I work at Apple on hardware-aware efficient-ML frameworks, as well as 3D vision applications. Before that, I worked at Georgia Tech as a Postdoc with Dhruv Batra , Devi Parikh , and Irfan Essa . I got my PhD in Brown University working with Erik Sudderth in the computer science department. I did my undergrad in statistics at Zhejiang University . Google Scholar | LinkedIn | Curriculum Vitae (in PDF) Research Projects UPSCALE: Unconstrained Channel Pruning Alvin Wan, Hanxiang Hao, Kaushik Patnaik, Sam Xu, Omer Hadad, David G\u00fcera, Zhile Ren , Qi Shan International Conference on Machine Learning (ICML 2023) Paper Code AutoFocusFormer: Image Segmentation off the Grid Chen Ziwen, Kaushik Patnaik, Shuangfei Zhai, Alvin Wan, Zhile Ren , Alexander G. Schwing, Alex Colburn, Li Fuxin IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2023) Paper Code Generative Multiplane Images: Making a 2D GAN 3D-Aware Xiaoming Zhao, Fangchang Ma, David G\u00fcera, Zhile Ren , Alexander G. Schwing, Alex Colburn European Conference on Computer Vision (ECCV 2022 oral presentation) Paper Project Page FvOR: Robust Joint Shape and Pose Optimization for Few-view Object Reconstruction Zhenpei Yang, Zhile Ren , Miguel Angel Bautista, Zaiwei Zhang, Qi Shan, Qixing Huang IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022) Paper Code MVS2D: Efficient Multi-view Stereo via Attention-Driven 2D Convolutions Zhenpei Yang, Zhile Ren , Qi Shan, Qixing Huang IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022) Paper Project Page Semantic MapNet: Building Allocentric Semantic Maps and Representations from Egocentric Views Vincent Cartillier, Zhile Ren , Neha Jain, Stefan Lee, Irfan Essa, Dhruv Batra AAAI Conference on Artificial Intelligence (AAAI 2021) Media coverage: Venture Beat , MIT Technology Review , Digital Trends , ZDNet Paper Project Page Clouds of Oriented Gradients for 3D Detection of Objects, Surfaces, and Indoor Scene Layouts Zhile Ren , Erik Sudderth IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI 2020) Paper Cross-Channel Communication Networks Jianwei Yang, Zhile Ren , Chuang Gan, Hongyuan Zhu, Devi Parikh Neural Information Processing Systems (NeurIPS 2019) Paper Poster Code Embodied Amodal Recognition: Learning to Move to Perceive Objects Jianwei Yang*, Zhile Ren* , Mingze Xu, Xinlei Chen, David Crandall, Devi Parikh, Dhruv Batra ( Equal Contribution* ) IEEE International Conference on Computer Vision (ICCV 2019) Paper ML@GT Blog 3D Scene Reconstruction with Multi-layer Depth and Epipolar Transformers Daeyun Shin, Zhile Ren , Erik Sudderth, Charless Fowlkes IEEE International Conference on Computer Vision (ICCV 2019) Paper Supplementary Video Project Page A Fusion Approach for Multi-Frame Optical Flow Estimation Zhile Ren , Orazio Gallo, Deqing Sun, Ming-Hsuan Yang, Jan Kautz, Erik Sudderth IEEE Winter Conference on Applications of Computer Vision (WACV 2019) Nov 2019: MFF consistently ranks top-2 among published flow methods in KITTI and MPI Sintel Paper Project Page Supplementary Video 3D Object Detection with Latent Support Surfaces Zhile Ren , Erik Sudderth IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2018) Paper Code (Latent-SSVM) Cascaded Scene Flow Prediction using Semantic Segmentation Zhile Ren , Deqing Sun, Jan Kautz, Erik Sudderth International Conference on 3D Vision (3DV 2017 oral presentation) Paper Supplementary Talk Slides Three-Dimensional Object Detection and Layout Prediction using Clouds of Oriented Gradients Zhile Ren , Erik Sudderth IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2016 oral presentation) Paper Supplementary Detection Results Talk Slides Talk Recording Robust Graph SLAM in Dynamic Environments with Moving Landmarks Lingzhu Xiang, Zhile Ren , Mengrui Ni, Odest Chadwicke Jenkins IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2015) Paper Transient Attributes for High-Level Understanding and Editing of Outdoor Scenes Pierre-Yves Laffont, Zhile Ren , Xiaofeng Tao, Chao Qian and James Hays ACM Transactions on Graphics (SIGGRAPH 2014) Media coverage: Brown News , NBC News , IEEE Spectrum , PBS , Mic Gizmodo Paper Project Page Code (Color Transformation) Talk Recording Image Segmentation by Cascaded Region Agglomeration Zhile Ren , Greg Shakhnarovich IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2013) Paper Supplementary Results Thesis Semantic Three-Dimensional Understanding of Dynamic Scenes Zhile Ren Doctoral Thesis, Brown University, May 2018 Thesis Miscellaneous (Almost) Everyone calls me \" Ren \" You can find me in social networks: Facebook Instagram Twitter Goodreads Strava \u00a9 Zhile Ren with Bootstrap and Font Awesome", "https://cs.brown.edu/people/stellex/": "Main / Main Main Publications Research Personal projects Welcome to my home page. I am an assistant professor in the ComputerScience Department at Brown University .The aim of my research program is to construct robots that seamlesslyuse natural language to communicate with humans. In twenty years,every home will have a personal robot which can perform tasks such as clearing thedinner table , doing laundry ,and preparingdinner . As these machines become more powerful and moreautonomous, it is critical to develop methods for enabling people totell them what to do. Robots that can communicate with people usinglanguage can respondappropriately to commands given by humans, ask questions when they areconfused, and request help when they get stuck. We apply probabilistic methods, corpus-basedtraining, and decision theory to develop interactive robotic systemsthat can understand and generate natural language.I completed my Ph.D. at the MIT Media Lab in 2010, where I developedmodels for the meanings of spatial prepositions and motion verbs. Mypostdoctoral work at MIT CSAIL focused on creating robots thatunderstand natural language. I have published at SIGIR, HRI, RSS,AAAI, IROS, and ICMI, winning Best Student Paper at SIGIR and ICMI. Iwas named one of IEEE Spectrum\u2019s AI\u2019s 10 to Watch and won the RichardB. Salomon Faculty Research Award at Brown University. Here is our language-understanding system running on a forklift: Direction-understanding on a robotic helicopter: Direction-understanding for the PR2: I am also interested in reinforcement learning as applied to\u201chuman-cat communication\u201d:projects/gizmo.html:", "https://cs.brown.edu/people/staff/slm10/": "Steven Martins Lead System Administrator Email: steven_martins @@ @brown.edu", "https://cs.brown.edu/people/tbn/": "Tim Nelson Lecturer in Computer Science Brown Computer Science E-mail: tbn [at] cs [dot] brown [dot] edu Office: CIT 355 Publications Service Teaching I am part of the PLT Group at Brown University Computer Science .I'm interested in user-facing formal methods and formal-methods education, as well as applications like language design for network programming. Teaching is a major focus for me. Among other courses, I run Logic for Systems , a class that turns the usualformal-logic syllabus on its head by focusing on applications and tools. In the past, we used the excellent Alloy ; we now use our own pedagogically-focused version of Alloy, Forge . A note on my email address : I used to be tn, not tbn. Unfortunately, times change andinstitutional policies become better enforced. Rather than spend my time engaging in a quixotic battle over one keystroke, I've decided to view this as a mark of approval:the Powers that Be have granted me one more letter in my login name. TLDR: please use tbn, not tn, to avoid potential delays and other issues.", "https://cs.brown.edu/people/ycheng79/": "Yu Cheng Home Research Misc I am an Assistant Professor in the Department of Computer Science at Brown University. I received my Ph.D. from the University of Southern California in 2017, advised by Shang-Hua Teng .I was a postdoc at Duke University , a visiting member at the Institute for Advanced Study , and an Assistant Professor at the University of Illinois at Chicago . My Research : My main research interests include machine learning, optimization, and game theory.My recent work focuses on the design and analysis of scalable and provably robust algorithms for machine learning, especially in the areas of high-dimensional robust statistics, non-convex optimization, and learning with strategic agents. Email : yu_cheng AT brown.edu Office : CIT 413, 115 Waterman St, Providence, RI 02906. My CV and papers ( by date or by topic ). Teaching Spring 2024: CSCI1952Q: Algorithmic Aspects of Machine Learning . Fall 2023: CSCI2952Q: Robust Algorithms for Machine Learning . Spring 2023: CSCI1952Q: Algorithmic Aspects of Machine Learning . Fall 2022: CSCI2952Q: Robust Algorithms for Machine Learning . Fall 2021: MCS 401: Computer Algorithms I . Fall 2021: MCS 425: Codes and Cryptography . Fall 2020: MCS 401: Computer Algorithms I . Fall 2020: MCS 425: Codes and Cryptography . Spring 2020: MCS 425: Codes and Cryptography . Spring 2020: MCS 590: Spectral Graph Theory . Research Group Current Ph.D. Students: Binhao Chen Xing Gao (co-advised with Lev Reyzin ) Former Undergraduate Students: Haichen Dong Honghao Lin Publications Tight Lower Bounds for Directed Cut Sparsification and Distributed Min-Cut. Yu Cheng, Max Li , Honghao Lin , Zi-Yi Tai , David P. Woodruff , Jason Zhang . PODS 2024. Robust Matrix Sensing in the Semi-Random Model. Xing Gao ,Yu Cheng. NeurIPS 2023. Robust Second-Order Nonconvex Optimization and Its Application to Low Rank Matrix Sensing. Shuyao Li ,Yu Cheng, Ilias Diakonikolas , Jelena Diakonikolas , Rong Ge , Stephen Wright . NeurIPS 2023. Hiding Data Helps: On the Benefits of Masking for Sparse Coding. ( arXiv ) Muthu Chidambaram , Chenwei Wu ,Yu Cheng, Rong Ge . ICML 2023. Efficiently Solving Turn-Taking Stochastic Games with Extensive-Form Correlation. Hanrui Zhang ,Yu Cheng, Vincent Conitzer . EC 2023. Outlier-Robust Sparse Estimation via Non-Convex Optimization. ( arXiv , slides ) Yu Cheng, Ilias Diakonikolas , Rong Ge , Shivam Gupta , Daniel M. Kane , Mahdi Soltanolkotabi . NeurIPS 2022. Efficient Algorithms for Planning with Participation Constraints. ( arXiv ) Hanrui Zhang ,Yu Cheng, Vincent Conitzer . EC 2022. Planning with Participation Constraints. ( pdf ) Hanrui Zhang ,Yu Cheng, Vincent Conitzer . AAAI 2022. Sparsification of Directed Graphs via Cut Balance. ( arXiv ) Ruoxu Cen ,Yu Cheng, Debmalya Panigrahi , Kevin Sun . ICALP 2021. Robust Learning of Fixed-Structure Bayesian Networks in Nearly-Linear Time. ( arXiv ) Yu Cheng, Honghao Lin . ICLR 2021. Fair for All: Best-effort Fairness Guarantees for Classification. ( arXiv ) Anilesh Krishnaswamy , Zhihao Jiang , Kangning Wang ,Yu Cheng, Kamesh Munagala . AISTATS 2021. Classification with Few Tests through Self-Selection. ( pdf ) Hanrui Zhang ,Yu Cheng, Vincent Conitzer . AAAI 2021. Automated Mechanism Design for Classification with Partial Verification. ( arXiv ) Hanrui Zhang ,Yu Cheng, Vincent Conitzer . AAAI 2021. High-Dimensional Robust Mean Estimation via Gradient Descent. ( arXiv , slides ) Yu Cheng, Ilias Diakonikolas , Rong Ge , Mahdi Soltanolkotabi . ICML 2020. Distinguishing Distributions When Samples Are Strategically Transformed. ( pdf ) Hanrui Zhang ,Yu Cheng, Vincent Conitzer . NeurIPS 2019. Group Fairness in Committee Selection. ( arXiv ) Yu Cheng, Zhihao Jiang , Kamesh Munagala , Kangning Wang . EC 2019. Faster Algorithms for High-Dimensional Robust Covariance Estimation. ( arXiv , slides , talk video ) Yu Cheng, Ilias Diakonikolas , Rong Ge , David P. Woodruff . COLT 2019. When Samples Are Strategically Selected. ( pdf ) Hanrui Zhang ,Yu Cheng, Vincent Conitzer . ICML 2019. A Better Algorithm for Societal Tradeoffs. ( pdf ) Hanrui Zhang ,Yu Cheng, Vincent Conitzer . AAAI 2019. High-Dimensional Robust Mean Estimation in Nearly-Linear Time. ( arXiv , slides ) Yu Cheng, Ilias Diakonikolas , Rong Ge . SODA 2019. A Simple Mechanism for a Budget-Constrained Buyer. ( arXiv ) Yu Cheng, Nick Gravin , Kamesh Munagala , Kangning Wang . WINE 2018 (Best Paper Award). Robust Learning of Fixed\u2013Structure Bayesian Networks. ( arXiv ) Yu Cheng, Ilias Diakonikolas , Daniel M. Kane , Alistair Stewart . NeurIPS 2018. Non-Convex Matrix Completion Against a Semi-Random Adversary. ( arXiv , slides , talk video ) Yu Cheng, Rong Ge . COLT 2018. A Deterministic Protocol for Sequential Asymptotic Learning. ( arXiv ) Yu Cheng, Wade Hann-Caruthers , Omer Tamuz . ISIT 2018. On the Distortion of Voting with Multiple Representative Candidates. ( arXiv , slides ) Yu Cheng, Shaddin Dughmi , David Kempe . AAAI 2018. Computational Aspects of Optimal Information Revelation. ( pdf , slides , talk video ) Yu Cheng. Ph.D. Thesis. University of Southern California, 2017. Of the People: Voting Is More Effective with Representative Candidates. ( arXiv , slides , talk video ) Yu Cheng, Shaddin Dughmi , David Kempe . EC 2017. Well-Supported versus Approximate Nash Equilibria: Query Complexity of Large Games. ( arXiv , slides , talk video ) Xi Chen ,Yu Cheng, Bo Tang . ITCS 2017. Playing Anonymous Games using Simple Strategies. ( arXiv , slides ) Yu Cheng, Ilias Diakonikolas , Alistair Stewart . SODA 2017. On the Recursive Teaching Dimension of VC Classes. ( ECCC , talk video ) Xi Chen ,Yu Cheng, Bo Tang . NIPS 2016. Hardness Results for Signaling in Bayesian Zero-Sum and Network Routing Games. ( arXiv , slides ) Umang Bhaskar ,Yu Cheng, Young Kun Ko , Chaitanya Swamy . EC 2016. Mixture Selection, Mechanism Design, and Signaling ( arXiv , slides , talk video ) Yu Cheng, Ho Yee Cheung , Shaddin Dughmi , Ehsan Emamjomeh-Zadeh , Li Han , Shang-Hua Teng . FOCS 2015. Signaling in Quasipolynomial Time ( arXiv ) Yu Cheng, Ho Yee Cheung , Shaddin Dughmi , Shang-Hua Teng . Efficient Sampling for Gaussian Graphical Models via Spectral Sparsification (arXiv Part I and Part II , slides ) Dehua Cheng ,Yu Cheng, Yan Liu , Richard Peng , Shang-Hua Teng . COLT 2015. var sc_project=12790518; var sc_invisible=1; var sc_security=\"87f121db\";", "https://cs.brown.edu/people/staff/spoc/": "The SPOCs SPOCs (Systems Programmer, Operator, and Consultants) assist in theinstallation, maintenance, development, and documentation of localsoftware. In addition, they represent the off-hours technical supportstaff, and assist with administrative tasks. The current SPOCs are: Austin Miles Sophia Liu Jiahua Chen Kevin Lu Bokai Bi Edward Wibowo amiles6 sliu176 jchen345 klu25 bbi1 ewibowo How to get help In general, the best way to get help is to email problem@cs.brown.edu( more info .) This helps us deal with problemsmost efficiently. If an issue needs immediate attention, you can try emailing the on-duty SPOC (see the below schedule). On nights, weekends, and holidays, at least one SPOC will always beresponsible for reading submitted problem tickets (\"remote coverage\"). Onweeknights, a SPOC will also be in the building to deal with requests inperson. Current Schedule The schedule is available as a Google Calendar: Additional support resources Department Systems information & documentation After-hours support information Reporting problems (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-34495025-1', 'auto'); ga('send', 'pageview');", "https://cs.brown.edu/research/areas.html": "General Areas of Research Algorithms and Theory Primary: Yu Cheng , Lorenzo De Stefani , Pedro F Felzenszwalb , Shahrzad Haddadan , Ellis Hershkowitz , Sorin Istrail , Serdar Kadioglu , Philip Klein , Franco Preparata , Benjamin J Raphael , Roberto Tamassia , Eli Upfal Secondary: Tim Nelson , Suresh Venkatasubramanian Artificial Intelligence Primary: Alper Ahmetoglu , Stephen Bach , Eugene Charniak , Thomas L Dean , Carsten Eickhoff , Pedro F Felzenszwalb , Amy R Greenwald , Serdar Kadioglu , George D Konidaris , Michael L. Littman , David Paulius , Ellie Pavlick , Daniel C Ritchie , Ankit J Shah , Srinath Sridhar , Chen Sun , Stefanie A Tellex Secondary: Nora Ayanian , Eli Upfal Computational Biology Primary: Thomas L Dean , Sorin Istrail , David H. Laidlaw , Mark E Nadel , Franco Preparata , Sohini Ramachandran , Benjamin J Raphael , Ritambhara Singh Secondary: Eli Upfal Computer Systems R. Iris Bahar , Theophilus A Benson , Thomas W Doeppner , Rodrigo Fonseca , Vasileios Kemerlis , Sherief Reda , Malte Schwarzkopf , Alan M Usas , Nikos Vasilakis Computer Vision Thomas L Dean , Pedro F Felzenszwalb , Daniel C Ritchie , Srinath Sridhar , Chen Sun , Gabriel Taubin , James H Tompkin Computing Education Primary: Kathi Fisler , Shriram Krishnamurthi , Tim Nelson , Alexander Steinmaurer , Alan M Usas , Milda Zizyte Secondary: Robert Y. Lewis Data Science Primary: Stephen Bach , Karianne Bergen , Bruce Donald Campbell , Ugur Cetintemel , Andrew Crotty , Carsten Eickhoff , Pedro F Felzenszwalb , Jeff Huang , Serdar Kadioglu , David H. Laidlaw , Ellie Pavlick , Sohini Ramachandran , Matteo Riondato , Roberto Tamassia , Eli Upfal Secondary: Shahrzad Haddadan , Tom Sgouros Database Systems Primary: Carsten Binnig , Ugur Cetintemel , Andrew Crotty , Tim K Kraska , Stanley B Zdonik Secondary: Malte Schwarzkopf Distributed Systems Theophilus A Benson , Ugur Cetintemel , Rodrigo Fonseca , Maurice P Herlihy , Malte Schwarzkopf , Nikos Vasilakis , Stanley B Zdonik Geometric Modeling Gabriel Taubin Graphics and Visualization Bruce Donald Campbell , John F Hughes , David H. Laidlaw , Joseph J Laviola , Barbara J. Meier , Steven P Reiss , Daniel C Ritchie , Gabriel Taubin , James H Tompkin , Andries van Dam Human-Computer Interaction Primary: Adam Blumenthal , Bruce Donald Campbell , Thomas L Dean , Jeff Huang , Jose James , Shriram Krishnamurthi , David H. Laidlaw , Joseph J Laviola , Steven P Reiss , Donald L Stanford , James H Tompkin , Ernesto Zaldivar Secondary: Norm Meyrowitz , Srinath Sridhar Machine Learning Primary: Stephen Bach , Karianne Bergen , Eugene Charniak , Yu Cheng , Thomas L Dean , Carsten Eickhoff , Pedro F Felzenszwalb , Serdar Kadioglu , George D Konidaris , Michael L. Littman , Ellie Pavlick , Sohini Ramachandran , Daniel C Ritchie , Ritambhara Singh , Srinath Sridhar , Chen Sun , Stefanie A Tellex , Eli Upfal Secondary: Lorenzo De Stefani , Suresh Venkatasubramanian Networking Primary: Theophilus A Benson , Rodrigo Fonseca , Shriram Krishnamurthi Secondary: Tim Nelson Programming Languages Primary: Kathi Fisler , Shriram Krishnamurthi , Robert Y. Lewis , Nikos Vasilakis Secondary: Tim Nelson Robotics Alper Ahmetoglu , Nora Ayanian , R. Iris Bahar , Thomas L Dean , Ian Gonsher , George D Konidaris , Joseph J Laviola , Michael L. Littman , David Paulius , Ankit J Shah , Srinath Sridhar , Stefanie A Tellex , Milda Zizyte Security Primary: Vasileios Kemerlis , Nikos Vasilakis , Ernesto Zaldivar Secondary: Eli Upfal Security and Cryptography Seny F Kamara , Shriram Krishnamurthi , Anna A Lysyanskaya , Peihan Miao , Tarik Moataz , Bernardo Palazzi , Steven P Reiss , Donald L Stanford , Roberto Tamassia , Alan M Usas Software Engineering Primary: Shriram Krishnamurthi , Norm Meyrowitz , Tim Nelson , Steven P Reiss , Tom Sgouros , Milda Zizyte Secondary: Vasileios Kemerlis Theory Primary: Peihan Miao , Eli Upfal Secondary: Robert Y. Lewis , John E Savage Specialized Areas of Research 3D Photography Gabriel Taubin 3D Scanning Gabriel Taubin Algorithmic Fairness Primary: Tom Sgouros , Suresh Venkatasubramanian Secondary: Shahrzad Haddadan , Michael L. Littman Algorithmic Game Theory Amy R Greenwald Computational Geosciences Karianne Bergen Computer Architecture R. Iris Bahar , Sherief Reda , Donald L Stanford Deep Learning Primary: Alper Ahmetoglu , Eugene Charniak , Thomas L Dean , Carsten Eickhoff , Sherief Reda , Daniel C Ritchie , Ritambhara Singh , Srinath Sridhar , Chen Sun Secondary: Eli Upfal Design Adam Blumenthal , Ian Gonsher , Jeff Huang , David H. Laidlaw , Steven P Reiss Digital Geometry Processing Gabriel Taubin Formal Methods Primary: Kathi Fisler , Shriram Krishnamurthi , Robert Y. Lewis , Tim Nelson , Steven P Reiss , Milda Zizyte Secondary: Mark E Nadel Haptics Jose James Multi-Agent Systems Primary: Amy R Greenwald Secondary: Nora Ayanian Natural Language Processing Primary: Adam Blumenthal , Thomas L Dean , Carsten Eickhoff , Ellie Pavlick Secondary: David Paulius Randomized Algorithms and Probabilistic Analysis Primary: Eli Upfal Secondary: Lorenzo De Stefani , Matteo Riondato Reinforcement Learning Thomas L Dean , Amy R Greenwald , Michael L. Littman Security Policy Timothy H Edgar , John E Savage , Ernesto Zaldivar Signal Processing Karianne Bergen Virtual Reality Adam Blumenthal , Jose James", "https://cs.brown.edu/research/mri/mri_repository.html": "Brown-Edinburgh Diffusion MRI Resource This page presents a diffusion MRI resource of 80 normal subjects includingdemographic and neuropsychological measures. This work is supported by NIHR01 EB004155 in collaboration between David H. Laidlaw in the Visualization Research Lab atBrown University and Mark E. Bastin at University of Edinburgh. Under an IRB-approved protocol, diffusion-weighted MR images were acquired froma population of healthy volunteers, including a group of 80 normal aginghealthy controls. The subjects comprised a cross-sectional normal agingpopulation, which consisted of nearly equal number of each sex and roughlyuniformly distributed ages ranging from 25 to 65 years old. Imaging wasconducted on a GE 1.5T scanner with 2x2x2mm voxels and image resolution128x128x72. For each diffusion scan, seven baseline volumes were acquired, andthe diffusion-weighted images used a single-shell high angular resolutiondiffusion encoding scheme with 64 distinct gradient encoding directions at ab-value of 1000 s/mm^2. To gain access to the dataset, please send a request containing your name,institution, and a brief description of your research interest to David H. Laidlaw at // hopefully this fools the email harvesters var a = 'dh'+'l@c'+'s.br'+'own.'+'edu'; var t = '<a h'+'ref='+'\"mai'+'lto:'+a+'\">'+a+'</a>'; document.write(t); or Ryan P. Cabeen at // hopefully this fools the email harvesters var a = 'cabe'+'en@c'+'s.br'+'own.'+'edu'; var t = '<a h'+'ref='+'\"mai'+'lto:'+a+'\">'+a+'</a>'; document.write(t); . The data release page can then be accessed here .", "https://cs.brown.edu/research/lads/": "LADS Large Artwork Display on the Surface Home About Links Download A platform for viewing large, digitized images on touch-enabled devices \u00a9 2011 BROWN UNIVERSITY All rights reserved | Contact Us SPONSORED BY", "https://cs.brown.edu/research/plt/": "Computer Science Brown University Brown PLT Welcome to Brown PLT! Located in beautiful, historic Providence , our work unifies under themes of design, learning, and languages. We build languages, analyze them, and take them apart. We work on verification and other forms of formal methods. We create environments and other tools for working with languages and verifiers. We also write books for understanding these topics. If you want to learn more or join us, get in touch Pyret Pyret is the main language we're currently working on. We combine the best of functional and scripting languages to create an outstanding language for teaching and, down the road, general-purpose programming. Pyret is an umbrella for several efforts in compilation, type systems, error-reporting, language design, and much more. Forge Forge is a new tool and collection of languages for formal modeling. Forge is heavily inspired by Alloy, but offers its own opinionated take on modeling, analysis, and verification. DCIC A Data-Centric Introduction to Computing is a new book that lays out our research-driven approach to learning programming, following our data-centric perspective . Suppporting it requires a lot of the other work described on this page. PLAI Programming Languages: Application and Interpretation is our programming languages book, in widespread use. All three editions are available online. People We have five faculty members ( Shriram Krishnamurthi , Kathi Fisler , Rob Lewis , Tim Nelson , Milda Zizyte ), one post-doc ( Will Crichton ), five PhD students ( Yanyan Ren , Kuang-Chen Lu , Elijah Rivera , Siddhartha Prasad , Skyler Austen ), several undergraduates, and a research programmer ( Dorai Sitaram ). Several other faculty in the department have done work that is related to ours, including Maurice Herlihy , Vasileios Kemerlis , Michael Littman , Steve Reiss , Daniel Ritchie , Malte Schwarzkopf , Nikos Vasilakis . Finally, we also collaborate with several faculty at other universities (most notably Ben Lerner and Joe Politz ) and with (the rest of) Bootstrap . Location We are very convenient located in the greater-Boston area in the Northeast of the USA. If you're in the area, let us know! Many of our talks are co-located with the systems folk. Other Groups Our take on programming languages strikes a balance between theory, systems, HCI, and more. As a result we often work closely with people in the systems and computing education groups. Blog We often blog about our work . Our blog is a convenient, lightweight way to learn about some of our research. Talks Thanks to our convenient location , we host numerous speakers. Since we share many interests with them, our talks are co-located with the systems folk. Papers All of our papers are online . They have associated repositories of code, data, proofs, and other artifiacts, as appropriate. Repositories Most of our recent work is in our github repository , although individual papers have their own repositories elsewhere. In general, a paper's page above is the best source for material about that paper. Other Systems We view research and building systems as complementary and mutually-reinforcing. We have worked (and in some cases continue to work) on research-driven systems used by many other people, including JavaScript and Web tools , Flowlog and related tools , Racket and DrRacket , WeScheme , Margrave , Flapjax , FrTime , Continue , Captain Teach , and PerMission .", "https://cs.brown.edu/research/plt/dl/aluminum/": "here here", "https://cs.brown.edu/research/plt/dl/flowlog/": "here here Once running the VM To run a Flowlog program, cd to the FlowLog/interpreter folder and then: ./flowlog.native program.flg for instance to load the learning switch program: ./flowlog.native examples/Mac_Learning.flg Mininet has already been installed. For instance: sudo mn --controller=remote --topo=tree,depth=2,fanout=2 --mac --arp will load a tree topology with three switches and four hosts. The Alloy Analyzer has been downloaded into the default user root directory. To run it: java -jar alloy4.2.jar Contact: Tim Nelson Last Updated: Mar 6, 2014", "https://cs.brown.edu/research/plt/dl/fse2017/": "explanations Installation here You can run the JAR file by typing: \"java -jar amalgam.jar\"at your terminal. Example Specifications here Using Amalgam Provenance Commands Amalgam adds several new commands to the evaluator: @ln+ : lists the locally-necessary positive literals; @ln- : lists the locally-necessary negative literals; @why : generates provenance(s) for a positive literal; @whynot : generates provenance(s) for a negative literal; @prov # : displays the #th provenance for the last @why or @whynot command. The evaluator will print only debugging information; the structured provenance tree and highlighting will appear in the model-editing window. Scope not Provenance Detail ProvenanceDetail The default of \"1\" provides less information than \"2\"; to seemore information about each alpha formula and derivation, change this settingto \"2\". Different users may prefer different settings. New Instance-Viewing Options", "https://sites.google.com/a/brown.edu/ugur-cetintemel/": "Search this site .rrJNTc{opacity: 0;}.bKy5e{pointer-events: none; position: absolute; top: 0;} Skip to main content Skip to navigation Ugur Cetintemel Ugur Brown University Brown CS Ugur Cetintemel Ugur Brown University Brown CS More Ugur Brown University Brown CS Ugur Cetintemel Khosrowshahi University Professor of Computer Science Brown University Box 1910, 115 Waterman Street , Room 4 37 , CIT Providence, RI 02912 Research Interests Data management Data science systems and appl ications Distributed systems Brown Data Management Group Teaching CSCI 1951-I: CS for Social Change DATA 1030: Intro to Data and Computer Science CSCI 2950-T: Interacting with Big Data CSCI 1310: Fundamentals of Computer Systems Select Articles (more complete list at dblp ) Machine Learning for Database Systems DeepSqueeze: Deep Semantic Compression for Tabular Data (SIGMOD'20) The Case for a Learned Sorting Algorithm (SIGMOD'20) A Fully Pluggable NL2SQL Training Pipeline (SIGMOD'20) DBPal: A Learned Natural Language Interface for Database Systems (SIGMOD'18) Making the Case for Query-by-Voice with EchoQuery (SIGMOD16) Portable Workload Performance Prediction in the Cloud (ICDE'13) Learning-based Query Performance Modeling and Prediction (ICDE'12) Performance Prediction for Concurrent Database Workloads (SIGMOD'11) The Case for Predictive Database Systems: Opportunities and Challenges ( CIDR'11 ) Database Support for Continuous Prediction Queries over Streaming Data (PVLDB'10) Applied Data Engineering End-to-end artificial intelligence platform for the management of large vessel occlusions: a preliminary study (Journal of Stroke and Cerebrovascular Diseases, Vol 31, No 11, 2022) Detecting Large Vessel Occlusion at Multiphase CT Angiography by Using a Deep Convolutional Neural Network (Radiology, Vol 297, No 3, 2020) Modern Hardware for Database Systems The Case for In-Memory OLAP on \"Wimpy\" Nodes (ICDE'21) A Morsel-Driven Query Execution Engine for Multi-Cores (VLDB'19) Revisiting Reuse in Main Memory Database Systems (SIGMOD'17) SiliconDB: Rethinking DBMSs for Modern Heterogeneous Co-Processor Environments (DaMoN'17) An Architecture for Compiling UDF-centric Workflows (PVLDB'15) Tupleware: \"Big\" Data, Big Analytics, Small Clusters (CIDR'15) Data Exploration Dynamic Query Refinement for Interactive Data Exploration (EDBT'20) Interactive Search and Exploration of Waveform Data with Searchlight (SIGMOD'16) Searchlight: Enabling Integrated Search and Exploration over Large Multidimensional Data (PVLDB'15) Interactive Data Exploration using Semantic Windows (SIGMOD'14) Query Steering for Interactive Data Exploration (CIDR'13) Stream Processing S-Store: Streaming meets Transaction Processing (PVLDB'15) S-Store: A Streaming NewSQL System for Big Velocity Applications (PVLDB'14) Report abuse Page details Page updated Report abuse DOCS_timing['cov']=new Date().getTime();", "https://ics.uci.edu/~sudderth/": "Toggle navigation Erik Sudderth News Group Projects Papers Courses Erik B. Sudderth, Statistical Computation & Perception I am a Professor of Computer Science and Statistics , and Chancellor's Fellow, at the University of California, Irvine . My Learning, Inference, & Vision Group develops statistical methods for scalable machine learning, with applications in artificial intelligence, computer vision, and the natural and social sciences. My research affiliations at UC Irvine include: Director of the UCI Center for Machine Learning and Intelligent Systems . See our seminar series . Director of the HPI Research Center in Machine Learning and Data Science at UC Irvine . UCI Computational Vision Group . UCI Algorithms, Combinatorics, and Optimization Center . See their seminar series . UCI Steckler Center for Responsible, Ethical, and Accessible Technology (CREATE) . UC Irvine Initiative in AI, Law, & Society . UCI Institute for Mathematical Behavioral Sciences . UCI Data Science Initiative . Also see the statistics seminar series . For a tutorial introduction to probabilistic modeling and approximate inference, see the background chapter of my doctoral thesis , advised by Professors Alan Willsky and William Freeman at MIT EECS . My postdoctoral research at Berkeley EECS , advised by Professors Michael Jordan and Stuart Russell , focused on Bayesian nonparametric models (see my CVPR tutorial ). For more information: bio \u00b7 curriculum vit\u00e6 \u00b7 research projects & code \u00b7 publications & lectures Research Highlights At NeurIPS 2023 , we present work incorporating graphical models in deep generative models to learn discrete representations , and advancing differentiable training of discriminative particle filters . A large NSF grant funds research making collaboration accessible for visually impaired workers . A new model for sparse graphs with overlapping communities appears at NeurIPS 2022 . Related work was presented at the 13th International Conference on Bayesian Nonparametrics . Work on inference for soil biogeochemical models , an important framework for quantifying the impact of rising global surface temperatures, appears at the ICML 2022 AI for Science Workshop . We advance the scalability and stability of fair machine learning methods in work at NeurIPS 2021 . The ICML 2021 Time Series Workshop best poster award goes to our work on prediction constraints for semi-supervised classification with Hidden Markov models . Work on better black-box variational inference for probabilistic programs appears at ICML 2021 . This work supported in part by a Facebook Probability and Programming research award . Our work on 3D scene reconstruction with multi-layer depth and epipolar transformers appears at ICCV 2019 . Previously at the CVPR 3D Scene Understanding and SUMO Challenge workshops. Our cascaded 3D detection framework, which integrates geometric and contextual cues for robust scene understanding from RGB-D images, is summarized by a 2020 paper appearing in IEEE PAMI . An NSF Robust Intelligence Award with Alex Ihler supports work on new particle-based algorithms for inference and learning with continuous graphical models. I gave a talk at the 2017 SoCal Machine Learning Symposium about our earlier diverse particle max-product algorithm, which gives state-of-the-art predictions of continuous protein side-chain conformations. Code available . At AISTATS 2018 , our framework for prediction-constrained training of probabilistic models leads to improved semi-supervised learning of topic models, with applications to the analysis of documents and electronic health records. This work received the SoCal NLP Symposium best paper award . An NSF CAREER Award supports our open source toolbox BNPy: Bayesian Nonparametric clustering for Python . BNPy implements scalable, stochastic and memoized variational inference algorithms for a diverse range of Bayesian nonparametric models. Work with BrainGate on multiscale semi-Markov dynamics for improved brain-computer interfaces appeared at NIPS 2017 . A supplemental video demonstrates accurate, interactive control of a computer cursor by a clinical trial participant with tetraplegia. The 2014 ISBA Mitchell Prize for Bayesian analysis of an important applied problem goes to our NET-VISA system for global seismic monitoring , learned from data provided by the comprehensive nuclear-test-ban treaty organization (CTBTO) . For details see the Brown University news article . Weiss & Pearl introduce our review article on Nonparametric Belief Propagation for the CACM . Editorial Highlights Action editor for the Journal of Machine Learning Research . Associate editor for the IEEE Transactions on Pattern Analysis and Machine Intelligence . Senior area chair for AISTATS 2024 . Scientific committee for the 12th International Conference on Bayesian Nonparametrics . Area chair for NeurIPS 2023 & 2021 & 2019 & 2016 , CVPR 2019 & 2015 , ICML 2017 & 2015 , ICCV 2015 . Sponsor chair for the 2018 & 2019 International Conference on Machine Learning . Editor, IEEE PAMI Special Issue on Bayesian Nonparametrics , Feb. 2015. (editorial) Organizer, ICERM Workshop & Tutorials on Bayesian Nonparametrics , Sept. 2012. (group photo) Editor, IEEE Signal Processing Magazine special issue on Recent Advances & Emerging Developments of Graphical Models , Nov. 2010. (editorial) Editor, IEEE PAMI Special Issue on Probabilistic Graphical Models in Computer Vision , Oct. 2009. (editorial) Erik B. Sudderth E: lastname@uci.edu P: (949) 824-8169 Office: Donald Bren Hall 4206 Mailing Address: University of California, Irvine School of Information & Computer Sciences Irvine, CA 92697-3435 \u00a9 2024 Erik B. Sudderth \u00b7 lastname@uci.edu", "https://ics.uci.edu/~sudderth/group/": "Toggle navigation Erik Sudderth News Group Projects Papers Courses LIV: Learning, Inference, & Vision Group Principal Investigator: Erik Sudderth , UC Irvine Computer Science \u00b7 CV LIV group members of the HPI Research Center in Machine Learning and Data Science at UC Irvine at a Sept. 2023 retreat in Rheinsberg, Germany. LIV group and alumni at the December 2017 Conference on Neural Information Processing Systems in Long Beach, CA. LIV Group Members Sakshi Agarwal , PhD student. Harry Bendekgey , PhD student. Mehrnaz Motamed, PhD student. Debora Sujono , PhD student. Ali Younis , PhD student. Federica Zoe Ricci , PhD student, co-advised by Michele Guindani . LIV Alumni: PhD Theses Soumya Ghosh , IBM Research. 2015 Brown PhD: Bayesian Nonparametric Discovery of Layers and Parts from Scenes and Objects . Gabriel Hope , Visiting Assistant Professor, Harvey Mudd College. 2023 UC Irvine PhD: Prediction-Constrained Latent Variable Models . Michael Hughes , Assistant Prof. of Computer Science at Tufts University. 2016 Brown PhD: Reliable and Scalable Variational Inference for Nonparametric Mixtures, Topics, and Sequences . Geng Ji , Facebook AI. 2019 UC Irvine PhD: Efficient Variational Inference for Hierarchical Models of Images, Text, and Networks . Daeil Kim , founder of AI. Reverie. 2017 Brown PhD: Scalable Bayesian Nonparametric Models for Networks and Documents . Jason Pacheco , Assistant Prof. of Computer Science at Univ. of Arizona. 2016 Brown PhD: Variational Approximations with Diverse Applications . Zhile Ren , applied research scientist at Apple. 2018 Brown PhD: Semantic Three-Dimensional Understanding of Dynamic Scenes . LIV Alumni: Masters & Undergraduate Research Madina Abdrakhmanova , MS 2019: Prediction Constrained Factor Analysis . Samuel Ainsworth , ScB 2016. Michael Bryant, ScM 2012: Truly Nonparametric Online Variational Inference for Hierarchical Dirichlet Processes . Soravit Changpinyo , ScB 2012 (honors): Learning Image Attributes using the Indian Buffet Process . Xiaoyin Chen, BS 2021: Learning Consistent Deep Generative Models from Sparse Data via Prediction Constraints . Rajkumar Kothapa, ScM 2011: Max-Product Particle Belief Propagation . Andrew Miller , ScM 2010: Image and Audio Annotation: Approximate Inference in Dense Conditional Random Fields . Daniel Milstein, ScB 2015, ScM 2017: Multiscale Semi-Markov Dynamics for Intracortical Brain-Computer Interfaces . Mengrui Ni, ScM 2015: Variational Inference for Beta-Bernoulli Dirichlet Process Mixture Models . Carl Olsson , ScM 2016: Scene Category Context for 3D Object Detection with RGBD Cameras . Sonia Phene , ScB 2015 (honors): Parallelization of Variational Inference for Bayesian Nonparametric Topic Models . Roshan Rao , ScB 2017 (honors): Protein Structure Prediction from Low-Resolution Electron Density Data using Particle Belief Propagation. Jake Soloff , ScB 2016. William Stephenson , ScB 2015 (honors): Variational Inference for Hierarchical Dirichlet Process Based Nonparametric Models . Donglai Wei , ScB 2011. Leah Weiner, ScM 2017. \u00a9 2024 Erik B. Sudderth \u00b7 lastname@uci.edu LIV Group LIV Alumni", "https://cs.brown.edu/research/plt/dl/adsafety/v2/": "Type-Based Verification of Web Sandboxes Joe Gibbs Politz, Arjun Guha, and Shriram Krishnamurthi The paper: adsafety.pdf The typed, annotated version of ADsafe discussed in the paper: typed-adsafe.js The environment file that defines, among other things, the Untrusted type presented in the paper: adsafe.env The source code: adsafety-aug-2013.tgz", "https://cs.brown.edu/research/plt/dl/lambda-py/ae/index.html": "Python: The Full Monty A Tested Semantics for the Python Programming Language Artifact Evaluation Submission This Document This documentat is intended to assist the OOPSLA Artifact Evaluation Committee (AEC) and any other interested parties reproduce and extend the results from our OOPSLA 2013 paper. This document is available at http://cs.brown.edu/research/plt/dl/lambda-py/ae/index.html , and in the tarball that we submitted to the AEC. The tarball is also available from http://cs.brown.edu/research/plt/dl/lambda-py/ae/lambda-py.tgz . This document covers: Starting the \u03bb \u03c0 virtual machine and verifying the paper's results Exploring the \u03bb \u03c0 implementation and tests Building \u03bb \u03c0 from scratch Contact If you have any problems or questions that require consulting the authors during the review process, email joe@cs.brown.edu Getting Started The virtual machine is in the directory lambda-py-server . The file lambda-py-server.vbox is runnable by double-clicking on many platforms with VirtualBox installed. You can also create a new virtual machine, choosing 'Linux' and 'Ubuntu' (not 64-bit), and use lambda-py-server.vmdk as the disk image. If you take this route, provide at least 1G of memory for the VM. In the first run wizard, choose lambda-py-server.vmdk as the disk image to use. Once you start the server, it may take a few minutes to start up on a screen that looks like: There is one useful user on the virtual machine, reviewer , with sudo privileges and password reviewer . When prompted for a login, enter these credentials and you should be presented with a desktop that looks like: The files for review are all in the directory /home/reviewer/lambda-py . The implementation and tests for \u03bb \u03c0 at artifact submission time are in lambda-py-artifact-submission . We focus on the current state of the implementation, which enjoys some significant improvements over the implementation at submission time. It passes all the same tests as the submission-time version and more (we include the version from submission time with instructions (at the end of this document) for completeness). Our first goal should be to simply verify that lambda-py runs. Open a terminal (\"Applications Menu\" at the top left, then \"Terminal Emulator\"), and let's first run a very small test so we can find out if anything goes wrong right away (if you have the opportunity to ask the authors for help, we're putting this here for quick diagnosis): $ cd lambda-py/lambda-py-artifact-submission/base$ echo \"print('lambda-py works')\" | racket python-main.rkt --interplambda-py works This will take a few seconds to run, and confirms that the \u03bb \u03c0 interpreter is up and running for you. Step-by-Step Instructions We've added new features since submission time, documented in CHANGES.txt. The new test cases are alongside the old in the tests/python-reference subdirectory of lambda-py-artifact-submission . So if you run the following, you will see more tests passing than the 175 we report in the paper: $ cd ~/lambda-py/lambda-py-artifact-submission/base$ racket python-main.rkt --test ../tests/python-reference/205 tests succeeded0 tests failed We provide a script called line_count.sh that uses CLOC to count the lines of code in each directory of python-reference . This compares the current state of the repository to the numbers reported in the paper in Figure 12 (the \"Built-in Datatypes\" count is the combination of the directories function, bool, builtin, tuple, lists, and dict, \"Iteration\" is the combination of directories iter and range, and \"(Multiple) Inheritance\" is the combination of directories super and multiple-inheritance). So, you can do: $ cd ~/lambda-py/lambda-py-artifact-submission/tests$ ./line_count.sh Feature# of testsLOCBuilt-in Datatypes81902Scope39455Exceptions25247Multiple Inheritance16303Properties9184Iteration13214Generators9129Modules658Total2052636 The repository is also set up to run all the same tests using Python. We've included an installation of Python 3.2.3 (the version we are modelling) in the VM, and these tests can be run with: $ cd ~/lambda-py/lambda-py-artifact-submission/base$ racket python-main.rkt --python-path ~/install-stuff/Python-3.2.3/python --test-py ../tests/python-reference Note: We drive the Python tester with Racket , passing the Python path as an argument. The implementation of our test harness performs the same directory traversal as when running with \u03bb \u03c0 , but runs with the Python executable, and checks standard out and standard error the same way. To go back in time and run all the tests that we report in the paper, you can visit the other pre-installed directory that contains the code from that time: $ cd ~/lambda-py/lambda-py-28-march-2013/base$ racket python-main.rkt --python-path ~/install-stuff/Python-3.2.3/python --test ../tests/python-reference/175 tests succeeded0 tests failed (We pass the Python path because we originally used Python to get the original Python AST for desugaring, and it has since been replaced. Also, the --test-py option, when run on the submission time code, reports 3 failures in the modules tests, this is an error in the test harness setting the working directory for Python. We have since fixed it.) That's enough to verify the test results reported in the paper, and some of what we've worked on since then. Looking Around Code from the paper Many of the discussions in the paper directly correspond to a few places in the code; it is useful to see how they translate. These are presented as links to Github sources, since they have a nice viewer for the files. The Redex definition of the language (which is also used to typeset the paper's code examples) is in lambda-py-core.rkt , and the definition of the reduction steps and related metafunctions (which are also used to typeset the semantics shown in the paper) are in lambda-py-reduction.rkt . The redex/ directory contains a number of tests for these. The interpreter implementation (dubbed \u03bb \u03c0\u2193 in the paper) defines its abstract syntax in python-core-syntax.rkt , which is simply an encoding in Racket structs of the AST from lambda-py-core.rkt . Similarly, python-interp.rkt is a (much) more efficient implementation of the reduction relation from lambda-py-reduction.rkt . A number of straightforward operator desugarings are in python-desugar.rkt . The composition of all the steps of scope desugaring is split between python-phase1.rkt , which marks global variables and instance variables from classes and rewrites class bodies, and python-phase2.rkt , which rewrites rewrites class bodies, eliminating instance variables and introducing bindings for local and global variables. These do other less fundamental work that doesn't appear in the paper for straightforward desugarings of default arguments and decorators. The CPS transformation and code for the skeleton in Figure 11 are in the file python-cps.rkt We try to push functionality out of Racket and into Python-implemented libraries (with some macros, as indicated in Section 6.2). These are in the base/pylib/ directory. For example the object and type base classes implement a large swath of built-in functionality; they are implemented in Python with macros for primitive operators, at type.py and object.py . As noted in the paper, \u03bb \u03c0 isn't quite to the point of running Python's full unittest library, so these tests use a limited language of assertions. For example, if we look at tests/python-reference/multiple-inheritance/methods.py , we see lines like: ___assertEqual(Foo.getx(foo), 1) ___assertEqual == base/py-prelude.py Playing around with \u03bb \u03c0 It's easy to tweak the Python-implemented libraries of \u03bb \u03c0 to see what their effects are on Python programs. Since these libraries implement so much built-in behavior, tweaking them can have interesting effects. You can run individual Python programs through \u03bb \u03c0 by passing them through standard input and using the --interp option: $ racket python-main.rkt --interp < some-python-file.py Some things you might try: Change the definition of the __str__ method in pylib/dict.py and run a simple program like print({'x':5}) . Change the definition of the __getitem__ method on a built-in type like pylib/list or pylib/dict and see the effects on lookup statements like print([1,2,3][0]) . Similarly, change __add__ or __sub__ and see the effect on + and - expressions. Change the behavior of the various __getattribute__ functions in pylib/object.py and see how it affects simple attribute lookup Building from Scratch These instructions are included so reviewers can see the build process for \u03bb \u03c0 on their own machines. Reviewers should be able to evaluate the artifact's adequacy relative to the paper from the VM, but a manual installation hopefully demonstrates that the artifact is easy to install and extend. The code for \u03bb \u03c0 is available at https://github.com/brownplt/lambda-py . We have two points in the repository's history that are interesting for this review: One at the time of our OOPSLA submission (28 March, 2013), and one at the time of our artifact submission (1 June 2013). The former is tagged in the repository as oopsla2013 , and the latter is the HEAD of the artifactevaluation branch (we'll push minor bugfixes here if any come up in the evaluation process, it contains this index file which isn't on the master branch, and if we do work and change master during the review process, we won't make breaking changes for the reviewers). Getting Racket Both require that you install Racket; the main download link at http://racket-lang.org/download/ has installers for many platforms. We have tested on several different Ubuntus from 11.04 to 12.10, and on OSX, with both Racket 5.3.3 and Racket 5.3.4. For review, we recommend Racket 5.3.4. Download the installer and run it; you can pick any of the options for installing Racket (for example, you can install UNIX-style in /usr/ , or keep the installation in your home directory). In the instructions that follow, we assume that the $PATH environment variable is pointing to the bin/ directory of the Racket installation that holds the raco and racket commands (this may be done for you automatically depending on which options you choose in the Racket installer). Example: $ wget http://download.racket-lang.org/installers/5.3.4/racket/racket-5.3.4-bin-i386-linux-ubuntu-karmic.sh$ sh racket-5.3.4-bin-i386-linux-ubuntu-karmic.sh Getting the Source of \u03bb \u03c0 Github is the easiest way to get a copy of the code: $ git clone https://github.com/brownplt/lambda-py BE AWARE: If you fork the repository on Github, it will leak your identity to us (it's up to you if that's a problem). Just using git clone (as above) won't. Artifact Submission-time Build Check out the artifactevaluation branch: $ git checkout artifactevaluation PLAI-Typed: \u03bb \u03c0 is built in a language that sits on top of Racket called plai-typed. We have it included with the repository as plai-typed-18Feb2013.plt in the root of the repository. To install it, use the raco command: $ raco setup -A plai-typed-18Feb2013.plt Ragg: Since publication, we had a third-party contribution of a pure Racket parser for Python (see this merge ). It uses the Ragg parser package for Racket; to install it, use the raco command: $ raco setup -A ragg-mangled.plt Building: The implementation of \u03bb \u03c0 is in the base/ directory. To build, simply use make : $ cd base $ make Running Use the same commands as above to run the tests (e.g. the commands with the --test option). Paper Submission-time Build We recommend using the provided virtual machine to review the code as it was at submission time, since it involves additional build steps that we have since made much easier. Python At the time of submission, we used Python's parser to get original ASTs for desugaring (we have since switched to a pure-Racket Python parser). So, to run tests at the oopsla2013 tag, you will also need to install Python3 (source is available at http://www.python.org/download/releases/3.2.3/ ). Example: $ wget http://www.python.org/ftp/python/3.2.3/Python-3.2.3.tgz$ tar xzf Python-3.2.3.tgz$ cd Python-3.2.3$ ./configure$ make To view the code as it was at submission time, check out the oopsla2013 tag: $ git checkout oopsla2013 PLAI-Typed: As in the instructions for the current build, install plai-typed with: $ raco setup -A plai-typed-18Feb2013.plt Running: To run the tests that were reported in the paper, run: # One additional build step:$ cd base/$ raco make python-main.rkt$ racket python-main.rkt --python-path ~/install-stuff/Python-3.2.3/python --test ../tests/python-reference/175 tests succeeded0 tests failed Where ~/install-stuff/Python-3.2.3/python is the path to your Python3 installation's python binary.", "https://cs.brown.edu/research/plt/dl/icer2014ct/": "Source Data and Analysis Scripts zip file Link to paper", "https://cs.brown.edu/research/plt/dl/icfp2017/": "Inferring Scope through Syntactic Sugar This page contains the supplemental materials for Inferring Scope through Syntactic Sugar by Justin Pombrio, Shriram Krishnamurthi, and Mitchell Wand, published in ICFP 2017. The implementation is published on github , or you can download it directly (see the scope-inference folder). There is also an an extended version of the paper that contains all of the proofs and some additional material.", "https://cs.brown.edu/research/plt/dl/jquery/": "Combining Form and Function: Static Types for JQuery Programs Benjamin S. Lerner, Liam Elberty, Jincheng Li, andShriram Krishnamurthi @INPROCEEDINGS{Lerner2013b, author = {Benjamin S. Lerner and Liam Elberty and Jincheng Li and Shriram Krishnamurthi}, title = {Combining Form and Function: Static Types for JQuery Programs}, booktitle = {European Conference on Object-Oriented Programming (ECOOP)}, year = {2013}, month = jul} The jQuery library defines a powerful query language for webapplications\u2019 scripts to interact with Web page content. This languageis exposed as jQuery\u2019s API, which is implemented to fail silently sothat incorrect queries will not cause the program to halt. Since thecorrectness of a query depends on the structure of a page,discrepancies between the page\u2019s actual structure and what the queryexpects will also result in failure, but with no error traces toindicate where the mismatch occurred. This work proposes a novel typesystem to statically detect jQuery errors. The type system extendsTyped JavaScript with local structure about the page and withmultiplicities about the structure of containers. Together, these twoextensions allow us to track precisely which nodes are active in ajQuery object, with minimal programmer annotation effort. We evaluatethis work by applying it to sample real-world jQuery programs. Paper", "https://cs.brown.edu/research/plt/dl/lambda-py/ae/": "Python: The Full Monty A Tested Semantics for the Python Programming Language Artifact Evaluation Submission This Document This documentat is intended to assist the OOPSLA Artifact Evaluation Committee (AEC) and any other interested parties reproduce and extend the results from our OOPSLA 2013 paper. This document is available at http://cs.brown.edu/research/plt/dl/lambda-py/ae/index.html , and in the tarball that we submitted to the AEC. The tarball is also available from http://cs.brown.edu/research/plt/dl/lambda-py/ae/lambda-py.tgz . This document covers: Starting the \u03bb \u03c0 virtual machine and verifying the paper's results Exploring the \u03bb \u03c0 implementation and tests Building \u03bb \u03c0 from scratch Contact If you have any problems or questions that require consulting the authors during the review process, email joe@cs.brown.edu Getting Started The virtual machine is in the directory lambda-py-server . The file lambda-py-server.vbox is runnable by double-clicking on many platforms with VirtualBox installed. You can also create a new virtual machine, choosing 'Linux' and 'Ubuntu' (not 64-bit), and use lambda-py-server.vmdk as the disk image. If you take this route, provide at least 1G of memory for the VM. In the first run wizard, choose lambda-py-server.vmdk as the disk image to use. Once you start the server, it may take a few minutes to start up on a screen that looks like: There is one useful user on the virtual machine, reviewer , with sudo privileges and password reviewer . When prompted for a login, enter these credentials and you should be presented with a desktop that looks like: The files for review are all in the directory /home/reviewer/lambda-py . The implementation and tests for \u03bb \u03c0 at artifact submission time are in lambda-py-artifact-submission . We focus on the current state of the implementation, which enjoys some significant improvements over the implementation at submission time. It passes all the same tests as the submission-time version and more (we include the version from submission time with instructions (at the end of this document) for completeness). Our first goal should be to simply verify that lambda-py runs. Open a terminal (\"Applications Menu\" at the top left, then \"Terminal Emulator\"), and let's first run a very small test so we can find out if anything goes wrong right away (if you have the opportunity to ask the authors for help, we're putting this here for quick diagnosis): $ cd lambda-py/lambda-py-artifact-submission/base$ echo \"print('lambda-py works')\" | racket python-main.rkt --interplambda-py works This will take a few seconds to run, and confirms that the \u03bb \u03c0 interpreter is up and running for you. Step-by-Step Instructions We've added new features since submission time, documented in CHANGES.txt. The new test cases are alongside the old in the tests/python-reference subdirectory of lambda-py-artifact-submission . So if you run the following, you will see more tests passing than the 175 we report in the paper: $ cd ~/lambda-py/lambda-py-artifact-submission/base$ racket python-main.rkt --test ../tests/python-reference/205 tests succeeded0 tests failed We provide a script called line_count.sh that uses CLOC to count the lines of code in each directory of python-reference . This compares the current state of the repository to the numbers reported in the paper in Figure 12 (the \"Built-in Datatypes\" count is the combination of the directories function, bool, builtin, tuple, lists, and dict, \"Iteration\" is the combination of directories iter and range, and \"(Multiple) Inheritance\" is the combination of directories super and multiple-inheritance). So, you can do: $ cd ~/lambda-py/lambda-py-artifact-submission/tests$ ./line_count.sh Feature# of testsLOCBuilt-in Datatypes81902Scope39455Exceptions25247Multiple Inheritance16303Properties9184Iteration13214Generators9129Modules658Total2052636 The repository is also set up to run all the same tests using Python. We've included an installation of Python 3.2.3 (the version we are modelling) in the VM, and these tests can be run with: $ cd ~/lambda-py/lambda-py-artifact-submission/base$ racket python-main.rkt --python-path ~/install-stuff/Python-3.2.3/python --test-py ../tests/python-reference Note: We drive the Python tester with Racket , passing the Python path as an argument. The implementation of our test harness performs the same directory traversal as when running with \u03bb \u03c0 , but runs with the Python executable, and checks standard out and standard error the same way. To go back in time and run all the tests that we report in the paper, you can visit the other pre-installed directory that contains the code from that time: $ cd ~/lambda-py/lambda-py-28-march-2013/base$ racket python-main.rkt --python-path ~/install-stuff/Python-3.2.3/python --test ../tests/python-reference/175 tests succeeded0 tests failed (We pass the Python path because we originally used Python to get the original Python AST for desugaring, and it has since been replaced. Also, the --test-py option, when run on the submission time code, reports 3 failures in the modules tests, this is an error in the test harness setting the working directory for Python. We have since fixed it.) That's enough to verify the test results reported in the paper, and some of what we've worked on since then. Looking Around Code from the paper Many of the discussions in the paper directly correspond to a few places in the code; it is useful to see how they translate. These are presented as links to Github sources, since they have a nice viewer for the files. The Redex definition of the language (which is also used to typeset the paper's code examples) is in lambda-py-core.rkt , and the definition of the reduction steps and related metafunctions (which are also used to typeset the semantics shown in the paper) are in lambda-py-reduction.rkt . The redex/ directory contains a number of tests for these. The interpreter implementation (dubbed \u03bb \u03c0\u2193 in the paper) defines its abstract syntax in python-core-syntax.rkt , which is simply an encoding in Racket structs of the AST from lambda-py-core.rkt . Similarly, python-interp.rkt is a (much) more efficient implementation of the reduction relation from lambda-py-reduction.rkt . A number of straightforward operator desugarings are in python-desugar.rkt . The composition of all the steps of scope desugaring is split between python-phase1.rkt , which marks global variables and instance variables from classes and rewrites class bodies, and python-phase2.rkt , which rewrites rewrites class bodies, eliminating instance variables and introducing bindings for local and global variables. These do other less fundamental work that doesn't appear in the paper for straightforward desugarings of default arguments and decorators. The CPS transformation and code for the skeleton in Figure 11 are in the file python-cps.rkt We try to push functionality out of Racket and into Python-implemented libraries (with some macros, as indicated in Section 6.2). These are in the base/pylib/ directory. For example the object and type base classes implement a large swath of built-in functionality; they are implemented in Python with macros for primitive operators, at type.py and object.py . As noted in the paper, \u03bb \u03c0 isn't quite to the point of running Python's full unittest library, so these tests use a limited language of assertions. For example, if we look at tests/python-reference/multiple-inheritance/methods.py , we see lines like: ___assertEqual(Foo.getx(foo), 1) ___assertEqual == base/py-prelude.py Playing around with \u03bb \u03c0 It's easy to tweak the Python-implemented libraries of \u03bb \u03c0 to see what their effects are on Python programs. Since these libraries implement so much built-in behavior, tweaking them can have interesting effects. You can run individual Python programs through \u03bb \u03c0 by passing them through standard input and using the --interp option: $ racket python-main.rkt --interp < some-python-file.py Some things you might try: Change the definition of the __str__ method in pylib/dict.py and run a simple program like print({'x':5}) . Change the definition of the __getitem__ method on a built-in type like pylib/list or pylib/dict and see the effects on lookup statements like print([1,2,3][0]) . Similarly, change __add__ or __sub__ and see the effect on + and - expressions. Change the behavior of the various __getattribute__ functions in pylib/object.py and see how it affects simple attribute lookup Building from Scratch These instructions are included so reviewers can see the build process for \u03bb \u03c0 on their own machines. Reviewers should be able to evaluate the artifact's adequacy relative to the paper from the VM, but a manual installation hopefully demonstrates that the artifact is easy to install and extend. The code for \u03bb \u03c0 is available at https://github.com/brownplt/lambda-py . We have two points in the repository's history that are interesting for this review: One at the time of our OOPSLA submission (28 March, 2013), and one at the time of our artifact submission (1 June 2013). The former is tagged in the repository as oopsla2013 , and the latter is the HEAD of the artifactevaluation branch (we'll push minor bugfixes here if any come up in the evaluation process, it contains this index file which isn't on the master branch, and if we do work and change master during the review process, we won't make breaking changes for the reviewers). Getting Racket Both require that you install Racket; the main download link at http://racket-lang.org/download/ has installers for many platforms. We have tested on several different Ubuntus from 11.04 to 12.10, and on OSX, with both Racket 5.3.3 and Racket 5.3.4. For review, we recommend Racket 5.3.4. Download the installer and run it; you can pick any of the options for installing Racket (for example, you can install UNIX-style in /usr/ , or keep the installation in your home directory). In the instructions that follow, we assume that the $PATH environment variable is pointing to the bin/ directory of the Racket installation that holds the raco and racket commands (this may be done for you automatically depending on which options you choose in the Racket installer). Example: $ wget http://download.racket-lang.org/installers/5.3.4/racket/racket-5.3.4-bin-i386-linux-ubuntu-karmic.sh$ sh racket-5.3.4-bin-i386-linux-ubuntu-karmic.sh Getting the Source of \u03bb \u03c0 Github is the easiest way to get a copy of the code: $ git clone https://github.com/brownplt/lambda-py BE AWARE: If you fork the repository on Github, it will leak your identity to us (it's up to you if that's a problem). Just using git clone (as above) won't. Artifact Submission-time Build Check out the artifactevaluation branch: $ git checkout artifactevaluation PLAI-Typed: \u03bb \u03c0 is built in a language that sits on top of Racket called plai-typed. We have it included with the repository as plai-typed-18Feb2013.plt in the root of the repository. To install it, use the raco command: $ raco setup -A plai-typed-18Feb2013.plt Ragg: Since publication, we had a third-party contribution of a pure Racket parser for Python (see this merge ). It uses the Ragg parser package for Racket; to install it, use the raco command: $ raco setup -A ragg-mangled.plt Building: The implementation of \u03bb \u03c0 is in the base/ directory. To build, simply use make : $ cd base $ make Running Use the same commands as above to run the tests (e.g. the commands with the --test option). Paper Submission-time Build We recommend using the provided virtual machine to review the code as it was at submission time, since it involves additional build steps that we have since made much easier. Python At the time of submission, we used Python's parser to get original ASTs for desugaring (we have since switched to a pure-Racket Python parser). So, to run tests at the oopsla2013 tag, you will also need to install Python3 (source is available at http://www.python.org/download/releases/3.2.3/ ). Example: $ wget http://www.python.org/ftp/python/3.2.3/Python-3.2.3.tgz$ tar xzf Python-3.2.3.tgz$ cd Python-3.2.3$ ./configure$ make To view the code as it was at submission time, check out the oopsla2013 tag: $ git checkout oopsla2013 PLAI-Typed: As in the instructions for the current build, install plai-typed with: $ raco setup -A plai-typed-18Feb2013.plt Running: To run the tests that were reported in the paper, run: # One additional build step:$ cd base/$ raco make python-main.rkt$ racket python-main.rkt --python-path ~/install-stuff/Python-3.2.3/python --test ../tests/python-reference/175 tests succeeded0 tests failed Where ~/install-stuff/Python-3.2.3/python is the path to your Python3 installation's python binary.", "https://cs.brown.edu/research/plt/dl/pldi2018/": "Inferring Type Rules for Syntactic Sugar Justin Pombrio and Shriram Krishnamurthi The paper The full version of the paper The artifact: https://github.com/brownplt/judgmental-resugaring/releases/tag/v1.1", "https://cs.brown.edu/research/pubs/techreports/reports/CS-20-01.html": "Tech Report CS-20-01 Fast and Accurate 4D Light Field Depth Estimation Numair Khan, Min H. Kim and James Tompkin August 2020 Abstract: We present an algorithm for accurate depth estimation from 4D light fields that runs almost an order of magnitude faster than classical methods. Our proposed approach use epipolar-plane image edges to estimate sub-pixel disparityat a small set of pixels in the 4D space. By optimizing constraints at these pixels we are able to diffuse the sparse set in an occlusion-aware manner to obtain dense disparity maps. Qualitative and quantitative results on both synthetic and real-world light fields show that we have comparable, or better performance than existing methods, while being significantly faster (8--11x) than current non-learning-based methods. (complete text in pdf )", "https://cs.brown.edu/research/thmon/thmon.html": "A Tool for Monitoring Multithreaded Program Performance Introduction. An overview ofThreadMon and its uses. The Solaris 2.5 Threads Library. A description of Solaris's many-to-many thread model implementation(including background information on other threads package implementation models ). ThreadMon. A description of thetool itself, including some implementation notes. References. Sources of moreinformation. Examples. Some examples of the types of problems ThreadMon can help identify. paper Bryan M. Cantrill Thomas W. Doeppner Jr. Greg Foxman ( gmf@cs.brown.edu )", "https://cs.brown.edu/research/plt/dl/quizius-2019/": "Harnessing the Wisdom of the Classes This page contains the supplemental materials for this SIGCSE 2019 paper by (S)am Saarinen , Shriram Krishnamurthi , Kathi Fisler , and Preston Tunnell Wilson . Answer input types columns (excel) Answer input types data (excel) Answer equivalences columns (excel) Answer equivalences data (excel) Answer prototypes columns (excel) Answer prototypes data (excel) Answers columns (excel) Answers data (excel) Completion records columns (excel) Completion records data (excel) Courses columns (excel) Courses data (excel) Enrollments columns (excel) Enrollments data (excel) Question input types columns (excel) Question input types data (excel) Question priorities columns (excel) Question priorities data (excel) Questions columns (excel) Questions data (excel) Quizzes columns (excel) Quizzes data (excel)", "https://cs.brown.edu/research/plt/dl/progressive-types/": "Progressive Types Joe Gibbs Politz, Hannah Quay-de la Vallee, and Shriram Krishnamurthi @inproceedings{politz:progressive-types, author = {Joe Gibbs Politz and Hannah Quay-de la Vallee and Shriram Krishnamurthi}, title = {{Progressive Types}}, year = 2012, booktitle = {{SPLASH/Onward!}}} The paper. (pdf) Update 13 May 2013: Updated versions of the proofs presented in the paper: (pdf) . The link below is included for reference. We fixed bugs in the Application and Substitution Lemmas. Original proofs for the type system presented in the paper. (pdf) The Redex model and mechanized proofs in Coq. (github) .", "https://cs.brown.edu/research/plt/dl/resugaring/v1/": "Resugaring: Lifting Evaluation Sequences through Syntactic Sugar Justin Pombrio and Shriram Krishnamurthi The paper: resugar.pdf The source code for Confection: confection.zip . (This is a snapshot of the brownplt/Resugarer repository on Github. The README is in the zipfile.) Partial proofs in Coq: coq.tgz . These are also available in the Confection repo above. The source code for Pyret with Confection attached is available on Github: brownplt/pyret-lang-resugarer .", "https://cs.brown.edu/research/plt/dl/sigcse2016plancomp/": "Modernizing Plan-Composition Studies: Supplemental Materials This page contains the problem statements and coding rubrics used in this SIGCSE 2016 paper by Kathi Fisler , Shriram Krishnamurthi , and Janet Siegmund . Problem Statements Here are the versions of the problem statements as handed out ineach course used in the study: Java version (English), used at the school labeled US1-IM in the paper Java version (German) [ Programming | Reviewing ], used at the school labeled GM-IM in the paper Racket version (English), used at the schools labeled US1-FP and US2-FP in the paper OCaml version (English), used at the school labeled FR-FP in the paper Coding Rubric This coding rubric details the datarecorded for each programming problem solution, including instructionsabout how to interpret solutions relative to each datum. This spreadsheet template has columns corresponding to the various data items described in thecoding manual. There is one sheet for each of the programming problemsinvolved in the study.", "https://cs.brown.edu/research/pubs/theses/ugrad/": "Undergraduate Honors Theses 2023 Ahluwalia.Anika The Role of Context and Demographics in Emotional Online Interpretation (519.9 KB) Chang.Adrian Neuro Symbolic Methods for Indoor Scene Synthesis (2.1 MB) Foiani.Michael Interactive Branching Presentation Trails (24.1 MB) Gross.Hannah Funhouse: A Hall of Mirrors Database so Good That Even People on the Inside Can\u2019t See the Truth (772.7 KB) Handa.Kunal How does environment understanding emerge in transformer-based policy networks? (76.0 KB) Kobayashi.Momoka Evaluation of Explainability Methods on Single-Cell Classification Tasks Using Graph Neural Networks (677.5 KB) Levy.Amanda Mental Health and Innovative Technologies: The Use of Virtual Reality to Address Post-Traumatic Stress Disorder and Anxiety Disorders (387.1 KB) Li.Jessica Compositional Reasoning in Vision-Language Models (755.8 KB) Ma.Rachel Skill Generalization With Verbs (1.2 MB) Manjal.Anoop Examining the Antibody Response From a Covid-19 Booster Shot in Immunocompromised Patients. (566.7 KB) Mapeke.Marc Flowed Flight Fields: Dynamic View Synthesis and Time-of-Flight Corrections Under Motion (5.8 MB) Patel.Shalin Interpretability in Graph Neural Networks (29.1 KB) Rajesh.Sreshtaa Using Dependency Analysis and SAT Solving to Communicate Privacy Problems in Code (1.3 MB) Riya.Dulepet Using Dependency Analysis and SAT Solving to Communicate Privacy Problems in Code (3.1 MB) Roberts.Geireann Lindfield A User-Controlled Document Recommendation System for Knowledge Workers (4.6 MB) Thakkar.Nitya Using Graph Neural Networks to Model the Glioblastoma Free Energy Landscape (3.4 MB) Venkatachalam.Harshini Exploratory Analysis and Clustering of COVID-19 and Intellectual Developmental Disorders in Electronic Health Record Data (630.3 KB) Wang.Yuanhao On Human-like Biases in Deep Neural Networks for the Perception of Slant from Texture (8.0 MB) Yalavarti.Arvind Observatory: Fast and Scalable Systems Observability (1.1 MB) Yi.Xinjie Anonymous CVPR submission (3.6 MB) Yuan.Andrew Prompting and weak supervision (255.3 KB) Zhan.Xiao CharacterMixer: Rig-Aware Interpolation of 3D Characters (5.6 MB) Zhou.Zhiyuan Skill Generalization with Attention-Based Ensemble in Lifelong Reinforcement Learning (1.5 MB) 2022 Asif, Muhammad Haider Beyond DNA methylation: chromatin age of human tissues (1.6 MB) Bers, Tali Effects of Target Words and Their Locations in Prompts (3.0 MB) Bhalla, Usha Do Vision-Language Pretrained Models Learn Primitive Concepts? (2.7 MB) Chairattana-Apirom, Rutchathon Compact Cut-and-Choose: Boosting the Security of Blind Signature Schemes, Compactly (556.8 KB) Chen, Qianfan Language Levels in Teaching an Introductory Formal Methods Course (1.3 MB) Ciabaton, Jack Cost Function Based Prediction Markets Aggregate Risk-Averse Experts' Beliefs as Opinion Pools (552.1 KB) de Campos, Jackson Best Response in Alternating-Offers Negotiation (4.4 MB) Espiritu, Zachary Time- and Space-Efficient Aggregate Range Queries over Encrypted Databases (630.1 KB) Givertz, Benjamin Incremental Exception Resolution in Tuplex (1.9 MB) Idehen, Jordan Evaluating Machine Learning Methods for Predicting Gene Expression from Epigenetic Glioblastoma Data (816.9 KB) Ivanov, Alexander Discovering Options that Minimize Average Planning Time (2.9 MB) Kim, Jung Yeop Designing an Actuated Walker for Improving User Stability (2.2 MB) Laidlaw, Eliot Towards a More Object-Centric Dynamic Scene Reconstruction Model (30.4 MB) Lim, Jing Wei Nicholas Termination Classifiers for Image-Based Observation Spaces (2.8 MB) Ninagawa, Kotone Strategies in Automated Negotiation Against Time-based Opponents (1.4 MB) Pikielny, Adam Consistent Depth Estimation for Video (11.7 MB) Polatty, Jacob Securing Veracity: Defenses Against the Pervasive Influence of Social Media (1.0 MB) Randolph, John Banzhaf Power in Hierarchical Games (839.9 KB) Roy, Monica Task Specification in LTL with Quantifiers for Robotic Instruction Following (247.8 KB) Sachan, Kshitij Learning a Distance Metric over Markov Decision Processes (4.8 MB) Sharma, Gaurav and Glass, Geoffrey Handling Concept Drift in Weakly Supervised Learning (843.2 KB) Smits, Daniel The Data Structure of Ad-Hoc Alternatives (866.5 KB) So, Leonard Learning to Optimize (L20) (304.4 KB) Srivastava, Aryan Examining the effects of the like-dislike ratio on users' consumption of and interaction with political content on YouTube (340.2 KB) Syed, Sara Understanding and Increasing Empathy in Online Text-Based Peer Support Systems (1.5 MB) Trotz, Caleb Disentangling Levels of Detail in Implicit Shape Generation with Explicit Bounding Proxies (1.1 MB) Tung, Nathan Neuro-Hotnet: A Graph Theoretic Approach for Brain FC Estimation (4.4 MB) Wang, Jeremy Interpretable Modeling of Cellular Perturbations (403.9 KB) Yu, Jacob Towards Social Video Verification to Combat Deepfakes via Deep Learning (16.1 MB) Zaki, Hossam Predicting Cell Type and Extracting Key Genes using Single Cell Multi-Omics Data and Graph Neural Networks (416.8 KB) Zhang, William Learning Relabelled Convex Combinations of Weak Labellers (2.6 MB) 2021 Berg, Matthew Natural Language to Long-Range Robot Navigation in Outdoor Environments (16.7 MB) Blinn, Bryce Functional Chair Programs in ShapeAssembly (5.2 MB) Gonzalez, Lucia Regina Reyes What You See Is Not Always What You Get: An Analysis of Informative Graphs in Formal Methods Languages (14.5 MB) Jurayj, William Scaling Bias in Journalism using Contextual Embeddings (1.4 MB) Milefchik, Isa Interactive Image Synthesis Using a Latent 3D Gaussian Model (15.8 MB) O'Halloran, Amelia The Technical, Legal, and Ethical Landscape of Deepfake Pornography (1.7 MB) Pal, Koyena The Effect of Multi-Document Summarizations on User SERP Experience (1.1 MB) Sam, Dylan Learning from Dependent Weak Supervision Sources (1.4 MB) Walke, Homer Learning Finite Linear Temporal Logic Formulas (669.6 KB) 2020 Baruah, Prakrit Predicting Hospital Readmission using Unstructure Clinical Note Data (729.7 KB) Bayazit, Deniz Generalizing Natural Language Instruction Following to Aerial Robots and Arbitrary Environments (4.9 MB) Christ, Miranda New Lower Bounds on the Complexity of Provably Anonymous Onion Routing (608.6 KB) Galgana, Rigel Optimal Reserve Price Estimation in the Generalized First and Second Price Auctions with Best Response Dynamics (1.8 MB) Guo, Erica Information Retrieval for Genetic Mutations and Diseases (968.8 KB) Huang, Amy Mystery Functions (1.0 MB) Huang, Shawna Downstream Effects of the Brown Computer Science Introductory Sequences (4.1 MB) Jha, Rohan Data augmentation and the role of hardness for feature learning in NLP (853.1 KB) Levin, Joshua ViperProbe: Using eBPF Metrics to Improve Microservice Observability (4.0 MB) Ouyang, Kevin Self-E: Procedurally Guided Self-Experiments for Novice Health Hackers (1.9 MB) Renshaw, Lena Determining which Sentiment Analysis Predictive Model to use for a given Social Media Election Dataset (981.0 KB) Simons, Shoshana What Communication Complexity Can Tell Us About Circuit Complexity (199.5 KB) Stone, Henry Transparent Voxelized Geometry Representations for Machine Learning (18.0 MB) Tu, Karen Explaining Black Box Models for Document Retrieval (1.3 MB) Wagner, Andrew Where to Begin? Synthesizing Initial Configurations for Cellular Automata (382.1 KB) 2019 Ball, Michael RIPPED: Recursive Intent Propagation using Pretrained Embedding Distances (1.9 MB) Brennan, Nathaniel Remote Object Fetching with Descriptive Question Asking (339.1 KB) Chaudhry, Abraar Uncertainty Quantification for Robust Classification (1.7 MB) Diwan, Renuka The Effect of Rural Road Development on Hospital Births: Evidence from India (656.2 KB) Farley, Edwin Missing Data Methods when Values are Missing Together: A Simulation-Based Examination of Joint Modeling and Fully Conditional Specification Imputation Schemes (289.4 KB) Fong, Grant Direct Message Extraction for Automatic Emotional Inference and Drug Detection (838.3 KB) Gleyzer, Leonard Weakly-Supervised Classifier Learning via Temporal Logic (1.1 MB) Guerrant, Elisa Hardening the Linux Kernal Key Retention Service against Information Disclosure Vulnerabilities (615.8 KB) Jiang, Elaine Practicing in Virtual Reality Improves Mental Rotation Ability: Lower Scorers Benefit More (626.3 KB) Kasser, Lucas Lightfield Superpixel Segmentation and Segmentation-Based Editing (23.3 MB) Li, Michael Natural Language Understanding within the context of Question Matching (841.6 KB) Murphy, Daniel Markerless 3D Pose Estimation from RGB Data (667.5 KB) Nadimpalli, Shivam Discrete Isoperimetry and Protein Folding (1.8 MB) Ramos, Jerome Explainability in Transparent Information Retrieval Systems (711.9 KB) Romano, Joseph WebMesh: A Browser-Based Computational Framework for Serverless Applications (277.7 KB) Roy, Josh Learning Feature Extraction for Transfer from Simulation to Reality (3.4 MB) Servan-Schreiber, Sacha Cryptographically Certified Hypothesis Testing (1.1 MB) Shteinfeld, Benjamin LibFilter: Debloating Dynamically-Linked Libraries through Binary Recompilation (122.9 KB) Turcu, Adrian Protein Folding Prediction and Visualization Techniques Based on Hydrophobic Side Chain Interactions (5.3 MB) Weir, Nathaniel Bootstrapping Generalization in Neural Text-to-SQL Semantic Parsing Models (1.3 MB) Zhang, Aaron Proofs of sequential work with unique proofs (479.9 KB) 2018 Gadre, Samir Teaching Robots Using Mixed Reality (6.1 MB) Guo, Yue (Sophie) Finding Optimal Strategies over Families of Tasks in Reinforcement Learning (909.4 KB) Hou, Andrew Light Field Super Resolution with Convolutional Neural Networks (3.2 MB) Karamcheti, Siddharth Grounding Natural Language to Goals for Abstraction, Generalization, and Interpretability (1.8 MB) Kim Jr., Isaac Advancing Precision Medicine - Investigating The Relationship Between Race, Comorbidities, and Cancer Through Network Analysis (20.2 MB) Kubala, Vincent Inferring the Intentions of Learning Agents (265.0 KB) Lightsey, Connor Restricted Transactional Memory and SkipLists (339.7 KB) Picard, Noah Smooth Segmentation in Videos: Blind Consistency Over Semantic Segmentations Produced by Fully Convolutional Networks (21.6 MB) Porncharoenwase, Sorawee An Inside-Out Resugaring System (338.4 KB) Pratt, Sarah A Machine Learning Approach to Improve Automated Kinematics Tracking of Non-Human Primates (4.9 MB) Sanford, Clayton Applying Rademacher-Like Bounds to Combinatorial Samples and Function Selection (719.5 KB) Shi, Di Yang (Steven) An Exposition of Adversarial Examples in Neural Networks (8.3 MB) Whang, Sungseob Exploiting Timing Violations under Voltage Scaling with Hardware Transactional Memory (2.6 MB) 2017 Chen, Frances Exploring the Conversion of Videos into 3D Models (14.2 MB) Chitra, Uthsav Random Walks on Hypergraphs with Applications to Disease-Gene Prioritization (904.6 KB) Cunningham, Nick Two-Party Generation of Shared RSA Keys through Encryption Switching Protocols (218.5 KB) Jayaram, Rajesh Learning Stochastically Evolving Networks via Local Probing (831.5 KB) Liu, David Nonparametric Clustering with Variational Inference for Tumor Heterogeneity (2.9 MB) Perera, Sudheesha A Haplotype-Based Predictive Model for Genotype/Expression Datasets (878.8 KB) Vemuri, Keshav Growth Rate of the Cube Recurrence (429.8 KB) 2016 Hoff, Timothy Adam Extending Open vSwitch to Facilitate Creation of Stateful SDN Applications (119.9 KB) Kim, YounHun Algebraic Connectivity of Graphs, with Applications (309.5 KB) Nado, Zachary Deep Recurrent and Convolutional Neural Networks for Automated Behavior Classification (2.8 MB) Sachs, Sarah Similar-Part Approximation Using Invariant Feature Descriptors (4.5 MB) Thompson, Joseph Recent Applications in Mechanism Design (252.8 KB) Wallace, Henry Clustering of Musical Genres (980.3 KB) 2015 Acheson-Field, Hannah Reconstructing Clonal Trees From Multi-Sample Sequencing Data (1.2 MB) Correa Orozco, David TeachWithGlass: Improving the Teaching Experience through Google Glass (509.1 KB) Eldon, Miles Incrementally Interpreting Multimodal Referring Expressions in Real Time (4.6 MB) Hershkowitz, D. Ellis Leveraging and Learning Propositional Functions for Large State Spaces in Planning and Reinforcement Learning (5.1 MB) Light, Alex Reenix: Implementing a Unix-Like Operating System in Rust (335.3 KB) Lu, Jeffrey Avoiding Parameter Overfitting in a Monte Carlo Approach to Real-Time Strategy Games (329.8 KB) Metaxa-Kakavouli, Danae SleepCoacher: Combining Computational and Clinician-Generated Sleep Recommendations (3.2 MB) Phene, Sonia Parallelization of Variational Inference for Bayesian Nonparametric Topic Models (506.0 KB) Schvimer, Judah Take the First Right and Go Straight Forever: Novel Planning Algorithms in Stochastic Infinite Domains (429.0 KB) Siranosian, Benjamin A Multi-scale Ensemble Model of Chromatin Conformation (1.7 MB) Steen, Frances Teleportation as a Strategy for Improving Concurrent Skiplist Performance (476.2 KB) Stephenson, Will Variational Inference for Hierarchical Dirichlet Process Based Nonparametric Models (3.0 MB) Wu, Chenggang Nested Transaction: An Efficient Facility to Enforce the Nesting and the Partial Ordering Requirements in S-Store (1.1 MB) Yauney, Gregory Artificially and (Hopefully) Intelligently Modeling Program Synthesis: Planning in a Large, Strange State Space (232.5 KB) 2014 Aebi, Bryce Peernote Status Report Boreiko, John Implementation Analysis of Haze Protocol Frantz, Jacob Dynamic Resolution Fluid Simulation by Spectral Methods Herlihy, Anna Compilation Techniques for Distributed Analytics Hou, Ning Two Problems Related to cis-Regulatory Architecture of Transcription Factor Encoding Genes: Homologous Translation and Evolutionary Conservation-Based cis-Module Inference Hsiao, Vivian Network Constrained Regression Jain, Vishesh Network-Based Analyses of Pathological Gene Pathways in Neuropsychiatric Disorders (546.4 KB) Janthong, Abhabongse Streaming Algorithm for Determining A Topological Ordering of a Digraph (411.8 KB) Leavitt, Jonathan End-to-End Tracing Models: Analysis and Unification Wald, Elias A More Performant List Under Concurrent Environments Using Hardware Support for Transactional Memory 2013 Clay, Patrick Discovery of Mutated Collections of Genes Associated with Survival in Cancer Using Local Search (182.0 KB) Kang, Jung Uk Computational Modeling of Scene-selective Visual Neurons in area LIP (Lateral Intraparietal) (1.3 MB) Karumbunathan, Aswin Using Predictive Models for Compression in Database Systems (597.4 KB) Lauria, Kshitij Combinatorial Algorithms for Bipole Self-Assembly on Lattices with Applications to the Lipid Bilayer (522.7 KB) Malkin, Nathan Waiting Makes the Heart Grow Fonder and the Password Grow Stronger (298.6 KB) McErlean, Doug One Constraint to Rule Them All: How to simplify optimizations under constant variable sum, with applications for maximum likelihood (311.2 KB) Storch, David Towards an Intelligent Bidding Agent in QuiBids Penny Auctions (453.3 KB) Tremel, Edward Real-World Performance of Cryptographic Accumulators (747.5 KB) Zweig, Jonathan Procedural Architectural Facade Modeling (2.0 MB) 2012 Boger, Sam Defense Against the Dark Arts: An Approach to Introductory Computer Security Education (433.0 KB) Bressler, Garrett Software Transactional Memory in the Linux Kernel (954.2 KB) Changpinyo, Soravit Learning Image Attributes using the Indian Buffet Process (2.5 MB) Franco, Jacob Cryptic Population Substructure and Fuzzy Clustering (1.5 MB) Gillani, Nabeel Joint Assessment and Restoration of Power Systems (2.4 MB) Herman, Jeffrey A Markov random field model for inferring population structure (731.0 KB) Ryza, Sandy Solving Hard Problems with Lots of Computers (455.2 KB) Stix, Eric An Empirical Study of Online Penny Auctions (202.8 KB) Stix, Jeffrey Designing a Bidding Algorithm for Online Penny Auctions (302.8 KB) Weis, James Computational Genomics and Bioenergy: Modeling and Clustering of RNA-SEQ Data (1.0 MB) 2011 Donahue, Evan Searching for the Blackbox: Unsupervised Recovery of Relational Schema from Unstructured Airplane Crash Reports (259.4 KB) 2010 Mustacchi, Robert StashFS: Generalized Disconnected Operation (237.4 KB) Saftoiu, Claudiu JSTrace: Run-time Type Discovery for JavaScript (268.1 KB) Stewart, Allan Face-center cubic (FCC) lattice models for protein folding: energy function inference and biplane packing (657.9 KB) 2009 Cheever, Elizabeth One Dimensional Simulations of Cerebral Blood Flow (3.6 MB) Fischer, Travis Milton (6.5 MB) Franks, Alexander An Efficient Image Search Algorithm For Object Feature Identification in Biological Vision (525.5 KB) Lapping-Carr, Micah RGame: A Video Game for Interactive Robot Learning (4.2 MB) 2008 Baskin, Jacob Comparing Apples and Oranges: Using Consensus Rankings for Decision Support (141.7 KB) Cunningham, Sam Predicting when seam carved images become unrecognizable (4.9 MB) Diamond, Brandon [incr Insight] An easy to use, easy to extend module system for Insight/GDB (353.8 KB) Garton, Lian An Investigation of Population Subdivision Methods in Disease Associations with a Focus on Markov Chain Monte Carlo (208.3 KB) Gordon, Colin Stebbins Type-safe Stack Traversal for Garbage Collector Implementation (313.3 KB) Panda, Aurojit An Empirical Study of Structural Symmetry Breaking (267.4 KB) Quirk, Lincoln Ownership of a queue for practical lock-free scheduling (146.6 KB) Winograd-Cort, Daniel Deducing Relevant Bridge Bidding Information from Double Dummy Data (1.6 MB) 2007 Austerweil, Joe A Unified, Global and Local, Hierarchical Generative Document Ordering Model (249.4 KB) Greenberg, Michael Declarative, composable views (156.5 KB) Lee, Seong Jae Comparison of Bidding Algorithms for Simultaneous Auctions (454.7 KB) Meyerovich, Leo Flapjax: Functional Reactive Web Programming (709.4 KB) 2006 Ballard, Lucia Conflict Avoidance: Data Structures in Transactional Memory (213.4 KB) Chang, Edwin Sketching Articulation and Pose for Facial Meshes (1.6 MB) Tse, Ronald Henry TCP Fairness in Multipath Transport Protocols (1.6 MB) 2005 Arnaudov, Vesselin Unified Management of Heterogeneous Sensor Networks In the Atlantis Framework (239.3 KB) Bookstaber, Daniel Using Markov Decision Processes to Solve a Portfolio Allocation Problem (532.5 KB) Bromberg-Martin, Ethan Partial-Order Alignment of RNA Structures (1.5 MB) Kern, Edward The Crunch Mobile Robot (426.8 KB) Lee, Stephanie Quantitative Metrics for White Matter Integrity Based on Diffusion Tensor MRI Data (608.6 KB) Sakai, Haruyoshi Internet Poker: Data Collection and Analysis (1.4 MB) Taubman, Gabriel MusicHand: A Handwritten Music Recognition System (419.8 KB) Tom, Nancy GuShi: An Innovative Multimedia Program Implementing Traditional Textbook Methods for Teaching Intermediate Second Language Learners (442.4 KB) Tschantz, Michael The Clarity of Languages for Access-Control Policies (205.7 KB) Ye, Jason Atlantis: Location Based Services with Bluetooth (248.2 KB) 2004 Benisch, Michael Optimization Under Uncertainty in Online Trading Agents (252.1 KB) Licata, Daniel Verifying Interactive Web Programs (509.9 KB) 2003 Blundell, Colin A Constraint-Based Approach to Open Feature Verification (230.6 KB) Egan, Kevin Techniques for Real-Time Rigid Body Simulation (397.3 KB) Eigen, David Java Demonstration Software for Differential Geometry and Polyhedral Theories (191.9 KB) Finkel, Benjamin Curvilinear Graph Drawing Using The Force-Directed Method (135.5 KB) Ho, Kate Data Replication under Latency Constraints (340.7 KB) Huang, Albert Ad-hoc Collaborative Document Annotation on a Tablet PC (221.8 KB) Kern, Josh Aurora Performance Monitoring Tool Programmer's Guide (355.1 KB) Lederman, Roger Optimization of Stochastic Inventory Control with Correlated Demands (159.7 KB) McClain, Andrew W. CaveSculpture: Creating sculpture from CavePaintings (691.5 KB) Pytlik, Brock Automatic Debugging Using Potential Invariants (833.6 KB) Schrock, Eric Dynamic Lock Dependency Analysis of Concurrent Systems (333.3 KB) Sigelman, Ben Video-Based Tracking of 3D Human Motion Using Multiple Cameras (12.0 MB) Straub, Christian D. Authentication of Embedded Data in HTML Documents through the Use of Prooflets (379.1 KB)", "https://cs.brown.edu/degrees/undergrad/extended.html": "Our Fifth Year And Alternative Master's Options Staying A Fifth Year A student earning an ScB in one field (for example, computer science) and an AB in another (for example, economics) is permitted to stay an extra year if needed to finish up concentration requirements. The student must pass a minimum of 38 courses and declare their intent to stay for a fifth year by their fifth semester. Another option (please see below) is to earn a Master's degree. Earning A Fifth-Year Master's Degree Brown has three programs under which an undergraduate can stay for a fifth year to earn a Master's degree: The Master of Science in Cybersecurity is the only program of its kind in the Ivy League, a fully online degree designed to bring together students from all over the world. Cybersecurity at Brown is rooted in the University\u2019s interdisciplinary approach to learning and solving problems and participants will attend the same classes as in-person students, graduating with a sophisticated understanding of subjects like cryptography, network security, and cloud security. Click here to learn more and here to apply. The Fifth-Year Master's Degree program allows students, after completing their Baccalaureate degree, to continue at Brown for a Master's degree and use courses taken while an undergrad to satisfy two of their Master's course requirements. Applications open in mid September. Students completing their undergraduate degree requirements in December or May must apply by May 1 of that academic year for entry into the program in September. In addition, students who complete their undergraduate degree requirements in December may opt to apply by October 15 for entry into the program the following January. To apply, go to https://apply.professional.brown.edu/apply and indicate on your application that you're a current Brown senior. [This last instruction will soon change.] Of the eight courses used to satisfy the Master's degree requirements, two may be completed while the student is an undergraduate, even if they are also used to satisfy undergraduate concentration requirements. At least six semester courses must be taken while in residence as a master's student; the student should complete their graduate study in two semesters. While a student must be enrolled as an active undergrad student at the time of application, admission to the master's program can be deferred for up to two years with approval of the department's director of graduate studies (master's). The Concurrent Baccalaureate/Master's Degree program (click here to apply) allows exceptionally capable students to combine their last year or two of undergrad study with grad study, resulting in the simultaneous completion of both a Baccalaureate degree and a Master's degree. Students must apply for this program during their junior year. Their applications must be first approved by the Committee on Academic Standing, which will ascertain that the student's academic performance has been outstanding and that the student's undergrad program is sufficiently broad (normally meaning taking at least ten courses outside their fields of concentration). Applications then must be approved by the Graduate Council and the appropriate department, which may place additional requirements on admission to this special program. The candidate must complete a minimum of thirty-six courses within eight or nine semesters and complete the requirements of both the Baccalaureate degree and the Master's degree. No more than two courses may be used to satisfy both Baccalaureate concentration requirements and Master's requirements. Brown CS permits only those students pursuing an ScB in any of its concentrations to obtain a concurrent Baccalaureate/Master's degree.", "https://cs.brown.edu/video/171/": "Susanne Schennach, Brown University <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/f/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/f/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/f/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/f/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 10:17 a.m. Duration 0:49:48 \"Learning from Errors\" Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/f/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/f/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/f/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/f/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/video/173/": "Vincent Crawford, Oxford University <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/h/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/h/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/h/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/h/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 10:35 a.m. Duration 1:38:27 \u201cEfficient Mechanisms for Level-k Bilateral Trading\u201d Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/h/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/h/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/h/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/h/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/video/172/": "Mark Satterthwaite, Northwestern University <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/g/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/g/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/g/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/g/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 10:25 a.m. Duration 0:57:02 \"Designing Economic Institutions: Accomplishments and Constraints\" Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/g/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/g/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/g/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/g/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/about/system/services/files/filesystem/backups/snapshots/": "Snapshots Introduction The CS Department uses a GPFS (General Parallel File System) file server to provide network file service to both Unix and Windows clients. This server has a feature known as snapshots which allows for file recovery of recently changed or deleted files. On our system, snapshots are enabled for the main filesystem (which includes the /admin, /course, /home, and /research directories). This document will show you how this mechanism works and how to use it. How does it work? A snapshot is a read-only copy of all the files and directories in the filesystem. The server creates a snapshot every four hours. Snapshots can be accessed as quickly and easily as the live filesystem from the .snapshots directory in every directory. Snapshot directories are named for the (GMT) time the snapshot was taken. On disk we keep the most recent six snapshots, the last seven snapshots taken at midnight, and the last four snapshots taken at midnight on Sundays. This means that the live filesystem will have backups going back about a month. The snapshot mechanism is independent of our normal tape backup mechanism, which goes much further back. Using Snapshots How you use the snapshots depends on whether you're using Windows or Unix . For more information See the Backups, Restores, and Snapshots page for more information.", "https://cs.brown.edu/degrees/undergrad/jobs/": "Undergraduate Jobs There are many opportunities for undergraduates to work in the department. (This page only contains Computer Science department-specific opportunities\u2014see the Student Employment Office for other student jobs at Brown.) In addition to working as consultants, working for the UTA program, and working with the technical staff, there are also opportunities for undergraduates to assist with or conduct their own research. Note that most of these positions are hired regularly, but some become available on a less predictable basis. Check the individual pages, which should provide information about hiring and which faculty or staff person you should contact. Undergraduate Research Undergraduate Research Assistantships (URAs) : Several undergraduates in the Computer Science department routinely assist with (or even conduct their own) research. Undergraduates generally receive academic credit for research work (but, in some cases, can receive pay). Meta Undergraduate Research Assistants (MURAs) : MURAs help coordinate undergrad research opportunities in the department. They answer questions about research, advertise research opportunities for semester and/or summer positions, and host various outreach events throughout the semester to encourage students to get involved with research. MURAs are compensated for their work with pay. Teaching Assistant (TA) program Head Teaching Assistants (HTAs) : HTAs work with professors to coordinate many aspects of a course and manage a staff of UTAs if the course has any. An HTA\u2019s role can be very different from a UTA. HTAing often requires more attention to administrative details, organization, and often is a greater time commitment. Being an HTA really gives you the chance to shape a course and work closely with a professor. Shortly after being hired, HTAs begin coordinating the process of hiring UTAs (if the course has any). HTAs are compensated for their work with their choice of either credit or pay (or, in some cases, a combination of both). Teaching Assistants (UTAs) : UTAs work with professors and HTAs to support one of the department's courses during the semester. UTA's responsibilities typically include holding TA hours, grading assignments, writing/revising course assignments and materials, working on lecture slides, preparing support code or demos of programs, attending class, and in some cases, presenting supplemental materials for the class. UTAs are compensated for their work with their choice of either credit or pay (or, in some cases, a combination of both). Meta Teaching Assistants (MTAs) : MTAs work in conjunction with the Director of Undergraduate Studies to coordinate the TA Program and several other department-wide activities. Responsibilities include overseeing HTA, UTA, and STA hiring and training, managing TA program resources, and providing logistical and technical support for the program as a whole. MTAs are compensated for their work with pay. Socially Responsible Computing Teaching Assistants (STAs) : STAs (formerly known as ETAs) work directly with professors, HTAs, and the Head STAs to identify social issues relevant to their designated course, communicate with course staff, study the course structure, and collaborate with course staff to develop a curriculum plan for socially responsible computing content. STAs directly report to their course's HTA and the HSTAs, and their responsibilities also may include writing new assignments and grading STA-specific content for their course. STAs are compensated for their work with pay. Head Socially Responsible Computing Teaching Assistants (HSTAs) : HSTAs (formerly known as EHTAs) work in conjunction with the Department Chair to coordinate the STA Program. They also organize several department-wide events related to ethics in Computer Science and socially responsible computing. HSTAs are compensated for their work with pay. Technical Staff Sunlab Consultants : The Sunlab Consultants are paid to watch over the undergraduate computing labs and to help people use their accounts. The consultants provide support for remote login (via SSH and FastX) and various programs on the ugrad Linux systems that are commonly used by CS courses at Brown. Sunlab Consultants report to the Head Sunlab Consultants . They are compensated for their work with pay. Head Sunlab Consultants : Head Sunlab Consultants work in conjunction with the Director of Information Technology ( John Bazik ) and the Project and Finance Manager ( Kathy Kirman Billings ) to manage the Sunlab Consultants. They are hired from the pool of Sunlab Consultants when a Head Sunlab Consultant opening arises. Head Sunlab Consultants are compensated for their work with pay. Systems Programmer, Operator, and Consultants (SPOCs) : SPOCs work as fully-fledged members of the department's Technical Staff (\"tstaff\") and assist in the installation, maintenance, development, and documentation of local software. In addition, they represent the off-hours technical support staff and assist with administrative tasks. The SPOCs report to the Director of Information Technology ( John Bazik ) and the Project and Finance Manager ( Kathy Kirman Billings ). SPOCs are compensated for their work with pay. Student Advocates Diversity and Inclusion Student Advocates (D&I Advocates) : D&I Advocates work in conjunction with the Financial and Outreach Coordinator to identify and advocate for change regarding academic and social diversity issues in the Computer Science department, with the goal of increasing the retention number of students from historically underrepresented groups in Computer Science. D&I Advocates are compensated for their work with pay. Health & Wellness Student Advocates (H&W Advocates) : H&W Advocates work in conjunction with the Financial and Outreach Coordinator to aim to improve the mental and physical health with the CS department on an individual and systemic level, as well as increase the sense of departmental community. In addition, they serve as resources that can direct students to campus resources that are relevant to the issues or pressures they may be facing. H&W Advocates are compensated for their work with pay.", "https://cs.brown.edu/video/174/": "Panel Discussion/Sweat-Box Session with Professors Satterthwaite and Crawford <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/j/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/j/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/j/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/j/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 10:48 a.m. Duration 0:59:54 Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/j/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/j/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/j/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/j/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/degrees/undergrad/jobs/consult/": "Sunlab Consultants The consultants support the machines and users in the Sunlab and the MSlab . The consultant on duty sits at 9a, the machine nearest the door when you enter the Sunlab. The consultants also maintain other labs throughout the department when there is need. CIT 201 is currently used for this purpose. The Project and Financial Manager and head consultants manage the Sunlab, MSlab, and the student consulting staff. New consultants are hired for the following year each spring semester. Hiring is conducted by the Project and Financial Manager and head consultants . Occasionally, if vacancies need to be filled, one or more additional consultants will be hired in December. Schedule Consultant Hiring Schedule Sunlab consultant applications are currently open! Click here to apply. Current Consultants Name: Login: Nicholas Vadasz nvadasz Richard Tang rtang26 Dylan Hu dhu24 Adam Bredvik abredvik Nick Bottone nbottone Melvin He mhe36 Damir Kulzhanov dkulzhan Christian Armstrong carmstr8 Alexander Mazansky amazansk", "https://cs.brown.edu/video/175/": "Freeman Dyson, Institute for Advanced Study <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/k/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/k/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/k/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/k/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 11:01 a.m. Duration 0:51:35 \"The Blacksmiths'' Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/k/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/k/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/k/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/k/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/video/176/": "Nima Arkani-Hamid, Institute for Advanced Study <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/l/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/l/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/l/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/l/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 12:17 p.m. Duration 1:19:10 \"Quantum Mechanics and Space-Time in the 23rd Century\" Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/l/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/l/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/l/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/l/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/video/177/": "Leon Cooper, Brown University <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/m/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/m/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/m/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/m/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 2:28 p.m. Duration 0:39:12 \"Can Free Will and Locality Exist Together in the Quantum Theory?\" Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/m/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/m/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/m/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/m/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/video/178/": "Frank Wilczek, MIT <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/n/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/n/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/n/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/n/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 2:30 p.m. Duration 1:03:55 \u201cPhysics in 100 Years\u201d Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/n/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/n/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/n/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/n/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/video/179/": "Panel Discussion/Sweat-Box Session with Professors Dyson, Arkani-Hamid, Wilczek, and Cooper <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/p/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/p/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/p/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/p/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 2:35 p.m. Duration 0:49:24 Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/p/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/p/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/p/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/p/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/video/180/": "Marina von Neumann Whitman, University of Michigan <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/q/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/q/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/q/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/q/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 2:37 p.m. Duration 0:17:23 \u201cA View from Johnny\u2019s Daughter\u201d Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/q/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/q/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/q/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/q/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/video/181/": "Michael Jordan, University of California <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/r/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/r/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/r/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/r/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 21, 2015, 8:47 a.m. Duration 1:42:26 \"Computational Thinking, Inferential Thinking and \u2018Big Data\u2019\u201d Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/r/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/r/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/r/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/r/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/video/182/": "Tom Leighton, MIT, Akamai Technologies <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/s/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/s/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/s/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/s/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 21, 2015, 8:58 a.m. Duration 1:00:40 \"Grand Challenges Facing the Internet\u201d Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/s/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/s/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/s/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/s/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/research/pubs/theses/masters/": "Master's Project Reports 2023 Chen, Catherine Evaluating Search Explainability with Psychometrics and Crowdsourcing (2.6 MB) Chen, Yiwen and Ren, Jiahao CLIP NeRFlica: Unsupervised Semantic Recognition of Room-scaled Scenes (4.2 MB) Chernosky, Brynn Physics Simulations in the Dash Hypermedia System (1.1 MB) Christou, Neophytes Preventing Speculative Probing Attacks (246.5 KB) Dekle, Max Quantifying Static Privilege Reduction in External JavaScript Libraries (110.1 KB) Demetci, Pinar Statistical and Cominatorial Methods to Predict Gene Expression and Identify eQTLs from Haplotype Sequences (2.7 MB) Fu, Changcheng Prompt-based Object-centric Video Representation for Action Anticipation (7.0 MB) Fu, Haotian Model-based Lifelong Reinforcement Learning with Bayesian Exploration (2.2 MB) Goktas, Denizalp T\u00e2tonnement in Homothetic Fisher Markets (702.1 KB) Golovanevsky, Michal Multimodal Attention-based Deep Learning for Alzheimer's Disease Diagnosis (3.0 MB) Howe, Wyatt A Federated Public-Document Private-Query Search System (426.6 KB) Kaan, Ozulkulu Analysis of Leveraging C++ via Pybind11 for POMDP Problems Defined in Python (169.4 KB) Li, Shihang Leave Nothing Idle: Filling Datacenter Resource Utilization Gaps with Quicksand (802.8 KB) Lu, Cheng-You HyperBuff Branched Per-Frame Neural Radiance Fields using HyperNetwork (35.4 MB) Luo, Calvin Understanding Diffusion Models: A Unified Perspective (4.9 MB) Maynard, Patrick Enabling Few-Shot Learning on TESS Data with Prototypical Neural Networks (3.8 MB) Peng, Kathy Attention-Eraser: Training Latents in the Denoising Process to Adjust the Size of User-Select Tokens (20.0 MB) Ramesh, Dev Teaching Robots Social Norms with Behavior Trees (3.8 MB) Ryjikov, Benjamin Detailing a Translation From the Calculus of Inductive Constructions into Higher Order Logic (189.4 KB) Scherick, James A Survey of De Bruijn Graph Properties, Theorems, and Algorithms (13.1 MB) Sriram, Abhinav Decentralized Markets for Public Goods: Solving Collective Action Problems Using Blockchains (3.6 MB) Zhou, Peisen Medical Imaging Segmentation with Self-Supervised Learning (1.9 MB) Zhou, Tongyu Filtered ink: Creating Dynamic Illustrations with SVG Filters (15.6 MB) Zhuo, Wang FLEXIM_Learning similarity functions for time-series data (1.4 MB) 2022 Alabdulrazzaq, Bader and Zhang, Ce and Fu, Changcheng Addressing Limitations of Slot Attention using a Multiscale Hierarchical Approach (1.6 MB) Bagaria, Akhil and Senthil, Jason Skill Discovery for Exploration and Planning using Deep Skill Graphs (3.0 MB) Blinn, Bryce Body-Aware Chair Generative Models (173.9 KB) Chaaya, Richard Abou Type-based System Call Filtering with Temporal Specialization (193.3 KB) Ding, Sijie Canonical Arrangements (1.3 MB) Gong, Zhouqi Towards a Perceptual Similarity Measure for 3D Shapes (8.6 MB) Houchens, Trevor Neural Omnidirectional Distance Fields (1.1 MB) Kim, Yongjeong P4GPP: A GPU Accelerated P4 Packet Processing (789.9 KB) Nelson, Casey Eliminating Micro-architectural Side-Channel Attacks using NDP (480.6 KB) Pal, Koyena Summarization and Generation of Discharge Summary Medical Reports (1.1 MB) Pehlivanoglu, Sinan Harpocrates: A Statically Typed Privacy Conscious Programming Framework (136.8 KB) Pierce, Joshua, Neural Causal Discovery and Social Science Research (1.2 MB) Romero, Alejandro CatchAR: Prototyping Partial Object Manipulation, Naturalistic Throwing Interactions, and Intuitive Navigation Systems with AR Glasses (6.5 MB) Roy, Chitradeep Dutta Shapely residual estimation (329.7 KB) Rudman, William and Gillman, Nate IsoScore: Measuring the Uniformity of Embedding Space Utilization (1.2 MB) Shao, Yunzhi Speculative Compilation of Complex UDFS in Python Data Science (378.3 KB) Sharma, Gaurav and Glass, Geoffrey Handling Concept Drift in Weakly Supervised Learning (843.2 KB) Sharma, Ishan Read-Your-Writes Consistency in Streaming Dataflow Systems (471.6 KB) Woodard, Brandon Increasing the Use of LiDAR Data for Forestry Applications: Model for Ground Identification in Waveforms (1.2 MB) Yun, Tian and Bhalla Usha Do Vision-Language Pretrained Models Learn Primitive Concepts? (2.0 MB) 2021 Berckmann, Tucker Structure and Meaning in Word Embedding Spaces (384.9 KB) Boger, Sam L-Diversity for Data Analysis: Data Swapping with Customized Clustering (364.5 KB) Qin, Lucy A Decentralized and Encrypted National Gun Registry (1.9 MB) Sumigray, Austin Improving Remote Environment Visualization through 360 6DoF Multi-sensor Fusion for VR Telerobotics (17.9 MB) 2020 Alfajardo, Jearson Assessing the Correctness of Debloating Binary Shared Libraries with LibFilter (106.7 KB) Beck, Jacob Human-Actor Human-Critic: Human Demonstrations and Human Feedback in the Action-Space (3.7 MB) Cohen, Loudon Shape From Tracing Report (7.4 MB) Goel, Purvi Shape from Tracing: Reconstructing 3D Geometry and SVBRDF Material from Images via Differentiable Pathtracing (204.5 KB) Hiziroglu, Berkan Perceptual Image Similarity for Unsupervised Representation Learning (440.8 KB) Horvitz, Zachary Context-Driven Satirical Headline Generation (1.8 MB) Ilkhechi, Amir Rahimzadeh DeepSqueeze: Deep Semantic Compression for Tabular Data (1.8 MB) Kim, Seungchan (Chan) Adaptive Tuning of Temperature in Mellowmax using Meta-Gradients (520.9 KB) Lei, Leon Assembly of 3D Rooms into Floor Plans from Retrieved Layouts (1.4 MB) Lindsay, Natalie Roominoes: Learning to Assemble 3D Rooms into Floor Plans (477.8 KB) Ma, Jingxiao Approximate Logic Synthesis Using Boolean Matrix Factorization (1.0 MB) Ma, Ziyin Fauxtoshop: Modeling Image Editing Operations with Kernel Prediction Networks and Parameter Blocks (6.8 MB) Narain, Akshar Using Rust to Implement WEASEL+MUSE and RustyDB (655.7 KB) Roy, Josh Visual Transfer for Reinforcement Learning via Wasserstein Domain Confusion (1.5 MB) Shah, Aansh Comparing Global with Disease specific Machine-learned Readmission Prediction Models (443.2 KB) Shin, Milla Applications of computer vision to population dynamics: detecting flowering trees in high-resolution cube-sat imagery (1.0 MB) Sinha, Shash Assisting with Scalable Scalable Vector Graphics and VisConnect (7.3 MB) Slivinski, Matthew Robust Deep Skill Chaining (1.1 MB) Snower, Michael Improving Unpaired Object Translation for Unaligned Domains (10.6 MB) Srinivasan, Naveen Causal Inference for Planning in Reinforcement Learning: Part 2 (334.6 KB) Sunkara, Veda Causal Inference for Planning in Reinforcement Learning: Part 1/2 (739.7 KB) Teng, Changmin NestFuzz: A Framework for Fuzzing Nested Virtualization Environments (116.1 KB) Varga, Alexander Forging Forge: Contributions to the Forge Programming Language (1.1 MB) Vexler, Jonathan Characterization of Forward-edge Control-flow Integrity Targets in LLVM-compiled Linux (96.4 KB) Wang, Siqi Stylistic Compatibility Learning with Deep Neural Networks for Indoor Scene (2.6 MB) 2019 Blum, Roman Treating Agents as Workers (517.7 KB) Conard, Ashley Identification of Subclonal Drivers and Copy-Number Variants from Bulk and Single-Cell DNA Sequencing of Tumors (12.8 MB) Drelich, Arun Experiments with AIR: A Generative Model for Scenes (199.3 KB) Gokaslan, Aaron Exploring the Spectrum of Mask Supervision for unpaid Image-to-Image Translation (3.4 MB) Huang, Baichuan Flight, Camera, Action! Using Natural Language and Mixed Reality to Control a Drone (3.1 MB) Lister, Jonathan Project Report: Leveraging Near Memory Processing for Cuckoo Cycles (102.4 KB) Luo, Shiyang Weak Supervision for Sequence Modeling (133.4 KB) McKinney, Samuel Graph-Based Analysis for IoT Devices with Manufacturer Usage Descriptions (1.5 MB) Rice, Freddie Color Constancy through Adjusting for Ambient Light (530.8 KB) Yang, Jordan Simple Representation of Protein Structure and Folding Techniques (310.8 KB) 2018 Arumugam, Dilip Deep Reinforcement Learning from Policy-Dependent Human Feedback (979.0 KB) Dutta, Abhishek Applied Machine Learning to Healthcare Predictive Analytics (434.4 KB) Fu, Jessica Sochiatrist - Using Conversational and Biometric Data to Predict Mood (659.1 KB) Haq, Aman Sketchy: Interactive-Influenced Design (77.8 KB) He, Yuze Final Project Report (64.0 KB) Jones, Andrew Computational modeling of visual attention and saliency in the Smart Playroom (1.9 MB) Pendse, Sachin Sochiatrist: Inferring the Relationship Between Emotion and Private Social Messages (2.1 MB) Sharma, Abhishek Off-Chain Insured Networks (348.6 KB) Tumkur Vani, Sumukha Rethinking Distributed Indexing for RDMA-Based Networks (468.0 KB) Utama, Prasetya Evaluating Attribute-Object Compositionality in Text-Image Multimodal Embeddings (7.4 MB) Wilson, Preston Student Understanding of Aliasing and Procedure Calls (528.5 KB) Xiang, Yu Final Project Report (101.5 KB) 2017 Camery, Luke On Information Aggregation in Prediction Markets (275.1 KB) Hawkins, Craig BrownNow A Current Events Application for Brown University (3.5 MB) Hrytsenko, Yana Blockchain for PKI: Using Blockchain data structure for Public Key Infrastructure (144.1 KB) Johnson-Roberson, Cora Content-Based Genre Classification and Sample Recognition Using Topic Models (161.4 KB) Kelly, Samuel Fast Type-based Indexing and Querying of Dynamic Hierarchical Data (571.7 KB) Pane, Gianluca Hypergraph Valuations with Restricted Overlapping (423.9 KB) Singhal, Kartik How to Reason about Correctness of Programs Designed for Non-Volatile Memory? (1.0 MB) Solanka, Dronika Automatic Lung Cancer Detection Using Volumetric CT Imaging Features (1.7 MB) Su, Ying Data Visualization of the EchoQuery System (2.1 MB) Tian, Yulong Data Migration from S-Store to BigDAWG (572.6 KB) Tveite, Joshua Masters Project Report (43.8 KB) Wang, Bikong The Release of S-Store System (249.0 KB) Watson, Jeremy Automating the Collection and Processing of Cancer Mutation Data (708.6 KB) 2016 Chen, Junyang Achieving QoE Fairness in Video Streaming via Client-Network Interaction (1.7 MB) Hendricks, Jordan kGuard++: Improving the Performance of kGuard with Low-latency Code Inflation (200.2 KB) Murphy, Michael YURT Project Document (82.8 KB) Olsson, Carl Scene Category Context for 3D Object Detection with RGBD cameras (4.0 MB) Painton, Lee BURLAP BAG An Adjustable Game Engine for the BURLAP framework (314.7 KB) Romanski, Julia Algorithms for Large-Scale Prescriptive Evacuations (1.7 MB) Rosenthal, Eli Linearizable Iterators (203.0 KB) Shao, Qiming Spark, BlinkDB and Sampling (790.6 KB) Shen, John Developing an annotations system for the collaborative web application MAGI (Mutation Annotation and Genome Interpretation (1.3 MB) Sun, Hongkai General Baggage Model for End-to-End Tracing and Its Application on Critical Path Analysis (692.4 KB) Tang, Jikai TrendsMap A Real-time US Trends Map for Twitter (1.8 MB) Whalen, Christine TrendsMap A Real-time US Trends Map for Twitter (6.1 MB) 2015 Abel, David Learning to Plan in Complex Stochastic Domains (829.3 KB) Barth-Maron, Gabriel Learning Deep State Representations With Convolutional Autoencoders (549.0 KB) Eichmann, Philipp Evaluating Subjective Accuracy in Time Series Pattern-Matching Using Human-Annotated Rankings (1.2 MB) Harder, Brigitte Implementing TPC-E, A Streaming Benchmark (1.1 MB) The Effect of Visual Aspects of Website Design on User Perception: Project Specification (234.9 KB) Ho, Mark Teaching Agents with Evaluative Feedback: Communication versus Reward (3.5 MB) Li, Junsong Shrinking Desugaring (88.4 KB) Li, Yiming Simon: Scriptable Interactive Monitoring for SDNs (187.3 KB) Ni, Mengrui Variational Inference for Beta-Bernoulli Dirichlet Process Mixture Models (6.3 MB) Parsons, Timothy SimVis - A Portable Framework for Simulating Virtual Environments (529.0 KB) Repetti, Thomas A Case Study in Optimizing HTM-Enabled Dynamic Data Structures: Patricia Tries (317.9 KB) Roelke, Ryan Dynamic Causal Monitoring for Distributed Systems (3.1 MB) Xiang, Lingzhu Mapping and Control with Telepresence Robots (820.6 KB) Zhao, Zhe zhao.zhe.pdf (1.1 MB) 2014 Ellis, Marquita Early Foundations of a Transactional Boosting Library for Scala and Java (213.2 KB) Gao, Fan A Concurrent Skip List Implementation with RTM and HLE (139.6 KB) Ghosh, Esha Verifiable Member and Order Queries on a List in Zero-Knowledge (639.3 KB) LeVeque, Benjamin Extending Touch Art Gallery (18.8 MB) Li, Yan Laboratory for Engineering Man-Machine System (LEMS): Report of the Reading & Research (1.2 MB) Lu, Xinyi HDFS Cluster Installation Automation for TupleWare (402.6 KB) Shah, Valay Y. Sketch2Real: A New photoediting tool for digital alchemy (18.2 MB) Zhang, Minrui CS2980: Model-based Semantic Compression in Database Project Report (478.9 KB) Zhang, Shu Column-based Database Semantic Compression and Prediction-based Query Optimization (551.8 KB) Zhong, Zhigang Fractal Tree Implementation with Intel Hardware Supported Transactional Memory (106.1 KB) Zhou, Rui (Ray) Datacenter Network Large Flow Detection and Scheduling from the Edge (920.0 KB) Zhou, Yipin Explore the Power of External Data in Denoising Task (5.0 MB) 2013 Bost, Raphael Submatrix maximum queries in Monge matrices: an implementation (465.7 KB) Boucher, Alicia Interactive Volume Rendering (671.7 KB) Holla, Aditya Lock Elision for Memcached: Power and Performance analysis on an Embedded Platform (767.6 KB) Huang, Huanzhong PUF-Based UC-Secure Commitment without Fuzzy Extractor (211.4 KB) Icingir, Hasan Tuna Visualization of Semantic Windows with SciDB Integration (287.2 KB) Jia, Xin An Investigation of Performance Bottlenecks in a Main-Memory Database Management System (693.4 KB) Leiserson, Mark DM Methods for Identifying Driver Pathways in Cancer (3.6 MB) Lester, Ryan A Fast Implementation of FR-Dijkstra (161.0 KB) Liang, Chen Software Defined Network Support for Real Distributed Systems (109.2 KB) Loomis, Andrew Web Interfaces for Human Bidding Agents and General Auction Scheduling with the Java Auction Configuration Kit (JACK) (547.8 KB) Mahmoody, Ahmad Reconstructing Genome Mixtures From Partial Adjacencies (591.5 KB) Moussavi, Vazheh Learning Visual Scene Attributes (1.3 MB) Parker, B. Tyler Shadow Figures: An Interactive Shadow Animation Platform for Performance (2.7 MB) Quay-de la Valle, Hannah Modeling and Reasoning About Effective User Permissions in Social-Sharing Systems (339.1 KB) Ramani, Vibhu Regions in Retrievals - Using memorability regions in image retrieval pipelines (1.9 MB) Rocco, Dominic Food?: Streamlined meal planning and invitation application for iOS (709.2 KB) Su, Hang Scene Parsing Using Scene Attributes As Global Features (386.2 KB) Sun, Li An Attempt to Build Object Detection Models by Reusing Parts (4.9 MB) Xu, Chen Applications of Scene Attributes (1.9 MB) Zhang, Tan Charles A web application for splicing online videos with annotations (1.3 MB) 2012 Ayer, Andrew KVMSandbox: Application-Level Sandboxing with x86 Hardware Virtualization and KVM (107.0 KB) Calakli, Fatih High Resolution Colored Surface Reconstruction from Oriented Points (10.9 MB) Crow, Basil Time and Energy Profiling in Production Sensor Networks with Quanto (327.0 KB) Dertat, Arden Meliper: Making News Personal (347.8 KB) Duc, Phong Nguyen Event-based Phylogeny Inference and Multiple Sequence Alignment (893.1 KB) Ehmoda, Omran Statistical Stylometrics and the Marlowe-Shakespeare Authorship Debate (295.2 KB) Gillmor, Alexander Linear Methods for SNP Selection (284.6 KB) Goldenberg, Seth Exploratory Search in WorkTop (1.5 MB) Guha, Arjun Semantics and Types for Safe Web Programming (1.5 MB) Hills, Alexander LADS and TAG touch-first Systems for Museum Exhibition and Display (868.9 KB) Jin, Li Locality Aware Fair Scheduling for Hammr (225.9 KB) Lee, Sungmin Auto-colorization Exploiting Annotated Dataset (6.6 MB) Lee, Jihoon Web Applications for Robots using rosbridge (783.4 KB) Lu, Yang Serializable Snapshot Isolation in Shared-Nothing, Distributed Database Management Systems (627.4 KB) Ma, Zhongyu NUMA aware locks Implementation and Evaluation (172.8 KB) Megrelishvili, Georgy GradRanking: Online Personalized University Recommendation System (167.5 KB) Nguyen, Duy Verification of Web-Content Searching Through Authenticated Web Crawler (960.2 KB) Price, Michael NPR.js: A JavaScript library for Interactive Non-Photorealistic Rendering in WebGL (1.2 MB) Sastrasinh, Paul Improving Data Driven Image Geolocation (5.8 MB) Shen, Aaron Aspect-Specific Ranking of Product Reviews Using Topic Modeling (234.0 KB) Simon, Benjamin Randomized Adaptive Vehicle Decomposition for Large-Scale Power Restoration (310.8 KB) Verch, Shaun Performance Analysis of 64-Bit Capriccio (290.2 KB) Wang, Xiaowei Operating System Protection Domains (1021.5 KB) 2011 Angkanawaraphan, Visawee AuctionMark OLTP Benchmark (1.0 MB) Baldimtsi, Foteini Berg, Jordan Rank and Impression Estimation in a Stylized Model of Ad Auctions (883.4 KB) Chin, James C. LADS Tour Authoring & Playback System (367.8 KB) de Nijs, Joost Decision DAGS - A new approach (645.2 KB) Eisenstat, David Random road networks: the quadtree model (1.8 MB) Elliott, Nell Kiyoko An Algorithm to Find Efficient Supported Solutions of Non-Convex Multiobjective Optimization Problems (2.2 MB) Ferguson, Andrew Ghosh, Soumya Image Understanding in a Nonparametric Bayesian Framework (1.3 MB) Goldmints-Orlov, Arcady Exploded Images (2.0 MB) Gomez, Steve Imhmed, Hassan Distributed Debugging Tool (719.1 KB) Jayaraman, Venkatasubramanian Distributed Debugging Tool (719.1 KB) Kendall, Donnie Garibaldi & LADS Interactive Multitouch Systems for the Visual Arts (1.0 MB) Ko, Hsu-Sheng Linear Gesture Recognition and Large Screen Simulation of Gesture Select (586.8 KB) Kothapa, Rajkumar Max-Product Particle Belief Propagation (280.1 KB) Li, Yu Making Programming More Easily in Code Bubbles (1.2 MB) Mallya, Sunil Entracker: Energy Tracker for Homes (4.2 MB) Martins, Marcelo Mason, Rebecca Extractive Multi-Document Summaries Should Explicitly Not Contain Document-Specific Content (1.1 MB) McCann, Paul Caging the Muse: Metrics for Unconcious Author Markers (123.0 KB) Pattabiraman, Karthik Distributed Debugging Tool (719.1 KB) Politz, Joseph ADsafety Type-Based Verification of JavaScript Sandboxing (310.5 KB) Santhanam, Deepak Learning to Fuse Disparate Sentences (207.8 KB) Segal, Aaron Rational Secret Sharing with Side Information in Point-to-Point Networks via Time-Delayed Encryption (262.8 KB) Song, Wei Effective Data Transmission in Distributed Visual Sensor Systems (1.0 MB) Swanson, Ben Using Probabilistic Tree Substitution Grammars (473.4 KB) Tarvo, Alexander Using computer simulation to predict performance of parallel programs (856.2 KB) Vittayakorn, Sirion Quality Assessment for Crowdsourced Object Annotations (3.3 MB) Wang, Zikai A Distributed Implementation of Continuous-MapReduce Stream Processing Framework (143.0 KB) Zuffi, Silvia 2010 Aguiar, Derek The Clark Phase-able Sample Size Problem: Long-range Phasing and Loss of Heterozygosity in GWAS (726.2 KB) Coffrin, Carleton Constraint-Based Local Search for the Automatic Generation of Architectural Tests (296.2 KB) Doran, Patrick J. Expressive Rendering with Watercolor (12.7 MB) Feijoo, Milagro I. Improving Mobile GeoMaps Applications with Expressive Rendering: A Test Case (28.8 MB) Feldman, Michael Distributed Transactional Boosting (53.6 KB) Guan, Peng Estimating Human Shape and Pose from a Single Image (2.1 MB) Hristov, Borislav H. Optimizing Directed Acyclic Graphs via Simulated Annealing for Reconstructing Human Segmental Duplications (1.3 MB) Hussain, Ahsan Query Generator (195.4 KB) Ikhariale, Newton Fractured Indexes: Improved B-trees To Reduce Maintenance Cost and Fragmentation (200.0 KB) Islam, Sidra Provenance, Lineage, and Workflows (579.0 KB) Jablin, James Ragnarok: RAndom Graphs Never ARe OK (362.2 KB) Kaya, Lutfi Ilke Trading Agents (51.8 KB) Keskin, R. Onur Spatial Querying for Camera-Based Tracking Platforms (2.2 MB) Miller, Andrew C. Image and Audio Annotation: Approximate Inference in Dense Conditional Random Fields (417.6 KB) Ohrimenko, Olga Finding Compensatory Pathways in Yeast Genome (258.3 KB) Park, Hojoon A Method for Controlling Mouse Movement using a Real-Time Camera (302.2 KB) Riondato, Matteo Mining Top-K Frequent Itemsets Through Progressive Sampling (420.2 KB) Rosenberg, Dan On-Disk Authenticated Data Structures for Verifying Data Integrity on Outsourced File Storage (133.6 KB) Shi, Ning Resolving Ambiguous Paths Using BorderPatrol (178.8 KB) Tierney, Kevin GGA: A Gender-Based Genetic Algorithm for the Automatic Configuration of Algorithms (175.5 KB) Vondrak, Marek Physical Simulation for Probabilistic Motion Tracking (1.4 MB) Wang, Dongbo Object Identification by enhanced Local SIFT Features (215.3 KB) Wang, Juexin A Rank-Based Skip Lists in Dynamic Provable Data Possession (330.6 KB) Xie, Qiao Implementation of Methods for Distributed Data Authentication (143.8 KB) Zhang, Zhe An Automatic Source Code Generation Tool for OLTP Database Benchmarks (438.1 KB) 2009 Backman, Nathan A Fine-Grained, Dynamic Load Distribution Model for Parallel Stream Processing (246.9 KB) Bartholomew, Andy The performance of select STAMP benchmarks with transactional cache hardware configurations (43.3 KB) Bascetincelik, Aysun WiiRobot: Controlling Robots with Wii Gestures (1.5 MB) Berg, Bradley Disentangling Exceptions (309.9 KB) Bragdon, Andrew GestureBar: Improving the Approachability of Gesture-based Interfaces (732.0 KB) Cha, Sanghoon RCHeli: Infrastructure for PC-Controlled Micro Helicopter (173.9 KB) Conrad, Adam Database Economic Cost Optimization for Cloud Computing (228.8 KB) Daniel, Scott An Energy Minimization Approach to Surface Reconstruction (642.2 KB) Diamond, Brandon iCDA: Continuous Double Auction on the Web (602.3 KB) Doutre, Will Providing Captured Images and Video to REVEAL (81.9 KB) Eisenstat, Sarah Learning Underlying Forms With MaxEnt (238.6 KB) Gbarayor Jr., Kembey Linear Dynamical Systems: A Machine Learning Framework for Financial Time Series Analysis (281.1 KB) Hickey, Brendan Detection of Correlated Breakpoints in Cancer (897.7 KB) Huang, Ling-Ya Improve Chinese Parsing with Max-Ent Reranking Parser (354.6 KB) Kadioglu, Serdar Grammar Constraints: Combining Expressiveness with Efficiency (557.0 KB) Kalafarski, E.J. SurfaceShop: Techniques for Complex Adjustments in Multi-Touch Computing (6.2 MB) Kallman, Rob Volt GUI Console: A Graphical User Interface for Volt Distributed Transaction Processing Database (456.0 KB) Kim, Dong Wook Haplotype Phasing using Pre-Resolved Table on the Ancestral Tree Structure (499.0 KB) Kumar, Mayank Automating Visual Sensor Networks (312.2 KB) Lara, Laura Sevilla Bone tracking from X-Ray sequences (673.4 KB) Lin, Ming-Li A Case Study in Extracting DEMs from High-Resolution Mars Stereo Pairs Using a Simple Computer Vision Algorithm (668.6 KB) Liu, Chu-chi Contributions on Lineogrammer (974.8 KB) Meiklejohn, Sarah An Extension of the Groth-Sahai Proof System (399.2 KB) Mozes, Shay Some Lower and Upper Bounds for Tree Edit Distance (603.0 KB) Nicholas, Greg Building part compositions for hierarchical object recognition (445.9 KB) Odean, Tyler Marginal Bidding: An Application of the Equimarginal Principle to Bidding in TAC SCM (166.0 KB) Reddy Cherabuddi, Neehar Exergaming: Video Games as a form of Exercise (368.6 KB) Rogers, Jennie Towards a Generic Data Compression Advisor (1.0 MB) Sun, Deqing Learning Optical Flow (1.3 MB) Tarpine, Ryan CYRENE: A Database, Browser, and Library of Tools for Regulatory Genomics (518.8 KB) Wilson, Ahmad Exergaming: A Fusion of Exercise and Video Gaming (531.6 KB) Yadollahpour, Payman Neurally Constrained Subspace Learning of Reach and Grasp (1.6 MB) Yip, Justin Bound Consistency for Binary Length-Lex Set Constraints (175.5 KB) Zhao, Zhenyuan Architectural Models for Visual Sensor Networks (127.8 KB) Zhou, Wenjin An Analytical Model of Water Diffusion and Exchange in White Matter from Diffusion MRI and Its Application in Measuring Axon Radi (620.0 KB) 2008 Akdere, Mert Combining Proactive and Retroactive Processing for Distributed Complex Event Detection (597.0 KB) Bircan, Korhan Making Next-Gen Video Games in Your Basement (584.4 KB) Boller, Ryan Application of Uncertainty Visualization Methods to Meteorological Trajectories (639.8 KB) Bragdon, Andrew GestureBar: Making Gestures Browseable, Discoverable, Learnable and Training-Free (688.0 KB) Buller, Mark Thermal State Estimation Model Development Using Time Series Machine Learning Techniques (532.5 KB) Fuller, Matt RSS Feed Complex Event Detection (299.5 KB) Grabiner, David A Treatment of Correlated Attribute Uncertainty in Array Database Systems (215.8 KB) Kahn, Crystal Duplication Distance (231.5 KB) Kim, Sangjin A Global Credibility Measure in Pairwise Sequence Alignment (1.0 MB) Kimura, Hideaki Designing Correlation Indices with Bucketing and Composition (358.5 KB) Kostandov, Mykhaylo Qualitative Visual Comparison of Three Simulations of Fluid Flow around a Flying Bat (910.2 KB) Lim, Kian Huat (Eric) A Computational Method to Identify Splicing Elements (6.4 MB) Loper, Matthew Research Comprehensive Final Exam: Action Recognition on a Mobile Robotic Platform (772.7 KB) Maloney, Christopher Michael Reactor: An Organic Chemistry Reaction Prediction System (182.0 KB) McCorkle, Eric Realizing Concurrent Functional Programming Languages (397.1 KB) Miles, Jadrian A Characteristic-Oriented User Evaluation of Immersive Virtual Reality Comparison Visualizations (769.3 KB) Mozes, Shay Some Lower and Upper Bounds for Tree Edit Distance (603.0 KB) Myers, Aaron Operating System Protection Domains, a New Approach (434.5 KB) Pacheco, Jason Temporal Decomposition for Online Multisensor-Multitarget Tracking (813.4 KB) Ritz, Anna A Minimum Description Length Approach to the Multiple Motif Problem (1.2 MB) Schwertfeger, Jonas Multi-Robot Belief Propagation for Distributed Robot Allocation (156.6 KB) Tsoli, Aggeliki Sparse Control of Robot Grasping from 2D Subspaces (388.4 KB) 2007 Boghraty, Kaveh Art Gallery Positioning System (513.2 KB) Burchett, Kimberley Lowering A Static Optimization Technique for Transparent Functional Reactivity (174.8 KB) Dickinson, Brendan Roomba Pac-Man: Teaching Autonomous Robotics through Embodied Gaming (1.7 MB) Donaldson, John A Marginal Revenue Approach to Bidding in TAC SCM (215.8 KB) Elsner, Micha A Unified Local and Global Model for Discourse Coherence (87.8 KB) Gaiman, Michael Cellarium: A Computational Biology Workflowing Environment Hiratsuka, Tamaki An Algorithm to Compute the Secondary Structure of tRNA Molecules (51.2 KB) Hoenselaar, Andreas Mutual Information as a Measure of Relevance in Neural Coding (699.0 KB) Jianu, Radu Viewing proteomic experiments in context with known protein (334.4 KB) Joo, Jong Wha Joanne Haplotype Phasing Algorithms and Comparison (3.8 MB) Koskinen, Eric BorderPatrol: Isolating Events for Precise Black-box Tracing (264.2 KB) Kupcu, Alptekin SECMECE: Optimizing Lifetime of Federated Sensor Networks by Exploiting Data and Model Redundancy (679.6 KB) Liang, Vince SmartCIT An Intelligent Sensor Network System (1.3 MB) McCarthy, Jay Interaction-Safe State for the Web (821.3 KB) Mercier, Luc Strong Polynomiality of Resource Constraint Propagation (521.6 KB) Moseley, Mark Technical Aspects of Roomba Pac-Man (1.2 MB) Papamanthou, Charalampos Efficient Localization for Wireless Sensor Networks Using Power Measurements Sampling (1.2 MB) Penney, Devon A Comparison of Rendering Techniques for Scenes with High Geometric Complexity (80.1 KB) Schreiber, Ethan A Distributed Model for Image Recognition Using Pyramidal Bayesian Networks (200.2 KB) Schudy, Warren How to rank with few errors A PTAS for Weighted Feedback Arc Set on Tournaments (277.0 KB) Tamura, Eric Protection Domains (51.2 KB) Tran, Ha Sonic Gallery (171.9 KB) Vu, Theresa Modeling the Visual Cortex: Object Recognition with Extended Hierarchical Bayesian Networks (178.2 KB) Weinberger, Joel Protection Domains (61.4 KB) Wicks, John Stochastic Stability (216.0 KB) 2006 Apte, Salil Time-varying Azimuth Discrimination and Resynthesis: A New Method for Music Repurposing (813.6 KB) Birck, Andrew Extending Click to Support Block Requests (408.8 KB) Cho, Kyu Wook A Simple Event Detection System for Wireless Sensor Networks (309.7 KB) Domanic, Nevzat Onur An Algorithm for Detecting Approximate Tandem Repeats in Genomic Sequences (972.5 KB) Erway, Chris Designing the Network Layer for End-Host Traffic Engineering (81.8 KB) Fisher, Jessica Motor Cortical Decoding Using an Autoregressive Moving Average Model (152.5 KB) Ge, Tingjian Fast, Secure Encryption for Indexing in a Column-Oriented DBMS (287.2 KB) Headden, William Learning Phrasal Categories (67.7 KB) Ketpreechasawat, Suamporn Hierarchical Landmark Charting (3.8 MB) Leland, Ethan The Brown University Robocup 2006 Four-Legged League Team Report (565.7 KB) Lemmerman, Dmitri The Effect of Interaction-Display Offset on User Performance for a 3D-Widget Task in the Cave (8.6 MB) McClosky, David Effective Self-Training for Parsing (81.1 KB) Park, Austin Architecture and Implementation of a Content-based Data Dissemination System (102.1 KB) Peng, Luke The Sandbox: Improving File Access Security in the Internet Age (754.2 KB) Pivkin, Igor Visualization and Interpretation of the Proper Orthogonal Decomposition of Bat Wing Kinematics (337.6 KB) Pozar, Michael Bllip: An Improved Evaluation Metric for Machine Translation (94.8 KB) Rachlin, Eric Robust Nanowire Decoding (2.8 MB) Snyder, Derek A Framework for Creating Distributed GUI Applications (206.1 KB) Tse, Ronald Henry TCP Fairness in Multipath Transport Protocols (1.6 MB) Wrotek, Pawel Dynamo: Dynamic Data-driven Character Control with Adjustable Balance (vgsp_0007) (12.0 MB) 2005 Cole, Christopher Snapshots and Software Transactional Memory (88.0 KB) Fein, Andrea Disney Curves (167.9 KB) Funaro, Jesse Diversity as an Objective in Informational Retrieval Experiments with a Navigation System (331.3 KB) Jhingran, Anjali Implementation of Type Checker in Borealis (147.4 KB) Tenneson, Dana ChemPad: A Pedagogical Tool For Exploring Handwritten Organic Molecules (154.5 KB) 2004 Chan-Tin, Sebastien Sandboxing programs (1.5 MB) Yao, Danfeng Role-Based Cascaded Delegation (4.0 MB) 2003 Almanza, Robert Reliable Multicast for Small Wireless Networks (6.2 MB) Altshuler, Robert Charles Decomposing Image Sequences into Layers According to Motion with the use of an Appearance Model (8.4 MB) Altun, Yasemin Investigating Loss Functions and Optimization Methods for Discriminative Learning of Label Sequences (119.3 KB) Antoniu, Tudor A Framework for Checking Spreadsheets (12.6 MB) Audleman, Kevin Forbes TIV: Thread Interaction Visualizer (6.5 MB) Ciaramita, Massimiliano Hierarchical Semantic Classification: Word Sense Disambiguation with World Knowledge (3.8 MB) Convey, Christian The Aurora Storage Manager (4.1 MB) Erwin, Christina Aurora Box Research (2.6 MB) Flinders, Andrew Energy-Efficient Dynamic Data Scheduling in Wireless Multihop Networks (15.8 MB) Jafari, Amir On the Notion of Regret in Infinitely Repeated Games (5.2 MB) Karelitz, David Using CavePainting to Create Scientific Visualizations (2.1 MB) Kong, George Replica Location in Sand (6.3 MB) Leroy, Christian Matthew Exploration of the Routing Task Domain (9.9 MB) Nachbar, Curran Detecting Features Through Concept Analysis (8.8 MB) Nisenfeld, Scott Using Reality to Evaluate the ITC Presence Questionnaire (3.9 MB) Rasin, Alexander Priority-Based Bandwidth Allocation in Aurora (2.3 MB) Sigal, Leonid Fabricating People: Assembling Articulated 3D Models using Non-parametric Belief Propagation (3.8 MB) Sobel, Jason SciVL: A Descriptive Language for 2D Multivariate Scientific Visualization Synthesis (4.3 MB) Tenneson, Dana Overview of the Goals and Present Status of the Graphics Teaching Tool Project (3.6 MB) Wu, Wei Neural Decoding in Motor Cortex (5.0 MB) Yan, Robin Implementing a Persistent Query Graphical User Interface for a Streaming Database (5.2 MB) Ye, Qiang Security in Reliable Multicasting (Security for the Electronic Notebook Project) (8.8 MB) Zheng, Cheng Distributed Obstruction-Free Transactional Memory (3.0 MB) 2002 Chen, Jeff Performance Evaluation of Scheduling Algorithms in Aurora (742.1 KB) Cooper, Gregory A Modular Compilation Strategy for Open Classes and Multimethods in Java (2.2 MB) Gao, Yun Nonparametric Representation of Neural Activity in Motor Cortex (710.2 KB) Hasic, Jasminka An Efficient Dynamic and Distributed Cryptographics Accumulator (579.3 KB) Hu, Xiaolan Simulation of Quality of Service (QoS) Graph-Based Load-Shedding Algorithm in Aurora System Using CSIM (1.3 MB) 2001 Acevedo, Daniel ARCHAVE: A Virtual Reality Research Environment for Scientific Applications (278.0 KB) Chen, Feng Statistical Methods Of Motion Estimation From Omni-Directional Image Sequences (285.8 KB) Coglianese, Michael Mobile Aleph: A System for Distributed Mobile Applications (263.7 KB) Engel, Donald Edward The Utility of Filled Pauses, Interjections, and Parentheticals in Parsing Conversational Language (39.2 KB) Gilbert, Richards C. A Program for Quantifying Humanlike Finger Forces Using an Anatomic Hand Tendon Model (529.8 KB) Hall, Keith B. A Statistical Model of Nominal Anaphora (227.2 KB) Jeon, Seung Hoan A Statistical Model of Nominal Anaphora (66.4 KB) Karpenko, Olga Interactively generating 3D models from contour drawings (520.5 KB) Keefe, Daniel Kirby, Robert M. Visualizing Fluid Flow Data: From the Canvas to the CAVE (997.7 KB) Marai, Liz Modeling the Length of Distal Radioulnar Ligaments (371.0 KB) Moscovich, Tomer Animation Sketching: An Approach to Accessible Animation (129.5 KB) Paranthaman, Pramod Prabhat Comparative Evaluation of Desktop and Cave Environments for Learning Hypercube Rotations (213.5 KB) Pyo, Changhee Reiter, Jonathan Immersive Hierarchical Visualization and Steering for Spectral/hp Element Methods (159.1 KB) Reitsma, Paul S. A. Metrics for Motion Editing (206.2 KB) Schmidt, Keith Using Tabu Search to Solve the Job Shop Scheduling Problem with Sequence Dependent Setup Times (633.9 KB) Shi, Shaoqing Mobile Collaboration System For An Electronic Notebook (76.7 KB) Tatbul, E Nesime Index Structures and Algorithms for Efficient Profile Matching (289.8 KB) Vega, Luis J. WOODSTOCK: A Wireless Stock Trading Game for Windows CE (392.6 KB) Xing, Ying Caching on the Changing Web (137.4 KB) Zhang, Jie E-Seminar (430.2 KB) 2000 Carney, Donald P. Channelization for Publish-Subscribe Systems (291.8 KB) Chang, Remco K. Simulation Techniques For Deformable Animated Characters (1.8 MB) Coglianese, Michael Mobile Aleph: A System for Distributed Mobile Applications (1.3 MB) Ho, Jimmy Sketching Interfaces for 2D Animation of Simple Objects (871.6 KB) Hu, Ying Monte Carlo Simulation of United States Power Network with Faulty Nodes and Fail Propagation (469.8 KB) Zhang, Song Visualizing Diffusion Tensor MR Image Using Streamtubes and Streamsurfaces (5.7 MB) 1999 Bhuphaibool, Dom Sithikorn Multi-resolution Animation and Behavior in Densely Populated Scenes (2.3 MB) Bose, Rahul The Pub-Sub Simulator (656.5 KB) Chen, Qiusheng Checkpointing Transaction-based Distributed Shared Memory (911.2 KB) Dahllof, Caroline Painterly Rendering with a Painter's Perspective (1.5 MB) Guo, Dongbai Automatic image mosaic assembly (1.0 MB) 1998 Atanassova, Zornitza Applying Traditional Animation-Techniques to Shared 3D Virtual Worlds (510.2 KB) Ayers, Matthew R. A Framework for the Synchronous Editing of Multiple Curve Representations (830.4 KB) Bourdev, Lubomir Rendering Nonphotorealistic Strokes with Temporal and Arc-Length Coherence (356.3 KB) Bremer, David Rapid Silhouette Rendering of Implicit Surfaces (986.4 KB) Choi, Sumi Y. Orthogonal Straight Line Drawing of Trees (715.5 KB) Cui, Jie Client-Server Performance Evaluation in Pushed-based Systems (1.2 MB) Cummings, Jonathan R. Motion Blending and Editing (1.9 MB) Yang, Baolin Project Report: Extensions to GeomLib (727.8 KB) 1997 Beall, Jeffrey Evan New Java Technologies and a Java-based Framework for Interactive Illustration Development (2.0 MB) Chin, Bing Sketching Curved Three-Dimensional Surfaces (190.0 KB) Dai, Peng The Performance of Large Software Systems: A Case Study (649.0 KB) Drew, Kenrick Edward Sketching 2D Stick Figures for 3D Jointed Figures: An interaction paradigm applied to a constrained modeling task (145.3 KB) Fayan, Randy M. DCE-Web GradeServer (466.8 KB) Gorguner, Murat VBnB - Visual Branch and Bound (929.6 KB) Luo, Chenghui Construction of an Image Mosaicing and Image-based Rendering System (565.2 KB) 1996 Chien, Yung-Ming chien.pdf (3.2 MB) Forsberg, Andrew Stephen An Implementation of 6-DOF-Based Direct-Manipulation Techniques for Immersive Virtual Environments (1.5 MB) Herndon, Kenneth P. Three-Dimensional User Interfaces for Scientific Visualization (2.3 MB) Hoecker, Charles G. A Distributed Threads Package for Solaris 2.4+ (415.8 KB) Leach, Sonia Learning Dynamical Systems Using Hidden Markov Models (1.2 MB) Meyer, Thomas Scheduling Time-Critical Graphics on Multiple Processors for Virtual Environments (1.1 MB) Wong, Jasper Y. Mini-Distributed System (MDS) (918.5 KB) Wong, Hoog-Shen A Heuristic Search For Linear Programs with 0-1 Variables (1.4 MB) Young, Joel D. On Unifying Time and Uncertainty: The Probabilistic Temporal Network (484.9 KB) 1995 Anderson, Brian G. A Visual Interface for Producing Queries in the AQUA Algebra (1.8 MB) Ersan, Murat Extracting Grammatical Information From Large Corpora (572.8 KB) Ersan, Ebru Clustering Words (393.2 KB) Hasson, Laurent-David GPEC, A Graphical Programming Environment for C++ (1.3 MB) Ignatowicz, Jovanna Ava 3D Menu: Text Menus in a 3D World (783.1 KB) Jacobson, Neil A. Robotic Object Recognition: Utilizing Multiple Views to Recognize Partially Occluded Objects (814.3 KB) Jalan, Madhu Estimating Cadinalities of Sets in EPOQ (2.0 MB) Lu, Weining Implementation of the EAT-Based Control Strategy for the EPOQ Optimizer (1.1 MB) Mamdani, Alnoor Checkpointing and Migration for Quahog (780.2 KB) Mander, Bobby Reading Signs: Robot Vision for Optical Character Recognition and Motion Planning (1.5 MB) Marcus, Mark A Parallel Adaptive Point-Sampling Algorithm (2.2 MB) Martin, John K. Building a Client Application in the CORBA Environment Using HyperDesk's Object Services (1.1 MB) McCann, John Neural Networks for Mobile Robot Navigation (1.1 MB) Paglione, Laura Ann Dorival Braitenberg Vehicles in a Virtual Environment (1.3 MB) Snibbe, Scott Gestural Controls for Computer Animation (1.8 MB) Spiewak, Joshua S. Replication in Spring: A New Subcontract (1.1 MB) Stradal, Eric The Performance of Various Tracing Algorithms for Shared-Memory Parallel Programs (1.3 MB) Vorbrich, David W. Assembly-to-Assembly Translation for Instrumenting User Code (2.4 MB) Walker, Peter A. Identifying Failure Modes in Compiler Algorithms applied to Distributed Memory Data Parallel Computation (1.4 MB) Yan, Weihua The Performance of Two Tracing and Replay Algorithms for Message-Passing Parallel Programs (1.1 MB) 1994 Agarwal, Lalit K. A System for Supporting Mark-based Interaction in Motif (4.5 MB) Ashar, Rachita Hierarchical Learning in Stochastic Domains (3.0 MB) Cassandra, Anthony Rocco Optimal Policies for Partially Observable Markov Decision Processes (3.7 MB) Castanos, Jose Gabriel The Dynamic Adaptation of Parallel Mesh-Based Computation (3.9 MB) Corkum, Matt Three Dimensional Morphing Using an Adaptive Oriented Particle System (2.8 MB) Ji, Shuang Information Query in Trace-based Debugging (1.3 MB) Loughlin, Maria M. An Annotation System for 3D Fluid Flow Visualization (1.2 MB) Mamaysky, Harry Three Dimensional Morphing Using an Adaptive Oriented Particle System (2.8 MB) Moussavi-Aghdam, Shamsi NIS+NSI A Name Service Adjunct to SUN's NIS+ (845.3 KB) Phalen, Elizabeth Jean Executing Parallel Programs on a Network of User owned Workstations (2.7 MB) Rocha, Renato C. Transaction Management for Multidatabases (Interactions): Synchronization of Transactions Used on Planning Applications (1.7 MB) Rubino, Vincent C. MOM: A Memory Object Manager for BOSS (1.4 MB) Stevens, Marc A Toolkit for the Construction of Three Dimensional Interfaces (1.4 MB) Thatte-Potter, Nisha D. Displaying Multivariate US Census and Migration Data Using Three-Dimensional Graphics and Animation (7.1 MB) Vorbrich, David W. Assembly-to-Assembly Translation for Instrumenting User Code (2.4 MB) 1993 Baynes, Robert T. Interactions Recovery System (IRS): Rollback and Recovery for Multidatabases in a Heterogeneous, Distributed Computing Environment (1.8 MB) Bhatia, Yashesh V. Design and Implementation of the Logging and Recovery System for InterAction - Multidatabase Transaction Model (1.7 MB) Chou, Tsung-Jen A Multiple-Process Implementation of Threads (4.2 MB) Curewitz, Kenneth Marion Practical Prefetching via Data Compression (1.8 MB) Krupka, John J. 3D Texture Synthesis (1.8 MB) Lin, Yueh-hong CCEL: The C++ Constraint Expression Language (1.7 MB) Lough, Ira Earl: A Tool for Portable Distributed Debugging (1.3 MB) Lu, Ming-Tsung Local Database Support for Long-Term Multidatabase Transactions (2.0 MB) MacKeith, Andrew EREQ Query Representation and Cost Model (2.8 MB) Marshall, Ralph Bringing Graphic Design Expertise to Computer Generated Presentations (1.4 MB) McCluskey, Peter C. Feedfoward and Recurrent Neural Networks and Genetic Programs for Stock Market and Time Series Forecasting (1.4 MB) Nakai, Sergio A. The Concurrency Control Mechanism of the Mongrel System Design and Implementation (1.3 MB) Nakos, Noela V. Specification Environment For Multidatabase Applications (1.3 MB) Nuzum, Christopher FutureFone (1.0 MB) Papka, Ron Net-time and Conflation: Improving Classification Models with Ablated Input (1.7 MB) Radhakrishnan, Rajesh Explicit Versus Implicit Remote Procedure Call Based Parallel Programming Languages: An Analysis (2.0 MB) Reilly, Paul Alan Logging and Recovery in ObServer2 (766.8 KB) Rosenzweig, Seth H. A Comparative Study of Relational and Object-Oriented Database Technology using The INGRES and ObjectStore Database Management Systems (6.6 MB) Stauffer, Adam Concurrency Control and Transaction Management in Observer2 (547.8 KB) Thamel, Stephen W. Monotonic Chain Decomposition in Randomly Generated Terrains (1.1 MB) Tversky, Oren J. Using Texture Mapping and WYSIWYG Painting to Create Geometric Tools (929.2 KB) Wong, Eddy XEMS: An X-based Event Messaging System (4.9 MB) 1992 Apgar, Scott W. Interactive Animation of Fault Tolerant Parallel Algorithms (2.1 MB) Axel G. Merk, Ronald C.F. Antony DeTerminator (4.5 MB) Chang, Daniel Ta-Ping Browsing in Hypertext Documents With the Assistance of Automatic Link Generation (923.3 KB) Cheng, Ming-Li Contribution to Incremental Constraint Algorithms (2.4 MB) Duby, Carolyn Kay CCEL: A Metalanguage for C++ (722.5 KB) Good, Timothy Todd Blank Map Orienteering For an Autonomous Mobile Robot Using Certainty Grids (7.1 MB) Hamlyn, Stuart NeXTPIEMail A Graphical, Personalized Environment Mail Tool (2.0 MB) Huang, Chih-Yung Two Phase Commit (563.5 KB) Katie Mohrfeld, David Ross Bat: A Source-level Debugger for C (8.7 MB) Knep, Brian Mapping a 3D Surface to the UV Plane for Texture Mapping, Patchifying and Metamorphosing (883.7 KB) Li, Yu-Fang Integrity Constraints for Object-Oriented Database System (3.2 MB) Teng, Choh Man On Generic Consistency Algorithms and their Specializations (2.1 MB) True, Thomas J. Volume Warping: A New Technique for Modeling with Volumetric Data (1.2 MB) Weiner, Bob PIEmail: A Personalized Information Environment Mail Tool (3.6 MB) Wen, James A Three Dimensional Browser for Visualizing Orthogonal Hierarchies (Using Only Two-and-a-Half Dimensions) (1.2 MB) Wood, Christopher A. XComment: An Interactive Documentation Tool (2.1 MB) Zachwieja, Stephan J. Interactive Collision Detection (1.1 MB) 1991 Barman, Dilip K. RelType Relaxed Typing for Intelligent Hypermedia (1.8 MB) Bartsocas, Spyros-Nicholas THEODORA: User's Manual for Version 0.6 (1.1 MB) Boyer, Robert An Operating System Development Environment (2.3 MB) Chiang, Yi-Jen Dynamization of the Trapezoid Method for Planar Point Location (777.7 KB) Delott, Gregory Performance Improvements in the ObServer Object Server (1.5 MB) Fitzmaurice, George Form-Centered Workflow Automation Using an Agent Framework (3.7 MB) Haring-Smith, Robert Object Models (2.8 MB) Hsu, William M. A Direct Manipulation Interface to Free-Form Deformations (1.5 MB) Huang, Nathan The Addition of Simulation to BAGS (623.5 KB) Husain, Saadia Heuristics for Cost-based Abduction in Belief Networks for Story Understanding (1.2 MB) Lee, Jin Joo Localization with Extended Kalman Filtering (822.9 KB) Meyers, James M. Automating Multi-Locus Viability Analyses for Human Linkage with \"Emilie\" (5.2 MB) Morse, Erik J. The CARE Package for CApture and REplay of Parallel Code Sequences (2.4 MB) Palmer, Mark L. A Data Cache that Learns to Fetch (947.9 KB) Reilly, George V. Text Objects (586.2 KB) Singh, Sumeet Kaur User Constraints for Giotto (974.9 KB) Stern, Mark L. Interaction Objects (1.8 MB) Tegan, Patrice Pattern Specification and Global Transaction Management in Heterogeneous Multidatabases (2.0 MB) Wagner, Peter Class Library for the Automation of Motif (CLAM) Programmer's Manual (1.3 MB) 1990 Anand, Mala Integrating Observer and Intermedia: A Case Study (408.7 KB) Borden, Lisa Kay Articulated Objects in BAGS (1.5 MB) Chekaluk, Robert Alan Using Influence Diagrams in Recognizing Locally-Distinctive Places (3.0 MB) Gold, Melissa Y. Multi-Dimensional Input Devices and Interaction Techniques for a Modeler-Animator (1.9 MB) Hagemark, Bent Site A Language and System for Configuring Many Computers as One Computing Site (2.1 MB) Hyun, Seungseok Handling Uncertainties in Classifying Junctions (3.7 MB) Ishii, Katsuji Garbage Collection for Encore/Observer (1.0 MB) Kogut, Richard M. Report on Implementing Caching for ObServer Clients (495.6 KB) Kozlowski, Raymond Inferring Knowledge and Ignorance about Motion from the Limits of Vision and Physics (2.5 MB) Lee, Shin Y. Collections, Tuples and Iterators in Object-Oriented Database Systems (933.6 KB) Liu, Chen Hui-ching An Implementation of Cooperative Concurrency Control in an OODB (3.9 MB) Randazza, Margaret J. The Feature Recognition Module of the LDP System for the Robot Huey (3.1 MB) Shriver, Elizabeth A. Optimal Disk I/O with Parallel Block Transfer (2.1 MB) Stone, Margaret D. A System Model Which Accounts for Previous Experience: A Combined Interface and Help System (8.2 MB) Tsai, Tu-Hsin An Implementation of Certainty Grids for Mobile Robot Exempt from the Higher Order Echo Reflection (1.6 MB) 1989 Da Silva, Dilip Raster Algorithms for 2D Primitives (2.8 MB) DiPalma, Louis P. Temporal Reasoning with Infinitesimals (1.8 MB) Ewald, Alan N. Implementing Views in the ENCORE Object-Oriented Database System (1.6 MB) Fernandez, Mary F. Transaction Groups in ObServer (1.7 MB) Koh, Young Woo Graphical User Interface to ENCORE -- Type and Instance Browser (2.3 MB) Mead, David S. Learning Through Exploration (665.9 KB) Nunez, Linda Relationship Between Temporal Bayes Networks and Markov Random Process Transition Tables (3.8 MB) Wong, Wayne Dexter A Query Processor for an Object Oriented Database (4.0 MB) Zeleznik, Robert C. Visualization of Disassemblies of Mechanical Objects (1.4 MB)", "https://cs.brown.edu/video/183/": "Panel Discussion with Professor Leighton <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/t/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/t/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/t/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/t/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 21, 2015, 9:05 a.m. Duration 0:45:38 Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/t/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/t/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/t/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/t/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/video/184/": "Christos Papadimitriou, University of California <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/v/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/v/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/v/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/v/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 21, 2015, 9:16 a.m. Duration 1:04:02 \"Games Johnny Would Play: Computation as a Lens\" Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/v/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/v/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/v/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/v/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/video/185/": "Leslie Valiant, Harvard University <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/w/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/w/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/w/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/w/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 21, 2015, 9:25 a.m. Duration 1:04:34 \u201cHow Nature Exploits Big Data: Learning and Evolution\u201d Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/w/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/w/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/w/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/w/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/video/188/": "David Berson, Brown University <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/z/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/z/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/z/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/z/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 21, 2015, 2:10 p.m. Duration 1:28:09 \"The Brain in Your Eye\" Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/z/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/z/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/z/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/z/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/video/189/": "Patricia Churchland, University of California <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/2/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/2/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/2/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/2/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 21, 2015, 2:28 p.m. Duration 1:06:51 \"Nerve Agents: You and Your Amazing Old-Fangled Reward System\" Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/2/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/2/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/2/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/2/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/video/190/": "Kenneth Arrow, Stanford University <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/4/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/4/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/4/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/4/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 21, 2015, 2:34 p.m. Duration 1:02:18 \u201cHow the Future Influences the Present\u201d Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/4/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/4/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/4/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/4/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/video/194/": "Panel Discussion with Professors Valiant and Papadimitriou <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/8/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/8/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/8/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/8/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 31, 2015, 2:25 p.m. Duration 0:54:20 Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/8/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/8/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/8/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/8/mdres.ogv\"/></applet></video> Videos Home Channels", "http://architaagarwal.com/": "Home Publications Archita Agarwal E-mail: archita.agarwal19@gmail.com About Me I am a computer scientist focusing on cryptography and distributed systems. I currently work in the Cryptography Research Group of MongoDB where I design protocols to integrate cryptography into large distributed storage systems, thus making them inherently secure to use. Even though I am a cryptographer by training, I have very broad research interests touching multiple subfields of computer science, including approximation algorithms, databases, and social networks. For example, during my stay at IBM Research, I developed data analysis and visualization tools for large weather datasets, and also designed approximation algorithms for set cover and resource allocation problems. Before joining MongoDB, I was an Assistant Professor for a year at Denison University in Ohio, where I taught both introductory and intermediate CS courses. In general, I like to experiment with non-traditional teaching methods such as flipped classrooms, group exercises to teach content, and theming courses to make them more fun. In my spare time, you can find me challenging a friend to a card game; I take pride in knowing at least 30 of them. I am passionate about all things beach-related, watercoloring, and Hindi music. I dream of one day owning a board-game cafe on an ocean beach where people can paint and play to relax with Hindi music older than 2010 playing in the background. I love cricket but I am very slowly moving toward soccer.", "https://cs.brown.edu/video/195/": "A Conversation with Freeman Dyson <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/9/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/9/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/9/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/9/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 31, 2015, 2:27 p.m. Duration 0:49:27 Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/F/9/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/F/9/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/F/9/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/F/9/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/video/351/": "Distinguished Lecture: E\u200blizabeth Mynatt <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/K/L/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/K/L/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/K/L/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/K/L/mdres.ogv\"/></applet></video> 1280x720 512x288 640x360 Channel 2018 Talks Owner John Meehan Group no group Published Feb. 8, 2018, 11:05 p.m. Duration 1:05:01 E\u200blizabeth Mynatt Georgia Tech Thursday, February 8, 2017 at 4:00 PM Room 368 (CIT 3rd Floor) Rethinking Ubiquitous Computing to Transform Healthcare Healthcare for chronic disease is the dominant cost for many healthcare systems, now and for the foreseeable future. The unique capabilities of pervasive computing technologies have the potential to transform healthcare by shifting care from institutional to home settings, by helping individuals engage in their own care, by facilitating problem solving and decision making, and by creating a network of communication and collaboration channels that extends healthcare delivery to everyday settings. In this talk, I will draw from a number of research projects that integrate computing research, human-centered design, and health management theory to create promising approaches for promoting wellness, supporting behavior change and delivering improved health outcomes. Dr. Elizabeth Mynatt is Distinguished Professor in the College of Computing and the Executive Director of Georgia Tech\u2019s Institute for People and Technology (IPaT). IPaT aims to promote healthy, productive and fulfilling lives on a global scale. By fostering an interdisciplinary and collaborative environment between Georgia Tech faculty, students, and external partners, IPaT provides the continuity and capacity to address and solve today\u2019s scientific, social, and economic grand challenges surrounding the health and well\u200b \u200bbeing of people, their families, and communities. In her research, Mynatt directs the Everyday Computing Lab. There she investigates the design and evaluation of health information technologies including creating personalized mobile technology for supporting breast cancer patients during their cancer journey, evaluating mobile sensing and mHealth engagement for pediatric epilepsy patients and their caregivers, and investigating the positive and negative influence of social media on self-harm behaviors such as eating disorders. She is also one of the principal researchers in the Aware Home Research Initiative; investigating the design of future home technologies, especially those that enable older adults to continue living independently as opposed to moving to an institutional care setting. Mynatt is also the Chair of the Computing Community Consortium, an NSF-sponsored effort to engage the computing research community in envisioning more audacious research challenges. She serves as member of the National Academies Computer Science and Telecommunications Board (CSTB) and as an ACM Council Member at Large. She has been recognized as an ACM Fellow, a member of the SIGCHI Academy, and a Sloan and Kavli research fellow. She has published more than 100 scientific papers and chaired the CHI 2010 conference, the premier international conference in human-computer interaction. Prior to joining the Georgia Tech faculty in 1998, Mynatt was a member of the research staff at Xerox PARC. Host: Professor Amy Greenwald Embed this video: <video controls width=\"640\" height=\"360\" poster=\"http://streamod.cs.brown.edu:8801/K/L/mdres.jpg\" > <source type=\"video/mp4\" src=\"http://streamod.cs.brown.edu:8801/K/L/mdres.mp4\" /> <source type=\"video/ogg\" src=\"http://streamod.cs.brown.edu:8801/K/L/mdres.ogv\" /> <applet code=\"com.fluendo.player.Cortado.class\" archive=\"/cortado/cortado.jar\" width=\"640\" height=\"360\"><param name=\"url\" value=\"http://streamod.cs.brown.edu:8801/K/L/mdres.ogv\"/></applet></video> Videos Home Channels", "https://cs.brown.edu/~amazzett/": "Alessio Mazzetto Publications Alessio Mazzetto amazzett [at] cs [dot] brown [dot] edu PhD student in Computer Science Advisor: Eli Upfal || Brown University My CV Google Scholar I am a fifth year Computer Science Ph.D. student at Brown University with a research focus in Theoretical Computer Science , where I am fortunate to be advised by Eli Upfal. In Spring 2024, my work is supported by the Kanellakis Fellowship. In Fall 2023, I was a co-instrucor for Advanced Introduction to Probability for Computing and Data Science ( CS145 . In Summer 2023, I was an intern at Yahoo! Research on the Scalable Machine Learning team. My main research area is Machine Learning Theory . I am broadly interested in learning settings where there is access to a small amount of data for the target task. In my work, I developed theoretically sound methods that can quantify and use the knowledge provided by different sources other than labeled data for weak supervision . Recently, I worked on the problem of learning with distribution drift , where we are given a sequence of samples from a distribution that gradually changes in time, and we want to solve a learning task with respect to the current distribution. Prior to coming to Brown, I completed a Master in Computer Science and a Bachelors in Information Engineering from University of Padua in Italy. News January 2024 : My first solo-author paper An Improved Algorithm for Learning Drifting Discrete Distributions was accepted at AISTATS 2024! September 2023 : Our paper An Adaptive Algorithm for Learning with Unknown Distribution Drift was accepted at NeurIPS 2023! April 2023 : Our paper Nonparametric Density Estimation under Distribution Drift was accepted at ICML 2023! Publications An Improved Algorithm for Learning Drifting Discrete Distributions Alessio Mazzetto To appear in Artificial Intelligence and Statistics (AISTATS) 2024 An Adaptive Algorithm for Learning with Unknown Distribution Drift Alessio Mazzetto and Eli Upfal Conference on Neural Information Processing Systems (NeurIPS) 2023 [ pdf ] Nonparametric Density Estimation under Distribution Drift Alessio Mazzetto and Eli Upfal International Conference on Machine Learning (ICML) 2023 [ pdf ] Tight Lower Bounds on Worst-Case Guarantees for Zero-Shot Learning with Attributes Alessio Mazzetto*, Cristina Menghini*, Andrew Yuan, Eli Upfal, and Stephen H. Bach Conference on Neural Information Processing Systems (NeurIPS) 2022 [ pdf ] Adversarial Multiclass Learning under Weak Supervision with Performance Guarantees Alessio Mazzetto*, Cyrus Cousins*, Dylan Sam, Stephen H. Bach, and Eli Upfal International Conference on Machine Learning (ICML) 2021 [ pdf ][ code ] Semi-Supervised Aggregation of Dependent Weak Supervision Sources with Performance Guarantees Alessio Mazzetto, Dylan Sam, Andrew Park, Eli Upfal, and Stephen H. Bach Artificial Intelligence and Statistics (AISTATS) 2021 [ pdf ][ appendix ][ code ] Accurate MapReduce Algorithms for k-Median and k-Means in General Metric Spaces Alessio Mazzetto, Andrea Pietracaprina, and Geppino Pucci International Symposium on Algorithms and Computation (ISAAC) 2019 [ pdf ] Manuscripts An Adaptive Method for Weak Supervision with Drifting Data Alessio Mazzetto, Reza Esfandiarpoor, Eli Upfal, and Stephen H. Bach Preprint. Under submission. [ pdf ][ code ] Awards \u201cBest Master Thesis in Theoretical Computer Science\u201d award from Capitolo Italiano of EATCS , 2020. The award was given to the best master thesis in Theoretical Computer Science in Italy for the year 2019. Alessio Mazzetto Last Updated: September 2023", "https://cs.brown.edu/~aritz/": "HOME RESEARCH PUBLICATIONS SOFTWARE TEACHING Contact Info: Dept. of Computer Science 114 McBryde Hall (0106) Virginia Tech Blacksburg, VA 24061 Email: annaritz-at-vt-dot-edu I am currently a Postdoctoral Associate in the Department of Computer Science at Virginia Tech , working with T. M. Murali . I develop graph and hypergraph algorithms for signaling pathway prediction. I received my PhD in 2012 from the Department of Computer Science at Brown University , advised by Ben Raphael . My dissertation focused on developing algorithms for structural variant detection for a number of different experimental applications, including array-CGH and various DNA sequencing technologies. I received my Master's from Brown in 2008 for work in motif identification from phosphoproteomic data. From 2008-2011, I was a National Science Foundation Graduate Research Fellowship Program (GRFP) Fellow. I received my undergraduate degree from Carleton College in 2006. Advised by Dave Musicant , I worked with chemists to develop useful and scalable tools to analyze atmospheric particles.", "https://cs.brown.edu/~bcz/": "Intra-Mural Football Champs, 2001", "https://cs.brown.edu/~bjm/": "", "https://cs.brown.edu/people/am104/": "Ahmad Mahmoody Site Navigation [Skip] Sidebar [Skip] Contact: [first name] AT CS dot BROWN dot EDU Department of Computer Science, Brown University, B.O. 1910 115 Waterman St., Providence , RI zip: 02912 I am a PhD candidate at the Department of Computer Science of Brown University working under the supervision of Eli Upfal . I am interested in Graphs/Data mining, and the theory of Machine Learning. Previously, I have done some work in studying cancer evolution under supervision of Ben Raphael . I did my undergraduate studies in mathematics at Sharif University of Technology . Graph Theory, Combinatrics and Linear Algebra were my favorites. During my Masters in mathematics at Simon Fraser University I became interested in the field of Computational Biology and worked under the supervision of Cedric Chauve and Ladislave Stacho . (My master thesis ). You can download my CV from here . Publications _____________________________________________________________________________ A. Mahmoody and E. Upfal Optimizing Static and Adaptive Probing Schedules for Rapid Event Detection (EXTENDED) To Appear in Theoretical Computer Science. _____________________________________________________________________________ A. Mahmoody, C. E. Tsourakakis, and E. Upfal Scalable Betweenness Centrality Maximization via Sampling The 22nd ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2016). _____________________________________________________________________________ A. Mahmoody, M. Riondato, and E. Upfal Wiggins: Detecting Valuable Information in Dynamic Networks Using Limited Resources The 9th ACM International Conference on Web Search and Data Mining (WSDM 2016). _____________________________________________________________________________ A. Mahmoody, E. kornaropoulos, and E. Upfal Optimizing Static and Adaptive Probing Schedules for Rapid Event Detection The 9th Annual International Conference on Combinatorial Optimization and Applications (COCOA'15). _____________________________________________________________________________ A. Mahmoody, I. Hajirasouliha, and B. Raphael, Binary tree partitions: A combinatorial approach for analyzing intra-tumor heterogeneity from high-throughput sequencing data . , The 22th Annual International Conference Intelligent Systems for Molecular Biology, ISMB 2014, (Also, Bioinformatics 30 (12), i78-i86). _____________________________________________________________________________ L. Oesper, A. Mahmoody, and B. Raphael, Inferring Intra-tumor Heterogeneity from High-Throughput DNA Sequencing Data , Genome Biology. A preliminary version accepted at 17th Annual International Conference on Research in Computational Molecular Biology (RECOMB 2013), LNCS 7821, Pages 171--172 (Extended Abstract). _____________________________________________________________________________ A. Mahmoody, C. Kahn, and B. Raphael, Reconstructing Genome Mixtures From Partial Adjacencies , RECOMB-CG, BMC Bioinformatics 2012, 13(Suppl 19):S9. _____________________________________________________________________________ Ahmad Mahmoody, Tractability Results for The Double-Cut-and-Join Mutlichromosomal Median Problem , M.Sc. Thesis, Simon Fraser University, 2011. _____________________________________________________________________________ Ahmad Mahmoody, A Note on Graceful Graphs with Large Chromatic Numbers , Ars Combinatoria 90 (2009), 423--424. _____________________________________________________________________________ S. Akbari, N. Ghareghani, G.B. Khosrovshahi, and A. Mahmoody, On Zero-Sum 6-flows of Graphs , Linear Algebra and Its Appl. 430 (2009), no. 11-12, 3047--3052. _____________________________________________________________________________ S. Akbari, M. Jamaali, A. Mahmoody, and S. A. Seyed Fakhari, On the size of graphs whose cycles have length divisible by a fixed integer , Australasian Journal of Combinatorics 45 (2009), 67--72. _____________________________________________________________________________ A. Mahmoody, P. Ronagh, and K. Alishahi, \"Introductory Combinatorics\" (Book in Persian), Fatemi Pub. Co., Tehran, Iran, March 2009. _____________________________________________________________________________ [Back To Top] var _gaq = _gaq || []; _gaq.push(['_setAccount', 'UA-40607984-1']); _gaq.push(['_trackPageview']); (function() { var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })();", "https://cs.brown.edu/~ccousins/": "About News Major Projects Publications Teaching Curriculum Vitae The Life and Times of Cyrus Cousins \ud83d\udd0a Finitely Wise, Infinitely Curious About Me Abridged Biography I am Cyrus Cousins, a visiting assistant professor at Brown University in the BIGDATA group, where I also completed my doctoral studies under the tutelage of the great Eli Upfal .Before arriving at Brown University, I earned my undergraduate degree in computer science, mathematics, and biology from Tufts University. My research interests lie primarily in showing novel techniques to bound uniform convergence rates and generalization error in exotic settings, and applying these bounds to tasks of real-world interest, most notably in data science, empirical game theory, and fair machine learning. My favorite theorem is the Dvoretzky-Kiefer-Wolfowitz Inequality , and my favorite algorithm is simulated annealing . Research Overview In my research, I strive to strike a delicate balance between theory and practice.On the theory side, my work primarily lies in sample complexity analysis for machine learning algorithms, as well as time complexity analysis and probabilistic guarantees for efficient sampling-based routines in randomized algorithms and statistical data science [1] [2] [3] [4] .In addition to statistical analysis, much of my work deals with delicate computational questions, like how to optimally characterize and estimate the sample-complexity of various estimation tasks (with applications to oblivious algorithms, which achieve near-optimal performance while requiring limited a priori knowledge), as well as the development of fair-PAC learning , with the accompanying computational and statistical reductions between classes of learnable models. On the practical side, much of my early work was led by the observation that modern methods in statistical learning theory (Rademacher averages and localized Rademacher averages) often yield vacuous or unsatisfying guarantees, so I strove to understand why, and to show sharper bounds , with particular emphasis on constant factors and performance in the small sample setting . From there, I have worked to apply statistical methods developed for these approaches to myriad practical settings, including statistical data science tasks, and the analysis of machine learning, and more recently, fairness sensitive machine learning algorithms. By blurring the line between theory and practice, I have been able to adapt rigorous theoretical guarantees to novel settings. For example, my work on adversarial learning from weak supervision stemmed from a desire to apply statistical learning theory techniques in absentia of sufficient labeled data. Conversely, I have also been able to treat theoretical problems that previously seemed unmotivated or irrelevant; my work in fair machine learning led to the fair-PAC learning formalism, where power-means over per-group losses (rather than averages) are minimized. The motivation to optimize power-means derives purely from the economic theory of cardinal welfare, but the value of this learning concept only becomes apparent when one observes that many of the desirable (computational and statistical) properties of risk minimization directly translate to power-mean minimization. Research Statements My research statement is publicly available (5 pages). The best (mostly current) overview of my research is given in my thesis summary (4 pages). The piece is a non-mathematical, but still somewhat technical, overview of my dissertation . The best mathematical overview of my research for general audiences is given in this piece (5 pages). Here the focus is less on applications and implications, and more on intuition for the deeper mathematical connections between my various areas of study. Results are selected for elegance and simplicity, and the piece should be broadly accessible to all audiences with a basic grounding in probability and statistics. News 2021 I was honored to recieve a NeurIPS 2021 Outstanding Reviewer Award . This award is given to the top 8% of reviewers, based on area chair and author feedback. It even came with free registration to the entire conference ! I received the Dean's Faculty Fellowship at Brown University, and will be returning to Brown University in the fall of 2021 as a visiting assistant professor, in order to continue my research and to teach . On March 25, I successfully defended my thesis . I was awarded the Joukowsky Outstanding Dissertation Prize (in the physical sciences) for my dissertation Bounds and Applications of Concentration of Measure in Fair Machine Learning and Data Science . 2020 I survived an apocalyptic event, largely by staying inside, writing my dissertation , and publishing many papers . 2019 I will be returning to the Labs group at Two Sigma Investments to work with Larry Rudolph . 2018 I have accepted a summer internship offer with Two Sigma Investments, and will be working with Matteo Riondato in the Labs group. Major Projects Axiomatically Justified and Statistically Sound Fair Machine Learning Fair Adversarial Machine Learning from Partial Demographic Information Making mean-estimation more efficient using an MCMC trace variance approach: DynaMITE Adversarial Multi Class Learning under Weak Supervision with Performance Guarantees Sharp Uniform Convergence Bounds through Empirical Centralization CADET: Interpretable Parametric Conditional Density Estimation with Decision Trees and Forests Empirical Game Theoretic Analysis My dissertation: Bounds and Applications of Concentration of Measure in Fair Machine Learning and Data Science A Complete List of Publications Find My Work DBLP Google Scholar ResearchGate Scopus ArXiv Teaching Professor Fall 2021: CS1450: Advanced Introduction to Probability for Computing and Data Science Graduate Teaching Assistant Spring 2020: CS2550/CS1550: Probabilistic Methods in Computer Science , with professor Eli Upfal Fall 2018: CS1450: Advanced Introduction to Probability for Computing and Data Science , with professor Eli Upfal Spring 2018: DATA2040: Deep Learning and Special Topics in Data Science , with professors Eli Upfal and Dan Potter Fall 2016: CS1810: Computational Molecular Biology , with professor Sorin Istrail Curriculum Vitae (CV) Last updated: August 2022", "https://cs.brown.edu/~dhl/": "David H. Laidlaw Computer Science Brown University Visualization Research Lab lab research pages Research Interests Caltech graphics group Beckman Institute Biology division web pages Some of the projects I am directing and participating in are alsodescribed in the scientific visualization pages of the Brown Graphics Group. Check out the VR Wiki that my cs1951t class has been building. My CV lists publications, teaching,service, funding, and has links to papers. List of allpublications at DPLP , and at PubMed diffusion MRI data Questions, comments, suggestions? E-mail me: dhl@cs.brown.edu Office: CIT 521 Snail mail: Box 1910, Computer Science Department Brown University Providence, RI 02912 Packages: Computer Science Dept 115 Waterman St 4th floor Providence, RI 02906 401-863-7600 (voice) 401-863-7657 (fax) For students If you are in CS, See my tips for advisees page var gaJsHost = ((\"https:\" == document.location.protocol) ? \"https://ssl.\" : \"http://www.\");document.write(unescape(\"%3Cscript src='\" + gaJsHost + \"google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E\")); var pageTracker = _gat._getTracker(\"UA-4338065-1\");pageTracker._initData();pageTracker._trackPageview();", "https://david-abel.github.io/": "David Abel Home Publications Notes Teaching Blog Collaborators Welcome! I am a Senior Research Scientist at DeepMind in the UK. Before that, I completed my Ph.D in Computer Science at Brown University where I was fortunate to be advised by Prof. Michael Littman . I got my start in research working with Prof. Stefanie Tellex at Brown, and before that studied Philosophy and Computer Science at Carleton College. News Aug. 2024: On a panel at RLC . Jun. 2024: Giving a talk at a workshop in Bath May 2024: Visiting Montreal. Apr. 2024: Visiting the Autonomous Agents group at the University of Edinburgh. Mar. 2024: I am moving to Edinburgh, Scotland. Feb. 2024: Podcast with Ather. Dec. 2023: Attending NeurIPS. Oct. 2023: Recording of Three Dogmas of Reinforcement Learning available. Oct. 2023: Podcast with Ron. Sep. 2023: A Definition of Continual Reinforcement Learning accepted to NeurIPS. Jul. 2023: Attended ICML and gave a talk at the interactive learning workshop . Jun. 2023: Attended a workshop in California. Apr. 2023: Settling the Reward Hypothesis accepted to ICML Apr. 2023: Guest lecture in Prof. Ben Van Roy's course at Stanford. Feb. 2023: Attended the Barbados RL Workshop. Jan. 2023: Invited talk at Fidelity AI Lab Interests My research focuses on bringing clarity to the central philosophical questions surrounding agency, computation, and learning. I value research that provides new understanding, and tend to get excited by simple but foundational questions. I typically work with the reinforcement learning problem, drawing on tools and perspectives from across philosophy, math, and computer science. I am currently interested in better defining the main concepts of AI, such as learning, agency, and goals. Previously, my dissertation studied how agents model the worlds they inhabit, focusing on the representational practices that underly effective learning and planning. Featured Research A Definition of Continual Reinforcement Learning NeurIPS 2023 We present a precise definition of the continual reinforcement learning problem. Joint with Andr\u00e9 Barreto , Benjamin Van Roy , Doina Precup , Hado van Hasselt , and Satinder Singh . Settling the Reward Hypothesis ICML 2023 We illustrate the implicit requirements on goals and purposes under which the reward hypothesis holds. Led by Michael Bowling and John D. Martin , joint with Will Dabney . People Construct Simplified Mental Representations to Plan Nature 2022 We develop a new theory describing how people simplify and represent problems when planning. Led by Mark K. Ho , joint with Carlos G. Correa , Jonathan D. Cohen , Michael L. Littman , Thomas L. Griffiths . On the Expressivity of Markov Reward NeurIPS 2021 (Outstanding Paper Award) We study the expressivity of Markov reward functions in finite environments by analysing what kinds of tasks such functions can express. Joint work with Will Dabney , Anna Harutyunyan , Mark K. Ho , Michael L. Littman , Doina Precup , Satinder Singh . A Theory of Abstraction in Reinforcement Learning Ph.D Thesis, 2020 My dissertation, aimed at understanding abstraction and its role in effective reinforcement learning. Advised by Michael L. Littman . Value Preserving State-Action Abstractions AISTATS 2020 We prove which combinations of state abstractions and options are guaranteed to preserve representation of near-optimal policies in any finite Markov Decision Process. Joint work with Nate Rahn , Khimya Khetarpal , Dilip Arumugam , Doina Precup , and Michael L. Littman . The Value of Abstraction Current Opinions in Behavioral Science 2019 We discuss the vital role that abstraction plays in efficient decision making. Led by Mark K. Ho , joint with Michael L. Littman , Thomas L. Griffiths . Finding Options that Minimize Planning Time ICML 2019 We prove that the problem of finding options that minimize planning time is NP-Hard. Led by Yuu Jinnai , joint with D Ellis Hershkowitz , Michael L. Littman , and George Konidaris . Selected Awards Outstanding Paper Award , NeurIPS 2021, On the Expressivity of Markov Reward Presidential Award for Excellence in Teaching , Brown University Runner-Up , 2020 AAAI/ACM SIGAI Dissertation Award 7x Top Reviewer: ICML 2018, 2019, 2020, 2021; NeurIPS 2019, 2020, AISTATS. About Me I'm a big fan of basketball, lifting, baking, reading, games, snowboarding, and music (I play guitar/piano/violin and love listening to just about everything). I live in Edinburgh with my wife Elizabeth and our dog Barley. Always up for a chat -- shoot me an email if you'd like to discuss anything! If you would like to arrange a call, I have a recurring open slot in my calendar here . If you have feedback of any kind, please feel free to fill out this anonymous feedback form . Theme based on minimal by orderedlist Copyright David Abel document.write(new Date().getFullYear())", "https://cs.brown.edu/people/cerway/": "C. Chris Erway Hi! I received a PhD from Brown in 2011.My advisor was John Jannotti .Since then I co-founded Tracelytics , and am now Chief Architect of the SolarWinds Monitoring Cloud . cce@cs (dot brown dot ee-dee-yew) academics, publications While at Brown I was a member of the Brownie Points project , which aimed to provide incentives and accountability in peer-to-peer systems using secure, anonymous e-cash. Before that I worked on the BlueGene/L systems software team at IBM Research to help build the world's fastest supercomputer. As the Brown CS blog noted , our DPDP paper was recently ranked by Influential Security Papers as the 4th most cited paper in computer security in 2009, and the 50th most cited paper since 1981! \u201cDynamic Provable Data Possession.\u201d C. Chris Erway, Alptekin K\u00fcp\u00e7\u00fc, Charalampos Papamanthou, Roberto Tamassia.In ACM Transactions on Information and System Security (TISSEC) , Volume 17 Issue 4, April 2015. ( ACM DL link ) \u201cAnonymous Accounting for Decentralized Systems,\u201d PhD thesis ( pdf ) \u201c ZKPDL : A Language-based System for Efficient Zero-Knowledge Proofs and Electronic Cash.\u201dSarah Meiklejohn, C. Chris Erway, Alptekin K\u00fcp\u00e7\u00fc , Theodora Hinkle, Anna Lysyanskaya. In USENIX Security 2010 . ( pdf , project page ) \u201cDynamic Provable Data Possession.\u201d C. Chris Erway, Alptekin K\u00fcp\u00e7\u00fc, Charalampos Papamanthou, Roberto Tamassia.In ACM CCS 2009 . ( full version on eprint ) \u201c MicroID considered harmful (to privacy) .\u201d C. Chris Erway. Brown CS technical report , 2008. ( PDF , details ) \u201cIncentivizing Outsourced Computation.\u201d Mira Belenkiy, Melissa Chase, C. Chris Erway, John Jannotti, Alptekin K\u00fcp\u00e7\u00fc, Anna Lysyanskaya. In NetEcon 2008 . (full TR version with proofs: pdf ) \u201cMaking P2P Accountable without Losing Privacy.\u201d Mira Belenkiy, Melissa Chase, C. Chris Erway, John Jannotti, Alptekin K\u00fcp\u00e7\u00fc, Anna Lysyanskaya, Eric Rachlin. In WPES 2007 . PET Award finalist! ( press release , pdf ) \u201cDesigning the Network Layer for End-Host Traffic Engineering,\u201d masters thesis, from 2006. ( pdf ) \u201cOptimization of MPI Collective Communication on BlueGene/L Systems.\u201d George Alm\u00e1si, Charles J. Archer, C. Chris Erway, Philip Heidelberger, Xavier Martorell, Jose E. Moreira, Burkhard Steinmacher-Burow, Yili Zheng. In ICS 2005 . ( pdf , ACM ) \u201cEfficient Implementation of Allreduce on BlueGene/L Collective Network.\u201dGeorge Alm\u00e1si, G\u00e1bor D\u00f3zsa, C. Chris Erway, Burkhard D. Steinmacher-Burow.In PVM/MPI 2005 . ( doi.org ) \u201cSystem Management in the BlueGene/L Supercomputer.\u201dGeorge S. Almasi, Leonardo R. Bachega, Ralph Bellofatto, Jos\u00e9 R. Brunheroto, Calin Cascaval, Jos\u00e9 G. Casta\u00f1os, Paul Crumley, C. Christopher Erway, Joseph Gagliano, Derek Lieber, Pedro Mindlin, Jos\u00e9 E. Moreira, Ramendra K. Sahoo, Alda Sanomiya, Eugen Schenfeld, Richard A. Swetz, M. Bae, G. Laib, Kavitha Ranganathan, Yariv Aridor, Tamar Domany, Y. Gal, Oleg Goldshmidt, Edi Shmueli.In IPDPS 2003 . ( pdf ) more publications are listed on DBLP , CSB . other my brown.edu public key ( show ) ( hide ) -----BEGIN PGP PUBLIC KEY BLOCK-----Version: GnuPG v1.2.4 (GNU/Linux)mQGiBEFIXf8RBACKfysBOvzeW9Ysjm7AWzMTUc4xWRKuhhehv8PNqjAnl2kGT0rBWWRqCmslfJohOvJooWwYU87xYI78kYOgQCFRAK2UZfbdUAAAxFduzhX6bq06jIqGsCJdcyYxp5oUUB1qElg8f+WQy6CWhtIJOb0WikbzRrGSLWy6w0t7LmFaxwCgr/cygI642nqsKvfbtNHHPSM30nED/2VqDUeVKKa9mO0xDWUr9QDEPI1uAHXL4ZI7mnxi3ODbWGSz5H4ctFCox6b17txT5N1GF4+eXEGkpK7TkKFmgNIgHD2LFfDINXtfvZNqST/0ZaR97wsJGanxFojY82/7gfL+LmjcpHybr8hmbgdqXDHxM/DjQTYhCa9bV4T3PtpqA/kBzH3F7mMaoJ6NITnaY1buHAQjGO/77nBDa8ZG6uxlf0K6I/hYRbE1qLtxUILUhc3klUD9QKA7CorzYqKMRK+L1gswk2q7mXl2sloCfmaH87u66TyrAUuogzEWp5Npm8Ep4DPk8l5vT+rMk/b08Skwti8AxDtyANtR6gwJ5qfuorYAAAApQ2hyaXMgRXJ3YXkgKEJyb3duIENTKSA8Y2NlQGNzLmJyb3duLmVkdT6IXQQTEQIAHgUCQUhd/wIbAwYLCQgHAwIDFQIDAxYCAQIeAQIXgAAKCRCwHHqQZfa61sn3AJdTmMTGYY+LSl4etgIYMXiF+gLDAJ42AP46Y04Ng+CepAkBZJ5MmkQ+BLkBDQRBSF3/EAQA1LE1VpWysVPUu/Z0x6XXXkGC9tLzsPwJlVr3yukQlqMgClItyACnLc2SNYxbcHUftzVNGlKrriLvHIKDYeZ3OB7XP+l5xryycoOHZ09ko7KIr4ebhfvlFk4v7a+p4SfGqfoRUJ518cr4I2C/TrefPNiSGSBbHLMSWlDGY6ipOx8AAwUD/ilUjDI/qQNecqJY4lSLAWTqyuShQZOurDR9yEp/RvmqI5ZkQgZFRF+OK/uFyDTkN/dJrrnS3z45BEhJmNqJveZl5PBOUqDopHpOmvAU/8MwopoVKj5FpeqluAzLzsQehk5ZLlAE9z5e39FcucHxDcFiaHQkxvpsSa+Tkh5hK5uuiEkEGBECAAkFAkFIXf8CGwwACgkQsBx6kGX2utbN3gCgopk4vqp4IhQ5PYDoU+RzvcrWCXUAniVplgnikdifrdH52Wx7w30XAY6e=0zYF-----END PGP PUBLIC KEY BLOCK----- I play trombone in the What Cheer? Brigade . my sister's blog, Not Eating Out in New York . Brown CS var gaJsHost = ((\"https:\" == document.location.protocol) ? \"https://ssl.\" : \"http://www.\");document.write(unescape(\"%3Cscript src='\" + gaJsHost + \"google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E\")); try {var pageTracker = _gat._getTracker(\"UA-327459-6\");pageTracker._trackPageview();} catch(err) {}", "https://cs.brown.edu/~erfanz/": "Erfan Zamanian Computer Science PhD student at Brown University About Me I am currently on the job market. I am a PhD student in the Computer Science Department at Brown University. I am advised by Tim Kraska and am a member of Data Management Group . I received my BSc from Sharif University of Technology , Iran and my MSc from ETH Zurich , Switzerland under the supervision of Donald Kossmann . I can be reached at erfanz@cs.brown.edu .You can see my resume here . Research Interests High-performance Transactoin Processing Data Management Systems Distributed Systems Systems for Analytics and Data Science Publications Distributed Data Stores Chiller: Contention-centric Transaction Execution and Data Partitioning for Modern Networks , SIGMOD 2020 Rethinking Database High Availability with RDMA Networks , VLDB 2019 The End of a Myth: Distributed Transactions can Scale , VLDB 2017 The End of Slow Networks: It\u2019s Time for a Redesign , VLDB 2016 I-Store: Data Management for Fast Networks , NEDB, 2015 Analytics Systems Locality-aware partitioning in parallel database systems , ACM SIGMOD 2015 Spotgres - Parallel Data Analytics on Spot Instances , IEEE ICDE, 2015 XDB: A novel Database for Data Analytics as a Service , ACM SoCC, 2013 Fault Tolerance Cost-based Fault-tolerance for Parallel Data Processing , ACM SIGMOD 2015 DoomDB - Kill the Query , ACM SIGMOD 2014 Other Crowd Access Path Optimization: Diversity Matters , HCOMP 2015 \u00a9 2018 Erfan Zamanian Carte Noir theme by Jacob Tomlinson (and Simon Brand )", "https://cs.brown.edu/~gmpatter/cocottributes.html": "COCO Attributes: Attributes for People, Animals, and Objects Hays Lab | 2016 People Genevieve Patterson James Hays Abstract In this paper, we discover and annotate visual attributes for the COCO dataset. With the goal of enabling deeper object understanding, we deliver the largest attribute dataset to date. Using our COCO Attributes dataset, a fine-tuned classification system can do more than recognize object categories -- for example, rendering multi-label classifications such as ''sleeping spotted curled-up cat'' instead of simply ''cat''. To overcome the expense of annotating thousands of COCO object instances with hundreds of attributes, we present an Economic Labeling Algorithm (ELA) which intelligently generates crowd labeling tasks based on correlations between attributes. The ELA offers a substantial reduction in labeling cost while largely maintaining attribute density and variety. Currently, we have collected 3.5 million object-attribute pair annotations describing 180 thousand different objects. We demonstrate that our efficiently labeled training data can be used to produce classifiers of similar discriminative ability as classifiers created using exhaustively labeled ground truth. Finally, we provide baseline performance analysis for object attribute recognition. Paper Genevieve Patterson, James Hays. COCO Attributes: Attributes for People, Animals, and Objects. ECCV 2016. paper , Bibtex , poster COCO Attribute Dataset COCO Attribute Dataset Statistics: 84,000 images 180,000 unique objects 196 attributes 29 object categories 3.5 Million objection-attribute pairs Attribute Labels including references to COCO dataset images. Example of how to read COCO Attributes annotations. New Code Release v1.0! (Updated 10/13/2016) This is code for the Flask server used to generate the Mechanical Turk tasks for annotating COCO Attributes. Code for finetuning the COCO Attributes network and training attribute classifiers from other pretrained features is also included. GitHub Repo Pretrained COCO Attributes Network (205 MB) Pretrained COCO Attributes Network with LBDM formatted training data (6.1 GB) \u00a9 2016 genevieve patterson | james hays lab, brown university", "https://cs.brown.edu/people/acrotty/": "Andrew Crotty andrew.crotty@northwestern.edu Google Scholar DBLP About Me I am an Assistant Professor of Computer Science at Northwestern University .I was previously a postdoctoral researcher at Carnegie Mellon University and Brown University . I received my Ph.D. in Computer Science from Brown in 2019. Publications Wan Shen Lim, Matthew Butrovich, William Zhang, Andrew Crotty, Lin Ma, Peijing Xu, Johannes Gehrke, Andrew Pavlo.Database Gyms.CIDR (2023) Andrew Crotty, Viktor Leis, Andrew Pavlo. Are You Sure You Want to Use MMAP in Your Database Management System? CIDR (2022) [talk] Franco Solleza, Andrew Crotty, Suman Karumuri, Nesime Tatbul, Stan Zdonik. Mach: A Pluggable Metrics Storage Engine for the Age of Observability. CIDR (2022) Jiwon Choe, Andrew Crotty, Tali Moreshet, Maurice Herlihy, R. Iris Bahar. HybriDS: Cache-Conscious Concurrent Data Structures for Near-Memory Processing Architectures. SPAA (2022) Andrew Crotty. Hist-Tree: Those Who Ignore It Are Doomed to Learn. CIDR (2021) [talk] Andrew Crotty, Alex Galakatos, Connor Luckett, Ugur Cetintemel. The Case for In-Memory OLAP on \"Wimpy\" Nodes. ICDE (2021) Connor Luckett, Andrew Crotty, Alex Galakatos, Ugur Cetintemel. Odlaw: A Tool for Retroactive GDPR Compliance. ICDE (2021) Andrew Crotty, Alex Galakatos, Tim Kraska. Getting Swole: Generating Access-Aware Code with Predicate Pullups. ICDE (2020) [talk] Amir Ilkhechi, Andrew Crotty, Alex Galakatos, Yicong Mao, Grace Fan, Xiran Shi, Ugur Cetintemel. DeepSqueeze: Deep Semantic Compression for Tabular Data. SIGMOD (2020) Nathaniel Weir, Prasetya Utama, Alex Galakatos, Andrew Crotty, Amir Ilkhechi, Shekar Ramaswamy, Rohin Bhushan, Nadja Geisler, Benjamin Hattasch, Steffen Eger, Ugur Cetintemel, Carsten Binnig. DBPal: A Fully Pluggable NL2SQL Training Pipeline. SIGMOD (2020) Andrew Crotty. NullDB: Instantaneously Answering Any OLAP Query. CIDR (2019) Nathaniel Weir, Andrew Crotty, Alex Galakatos, Amir Ilkhechi, Shekar Ramaswamy, Rohin Bhushan, Ugur Cetintemel, Prasetya Utama, Nadja Geisler, Benjamin Hattasch, Steffen Eger, Carsten Binnig. DBPal: Weak Supervision for Learning a Natural Language Interface to Databases. CAST@VLDB (2019) Alex Galakatos, Andrew Crotty, Tim Kraska. Distributed Machine Learning. EDBS (2018) Alex Galakatos, Andrew Crotty, Emanuel Zgraggen, Carsten Binnig, Tim Kraska. Revisiting Reuse for Approximate Query Processing. VLDB (2017) Emanuel Zgraggen, Alex Galakatos, Andrew Crotty, Jean-Daniel Fekete, Tim Kraska. How Progressive Visualizations Affect Exploratory Analysis. TVCG (2017) Carsten Binnig, Fuat Basik, Benedetto Buratti, Ugur Cetintemel, Yeounoh Chung, Andrew Crotty, Cyrus Cousins, Dylan Ebert, Philipp Eichmann, Alex Galakatos, Benjamin Hattasch, Amir Ilkhechi, Tim Kraska, Zeyuan Shang, Isabella Tromba, Arif Usta, Prasetya Utama, Eli Upfal, Linnan Wang, Nathaniel Weir, Robert C. Zeleznik, Emanuel Zgraggen. Towards Interactive Data Exploration. BIRTE@VLDB (2017) Philipp Eichmann, Andrew Crotty, Alex Galakatos, Emanuel Zgraggen. Discrete Time Specifications in Temporal Queries. CHI LBW (2017) Carsten Binnig, Andrew Crotty, Alex Galakatos, Tim Kraska, Erfan Zamanian. The End of Slow Networks: It's Time for a Redesign. VLDB (2016) Andrew Crotty, Alex Galakatos, Emanuel Zgraggen, Carsten Binnig, Tim Kraska. The Case for Interactive Data Exploration Accelerators (IDEAs). HILDA@SIGMOD (2016) Andrew Crotty, Alex Galakatos, Kayhan Dursun, Tim Kraska, Carsten Binnig, Ugur Cetintemel, Stan Zdonik. An Architecture for Compiling UDF-centric Workflows. VLDB (2015) Andrew Crotty, Alex Galakatos, Emanuel Zgraggen, Carsten Binnig, Tim Kraska. Vizdom: Interactive Analytics through Pen and Touch. VLDB (2015) \u2013 Best Demo Award Andrew Crotty, Alex Galakatos, Kayhan Dursun, Tim Kraska, Ugur Cetintemel, Stanley B. Zdonik. Tupleware: \"Big\" Data, Big Analytics, Small Clusters. CIDR (2015) Carsten Binnig, Ugur Cetintemel, Tim Kraska, Stan Zdonik, Erfan Zamanian, Andrew Crotty. I-Store: Data Management for Fast Networks. NEDB (2015) Andrew Crotty, Alex Galakatos, Tim Kraska. Tupleware: Distributed Machine Learning on Small Clusters. IEEE Data Eng. Bull. (2014) Teaching CS496: Special Topics in Data Systems \u2013 Northwestern University: Fall 2022 (Instructor) 15-445/645: Database Systems \u2013 Carnegie Mellon University: Fall 2021 (Co-Instructor) CSCI 1270: Database Management Systems \u2013 Brown University: Fall 2014 (Grad TA) CSCI 2257: Database Systems and Applications \u2013 Boston College: Spring 2011 (TA), Spring 2012 (TA) Awards & Service Google PhD Fellowship (2016\u20132018) VLDB Best Demo Award (2015) Brown CS Application Feedback Program for Underrepresented Applicants (2020) Brown CS PhD Admissions (2016, 2019) Research PC: SIGMOD '24, VLDB '23, SIGMOD '23, CIDR '23, VLDB '20 Demo PC: VLDB '23, VLDB '22 Reviewer: SIGMOD '18, IEEE Data Eng. Bull. '17, OSDI '16, ICDE '16, SIGMOD '15, HotCloud '14, SIGMOD '14, ICDE '14, SOCC '13", "https://cs.brown.edu/~gmpatter/sunattributes.html": "SUN Attribute Database: Discovering, Annotating, and Recognizing Scene Attributes Hays Lab | 2011 People Genevieve Patterson Xu Chen James Hays Abstract In this paper we present the first large-scale scene attribute database. First, we perform crowd-sourced human studies to find a taxonomy of 102 discriminative attributes. Next, we build the \"SUN attribute database'' on top of the fine-grained SUN categorical database. Our attribute database spans more than 700 categories and 14,000 images and has potential for use in high-level scene understanding and fine-grained scene recognition. We use our dataset to train attribute classifiers, and evaluate how well these relatively simple classifiers can recognize a variety of attributes related to materials, surface properties, lighting, functions and affordances, and spatial envelope properties. Papers Genevieve Patterson, Chen Xu, Hang Su, James Hays. The SUN Attribute Database: Beyond Categories for Deeper Scene Understanding. IJCV 2014. paper , Bibtex Genevieve Patterson, James Hays. SUN Attribute Database: Discovering, Annotating, and Recognizing Scene Attributes. Proceedings of CVPR 2012. paper , Bibtex SUN Attribute Dataset Thisdataset includes the 102 attribute labels x 3 worker annotations for each of the 14340 images included.The subset of images from the SUN Dataset used in this project are also available for download from the link below.Users can also download the SUN dataset images used in this project at the SUN Database website . Attribute Labels(532 KB) including list of images used from SUN dataset. AttributeDB Images(1.7 GB) including all 14340 images used in the SUN Attribute dataset. Attribute Detectors 102 SUN scene attribute detectors using FC7 feature of Places205-AlexNet, courtesy Bolei Zhou (MIT). \u00a9 2012 genevieve patterson | james hays lab, brown university", "https://cs.brown.edu/~gamjad/": "Announcements About Publications Experience Other Interests Contact Me < Ghous Amjad +1 (401) 837-4081 \u00b7 ghous_amjad@brown.edu I am a fifth year PhD student at Brown CS where I work on problems in the area of Cryptography and Applied Cryptography with Seny Kamara and Tarik Moataz . I am a member of the Encrypted Systems Lab and CAPS group at Brown. Recently, my research has been particularly focused on Encrypted Search and Structured Encryption where I work on designing and implementing provably secure, efficient and usable schemes with well defined leakage profiles, that also guarantee various desirable security properties of Searchable Symmetric Encryption schemes such as Forward Privacy, Snapshot Security, Volume-Hiding, Past-Hiding etc. Currently, I am working on new efficient designs for Structured Encryption schemes and Private Data Structures. Before coming to Brown, I was an undergrad at Lahore University of Management Sciences (LUMS) and was advised by Fareed Zaffar . In LUMS, I worked on projects in different areas of Computer Science such as Privacy, Networks and Graphics etc. Please email me for a detailed list of my research and other projects! Recent News: [August 2021] I am very happy to announce that I will be joining the Private Computing team at Google NYC in a full-time role. [May 2021] I successfully defended my PhD Dissertation titled \"Theoretical and Practical Advances in Structured Encryption\". Special thanks to Seny Kamara & Tarik Moataz for all the help over the years and to my committee Moti Yung & Giuseppe Persiano! [September 2020] I will be a Teaching Assistant for Algorithms For The People this Fall. [September 2020] I was an intern at Google NYC this summer with the Private Computing team! I was hosted by Kevin Yeo and Joon Young Seo. [September 2019] I will be a Teaching Assistant for Topics in Applied Cryptography: Crypto for Social Good this Fall. I will be consulting on and be a part of many amazing projects that are expected to come out of his class. Stay tuned! [September 2019] I was an intern at Google NYC this summer with the Private Computing team! I was hosted by Kevin Yeo and Sarvar Patel. [July 2019] I presented my paper titled \"Breach Resistant Structured Encryption\" at PETS 2019 . Video link to the talk is available here . [March 2019] I presented my paper titled \"Forward and Backward Private Searchable Encryption with SGX\" at EuroSec 2019 [September 2018] Nominated for Microsoft Research Fellowship by Brown Computer Science. [March 2018] Won the Award for the best Poster at ACM CODASPY 2018. Also presented our paper on the same work there. Publications Breach-Resistant Structured Encryption [ Paper ] G. Amjad, T. Moataz, S. Kamara PETS '19 Forward and Backward Private Searchable Encryption with SGX [ Paper ] G. Amjad, T. Moataz, S. Kamara EuroSec '19 Forgetting with Puzzles: Using Cryptographic Puzzles to support Digital Forgetting [ Paper ] G. Amjad, S. Mirza, C. P\u00f6pper ACM CODASPY '18 Past-Hiding Dynamic Encrypted Storage: Securing Cloud Data Before and After Server Breaches G. Amjad, S. Patel, G. Persiano, K. Yeo, M. Yung In Submission. Correlation-Secure Leakage: Revisiting Forward Privacy and Achieving Injection Security G. Amjad, T. Moataz, S. Kamara In Progress. Self Erasing and Auditable Databases G. Amjad, S. Kamara, L. Qin In Progress. Experience / Education Summer Intern at Google NYC Hosts: Kevin Yeo and Joon Young Seo Integrated the backend service I developed last year at Google, with an existing API within Google. Implemented a proof of concept prototype for clients within Google, in C++. Vetted the privacy guarantees of the integration and helped flesh out the protocols. June 2019 - September 2019 PhD Candidate at Brown Advisor: Seny Kamara Major: Computer Science. Recieved my Master of Science degree in May 2018. Primarily working on designing and implementing Searchable Encryption Schemes. Serving as a Teaching Assistant for Algorithms For The People August 2016 - Present Summer Intern at Google NYC Hosts: Kevin Yeo and Sarvar Patel Implemented a general backend service for Chrome Password Breach Checker. Vetted the privacy guarantees of the service and helped flesh out the protocol. Implemented load-tests for the service using Google\u2019s various load testing frameworks and programmatically generated queries for the load-tests and end to end latency tests. June 2019 - September 2019 Research Assistant at NYU Abu Dhabi Advisor: Christina P\u00f6pper Our Research was focused on the area of Digital Forgetting. June 2016 - August 2016 Research Assistant, Teaching Assistant and Undergrad at LUMS Advisor: Fareed Zaffar Major: Computer Science. Graduated with the NMF Gold Medal and the Award of Distinction. I have served as a Teaching Assistant for Discrete Mathematics, Data Structures, Operating Systems and Digital Image Processing. August 2012 - May 2016 Selected Coursework Advanced Programming, Algorithms, Data Structures (Class Rank: 1), Software Security and Exploitation, Topics in Advanced Cryptography, Topics in Applied Cryptography, Topics in Software Security, Probabilistic Methods in Computer Science, Artificial Intelligence, Big Data Analytics, Computer Vision, Digital Image Processing, Operating Systems (Class Rank: 1), Network Security, Software Engineering, Databases, Network Security, Cryptography: Classical and Quantum, Topics in Internet Research, Applied Probability Skills C/C++, Java, Python, Rust, MATLAB, SGX, Clusion, SQL, Android, HTML, Network Simulator, Bash Scripting, Spark, R, Pyret, Ruby on Rails, Emulab, TCL, MIPS, JSP Other Interests / Random Things I love to travel. I have been to a few different countries and a lot of cities in the United States. For me, the best thing about travel is that I get to sample and relish in the local cuisine. One of the notable trips I took was my trip to Japan. Majority of my time was spent in Tokyo, Kyoto and Osaka. I did take day trips to Yokohama and Nara. I miss the food I had there everyday. I love New York! Lahore is the best city ever though! Well, you can say I am a little biased. I served as the Chair of Technology on the Brown Graduate Student Council from 2016 to 2018. I also served on the GSC International Committee led by the Chair of International Advocacy. Contact Me Get in touch for a detailed CV, a short resume or for any other queries. I can be reached either by phone (+1 401-837-4081) or email .", "https://cs.brown.edu/~jcmace/": "Jonathan Mace PhD Candidate Department of Computer Science Brown University CV About Me News Publications Education Demos Contact Copyright \u00a9 2018 by Jonathan Mace Jonathan Mace PhD Candidate Brown University Department of Computer Science This web page is deprecated as of September 2018! I am now a tenure-track faculty member at the Max Planck Institute for Software Systems in Saarbr\u00fccken, Germany Click here to visit my home page at MPI-SWS About Me I graduated in May 2018 and I am now a tenure-track faculty member at the Max Planck Institute for Software Systems in Saarbr\u00fccken, Germany! At Brown, I was advised by Professor Rodrigo Fonseca . My research focuses on monitoring, understanding, and enforcing distributed system behaviors . In my PhD work I adapted techniques from end-to-end request tracing to new applications in multi-tenant resource management and dynamic causal profiling . My work on Pivot Tracing introduced baggage , a concept for generic cross-system metadata now widely used by tracing systems like Zipkin and OpenTracing . I am currently working on large-scale end-to-end performance analysis , ranging from data collection, aggregation, and storage, to deriving high-level insights using machine learning and statistical analysis. My ongoing work is a collaboration with researchers in Facebook's tracing and performance groups. Interests Distributed Systems Networking & Operating Systems Multi-Tenant Cloud Systems Multi-Resource Scheduling End-to-End Request Tracing Data-Driven Performance Analysis Recent News 2018-05 I have accepted a faculty position at the Max Planck Institute for Software Systems, in Saarbr\u00fccken, Germany! 2018-01 Our paper on Context Propagation in Distributed Systems was accepted to EuroSys 2018! See you in Portugal. 2017-11 Our SOSP paper, Canopy , was featured on the Morning Paper blog today :) 2017-08 Canopy, our paper on end-to-end tracing at Facebook, is accepted to appear at SOSP 2017. 2017-05 Prototype of our Baggage Definition Language (BDL) compiler and libraries for Java and Go released on GitHub with a paper soon to come 2016-04 2DFQ is accepted to appear in SIGCOMM 2016! This is joint work with my colleagues from Microsoft. 2016-01 I'm very fortunate to be awarded a Facebook Graduate Fellowship ! 2015-10 Pivot Tracing received a Best Paper Award at this year's SOSP Publications SoCC 2018 Weighted Sampling of Execution Traces: Capturing More Needles and Less Hay Pedro Las-Casas, Jonathan Mace , Dorgival Guedes, Rodrigo Fonseca In Proceedings of the 9th ACM Symposium on Cloud Computing (SoCC '18) Abstract End-to-end tracing has emerged recently as a valuable tool to improve the dependability of distributed systems, by performing dynamic verification and diagnosing correctness and performance problems. Contrary to logging, end-to-end traces enable coherent sampling of the entire execution of specific requests, and this is exploited by many deployments to reduce the overhead and storage requirements of tracing. This sampling, however, is usually done uniformly at random, which dedicates a large fraction of the sampling budget to common, 'normal' executions, while missing infrequent, but sometimes important, erroneous or anomalous executions. In this paper we define the representative trace sampling problem, and present a new approach, based on clustering of execution graphs, that is able to bias the sampling of requests to maximize the diversity of execution traces stored towards infrequent patterns. In a preliminary, but encouraging work, we show how our approach chooses to persist representative and diverse executions, even when anomalous ones are very infrequent. @inproceedings{lascasas2018weighted, title={{Weighted Sampling of Execution Traces: Capturing More Needles and Less Hay}}, author={Las-Casas, Pedro and Mace, Jonathan and Guedes, Dorgival and Fonseca, Rodrigo}, booktitle={9th ACM Symposium on Cloud Computing (SoCC '18)},} Ph.D. Thesis 2018 A Universal Architecture for Cross-Cutting Tools in Distributed Systems Jonathan Mace Ph.D. Thesis, Brown University, May 2018 Abstract Recent research has proposed a variety of cross-cutting tools to help monitor and troubleshoot end-to-end behaviors in distributed systems. However, most prior tools focus on data collection and aggregation, and treat analysis as a distinct step to be performed later, offline. This restricts the applicability of such tools to only doing post-facto analysis. However, this is not a fundamental limitation. Recent research has proposed tools that integrate analysis and decision-making at runtime, to directly enforce end-to-end behaviors and adapt to events. In this thesis I present two new applications of cross-cutting tools to previously unexplored domains: resource management, and dynamic monitoring. Retro, a cross-cutting tool for resource management, provides end-to-end performance guarantees by propagating tenant identifiers with executions, and using them to attribute resource consumption and enforce throttling decisions. Pivot Tracing, a cross-cutting tool for dynamic monitoring, dynamically monitors metrics and contextualizes them based on properties deriving from arbitrary points in an end-to-end execution. Retro and Pivot Tracing illustrate the potential breadth of cross-cutting tools in providing visibility and control over distributed system behaviors. From this, I identify and characterize the common challenges associated with developing and deploying cross-cutting tools. This motivates the design of baggage contexts, a general-purpose context that can be shared and reused by different cross-cutting tools. Baggage contexts abstract and encapsulate components that are otherwise duplicated by most cross-cutting tools, and decouples the design of tools into separate layers that can be addressed independently by different teams of developers. The potential impact of a common architecture for cross-cutting tools is significant. It would enable more pervasive, more useful, and more diverse cross-cutting tools, and make it easier for developers to defer development-time decisions about which tools to deploy and support. A Universal Architecture for Cross-Cutting Tools in Distributed Systems @phdthesis{mace2018thesis, title={{A Universal Architecture for Cross-Cutting Tools in Distributed Systems}}, author={Mace, Jonathan}, school={Brown University}, year=2018} EuroSys 2018 Universal Context Propagation for Distributed System Instrumentation Jonathan Mace , Rodrigo Fonseca In Proceedings of the 13th ACM European Conference on Computer Systems (EuroSys '18) Abstract Many tools for analyzing distributed systems propagate contexts along the execution paths of requests, tasks, and jobs, in order to correlate events across process, component and machine boundaries. There is a wide range of existing and proposed uses for these tools, which we call cross-cutting tools, such as tracing, debugging, taint propagation, provenance, auditing, and resource management, but few of them get deployed pervasively in large systems. When they do, they are brittle, hard to evolve, and cannot coexist with each other. While they use very different context metadata, the way they propagate the information alongside execution is the same. Nevertheless, in existing tools, these aspects are deeply intertwined, causing most of these problems.In this paper, we propose a layered architecture for cross-cutting toolsthat separates concerns of system developers and tool developers, enabling independent instrumentation of systems, and the deployment and evolution of multiple such tools. At the heart of this layering is a general underlying format, baggage contexts, that enables the complete decoupling of system instrumentation for context propagation from tool logic. Baggage contexts make propagation opaque and general, while still maintaining correctness of the metadata under arbitrary concurrency and different data types. We demonstrate the practicality of the architecture with implementations in Java and Go, porting of several existing cross-cutting tools, and instrumenting existing distributed systems with all of them. Universal Context Propagation for Distributed System Instrumentation @inproceedings{mace2018universal, title={{Universal Context Propagation for Distributed System Instrumentation}}, author={Mace, Jonathan and Fonseca, Rodrigo}, booktitle={13th ACM European Conference on Computer Systems (EuroSys '18)},} SOSP 2017 Canopy: An End-to-End Performance Tracing And Analysis System Jonathan Kaldor, Jonathan Mace , Micha\u0142 Bejda, Edison Gao, Wiktor Kuropatwa, Joe O'Neill, Kian Win Ong, Bill Schaller, Pingjia Shan, Brendan Viscomi, Vinod Venkataraman, Kaushik Veeraraghavan, Yee Jiun Song In Proceedings of the 26th ACM Symposium on Operating Systems Principles (SOSP '17) ----- Also featured in The Morning Paper Abstract This paper presents Canopy, Facebook\u2019s end-to-end performance tracing infrastructure. Canopy records causally related performance data across the end-to-end execution path of requests, including from browsers, mobile applications, and backend services. Canopy processes traces in near real-time, derives user-specified features, and outputs to performance datasets that aggregate across billions ofrequests. Using Canopy, Facebook engineers can query and analyze performance data in real-time. Canopy addresses three challenges we have encountered in scaling performance analysis: supporting the range of execution and performance models used by different components of the Facebook stack; supporting interactive ad-hoc analysis of performance data; and enabling deep customization by users, from sampling traces to extracting and visualizing features. Canopy currently records and processes over1 billion traces per day. We discuss how Canopy has evolved to apply to a wide range of scenarios, and present case studies of its use in solving various performance challenges. Canopy: An End-to-End Performance Tracing And Analysis System @inproceedings{kaldor2017canopy, title={{Canopy: An End-to-End Performance Tracing And Analysis System}}, author={Kaldor, Jonathan and Mace, Jonathan and Bejda, Micha\\l{} and Gao, Edison and Kuropatwa, Wiktor and O'Neill, Joe and Ong, Kian Win and Schaller, Bill and Shan, Pingjia and Viscomi, Brendan and Vekataraman, Vinod and Veeraraghavan, Kaushik and Song, Yee Jiun}, booktitle={26th ACM Symposium on Operating Systems Principles (SOSP '17)},} SIGCOMM 2016 2DFQ: Two-Dimensional Fair Queuing for Multi-Tenant Cloud Services Jonathan Mace , Peter Bodik, Madanlal Musuvathi, Rodrigo Fonseca, Krishnan Varadarajan In Proceedings of the 2016 ACM SIGCOMM Conference Abstract In many important cloud services, different tenants execute their requests in the thread pool of the same process, requiring fair sharing of resources. However, using fair queue schedulers to provide fairness in this context is difficult because of high execution concurrency, and because request costs are unknown and have high variance. Using fair schedulers like WFQ and WF\u00b2Q in such settings leads to bursty schedules, where large requests block small ones for long periods of time. In this paper, we propose Two-Dimensional Fair Queuing (2DFQ), which spreads requests of different costs across di erent threads and minimizes the impact of tenants with unpredictable requests. In evaluation on production workloads from Azure Storage, a large-scale cloud system at Microsoft, we show that 2DFQ reduces the burstiness of service by 1-2 orders of magnitude. On workloads where many large requests compete with small ones, 2DFQ improves 99th percentile latencies by up to 2 orders of magnitude. 2DFQ: Two-Dimensional Fair Queuing for Multi-Tenant Cloud Services @inproceedings{mace20162dfq, title={{2DFQ: Two-Dimensional Fair Queuing for Multi-Tenant Cloud Services}}, author={Mace, Jonathan and Bodik, Peter and Musuvathi, Madanlal and Fonseca, Rodrigo and Varadarajan, Krishnan}, booktitle={Proceedings of the ACM SIGCOMM 2016 Conference (SIGCOMM '16)},} SOCC 2016 Principled Workflow-Centric Tracing of Distributed Systems Raja R. Sambasivan, Ilari Shafer, Jonathan Mace , Benjamin H. Sigelman, Rodrigo Fonseca, Gregory R. Ganger In Proceedings of the 7th ACM Symposium on Cloud Computing (SOCC '16) Abstract Workflow-centric tracing captures the workflow of causally-related events (e.g., work done to process a request) within and among the components of a distributed system. As distributed systems grow in scale and complexity, such tracing is becoming a critical tool for understanding distributed system behavior. Yet, there is a fundamental lack of clarity about how such infrastructures should be designed to provide maximum benefit for important management tasks, such as resource accounting and diagnosis. Without research into this important issue, there is a danger that workflow-centric tracing will not reach its full potential. To help, this paper distills the design space of workflow-centric tracing and describes key design choices that can help or hinder a tracing infrastructure\u2019s utility for important tasks. Our design space and options for them are based on our experiences developing several previous workflow-tracing infrastructures. Principled Workflow-Centric Tracing of Distributed Systems @inproceedings{sambasivan2016principled, title={{Principled Workflow-Centric Tracing of Distributed Systems}}, author={Sambasivan, Raja R and Shafer, Ilari and Mace, Jonathan and Sigelman, Benjamin H and Fonseca, Rodrigo and Ganger, Gregory R}, booktitle={7th ACM Symposium on Cloud Computing (SoCC '16)},} SOSP 2015 Best Paper Award Pivot Tracing: Dynamic Causal Monitoring for Distributed Systems Jonathan Mace , Ryan Roelke, Rodrigo Fonseca In Proceedings of the 25th ACM Symposium on Operating Systems Principles (SOSP '15) In ACM Transactions on Computer Systems (TOCS, forthcoming 2017 ) In Communications of the ACM (CACM, forthcoming 2017 ) ----- Also featured in The Morning Paper. Abstract Monitoring and troubleshooting distributed systems is notoriously difficult; potential problems are complex, varied, and unpredictable. The monitoring and diagnosis tools commonly used today \u2013 logs, counters, and metrics \u2013 have two important limitations: what gets recorded is defined a priori, and the information is recorded in a component- or machine-centric way, making it extremely hard to correlate events that cross these boundaries. This paper presents Pivot Tracing, a monitoring framework for distributed systems that addresses both limitations by combining dynamic instrumentation with a novel relational operator: the happened-before join. Pivot Tracing gives users, at runtime, the ability to define arbitrary metrics at one point of the system, while being able to select, filter, and group by events meaningful at other parts of the system, even when crossing component or machine boundaries. We have implemented a prototype of Pivot Tracing for Java-based systems and evaluate it on a heterogeneous Hadoop cluster comprising HDFS, HBase, MapReduce, and YARN. We show that Pivot Tracing can effectively identify a diverse range of root causes such as software bugs, misconfiguration, and limping hardware. We show that Pivot Tracing is dynamic, extensible, and enables cross-tier analysis between inter-operating applications, with low execution overhead. Pivot Tracing: Dynamic Causal Monitoring for Distributed Systems @inproceedings{mace2015pivot, title={{Pivot Tracing: Dynamic Causal Monitoring for Distributed Systems}}, author={Mace, Jonathan and Roelke, Ryan and Fonseca, Rodrigo}, booktitle={25th ACM Symposium on Operating Systems Principles (SOSP '15)},} NSDI 2015 Retro: Targeted Resource Management in Multi-tenant Distributed Systems Jonathan Mace , Peter Bodik, Rodrigo Fonseca, Madanlal Musuvathi In Proceedings of the 12th USENIX Symposium on Networked Systems Design and Implementation (NSDI '15) Abstract In distributed systems shared by multiple tenants, effective resource management is an important pre-requisite to providing quality of service guarantees. Many systems deployed today lack performance isolation and experience contention, slowdown, and even outages caused by aggressive workloads or by improperly throttled maintenance tasks such as data replication. In this work we present Retro, a resource management framework for shared distributed systems. Retro monitors per-tenant resource usage both within and across distributed systems, and exposes this information to centralized resource management policies through a high-level API. A policy can shape the resources consumed by a tenant using Retro\u2019s control points, which enforce sharing and rate-limiting decisions. We demonstrate Retro through three policies providing bottleneck resource fairness, dominant resource fairness, and latency guarantees to high-priority tenants, and evaluate the system across five distributed systems: HBase, Yarn, MapReduce, HDFS, and Zookeeper. Our evaluation shows that Retro has low overhead, and achieves the policies\u2019 goals, accurately detecting contended resources, throttling tenants responsible for slowdown and overload, and fairly distributing the remaining cluster capacity. Retro: Targeted Resource Management in Multi-tenant Distributed Systems @inproceedings{mace2015retro, title={{Retro: Targeted Resource Management in Multi-tenant Distributed Systems}}, author={Mace, Jonathan and Bodik, Peter and Fonseca, Rodrigo and Musuvathi, Madanlal}, booktitle={12th USENIX Symposium on Networked Systems Design and Implementation (NSDI '15)},} HPTS 2015 We are Losing Track: a Case for Causal Metadata in Distributed Systems Rodrigo Fonseca, Jonathan Mace In Proceedings of the 15th International Workshop on High Performance Transaction Systems (HPTS '15) As our systems move to more concurrent and distributed execution patterns, the tools and abstractions we have to understand, monitor, schedule, and enforce their behavior become progressively less effective or adequate. We argue that systems should be built with causal propagation of generic metadata as a first class primitive, to serve as the narrow waist upon which many debugging and troubleshooting tools could be built, in an analogy to the role of the IP layer in networking We are Losing Track: a Case for Causal Metadata in Distributed Systems @inproceedings{fonseca2015losing, title={{We are Losing Track: a Case for Causal Metadata in Distributed Systems}}, author={Fonseca, Rodrigo and Mace, Jonathan}, booktitle={15th International Workshop on High Performance Transaction Systems (HPTS '15)},} HotDep 2014 Towards General-Purpose Resource Management in Shared Cloud Services Jonathan Mace , Peter Bodik, Rodrigo Fonseca, Madanlal Musuvathi In Proceedings of the 10th Workshop on Hot Topics in Dependability (HotDep '14) Abstract In distributed services shared by multiple tenants, managing resource allocation is an important pre-requisite to providing dependability and quality of service guarantees. Many systems deployed today experience contention, slowdown, and even system outages due to aggressive tenants and a lack of resource management. Improperly throttled background tasks, such as data replication, can overwhelm a system; conversely, high-priority background tasks, such as heartbeats, can be subject to resource starvation. In this paper, we outline \u009dve design principles necessary for e\u009affective and e\u009bfficient resource management policies that could provide guaranteed performance, fairness, or isolation. We present Retro, a resource instrumentation framework that is guided by these principles. Retro instruments all system resources and exposes detailed, real-time statistics of pertenant resource consumption, and could serve as a base for the implementation of such policies. Towards General-Purpose Resource Management in Shared Cloud Services @inproceedings{mace2014towards, title={{Towards General-Purpose Resource Management in Shared Cloud Services}}, author={Mace, Jonathan and Bodik, Peter and Fonseca, Rodrigo and Musuvathi, Madanlal}, booktitle={10th Workshop on Hot Topics in System Dependability (HotDep '14)}, year={2014}} Other Documents 2018 Job Application Documents Jonathan Mace Documents relating to my academic job search in 2018 These are the application documents I used during my faculty job search in 2018. The outcome of my job search was to accept a faculty position at the Max Planck Institute for Software Systems. CV Diversity Statement Research Statement Teaching Statement Survey 2017 End-to-End Tracing: Adoption and Use Cases Jonathan Mace Survey, Brown University, March 2017 Abstract This document summarizes information about end-to-end tracing for 26 companies. The information was gathered from documents shared to the Distributed Tracing Workgroup and through in-person conversations at tracing workshops. End-to-End Tracing: Adoption and Use Cases @techreport{mace2017survey, title={{End-to-End Tracing: Adoption and Use Cases}}, author={Jonathan Mace}, type={{Survey}}, institution={Brown University}, year={2017},} ;login: 2016 Pivot Tracing: Dynamic Causal Monitoring for Distributed Systems Jonathan Mace , Ryan Roelke, Rodrigo Fonseca USENIX ;login: Magazine, Spring 2016 Abstract Pivot Tracing is a monitoring framework for distributed systems that can seamlessly correlate statistics across applications, components, and machines at runtime without needing to change or redeploy system code. Users can define and install monitoring queries on-the-fly to collect arbitrary statistics from one point in the system while being able to select, filter, and group by events meaningful at other points in the system. Pivot Tracing does not correlate cross-component events using expensive global aggregations, nor does it perform offline analysis. Instead, Pivot Tracing directly correlates events as they happen by piggybacking metadata alongside requests as they execute\u2014even across component and machine boundaries. This gives Pivot Tracing a very low runtime overhead\u2014less than 1% for many cross-component monitoring queries. Pivot Tracing: Dynamic Causal Monitoring for Distributed Systems M.Sc. Project 2013 Revisiting End-to-End Trace Comparison with Graph Kernels Jonathan Mace , Rodrigo Fonseca Master's Project, Brown University, May 2013 Abstract End-to-end tracing has emerged recently as a valuable tool to improve the dependability of distributed systems by performing dynamic verification and diagnosing correctness and performance problems. End-to-end traces are commonly represented as richly annotated directed acyclic graphs, with events as nodes and their causal dependencies as edges. Being able to automatically compare these graphs at scale is a key primitive for tasks such as clustering, classification, and anomaly detection. In this paper we explore recent developments in the theory of graph kernels, and investigate the feasibility of using a family of kernels based on the Weisfeiler-Lehman graph isomorphism test as an efficient and robust graph comparison primitive. We find that graph kernels provide a good formulation of the execution graph comparison problem, and present preliminary but encouraging results on their ability to distinguish high-level differences between execution graphs. Revisiting End-to-End Trace Comparison with Graph Kernels @mastersthesis{mace2013revisiting, title={{Revisiting End-to-End Trace Comparison with Graph Kernels}}, author={Jonathan Mace}, type={{M.Sc. Project}}, school={Brown University}, year={2013},} Experience 2011 - 2018 ( expected ) Ph.D. Candidate Department of Computer Science Brown University, USA Summer 2016 Research Intern Facebook, New York Summer 2013 Summer 2015 Research Intern Microsoft Research, Redmond 2011 - 2014 MSc Computer Science Brown University, USA 2009 - 2011 Software Developer IBM UK 2005 - 2009 Mathematics & Computer Science MMathComp, 1st Class Oxford University, UK Awards 2017 SIGCOMM Student Scholar 50 Years of the ACM Turing Award Celebration 2016 Facebook Graduate Fellowship Pervasive Monitoring, Diagnostics, and Analytics of Distributed Systems through Dynamic Causal Tracing 2016 USENIX ATC \"Best of the Rest\" Invited speaker for Pivot Tracing: Dynamic Causal Monitoring for Distributed Systems 2015 Best Paper Award Pivot Tracing: Dynamic Causal Monitoring for Distributed Systems , SOSP '15 2015 Great TA Award Nominated by students of Brown CS138: Distributed Systems, Spring Semester 2015 Student Scholar 3rd Heidelberg Laureate Forum 2011 Graduate School Fellowship Brown University 2006 Hertford College Scholarship Oxford University , Hertford College Demos Interactive Hadoop Visualization HDFS Swimlane Visualization Hadoop example Spark tracing example Critical Path Analysis example Execution Graph Comparison Execution Graph Clustering Contact Me jcmace @cs.brown.edu (206) 489-6067 @brownsys_jmace JonathanMace jonathanmace +JonathanMace", "https://cs.brown.edu/~jj/startup.html": "csciStartup More than a class In csciStartup, you will incorporate and run a startup. Apply as a team to be a part of a prototype class to remove the mystery from starting a company, and to focus entirely on a product you're passionate about. Apply as a team You should apply if you have a team in place and a product in mind. Teams of two and three are probably best, and a great team might not be all CS students. We will focus on products that a small team can implement in months \u2014 web sites and mobile apps will be the norm. If you nearly have a team in place, and want to meet other students who are looking for a team (or vice versa), you might check out this Facebook group . For this year, you'll ned to apply as a complete group, by January 19th . Apply \u00bb Product Focused We will learn by doing. Each team will incorporate, build a product for real customers, advertise their product, and improve it week after week. We'll spend at least half of our class meetings with individual attention to each group's progress and how to improve your offerings. Assignments will be designed to apply to any company, with enough flexibility to ensure you're always working things that make sense for your business. Lectures / Talks Once a week, we'll have a more traditional \u201cclass\u201d with a topic that should apply broadly to all teams. The current plan is for Tuesday and Thursday meetings, one for progress reports and one for guest lectures. Development environment and hosting. What goes into an MVP? Incorporation, Equity, Vesting Case study: consumer product (Teespring, Foodler) Case study: business product (Vertica, SightPath, Tracelytics) Growth: Advertising, A/B tests, Market testing, Email marketing Hiring (real, contract, gig) Sales Conducting User Studies From MVP to 1.0 Raising money Syllabus \u00bb John Jannotti window.jQuery || document.write('<scr'+'ipt src=\"js/vendor/jquery-1.11.2.min.js\"></scr'+'ipt>')", "https://cs.brown.edu/~jj/": "John Jannotti Courses cs161: Building High-Performance Servers cs168: Computer Networks cs296-2: Large-Scale Networked Systems Publications Distributed Systems Making P2P Accountable Without Losing Privacy XPORT (SIGMOD) XPORT (SeNS) Locality Aware Networked Join Evaluation Overcast: Reliable Multicasting with an Overlay Network System Software BorderPatrol (in submission, write for a copy) Safe at Any Speed: Fast, Safe Parallelism in Servers (poster) Exokernel (MEng) Exokernel (SOSP) Sensors and Mobile Networking Distributed Calibration of Smart Cameras Data-Centric Visual Sensor Networks for 3D Sensing Image Based Routing for Image Based Rendering CarNet Grid Networking/Routing Blind Source Routing (in submission, write for a copy) Reflect/Paint (PhD) Reflect/Paint (OpenArch) Click (TOCS) Click (SOSP) Companies Foodler is a site to order takeout and delivery food in the Boston area. I used to work for Cisco after they bought a content distribution company I worked for, SightPath. jj@cs.brown.edu Box 1910, Computer Science Department Brown University Providence, RI 02912 401-863-7755 (voice) 401-863-7657 (fax)", "https://cs.brown.edu/~jmacglashan/": "[ home ] [ burlap ] [ curriculum vitae ] [ publications ] [ contact ] Welcome Hello and welcome to my home page! I am postdoctoral researcher at Brown University in computer science and I received my PhD in computer science from the University of Maryland, Baltimore County in 2013. My research spans a large range of artificial intelligence topics, though I primarily am involved in reinforcement learning and autonomous planning research. To that end, I am the creator of the Brown-UMBC Reinforcement Learning and Planning (BURLAP) Java library. BURLAP provides a very large range of tools an algorithms from classic A*, to value function approximation, to multi-agent learning in stochastic games. My dissertation work was in transfer learning in reinforcement learning and I also have done research in human-AI interaction, evolutionary dynamics of social reward functions in multi-agent environments, the optimization and evaluation of learning algorithms in classes of environments, and learning planning knowledge to accelerate planning. In the near future, I will be providing example programs/code to demonstrate some of the active research that I am doing and what can be done with BURLAP. [ home ] [ burlap ] [ curriculum vitae ] [ publications ] [ contact ] James MacGlashan \u00a92010", "https://cs.brown.edu/people/ihajiras/": "Iman Hajirasouliha Home About me Events|News Publications Presentations Tools Fun Things Curriculum vitae About me Email: imanh at stanford.edu Please do NOT use my old SFU or Brown email addresses -- they no longer work! I am a Post Doctoral scholar with Serafim Batzoglou at Stanford University. More info ... My Erd\u0151s number is 2! Tweets by @hajirasouliha !function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+\"://platform.twitter.com/widgets.js\";fjs.parentNode.insertBefore(js,fjs);}}(document,\"script\",\"twitter-wjs\"); Research | Publications My research field is \"Computational Biology\" and I am excited about recent developments in genomics and sequencing technologies. See the following short video, featuring Bonnie Berger (my academic grandmother) of MIT, about modern challenges of this field in the 21st century. The highlights of my research can be seen in my publications: A full list of my recent publications is available here . You may also check the following databases: PUBMED | DBLP | Google Scholar (H-index 16) Curriculum vitae (Updated September 2015) NIH Biosketch (Updated September 2015) Events|News I receive a Simons-Berkeley Research Fellowship for the Spring semester 2016 in connection with \"Algorithmic Challenges in Genomics\" program. I served as a Program Committee member for AlCoB 2016 , ISMB/ECCB 2015 , GIW/InCoB 2015 and Genome Medicine 2015 . I presented a Reviewers' Choice poster at the ASHG 2015 , an oral presentation at the ISMB-HitSeq 2015 , and two earlier presentations in the Proceedings Track of ISMB 2014 and WABI 2014 . All were on my recent studies on somatic variations and reconstructing mutational history in heterogeneous tumor samples. A list of upcoming and past events as well as media releases is available here . \u00a9 2012 Iman Hajirasouliha | Template design by andreasviklund.com $(window).load(function() {$('#slider').nivoSlider();}); (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-47653410-1', 'imanh.org'); ga('send', 'pageview');", "https://cs.brown.edu/~kfisler/Pubs/index.html": "Kathi Fisler Publications by Area This list is also available sorted by year . Education for Socially-Responsible Computing [Active Area] A New Model for Weaving Responsible Computing Into Courses Across the CS Curriculum . Lena Cohen, Heila Precel, Harold Triedman, and Kathi Fisler. SIGCSE 2021. Data-Centric Computing Education (for K-12 and University) [Active Area] Data-Centricity: A Challenge and Opportunity for Computing Education . Shriram Krishnamurthi and Kathi Fisler. Communications of the ACM Viewpoint. 2020. Data Science as a Route to AI for Middle- and High-School Students. Shriram Krishnamurthi, Emmanuel Schanzer, Joe Gibbs Politz, Benjamin S. Lerner, Kathi Fisler, Sam DoomanAAAI 2019 Fall Symposium: Teaching AI in K-12, 2019. Computing Education General [Active Area] Harnessing the Wisdom of the Classes: Classsourcing and Machine Learning for Assessment Instrument Generation. Sam Saarinen, Shriram Krishnamurthi, Kathi Fisler and Preston Tunnell Wilson. SIGCSE 2019. What Help Do Students Seek in TA Office Hours? Yanyan Ren, Shriram Krishnamurthi, and Kathi Fisler. ICER 2019. Who Tests the Testers?: Avoiding the Perils of Automated Testing .John Wrenn, Shriram Krishnamurthi, Kathi FislerSIGCSE International Computing Education Research Conference, 2018. Plan Composition (Computing Education) [Active Area] Qualitative Analyses of Movements Between Task-level and Code-level Thinking of Novice Programmers. Francis Castro and Kathi Fisler. SIGCSE 2020. Designing a Multi-Faceted SOLO Taxonomy to Track Program Design Skills Through an Entire Course . Francis Castro and Kathi Fisler. Koli Calling 2017. Best paper award . The Impact of a Single Lecture on Program Plans in First-Year CS (short paper). Francis Castro, Shriram Krishnamurthi, and Kathi Fisler. Koli Calling 2017. ( longer tech report version ) Sometimes, Rainfall Accumulates: Talk-Alouds with Novice Functional Programmers . Kathi Fisler and Francis Castro. ICER 2017. On the Interplay Between Bottom-Up and Data-Driven Program Design . Francis Castro and Kathi Fisler. SIGCSE 2016. Modernizing Plan-Composition Studies . Kathi Fisler, Shriram Krishnamurthi, and Janet Siegmund. SIGCSE 2016. The Recurring Rainfall Problem. Kathi Fisler. International Conference on Computing Education Research (ICER), 2014. [ coding manual, analysis notes, and errata ] Notional Machines and Language Learning (Computing Education) [Active Area] Using Design Alternatives to Learn About Data Organizations . Xingjian Gu, Max A. Heller, Stella Li, Yanyan Ren, Kathi Fisler and Shriram Krishnamurthi. ICER 2020. Programming Paradigms and Beyond . Shriram Krishnamurthi and Kathi Fisler. In The Cambridge Handbook of Computing Education Research. Cambridge University Press, 2019. Evaluating the Tracing of Recursion in the Substitution Notional Machine . Preston Tunnell Wilson, Shriram Krishnamurthi, and Kathi Fisler. SIGCSE 2018. Student Understanding of Aliasing and Procedure Calls . Preston Tunnell Wilson, Kathi Fisler, Shriram Krishnamurthi. SPLASH-E 2017. Assessing and Teaching Scope, Mutation,and Aliasing in Upper-Level Undergraduates . Kathi Fisler, ShriramKrishnamurthi, Preston Tunnell Wilson. SIGCSE 2017 Teaching Programming Languages byExperimental and Adversarial Thinking . Justin Pombrio,Shriram Krishnamurthi, Kathi Fisler. Summit on Advances inProgramming Languages (SNAPL), 2017. Do Values Grow on Trees?: Expression Integrity in Functional Programing. Guillaume Marceau, Kathi Fisler, and Shriram Krishnamurthi. ICER 2011 Discussion Paper. Bootstrap-Related (incl Transfer and Tool Design) [Active Area] Evolving a K-12 Curriculum for Integrating Computer Science into Mathematics Kathi Fisler, Emmanuel Schanzer, Steve Weimar, Annie Fetter, K. Ann Renninger, Shriram Krishnamurthi, Joe Gibbs Politz, Benjamin Lerner, Jennifer Poole, Christine Koerner. SIGCSE 2021. What Does It Mean for a Curriculum to Succeed? Emmanuel Schanzer, Shriram Krishnamurthi, Kathi Fisler.Communications of the ACM, 2019. Assessing Bootstrap:Algebra Students on Scaffolded and Unscaffolded Word Problems . Emmanuel Schanzer, Kathi Fisler, and Shriram Krishnamurthi. SIGCSE 2018. Creativity, Customization, and Ownership: Game Design in Bootstrap:Algebra . Emmanuel Schanzer, Shriram Krishnamurthi, and Kathi Fisler. SIGCSE 2018. Blocks versus Text: Ongoing Lessons from Bootstrap .Emmanuel Schanzer, Shriram Krishnamurthi, and Kathi Fisler.Blocks and Beyond Workshop (in conjunction with VL/HCC), 2015. Transferring Skills atSolving Word Problems from Computing to Algebra ThroughBootstrap. Emmanuel Schanzer, Kathi Fisler, ShriramKrishnamurthi, and Matthias Felleisen. SIGCSE 2015. Bootstrap: Going Beyond Programming in After-School ComputerScience . Emmanuel Schanzer, Kathi Fisler, and ShriramKrishnamurthi. SPLASH-E (Education track of the OOPSLA/SPLASHconference), 2013. WeScheme: The Browser is Your Programming Environment. Danny Yoo, Emmanuel Schanzer, Shriram Krishnamurthi, and Kathi Fisler. ITiCSE 2011. Error Messages (Computing Education) Mind Your Language: On Novices' Interactions with Error Messages . Guillaume Marceau, Kathi Fisler, and Shriram Krishnamurthi. OOPSLA Onward 2011. Measuring the Effectiveness of Error Messages Designed forNovice Programmers . Guillaume Marceau, Kathi Fisler, ShriramKrishnamurthi. (Follow link for comparison to Scheme Workshop '10 paper) ACM SIGCSE 2011. Best Paper Award Measuring the Effectiveness of Error Messages Designed forNovice Programmers . Guillaume Marceau, Kathi Fisler, ShriramKrishnamurthi. Scheme Workshop 2010. Peer Review (Computing Education) Peer Review in Cybersecurity Education . William M. Temple, Kathi Fisler. SPLASH-E 2017. The Sweep: Essential Examples for In-Flow PeerReview . Joe Gibbs Politz, Joseph Collard, ShriramKrishnamurthi, Arjun Guha, and Kathi Fisler. SIGCSE 2016. In-Flow Peer-Review of Tests in Test-First Programming. JoeGibbs Politz, Shriram Krishnamurthi, and Kathi Fisler. InternationalConference on Computing Education Research (ICER), 2014. [ datasources ] In-Flow Peer Review . Dave Clarke, TonyClear, Kathi Fisler, Matthias Hauswirthm, Shriram Krishnamurthi, JoeGibbs Politz, Ville Tirronen, and Tobias Wrigstad. Working groupreport from ITiCSE 2014. CaptainTeach: Multi-Stage, In-Flow Peer Review forProgramming Assignments. Joe Gibbs Politz, Daniel Patterson, ShriramKrishnamurthi, and Kathi Fisler. International Conference onInnovation and Technology in Computer Science Education (ITiCSE),2014. Policy Analysis and Authoring Usable Security as a Static Analysis Problem . HannahQuay de la Vallee, James M. Walsh, William Zimrin, Kathi Fisler, andShriram Krishnamurthi. Onward! 2013. A Balance of Power: Expressive, Analyzable ControllerProgramming . Tim Nelson, Arjun Guha, Daniel J. Dougherty,Kathi Fisler, and Shriram Krishnamurthi. Workshop on Hot Topics inSoftware Defined Networks (HoTSDN), August 2013. Aluminum: Principled ScenarioExploration through Minimality. Tim Nelson, Salman Saghafi,Daniel J. Dougherty, Kathi Fisler, and Shriram Krishnamurthi. ICSE2013. Towards a More Complete Alloy. Tim Nelson, Dan Dougherty,Kathi Fisler, and Shriram Krishnamurthi. ABZ Conference, June2012. Embracing Policy Engineering . Kathi Fisler, Shriram Krishnamurthi, and Daniel J. Dougherty. NSF/FSE Workshop on the Future of Software Engineering, Nov 2010. The Margrave Tool for Firewall Analysis . Timothy Nelson,Christopher Barratt, Daniel J. Dougherty, Kathi Fisler, ShriramKrishnamurthi. Usenix Large System Administration Conference (LISA) 2010. A Model of Triangulating Environments for Policy Authoring .Kathi Fisler, Shriram Krishnamurthi.ACM Symposium on Access Control Models and Technologies, July 2010. EscapeFrom the Matrix: Lessons From a Case Study in Access-ControlRequirements . Kathi Fisler and Shriram Krishnamurthi.Symposium on Usable Security and Privacy (SOUPS) Poster Session. July2009. ( fulltechnical report version ) Obligations and their Interaction with Programs .Daniel J. Dougherty, Kathi Fisler, and Shriram Krishnamurthi.European Symposium on Research in Computer Security (ESORICS),September 2007. Specifying and Reasoning about Dynamic Access ControlPolicies . Daniel J. Dougherty, Kathi Fisler, and ShriramKrishnamurthi. International Joint Conference on Automated Reasoning(IJCAR), August 2006. Verification and Change Impact Analysis of Access-ControlPolicies . Kathi Fisler, Shriram Krishnamurthi, Leo Meyerovich, and Michael Tschantz. International Conference on SoftwareEngineering (ICSE), May 2005. Synthesizing APIs from Relational Specifications Towards An Operational Semantics for Alloy . DanielJ. Dougherty, Shriram Krishnamurthi, Kathi Fisler, and TheophilosGiannakopoulos. International Conference on Formal Methods (FM).November 2009. Alchemy: Transmuting Base Alloy Specificationsinto Implementations . Shriram Krishnamurthi, DanielJ. Dougherty, Kathi Fisler, and Daniel Yoo. International Conferenceon Foundations of Software Engineering (FSE). November 2008. Features and Capabilities Features and Object Capabilities: Reconciling Two Visions ofModularity. Salman Saghafi, Kathi Fisler, and Shriram Krishnamurthi.International Conference on Aspect-Oriented Software Development(AOSD), Modularity Visions track. March 2012 Timing Diagrams (Diagrammatic Reasoning and Formal Methods) Towards an Aspect Language for Bus Protocols. KathiFisler, Paul Freitas, and Dan Bjorge. Workshop on Domain-SpecificAspect Languages (DSAL), held in conjunction with AOSD, March 2012. Two-Dimensional Regular Expressions forCompositional Bus Protocols (short paper). Kathi Fisler.International Conference on Formal Methods in Computer-Aided Design(FMCAD). November 2007. Temporal Modalities for ConciselyCapturing Timing Diagrams . With Hana Chockler. CHARME 2005. Towards Diagrammability and Efficiency in Event SequenceLanguages . CHARME 2003. (Journal version in SoftwareTools for Technology Transfer 8(4--5): 431--447, 2006). Diagrams and ComputationalEfficacy . In Words, Proofs, and Diagrams, DaveBarker-Plummer, David I. Beaver, Johan van Benthem, and Patrick Scottodi Luzio, editors. CSLI Publications, 2002. On Tableau Constructions for TimingDiagrams . NASA Langley Workshop on Formal Methods, June 2000. Timing Diagrams: Formalizationand Algorithmic Verification . Journal of Logic, Language, and Information; volume 8, number 3, July 1999. Containment of Regular Languages in Non-Regular Timing DiagramLanguages is Decidable . Proceedings of CAV '97, LNCS, June 1997. A Unified Approach to Hardware Verification Through aHeterogeneous Logic of Design Diagrams. PhD Dissertation.Indiana University Department of Computer Science, August 1996 ( abstract , fulldissertation postscript ) Visualizing System Language Relationships with Logic. CADE '96 workshop on Visual Reasoning, July 1996. Exploiting the Potential ofDiagrams in Guiding Hardware Reasoning . In Logical Reasoning with Diagrams, edited by Gerard Allwein and JonBarwise, Oxford University Press, 1996. Integrating Design and Verification Environments Through a LogicSupporting Hardware Diagrams. With Steven D. Johnson. CHDL '95, June 1995. ACanonical Form for Circuit Diagrams . Indiana University TechnicalReport 432, May 1995. ALogical Formalization of Hardware Design Diagrams . Indiana University Technical Report 416.September 1994. Extending Formal Reasoning with Support for Hardware Diagrams. TPCD '94, September 1994. Aspect-Oriented Verification Foundations of Incremental Aspect Model-Checking . ShriramKrishnamurthi and Kathi Fisler. TOSEM 16(2), 2007. Verifying Aspect Advice Modularly . Shriram Krishnamurthi, Kathi Fisler, andMichael Greenberg. International Conferenceon Foundations of Software Engineering (FSE). November 2004. Feature-Oriented Verification DecomposingVerification Around End-Users Features . Kathi Fisler andShriram Krishnamurthi. IFIP Working Conference on Verified Software:Theories, Tools, Experiments, 2005. A Case Study in Using ACL2 for Feature-OrientedVerification . Kathi Fisler and Brian Roberts. Proceedings ofthe ACL2 Workshop. November 2004. Parameterized Interfaces for Open SystemVerification of Product Lines . Colin Blundell, KathiFisler, Shriram Krishnamurthi, and Pascal Van Hentenryck.International Conference on Automated Software Engineering (ASE).September 2004. Modular Verification of Open FeaturesThrough Three-Valued Model Checking . Harry Li, ShriramKrishnamurthi and Kathi Fisler. Journal of AutomatedSoftware Engineering 12(3): 349--382, 2005. Verifying Cross-Cutting Features as OpenSystems. Harry Li, Shriram Krishnamurthi and Kathi Fisler.International Conference on Foundations of Software Engineering.November 2002. Interfaces for Modular FeatureVerification. Harry Li, Shriram Krishnamurthi and KathiFisler. International Conference on Automated Software Engineering.September 2002. The Influence of Software ModuleSystems on Modular Verification. Harry Li, Kathi Fisler, andShriram Krishnamurthi. 9th International SPIN Workshop on ModelChecking of Software. April 2002. Modular Verification ofCollaboration-Based Soft/ware Designs . With ShriramKrishnamurthi. International Conference on Foundations of SoftwareEngineering. September 2001. ( full technical report version ) A Model Checking Framework for Layered Command and ControlSoftware. With Shriram Krishnamurthi, Don Batory, and JiaLiu. Monterey Workshop on Software Engineering, June 2001. Verifying Component-Based Collaboration Designs. With Shriram Krishnamurthi and Don Batory. 4th ICSE Workshop onComponent-Based Software Engineering: Component Certification andSystem Prediction, May 2001. General Computer-Aided Verification Bisimulation and Model Checking . With MosheY. Vardi. Formal Methods in System Design, 2002. Shortversion presented at Conference on Correct Hardware Reasoning Methods(CHARME) 1999. ( full technical reportversion ). Is There a Best Symbolic Cycle-Detection Algorithm? With Ranan Fraer, Gila Kamhi, Moshe Y. Vardi and Zijiang Yang.Proceedings of TACAS 2001, April 2001. Bisimulation Minimization in an Automata-TheoreticVerification Framework . With Moshe Y. Vardi. Proceedings ofthe Conference on Formal Methods in Computer-Aided Design (FMCAD),1998. ( full technical report version ) Testing the FormalCheck Query Library .S. Dershowitz, K. Fisler, S. K. Shukla, G.J. Holzmann, R.P. Kurshan,and D. Peled. Proceedings of LCET 96, Vol. 14, pp. 173-176, LucentTechnologies, 1997. Software Engineering Issues Implementing ExtensibleTheorem Provers. With Shriram Krishnamurthi and KathrynE. Gray. Theorem Proving in Higher-Order Logics: EmergingTrends. INRIA Research Report, September 1999. Verification in Practice Modelling and Model Checking aShared Memory Consistency Protocol. With ClaudeGirault. International Conference on Applications and Theory of Petri Nets, 1998. Verifying VHDL Designs with COSPAN. With R.P. Kurshan. In Formal Hardware Verification: Methods and Systems inComparison, Thomas Kropf, ed, Springer Verlag Lecture Notes inComputer Science 1287, 1997. Verification Using Abstractions, Reductions, and Decompositions: ACase Study in COSPAN. Unpublished report, 1996. Using COSPAN to Partially Verify and Debug a BarcodeReader. AT&TBell Laboratories Technical Memorandum, December 1995. Teaching Issues CounterMeasures: A Game for Teaching Computer Security . Craig Jordan, Matt Knapp, Dan Mitchell, Mark Claypool, and Kathi Fisler. NetGames 2011 [WPI MQP project] \"Little Language\" Project Modules . With John Clements. Journalof Functional Programming Educational Pearl. January 2010. Implementing domain-specific languages as the foundations ofan honors CS course . SIGPLAN Notices 43(11): 66-70, 2008. Teaching Reasoning Using Heterogeneous Logic . With Jon Barwiseand Ruth Eberle. Presented at DIMACS workshop on Teaching Logic in anIllogical World, July 1996.", "https://cs.brown.edu/~kfisler/": "Kathi Fisler Research Professor, Computer Science Co-Director of the CS Undergraduate Program Research Director, Bootstrap (previously Professor, WPI Computer Science ) CIT 309 | 401-863-7607 | kfisler@cs.brown.edu Contact Schedule Publications Brown PLT I'm interested in various facets of how people learn and use formalsystems. My current focus is computing education, where I'm lookingat models and representations for explaining program behavior(notional machines) and how to leverage contrasts between concreteexamples to teach computing concepts. I've been developing a course (and textbook ) on teaching computing through a data-centriclens (data science + data structures). I am also one of the facultyleading the design andassess of our department-wide effort on integrating socially-responsiblecomputing across all four years of our CS curriculum. Through thisproject, I'm trying to understand how people learn to perceive andreason about social systems.I've also worked ondiagrammatic logics for hardware design (late 1990s), modularverification of feature-oriented programs (early 2000s), and reasoningabout access-control and privacy policies (mid-late 2000s). Thoseprojects emphasized formal systems over human reasoning. My work incomputing education tilts the balance, but is part of the same broadtheme. I have been heavily involved in outreach for K-12 computing education since the late 1990s. Almost all of my work is done in collaboration with two terrificteams: the Brown ComputingEducation Research group and Bootstrap (K-12 outreach). Research Teaching Outreach Professional Personal Current Projects Data-Centric ComputingEducation With both computing and data science becomingessential across disciplines, it's time to rethink introductorycomputer science education. We're developing data-centriccomputing as a blend of computer science, data science, and dataengineering that provides skills to students across campus. We have an op-edsummarizing the goal , an introductory collegiatecourse , and a textbook (releasedAugust 2021). Our decisions are driven by our research incomputing education. Our Bootstrap:DataScience curriculum provides a high-school pre-cursor for thosestarting in K-12. Program Design and PlanComposition in Computing Education Programming problemstypically contain multiple subtasks, solutions to which must beintegrated into a single program. This project explores how noviceprogrammers decompose problems and compose subtask immplementations.Our work emphasizes both the impact of programming languages andlibraries on planning behavior, and pedagogies for teaching programdesign, planning, and composition. Cross-Discipline Transfer of Knowledge in Computing Education Bootstrap produces a family of curricula that integrate computing education for middle- and high-school students with other disciplines (such as algebra, physics, and social sciences). The research components of this project study the pedagogical techniques and curricular conditions under which knowledge gained through computing transfers back to the host discipline (and vice-versa for teachers)> Notional Machines for Computing Education Notional machines are the abstract machines that programmers are attempting to control when they write programs. Different programming languages afford different notional machines, which in turn allow different misconceptions about language behavior. We are studying tradeoffs among notional machines and pedagogies for avoiding misconceptions in various CS courses, both intro- and upper-level. Past Projects Security Policy Analysis Analysis of Datalog-based policies, such as those used for access-control and privacy. Our Margrave policy analyzer was a SAT-based engine for verifying properties of policies, as well as for verifying and exploring consequences of changes to policies. We also worked on models of how policies interact with underlying software systems. Feature-Oriented SoftwareVerification Features are cohesive, user-facing behaviors ofsystems. Feature-oriented designs (like aspect-oriented design)modularize code around features. Shriram Krishnamurthi and I developeda theory of compositional verification of feature-based softwaredesigns; our approach generated logical constraints as interfaces onfeatures used in open systems (in which not all features were known inadvance). Formal Reasoning withTiming Diagrams Given a semantics, timing diagrams become aformal representation of system behavior. This project exploredsemantics and analysis techniques for such specifications. I provedthat timing diagram verification is decidable, even though timingdiagrams capture some non-context-free languages. Work and Education History 2017-present: Research Professor and Co-Director of Undergraduate Program in Computer Science , Brown University 2014-2017: Professor of Computer Science , WPI 2007-2014: Associate Professor of Computer Science , WPI 2000-2007: Assistant Professor of Computer Science , WPI 1996-2000: Postdoc and Instructor of Computer Science , Rice University 1997: Summer Intern at IBM Haifa (formal verification group) 1991-1996: PhD student in Computer Science , Indiana University 1987-1991: Undergraduate at Williams College (Computer Science and Asian Studies) Editorial and Program Committees Editorial Board: Communications of the ACM Program Chair for ICER 2022 (junior chair) and 2023 (senior chair) Former Associate Editor: ACM Transactions on Computing Education Former Associate Editor: IEEE Transactions on Education Recent Program Committees: SEET 2024, ICER2021, ICER 2020, ICER 2019, SIGCSE 2018, SIGCSE 2017, ICER 2016 , SIGCSE 2016, ICER 2015 , ISSEP 2015 , SPLASH-E 2014 (Chair), FOSD 2013, FOSD 2012, ABZ 2012 I mostly teach introductory-level courses and research seminars on computing education. I have also taught programming languages, software security, computer-aided verification, and various research seminars. Courses at Brown Spring 2024: CSCI0200 : Program Design with Data Structures and Algorithms (also Spring 2023, Spring 2022) Fall 2022: CSCI0111 : Computing Foundations:Data (also Fall 2021, Fall 2020) Summer 2020: CSCI0180: Computer Science, An Integrated Introduction (also Spring 2020, Spring 2019, Spring 2018) Summer 2019: CS0050 : A Data-Centric Introduction to Programming [ 2017 offering ] Courses at WPI Links are to my last offering of each course, but I taught several of these many times: CS2102 (Object-Oriented Design Concepts) CS525 (Spring 17): Theory and Practice of Computing Education: A Research Seminar CS4536 (Programming Languages) CS4401 (Software Security Engineering) CS1101 (Introduction to Program Design) CS1102 (Accelerated Intro to Program Design) Links to Older Courses TeachScheme/Program by Design I have also developed various TeachScheme exercises and materials over the years. I began doing serious K-12 computer science outreach in 1997, whenI joined the Program byDesign team (then called TeachScheme!). I co-directed Program By Design with Shriram Krishnamurthi, starting in 2000. Bootstrap I co-founded Bootstrap with Emmanuel Schanzer and Shriram Krishnamurthi. Bootstrapproduces a series of CS curricular modules for middle- andhigh-school, with an emphasis on modules that integrate into existingsubjects. We currently have modules that integrate into algebra,physics (science modeling), and social science (data science). Wealso have a computer science module that follows on the algebra module for those looking for a complete introductory CS course. Bootstrap is active on the national level. We train hundreds ofteachers in many states each year, reaching roughly 25,000 studentsper year. We are actively engaged in both national and state-level CSforAll projects, including CS4RI. Details are on the Bootstrap website . Within Bootstrap, I take the lead on grant writing, research and assessment, our partnership with the Oklahoma State Dept of Education, our social studies/data science curriculum, and our software infrastructure for producing curricular materials. We all do a bit of everything though, so feel free to reach out if you have a question about the project. CS Standards Efforts I have been involved in several efforts to develop educational standards for K-12 CS: I was a consultant on the K-12 CS standards for New York. In 2017-18, I was a lead author on the K-12 CS standards for Rhode Island. In 2014-15, I was on the authoring panel that developed the K-12CS/Digital Literacy standards for Massachusetts. I was an advisor to the NationalK-12 CS Framework Project . I was also part of the group that developed the programming languages component of the ACM 2013 CS curriculum. I was a theater junkie through high school. As an undergraduate at Williams College , I rang handbells, worked in the college archives, walked campus backwards giving tours, danced folk and jitterbug, double majored in Chinese and Computer Science, and sang in an acapella group for folks who couldn't carry a tune. These days, I like to hike, sing, exercise, and cook vegetarian food from around the world. Jigsaw puzzles distract me for hours. I love puns and other forms of word-play. As a native New Yorker, I'm a thin-crust pizza snob. Four years living in Houston learned me in salsa. I'm yet to live in a place that offers both great pizza and great salsa.", "http://www.john-meehan.com": "john john meehan meehan PhD Candidate | Brown University CS PhD Candidate Brown University CS john at cs.brown.edu john at cs.brown.edu about I am a PhD candidate at Brown University's Computer Science department , focusing on database research, particularly relating to adding transactions to high-velocity streaming systems. I am advised by Stan Zdonik , and primarily work on the S-Store project with collaborator Nesime Tatbul of Intel Labs. I recently obtained my ScM in computer science at Brown, and am currently in my 3rd year of PhD candidacy. Before Brown, I obtained my undergraduate degree from the University of Notre Dame , and worked for several years as a database engineer at S&P Capital IQ. publications S-Store: A Streaming NewSQL System for Big Velocity Applications Ugur Cetintemel, Jiang Du, Tim Kraska, Samuel Madden, David Maier, John Meehan , Andrew Pavlo, Michael Stonebraker, Erik Sutherland, Nesime Tatbul, Kristin Tufte, Hao Wang, Stanley Zdonik VLDB 2014 document.write('<script src=js/vendor/' + ('__proto__' in {} ? 'zepto' : 'jquery') + '.js><\\/script>') $(document).foundation();", "https://cs.brown.edu/~lbsun/GoodPriors2014/goodpriors2014eccv.html": "Good Image Priors for Non-blind Deconvolution: Generic vs Specific Libin Sun 1 Sunghyun Cho 2 Jue Wang 2 James Hays 1 1 Brown University 2 Adobe Research Abstract Most image restoration techniques build \"universal\" image priors, trained on a variety of scenes, which can guide the restoration of any image. But what if we have more specific training examples, e.g. sharp images of similar scenes? Surprisingly, state-of-the-art image priors don't seem to benefit from from context-specific training examples. Re-training generic image priors using ideal sharp example images provides minimal improvement in non-blind deconvolution. To help understand this phenomenon we explore non-blind deblurring performance over a broad spectrum of training image scenarios. We discover two strategies that become beneficial as example images become more context-appropriate: (1) locally adapted priors trained from region level correspondence significantly outperform globally trained priors, and (2) a novel multi-scale patch-pyramid formulation is more successful at transferring mid and high frequency details from example scenes. Combining these two key strategies we can qualitatively and quantitatively outperform leading generic non-blind deconvolution methods when context-appropriate example images are available. We also compare to recent work which, like ours, tries to make use of context-specific examples. Paper goodpriors_eccv2014.pdf , 20MB Supplementary Materials Full Results , 53MB Poster goodpriors_eccv2014_poster.pdf , 12MB Citation Libin Sun, Sunghyun Cho, Jue Wang, James Hays. Good Image Priors for Non-blind Deconvolution: Generic vs Specific.Proceedings of the European Conference on Computer Vision (ECCV), 2014. Bibtex @inproceedings{goodpriors_eccv2014, Author = {Libin Sun and Sunghyun Cho and Jue Wang and James Hays}, Title = {Good Image Priors for Non-blind Deconvolution: Generic vs Specific}, Booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)}, Year = {2014}} Example Results Comparison of our non-blind deconvolution results against numerous well-known methods in generic non-blind deconvolution (2~5) as well as leading method in example-based deconvolution (8), please choose a test image and click through the slider buttons. Please note that methods 2 through 5 do not make use of specific example images, whereas method 8 and ours do. For full detailed results, please refer to our supplementary material.From left to right: 1.input image with known blur kernel 2. Krishnan and Fergus (2009) 3. Levin et al (2007) 4. Zoran and Weiss (2011) 5. Schmidt et al (2013) 6. Ours (7x7x2 local priors) 7. Groundtruth image 8. HaCohen et al (2013): blind deconvolution, estimated kernel shown in top-left. 9. Ours: non-blind deconvolution, using kernel estimates from 8. Graphics, Visualization & Interaction Group Comments, questions to Libin Sun . changeimg1();", "https://cs.brown.edu/~lspiegel/": "Leonhard Spiegelberg Ph.D. Student@Brown About Hello world! I am a 4th year Ph.D. student in Computer Science at Brown University . My advisors are Dr. Malte Schwarzkopf and Dr. Tim Kraska in the database management group. My research interests include building more efficient big data analytics systems that are designed for modern, UDF driven data pipelines, dealing with dirty data in a better way and designing future systems for sensor-driven Machine Learning products. Furthermore, I am interested in applications for Computer Vision especially for self-driving cars and how to retrieve statistically sound insights from data. Before coming to Brown I was working for Mentat Innovations as Data Scientist and as Machine Learning/Data Engineer for BMW 's self-driving car group. Research Projects Tuplex Data Science in Python at Native Code Speed Tuplex , short for tuples and exceptions , is a novel big data anlytics framework that is inherently more robust to exceptions and errors produced when processing raw data. Written with a powerful C++ backend and easy-to-use Python frontend it provides a novel programming paradigm, an order of magnitude faster execution speed than Apache Spark and efficient parsers for raw data. The project is currently under heavy development and available under tuplex.cs.brown.edu . A preprint can be accessed below. VizCertify A framework for secure data exploration Visual representations of data (visualizations) are tools of great importance and widespread use in data analytics as they provide users visual insight to patterns in the observed data in a simple and effective way. When visualizations are retrieved from sample data however, there is a a risk of visualizing random fluctuations in the sample rather than a true pattern in the data. This problem especially arises when differences between visualizations are compared, e.g. to identify an interesting deviation in a pair of observations among many possible pairs. Using theorems from Vapnik/Chervonenkis we developed a novel framework VizRec to provide a safe space for visualization recommendations. This work has been published in DSAA 2019 . Publications Spiegelberg, L. , Yesentharao, R., Schwarzkopf, M. Kraska, T. (2020). Tuplex: Data Science in Python at Native Code Speed [pub preprint] De Stefani, L., Spiegelberg, L. , Kraska, T., & Upfal, E. (2019). VizCertify: A framework for secure data exploration. [DSAA'19] [pub] [slides] Spiegelberg, L. , Kraska, T. (2019). Tuplex: Robust, Efficient Analytics When Python Rules [VLDB'19] [pub] Engel, J., Scherer, M., & Spiegelberg, L. (2017). One-Factor L\u00e9vy-Frailty Copulas with Inhomogeneous Trigger Rates. In M. B. Ferraro, P. Giordani, B. Vantaggi, M. Gagolewski, M. \u00c1ngeles Gil, P. Grzegorzewski, & O. Hryniewicz (Eds.), SMDS'17 Other Projects This is a (non-complete) list of other projects I have been working on in the past: Picture Perfect Plates Building a model to classify restaurant images We developed a computer vision from the ground up to classify restaurant images into different categories together with TripAdvisor, Inc . More can be read about this project here and here . Two-stage Dictionary Selection via greedy selection In this project we developed a two-stage optimization algorithm for dictionary selection under a supermodular assumption that is based on greedy minimization of weakly supermodular set functions. Our final report can be found here . Adaptive Extendible Hashmaps with a better in-bucket strategy Extendible Hashmaps are a commonly used data-structure in filesystems or databases for dynamic hashing (i.e. a growable hashmap). In this work we relaxed the assumption of using fixed buckets and experimented with different in-bucket structures to adapt better to different workloads. Ordinal regression in Apache Spark With ratings and curated lists being widespread, ordinal regression is a modified version of the popular linear model that takes the ordering property of such data into account. In this project we extended Spark by an ordinal regression model and performed various experiments. All content copyright L. Spiegelberg \u00a9 2017-2020.", "https://cs.brown.edu/~ml137/": "Molly Long About Design Coding Hi! I'm currently a junior at Brown University studying computer science. I'm an aspiring developer who likes to build cool stuff in my free time, while honing on my creative pursuits on my spare time. When I'm not studying, I love petting bunnies, eating chocolate croissants and instagramming things that inspire me. Feel free to contact me for an ice cream date! Some press: Google Student Blogpost CBS News: Why are women not pursuing tech jobs? 2 Billion Under 20 NAF Alumni scholarship", "https://cs.brown.edu/~mlittman/courses/hcri14/": "CS 1951C, Designing Humanity Centered Robots, Spring 2014 Brown University Fall 2014 Michael L. Littman Ian Gonsher steamstudio.us browncreativemind.com Andrew Harpin Time : Tue/Thu 9am-10:20am Place : CIT Center (Thomas Watson CIT) 345 Semester : Fall 2014 Office hours: By appointment. Description The course has two tracks, one intended for CS concentrators, and oneintended for non-concentrators with previous design experience. Thenon-concentrator track cannot be used toward fulfilling a ComputerScience concentration requirement. Prerequisites : Permission of an instructor. telepresence robots Planned Schedule Date (Place) In Class Assignment Thu 9/4 (CIT 345) Introduction . Each student test-drives an existing telepresencerobot to understand its capacity and limitations. Students will testthe following telepresence robots: VGo, Beam, and, a Roomba-basedkit. Collect contact information. Get your paragraphs in. Tue 9/9 (BDW) Context . Students continue to explore robot-mediatedhuman-to-human interaction. In-class assignment : Ideation exercise. We will begin in a group with a big roll of paper and sharpies,identifying areas of telepresence we want to explore. Then, webreak into groups of 3-4 to refine some of the better ideas. Set up tumblr blog. Thu 9/11 (CIT 345) Sketches . Develop an idea from last week in a small group. Begin creating a small 3-d model and scenario to motivate your design. Meet outside of class to refine the ideafurther, prepare a short presentation for next Thursday's class. Tue 9/16 (CIT 345) Field Trip . We will travel to St. Elizabeth's nursing and rehab center in East Greenwich. Students will observe telepresence robots in a real-world environment to understand their shortcomings and identify areas of improvement. Brainstorm about \"Better World By Design\". Thu 9/18 (CIT 345) Stories . Share your 3-d model and scenario for feedback. Iterate the design. Tue 9/23 (BDW) Laser cutters . Ian will run a tutorial in the Brown Design Workshop. (Michael is away.) Thu 9/25 (Rosh Hashana) Industrial design . In-class presentation from Prof. Michael Lye. Tue 9/30 Quarter scale . Read last week's stories out loud. Now, pairs create a quarter-scale sketchmodel of an improved telepresence robot that utilizes one additionalfeature to enhance human interaction. Complete models. Thu 10/2 Building up . Group review of quarter-scalesketch models. After the review, we will combine groups with similarthemes and interest to form groups of 4 students in total. Each of these newly formed groups will meet up with instructors individually to identify one consistent group concept. After identifying the group concept, create a full-scale cardboard mock-up that highlights the new feature(s) of your telepresence robot without neglecting proportions. Tue 10/7 Cardboard . Continue to work on cardboard prototypes. Learn some mock-up techniques. Complete prototype. Thu 10/9 (BDW) Kits . Group review of full-scale cardboard mock-ups. Switching modes to introduction of robot kit consisting of a base on wheels and a laptop. This kit will act as the foundation for building up to the final prototype. We will work together in class to create a rough mockup for how to mount the computer on the robot base using materials such as cardboard, chipboard, and foamcore. Complete the first iteration robot, dealing with the constraints of the Roomba and the computer. Tue 10/14 (BDW) Body . The goal for this week is to create a version of the robot from last time using refined materials (plastic, metal, wood). Complete the second iteration robot. Thu 10/16 (BDW) Refinement . Feedback on 2nd iteration robots. Hone second iteration robot based on feedback. Tue 10/21 Servos . Learning about motors, servos, microphones, Arduinos. This introduction will help students to understand how to control mechanical functions remotely via Arduino. We will work on creating a simple mechanical function to add to your telepresence robot.The custom-made mechanical components needed for this assignment can be made out of very basic materials such foam core and straight pins. At this point, do not focus on aesthetics or machined precision. Complete servo project. Thu 10/23 Control . We will augment the telepresence software to allow remote control of the servo. Experiment with interface. Tue 10/28 Project . We will review the servo controls created by each group. At this point, we transition to the design and creation of the final projects. Individual desktop reviews with each group. (Michael away.) Design sketches, concepts. Thu 10/30 Maker bot . Introduction of MakerBot desktop rapid prototype machine. Individual desktop reviews with each group. Small scale mockup. Tue 11/4 Progress review . Presentations of (1) Full-scale cardboard/foam core mock-up that houses the provided kit with functioning motor(s) and servo(s), (2) Drawing/collage that places your telepresence robot in a specific environment, (3) Your motor/servo assignment, (4) Additional support material as sketches and drawings are optional. Thu 11/6 Progress review . Complete reviews/feedback/discussion. Rebuild and refine full-scale cardboard/foam core mock-up according to progress review feedback. Tue 11/11 Construction . Final construction of your final prototype starts. Individual desktop reviews with each group to discuss construction process. Thu 11/13 Work . Tue 11/18 Work . Individual desktop reviews with each group. Thu 11/20 Work . Tue 11/25 Work . Individual desktop reviews with each group. Thu 11/27 (Thanksgiving) Greetings . Maybe some people can stop in on each other's celebrations via robot. Tue 12/2 Final crit . Presentation material includes: (1) Final prototype. (2) Drawing/collage that places your telepresence robot in a specific environment, (2) Additional support material as sketches, drawings, and mock-ups are optional. Thu 12/4 Final crit . Tue 12/9 Wrap-up review . Presentation of refined prototype that incorporates feedback of final crit. Thu 12/11 Discussion . What impact could our designs have? How could we know? What are the next steps to making them a reality? _uacct = \"UA-1439895-1\";urchinTracker();", "https://marilyngeorge.com/": "Toggle navigation Home Publications CV I am a Research Scientist in the Cryptography Research Group at MongoDB. I currently focus on designing practical techniques for leakage suppression in structured encryption. Before this, I was a Ph.D. student in the Brown University Encrypted Systems Lab , working with Professor Seny Kamara . Recent News [Aug 2023] Queryable Encryption has gone GA ! [Aug 2023] Participated in the StorySLAM for RISE at CRYPTO 2023. [July 2023] Our work on Synq: Public Policy Analytics over Encrypted Data is accepted to IEEE S&P 2024. [Aug 2022] Joined the Cryptography Research Group at MongoDB as a Research Scientist. [May 2022] Defended my thesis on Compliant and Secure Databases. Marilyn George marilyn.george at mongodb.com MongoDB Inc. 1633 Broadway New York City, NY Google Scholar Publications Synq: Public Policy Analytics over Encrypted Data Z. Espiritu, M. George , S. Kamara, L. Qin IEEE S&P 2024 (proceedings pdf ) On the Cost of Suppressing Volume for Encrypted Multi-maps M. Ando, M. George PETS 2022 (proceedings pdf ) GDPRizer: Retrofitting GDPR Compliance onto Legacy Databases A. Agarwal, M. George , A. Jeyaraj, M. Schwarzkopf VLDB 2022 (proceedings pdf ) Adversarial Level Agreements for Two-Party Protocols M. George , S. Kamara AsiaCCS 2022 (proceedings pdf ) IACR Cryptology ePrint Archive (full pdf ) Structured Encryption and Dynamic Leakage Suppression M. George , S. Kamara, T. Moataz EUROCRYPT 2021 (proceedings pdf ) Towards Untrusted Social Video Verification to Combat Deepfakes via Face Geometry Consistency E. Tursman, M. George , S. Kamara, J.Tompkin Workshop on Media Forensics, CVPR 2020 (proceedings pdf ) Plain Academic", "http://people.csail.mit.edu/kraska/index.html": "Tim Kraska Associate Professor, MIT Home Biosketch Research People Teaching Publications Awards & Grants I am an Associate Professor of Electrical Engineering and Computer Science in MIT's Computer Science and Artificial Intelligence Laboratory (CSAIL) , founding co-director of the Data System and AI Lab (DSAIL) at MIT, and co-founder of einblick analytics, inc. My group aims to dramatically increase the efficiency of data-intensive systems and democratize data science by enabling a broader range of users to unfold the potential of (their) data through the development of a new generation of algorithms and systems. This entails exploring how we can build systems to better support the recent advances in machine learning (Systems for ML) and how we can leverage machine learning to improve systems (ML for Systems) .For example, with our work on SageDB we started to explore how we can enhance or even replace core systems components using machine learning models and early results suggest, that we can improve the state-of-the-art by more than an order-of-magnitude in performance.On the other hand, with Northstar we are exploring new user interfaces and infrastructure to democratize data science by enabling visual, interactive, and assisted data exploration and model building. One particular focus of this work is to help all types of users to analyse data and build models faster, but also make data exploration and model building safer by automatically preventing the user from common pitfalls. Our work has been featured several times by the media ( TechCrunch , Science , O'Reilly among others) and we are proud, that we had significant impact on academia and industry. For example, Northstar is now being commercialized by einblick analytics backed by venture capital and our ML for Systems work is getting extended by countless researchers around the world (for a slightly outdated overview see our SIGMOD 2019 tutorial on Learned Data Structuresand Algorithms ) and is even finding its way into some cloud products of leading internet companies. I am fortunate to be working with an outstanding team of grad student, under-graduates, and post-docs , with numerous collaborators from academia and industry, and grateful for the research funding we have been receiving from NSF, DARPA, Airforce, Google, Microsoft, and Intel . Biosketch Research Statement Current Research Interests ML-enhanced data structures and algorithms Systems for interactive data exploration and model building Infrastructure for rack-scale analytics and machine learning Transaction processing over high-speed networks Hybrid human-machine data management systems Research Projects In the following, a list of my current and past research projects: Learned Systems Components - How to Enhance traditional data structures and algorithms through machine learning Northstar - A System for Interactive Data Science NAM - Redefining Databases for the Next Generation of Networks QUDE - Quantifying the Uncertainty in Data Exploration Tupleware - Redefining Modern Analytics on Modern Hardware MLBase - The Distributed Machine-Learning Management System S-Store - A streaming OLTP system for big velocity applications MDCC - The Fastest Strong Consistent Multi-Data Center Replication Protocol CrowdDB - Answering Queries with Crowdsourcing PIQL - Performance Insightful Query Language Cloudy/Smoky - a distributed storage and streaming service in the cloud Building a database on cloud infrastructure CloudBench - a benchmark for the cloud Zorba - a general purpose XQuery processor implementing in C++ MXQuery - A lightweight, full-featured Java XQuery Engine Mapping Data to Queries (MDQ) - data integration with XQuery XQIB - XQuery In the Browser Room 32-G914 MIT - CSAIL 32 Vassar St. Cambridge, MA 02139 var parts = [\"kraska\", \"mit\", \"edu\", \"&#46;\", \"&#64;\"]; var email = parts[0] + parts[4] + parts[1] + parts[3] + parts[2]; document.getElementById(\"email\").innerHTML=email; Phone: +1 (510) 926-5856 !function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs'); News August 31, 2020 I am giving an online keynote about learned systems at AIDB@VLDB as well as I am organizing a round-table on the same topic at VLDB. August 11, 2020 Our work on learned storage systems and query optimizers is featured on MIT News . May 10, 2020 Our paper on automatic joins to improve model prediction got accepted at VLDB. ARDA: Automatic Relational Data Augmentation forMachine Learning . March 26, 2020 We got 8 papers accepted at SIGMOD 2018 (7 research, 1 demo). In addition we also already got an ICDE paper and an SMDB paper accepted. Just a pity that most of these conferences might end up to be virtual. January , 2020 Erfan Zamanian successfully defended his PhD thesis. Big congrats!!! October 5, 2019 We got 1 NIPS paper, 5 workshop papers at NIPS, and 1 workshop paper at the AI Systems Workshop at SOSP accepted. I am particular proud of Darryl Ho's (he is an undergraduate at MIT) work on using learning to improve DNA index search. August 12, 2019 The VLDB 2019 tutorial slides on Learned and Self-Designed Data Structures and Algorithms are now uploaded. Support \u00a9 2020 Tim Kraska | Accessibility | Based on a Design by NodeThirtyThree . var _gaq = _gaq || []; _gaq.push(['_setAccount', 'UA-36125292-1']); _gaq.push(['_trackPageview']); (function() { var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; ga.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 'stats.g.doubleclick.net/dc.js'; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })();", "https://cs.brown.edu/~novotny/intl_amb/": "<div style=\"min-height:120px\"><nobr><img style=\"float: left; margin: 10px 10px 10px 10px;\" src=\"portraits/<%= portrait%>\" height=\"100px\"/> <div style=\"float: left\"><h4><a href=\"<%= site%>\"><%= stud %> <img src=\"files/ico_external.png\" /></a></h4><p><%= name %><br><a href=\"email:<%= mail%>\"><%= mail%></a></p></div></nobr></div> var width = 900, height = width * 5/9; var radius = d3.scale.sqrt() .domain([0, 200]) .range([0, 20]); var formats = { percent: d3.format('%') };var openTooltip = null;var projection = d3.geo.mercator().scale(height/3.5).translate([width / 2, height*6 / 9]).precision(.1); var path = d3.geo.path().projection(projection); var svg = d3.select(\"body\").append(\"svg\") .attr(\"width\", width) .attr(\"height\", height); queue() .defer(d3.json, 'files/world.json') .defer(d3.json, 'files/student_info.json') .await(ready); // template, for later var template = _.template(d3.select('#tooltip-template').html()); function ready(error, world, centroid) { var countries = svg.append(\"path\") .attr(\"class\", \"countries\") .datum(topojson.feature(world, world.objects.countries)) .attr(\"d\", path); var students = svg.selectAll(\".symbol\") .data(centroid.features) .enter().append(\"path\") .attr(\"class\", \"symbol\") .attr(\"d\", path.pointRadius(8)); students.on('mouseenter', tooltipShow); svg.on('click', tooltipHide); } function tooltipShow(d, i) { var datum = d.properties; if (!datum) return; datum.formats = formats;if(_.isEqual(openTooltip, $(this))) {return;}if(openTooltip) openTooltip.tooltip('hide'); openTooltip = $(this).tooltip({animation: false, title: template(datum), html: true,trigger: 'manual', container: svg.node().parentNode, placement: 'auto' }).tooltip('show'); } function tooltipHide(d, i) { if(openTooltip) openTooltip.tooltip('hide');openTooltip = null; //$(this).tooltip('hide'); }function tooltipUpdate() { if(openTooltip) {//openTooltip.tooltip({animation: false});openTooltip.tooltip('hide');openTooltip.tooltip('show');//openTooltip.tooltip({animation: true});}//openTooltip = null; //$(this).tooltip('hide'); }", "https://nkhan2.github.io": "Numair Khan I am a research scientist at Meta Reality Labs in Redmond, Washington. I work on computer vision and machine learning for applications in computational photography. I completed my PhD at Brown where I was advised by James Tompkin . I received a Fulbright Scholarship for my Masters at the Courant Institute of New York University where my Master's thesis was advised by Ken Perlin . Email &nbsp/&nbsp CV &nbsp/&nbsp Google Scholar Research Your browser does not support the video tag. function gauffre_start() { document.getElementById('gauffre_image').style.opacity = \"1\"; } function gauffre_stop() { document.getElementById('gauffre_image').style.opacity = \"0\"; } gauffre_stop() GauFRe: Gaussian Deformation Fields for Real-time Dynamic Novel View Synthesis Yiqing Liang , Numair Khan , Zhenqin Li , Thu Nguyen-Phuoc , Douglas Lanman, James Tompkin , Lei Xiao , ArXiv , 2024 &nbsp arXiv / project page / bibtex We propose a method for dynamic scene reconstruction based on a deformable set of 3D Gaussians residing in a canonical space, and a time-dependent deformation field defined by a multi-layer perceptron (MLP) Your browser does not support the video tag. function texturedreamer_start() { document.getElementById('texturedreamer_image').style.opacity = \"1\"; } function texturedreamer_stop() { document.getElementById('texturedreamer_image').style.opacity = \"0\"; } texturedreamer_stop() TextureDreamer: Image-guided Texture Synthesis through Geometry-aware Diffusion Yu-Ying Yeh , Jia-Bin Huang , Changil Kim , Lei Xiao , Thu Nguyen-Phuoc , Numair Khan , Cheng Zhang , Manmohan Chandrakar , Carl Marshall , Zhao Dong , Zhenqin Li , ArXiv , 2024 &nbsp arXiv / project page / bibtex We present a novel image-guided texture synthesis method to transfer relightable textures from a small number of input images to target 3D shapes across arbitrary categories. Your browser does not support the video tag. function tmpi_start() { document.getElementById('tmpi_image').style.opacity = \"1\"; } function tmpi_stop() { document.getElementById('tmpi_image').style.opacity = \"0\"; } tmpi_stop() Tiled Multiplane Images for Practical 3D Photography Numair Khan , Douglas Lanman, Lei Xiao , ICCV , 2023 &nbsp arXiv / code [coming soon] / bibtex We propose a method for generating tiled multiplane images with only a small number of adaptive depth planes for single-view 3D photography in the wild. Your browser does not support the video tag. function tcod_start() { document.getElementById('tcod_image').style.opacity = \"1\"; } function tcod_stop() { document.getElementById('tcod_image').style.opacity = \"0\"; } tcod_stop() Temporally Consistent Online Depth Estimation Using Point-Based Fusion Numair Khan , Eric Penner, Douglas Lanman, Lei Xiao , CVPR , 2023 &nbsp arXiv / code / bibtex We aim to estimate temporally consistent depth maps of video streams in an online setting by using a global point cloud along with a learned fusion approach in image space. function neuralfields_start() { document.getElementById('neuralfields_image').style.opacity = \"1\"; } function neuralfields_stop() { document.getElementById('neuralfields_image').style.opacity = \"0\"; } neuralfields_stop() Neural Fields in Visual Computing and Beyond Yiheng Xie , Towaki Takikawa , Shunsuke Saito , Or Litany , Shiqin Yan , Numair Khan , Federico Tombari James Tompkin Vincent Sitzmann Srinath Sridhar Eurographics State-of-the-Art Report , 2022 project page / website / arXiv We present a comprehensive review of neural fields by providing context, mathematical grounding, and an extensive literature review. A companion website contributes a living version that can be continually updated by the community. function diffdiff_start() { document.getElementById('diffdiff_image').style.opacity = \"1\"; } function diffdiff_stop() { document.getElementById('diffdiff_image').style.opacity = \"0\"; } diffdiff_stop() Differentiable Diffusion for Dense Depth Estimation from Multi-View Images Numair Khan Min H. Kim , James Tompkin CVPR , 2021 project page / code / arXiv / bibtex A method to estimate dense depth by optimizing a sparse set of points such that their diffusion into a depth map minimizes a multi-view reprojection error from RGB supervision. function bidirectional_start() { document.getElementById('bidirectional_image').style.opacity = \"1\"; } function bidirectional_stop() { document.getElementById('bidirectional_image').style.opacity = \"0\"; } bidirectional_stop() Edge-Aware Bidirectional Diffusion for Dense Depth Estimation from Light Fields Numair Khan , Min H. Kim , James Tompkin BMVC , 2021 arXiv / project page / code / bibtex We present an algorithm to estimate fast and accurate depth maps from light fields via a sparse set of depth edges and gradients. Your browser does not support the video tag. function vclfd_start() { document.getElementById('vclfd_image').style.opacity = \"1\"; } function vclfd_stop() { document.getElementById('vclfd_image').style.opacity = \"0\"; } vclfd_stop() View-Consistent 4D Light Field Depth Estimation Numair Khan , Min H. Kim , James Tompkin BMVC , 2020 arXiv / project page / code / bibtex We propose a method to compute depth maps for every sub-aperture image in a light field in a view-consistent way. Your browser does not support the video tag. function vclfs_start() { document.getElementById('vclfs_image').style.opacity = \"1\"; } function vclfs_stop() { document.getElementById('vclfs_image').style.opacity = \"0\"; } vclfs_stop() View-Consistent 4D Light Field Superpixel Segmentation Numair Khan , Qian Zhang , Lucas Kasser, Henry Stone, Min H. Kim , James Tompkin ICCV , 2019 (Oral Presentation) paper / code / bibtex We use occlusion-aware angular segmentation of an Epipolar Plane Image (EPI) to generate light field superpixels that are consistent across views. function minimap_start() { document.getElementById('minimap_image').style.opacity = \"1\"; } function minimap_stop() { document.getElementById('minimap_image').style.opacity = \"0\"; } minimap_stop() Rethinking the Mini-Map: A Navigational Aid to Support Spatial Learning in Urban Game Environments Numair Khan , Anis Ur Rahman IJHCI , 2017 paper / bibtex We propose landmark-based verbal directions as an alternative to mini-maps, and examine the development of spatial knowledge in an open-world urban game environment. Data Analysis and Call Prediction on Dyadic Data from an Understudied Population Mehwish Nasim, Aimal Rextin, Shumaila Hayat, Numair Khan , Mudassir Malik Pervasive and Mobile Computing , 2017 paper / bibtex Predicting outgoing mobile phone calls using machine learning and time clusters-based approaches. Space-Efficient Pointwise Computation of the Distance Transform on GPUs Numair Khan , Mohamed Zahran International Parallel and Distributed Processing Symposium Workshops (IPDPSW) , 2017 paper / bibtex The distance transform is decomposed into a map-and-reduction pattern for efficient computation on GPUs. Understanding Call Logs of Smartphone Users for Making Future Calls Mehwish Nasim, Aimal Rextin, Numair Khan , Mudassir Malik International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI) , 2016 paper / bibtex In this measurement study, we analyze whether mobile phone users exhibit temporal regularity in their mobile communication. Misc In Search of a Strategy Against Misinformation I, Entrepreneur The Essentials of a Computer Scientist's Toolkit Teaching Assistant, CSCI 1290 - Computational Photography, Fall 2020 Teaching Assistant, CSCI 1290 - Computational Photography, Fall 2018 Teaching Assistant, CSCI 2240 - Interactive Computer Graphics, Spring 2018 Instructor, Advanced Programming Spring 2016 Instructor, Operating Systems Fall 2015 The source code for this website was copied from Jon Barron's website. It is freely available for personal use here .", "https://cs.brown.edu/~pck/": "This web site is dedicated to the memory of Paris Christos Kanellakis Dec. 3, 1953 - Dec. 20, 1995 Professor, Computer Science Dept. Brown University, Providence RI, USA \"He combined Mediterranean passion about all aspects of life - family, friends, colleagues, his research, and teaching - with great precision of thought and language.&quot Andries van Dam, Brown University In Honor of Paris Awards and Fellowships The ACM Paris Kanellakis Theory and Practice Award The Kanellakis Graduate Fellowship at Brown The Kanellakis Graduate Fellowship at MIT The Kanellakis Fellowship at NTUA ( In Greek ) Events (If you are organizing an event in memory of Paris, please email alexpap at cs.brown.edu to include a link to your event on this page.) The annual Paris Kanellakis Lecture at Brown If you would like to be included to the mailing list for this lecture series, please email alexpap at cs.brown.edu. Principles of Computing and Knowledge, an FCRC 2003 Workshop ( Proceedings ) The 1st Hellenic Data Management Symposium (HDMS 2002) Past events Remembering Paris An announcement from the Brown News Bureau of a Memorial Service at Brown University on Jan. 29, 1996. Here is the speech presented at the service by Eugene Charniak , then chair of the department. Articles from the Associated Press and the Brown Daily Herald about the accident, Paris and his family. Paris' Professional Life Paris' unfinished work - Paris was involved in many professional activities (in PostScript) Paris' CV - as he left it (in PostScript) Technical Obituary - appeared in Computing Surveys , March 1996 issue (in PostScript) A partial list, with e-mail addresses, of Paris' co-authors and colleagues . Paris' Other Side An article (in PS) about Brown's sexual harassment policies, published in the faculty bulletin. A cartoon illustrating the `ISA' principle. Some quotes collected by the students in Paris' Theory of Computation course. Paris' Publications Journal Articles , Book Chapters , Conference Abstracts , Miscellaneous Manuscripts This page is maintained by Alexandra Papoutsaki (alexpap at cs.brown.edu).", "https://cs.brown.edu/~pvaliant/": "Website moved!", "https://cs.brown.edu/people/pfelzens/engn2520/": "ENGN 2520 Pattern Recognition and Machine Learning Instructor: Pedro Felzenszwalb Office: Barus & Holley 355 Email: pff (at) brown.edu Office hours: Thursday 1pm-2pm in B&H 355 Course Description This course will cover fundamental concepts in pattern recognition and machine learning. We will focus on mathematical formulations and computational methods that are broadly applicable. Topics include supervised learning, parametric and non-parametric models, decision theory, bayesian inference, dimensionality reduction, clustering, feature selection, generalization bounds, support vector machines and neural networks. We will consider motivating applications in computer vision, signal processing, medical diagnostics, and information retrieval. Prerequisites: probability and statistics, linear algebra, calculus and programming experience. Textbook: C. Bishop, Pattern Recognition and Machine Learning, Springer. Grading: Grading will be based on regular homework assignments and a final exam. Homework will involve both mathematical exercises and programming assignments/projects. Students can use python or Matlab for programming.", "https://cs.brown.edu/people/pfelzens/engn2912p/": "Topics in Optimization (ENGN 2912P) Home Assignments Lectures Lecture: MWF 11am-11:50am in Barus & Holley 159 Instructor Pedro Felzenszwalb Email: pff (at) brown.edu Office: Barus & Holley 355 Office hours: Monday 2-4pm in BH355 TA Jeroen Chua Email: jeroen_chua (at) brown.edu Office hours: Thursday 2-4pm in BH317 Course description This course will cover various topics in discrete and continuousoptimization. Topics include graph algorithms, dynamic programming,linear programming, convex optimization and coarse-to-fine methods. References Combinatorial Optimization. Schrijver. Springer. Introduction to Algorithms. Cormen, Leiserson, Rivest, Stein. MIT Press. The Design and Analysis of Computer Algorithms. Aho, Hopcroft, Ullman. Addison-Wesley. Algorithm Design. Kleinberg, Tardos. Addison-Wesley. Randomized Algorithms. Motwani and Raghavan. Preliminary list of topics for 2015 Shortest paths - Dijkstra, Bellman-Ford, Floyd-Warshall - Min-plus matrix multiplication - Minimum-ratio paths - String edit and time warping Flow - Max-flow / Min-cut - Min-cost circulation - Bipartite matching Linear programming - Simplex - Duality Dynamic programming - Sequence labeling - Graph labeling - Piecewise quadratic fitting Approximation algorithms - Min-cover (greedy) - Max-cut (local search) - Packing (rounding + DP) - LP relaxations Other topics - Randomized Algorithm - Branch-and-bound - Heuristic search - Local search - Convex optimization", "https://cs.brown.edu/people/pfelzens/engn2520-2012/": "ENGN 2520 Pattern Recognition and Machine Learning Spring 2012 Lecture: Tue/Thu 2:30pm-3:50pm Location: Barus & Holley 159 Instructor: Pedro Felzenszwalb Email: pff (at) brown.edu Office: Barus & Holley 355 Office hours by appointment Course description Textbook Grading Homework Homework 1 Data for programming assignment Homework 2 Due Wednesday February 22 by 4pm Data for programming assignment Homework 3 Due Friday March 9 by 4pm Homework 4 Due Friday April 6 by 4pm Data for programming assignment Homework 5 Due Thursday May 3 by 4pm Data for programming assignment Final exam Take-home Lectures Lecture Date Topic Reference (book sections) 1 January 26 Introduction and overview 2 January 31 Linear models for regression, basis functions, least squares 1.1, 3.1 3 February 2 Linear models for regression, regularization, probabilistic perspective 3.1.1, 3.1.2, 3.1.4 4 February 7 Classifiers, decision theory 1.5, 1.5.1 5 February 9 Decision theory, loss functions 1.5.2 6 February 14 Naive bayes classifier, ML estimation 4.2.2, 4.2.3 7 February 16 Linear threshold classifier, Perceptron 4.1.7 8 February 23 Linear Support Vector Machines 7.1, 7.1.1 9 February 28 Generalization bounds, VC-dimension 7.1.5 10 March 1 Kernels 6, 6.1 11 March 6 Sequential data 13, 13.1 12 March 8 Hidden Markov Models 13.2 13 March 13 HMM computation (forward/backward) Rabiner 14 March 15 HMM computation (viterbi) Rabiner 15 March 20 Bayesian networks 8.1, 8.2 16 March 22 Bayesian networks 17 April 3 Markov Random Fields 8.3.1, 8.3.2, 8.3.4 18 April 5 MRFs for image analysis 8.3.3 19 April 10 Markov chains 11.2 20 April 12 Gibbs sampling 11.3 21 April 17 Clustering, k-means 9.1 22 April 19 Mixtures of gaussians 9.2 23 April 24 Expectation Maximization 9.4 24 April 26 Principal Component Analysis 12.1 25 May 1 Linear Discriminant Analysis & Random Projections", "https://www2.cs.arizona.edu/~pachecoj/": "Home Publications Courses Code Office: Gould-Simpson, Rm. 724 Mailing Address University of Arizona Department of Computer Science 1040 E 4th St. Tucson, AZ 85721 Jason L. Pacheco Statistical Machine Learning and Stochastic Systems About me. I am an Assistant Professor in the Department of Computer Science at the University of Arizona in sunny Tucson Arizona. Before joining UA I completed my PhD in Computer Science at Brown University with Erik Sudderth . I also held a postdoc position at MIT CSAIL with John Fisher III . Research. My research in statistical machine learning aims to build intelligent systems for automated reasoning in stochastic systems. To achieve this requires the development of algorithms that yield efficient inferences, while remaining flexible enough to adapt to complex domains. My research interests span a variety of application domains including computer vision, signal processing, computational biology, and computational neuroscience. For more details see my CV . For more information about machine learning at UA see our website. Recent News Our paper Efficient Variational Sequential Information Control was accepted to AISTATS 2024 Our paper On Convergence of Polynomial Approximations to the Gaussian Mixture Entropy was accepted to NeurIPS 2023 Our paper Fast Variational Estimation of Mutual Information for Implicit and Explicit Likelihood Models was accepted to AISTATS 2023 Recieved the Air Force Office of Scientific Research (AFOSR) Young Investigator Program (YIP) award for Robust Maximum Entropy Planning, Learning, and Control in Uncertain Environments Interested in working with me? I am happy to collaborate with motivated students! If you would like to join my group, see the following items before emailing me: Take my classes CSC 535 : Intro. to Probabilistic Graphical Models or CSC 665 : AdvancedTopics in Probabilistic Graphical Models . If you wish to work with me as a PhD student read more here . Checkout some of my recent publications for project ideas. \u00a9 Jason Pacheco, 2019", "https://matteo.rionda.to/": "(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-46147553-2', 'auto'); ga('require', 'linkid'); ga('send', 'pageview'); Matteo Riondato Home Short Bio CV (Updated: Feb 22) Publications Teaching Service Software Misc Contact info E-mail: rionda@acm.org Office: Science Center C214 Twitter: @teorionda Mastodon: @matteo@bsd.network GitHub: rionda Group: Data* Mammoths I am an associate professor of computerscience at AmherstCollege , where I lead the Data* Mammoths , aresearch&learning group of brilliant undergraduate students. Ialso have an appointment as visiting faculty in Computer Science at BrownUniversity . Previously, I spent some fantastic years as aresearch scientist in the Labs group at Two Sigma . My research focuses on algorithms for knowledge discovery , data mining ,and machine learning . I develop theory and methodsto extract the most information from large datasets, as fast aspossible and in a statistically sound way. The problems I studyinclude pattern extraction, graph mining, and time series analysis.My algorithms often use concepts from statistical learning theory andsampling. My research is supported, in part, by NSFCAREER Award #2238693 and by NSFAward #2006765 . My Erd\u0151snumber is 3 ( Erd\u0151s \u2192 Suen \u2192 Upfal \u2192 Matteo),and I am a mathematicaldescendant of EliUpfal , EliShamir (2 nd generation), JacquesHadamard (5 th ), Sim\u00e9onDenis Poisson (9 th ), and Pierre-SimonLaplace (10 th ). News Dagstuhl: With Eli and Aris , I'morganizing a 5-day workshop on Statistical andProbabilistic Methods in Algorithmic Data Analysis in Dagstuhl . So glad to go back tothe beautiful Schl\u00f6ss! KDD'24: Happy to help out the organization asa Co-chair of the PhD Consortium. CogMI: I am giving an invited talk on Statistically-soundKDD at this interesting conference bringing togetherresearchers from different areas. KAIS: the journal version of Alice was accepted tothe KAIS special issue for the best papers of IEEE ICDM'22. Tenure+Promotion: Since July 1, I am atenured associate professor of computer science! I'm over the moonabout this! NSF CAREER: I received a $600k NSFCAREER award to work on Statistically-soundKnowledge Discovery from Data (my SDM'23blue-sky-idea paper has more details about what I plan to do).I am extremely thankful for the trust from the community and NSF,and excited for 5 years of work ahead! DMKD/DAMI (ECML PKDD'23): the Data* Mammoths publishedanother paper: Maryam and Alex introduce ROhAN , a new set ofnull models for Statistically-sound KDD. News archive \u00a9 2024 Matteo Riondato \u2014 Licensed under a Creative Commons Attribution-ShareAlike 4.0 International License \u2014 Last modified: Feb 22, 2024"}